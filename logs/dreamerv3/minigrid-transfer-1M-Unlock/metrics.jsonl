{"step": 1156, "time": 63.91413164138794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1156, "time": 63.93900394439697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1156, "time": 65.05155396461487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1156, "time": 65.05810046195984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1300, "time": 66.24996733665466, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1300, "time": 66.25728392601013, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1300, "time": 66.26237726211548, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1300, "time": 66.26811671257019, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 100.5361499786377, "eval_episode/length": 272.0, "eval_episode/score": 0.15000000596046448, "eval_episode/reward_rate": 0.003663003663003663}
{"step": 1560, "time": 100.77277135848999, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 100.77925539016724, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 100.78532004356384, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 104.72867393493652, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 104.9666895866394, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 104.97315216064453, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 104.97909712791443, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 223.36166739463806, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.88385009765625, "train/action_min": 0.0, "train/action_std": 1.8536540269851685, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0009237260674126446, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.7417198419570923, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9990234375, "train/cont_loss_mean": 0.620592474937439, "train/cont_loss_std": 0.24349747598171234, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 0.8014724850654602, "train/cont_pos_acc": 0.6441837549209595, "train/cont_pos_loss": 0.6204156279563904, "train/cont_pred": 0.5531303882598877, "train/cont_rate": 0.9990234375, "train/dyn_loss_mean": 11.047248840332031, "train/dyn_loss_std": 0.379760205745697, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 9.756861686706543, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 39060.40625, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 4999.5703125, "train/image_loss_std": 40.1146125793457, "train/model_loss_mean": 5012.36083984375, "train/model_loss_std": 40.10211944580078, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50123608.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9272361993789673, "train/policy_entropy_max": 1.9272361993789673, "train/policy_entropy_mean": 1.6427775621414185, "train/policy_entropy_min": 0.658942461013794, "train/policy_entropy_std": 0.14521558582782745, "train/policy_logprob_mag": 4.780257225036621, "train/policy_logprob_max": -0.15719401836395264, "train/policy_logprob_mean": -1.6475008726119995, "train/policy_logprob_min": -4.780257225036621, "train/policy_logprob_std": 0.7256799936294556, "train/policy_randomness_mag": 0.9904035329818726, "train/policy_randomness_max": 0.9904035329818726, "train/policy_randomness_mean": 0.844220757484436, "train/policy_randomness_min": 0.33862945437431335, "train/policy_randomness_std": 0.07462605088949203, "train/post_ent_mag": 105.58863830566406, "train/post_ent_max": 105.58863830566406, "train/post_ent_mean": 105.28460693359375, "train/post_ent_min": 104.91726684570312, "train/post_ent_std": 0.10856617987155914, "train/prior_ent_mag": 106.39432525634766, "train/prior_ent_max": 106.39432525634766, "train/prior_ent_mean": 105.52146911621094, "train/prior_ent_min": 104.60012817382812, "train/prior_ent_std": 0.2765088379383087, "train/rep_loss_mean": 11.047248840332031, "train/rep_loss_std": 0.379760205745697, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.6162295341491699, "report/cont_loss_std": 0.2653316259384155, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 0.7317681312561035, "report/cont_pos_acc": 0.6754643321037292, "report/cont_pos_loss": 0.6161165237426758, "report/cont_pred": 0.5576997399330139, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 10.971426010131836, "report/dyn_loss_std": 0.33272111415863037, "report/image_loss_mean": 5001.4267578125, "report/image_loss_std": 36.394439697265625, "report/model_loss_mean": 5014.1669921875, "report/model_loss_std": 36.411922454833984, "report/post_ent_mag": 105.6137924194336, "report/post_ent_max": 105.6137924194336, "report/post_ent_mean": 105.3039321899414, "report/post_ent_min": 104.96063995361328, "report/post_ent_std": 0.11043208092451096, "report/prior_ent_mag": 106.26870727539062, "report/prior_ent_max": 106.26870727539062, "report/prior_ent_mean": 105.54535675048828, "report/prior_ent_min": 104.54447937011719, "report/prior_ent_std": 0.27682894468307495, "report/rep_loss_mean": 10.971426010131836, "report/rep_loss_std": 0.33272111415863037, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.5880095958709717, "eval/cont_loss_std": 0.24634264409542084, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 0.7385357618331909, "eval/cont_pos_acc": 0.7028347849845886, "eval/cont_pos_loss": 0.587862491607666, "eval/cont_pred": 0.571502149105072, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 11.0430908203125, "eval/dyn_loss_std": 0.36425867676734924, "eval/image_loss_mean": 5006.9453125, "eval/image_loss_std": 41.48531723022461, "eval/model_loss_mean": 5019.701171875, "eval/model_loss_std": 41.483978271484375, "eval/post_ent_mag": 105.65425872802734, "eval/post_ent_max": 105.65425872802734, "eval/post_ent_mean": 105.30580139160156, "eval/post_ent_min": 104.95181274414062, "eval/post_ent_std": 0.1153997927904129, "eval/prior_ent_mag": 106.3073501586914, "eval/prior_ent_max": 106.3073501586914, "eval/prior_ent_mean": 105.5472183227539, "eval/prior_ent_min": 104.67994689941406, "eval/prior_ent_std": 0.26940789818763733, "eval/rep_loss_mean": 11.0430908203125, "eval/rep_loss_std": 0.36425867676734924, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1049.0, "replay/inserts": 1049.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.2877785216296026e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.749110358101981e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3360.0, "eval_replay/inserts": 3360.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.4757116635640462e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.196145193917411e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 160.46591329574585, "timer/env.step_count": 326.0, "timer/env.step_total": 1.0586695671081543, "timer/env.step_frac": 0.006597473228828224, "timer/env.step_avg": 0.003247452659840964, "timer/env.step_min": 0.0029027462005615234, "timer/env.step_max": 0.007288455963134766, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.14129161834716797, "timer/replay._sample_frac": 0.0008805086104907602, "timer/replay._sample_avg": 0.0012615323066711426, "timer/replay._sample_min": 0.00034356117248535156, "timer/replay._sample_max": 0.015336275100708008, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.458998680114746, "timer/agent.save_frac": 0.015324118559576586, "timer/agent.save_avg": 2.458998680114746, "timer/agent.save_min": 2.458998680114746, "timer/agent.save_max": 2.458998680114746, "timer/agent.policy_count": 579.0, "timer/agent.policy_total": 29.096148014068604, "timer/agent.policy_frac": 0.18132292034161238, "timer/agent.policy_avg": 0.050252414532070126, "timer/agent.policy_min": 0.008363723754882812, "timer/agent.policy_max": 20.518651723861694, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.075599670410156e-05, "timer/dataset_train_frac": 1.9166685355423045e-07, "timer/dataset_train_avg": 3.075599670410156e-05, "timer/dataset_train_min": 3.075599670410156e-05, "timer/dataset_train_max": 3.075599670410156e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 91.07871103286743, "timer/agent.train_frac": 0.5675891481389278, "timer/agent.train_avg": 91.07871103286743, "timer/agent.train_min": 91.07871103286743, "timer/agent.train_max": 91.07871103286743, "timer/agent.report_count": 2.0, "timer/agent.report_total": 24.03482699394226, "timer/agent.report_frac": 0.1497815112275278, "timer/agent.report_avg": 12.01741349697113, "timer/agent.report_min": 0.24573826789855957, "timer/agent.report_max": 23.7890887260437, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.743171691894531e-05, "timer/dataset_eval_frac": 2.3326896130243554e-07, "timer/dataset_eval_avg": 3.743171691894531e-05, "timer/dataset_eval_min": 3.743171691894531e-05, "timer/dataset_eval_max": 3.743171691894531e-05}
{"step": 2572, "time": 254.6504201889038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2572, "time": 254.6573247909546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2572, "time": 254.68239188194275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2572, "time": 254.68895292282104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 3728, "time": 290.45153284072876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 3728, "time": 290.4683530330658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 3728, "time": 290.47890615463257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 3728, "time": 290.4954333305359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4884, "time": 326.4699025154114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4884, "time": 326.4785535335541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4884, "time": 326.4861478805542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4884, "time": 326.4936008453369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6040, "time": 362.37791872024536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6040, "time": 362.3854522705078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6040, "time": 362.39622926712036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6040, "time": 362.40479850769043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 7196, "time": 398.59989881515503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 7196, "time": 398.6074523925781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 7196, "time": 398.6143958568573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 7196, "time": 398.621217250824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 7860, "time": 418.90630316734314, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 8352, "time": 434.31336641311646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8352, "time": 434.32258558273315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8352, "time": 434.3287935256958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9016, "time": 454.96268820762634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9508, "time": 470.28037762641907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9508, "time": 470.28808975219727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9508, "time": 470.29691076278687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10060, "time": 492.1275408267975, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10060, "time": 492.1340630054474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10060, "time": 492.1415157318115, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10060, "time": 492.147412776947, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10060, "time": 496.27327013015747, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10060, "time": 496.2799401283264, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10060, "time": 496.28607749938965, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10060, "time": 496.29199981689453, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10172, "time": 499.7339680194855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10664, "time": 514.6358411312103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10664, "time": 514.643043756485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10664, "time": 514.6497259140015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11328, "time": 535.28577876091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11820, "time": 550.6017363071442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11820, "time": 550.6090860366821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11820, "time": 550.6158437728882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 12484, "time": 570.9041562080383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 12976, "time": 586.4264698028564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 12976, "time": 586.4335842132568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 12976, "time": 586.4401512145996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13640, "time": 606.797732591629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14132, "time": 622.0659332275391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14132, "time": 622.0729827880859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14132, "time": 622.0796947479248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14796, "time": 642.7666385173798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15288, "time": 657.6359384059906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15288, "time": 657.6431910991669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15288, "time": 657.6499402523041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15952, "time": 678.4089682102203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16444, "time": 693.7015843391418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16444, "time": 693.708797454834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16444, "time": 693.7158460617065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17108, "time": 714.139520406723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17600, "time": 729.5165731906891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17600, "time": 729.5253121852875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17600, "time": 729.5327990055084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18264, "time": 749.8251881599426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18756, "time": 765.1770660877228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18756, "time": 765.1841604709625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18756, "time": 765.19145154953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 19420, "time": 785.9294896125793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 19520, "time": 788.9159128665924, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 19912, "time": 800.7839477062225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 19912, "time": 800.7916598320007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20060, "time": 809.851630449295, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20060, "time": 809.8579525947571, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20060, "time": 809.8641023635864, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20060, "time": 809.870138168335, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20060, "time": 814.4351644515991, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20060, "time": 814.4417378902435, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20060, "time": 814.448224067688, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20060, "time": 814.4556624889374, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20576, "time": 830.2420628070831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20676, "time": 833.2394659519196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21068, "time": 845.8365786075592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21068, "time": 845.8437993526459, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21732, "time": 866.0700073242188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21832, "time": 869.028790473938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22224, "time": 881.3262083530426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22224, "time": 881.3329174518585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22888, "time": 901.510617017746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22988, "time": 904.8836374282837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23380, "time": 916.660165309906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23380, "time": 916.6672439575195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23516, "time": 921.0730526447296, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 24044, "time": 937.3271598815918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24144, "time": 940.294595003128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24536, "time": 952.0379204750061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24672, "time": 956.4237966537476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24904, "time": 963.5644242763519, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 25300, "time": 975.8406643867493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25692, "time": 988.0488028526306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25828, "time": 992.0037231445312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26060, "time": 999.3921527862549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26456, "time": 1011.259546995163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26848, "time": 1023.6080060005188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26984, "time": 1027.5704562664032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27216, "time": 1034.939862728119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27612, "time": 1047.2221081256866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28004, "time": 1059.1298344135284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28140, "time": 1063.549176454544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28372, "time": 1070.431002855301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28768, "time": 1082.7473254203796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29160, "time": 1094.730328798294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29296, "time": 1099.159494638443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29528, "time": 1106.0691418647766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29924, "time": 1118.3846216201782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30060, "time": 1126.781700849533, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30060, "time": 1126.7883298397064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30060, "time": 1126.7939972877502, "eval_episode/length": 288.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.0034602076124567475}
{"step": 30060, "time": 1126.7994883060455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30060, "time": 1130.7715764045715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30060, "time": 1130.7781450748444, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30060, "time": 1130.7841098308563, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30060, "time": 1130.7918620109558, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30316, "time": 1138.6374814510345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30452, "time": 1142.6583137512207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30684, "time": 1149.9881386756897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31080, "time": 1161.779905796051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31472, "time": 1174.0419681072235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31608, "time": 1177.9862790107727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31840, "time": 1185.3493838310242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32236, "time": 1197.5800247192383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32297, "time": 1200.104131937027, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.001631418863932, "train/action_min": 0.0, "train/action_std": 2.000820152461529, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 9.500770750037191e-05, "train/actor_opt_grad_steps": 965.0, "train/actor_opt_loss": -3.5051815198142626, "train/adv_mag": 0.00018966689806880024, "train/adv_max": 0.00018962703869160324, "train/adv_mean": 0.0001132803727366543, "train/adv_min": 1.6927220337821975e-05, "train/adv_std": 5.262301780205083e-05, "train/cont_avg": 0.99658203125, "train/cont_loss_mean": 0.026148990058572963, "train/cont_loss_std": 0.3223281096042025, "train/cont_neg_acc": 0.0026595744680851063, "train/cont_neg_loss": 5.7061130702495575, "train/cont_pos_acc": 0.9982689780493578, "train/cont_pos_loss": 0.006705501712834423, "train/cont_pred": 0.9942113120729724, "train/cont_rate": 0.99658203125, "train/dyn_loss_mean": 1.0699941795319319, "train/dyn_loss_std": 0.004481609249547584, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.4021691878636675, "train/extr_critic_critic_opt_grad_steps": 965.0, "train/extr_critic_critic_opt_loss": 5361.270004590352, "train/extr_critic_mag": 0.0003419263909260432, "train/extr_critic_max": 0.00034191769858201343, "train/extr_critic_mean": 0.00034068176086599896, "train/extr_critic_min": 0.000339833398660024, "train/extr_critic_std": 2.2866712812210735e-07, "train/extr_return_normed_mag": 0.00026558476288823796, "train/extr_return_normed_max": 0.000265576129034296, "train/extr_return_normed_mean": 0.00018968233687298905, "train/extr_return_normed_min": 9.368787221953011e-05, "train/extr_return_normed_std": 5.261269287808746e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0005298699430175274, "train/extr_return_raw_max": 0.0005298555823299254, "train/extr_return_raw_mean": 0.00045396179685115745, "train/extr_return_raw_min": 0.00035796732531483827, "train/extr_return_raw_std": 5.261269320024918e-05, "train/extr_reward_mag": 1.8987183769543965e-05, "train/extr_reward_max": 1.8985321124394734e-05, "train/extr_reward_mean": 1.892717150615032e-05, "train/extr_reward_min": 1.8810232480367024e-05, "train/extr_reward_std": 2.4295121246973677e-08, "train/image_loss_mean": 27.286931158353884, "train/image_loss_std": 0.38443505903705955, "train/model_loss_mean": 28.064528323089082, "train/model_loss_std": 0.6641846351558343, "train/model_opt_grad_norm": 103.68641080406948, "train/model_opt_grad_steps": 955.0, "train/model_opt_loss": 533.51032452782, "train/model_opt_model_opt_grad_overflow": 0.005208333333333333, "train/model_opt_model_opt_grad_scale": 14.394124348958334, "train/policy_entropy_mag": 1.9457998052239418, "train/policy_entropy_max": 1.9457998052239418, "train/policy_entropy_mean": 1.9414406027644873, "train/policy_entropy_min": 1.8849530437340338, "train/policy_entropy_std": 0.002875056792011795, "train/policy_logprob_mag": 2.3802111260592937, "train/policy_logprob_max": -1.5078676892444491, "train/policy_logprob_mean": -1.941517785191536, "train/policy_logprob_min": -2.3802111260592937, "train/policy_logprob_std": 0.0817091025528498, "train/policy_randomness_mag": 0.9999433516835173, "train/policy_randomness_max": 0.9999433516835173, "train/policy_randomness_mean": 0.9977031645054618, "train/policy_randomness_min": 0.9686743019459149, "train/policy_randomness_std": 0.0014774870393618282, "train/post_ent_mag": 77.62600143750508, "train/post_ent_max": 77.62600143750508, "train/post_ent_mean": 77.51707639296849, "train/post_ent_min": 77.43025231361389, "train/post_ent_std": 0.0279401715718753, "train/prior_ent_mag": 82.6260511080424, "train/prior_ent_max": 82.6260511080424, "train/prior_ent_mean": 82.50249107678731, "train/prior_ent_min": 82.2698260943095, "train/prior_ent_std": 0.0508495452037702, "train/rep_loss_mean": 1.0699941795319319, "train/rep_loss_std": 0.004481609249547584, "train/reward_avg": 7.475217262253864e-05, "train/reward_loss_mean": 0.10945012490022539, "train/reward_loss_std": 0.04322097271267444, "train/reward_max_data": 0.06764322984963655, "train/reward_max_pred": 1.8911436200141907e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.10800456210108678, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.504573027292887, "train/reward_pred": 1.8843470873738017e-05, "train/reward_rate": 0.0001373291015625, "train_stats/mean_log_entropy": 1.9269773325073385, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.015947431325912476, "report/cont_loss_std": 0.22627346217632294, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.1309285163879395, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0059376852586865425, "report/cont_pred": 0.9940800666809082, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2676723003387451, "report/image_loss_std": 0.08856479078531265, "report/model_loss_mean": 0.8842141628265381, "report/model_loss_std": 0.24653691053390503, "report/post_ent_mag": 62.39643859863281, "report/post_ent_max": 62.39643859863281, "report/post_ent_mean": 62.152915954589844, "report/post_ent_min": 62.1224365234375, "report/post_ent_std": 0.03365594893693924, "report/prior_ent_mag": 68.40798950195312, "report/prior_ent_max": 68.40798950195312, "report/prior_ent_mean": 68.29679870605469, "report/prior_ent_min": 68.11514282226562, "report/prior_ent_std": 0.036271706223487854, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0005943556316196918, "report/reward_loss_std": 2.049320755759254e-06, "report/reward_max_data": 0.0, "report/reward_max_pred": 5.328655242919922e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005943556316196918, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.295674782246351e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020944733172655106, "eval/cont_loss_std": 0.27685171365737915, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.128339767456055, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005937694106251001, "eval/cont_pred": 0.9940800070762634, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2870246171951294, "eval/image_loss_std": 0.09126944839954376, "eval/model_loss_mean": 0.9085636138916016, "eval/model_loss_std": 0.2875191271305084, "eval/post_ent_mag": 62.39147186279297, "eval/post_ent_max": 62.39147186279297, "eval/post_ent_mean": 62.153202056884766, "eval/post_ent_min": 62.129791259765625, "eval/post_ent_std": 0.0340898334980011, "eval/prior_ent_mag": 68.42909240722656, "eval/prior_ent_max": 68.42909240722656, "eval/prior_ent_mean": 68.29710388183594, "eval/prior_ent_min": 68.11514282226562, "eval/prior_ent_std": 0.03834916278719902, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0005942187272012234, "eval/reward_loss_std": 2.1013513560319552e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 5.340576171875e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005942187272012234, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.2944174967706203e-05, "eval/reward_rate": 0.0, "replay/size": 31785.0, "replay/inserts": 30736.0, "replay/samples": 30736.0, "replay/insert_wait_avg": 1.4664573262347211e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.209833932506238e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10296.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3735192594781191e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 976.719916343689, "timer/env.step_count": 7684.0, "timer/env.step_total": 37.66272497177124, "timer/env.step_frac": 0.038560414650660665, "timer/env.step_avg": 0.004901447809965024, "timer/env.step_min": 0.0038962364196777344, "timer/env.step_max": 0.03020334243774414, "timer/replay._sample_count": 30736.0, "timer/replay._sample_total": 15.49555516242981, "timer/replay._sample_frac": 0.015864891155733557, "timer/replay._sample_avg": 0.000504150024805759, "timer/replay._sample_min": 0.000339508056640625, "timer/replay._sample_max": 0.012653589248657227, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9418.0, "timer/agent.policy_total": 88.73776268959045, "timer/agent.policy_frac": 0.09085282403350249, "timer/agent.policy_avg": 0.009422145114630543, "timer/agent.policy_min": 0.00715947151184082, "timer/agent.policy_max": 0.04313969612121582, "timer/dataset_train_count": 1921.0, "timer/dataset_train_total": 0.2086958885192871, "timer/dataset_train_frac": 0.00021367014742622596, "timer/dataset_train_avg": 0.00010863919235777569, "timer/dataset_train_min": 8.320808410644531e-05, "timer/dataset_train_max": 0.00544285774230957, "timer/agent.train_count": 1921.0, "timer/agent.train_total": 834.529536485672, "timer/agent.train_frac": 0.8544205176133801, "timer/agent.train_avg": 0.4344245374730203, "timer/agent.train_min": 0.42328643798828125, "timer/agent.train_max": 0.5433175563812256, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47818732261657715, "timer/agent.report_frac": 0.0004895849000465269, "timer/agent.report_avg": 0.23909366130828857, "timer/agent.report_min": 0.23248815536499023, "timer/agent.report_max": 0.24569916725158691, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.07567609343456e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 31.468007748529107}
{"step": 32316, "time": 1200.7079832553864, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 32764, "time": 1214.6774175167084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32996, "time": 1221.5954551696777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33392, "time": 1234.067610502243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33472, "time": 1236.5333378314972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33920, "time": 1250.198195695877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34152, "time": 1257.0582118034363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34548, "time": 1269.3020107746124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34628, "time": 1271.738110780716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35076, "time": 1285.459837436676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35308, "time": 1292.7684144973755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35704, "time": 1304.532731294632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35784, "time": 1306.9781429767609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36232, "time": 1320.692381620407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36464, "time": 1328.0488550662994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36860, "time": 1340.2820537090302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36940, "time": 1342.7426762580872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37388, "time": 1357.107115983963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37620, "time": 1363.9439370632172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38016, "time": 1376.092294216156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38096, "time": 1378.542171239853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38544, "time": 1392.1859591007233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38776, "time": 1399.0273938179016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39172, "time": 1411.2285268306732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39252, "time": 1413.673546075821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39700, "time": 1427.2549636363983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39932, "time": 1434.5101206302643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40060, "time": 1442.7210981845856, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40060, "time": 1442.729249238968, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40060, "time": 1442.7358057498932, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40060, "time": 1442.7422482967377, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40060, "time": 1447.2837164402008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40060, "time": 1447.2903690338135, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40060, "time": 1447.2965650558472, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40060, "time": 1447.3027119636536, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40328, "time": 1455.1532669067383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40408, "time": 1457.6010100841522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40856, "time": 1471.2472786903381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41088, "time": 1478.5404765605927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41484, "time": 1490.842384815216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41564, "time": 1493.283297777176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42012, "time": 1506.994152545929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42244, "time": 1513.868427991867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42640, "time": 1525.9768216609955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42720, "time": 1528.4214842319489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43168, "time": 1542.1040728092194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43400, "time": 1548.9275925159454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43796, "time": 1561.14359998703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43876, "time": 1563.6108119487762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44324, "time": 1577.2369124889374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44556, "time": 1584.5134556293488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44952, "time": 1596.3317987918854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45032, "time": 1598.7694988250732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45268, "time": 1606.0524852275848, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 45480, "time": 1612.5579640865326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45712, "time": 1619.9044950008392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46108, "time": 1632.1546368598938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46424, "time": 1641.4583883285522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46636, "time": 1648.257098197937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46868, "time": 1655.1368238925934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47084, "time": 1661.9587643146515, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 47264, "time": 1667.3748426437378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47580, "time": 1677.1102695465088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47792, "time": 1683.510064125061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48240, "time": 1697.1411232948303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48420, "time": 1702.528797864914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48616, "time": 1708.3965711593628, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 48736, "time": 1712.3390936851501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48948, "time": 1718.6859395503998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49576, "time": 1737.8534934520721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49772, "time": 1744.1396203041077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49892, "time": 1747.5913512706757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50060, "time": 1756.9300382137299, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50060, "time": 1756.9361021518707, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50060, "time": 1756.9419014453888, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50060, "time": 1756.947660446167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50060, "time": 1760.985119819641, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50060, "time": 1760.9919397830963, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50060, "time": 1761.0010335445404, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50060, "time": 1761.0089013576508, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50104, "time": 1762.0233902931213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50732, "time": 1781.575676202774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50928, "time": 1787.446543455124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51048, "time": 1790.89177942276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51260, "time": 1797.6828615665436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51348, "time": 1800.161409854889, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 51888, "time": 1816.8199498653412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52084, "time": 1822.678739309311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52416, "time": 1832.962785243988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52504, "time": 1835.4383280277252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53044, "time": 1852.0345096588135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53240, "time": 1857.958077430725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53572, "time": 1868.440933227539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53660, "time": 1871.3370232582092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54200, "time": 1887.5679304599762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54396, "time": 1893.8984770774841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54488, "time": 1896.3759944438934, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 54728, "time": 1903.6745491027832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55356, "time": 1923.1298575401306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55552, "time": 1929.013528585434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55644, "time": 1931.9322788715363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55884, "time": 1939.2301571369171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56512, "time": 1958.2848660945892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56708, "time": 1964.11559009552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56800, "time": 1967.0252361297607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57040, "time": 1974.2722158432007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57668, "time": 1993.4186618328094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57864, "time": 1999.2595098018646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57956, "time": 2002.1627254486084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58196, "time": 2009.4757974147797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58824, "time": 2028.5866265296936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58948, "time": 2032.4847793579102, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 59020, "time": 2034.899774312973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59112, "time": 2037.3744361400604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59980, "time": 2064.1368606090546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60060, "time": 2070.6447083950043, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60060, "time": 2070.6512401103973, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60060, "time": 2070.6574733257294, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60060, "time": 2070.663468837738, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60060, "time": 2074.95694065094, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60060, "time": 2074.9630687236786, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60060, "time": 2074.9683649539948, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60060, "time": 2074.973850250244, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60104, "time": 2075.9776470661163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60176, "time": 2078.383355617523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60268, "time": 2081.274919271469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61136, "time": 2107.4995453357697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61260, "time": 2111.3874683380127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61332, "time": 2113.3678963184357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61424, "time": 2116.289574623108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62292, "time": 2142.8162055015564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62416, "time": 2146.697536468506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62488, "time": 2148.6780540943146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62580, "time": 2151.5945539474487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63448, "time": 2177.977150917053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63572, "time": 2181.869066476822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63644, "time": 2184.294302225113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63736, "time": 2186.7774152755737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64153, "time": 2200.4728965759277, "train_stats/mean_log_entropy": 1.9363424527017694, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0009912845477387, "train/action_min": 0.0, "train/action_std": 1.9997781700824373, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00012125657400731746, "train/actor_opt_grad_steps": 2920.0, "train/actor_opt_loss": -0.7640316571900504, "train/adv_mag": 0.00044840936965529046, "train/adv_max": 0.00044840936965529046, "train/adv_mean": 0.0002581634678735735, "train/adv_min": 2.157771796100403e-05, "train/adv_std": 0.0001201778938214297, "train/cont_avg": 0.9963832836055276, "train/cont_loss_mean": 0.024001545104287078, "train/cont_loss_std": 0.32821287849450775, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.684933855594733, "train/cont_pos_acc": 0.9999999856230003, "train/cont_pos_loss": 0.0034738147447597066, "train/cont_pred": 0.9965324593548799, "train/cont_rate": 0.9963832836055276, "train/dyn_loss_mean": 1.0000000083865832, "train/dyn_loss_std": 2.1989560205546143e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.07970169997170343, "train/extr_critic_critic_opt_grad_steps": 2920.0, "train/extr_critic_critic_opt_loss": 3406.147432720242, "train/extr_critic_mag": 0.0067823112909518295, "train/extr_critic_max": 0.0067823112909518295, "train/extr_critic_mean": 0.006761348353530369, "train/extr_critic_min": 0.006745848224390691, "train/extr_critic_std": 5.18231070431348e-06, "train/extr_return_normed_mag": 0.0008831375042191852, "train/extr_return_normed_max": 0.0008831375042191852, "train/extr_return_normed_mean": 0.0007035774719198211, "train/extr_return_normed_min": 0.00047529615396306143, "train/extr_return_normed_std": 0.00012002164449635777, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.007199071118392837, "train/extr_return_raw_max": 0.007199071118392837, "train/extr_return_raw_mean": 0.007019511414645006, "train/extr_return_raw_min": 0.006791229768136712, "train/extr_return_raw_std": 0.00012002164392963744, "train/extr_reward_mag": 6.1228646704899e-05, "train/extr_reward_max": 6.1228646704899e-05, "train/extr_reward_mean": 6.111813221211912e-05, "train/extr_reward_min": 6.0994421417389685e-05, "train/extr_reward_std": 3.579336306353573e-08, "train/image_loss_mean": 0.2719582075898971, "train/image_loss_std": 0.08495030501604679, "train/model_loss_mean": 0.8976854265634738, "train/model_loss_std": 0.37178215159842715, "train/model_opt_grad_norm": 79.00569327272962, "train/model_opt_grad_steps": 2910.0, "train/model_opt_loss": 50.06170089760018, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 55.84563442211055, "train/policy_entropy_mag": 1.9458905584249064, "train/policy_entropy_max": 1.9458905584249064, "train/policy_entropy_mean": 1.944904478950117, "train/policy_entropy_min": 1.9253399983123318, "train/policy_entropy_std": 0.0007373218424033243, "train/policy_logprob_mag": 2.224474285116148, "train/policy_logprob_max": -1.6974499159721872, "train/policy_logprob_mean": -1.9449392293565837, "train/policy_logprob_min": -2.224474285116148, "train/policy_logprob_std": 0.04463485375645772, "train/policy_randomness_mag": 0.9999899921105735, "train/policy_randomness_max": 0.9999899921105735, "train/policy_randomness_mean": 0.9994832427058388, "train/policy_randomness_min": 0.9894290916883766, "train/policy_randomness_std": 0.00037890849939205837, "train/post_ent_mag": 51.892597045131666, "train/post_ent_max": 51.892597045131666, "train/post_ent_mean": 51.62111556470094, "train/post_ent_min": 51.59537559777648, "train/post_ent_std": 0.04015035356334106, "train/prior_ent_mag": 60.32830783709809, "train/prior_ent_max": 60.32830783709809, "train/prior_ent_mean": 60.214186970312994, "train/prior_ent_min": 60.13775351059497, "train/prior_ent_std": 0.02733305995188766, "train/rep_loss_mean": 1.0000000083865832, "train/rep_loss_std": 2.1989560205546143e-07, "train/reward_avg": 7.382493633449302e-05, "train/reward_loss_mean": 0.0017256496881307968, "train/reward_loss_std": 0.0406398148999775, "train/reward_max_data": 0.06573492573134264, "train/reward_max_pred": 6.12532074127964e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00034056034014588363, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.102928002675375, "train/reward_pred": 6.110261805149628e-05, "train/reward_rate": 0.00013740577889447236, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025630291551351547, "report/cont_loss_std": 0.3579414486885071, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.741496562957764, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0032151236664503813, "report/cont_pred": 0.9967899918556213, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.28725600242614746, "report/image_loss_std": 0.11251930147409439, "report/model_loss_mean": 0.9131408929824829, "report/model_loss_std": 0.37459972500801086, "report/post_ent_mag": 44.146034240722656, "report/post_ent_max": 44.146034240722656, "report/post_ent_mean": 43.899478912353516, "report/post_ent_min": 43.87470245361328, "report/post_ent_std": 0.036026712507009506, "report/prior_ent_mag": 54.3333740234375, "report/prior_ent_max": 54.3333740234375, "report/prior_ent_mean": 54.23176956176758, "report/prior_ent_min": 54.18682098388672, "report/prior_ent_std": 0.025122156366705894, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00025463057681918144, "report/reward_loss_std": 1.4893883459876633e-08, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.390975952148438e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00025463057681918144, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.390871178358793e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008818915113806725, "eval/cont_loss_std": 0.17923370003700256, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.741496562957764, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003215123899281025, "eval/cont_pred": 0.9967899918556213, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.31089407205581665, "eval/image_loss_std": 0.12374512106180191, "eval/model_loss_mean": 0.9199676513671875, "eval/model_loss_std": 0.21400566399097443, "eval/post_ent_mag": 44.149139404296875, "eval/post_ent_max": 44.149139404296875, "eval/post_ent_mean": 43.89826202392578, "eval/post_ent_min": 43.87583923339844, "eval/post_ent_std": 0.033690035343170166, "eval/prior_ent_mag": 54.341278076171875, "eval/prior_ent_max": 54.341278076171875, "eval/prior_ent_mean": 54.22947692871094, "eval/prior_ent_min": 54.193946838378906, "eval/prior_ent_std": 0.023378591984510422, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00025463057681918144, "eval/reward_loss_std": 1.4893883459876633e-08, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.390975952148438e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00025463057681918144, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.390871178358793e-05, "eval/reward_rate": 0.0, "replay/size": 63641.0, "replay/inserts": 31856.0, "replay/samples": 31856.0, "replay/insert_wait_avg": 1.4791217417887022e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.273699485974237e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17232.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3933531003289844e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3514361381531, "timer/env.step_count": 7964.0, "timer/env.step_total": 38.56063508987427, "timer/env.step_frac": 0.038547088250042626, "timer/env.step_avg": 0.004841867791295112, "timer/env.step_min": 0.003803253173828125, "timer/env.step_max": 0.029756784439086914, "timer/replay._sample_count": 31856.0, "timer/replay._sample_total": 15.940713167190552, "timer/replay._sample_frac": 0.015935112992619394, "timer/replay._sample_avg": 0.0005003990823452584, "timer/replay._sample_min": 0.0003590583801269531, "timer/replay._sample_max": 0.025493860244750977, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9698.0, "timer/agent.policy_total": 90.21600317955017, "timer/agent.policy_frac": 0.090184309154219, "timer/agent.policy_avg": 0.009302536933341944, "timer/agent.policy_min": 0.007921934127807617, "timer/agent.policy_max": 0.0564422607421875, "timer/dataset_train_count": 1991.0, "timer/dataset_train_total": 0.2541656494140625, "timer/dataset_train_frac": 0.00025407635780008123, "timer/dataset_train_avg": 0.00012765728247818308, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.020661354064941406, "timer/agent.train_count": 1991.0, "timer/agent.train_total": 855.3303260803223, "timer/agent.train_frac": 0.8550298376961567, "timer/agent.train_avg": 0.4295983556405436, "timer/agent.train_min": 0.4215271472930908, "timer/agent.train_max": 0.826648473739624, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47927331924438477, "timer/agent.report_frac": 0.00047910494445293616, "timer/agent.report_avg": 0.23963665962219238, "timer/agent.report_min": 0.2319173812866211, "timer/agent.report_max": 0.24735593795776367, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.886222839355469e-05, "timer/dataset_eval_frac": 3.8848575600173016e-08, "timer/dataset_eval_avg": 3.886222839355469e-05, "timer/dataset_eval_min": 3.886222839355469e-05, "timer/dataset_eval_max": 3.886222839355469e-05, "fps": 31.84414108097895}
{"step": 64604, "time": 2214.2605226039886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64728, "time": 2217.704885482788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64800, "time": 2220.129115343094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64892, "time": 2223.127504348755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65760, "time": 2249.599450826645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65884, "time": 2253.6746501922607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65956, "time": 2255.6502108573914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66048, "time": 2258.5951018333435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66500, "time": 2272.2476267814636, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 67040, "time": 2289.008914232254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67112, "time": 2290.999406337738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67204, "time": 2293.927038669586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67656, "time": 2307.6611564159393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68196, "time": 2324.2592601776123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68268, "time": 2326.670234680176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68360, "time": 2329.1346323490143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68812, "time": 2343.288912296295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69352, "time": 2359.3647723197937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69424, "time": 2361.777125597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69516, "time": 2364.671576499939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69824, "time": 2373.933352947235, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 70060, "time": 2385.341784477234, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70060, "time": 2385.3483481407166, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70060, "time": 2385.3542926311493, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70060, "time": 2385.359879255295, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70060, "time": 2389.36043548584, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70060, "time": 2389.3669028282166, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70060, "time": 2389.3747725486755, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70060, "time": 2389.3818435668945, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70508, "time": 2403.0947682857513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70580, "time": 2405.0640127658844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70672, "time": 2407.979096889496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70980, "time": 2417.2499589920044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71664, "time": 2438.2786741256714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71736, "time": 2440.2550053596497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71828, "time": 2443.168642759323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72136, "time": 2452.5822508335114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72820, "time": 2473.7475197315216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72892, "time": 2476.1716916561127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72984, "time": 2478.695075273514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73292, "time": 2488.5005934238434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73976, "time": 2509.1903398036957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74048, "time": 2511.797534227371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74140, "time": 2514.7319667339325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74448, "time": 2524.160135984421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75132, "time": 2545.2606585025787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75204, "time": 2547.2710955142975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75296, "time": 2550.2188646793365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75604, "time": 2559.612880706787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76288, "time": 2580.681357860565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76360, "time": 2582.7149047851562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76452, "time": 2585.6781475543976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76760, "time": 2595.021322250366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77444, "time": 2616.185310125351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77516, "time": 2618.6041028499603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77608, "time": 2621.130133152008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77916, "time": 2630.9120604991913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78320, "time": 2643.4170570373535, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 78600, "time": 2651.7939851284027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78764, "time": 2657.140617132187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79072, "time": 2666.5485479831696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79476, "time": 2678.905910730362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79756, "time": 2687.7077374458313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79920, "time": 2692.6418170928955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80060, "time": 2701.6950628757477, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80060, "time": 2701.7093575000763, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80060, "time": 2701.7164976596832, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80060, "time": 2701.7226099967957, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80060, "time": 2705.936990261078, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80060, "time": 2705.9435391426086, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80060, "time": 2705.94949054718, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80060, "time": 2705.955713748932, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80228, "time": 2710.8943226337433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80632, "time": 2723.1997752189636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80912, "time": 2732.1294453144073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81076, "time": 2737.063417673111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81384, "time": 2746.4129526615143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81788, "time": 2759.160833835602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82068, "time": 2767.6131761074066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82232, "time": 2772.73907661438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82540, "time": 2782.5606191158295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82944, "time": 2794.978508234024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83224, "time": 2803.410626888275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83388, "time": 2808.7643492221832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83696, "time": 2818.1170949935913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84100, "time": 2830.5014646053314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84380, "time": 2839.3340389728546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84544, "time": 2844.2723047733307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84852, "time": 2853.6595702171326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85256, "time": 2865.9581875801086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85536, "time": 2875.2662522792816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85700, "time": 2880.2079973220825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86008, "time": 2889.6052725315094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86412, "time": 2902.527822494507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86692, "time": 2910.928325653076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86856, "time": 2915.9088776111603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87164, "time": 2925.680675506592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87568, "time": 2938.0315177440643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87848, "time": 2946.443271636963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88012, "time": 2951.817381620407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88320, "time": 2961.1726019382477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88724, "time": 2973.5545465946198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89004, "time": 2982.4284801483154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89168, "time": 2987.376478910446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89476, "time": 2996.7602219581604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89880, "time": 3009.115517139435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90060, "time": 3019.0632445812225, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90060, "time": 3019.0700845718384, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90060, "time": 3019.076454639435, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90060, "time": 3019.082820892334, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90060, "time": 3023.148905992508, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90060, "time": 3023.155527830124, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90060, "time": 3023.1611907482147, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90060, "time": 3023.16712641716, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90160, "time": 3026.108875513077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90324, "time": 3031.038767337799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90632, "time": 3040.6083817481995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91036, "time": 3053.2668125629425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91316, "time": 3061.723062515259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91480, "time": 3066.6383204460144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91788, "time": 3076.4127004146576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92192, "time": 3088.7148776054382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92472, "time": 3097.117541074753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92636, "time": 3102.449570417404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92944, "time": 3111.7959458827972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93348, "time": 3124.121417760849, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93628, "time": 3132.9402329921722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93792, "time": 3137.9011147022247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94100, "time": 3147.276513814926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94504, "time": 3159.760499238968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94784, "time": 3168.5515196323395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94908, "time": 3172.4668662548065, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 94932, "time": 3172.9939453601837, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 94948, "time": 3173.4874691963196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95801, "time": 3200.5251586437225, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000403201941288, "train/action_min": 0.0, "train/action_std": 1.9996745243217007, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.459825922917448e-05, "train/actor_opt_grad_steps": 4905.0, "train/actor_opt_loss": -3.2534352943884453, "train/adv_mag": 0.00026753998709597973, "train/adv_max": 0.00025894121746673727, "train/adv_mean": 0.0001278220478529777, "train/adv_min": -3.1597361984578043e-05, "train/adv_std": 6.744096861087779e-05, "train/cont_avg": 0.9963551530934344, "train/cont_loss_mean": 0.024192254878627608, "train/cont_loss_std": 0.3286214740370692, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.64950447229995, "train/cont_pos_acc": 0.9999999852493556, "train/cont_pos_loss": 0.003590635987083343, "train/cont_pred": 0.9964159922768371, "train/cont_rate": 0.9963551530934344, "train/dyn_loss_mean": 1.000000004816537, "train/dyn_loss_std": 1.5733123768998235e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.022928269302491287, "train/extr_critic_critic_opt_grad_steps": 4905.0, "train/extr_critic_critic_opt_loss": 6112.392444957386, "train/extr_critic_mag": 0.015064637468318747, "train/extr_critic_max": 0.015064637468318747, "train/extr_critic_mean": 0.015020753106459825, "train/extr_critic_min": 0.01499165790249603, "train/extr_critic_std": 1.1342798872120015e-05, "train/extr_return_normed_mag": 0.0004712586912016074, "train/extr_return_normed_max": 0.0004625551148571751, "train/extr_return_normed_mean": 0.0003562173758428348, "train/extr_return_normed_min": 0.0002213736967832753, "train/extr_return_normed_std": 6.492068345061963e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.015254910216864311, "train/extr_return_raw_max": 0.015254910216864311, "train/extr_return_raw_mean": 0.015148573286944267, "train/extr_return_raw_min": 0.015013728798790411, "train/extr_return_raw_std": 6.492068332200421e-05, "train/extr_reward_mag": 6.546757437966086e-05, "train/extr_reward_max": 6.546757437966086e-05, "train/extr_reward_mean": 6.534608788073952e-05, "train/extr_reward_min": 6.517557182697334e-05, "train/extr_reward_std": 4.087361624357264e-08, "train/image_loss_mean": 0.2627282032761911, "train/image_loss_std": 0.08498243012964124, "train/model_loss_mean": 0.8889762587619551, "train/model_loss_std": 0.384571930562908, "train/model_opt_grad_norm": 65.65095448734785, "train/model_opt_grad_steps": 4895.0, "train/model_opt_loss": 196.913786030779, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 221.74873737373738, "train/policy_entropy_mag": 1.9458985310612302, "train/policy_entropy_max": 1.9458985310612302, "train/policy_entropy_mean": 1.945305378750117, "train/policy_entropy_min": 1.9338438149654504, "train/policy_entropy_std": 0.00044575659896251794, "train/policy_logprob_mag": 2.1554696307037817, "train/policy_logprob_max": -1.7514798346191947, "train/policy_logprob_mean": -1.945330023765564, "train/policy_logprob_min": -2.1554696307037817, "train/policy_logprob_std": 0.034719790661274785, "train/policy_randomness_mag": 0.9999940870988249, "train/policy_randomness_max": 0.9999940870988249, "train/policy_randomness_mean": 0.9996892653330408, "train/policy_randomness_min": 0.993799191532713, "train/policy_randomness_std": 0.00022907358299672717, "train/post_ent_mag": 40.586767389316755, "train/post_ent_max": 40.586767389316755, "train/post_ent_mean": 40.402410719129776, "train/post_ent_min": 40.36733575300737, "train/post_ent_std": 0.02700638622421809, "train/prior_ent_mag": 50.65494032580443, "train/prior_ent_max": 50.65494032580443, "train/prior_ent_mean": 50.56130648140955, "train/prior_ent_min": 50.51073103240042, "train/prior_ent_std": 0.020046762270721222, "train/rep_loss_mean": 1.000000004816537, "train/rep_loss_std": 1.5733123768998235e-07, "train/reward_avg": 0.00010631831199391698, "train/reward_loss_mean": 0.0020557773755769237, "train/reward_loss_std": 0.05912837926274699, "train/reward_max_data": 0.10886995148177099, "train/reward_max_pred": 6.438204736420603e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.000207115871425497, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.130477724848566, "train/reward_pred": 6.431057893981536e-05, "train/reward_rate": 0.00018248895202020203, "train_stats/mean_log_entropy": 1.9378894285722212, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020013898611068726, "report/cont_loss_std": 0.3154163658618927, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.83885383605957, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002916426630690694, "report/cont_pred": 0.9970877170562744, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.26386767625808716, "report/image_loss_std": 0.0813923254609108, "report/model_loss_mean": 0.8841415643692017, "report/model_loss_std": 0.3215737044811249, "report/post_ent_mag": 38.71559143066406, "report/post_ent_max": 38.71559143066406, "report/post_ent_mean": 38.59010314941406, "report/post_ent_min": 38.54078674316406, "report/post_ent_std": 0.02009623497724533, "report/prior_ent_mag": 46.290252685546875, "report/prior_ent_max": 46.290252685546875, "report/prior_ent_mean": 46.19887924194336, "report/prior_ent_min": 46.15422439575195, "report/prior_ent_std": 0.016495758667588234, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0002599111758172512, "report/reward_loss_std": 2.207720513069944e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.00010907649993896484, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002599111758172512, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00010861130431294441, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020013896748423576, "eval/cont_loss_std": 0.3154163360595703, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.83885383605957, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002916426630690694, "eval/cont_pred": 0.9970877170562744, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.275513231754303, "eval/image_loss_std": 0.08496362715959549, "eval/model_loss_mean": 0.8957871198654175, "eval/model_loss_std": 0.3219577372074127, "eval/post_ent_mag": 38.71144104003906, "eval/post_ent_max": 38.71144104003906, "eval/post_ent_mean": 38.5903434753418, "eval/post_ent_min": 38.537696838378906, "eval/post_ent_std": 0.01983078010380268, "eval/prior_ent_mag": 46.290252685546875, "eval/prior_ent_max": 46.290252685546875, "eval/prior_ent_mean": 46.19822311401367, "eval/prior_ent_min": 46.140933990478516, "eval/prior_ent_std": 0.016978131607174873, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0002599055878818035, "eval/reward_loss_std": 2.027456105224701e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00010907649993896484, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002599055878818035, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00010860944166779518, "eval/reward_rate": 0.0, "replay/size": 95289.0, "replay/inserts": 31648.0, "replay/samples": 31648.0, "replay/insert_wait_avg": 1.4823039332583651e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.258693620818691e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24168.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3678475372244055e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0342233181, "timer/env.step_count": 7912.0, "timer/env.step_total": 39.07565784454346, "timer/env.step_frac": 0.03907432059164031, "timer/env.step_avg": 0.004938783852950386, "timer/env.step_min": 0.0038602352142333984, "timer/env.step_max": 0.04281210899353027, "timer/replay._sample_count": 31648.0, "timer/replay._sample_total": 16.07308006286621, "timer/replay._sample_frac": 0.01607253000755909, "timer/replay._sample_avg": 0.0005078703255455703, "timer/replay._sample_min": 0.0003466606140136719, "timer/replay._sample_max": 0.025617599487304688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9646.0, "timer/agent.policy_total": 91.1196358203888, "timer/agent.policy_frac": 0.09111651751082586, "timer/agent.policy_avg": 0.009446364899480489, "timer/agent.policy_min": 0.007720947265625, "timer/agent.policy_max": 0.04620027542114258, "timer/dataset_train_count": 1978.0, "timer/dataset_train_total": 0.22666716575622559, "timer/dataset_train_frac": 0.00022665940871918064, "timer/dataset_train_avg": 0.00011459411817807158, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.020555973052978516, "timer/agent.train_count": 1978.0, "timer/agent.train_total": 853.9277868270874, "timer/agent.train_frac": 0.8538985635849208, "timer/agent.train_avg": 0.43171273348184397, "timer/agent.train_min": 0.42153310775756836, "timer/agent.train_max": 0.9431710243225098, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4782414436340332, "timer/agent.report_frac": 0.0004782250771850933, "timer/agent.report_avg": 0.2391207218170166, "timer/agent.report_min": 0.23215889930725098, "timer/agent.report_max": 0.24608254432678223, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.884766080861677e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 31.64631609134072}
{"step": 95940, "time": 3204.6673426628113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96064, "time": 3208.6038961410522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96088, "time": 3209.1345081329346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96104, "time": 3209.634852170944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97096, "time": 3240.270201444626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97220, "time": 3244.2549726963043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97244, "time": 3245.2340404987335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97260, "time": 3245.7359013557434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98252, "time": 3276.4066314697266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98376, "time": 3279.9161727428436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98400, "time": 3280.874622106552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98416, "time": 3281.369609117508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99408, "time": 3312.0082564353943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99532, "time": 3315.898315191269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99556, "time": 3316.433266878128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99572, "time": 3316.9366397857666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100060, "time": 3336.4523243904114, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100060, "time": 3336.4584951400757, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100060, "time": 3336.4643154144287, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100060, "time": 3336.4701063632965, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100060, "time": 3340.4273295402527, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100060, "time": 3340.4340147972107, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100060, "time": 3340.439911842346, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100060, "time": 3340.445788860321, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100564, "time": 3355.625162124634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100688, "time": 3359.5599291324615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100712, "time": 3360.0869224071503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100728, "time": 3360.5805926322937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101720, "time": 3391.040332555771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101844, "time": 3394.9759879112244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101868, "time": 3395.952959537506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101884, "time": 3396.4484555721283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102876, "time": 3427.0723559856415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103000, "time": 3430.5627796649933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103024, "time": 3431.520647764206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103040, "time": 3432.017910718918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104032, "time": 3462.5161430835724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104156, "time": 3466.4540367126465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104180, "time": 3466.985689163208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104196, "time": 3467.489138364792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105188, "time": 3497.999370098114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105312, "time": 3501.932042121887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105336, "time": 3502.455206632614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105352, "time": 3502.9475622177124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105752, "time": 3515.2733182907104, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 105964, "time": 3522.107637166977, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 106344, "time": 3533.4719185829163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106468, "time": 3537.4219908714294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106908, "time": 3551.3741507530212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107120, "time": 3557.7832782268524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107500, "time": 3569.582323551178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107624, "time": 3573.0891325473785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108064, "time": 3586.7494673728943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108276, "time": 3593.177962779999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108656, "time": 3604.9402968883514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108780, "time": 3608.8935339450836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109220, "time": 3622.2135162353516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109432, "time": 3628.5995988845825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109812, "time": 3640.377145767212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109936, "time": 3644.2989897727966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110060, "time": 3652.2453479766846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110060, "time": 3652.2513840198517, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110060, "time": 3652.2567620277405, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110060, "time": 3652.262266397476, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110060, "time": 3656.6126670837402, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110060, "time": 3656.618760585785, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110060, "time": 3656.624496936798, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110060, "time": 3656.6304337978363, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110376, "time": 3666.112457036972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110588, "time": 3672.9604177474976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110968, "time": 3684.488501548767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111092, "time": 3688.4003586769104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111532, "time": 3702.235904455185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111744, "time": 3708.601326227188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112124, "time": 3720.333967447281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112248, "time": 3723.865016222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112688, "time": 3737.605455636978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112900, "time": 3744.055116176605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113280, "time": 3755.9145748615265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113404, "time": 3759.8803160190582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113844, "time": 3773.238527059555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114056, "time": 3779.7034237384796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114436, "time": 3791.5586602687836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114560, "time": 3795.5046269893646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115000, "time": 3808.9913980960846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115212, "time": 3815.8679633140564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115592, "time": 3827.222975254059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115716, "time": 3831.1518676280975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116156, "time": 3844.8909924030304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116368, "time": 3851.2776956558228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116748, "time": 3863.042436361313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116872, "time": 3866.501698255539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117312, "time": 3880.247129201889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117524, "time": 3886.629706144333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117904, "time": 3898.416973590851, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118028, "time": 3902.421890735626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118468, "time": 3915.682145357132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118680, "time": 3922.1120562553406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119060, "time": 3934.1181089878082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119184, "time": 3938.046003103256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119624, "time": 3951.2570559978485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119836, "time": 3958.094653606415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120060, "time": 3969.0448412895203, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120060, "time": 3969.051145553589, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120060, "time": 3969.0568900108337, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120060, "time": 3969.0625047683716, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120060, "time": 3973.0289494991302, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120060, "time": 3973.0356447696686, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120060, "time": 3973.0415844917297, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120060, "time": 3973.047411441803, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120216, "time": 3977.488429546356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120340, "time": 3981.4004287719727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120780, "time": 3995.1092042922974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120992, "time": 4001.518004179001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121372, "time": 4013.2747871875763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121496, "time": 4016.7820839881897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121936, "time": 4030.5478909015656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122148, "time": 4036.9222683906555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122528, "time": 4048.6927456855774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122652, "time": 4052.651059627533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123092, "time": 4065.982543706894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123304, "time": 4072.5410857200623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123684, "time": 4084.4065511226654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123808, "time": 4088.31205201149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124248, "time": 4101.576544046402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124460, "time": 4108.4178903102875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124840, "time": 4119.823099851608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124964, "time": 4123.753669261932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125404, "time": 4137.479388952255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125616, "time": 4143.934810638428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125996, "time": 4155.684819459915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126120, "time": 4159.170139074326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126560, "time": 4172.989023208618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126772, "time": 4179.400561332703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127152, "time": 4191.161225318909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127276, "time": 4195.227530956268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127433, "time": 4200.685115098953, "train_stats/mean_log_entropy": 1.9376752376556396, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0002785309922273, "train/action_min": 0.0, "train/action_std": 1.9998083078316626, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 5.4713195910559716e-05, "train/actor_opt_grad_steps": 6880.0, "train/actor_opt_loss": -4.758424460055864, "train/adv_mag": 0.00021472314211922855, "train/adv_max": 0.0001711014298920704, "train/adv_mean": 4.9068405295596683e-05, "train/adv_min": -8.671400775461632e-05, "train/adv_std": 5.105528202529321e-05, "train/cont_avg": 0.9965944241751269, "train/cont_loss_mean": 0.022787039438829884, "train/cont_loss_std": 0.31920869131519636, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.679969397233558, "train/cont_pos_acc": 0.9999999854770408, "train/cont_pos_loss": 0.0034626933289833633, "train/cont_pred": 0.996543416517035, "train/cont_rate": 0.9965944241751269, "train/dyn_loss_mean": 1.019926467522752, "train/dyn_loss_std": 0.0003592092390195821, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.012410714049932315, "train/extr_critic_critic_opt_grad_steps": 6880.0, "train/extr_critic_critic_opt_loss": 7009.184674413071, "train/extr_critic_mag": 0.0185033766751362, "train/extr_critic_max": 0.0185033766751362, "train/extr_critic_mean": 0.018448026576623092, "train/extr_critic_min": 0.018409062763156018, "train/extr_critic_std": 1.4528428918274391e-05, "train/extr_return_normed_mag": 0.0003221322248127255, "train/extr_return_normed_max": 0.0002734008987391661, "train/extr_return_normed_mean": 0.0001827140668215664, "train/extr_return_normed_min": 8.431973342362999e-05, "train/extr_return_normed_std": 4.70187888536456e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.018587769477197966, "train/extr_return_raw_max": 0.018587769477197966, "train/extr_return_raw_mean": 0.01849708358194622, "train/extr_return_raw_min": 0.01839868831188243, "train/extr_return_raw_std": 4.701878859626322e-05, "train/extr_reward_mag": 6.322388721601612e-05, "train/extr_reward_max": 6.322388721601612e-05, "train/extr_reward_mean": 6.320170400313192e-05, "train/extr_reward_min": 6.316398000959212e-05, "train/extr_reward_std": 1.281730878567666e-08, "train/image_loss_mean": 0.25605395012700616, "train/image_loss_std": 0.08506936341675404, "train/model_loss_mean": 0.8926589177344656, "train/model_loss_std": 0.37159554191349725, "train/model_opt_grad_norm": 56.53965385553195, "train/model_opt_grad_steps": 6870.0, "train/model_opt_loss": 785.2497481137968, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 875.6345177664974, "train/policy_entropy_mag": 1.9458929342666857, "train/policy_entropy_max": 1.9458929342666857, "train/policy_entropy_mean": 1.9452602591006283, "train/policy_entropy_min": 1.93105858413096, "train/policy_entropy_std": 0.0005016860051014399, "train/policy_logprob_mag": 2.169864742889017, "train/policy_logprob_max": -1.7373677467936792, "train/policy_logprob_mean": -1.9452783516820917, "train/policy_logprob_min": -2.169864742889017, "train/policy_logprob_std": 0.03507095335174333, "train/policy_randomness_mag": 0.9999912142148478, "train/policy_randomness_max": 0.9999912142148478, "train/policy_randomness_mean": 0.9996660763237077, "train/policy_randomness_min": 0.9923678633525287, "train/policy_randomness_std": 0.0002578156070989382, "train/post_ent_mag": 41.734339873802845, "train/post_ent_max": 41.734339873802845, "train/post_ent_mean": 41.67986245324769, "train/post_ent_min": 41.56971794941704, "train/post_ent_std": 0.028304876302260206, "train/prior_ent_mag": 46.42065499397704, "train/prior_ent_max": 46.42065499397704, "train/prior_ent_mean": 46.362864925171515, "train/prior_ent_min": 46.28766308702188, "train/prior_ent_std": 0.015858326506739493, "train/rep_loss_mean": 1.019926467522752, "train/rep_loss_std": 0.0003592092390195821, "train/reward_avg": 9.44650724003101e-05, "train/reward_loss_mean": 0.001862030707980473, "train/reward_loss_std": 0.052375774828818104, "train/reward_max_data": 0.09043464548696721, "train/reward_max_pred": 6.329529176508714e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00016561648385158415, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.060359328985214, "train/reward_pred": 6.324140151707351e-05, "train/reward_rate": 0.00016854378172588832, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.031118949875235558, "report/cont_loss_std": 0.3948209285736084, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.667524814605713, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003462397027760744, "report/cont_pred": 0.9965437054634094, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25593310594558716, "report/image_loss_std": 0.08654110133647919, "report/model_loss_mean": 0.8872103691101074, "report/model_loss_std": 0.40358424186706543, "report/post_ent_mag": 45.45237731933594, "report/post_ent_max": 45.45237731933594, "report/post_ent_mean": 45.444488525390625, "report/post_ent_min": 45.43225860595703, "report/post_ent_std": 0.0034224584233015776, "report/prior_ent_mag": 45.776695251464844, "report/prior_ent_max": 45.776695251464844, "report/prior_ent_mean": 45.76373291015625, "report/prior_ent_min": 45.71722412109375, "report/prior_ent_std": 0.009214977733790874, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001583099365234375, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 6.592273712158203e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001583099365234375, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.592273712158203e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014525018632411957, "eval/cont_loss_std": 0.25007396936416626, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.667524814605713, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0034623967949301004, "eval/cont_pred": 0.9965437054634094, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2506599426269531, "eval/image_loss_std": 0.08421731740236282, "eval/model_loss_mean": 0.8653432130813599, "eval/model_loss_std": 0.26034116744995117, "eval/post_ent_mag": 45.451438903808594, "eval/post_ent_max": 45.451438903808594, "eval/post_ent_mean": 45.444374084472656, "eval/post_ent_min": 45.432857513427734, "eval/post_ent_std": 0.003226935863494873, "eval/prior_ent_mag": 45.77655029296875, "eval/prior_ent_max": 45.77655029296875, "eval/prior_ent_mean": 45.763572692871094, "eval/prior_ent_min": 45.71722412109375, "eval/prior_ent_std": 0.008539101108908653, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001583099365234375, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 6.592273712158203e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001583099365234375, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.592273712158203e-05, "eval/reward_rate": 0.0, "replay/size": 126921.0, "replay/inserts": 31632.0, "replay/samples": 31632.0, "replay/insert_wait_avg": 1.4502666306483607e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.877189460642481e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31104.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.304667988725462e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1413538455963, "timer/env.step_count": 7908.0, "timer/env.step_total": 37.582494258880615, "timer/env.step_frac": 0.037577182579616314, "timer/env.step_avg": 0.004752465131370841, "timer/env.step_min": 0.003632068634033203, "timer/env.step_max": 0.025658369064331055, "timer/replay._sample_count": 31632.0, "timer/replay._sample_total": 16.328943967819214, "timer/replay._sample_frac": 0.01632663613501588, "timer/replay._sample_avg": 0.0005162159827965103, "timer/replay._sample_min": 0.0003886222839355469, "timer/replay._sample_max": 0.03013300895690918, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9642.0, "timer/agent.policy_total": 89.47973990440369, "timer/agent.policy_frac": 0.08946709338669916, "timer/agent.policy_avg": 0.009280205341672235, "timer/agent.policy_min": 0.008138895034790039, "timer/agent.policy_max": 0.04139399528503418, "timer/dataset_train_count": 1977.0, "timer/dataset_train_total": 0.20908570289611816, "timer/dataset_train_frac": 0.00020905615200508668, "timer/dataset_train_avg": 0.00010575908087815789, "timer/dataset_train_min": 8.463859558105469e-05, "timer/dataset_train_max": 0.005461454391479492, "timer/agent.train_count": 1977.0, "timer/agent.train_total": 857.4638919830322, "timer/agent.train_frac": 0.8573427032949276, "timer/agent.train_avg": 0.43371972280375937, "timer/agent.train_min": 0.42586302757263184, "timer/agent.train_max": 0.5090365409851074, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47408461570739746, "timer/agent.report_frac": 0.0004740176114951322, "timer/agent.report_avg": 0.23704230785369873, "timer/agent.report_min": 0.23012542724609375, "timer/agent.report_max": 0.2439591884613037, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7414261485394544e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 31.626935713754577}
{"step": 127716, "time": 4209.311325550079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127928, "time": 4215.693068742752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128308, "time": 4227.471423149109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128432, "time": 4231.465017080307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128676, "time": 4238.852318048477, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 128872, "time": 4244.775376319885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128896, "time": 4245.729740381241, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 129464, "time": 4263.150673627853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129832, "time": 4274.428173542023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130028, "time": 4280.775212049484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130052, "time": 4281.30263710022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130060, "time": 4285.778275251389, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130060, "time": 4285.785197257996, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130060, "time": 4285.791444540024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130060, "time": 4285.797899961472, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130060, "time": 4290.1210951805115, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130060, "time": 4290.127200603485, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130060, "time": 4290.132877588272, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130060, "time": 4290.1385753154755, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130620, "time": 4307.334312677383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130988, "time": 4318.653742074966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131184, "time": 4324.632591724396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131208, "time": 4325.160039424896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131776, "time": 4342.969159126282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132144, "time": 4354.342185974121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132340, "time": 4360.259127855301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132364, "time": 4361.213181972504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132932, "time": 4378.41662979126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133300, "time": 4389.725066423416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133496, "time": 4395.620111465454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133520, "time": 4396.577420711517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134088, "time": 4413.850096464157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134456, "time": 4425.138365268707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134652, "time": 4431.497296094894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134676, "time": 4432.040149688721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135244, "time": 4449.730663061142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135408, "time": 4454.659364461899, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 135808, "time": 4467.056103229523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135832, "time": 4467.579248666763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136400, "time": 4485.230646848679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136564, "time": 4490.1422481536865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136964, "time": 4502.446291446686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136988, "time": 4503.408933639526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137556, "time": 4520.600889444351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137720, "time": 4525.531669616699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138120, "time": 4537.8433537483215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138144, "time": 4538.803275346756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138712, "time": 4556.057827949524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138876, "time": 4561.473181724548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139276, "time": 4573.748436689377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139300, "time": 4574.273693084717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139868, "time": 4592.148077964783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140032, "time": 4597.06645488739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140060, "time": 4602.109312772751, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140060, "time": 4602.115335702896, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140060, "time": 4602.120943784714, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140060, "time": 4602.126228570938, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140060, "time": 4605.893453836441, "eval_episode/length": 227.0, "eval_episode/score": 0.2906250059604645, "eval_episode/reward_rate": 0.0043859649122807015}
{"step": 140060, "time": 4606.7600684165955, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140060, "time": 4606.766603946686, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140060, "time": 4606.773051023483, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140432, "time": 4618.11500620842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140456, "time": 4618.639835357666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141024, "time": 4636.374502420425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141188, "time": 4641.305083274841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141588, "time": 4653.6518387794495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141612, "time": 4654.60378241539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142180, "time": 4671.899305820465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142344, "time": 4676.856835842133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142744, "time": 4689.256861448288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142768, "time": 4690.214489936829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143336, "time": 4707.486807823181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143500, "time": 4712.923005104065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143900, "time": 4725.388967514038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143924, "time": 4725.908568382263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144492, "time": 4743.603563308716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144656, "time": 4748.5161254405975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145056, "time": 4760.720442056656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145080, "time": 4761.262998819351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145648, "time": 4778.972422361374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145812, "time": 4783.887701511383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146212, "time": 4796.119155883789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146236, "time": 4797.073852062225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146804, "time": 4814.223188877106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146968, "time": 4819.140191555023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147368, "time": 4831.473726034164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147392, "time": 4832.4313843250275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147960, "time": 4849.746465682983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148124, "time": 4855.097022533417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148524, "time": 4867.329253911972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148548, "time": 4867.850704193115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149116, "time": 4885.481921672821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149280, "time": 4890.394086360931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149680, "time": 4902.713163614273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149704, "time": 4903.238489627838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150060, "time": 4918.7160613536835, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150060, "time": 4918.72269821167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150060, "time": 4918.729328632355, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150060, "time": 4918.735176563263, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150060, "time": 4922.7122230529785, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150060, "time": 4922.718247890472, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150060, "time": 4922.724092960358, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150060, "time": 4922.729924201965, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150272, "time": 4929.082879543304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150436, "time": 4933.955052614212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150836, "time": 4946.185156106949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150860, "time": 4947.145824432373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151428, "time": 4964.298999547958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151592, "time": 4969.177416086197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151992, "time": 4981.68826341629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152016, "time": 4982.6498067379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152584, "time": 4999.86545920372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152748, "time": 5005.196540355682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153148, "time": 5017.415625810623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153172, "time": 5017.9364449977875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153740, "time": 5035.492956876755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153904, "time": 5040.4121861457825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154304, "time": 5052.628976583481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154328, "time": 5053.14895939827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154700, "time": 5064.858345031738, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 154896, "time": 5070.757986068726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155060, "time": 5075.6985104084015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155460, "time": 5087.9790053367615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155856, "time": 5100.260537862778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156052, "time": 5106.388605594635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156216, "time": 5111.321353435516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156616, "time": 5123.542694091797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157012, "time": 5135.839804172516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157208, "time": 5141.678254365921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157372, "time": 5146.977115392685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157772, "time": 5159.139485359192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158168, "time": 5170.969920158386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158364, "time": 5177.285841464996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158528, "time": 5182.192615747452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158928, "time": 5194.516638755798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159113, "time": 5200.927733182907, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9985675233783144, "train/action_min": 0.0, "train/action_std": 2.000360527423897, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.351801923041072e-05, "train/actor_opt_grad_steps": 8855.0, "train/actor_opt_loss": -5.531754444945943, "train/adv_mag": 0.00018808395234924373, "train/adv_max": 0.00013276037167419088, "train/adv_mean": 8.46834763368668e-06, "train/adv_min": -0.00011583867322916936, "train/adv_std": 4.313862536785775e-05, "train/cont_avg": 0.9964439315025253, "train/cont_loss_mean": 0.02364190872006043, "train/cont_loss_std": 0.3256028202771576, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.657165441757593, "train/cont_pos_acc": 0.9999999858514227, "train/cont_pos_loss": 0.0035430201249328826, "train/cont_pred": 0.9964633719487623, "train/cont_rate": 0.9964439315025253, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.009035987178018937, "train/extr_critic_critic_opt_grad_steps": 8855.0, "train/extr_critic_critic_opt_loss": 7059.579644097223, "train/extr_critic_mag": 0.01870826819930414, "train/extr_critic_max": 0.01870826819930414, "train/extr_critic_mean": 0.018658949974736178, "train/extr_critic_min": 0.01860625876320733, "train/extr_critic_std": 1.820731420127571e-05, "train/extr_return_normed_mag": 0.00022721377135527255, "train/extr_return_normed_max": 0.0001533074454978259, "train/extr_return_normed_mean": 7.257258195205864e-05, "train/extr_return_normed_min": -1.5391601306019407e-05, "train/extr_return_normed_std": 3.7462675096847567e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.018748146829882052, "train/extr_return_raw_max": 0.018748146829882052, "train/extr_return_raw_mean": 0.018667412940600907, "train/extr_return_raw_min": 0.01857944778307821, "train/extr_return_raw_std": 3.7462675201634676e-05, "train/extr_reward_mag": 5.740288532141483e-05, "train/extr_reward_max": 5.740288532141483e-05, "train/extr_reward_mean": 5.7383787117776755e-05, "train/extr_reward_min": 5.732822899866586e-05, "train/extr_reward_std": 1.4343843597734591e-08, "train/image_loss_mean": 0.2480894108161782, "train/image_loss_std": 0.08488943126767573, "train/model_loss_mean": 0.8733109913089059, "train/model_loss_std": 0.37053653763400185, "train/model_opt_grad_norm": 48.92813510217037, "train/model_opt_grad_steps": 8844.681818181818, "train/model_opt_loss": 2331.8891096018783, "train/model_opt_model_opt_grad_overflow": 0.005050505050505051, "train/model_opt_model_opt_grad_scale": 2657.8282828282827, "train/policy_entropy_mag": 1.9458911298501371, "train/policy_entropy_max": 1.9458911298501371, "train/policy_entropy_mean": 1.945001158449385, "train/policy_entropy_min": 1.9266860238229386, "train/policy_entropy_std": 0.0006850537690545686, "train/policy_logprob_mag": 2.214594117318741, "train/policy_logprob_max": -1.7016361313636856, "train/policy_logprob_mean": -1.9449892814713294, "train/policy_logprob_min": -2.214594117318741, "train/policy_logprob_std": 0.042604985637496214, "train/policy_randomness_mag": 0.9999902829377338, "train/policy_randomness_max": 0.9999902829377338, "train/policy_randomness_mean": 0.9995329340901038, "train/policy_randomness_min": 0.9901208124979578, "train/policy_randomness_std": 0.00035204801642608764, "train/post_ent_mag": 46.92705491576532, "train/post_ent_max": 46.92705491576532, "train/post_ent_mean": 46.90976909675984, "train/post_ent_min": 46.8970161014133, "train/post_ent_std": 0.004247985427465403, "train/prior_ent_mag": 45.78695986969302, "train/prior_ent_max": 45.78695986969302, "train/prior_ent_mean": 45.764853525643396, "train/prior_ent_min": 45.73238130049272, "train/prior_ent_std": 0.007927949712000261, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 6.632178804585522e-05, "train/reward_loss_mean": 0.0015796516302295706, "train/reward_loss_std": 0.04275806236379326, "train/reward_max_data": 0.05986426823367976, "train/reward_max_pred": 5.745767342923868e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00014519525564427374, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.353227615356445, "train/reward_pred": 5.740881897509098e-05, "train/reward_rate": 0.00013809974747474747, "train_stats/mean_log_entropy": 1.936599570351678, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025686968117952347, "report/cont_loss_std": 0.36232736706733704, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.811590671539307, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0029971522744745016, "report/cont_pred": 0.9970073103904724, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.23685702681541443, "report/image_loss_std": 0.07933340966701508, "report/model_loss_mean": 0.8627243041992188, "report/model_loss_std": 0.3714883327484131, "report/post_ent_mag": 48.33623123168945, "report/post_ent_max": 48.33623123168945, "report/post_ent_mean": 48.31352233886719, "report/post_ent_min": 48.303836822509766, "report/post_ent_std": 0.005092098843306303, "report/prior_ent_mag": 45.86676788330078, "report/prior_ent_max": 45.86676788330078, "report/prior_ent_mean": 45.82357406616211, "report/prior_ent_min": 45.80005645751953, "report/prior_ent_std": 0.00988867599517107, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00018024444580078125, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.224082946777344e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00018024444580078125, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.224082946777344e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008669606409966946, "eval/cont_loss_std": 0.1814299076795578, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.811590671539307, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0029971522744745016, "eval/cont_pred": 0.9970073103904724, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22842782735824585, "eval/image_loss_std": 0.07974038273096085, "eval/model_loss_mean": 0.8372777104377747, "eval/model_loss_std": 0.1962583065032959, "eval/post_ent_mag": 48.33638381958008, "eval/post_ent_max": 48.33638381958008, "eval/post_ent_mean": 48.31355667114258, "eval/post_ent_min": 48.30101776123047, "eval/post_ent_std": 0.004876081831753254, "eval/prior_ent_mag": 45.86457061767578, "eval/prior_ent_max": 45.86457061767578, "eval/prior_ent_mean": 45.82212829589844, "eval/prior_ent_min": 45.79315185546875, "eval/prior_ent_std": 0.009665428660809994, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00018024444580078125, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.224082946777344e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00018024444580078125, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.224082946777344e-05, "eval/reward_rate": 0.0, "replay/size": 158601.0, "replay/inserts": 31680.0, "replay/samples": 31680.0, "replay/insert_wait_avg": 1.4621576275488342e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.838913888642283e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38040.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3764754298649032e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.218897819519, "timer/env.step_count": 7920.0, "timer/env.step_total": 36.92194485664368, "timer/env.step_frac": 0.036913864492196316, "timer/env.step_avg": 0.004661861724323696, "timer/env.step_min": 0.0036656856536865234, "timer/env.step_max": 0.029534101486206055, "timer/replay._sample_count": 31680.0, "timer/replay._sample_total": 16.434987545013428, "timer/replay._sample_frac": 0.016431390749406718, "timer/replay._sample_avg": 0.000518781172506737, "timer/replay._sample_min": 0.0003833770751953125, "timer/replay._sample_max": 0.023012399673461914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9654.0, "timer/agent.policy_total": 89.66628336906433, "timer/agent.policy_frac": 0.08964665991068271, "timer/agent.policy_avg": 0.009287992890932704, "timer/agent.policy_min": 0.008100032806396484, "timer/agent.policy_max": 0.6612987518310547, "timer/dataset_train_count": 1980.0, "timer/dataset_train_total": 0.20310521125793457, "timer/dataset_train_frac": 0.00020306076169996856, "timer/dataset_train_avg": 0.00010257838952420938, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0009551048278808594, "timer/agent.train_count": 1980.0, "timer/agent.train_total": 858.2413671016693, "timer/agent.train_frac": 0.8580535410525023, "timer/agent.train_avg": 0.433455235909934, "timer/agent.train_min": 0.42375826835632324, "timer/agent.train_max": 0.5595118999481201, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47659873962402344, "timer/agent.report_frac": 0.0004764944360309633, "timer/agent.report_avg": 0.23829936981201172, "timer/agent.report_min": 0.23204731941223145, "timer/agent.report_max": 0.244551420211792, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5272369384765625e-05, "timer/dataset_eval_frac": 2.526683852890551e-08, "timer/dataset_eval_avg": 2.5272369384765625e-05, "timer/dataset_eval_min": 2.5272369384765625e-05, "timer/dataset_eval_max": 2.5272369384765625e-05, "fps": 31.672377840333283}
{"step": 159324, "time": 5207.483693599701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159520, "time": 5213.374325752258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159684, "time": 5218.337772369385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160060, "time": 5234.2158534526825, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160060, "time": 5234.223407506943, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160060, "time": 5234.229564189911, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160060, "time": 5234.235440731049, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160060, "time": 5238.044524908066, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160060, "time": 5238.050986051559, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160060, "time": 5238.056487321854, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160060, "time": 5238.062040805817, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160084, "time": 5238.588563919067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160480, "time": 5250.763861179352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160676, "time": 5256.703328847885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160840, "time": 5261.607670307159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161240, "time": 5273.837108135223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161636, "time": 5286.126806735992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161832, "time": 5291.9949543476105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161996, "time": 5297.308945417404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162396, "time": 5309.543815374374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162792, "time": 5321.424156665802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162988, "time": 5327.76790189743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163152, "time": 5332.66824054718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163552, "time": 5344.926540136337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163948, "time": 5357.153941392899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164144, "time": 5363.148674249649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164308, "time": 5368.040312767029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164708, "time": 5380.282021045685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165104, "time": 5392.430066823959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165300, "time": 5398.271035194397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165464, "time": 5403.1889588832855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165864, "time": 5415.32662653923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166260, "time": 5427.495236158371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166456, "time": 5433.415039300919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166620, "time": 5438.727635860443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167020, "time": 5450.871046543121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167360, "time": 5460.999371051788, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 167416, "time": 5462.4782807827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167420, "time": 5462.926748514175, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 167512, "time": 5465.403875589371, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 168516, "time": 5496.103101730347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168572, "time": 5498.0389316082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168576, "time": 5498.060269117355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168668, "time": 5500.989135026932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169672, "time": 5531.259229898453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169728, "time": 5533.206783294678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169732, "time": 5533.2290279865265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169824, "time": 5536.137951135635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170060, "time": 5546.238049030304, "eval_episode/length": 183.0, "eval_episode/score": 0.4281249940395355, "eval_episode/reward_rate": 0.005434782608695652}
{"step": 170060, "time": 5547.724987745285, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170060, "time": 5547.7310128211975, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170060, "time": 5547.736693382263, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170060, "time": 5550.215954065323, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170060, "time": 5551.475911855698, "eval_episode/length": 271.0, "eval_episode/score": 0.15312500298023224, "eval_episode/reward_rate": 0.003676470588235294}
{"step": 170060, "time": 5551.723690271378, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170060, "time": 5551.730016469955, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170828, "time": 5575.048207759857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170884, "time": 5576.535097122192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170888, "time": 5576.556577205658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170980, "time": 5579.4439861774445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171984, "time": 5610.032395601273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172040, "time": 5611.5108234882355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172044, "time": 5611.95743727684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172136, "time": 5614.421154022217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173140, "time": 5645.273584842682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173196, "time": 5647.183669805527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173200, "time": 5647.205397844315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173292, "time": 5650.1146235466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174296, "time": 5680.469676017761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174352, "time": 5682.421008110046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174356, "time": 5682.442573547363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174448, "time": 5685.352106809616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175452, "time": 5716.090398788452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175508, "time": 5717.5981867313385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175512, "time": 5717.619480133057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175604, "time": 5720.5244727134705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176572, "time": 5750.239110708237, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 176608, "time": 5751.241948127747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176664, "time": 5752.730672836304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176760, "time": 5755.66583275795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177184, "time": 5768.786744117737, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 177764, "time": 5786.393876791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177820, "time": 5788.3134343624115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177916, "time": 5791.228682518005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178108, "time": 5797.073193073273, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 178340, "time": 5803.960117340088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178920, "time": 5821.521388292313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179072, "time": 5826.39629483223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179264, "time": 5832.27722120285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179496, "time": 5839.151395559311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180060, "time": 5860.533151388168, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180060, "time": 5860.539616346359, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180060, "time": 5860.54497551918, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180060, "time": 5860.550513505936, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180060, "time": 5864.575403213501, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180060, "time": 5864.583687067032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180060, "time": 5864.592057943344, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180060, "time": 5864.597629070282, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180076, "time": 5865.088694810867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180104, "time": 5865.623894929886, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 180228, "time": 5869.521137475967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180652, "time": 5882.900454998016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181232, "time": 5900.500238418579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181260, "time": 5901.456246852875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181384, "time": 5904.9034996032715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181808, "time": 5918.063313961029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182388, "time": 5935.656481027603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182416, "time": 5936.6380298137665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182540, "time": 5940.542824745178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182964, "time": 5953.22432923317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183544, "time": 5970.781051397324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183572, "time": 5971.739450931549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183696, "time": 5975.659211158752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184120, "time": 5988.414089202881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184700, "time": 6006.714960813522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184728, "time": 6007.247284889221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184852, "time": 6011.163658380508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185276, "time": 6024.333615064621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185856, "time": 6041.9587235450745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185884, "time": 6042.949292182922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186008, "time": 6046.39716053009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186432, "time": 6059.607565641403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187012, "time": 6077.381274223328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187040, "time": 6078.353049516678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187164, "time": 6082.291496038437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187588, "time": 6095.149478197098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188168, "time": 6112.800950288773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188196, "time": 6113.763578891754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188320, "time": 6117.652589082718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188744, "time": 6130.582024097443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189324, "time": 6148.621028661728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189352, "time": 6149.155626535416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189476, "time": 6153.167269706726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189900, "time": 6166.40008020401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190004, "time": 6169.341991424561, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 190060, "time": 6175.201547622681, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190060, "time": 6175.207535266876, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190060, "time": 6175.212891578674, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190060, "time": 6175.2186143398285, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190060, "time": 6179.174692869186, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190060, "time": 6179.180721521378, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190060, "time": 6179.186316728592, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190060, "time": 6179.191897153854, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190480, "time": 6191.911041259766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190508, "time": 6192.891541957855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190761, "time": 6201.268621206284, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.993380459872159, "train/action_min": 0.0, "train/action_std": 2.00634402217287, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00014266617356704293, "train/actor_opt_grad_steps": 10835.0, "train/actor_opt_loss": -5.622706426443965, "train/adv_mag": 0.00039355022211869556, "train/adv_max": 0.00030175475121447533, "train/adv_mean": 2.579603983906968e-06, "train/adv_min": -0.00029134466265789185, "train/adv_std": 8.160549421316116e-05, "train/cont_avg": 0.9964981849747475, "train/cont_loss_mean": 0.023301936822444802, "train/cont_loss_std": 0.3220686813937703, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6597617065783625, "train/cont_pos_acc": 0.9999999861524562, "train/cont_pos_loss": 0.0035247540893973877, "train/cont_pred": 0.9964815823718755, "train/cont_rate": 0.9964981849747475, "train/dyn_loss_mean": 1.0000000078268725, "train/dyn_loss_std": 2.4507220348253885e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.006153175062876232, "train/extr_critic_critic_opt_grad_steps": 10835.0, "train/extr_critic_critic_opt_loss": 7190.646299419981, "train/extr_critic_mag": 0.019402721915582215, "train/extr_critic_max": 0.019402721915582215, "train/extr_critic_mean": 0.019202570666116896, "train/extr_critic_min": 0.019020352098676894, "train/extr_critic_std": 4.992688499065351e-05, "train/extr_return_normed_mag": 0.0004012043390310172, "train/extr_return_normed_max": 0.00032131864002557715, "train/extr_return_normed_mean": 0.00010944836557970083, "train/extr_return_normed_min": -9.55217865982441e-05, "train/extr_return_normed_std": 6.747661323841918e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.019417016729336194, "train/extr_return_raw_max": 0.019417016729336194, "train/extr_return_raw_mean": 0.0192051473064254, "train/extr_return_raw_min": 0.019000176302712373, "train/extr_return_raw_std": 6.747661317411146e-05, "train/extr_reward_mag": 5.8038066131900055e-05, "train/extr_reward_max": 5.8038066131900055e-05, "train/extr_reward_mean": 5.79795002586895e-05, "train/extr_reward_min": 5.7930296117609196e-05, "train/extr_reward_std": 2.453252246017468e-08, "train/image_loss_mean": 0.23244862875553093, "train/image_loss_std": 0.08709706238122901, "train/model_loss_mean": 0.8571122938936407, "train/model_loss_std": 0.3639632173710399, "train/model_opt_grad_norm": 45.53467944174102, "train/model_opt_grad_steps": 10823.277777777777, "train/model_opt_loss": 2740.2523729728928, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3207.070707070707, "train/policy_entropy_mag": 1.9457716791316717, "train/policy_entropy_max": 1.9457716791316717, "train/policy_entropy_mean": 1.9381140675207582, "train/policy_entropy_min": 1.854699315446796, "train/policy_entropy_std": 0.006293226850414273, "train/policy_logprob_mag": 2.5502920186880864, "train/policy_logprob_max": -1.3924383186932765, "train/policy_logprob_mean": -1.9382004683667964, "train/policy_logprob_min": -2.5502920186880864, "train/policy_logprob_std": 0.11250682598487897, "train/policy_randomness_mag": 0.9999288982815213, "train/policy_randomness_max": 0.9999288982815213, "train/policy_randomness_mean": 0.9959936722962544, "train/policy_randomness_min": 0.9531269609326064, "train/policy_randomness_std": 0.003234079022094551, "train/post_ent_mag": 50.99225666547063, "train/post_ent_max": 50.99225666547063, "train/post_ent_mean": 50.76138030158149, "train/post_ent_min": 50.6206028100216, "train/post_ent_std": 0.073715823972974, "train/prior_ent_mag": 48.61934160945391, "train/prior_ent_max": 48.61934160945391, "train/prior_ent_mean": 47.37797577212555, "train/prior_ent_min": 47.00285672659826, "train/prior_ent_std": 0.22762095771560614, "train/rep_loss_mean": 1.0000000078268725, "train/rep_loss_std": 2.4507220348253885e-07, "train/reward_avg": 6.122011168050871e-05, "train/reward_loss_mean": 0.0013617031708961786, "train/reward_loss_std": 0.03884949426217467, "train/reward_max_data": 0.06268939436084092, "train/reward_max_pred": 5.796581807762685e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00014706643909301767, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.26140284538269, "train/reward_pred": 5.7897868570918685e-05, "train/reward_rate": 0.00011837121212121212, "train_stats/mean_log_entropy": 1.9152177878185712, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.008563418872654438, "report/cont_loss_std": 0.18313808739185333, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.866118907928467, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002837559673935175, "report/cont_pred": 0.9971662759780884, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2134597897529602, "report/image_loss_std": 0.10407225042581558, "report/model_loss_mean": 0.8221545815467834, "report/model_loss_std": 0.21570706367492676, "report/post_ent_mag": 54.014949798583984, "report/post_ent_max": 54.014949798583984, "report/post_ent_mean": 53.43267822265625, "report/post_ent_min": 52.98887634277344, "report/post_ent_std": 0.2110462337732315, "report/prior_ent_mag": 54.574119567871094, "report/prior_ent_max": 54.574119567871094, "report/prior_ent_mean": 49.87848663330078, "report/prior_ent_min": 48.04599380493164, "report/prior_ent_std": 0.8280337452888489, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00013130903244018555, "report/reward_loss_std": 4.4203986249158334e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.8279762268066406e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00013130903244018555, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.816800355911255e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020015262067317963, "eval/cont_loss_std": 0.31689414381980896, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.866118907928467, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002837688662111759, "eval/cont_pred": 0.9971661567687988, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19692008197307587, "eval/image_loss_std": 0.10723055899143219, "eval/model_loss_mean": 0.8170667886734009, "eval/model_loss_std": 0.3358306288719177, "eval/post_ent_mag": 53.993526458740234, "eval/post_ent_max": 53.993526458740234, "eval/post_ent_mean": 53.373985290527344, "eval/post_ent_min": 53.01936721801758, "eval/post_ent_std": 0.21324585378170013, "eval/prior_ent_mag": 54.31907653808594, "eval/prior_ent_max": 54.31907653808594, "eval/prior_ent_mean": 49.82898712158203, "eval/prior_ent_min": 48.07547378540039, "eval/prior_ent_std": 0.8263252973556519, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00013138260692358017, "eval/reward_loss_std": 4.0456612282468996e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.8279762268066406e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00013138260692358017, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.819559399038553e-05, "eval/reward_rate": 0.0, "replay/size": 190249.0, "replay/inserts": 31648.0, "replay/samples": 31648.0, "replay/insert_wait_avg": 1.468246518299963e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.858516834864602e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47288.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3475754269266623e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.324107170105, "timer/env.step_count": 7912.0, "timer/env.step_total": 36.29785108566284, "timer/env.step_frac": 0.03628609050355556, "timer/env.step_avg": 0.004587696042171744, "timer/env.step_min": 0.0034062862396240234, "timer/env.step_max": 0.030347347259521484, "timer/replay._sample_count": 31648.0, "timer/replay._sample_total": 15.667717695236206, "timer/replay._sample_frac": 0.015662641320881326, "timer/replay._sample_avg": 0.0004950618584187376, "timer/replay._sample_min": 0.0003528594970703125, "timer/replay._sample_max": 0.011404275894165039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 10224.0, "timer/agent.policy_total": 92.2547299861908, "timer/agent.policy_frac": 0.09222483925452662, "timer/agent.policy_avg": 0.009023349959525704, "timer/agent.policy_min": 0.00777745246887207, "timer/agent.policy_max": 0.038643836975097656, "timer/dataset_train_count": 1978.0, "timer/dataset_train_total": 0.20788216590881348, "timer/dataset_train_frac": 0.0002078148116383075, "timer/dataset_train_avg": 0.00010509715162225151, "timer/dataset_train_min": 8.440017700195312e-05, "timer/dataset_train_max": 0.005354642868041992, "timer/agent.train_count": 1978.0, "timer/agent.train_total": 853.8877182006836, "timer/agent.train_frac": 0.8536110567367143, "timer/agent.train_avg": 0.43169247634008273, "timer/agent.train_min": 0.4214355945587158, "timer/agent.train_max": 0.5111441612243652, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48078012466430664, "timer/agent.report_frac": 0.0004806243508660639, "timer/agent.report_avg": 0.24039006233215332, "timer/agent.report_min": 0.23325419425964355, "timer/agent.report_max": 0.24752593040466309, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.88393010470389e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 31.63713727033207}
{"step": 191056, "time": 6210.218306064606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191160, "time": 6213.191243886948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191636, "time": 6227.783380508423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191664, "time": 6228.743504047394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192212, "time": 6245.36657333374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192316, "time": 6248.744992017746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192792, "time": 6263.193950176239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192820, "time": 6264.161237001419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193368, "time": 6280.757226467133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193472, "time": 6284.140709161758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193948, "time": 6298.798715591431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193976, "time": 6299.340602874756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194524, "time": 6316.465086936951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194628, "time": 6319.445090532303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195104, "time": 6334.135057449341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195132, "time": 6335.102108001709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195680, "time": 6351.7266166210175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195784, "time": 6354.678905010223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196260, "time": 6369.309494018555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196288, "time": 6370.2932341098785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196836, "time": 6386.972367763519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196940, "time": 6390.574337005615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197416, "time": 6404.88956952095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197444, "time": 6405.855449676514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197992, "time": 6422.478168487549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198096, "time": 6425.888320446014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198572, "time": 6440.504541873932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198600, "time": 6441.045207500458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199148, "time": 6458.190846681595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199252, "time": 6461.124126911163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199728, "time": 6475.695472955704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199756, "time": 6476.658764839172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200060, "time": 6489.8404376506805, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200060, "time": 6489.8478491306305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200060, "time": 6489.8534343242645, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200060, "time": 6489.858997106552, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200060, "time": 6493.95766043663, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200060, "time": 6493.9637241363525, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200060, "time": 6493.968907594681, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200060, "time": 6493.977876424789, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200228, "time": 6498.8738079071045, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 200408, "time": 6504.228996753693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200884, "time": 6518.87860918045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200912, "time": 6519.8552141189575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201384, "time": 6534.162907838821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201564, "time": 6540.043296337128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202040, "time": 6555.146838188171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202068, "time": 6556.116860151291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202540, "time": 6570.787393331528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202720, "time": 6576.242742776871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203196, "time": 6590.900527000427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203224, "time": 6591.444808483124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203696, "time": 6606.126645088196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203876, "time": 6611.527331352234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204352, "time": 6626.222302913666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204380, "time": 6627.199436426163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204852, "time": 6641.487351894379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205032, "time": 6646.8954792022705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205508, "time": 6661.83371090889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205536, "time": 6662.796955347061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206008, "time": 6677.006050825119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206188, "time": 6682.844222545624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206664, "time": 6697.060390710831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206692, "time": 6698.045193195343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207164, "time": 6712.658743858337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207344, "time": 6718.069903612137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207820, "time": 6732.758396625519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207848, "time": 6733.292401075363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208320, "time": 6748.002438545227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208500, "time": 6753.425015449524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208976, "time": 6768.11151766777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209004, "time": 6769.0768921375275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209476, "time": 6783.557630777359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209656, "time": 6788.948849916458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210036, "time": 6800.672275543213, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 210060, "time": 6805.573677539825, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210060, "time": 6805.5796892642975, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210060, "time": 6805.585428714752, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210060, "time": 6805.59143447876, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210060, "time": 6809.589459180832, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210060, "time": 6809.5954377651215, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210060, "time": 6809.601447582245, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210060, "time": 6809.606889486313, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210160, "time": 6812.613219976425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210632, "time": 6826.823240995407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210812, "time": 6832.681254386902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211192, "time": 6843.968826532364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211316, "time": 6847.881301641464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211392, "time": 6850.309928178787, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 211968, "time": 6867.926320314407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212348, "time": 6879.729629993439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212472, "time": 6883.194763422012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212548, "time": 6885.627403974533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213124, "time": 6903.197310686111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213504, "time": 6915.1052968502045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213628, "time": 6919.018507480621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213704, "time": 6921.017710924149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213808, "time": 6924.430266618729, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 214660, "time": 6950.421950101852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214784, "time": 6954.302043676376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214860, "time": 6956.737294912338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214964, "time": 6959.696218729019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214988, "time": 6960.66227388382, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 215816, "time": 6985.724118232727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216016, "time": 6992.137139081955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216120, "time": 6995.1244921684265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216144, "time": 6996.089454174042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216972, "time": 7021.485586643219, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217172, "time": 7027.380389451981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217276, "time": 7030.787690639496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217300, "time": 7031.31659078598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217748, "time": 7045.237808227539, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 218128, "time": 7057.048866987228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218328, "time": 7062.935279130936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218432, "time": 7066.350425958633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218904, "time": 7080.62540435791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219284, "time": 7092.457748413086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219484, "time": 7098.820446968079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219588, "time": 7101.777085065842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220060, "time": 7116.353246450424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220060, "time": 7120.576323509216, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220060, "time": 7120.582602024078, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220060, "time": 7120.588451623917, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220060, "time": 7120.594343662262, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220060, "time": 7124.440539598465, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220060, "time": 7124.447426319122, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220060, "time": 7124.453140258789, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220060, "time": 7124.459119319916, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220440, "time": 7135.7185151577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220640, "time": 7142.155706167221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220744, "time": 7145.120771408081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221216, "time": 7159.859251499176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221596, "time": 7171.839973688126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221796, "time": 7177.759378194809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221900, "time": 7181.150443315506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222372, "time": 7195.319274663925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222553, "time": 7201.728272676468, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.995721404875942, "train/action_min": 0.0, "train/action_std": 1.9977789506241306, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00010821317367451078, "train/actor_opt_grad_steps": 12820.0, "train/actor_opt_loss": -5.156855088008109, "train/adv_mag": 0.0006119004970219866, "train/adv_max": 0.0005008550126798189, "train/adv_mean": 2.6668362683488422e-05, "train/adv_min": -0.0005225028056445434, "train/adv_std": 0.0001032336630162914, "train/cont_avg": 0.9964716158919598, "train/cont_loss_mean": 0.02348577176295595, "train/cont_loss_std": 0.3227373233396814, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.662000808519187, "train/cont_pos_acc": 0.9999999832268336, "train/cont_pos_loss": 0.0035144700984653067, "train/cont_pred": 0.9964917766388937, "train/cont_rate": 0.9964716158919598, "train/dyn_loss_mean": 1.0000023763982495, "train/dyn_loss_std": 4.794109324151276e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.005253539379567947, "train/extr_critic_critic_opt_grad_steps": 12820.0, "train/extr_critic_critic_opt_loss": 7317.640298661275, "train/extr_critic_mag": 0.020280537293783985, "train/extr_critic_max": 0.020280537293783985, "train/extr_critic_mean": 0.019732263126415225, "train/extr_critic_min": 0.019457776342804108, "train/extr_critic_std": 7.641460648465822e-05, "train/extr_return_normed_mag": 0.0005974827905246361, "train/extr_return_normed_max": 0.0005928540611686418, "train/extr_return_normed_mean": 0.0001849498787843991, "train/extr_return_normed_min": -8.04062633208893e-05, "train/extr_return_normed_std": 8.17302876092428e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.020166812427154738, "train/extr_return_raw_max": 0.020166812427154738, "train/extr_return_raw_mean": 0.01975890913575738, "train/extr_return_raw_min": 0.019493552102665207, "train/extr_return_raw_std": 8.173028771893061e-05, "train/extr_reward_mag": 6.765875984076879e-05, "train/extr_reward_max": 6.765875984076879e-05, "train/extr_reward_mean": 6.259252962140932e-05, "train/extr_reward_min": 6.079194533765016e-05, "train/extr_reward_std": 1.166058929783124e-06, "train/image_loss_mean": 0.20096808290062237, "train/image_loss_std": 0.09937572962225381, "train/model_loss_mean": 0.8258108589517411, "train/model_loss_std": 0.3688027473101065, "train/model_opt_grad_norm": 40.42505980982925, "train/model_opt_grad_steps": 12806.4824120603, "train/model_opt_loss": 2095.0333662943626, "train/model_opt_model_opt_grad_overflow": 0.005025125628140704, "train/model_opt_model_opt_grad_scale": 2525.1256281407036, "train/policy_entropy_mag": 1.9457336358688584, "train/policy_entropy_max": 1.9457336358688584, "train/policy_entropy_mean": 1.9342601461027136, "train/policy_entropy_min": 1.823376257215912, "train/policy_entropy_std": 0.00936309112020623, "train/policy_logprob_mag": 2.7191567588691137, "train/policy_logprob_max": -1.2165630142293384, "train/policy_logprob_mean": -1.934126183615258, "train/policy_logprob_min": -2.7191567588691137, "train/policy_logprob_std": 0.15190300862094266, "train/policy_randomness_mag": 0.9999093485237965, "train/policy_randomness_max": 0.9999093485237965, "train/policy_randomness_mean": 0.994013145341346, "train/policy_randomness_min": 0.9370300913575905, "train/policy_randomness_std": 0.0048116772908286835, "train/post_ent_mag": 53.16794175957914, "train/post_ent_max": 53.16794175957914, "train/post_ent_mean": 52.555159928211616, "train/post_ent_min": 52.121957060080675, "train/post_ent_std": 0.22654043632236556, "train/prior_ent_mag": 53.56401844120505, "train/prior_ent_max": 53.56401844120505, "train/prior_ent_mean": 50.100675573301075, "train/prior_ent_min": 48.424260700168325, "train/prior_ent_std": 0.8104356335635161, "train/rep_loss_mean": 1.0000023763982495, "train/rep_loss_std": 4.794109324151276e-05, "train/reward_avg": 5.7431321281672984e-05, "train/reward_loss_mean": 0.0013555564248382147, "train/reward_loss_std": 0.03819056387050943, "train/reward_max_data": 0.058809672992433136, "train/reward_max_pred": 6.671467019085908e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00016159531938985, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.137685338656107, "train/reward_pred": 6.253842320573989e-05, "train/reward_rate": 0.00011777638190954773, "train_stats/mean_log_entropy": 1.8963520739759718, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014437653124332428, "report/cont_loss_std": 0.25283345580101013, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.729815483093262, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032529612071812153, "report/cont_pred": 0.9967525005340576, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.20096629858016968, "report/image_loss_std": 0.0947146788239479, "report/model_loss_mean": 0.8156648278236389, "report/model_loss_std": 0.26751652359962463, "report/post_ent_mag": 49.75559997558594, "report/post_ent_max": 49.75559997558594, "report/post_ent_mean": 49.145145416259766, "report/post_ent_min": 48.79578399658203, "report/post_ent_std": 0.1932506412267685, "report/prior_ent_mag": 51.75252914428711, "report/prior_ent_max": 51.75252914428711, "report/prior_ent_mean": 49.726417541503906, "report/prior_ent_min": 47.85505676269531, "report/prior_ent_std": 0.6082198619842529, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0002608438953757286, "report/reward_loss_std": 9.89838081295602e-05, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.00024080276489257812, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002608438953757286, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00010380649473518133, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03680703788995743, "eval/cont_loss_std": 0.43706247210502625, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.729815483093262, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032529612071812153, "eval/cont_pred": 0.9967525005340576, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17249706387519836, "eval/image_loss_std": 0.09930714964866638, "eval/model_loss_mean": 0.8152083158493042, "eval/model_loss_std": 0.5475642681121826, "eval/post_ent_mag": 49.743873596191406, "eval/post_ent_max": 49.743873596191406, "eval/post_ent_mean": 49.13154602050781, "eval/post_ent_min": 48.789127349853516, "eval/post_ent_std": 0.19382469356060028, "eval/prior_ent_mag": 52.2542724609375, "eval/prior_ent_max": 52.2542724609375, "eval/prior_ent_mean": 49.779483795166016, "eval/prior_ent_min": 48.03339385986328, "eval/prior_ent_std": 0.6899639964103699, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 9.765625145519152e-05, "eval/reward_loss_mean": 0.0059041231870651245, "eval/reward_loss_std": 0.18025852739810944, "eval/reward_max_data": 0.10000000149011612, "eval/reward_max_pred": 0.0002180337905883789, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0059041231870651245, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00010678684338927269, "eval/reward_rate": 0.0, "replay/size": 222041.0, "replay/inserts": 31792.0, "replay/samples": 31792.0, "replay/insert_wait_avg": 1.4813719050153512e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.872717669697701e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54224.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3248455703189767e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4416055679321, "timer/env.step_count": 7948.0, "timer/env.step_total": 36.670782804489136, "timer/env.step_frac": 0.036654595930835775, "timer/env.step_avg": 0.004613837796236681, "timer/env.step_min": 0.003385782241821289, "timer/env.step_max": 0.032761335372924805, "timer/replay._sample_count": 31792.0, "timer/replay._sample_total": 15.885869264602661, "timer/replay._sample_frac": 0.015878857072906868, "timer/replay._sample_avg": 0.0004996813432499578, "timer/replay._sample_min": 0.0003833770751953125, "timer/replay._sample_max": 0.04975104331970215, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9682.0, "timer/agent.policy_total": 88.01101803779602, "timer/agent.policy_frac": 0.08797216903812571, "timer/agent.policy_avg": 0.009090169183825245, "timer/agent.policy_min": 0.007998466491699219, "timer/agent.policy_max": 0.04297614097595215, "timer/dataset_train_count": 1987.0, "timer/dataset_train_total": 0.21114087104797363, "timer/dataset_train_frac": 0.0002110476712212632, "timer/dataset_train_avg": 0.00010626113288775724, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.005675077438354492, "timer/agent.train_count": 1987.0, "timer/agent.train_total": 860.4578948020935, "timer/agent.train_frac": 0.8600780795333153, "timer/agent.train_avg": 0.43304373165681603, "timer/agent.train_min": 0.4241459369659424, "timer/agent.train_max": 1.1996080875396729, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4805724620819092, "timer/agent.report_frac": 0.0004803603322845586, "timer/agent.report_avg": 0.2402862310409546, "timer/agent.report_min": 0.23452401161193848, "timer/agent.report_max": 0.2460484504699707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.1457672119140625e-05, "timer/dataset_eval_frac": 2.144820047438901e-08, "timer/dataset_eval_avg": 2.1457672119140625e-05, "timer/dataset_eval_min": 2.1457672119140625e-05, "timer/dataset_eval_max": 2.1457672119140625e-05, "fps": 31.77733034730094}
{"step": 222752, "time": 7207.737386226654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222868, "time": 7211.186458110809, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 223056, "time": 7217.032386302948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223528, "time": 7231.203327655792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223908, "time": 7242.874686956406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224024, "time": 7246.298075437546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224212, "time": 7252.123973846436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224464, "time": 7259.891268968582, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 224588, "time": 7263.845428228378, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 224684, "time": 7266.76220536232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225180, "time": 7281.850230693817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225620, "time": 7295.2699155807495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225696, "time": 7297.686533689499, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 225744, "time": 7299.188066244125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225840, "time": 7302.130900144577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226776, "time": 7330.485523223877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226852, "time": 7332.918251514435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226900, "time": 7334.393769741058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226996, "time": 7337.344947338104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227932, "time": 7366.025954723358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228008, "time": 7368.022255420685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228056, "time": 7369.484938383102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228152, "time": 7372.413220405579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229088, "time": 7401.08849978447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229164, "time": 7403.518495559692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229212, "time": 7404.970849990845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229308, "time": 7407.898676395416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230060, "time": 7434.7694392204285, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230060, "time": 7434.776427745819, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230060, "time": 7434.781841754913, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230060, "time": 7434.787762880325, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230060, "time": 7438.747357845306, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230060, "time": 7438.753725528717, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230060, "time": 7438.759274959564, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230060, "time": 7438.765000581741, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230244, "time": 7444.160161495209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230320, "time": 7446.580954313278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230368, "time": 7448.062893867493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230464, "time": 7450.980711698532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231400, "time": 7479.231317996979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231476, "time": 7481.664009094238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231524, "time": 7483.121870279312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231620, "time": 7486.036502838135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232556, "time": 7514.778932571411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232632, "time": 7516.781388282776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232680, "time": 7518.246581792831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232776, "time": 7521.17825293541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233712, "time": 7549.889321804047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233788, "time": 7552.51678276062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233836, "time": 7553.98833823204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233932, "time": 7556.919845581055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234868, "time": 7585.316252946854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234944, "time": 7587.749264717102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234992, "time": 7589.229127645493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235088, "time": 7592.167456865311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235580, "time": 7607.3215935230255, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 236024, "time": 7620.614538669586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236100, "time": 7623.12318277359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236244, "time": 7627.537503480911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236736, "time": 7642.706731796265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237180, "time": 7656.3718848228455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237256, "time": 7658.376038789749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237400, "time": 7662.757595300674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237892, "time": 7677.969266653061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238336, "time": 7691.653547525406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238412, "time": 7694.089685916901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238556, "time": 7698.472672700882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239048, "time": 7713.1595005989075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239492, "time": 7726.715358018875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239568, "time": 7729.145581245422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239712, "time": 7733.520796060562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240060, "time": 7748.434470176697, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240060, "time": 7748.440618276596, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240060, "time": 7748.446190595627, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240060, "time": 7748.451809167862, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240060, "time": 7752.273313522339, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240060, "time": 7752.279915571213, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240060, "time": 7752.285698413849, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240060, "time": 7752.292134046555, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240204, "time": 7756.660938262939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240648, "time": 7769.8713302612305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240724, "time": 7772.3345601558685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240868, "time": 7776.703323602676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241060, "time": 7782.4883551597595, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 241360, "time": 7791.691946029663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241804, "time": 7805.296605587006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241880, "time": 7807.294173717499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242216, "time": 7817.648323297501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242516, "time": 7826.8539481163025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242960, "time": 7840.429416418076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243036, "time": 7842.873711109161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243372, "time": 7853.044813156128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243672, "time": 7861.909049034119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244116, "time": 7875.436145544052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244192, "time": 7877.857878923416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244528, "time": 7888.05934548378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244828, "time": 7897.2999448776245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245272, "time": 7910.451289653778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245348, "time": 7912.863185167313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245684, "time": 7923.08590722084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245984, "time": 7932.246840715408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246428, "time": 7945.99103975296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246504, "time": 7947.980417013168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246840, "time": 7958.279270648956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247140, "time": 7967.491726636887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247584, "time": 7981.155237913132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247660, "time": 7983.610730171204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247664, "time": 7983.631645441055, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 247996, "time": 7993.837680578232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248740, "time": 8016.238482952118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248816, "time": 8018.6673102378845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248820, "time": 8018.688115596771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249152, "time": 8028.881510257721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249896, "time": 8051.408230304718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249972, "time": 8053.832222938538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249976, "time": 8053.895864248276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250060, "time": 8060.684860229492, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250060, "time": 8060.691086292267, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250060, "time": 8060.696580171585, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250060, "time": 8060.70280122757, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250060, "time": 8063.287931203842, "eval_episode/length": 189.0, "eval_episode/score": 0.40937501192092896, "eval_episode/reward_rate": 0.005263157894736842}
{"step": 250060, "time": 8064.6232171058655, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250060, "time": 8064.630556106567, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250060, "time": 8064.6364459991455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250308, "time": 8072.151411056519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250360, "time": 8073.64568400383, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 251052, "time": 8094.954449415207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251132, "time": 8097.382470846176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251464, "time": 8107.218621492386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251516, "time": 8109.138251066208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252208, "time": 8130.043342351913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252288, "time": 8132.506615638733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252620, "time": 8142.692393064499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252648, "time": 8143.217003107071, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 252672, "time": 8144.1604697704315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253364, "time": 8165.177363157272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253776, "time": 8177.886715888977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253804, "time": 8178.841142177582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253828, "time": 8179.364033699036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253912, "time": 8181.830723285675, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 254520, "time": 8200.589379310608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254537, "time": 8202.059759616852, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.1904202270507813, "train/action_min": 0.0, "train/action_std": 1.898682909011841, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.001108824034454301, "train/actor_opt_grad_steps": 14815.0, "train/actor_opt_loss": 3.0320304778032003, "train/adv_mag": 0.004567188210785389, "train/adv_max": 0.0044762818049639466, "train/adv_mean": 0.0006673839470533949, "train/adv_min": -0.00183473558165133, "train/adv_std": 0.0007922529139614198, "train/cont_avg": 0.996611328125, "train/cont_loss_mean": 0.022693779597757383, "train/cont_loss_std": 0.31595972949475454, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.644477163042341, "train/cont_pos_acc": 0.9999999853968621, "train/cont_pos_loss": 0.0035684520564973356, "train/cont_pred": 0.9964380067586899, "train/cont_rate": 0.996611328125, "train/dyn_loss_mean": 1.0000027847290038, "train/dyn_loss_std": 6.309753145615104e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.037416569799825085, "train/extr_critic_critic_opt_grad_steps": 14815.0, "train/extr_critic_critic_opt_loss": 9807.024265136719, "train/extr_critic_mag": 0.03498662650585174, "train/extr_critic_max": 0.03498662650585174, "train/extr_critic_mean": 0.033618506090715525, "train/extr_critic_min": 0.031765606999397275, "train/extr_critic_std": 0.0003994274455908453, "train/extr_return_normed_mag": 0.006558390194550156, "train/extr_return_normed_max": 0.0065582491271197795, "train/extr_return_normed_mean": 0.0025508204990433115, "train/extr_return_normed_min": 0.00016635031439363957, "train/extr_return_normed_std": 0.0008701730892425985, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.038293321002274755, "train/extr_return_raw_max": 0.038293321002274755, "train/extr_return_raw_mean": 0.034285894157364966, "train/extr_return_raw_min": 0.03190142218954861, "train/extr_return_raw_std": 0.0008701730926622985, "train/extr_reward_mag": 0.00142406165599823, "train/extr_reward_max": 0.00142406165599823, "train/extr_reward_mean": 0.0001787953658413244, "train/extr_reward_min": 1.707911491394043e-05, "train/extr_reward_std": 0.00024684544741830904, "train/image_loss_mean": 0.18535531491041182, "train/image_loss_std": 0.10327489838004113, "train/model_loss_mean": 0.8093979293107987, "train/model_loss_std": 0.36292313288897277, "train/model_opt_grad_norm": 37.37759065628052, "train/model_opt_grad_steps": 14799.72, "train/model_opt_loss": 2456.718095703125, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3050.0, "train/policy_entropy_mag": 1.9135374319553375, "train/policy_entropy_max": 1.9135374319553375, "train/policy_entropy_mean": 1.669312208890915, "train/policy_entropy_min": 0.927880729213357, "train/policy_entropy_std": 0.12844923710916192, "train/policy_logprob_mag": 4.551873817443847, "train/policy_logprob_max": -0.3787344636861235, "train/policy_logprob_mean": -1.6699470469355584, "train/policy_logprob_min": -4.551873817443847, "train/policy_logprob_std": 0.6185095741599799, "train/policy_randomness_mag": 0.9833637708425522, "train/policy_randomness_max": 0.9833637708425522, "train/policy_randomness_mean": 0.8578568254411221, "train/policy_randomness_min": 0.47683639779686926, "train/policy_randomness_std": 0.0660098538850434, "train/post_ent_mag": 49.072685871124264, "train/post_ent_max": 49.072685871124264, "train/post_ent_mean": 48.449749870300295, "train/post_ent_min": 48.11834348678589, "train/post_ent_std": 0.1890610432624817, "train/prior_ent_mag": 50.07658477783203, "train/prior_ent_max": 50.07658477783203, "train/prior_ent_mean": 47.65044521331787, "train/prior_ent_min": 45.91997295379639, "train/prior_ent_std": 0.692265792787075, "train/rep_loss_mean": 1.0000027847290038, "train/rep_loss_std": 6.309753145615104e-05, "train/reward_avg": 5.526733395527117e-05, "train/reward_loss_mean": 0.0013471452984958887, "train/reward_loss_std": 0.037772053801490985, "train/reward_max_data": 0.05659374997019768, "train/reward_max_pred": 0.0010220307111740113, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00017730225570630864, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.214923785283016, "train/reward_pred": 6.872782192658633e-05, "train/reward_rate": 0.000126953125, "train_stats/mean_log_entropy": 1.3196338511939742, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02006206288933754, "report/cont_loss_std": 0.30549365282058716, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.655847072601318, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003502458333969116, "report/cont_pred": 0.9965035915374756, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1594245433807373, "report/image_loss_std": 0.10596916824579239, "report/model_loss_mean": 0.7796403169631958, "report/model_loss_std": 0.32599642872810364, "report/post_ent_mag": 46.742393493652344, "report/post_ent_max": 46.742393493652344, "report/post_ent_mean": 46.22167205810547, "report/post_ent_min": 45.999576568603516, "report/post_ent_std": 0.1350950300693512, "report/prior_ent_mag": 46.58415222167969, "report/prior_ent_max": 46.58415222167969, "report/prior_ent_mean": 44.817893981933594, "report/prior_ent_min": 43.54573059082031, "report/prior_ent_std": 0.5275898575782776, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001536766067147255, "report/reward_loss_std": 0.0005074584041722119, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0018672943115234375, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001536766067147255, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.411178037524223e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020066037774086, "eval/cont_loss_std": 0.305563747882843, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.657144546508789, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0035026317927986383, "eval/cont_pred": 0.996503472328186, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16887208819389343, "eval/image_loss_std": 0.09852512925863266, "eval/model_loss_mean": 0.7890541553497314, "eval/model_loss_std": 0.32035765051841736, "eval/post_ent_mag": 46.880348205566406, "eval/post_ent_max": 46.880348205566406, "eval/post_ent_mean": 46.237789154052734, "eval/post_ent_min": 45.99421691894531, "eval/post_ent_std": 0.1545056402683258, "eval/prior_ent_mag": 46.63574981689453, "eval/prior_ent_max": 46.63574981689453, "eval/prior_ent_mean": 44.91011047363281, "eval/prior_ent_min": 43.55693817138672, "eval/prior_ent_std": 0.5481793284416199, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00011601066216826439, "eval/reward_loss_std": 0.0004284254682715982, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0017879009246826172, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00011601066216826439, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.846276715397835e-05, "eval/reward_rate": 0.0, "replay/size": 254025.0, "replay/inserts": 31984.0, "replay/samples": 31984.0, "replay/insert_wait_avg": 1.4982636777563892e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.739285936112283e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61160.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3148770887821466e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3137373924255, "timer/env.step_count": 7996.0, "timer/env.step_total": 36.23760747909546, "timer/env.step_frac": 0.03622624195240794, "timer/env.step_avg": 0.004531966918346105, "timer/env.step_min": 0.0034134387969970703, "timer/env.step_max": 0.03043961524963379, "timer/replay._sample_count": 31984.0, "timer/replay._sample_total": 15.673800230026245, "timer/replay._sample_frac": 0.015668884315119, "timer/replay._sample_avg": 0.000490051282829735, "timer/replay._sample_min": 0.0003795623779296875, "timer/replay._sample_max": 0.010263919830322266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9730.0, "timer/agent.policy_total": 87.78815388679504, "timer/agent.policy_frac": 0.08776062009868764, "timer/agent.policy_avg": 0.0090224207488998, "timer/agent.policy_min": 0.007954835891723633, "timer/agent.policy_max": 0.0383601188659668, "timer/dataset_train_count": 1999.0, "timer/dataset_train_total": 0.2332754135131836, "timer/dataset_train_frac": 0.00023320224924759688, "timer/dataset_train_avg": 0.0001166960547839838, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.019909143447875977, "timer/agent.train_count": 1999.0, "timer/agent.train_total": 861.0824491977692, "timer/agent.train_frac": 0.8608123801662482, "timer/agent.train_avg": 0.43075660290033474, "timer/agent.train_min": 0.4194667339324951, "timer/agent.train_max": 0.5111889839172363, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48259639739990234, "timer/agent.report_frac": 0.00048244503635220854, "timer/agent.report_avg": 0.24129819869995117, "timer/agent.report_min": 0.23428058624267578, "timer/agent.report_max": 0.24831581115722656, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.384185791015625e-05, "timer/dataset_eval_frac": 2.3834380173870422e-08, "timer/dataset_eval_avg": 2.384185791015625e-05, "timer/dataset_eval_min": 2.384185791015625e-05, "timer/dataset_eval_max": 2.384185791015625e-05, "fps": 31.973398598348876}
{"step": 254960, "time": 8214.911800861359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254984, "time": 8215.433900117874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255068, "time": 8218.312365055084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255676, "time": 8236.830969572067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256116, "time": 8249.9833714962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256140, "time": 8250.935335159302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256224, "time": 8253.41710615158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256832, "time": 8271.98181605339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257272, "time": 8285.16102528572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257296, "time": 8286.105052947998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257380, "time": 8288.544304847717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257988, "time": 8306.99243736267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258428, "time": 8320.782800674438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258436, "time": 8320.819363117218, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 258452, "time": 8321.312122821808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259144, "time": 8342.283058643341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259584, "time": 8355.89464187622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259592, "time": 8355.929227590561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259608, "time": 8356.420150518417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260060, "time": 8374.697081804276, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260060, "time": 8374.703074216843, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260060, "time": 8374.708334684372, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260060, "time": 8374.71383523941, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260060, "time": 8378.49051451683, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260060, "time": 8378.496602773666, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260060, "time": 8378.502063035965, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260060, "time": 8378.507813215256, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260300, "time": 8385.744094133377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260740, "time": 8398.886395215988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260748, "time": 8399.367630958557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260764, "time": 8399.862190485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261456, "time": 8420.785691738129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261896, "time": 8433.912054300308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261904, "time": 8434.375294208527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261920, "time": 8434.863445997238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262612, "time": 8455.933981180191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263052, "time": 8469.598731517792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263060, "time": 8469.634551048279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263076, "time": 8470.1272585392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263300, "time": 8476.91895198822, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 264208, "time": 8504.810361623764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264216, "time": 8504.845008850098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264232, "time": 8505.337120771408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264416, "time": 8511.090630054474, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 264456, "time": 8512.103905677795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265364, "time": 8539.920642375946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265388, "time": 8540.890242815018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265572, "time": 8546.261358261108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265612, "time": 8547.701366186142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266520, "time": 8575.35737657547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266544, "time": 8576.307942152023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266728, "time": 8581.727489709854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266768, "time": 8583.155919790268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267676, "time": 8610.851533412933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267700, "time": 8611.44109416008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267884, "time": 8617.234987258911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267924, "time": 8618.243875741959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268832, "time": 8645.828680753708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268856, "time": 8646.342784166336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269040, "time": 8652.1255941391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269080, "time": 8653.126808643341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269988, "time": 8680.734780550003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270012, "time": 8681.680906534195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270060, "time": 8686.992225646973, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270060, "time": 8686.99826669693, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270060, "time": 8687.003958463669, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270060, "time": 8687.010367393494, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270060, "time": 8691.158638477325, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270060, "time": 8691.164856433868, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270060, "time": 8691.170242071152, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270060, "time": 8691.17581820488, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270196, "time": 8695.10795879364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270236, "time": 8696.537791013718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271144, "time": 8724.763649702072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271168, "time": 8725.727857589722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271352, "time": 8731.147514104843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271392, "time": 8732.586166620255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272300, "time": 8760.14688372612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272324, "time": 8760.669074058533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272508, "time": 8766.527908563614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272548, "time": 8767.539204835892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273456, "time": 8795.343412399292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273480, "time": 8795.858841180801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273664, "time": 8801.647488832474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273704, "time": 8802.65374302864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274612, "time": 8830.252925395966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274636, "time": 8831.199872255325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274768, "time": 8835.290368318558, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 274860, "time": 8838.19806098938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275768, "time": 8865.436874389648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275792, "time": 8866.404226064682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275900, "time": 8869.769296646118, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 275924, "time": 8870.288120985031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276016, "time": 8873.192499876022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276924, "time": 8900.794392347336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277056, "time": 8904.664002418518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277080, "time": 8905.195608377457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277172, "time": 8908.102148532867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278080, "time": 8935.748976945877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278212, "time": 8939.650022506714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278236, "time": 8940.591479301453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278328, "time": 8943.113991260529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279236, "time": 8970.96909737587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279368, "time": 8974.905025720596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279392, "time": 8975.85962152481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279484, "time": 8978.7779276371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280060, "time": 9000.303997039795, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280060, "time": 9000.310713529587, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280060, "time": 9000.316999912262, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280060, "time": 9000.324627399445, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280060, "time": 9004.430980443954, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280060, "time": 9004.437638998032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280060, "time": 9004.443846702576, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280060, "time": 9004.449580430984, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280392, "time": 9014.237340211868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280524, "time": 9018.571774721146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280548, "time": 9019.094408512115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280640, "time": 9022.00208735466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281548, "time": 9049.603013277054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281680, "time": 9053.49860072136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281704, "time": 9054.018685102463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281796, "time": 9056.942191123962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282704, "time": 9084.702636003494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282836, "time": 9088.619202375412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282860, "time": 9089.563935756683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282952, "time": 9092.214432001114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283860, "time": 9119.924103975296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283992, "time": 9123.9220328331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284016, "time": 9124.888982534409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284108, "time": 9127.819690227509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284804, "time": 9148.794646263123, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 285016, "time": 9155.135972499847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285148, "time": 9159.478485584259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285172, "time": 9160.005656003952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285660, "time": 9175.099782943726, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 285960, "time": 9183.910367965698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286172, "time": 9190.662358283997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286304, "time": 9194.558333396912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286537, "time": 9202.410650730133, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0927239990234376, "train/action_min": 0.0, "train/action_std": 1.949807733297348, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0009062534922486521, "train/actor_opt_grad_steps": 16815.0, "train/actor_opt_loss": -8.485682706385852, "train/adv_mag": 0.002670037355273962, "train/adv_max": 0.002078362554311752, "train/adv_mean": -9.650248053048927e-05, "train/adv_min": -0.001348918043076992, "train/adv_std": 0.0005002747590333456, "train/cont_avg": 0.9963916015625, "train/cont_loss_mean": 0.02393354486208409, "train/cont_loss_std": 0.3288502020273984, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.657234854168362, "train/cont_pos_acc": 0.9999950775504112, "train/cont_pos_loss": 0.0035349735268391668, "train/cont_pred": 0.9964791920781135, "train/cont_rate": 0.9963916015625, "train/dyn_loss_mean": 1.0514261800050735, "train/dyn_loss_std": 0.02366800929803958, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03832955118065001, "train/extr_critic_critic_opt_grad_steps": 16815.0, "train/extr_critic_critic_opt_loss": 11791.999677734375, "train/extr_critic_mag": 0.04784974038600922, "train/extr_critic_max": 0.04784974038600922, "train/extr_critic_mean": 0.04728965619578958, "train/extr_critic_min": 0.046538578271865846, "train/extr_critic_std": 0.00016542913450393827, "train/extr_return_normed_mag": 0.003305664137005806, "train/extr_return_normed_max": 0.0026276013255119323, "train/extr_return_normed_mean": 0.0004597033874011913, "train/extr_return_normed_min": -0.0006241281516849995, "train/extr_return_normed_std": 0.0005008495224683429, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0493610230088234, "train/extr_return_raw_max": 0.0493610230088234, "train/extr_return_raw_mean": 0.047193127293139694, "train/extr_return_raw_min": 0.04610929353162646, "train/extr_return_raw_std": 0.0005008495219954057, "train/extr_reward_mag": 0.0009713780879974365, "train/extr_reward_max": 0.0009713780879974365, "train/extr_reward_mean": 0.000122335891937837, "train/extr_reward_min": 2.9004216194152833e-05, "train/extr_reward_std": 0.00014451593969852183, "train/image_loss_mean": 0.5538624618202448, "train/image_loss_std": 0.981229903884232, "train/model_loss_mean": 1.211054377257824, "train/model_loss_std": 1.2762894701585175, "train/model_opt_grad_norm": 35.68770396649538, "train/model_opt_grad_steps": 16797.3, "train/model_opt_loss": 1395.032163696289, "train/model_opt_model_opt_grad_overflow": 0.005, "train/model_opt_model_opt_grad_scale": 1121.875, "train/policy_entropy_mag": 1.9245337843894958, "train/policy_entropy_max": 1.9245337843894958, "train/policy_entropy_mean": 1.836660952270031, "train/policy_entropy_min": 1.5759053188562393, "train/policy_entropy_std": 0.04311424947460182, "train/policy_logprob_mag": 3.0392226326465606, "train/policy_logprob_max": -0.9991272648237646, "train/policy_logprob_mean": -1.8368134227395059, "train/policy_logprob_min": -3.0392226326465606, "train/policy_logprob_std": 0.3171401286497712, "train/policy_randomness_mag": 0.9890147817134857, "train/policy_randomness_max": 0.9890147817134857, "train/policy_randomness_mean": 0.9438570682704449, "train/policy_randomness_min": 0.8098551798611879, "train/policy_randomness_std": 0.022156342442613094, "train/post_ent_mag": 93.40700592041016, "train/post_ent_max": 93.40700592041016, "train/post_ent_mean": 93.27772354125976, "train/post_ent_min": 92.94180500030518, "train/post_ent_std": 0.08181886542588472, "train/prior_ent_mag": 93.17809284210205, "train/prior_ent_max": 93.17809284210205, "train/prior_ent_mean": 92.57819339752197, "train/prior_ent_min": 90.95841836929321, "train/prior_ent_std": 0.352272862046957, "train/rep_loss_mean": 1.0514261800050735, "train/rep_loss_std": 0.02366800929803958, "train/reward_avg": 0.00012359619227936492, "train/reward_loss_mean": 0.00240264825290069, "train/reward_loss_std": 0.06495825024704573, "train/reward_max_data": 0.11178124994039536, "train/reward_max_pred": 0.0007413870096206665, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00019265425149569637, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.468811279389916, "train/reward_pred": 8.017831132747232e-05, "train/reward_rate": 0.000234375, "train_stats/mean_log_entropy": 1.673706761577673, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.009219909086823463, "report/cont_loss_std": 0.17423127591609955, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.581897735595703, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003772520460188389, "report/cont_pred": 0.996234655380249, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.21819952130317688, "report/image_loss_std": 0.09729389101266861, "report/model_loss_mean": 0.8278432488441467, "report/model_loss_std": 0.2010456621646881, "report/post_ent_mag": 103.81060791015625, "report/post_ent_max": 103.81060791015625, "report/post_ent_mean": 103.74565124511719, "report/post_ent_min": 103.33467864990234, "report/post_ent_std": 0.0723470151424408, "report/prior_ent_mag": 103.33551025390625, "report/prior_ent_max": 103.33551025390625, "report/prior_ent_mean": 103.00052642822266, "report/prior_ent_min": 101.82337951660156, "report/prior_ent_std": 0.2315707951784134, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0004237932153046131, "report/reward_loss_std": 0.000690923014190048, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0011968612670898438, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0004237932153046131, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00018066680058836937, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02556207962334156, "eval/cont_loss_std": 0.3479512631893158, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.581897735595703, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.003772520227357745, "eval/cont_pred": 0.996234655380249, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 2.3171305656433105e-06, "eval/image_loss_mean": 0.22605347633361816, "eval/image_loss_std": 0.10299128293991089, "eval/model_loss_mean": 0.8519636392593384, "eval/model_loss_std": 0.36811351776123047, "eval/post_ent_mag": 103.80760192871094, "eval/post_ent_max": 103.80760192871094, "eval/post_ent_mean": 103.73716735839844, "eval/post_ent_min": 103.33500671386719, "eval/post_ent_std": 0.07800532877445221, "eval/prior_ent_mag": 103.31510925292969, "eval/prior_ent_max": 103.31510925292969, "eval/prior_ent_mean": 102.97901153564453, "eval/prior_ent_min": 101.82337951660156, "eval/prior_ent_std": 0.23695190250873566, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 2.3171305656433105e-06, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00034804176539182663, "eval/reward_loss_std": 0.0006240828079171479, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0013880729675292969, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00034804176539182663, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00014828972052782774, "eval/reward_rate": 0.0, "replay/size": 286025.0, "replay/inserts": 32000.0, "replay/samples": 32000.0, "replay/insert_wait_avg": 1.4700070023536681e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.599443197250367e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68096.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3229549962344055e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.319785118103, "timer/env.step_count": 8000.0, "timer/env.step_total": 36.550681352615356, "timer/env.step_frac": 0.03653899672523221, "timer/env.step_avg": 0.004568835169076919, "timer/env.step_min": 0.0034096240997314453, "timer/env.step_max": 0.030249834060668945, "timer/replay._sample_count": 32000.0, "timer/replay._sample_total": 15.537336587905884, "timer/replay._sample_frac": 0.015532369567269395, "timer/replay._sample_avg": 0.0004855417683720589, "timer/replay._sample_min": 0.00037097930908203125, "timer/replay._sample_max": 0.010699987411499023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9734.0, "timer/agent.policy_total": 87.67147064208984, "timer/agent.policy_frac": 0.08764344357313585, "timer/agent.policy_avg": 0.00900672597514792, "timer/agent.policy_min": 0.008014440536499023, "timer/agent.policy_max": 0.03659486770629883, "timer/dataset_train_count": 2000.0, "timer/dataset_train_total": 0.21756815910339355, "timer/dataset_train_frac": 0.00021749860628589518, "timer/dataset_train_avg": 0.00010878407955169678, "timer/dataset_train_min": 8.511543273925781e-05, "timer/dataset_train_max": 0.005400180816650391, "timer/agent.train_count": 2000.0, "timer/agent.train_total": 860.8245418071747, "timer/agent.train_frac": 0.8605493509313537, "timer/agent.train_avg": 0.43041227090358736, "timer/agent.train_min": 0.4220099449157715, "timer/agent.train_max": 1.339996337890625, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4790151119232178, "timer/agent.report_frac": 0.00047886197898871184, "timer/agent.report_avg": 0.2395075559616089, "timer/agent.report_min": 0.23279333114624023, "timer/agent.report_max": 0.24622178077697754, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.4557113647460938e-05, "timer/dataset_eval_frac": 2.4549263158442474e-08, "timer/dataset_eval_avg": 2.4557113647460938e-05, "timer/dataset_eval_min": 2.4557113647460938e-05, "timer/dataset_eval_max": 2.4557113647460938e-05, "fps": 31.988859737495027}
{"step": 286816, "time": 9210.822067975998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287116, "time": 9220.274407148361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287328, "time": 9226.648419380188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287460, "time": 9230.530972242355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287972, "time": 9246.13695859909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288196, "time": 9252.969367980957, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 288272, "time": 9255.41214632988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288484, "time": 9261.751311540604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288488, "time": 9261.772834539413, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 289352, "time": 9288.06202340126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289428, "time": 9290.476084470749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289640, "time": 9296.799645662308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289644, "time": 9297.252876996994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290060, "time": 9313.901087999344, "eval_episode/length": 279.0, "eval_episode/score": 0.12812499701976776, "eval_episode/reward_rate": 0.0035714285714285713}
{"step": 290060, "time": 9314.0425760746, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290060, "time": 9314.049342393875, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290060, "time": 9314.055269002914, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290060, "time": 9315.513995885849, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 290060, "time": 9317.502103328705, "eval_episode/length": 224.0, "eval_episode/score": 0.30000001192092896, "eval_episode/reward_rate": 0.0044444444444444444}
{"step": 290060, "time": 9318.419336080551, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290060, "time": 9318.425826787949, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290508, "time": 9332.167124509811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290584, "time": 9334.145370960236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290768, "time": 9339.959359884262, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 290796, "time": 9340.926070928574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291588, "time": 9365.113396406174, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 291664, "time": 9367.5576877594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291740, "time": 9369.979808568954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291952, "time": 9376.349405527115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292744, "time": 9400.29908490181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292820, "time": 9402.733382940292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292896, "time": 9405.155038833618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293048, "time": 9409.553580284119, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 293108, "time": 9411.501299619675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293460, "time": 9422.209821462631, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 293748, "time": 9430.97976899147, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 293900, "time": 9435.83506822586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293976, "time": 9437.82450389862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294204, "time": 9445.156150579453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294904, "time": 9466.272330760956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295056, "time": 9471.13379240036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295132, "time": 9473.573440790176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295360, "time": 9480.637193918228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295528, "time": 9485.617484807968, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 296060, "time": 9502.270694255829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296212, "time": 9506.721650838852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296288, "time": 9509.205567598343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296684, "time": 9521.478809595108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297216, "time": 9537.689161777496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297368, "time": 9542.187721252441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297444, "time": 9544.648657560349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297840, "time": 9556.841185331345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298372, "time": 9573.015362739563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298524, "time": 9577.922104597092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298600, "time": 9579.926849842072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298996, "time": 9592.151074409485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299528, "time": 9608.443697214127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299680, "time": 9613.297068119049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299756, "time": 9615.708113908768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300060, "time": 9628.930605888367, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300060, "time": 9628.9365940094, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300060, "time": 9628.94200348854, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300060, "time": 9628.947511911392, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300060, "time": 9632.858811378479, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300060, "time": 9632.864994049072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300060, "time": 9632.870216608047, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300060, "time": 9632.87571644783, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300152, "time": 9635.367985486984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300684, "time": 9651.8938434124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300836, "time": 9656.30870604515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300912, "time": 9658.740027666092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301308, "time": 9670.932451248169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301840, "time": 9686.98661661148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301992, "time": 9691.470234632492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302068, "time": 9693.90780711174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302464, "time": 9706.08032464981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302996, "time": 9722.21908903122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303148, "time": 9727.103930711746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303224, "time": 9729.098930597305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303620, "time": 9741.4231569767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303628, "time": 9741.900549650192, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 304152, "time": 9757.570949077606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304304, "time": 9762.42807340622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304776, "time": 9776.579342126846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304784, "time": 9777.04738688469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304876, "time": 9779.96477508545, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 305460, "time": 9797.602301597595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305820, "time": 9808.741348028183, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 305932, "time": 9812.171679973602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305940, "time": 9812.20639538765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306032, "time": 9815.144617795944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306976, "time": 9843.92038846016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307088, "time": 9847.344190597534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307096, "time": 9847.377380132675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307188, "time": 9850.29371213913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307536, "time": 9861.212718486786, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 308132, "time": 9879.416673898697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308244, "time": 9882.83739900589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308252, "time": 9883.305705308914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308440, "time": 9888.761570215225, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 308540, "time": 9892.13635802269, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 308692, "time": 9896.54671907425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308720, "time": 9897.506365776062, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 309596, "time": 9924.258612394333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309696, "time": 9927.177558898926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309848, "time": 9931.667795658112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309876, "time": 9932.654018640518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309952, "time": 9935.074112415314, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 310060, "time": 9940.594691514969, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 310060, "time": 9940.713000774384, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 310060, "time": 9942.17073059082, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 310060, "time": 9942.665055513382, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310060, "time": 9942.671196937561, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310060, "time": 9944.684481620789, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310060, "time": 9945.918323278427, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310060, "time": 9946.401796340942, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310060, "time": 9946.407676935196, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310196, "time": 9950.32504081726, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 310424, "time": 9957.160022735596, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 310852, "time": 9970.384804010391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310924, "time": 9972.78873515129, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 311004, "time": 9975.250235080719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311580, "time": 9992.944483041763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312008, "time": 10005.659081220627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312080, "time": 10008.073385238647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312160, "time": 10010.531328439713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312736, "time": 10028.141272306442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313152, "time": 10040.83667588234, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 313236, "time": 10043.311338186264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313316, "time": 10045.74988412857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313892, "time": 10063.43123459816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314212, "time": 10073.241982221603, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 314228, "time": 10073.73292851448, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 314308, "time": 10076.174396514893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314472, "time": 10081.197234153748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314664, "time": 10087.044168949127, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 314744, "time": 10089.509533643723, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 315080, "time": 10099.744329690933, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 315368, "time": 10108.517326116562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315820, "time": 10122.766014099121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315900, "time": 10125.19998049736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316236, "time": 10135.393246173859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316524, "time": 10144.155319213867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316880, "time": 10154.839120149612, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 316976, "time": 10157.782917261124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317056, "time": 10160.220481872559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317124, "time": 10162.217775344849, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 318036, "time": 10190.049187898636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318132, "time": 10192.971122026443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318212, "time": 10195.425618886948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318280, "time": 10197.39571595192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318425, "time": 10202.842433691025, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.015072616500471, "train/action_min": 0.0, "train/action_std": 1.8331411447956334, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0016462217897045702, "train/actor_opt_grad_steps": 18810.0, "train/actor_opt_loss": 5.26357894958039, "train/adv_mag": 0.008569858799777438, "train/adv_max": 0.008287271175851775, "train/adv_mean": 0.0011302832267963037, "train/adv_min": -0.0026734380341654445, "train/adv_std": 0.0013960836994597436, "train/cont_avg": 0.9965746702261307, "train/cont_loss_mean": 0.02290394438908028, "train/cont_loss_std": 0.32024984061864264, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.644919412304657, "train/cont_pos_acc": 0.9999999850239586, "train/cont_pos_loss": 0.003569545032428437, "train/cont_pred": 0.9964369047227217, "train/cont_rate": 0.9965746702261307, "train/dyn_loss_mean": 1.0000373089133794, "train/dyn_loss_std": 0.0007687589729161045, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11220209960926361, "train/extr_critic_critic_opt_grad_steps": 18810.0, "train/extr_critic_critic_opt_loss": 12677.693707796796, "train/extr_critic_mag": 0.0638571642152029, "train/extr_critic_max": 0.0638571642152029, "train/extr_critic_mean": 0.061712329786027496, "train/extr_critic_min": 0.05949015773121436, "train/extr_critic_std": 0.0006565095101914312, "train/extr_return_normed_mag": 0.012482763197853337, "train/extr_return_normed_max": 0.01242466351419837, "train/extr_return_normed_mean": 0.004446150953374205, "train/extr_return_normed_min": 0.0007418546844367406, "train/extr_return_normed_std": 0.0015759837654847465, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.07082107178305262, "train/extr_return_raw_max": 0.07082107178305262, "train/extr_return_raw_mean": 0.06284256305676608, "train/extr_return_raw_min": 0.05913826297201104, "train/extr_return_raw_std": 0.0015759837574409743, "train/extr_reward_mag": 0.004277262256373113, "train/extr_reward_max": 0.004277262256373113, "train/extr_reward_mean": 0.0003555669426802053, "train/extr_reward_min": 4.384984922169441e-06, "train/extr_reward_std": 0.000696814719350785, "train/image_loss_mean": 0.18036164320893025, "train/image_loss_std": 0.10515232047243933, "train/model_loss_mean": 0.8046918011190903, "train/model_loss_std": 0.3653499260170376, "train/model_opt_grad_norm": 32.310729985261084, "train/model_opt_grad_steps": 18791.718592964826, "train/model_opt_loss": 1966.9547551600776, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2456.030150753769, "train/policy_entropy_mag": 1.835334900036529, "train/policy_entropy_max": 1.835334900036529, "train/policy_entropy_mean": 1.3935214928047142, "train/policy_entropy_min": 0.49364303516682667, "train/policy_entropy_std": 0.24700213719075123, "train/policy_logprob_mag": 5.308513422108176, "train/policy_logprob_max": -0.20771528363003203, "train/policy_logprob_mean": -1.394312489272362, "train/policy_logprob_min": -5.308513422108176, "train/policy_logprob_std": 0.8069894639541156, "train/policy_randomness_mag": 0.9431756207691365, "train/policy_randomness_max": 0.9431756207691365, "train/policy_randomness_mean": 0.7161284303245832, "train/policy_randomness_min": 0.253682352302961, "train/policy_randomness_std": 0.12693399589288812, "train/post_ent_mag": 85.35175461505526, "train/post_ent_max": 85.35175461505526, "train/post_ent_mean": 84.5954518917218, "train/post_ent_min": 83.9127128639413, "train/post_ent_std": 0.26929546697018436, "train/prior_ent_mag": 87.25906789961772, "train/prior_ent_max": 87.25906789961772, "train/prior_ent_mean": 84.185960204158, "train/prior_ent_min": 81.5852594040147, "train/prior_ent_std": 0.863415206122638, "train/rep_loss_mean": 1.0000373089133794, "train/rep_loss_std": 0.0007687589729161045, "train/reward_avg": 8.649203053794932e-05, "train/reward_loss_mean": 0.001403810285574677, "train/reward_loss_std": 0.03835412242765575, "train/reward_max_data": 0.08756281420513613, "train/reward_max_pred": 0.0028436842875264995, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001993851276084163, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.656249153998591, "train/reward_pred": 8.313179053553385e-05, "train/reward_rate": 0.000157035175879397, "train_stats/mean_log_entropy": 1.029826779450689, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.030903052538633347, "report/cont_loss_std": 0.380389541387558, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.4612884521484375, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004257389344274998, "report/cont_pred": 0.9957518577575684, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.16050273180007935, "report/image_loss_std": 0.10309239476919174, "report/model_loss_mean": 0.7917779684066772, "report/model_loss_std": 0.39144366979599, "report/post_ent_mag": 77.61084747314453, "report/post_ent_max": 77.61084747314453, "report/post_ent_mean": 76.86122131347656, "report/post_ent_min": 75.93911743164062, "report/post_ent_std": 0.35369449853897095, "report/prior_ent_mag": 77.98424530029297, "report/prior_ent_max": 77.98424530029297, "report/prior_ent_mean": 75.39384460449219, "report/prior_ent_min": 72.65000915527344, "report/prior_ent_std": 0.9765365123748779, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0003721187822520733, "report/reward_loss_std": 0.0012563435593619943, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.003841400146484375, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0003721187822520733, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00016677461098879576, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014915588311851025, "eval/cont_loss_std": 0.2409333735704422, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.4612884521484375, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004257322754710913, "eval/cont_pred": 0.9957519173622131, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19183465838432312, "eval/image_loss_std": 0.10705043375492096, "eval/model_loss_mean": 0.806887149810791, "eval/model_loss_std": 0.26686400175094604, "eval/post_ent_mag": 77.65290832519531, "eval/post_ent_max": 77.65290832519531, "eval/post_ent_mean": 76.80722045898438, "eval/post_ent_min": 76.0376205444336, "eval/post_ent_std": 0.32657498121261597, "eval/prior_ent_mag": 77.90632629394531, "eval/prior_ent_max": 77.90632629394531, "eval/prior_ent_mean": 75.46463775634766, "eval/prior_ent_min": 71.84568786621094, "eval/prior_ent_std": 0.9784896373748779, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00013687042519450188, "eval/reward_loss_std": 0.0007761918241158128, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.006272792816162109, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00013687042519450188, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.0720834881067276e-05, "eval/reward_rate": 0.0, "replay/size": 317913.0, "replay/inserts": 31888.0, "replay/samples": 31888.0, "replay/insert_wait_avg": 1.5060789789677384e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.763482551746972e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 75032.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3762004372707838e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4123759269714, "timer/env.step_count": 7972.0, "timer/env.step_total": 36.41841721534729, "timer/env.step_frac": 0.03640340532733052, "timer/env.step_avg": 0.004568291171016971, "timer/env.step_min": 0.003492593765258789, "timer/env.step_max": 0.021062374114990234, "timer/replay._sample_count": 31888.0, "timer/replay._sample_total": 15.638073444366455, "timer/replay._sample_frac": 0.01563162733755306, "timer/replay._sample_avg": 0.0004904062168955863, "timer/replay._sample_min": 0.0003559589385986328, "timer/replay._sample_max": 0.028576135635375977, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9706.0, "timer/agent.policy_total": 87.97711968421936, "timer/agent.policy_frac": 0.08794085499262312, "timer/agent.policy_avg": 0.009064199431714338, "timer/agent.policy_min": 0.007900238037109375, "timer/agent.policy_max": 0.042919158935546875, "timer/dataset_train_count": 1993.0, "timer/dataset_train_total": 0.21370148658752441, "timer/dataset_train_frac": 0.00021361339756469016, "timer/dataset_train_avg": 0.00010722603441421195, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.006360530853271484, "timer/agent.train_count": 1993.0, "timer/agent.train_total": 860.7787504196167, "timer/agent.train_frac": 0.8604239323029449, "timer/agent.train_avg": 0.4319010288106456, "timer/agent.train_min": 0.41942381858825684, "timer/agent.train_max": 0.5152318477630615, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4780709743499756, "timer/agent.report_frac": 0.00047787391065309457, "timer/agent.report_avg": 0.2390354871749878, "timer/agent.report_min": 0.2314305305480957, "timer/agent.report_max": 0.24664044380187988, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.6930194074731473e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 31.874251201562917}
{"step": 318612, "time": 10208.395648479462, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 319220, "time": 10226.899677276611, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 319368, "time": 10231.32631111145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319436, "time": 10233.745787858963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319768, "time": 10243.753712177277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320060, "time": 10256.695797204971, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320060, "time": 10256.702013492584, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320060, "time": 10256.707353115082, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320060, "time": 10256.713672161102, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320060, "time": 10260.587818145752, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320060, "time": 10260.594066143036, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320060, "time": 10260.600914478302, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320060, "time": 10260.60677742958, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320376, "time": 10269.89651966095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320524, "time": 10274.730063199997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320592, "time": 10276.702214956284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320924, "time": 10286.926785707474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320936, "time": 10286.97280573845, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 321532, "time": 10305.478581666946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321680, "time": 10309.88094329834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322080, "time": 10322.152835845947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322092, "time": 10322.636683940887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322688, "time": 10340.744505643845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322836, "time": 10345.151699781418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322988, "time": 10349.990108966827, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 323148, "time": 10354.864177942276, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 323224, "time": 10356.87125134468, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 323236, "time": 10357.351537942886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323248, "time": 10357.827103853226, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 323572, "time": 10367.61270403862, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 324144, "time": 10385.444765090942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324380, "time": 10392.717360973358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324392, "time": 10392.767543077469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324728, "time": 10402.985930681229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325300, "time": 10420.467936515808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325328, "time": 10421.426179409027, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 325536, "time": 10427.76261806488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325548, "time": 10428.26265001297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325636, "time": 10430.729082107544, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 325764, "time": 10434.653722286224, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 325968, "time": 10440.98364162445, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 326284, "time": 10450.747029781342, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 326484, "time": 10456.585609197617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326920, "time": 10469.817992687225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327124, "time": 10476.195909261703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327264, "time": 10480.586474895477, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 327440, "time": 10485.964201450348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327680, "time": 10493.311205148697, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 327688, "time": 10493.346060037613, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 327712, "time": 10494.291507482529, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 328280, "time": 10511.68088388443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328836, "time": 10528.758405923843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328844, "time": 10529.22497677803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328868, "time": 10529.748803377151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328908, "time": 10531.224868297577, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 329460, "time": 10547.763510465622, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 329484, "time": 10548.709728240967, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 329552, "time": 10550.683010339737, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 330000, "time": 10564.364450216293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330060, "time": 10567.2075548172, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 330060, "time": 10568.44537949562, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 330060, "time": 10569.580439805984, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 330060, "time": 10570.505894422531, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330060, "time": 10570.512039661407, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330060, "time": 10570.920605182648, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 330060, "time": 10571.113874435425, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 330060, "time": 10572.114423274994, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 330616, "time": 10588.723080158234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330640, "time": 10589.67413687706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330708, "time": 10591.687959909439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330980, "time": 10599.888929128647, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 331156, "time": 10605.249430418015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331796, "time": 10624.756136655807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331864, "time": 10626.727169513702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332136, "time": 10635.224507570267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332220, "time": 10638.096273422241, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 332312, "time": 10640.597992420197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332560, "time": 10648.336154460907, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 332572, "time": 10648.815187692642, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 332612, "time": 10649.83104133606, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 332620, "time": 10650.289960384369, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 332736, "time": 10653.7231965065, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 333020, "time": 10662.435346841812, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 333140, "time": 10665.850565195084, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 333672, "time": 10682.004572153091, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 333716, "time": 10683.478944301605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334048, "time": 10693.70660686493, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 334176, "time": 10697.61089682579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334296, "time": 10701.07505273819, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334872, "time": 10718.683449268341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335204, "time": 10728.912414312363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335304, "time": 10731.842295646667, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 335332, "time": 10732.814695119858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335452, "time": 10736.652908802032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335644, "time": 10742.5552110672, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 335824, "time": 10747.923047304153, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 335892, "time": 10749.895449876785, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 336340, "time": 10763.653526067734, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 336488, "time": 10768.031486988068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336608, "time": 10771.954130411148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336980, "time": 10783.166195631027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337496, "time": 10798.759562015533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337644, "time": 10803.626264333725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337764, "time": 10807.088276386261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338104, "time": 10817.324012756348, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 338136, "time": 10818.306868076324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338652, "time": 10834.382595539093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338920, "time": 10842.22596526146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339260, "time": 10852.937967777252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339292, "time": 10853.917209386826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339464, "time": 10858.869513511658, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 339808, "time": 10869.735444307327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340060, "time": 10880.447199821472, "eval_episode/length": 212.0, "eval_episode/score": 0.3375000059604645, "eval_episode/reward_rate": 0.004694835680751174}
{"step": 340060, "time": 10881.448068141937, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340060, "time": 10881.455388069153, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340060, "time": 10881.461159467697, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340060, "time": 10884.304248809814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340060, "time": 10885.351884126663, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340060, "time": 10885.3583381176, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340060, "time": 10885.364063739777, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340076, "time": 10885.860361099243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340416, "time": 10896.303019285202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340620, "time": 10902.654580116272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340836, "time": 10909.031881093979, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 341232, "time": 10921.247351884842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341572, "time": 10931.499014377594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341776, "time": 10937.813879489899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341992, "time": 10944.160471439362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342388, "time": 10956.330414533615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342728, "time": 10966.579411506653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342932, "time": 10972.895274162292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343148, "time": 10979.73808002472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343544, "time": 10991.499585866928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343884, "time": 11002.193389892578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344088, "time": 11008.107440948486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344252, "time": 11013.51866531372, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 344304, "time": 11015.01611995697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344448, "time": 11019.612416505814, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 344692, "time": 11026.954290866852, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 344884, "time": 11032.814144849777, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 345040, "time": 11037.685791015625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345460, "time": 11050.464913606644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345848, "time": 11062.143606185913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346040, "time": 11067.980653047562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346196, "time": 11072.893136262894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346396, "time": 11079.185137748718, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 346616, "time": 11085.556478738785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347004, "time": 11097.713047027588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347204, "time": 11103.65052652359, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 347476, "time": 11111.966839075089, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 347552, "time": 11114.385191440582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347624, "time": 11116.346746206284, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 347772, "time": 11121.180628538132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348160, "time": 11132.948227882385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348244, "time": 11135.38861322403, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 348336, "time": 11138.293315172195, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 348704, "time": 11149.599035024643, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 348708, "time": 11149.621263027191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349028, "time": 11159.384849309921, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 349400, "time": 11170.719030857086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349400, "time": 11170.729428768158, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 349492, "time": 11173.646265506744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349700, "time": 11179.968964338303, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 349756, "time": 11181.89568567276, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 349860, "time": 11184.862934589386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350060, "time": 11191.74140572548, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 350060, "time": 11192.334920167923, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 350060, "time": 11192.648030281067, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 350060, "time": 11193.06721162796, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 350060, "time": 11194.701221466064, "eval_episode/length": 237.0, "eval_episode/score": 0.2593750059604645, "eval_episode/reward_rate": 0.004201680672268907}
{"step": 350060, "time": 11195.400722503662, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350060, "time": 11196.382442235947, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 350060, "time": 11196.56258392334, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350196, "time": 11200.472569704056, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 350204, "time": 11200.936626195908, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 350249, "time": 11202.941893100739, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.78531757910647, "train/action_min": 0.0, "train/action_std": 1.744368964104197, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0025754190168820845, "train/actor_opt_grad_steps": 20800.0, "train/actor_opt_loss": 17.93495043573068, "train/adv_mag": 0.02543236382642583, "train/adv_max": 0.02533702009437072, "train/adv_mean": 0.003468508639610003, "train/adv_min": -0.005700288930130963, "train/adv_std": 0.0036227869825793345, "train/cont_avg": 0.996540318781407, "train/cont_loss_mean": 0.023031417134185158, "train/cont_loss_std": 0.3208711366598148, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.620027150426592, "train/cont_pos_acc": 0.9999999841253961, "train/cont_pos_loss": 0.0036113251517784204, "train/cont_pred": 0.996394632749222, "train/cont_rate": 0.996540318781407, "train/dyn_loss_mean": 1.000008664538513, "train/dyn_loss_std": 0.00025642459144337274, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.19213714953465152, "train/extr_critic_critic_opt_grad_steps": 20800.0, "train/extr_critic_critic_opt_loss": 8899.459302739282, "train/extr_critic_mag": 0.14931287717579597, "train/extr_critic_max": 0.14931287717579597, "train/extr_critic_mean": 0.14531483684652416, "train/extr_critic_min": 0.13833830943658723, "train/extr_critic_std": 0.0020546158631264944, "train/extr_return_normed_mag": 0.03569460862395751, "train/extr_return_normed_max": 0.03569460862395751, "train/extr_return_normed_mean": 0.011750526048814007, "train/extr_return_normed_min": 0.001496361952331198, "train/extr_return_normed_std": 0.004375159740447998, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.17272741811808628, "train/extr_return_raw_max": 0.17272741811808628, "train/extr_return_raw_mean": 0.1487833431093537, "train/extr_return_raw_min": 0.13852917152134017, "train/extr_return_raw_std": 0.0043751597278704635, "train/extr_reward_mag": 0.019816360880981137, "train/extr_reward_max": 0.019816360880981137, "train/extr_reward_mean": 0.0009487387796614703, "train/extr_reward_min": 3.6319895605346065e-06, "train/extr_reward_std": 0.002305059070726997, "train/image_loss_mean": 0.16235513356163275, "train/image_loss_std": 0.10895356352455053, "train/model_loss_mean": 0.7879526642099697, "train/model_loss_std": 0.38766294931197287, "train/model_opt_grad_norm": 30.420663747356166, "train/model_opt_grad_steps": 20780.201005025127, "train/model_opt_loss": 2403.4904134932476, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3052.763819095477, "train/policy_entropy_mag": 1.7517305420870757, "train/policy_entropy_max": 1.7517305420870757, "train/policy_entropy_mean": 0.8359611570535592, "train/policy_entropy_min": 0.06753405411938328, "train/policy_entropy_std": 0.39173005199312566, "train/policy_logprob_mag": 6.498212521998727, "train/policy_logprob_max": -0.009053793024440208, "train/policy_logprob_mean": -0.8359543558341175, "train/policy_logprob_min": -6.498212521998727, "train/policy_logprob_std": 0.9960115021796682, "train/policy_randomness_mag": 0.9002114750033048, "train/policy_randomness_max": 0.9002114750033048, "train/policy_randomness_mean": 0.4295990810022881, "train/policy_randomness_min": 0.034705640532862604, "train/policy_randomness_std": 0.20130943563116255, "train/post_ent_mag": 75.37929676765174, "train/post_ent_max": 75.37929676765174, "train/post_ent_mean": 74.68749378913611, "train/post_ent_min": 73.94801008521613, "train/post_ent_std": 0.2758611353048727, "train/prior_ent_mag": 76.93173509147299, "train/prior_ent_max": 76.93173509147299, "train/prior_ent_mean": 73.6854701209907, "train/prior_ent_min": 70.6546668047881, "train/prior_ent_std": 0.9365197045719205, "train/rep_loss_mean": 1.000008664538513, "train/rep_loss_std": 0.00025642459144337274, "train/reward_avg": 0.00017545307173578528, "train/reward_loss_mean": 0.0025608949176031143, "train/reward_loss_std": 0.06707904318797439, "train/reward_max_data": 0.1561243717544642, "train/reward_max_pred": 0.008660267345869362, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0003281091055794778, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.076310864516667, "train/reward_pred": 0.00014670854247170477, "train/reward_rate": 0.00031897770100502515, "train_stats/mean_log_entropy": 0.447207984807608, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.019779875874519348, "report/cont_loss_std": 0.29751071333885193, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.497851848602295, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003683681832626462, "report/cont_pred": 0.9963217377662659, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12523533403873444, "report/image_loss_std": 0.09351400285959244, "report/model_loss_mean": 0.7454513311386108, "report/model_loss_std": 0.31473398208618164, "report/post_ent_mag": 74.98455810546875, "report/post_ent_max": 74.98455810546875, "report/post_ent_mean": 74.38230895996094, "report/post_ent_min": 73.71376037597656, "report/post_ent_std": 0.24075305461883545, "report/prior_ent_mag": 76.41192626953125, "report/prior_ent_max": 76.41192626953125, "report/prior_ent_mean": 72.7254638671875, "report/prior_ent_min": 70.08470916748047, "report/prior_ent_std": 1.0115224123001099, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0004361015744507313, "report/reward_loss_std": 0.0016484203515574336, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.009155869483947754, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0004361015744507313, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00019363430328667164, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03133721649646759, "eval/cont_loss_std": 0.39933523535728455, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.732152462005615, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00336462096311152, "eval/cont_pred": 0.9966416954994202, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20949053764343262, "eval/image_loss_std": 0.11125219613313675, "eval/model_loss_mean": 0.8409368991851807, "eval/model_loss_std": 0.40900561213493347, "eval/post_ent_mag": 74.89413452148438, "eval/post_ent_max": 74.89413452148438, "eval/post_ent_mean": 74.28529357910156, "eval/post_ent_min": 73.66439819335938, "eval/post_ent_std": 0.22245019674301147, "eval/prior_ent_mag": 76.51268768310547, "eval/prior_ent_max": 76.51268768310547, "eval/prior_ent_mean": 72.55314636230469, "eval/prior_ent_min": 69.99180603027344, "eval/prior_ent_std": 1.02182936668396, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00010907603427767754, "eval/reward_loss_std": 0.000699988508131355, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0040634870529174805, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00010907603427767754, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.787882789969444e-05, "eval/reward_rate": 0.0, "replay/size": 349737.0, "replay/inserts": 31824.0, "replay/samples": 31824.0, "replay/insert_wait_avg": 1.4913747393347739e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.809586954092847e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 82788.0, "eval_replay/inserts": 7756.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3147757925158496e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.082261800766, "timer/env.step_count": 7956.0, "timer/env.step_total": 36.308491945266724, "timer/env.step_frac": 0.0363055053890157, "timer/env.step_avg": 0.004563661632135083, "timer/env.step_min": 0.003473043441772461, "timer/env.step_max": 0.029649972915649414, "timer/replay._sample_count": 31824.0, "timer/replay._sample_total": 15.63694143295288, "timer/replay._sample_frac": 0.015635655215798672, "timer/replay._sample_avg": 0.000491356882634266, "timer/replay._sample_min": 0.0003597736358642578, "timer/replay._sample_max": 0.009736776351928711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9895.0, "timer/agent.policy_total": 89.27512454986572, "timer/agent.policy_frac": 0.08926778122143206, "timer/agent.policy_avg": 0.009022246038389664, "timer/agent.policy_min": 0.007932901382446289, "timer/agent.policy_max": 0.04832792282104492, "timer/dataset_train_count": 1989.0, "timer/dataset_train_total": 0.24606966972351074, "timer/dataset_train_frac": 0.00024604942925438283, "timer/dataset_train_avg": 0.00012371526884037744, "timer/dataset_train_min": 8.749961853027344e-05, "timer/dataset_train_max": 0.03474020957946777, "timer/agent.train_count": 1989.0, "timer/agent.train_total": 858.205290555954, "timer/agent.train_frac": 0.8581346988503268, "timer/agent.train_avg": 0.43147576196880544, "timer/agent.train_min": 0.4213900566101074, "timer/agent.train_max": 0.5172653198242188, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.482818603515625, "timer/agent.report_frac": 0.0004827788892548231, "timer/agent.report_avg": 0.2414093017578125, "timer/agent.report_min": 0.2357616424560547, "timer/agent.report_max": 0.2470569610595703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.935264587402344e-05, "timer/dataset_eval_frac": 4.934858637044335e-08, "timer/dataset_eval_avg": 4.935264587402344e-05, "timer/dataset_eval_min": 4.935264587402344e-05, "timer/dataset_eval_max": 4.935264587402344e-05, "fps": 31.820808362991755}
{"step": 350288, "time": 11204.075805664062, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 350324, "time": 11205.0673558712, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 350460, "time": 11209.42662858963, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 350556, "time": 11212.351424217224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351360, "time": 11237.926569461823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351480, "time": 11241.408906459808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351616, "time": 11245.790163993835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351712, "time": 11248.747481107712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351740, "time": 11249.721404314041, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 351912, "time": 11254.678496837616, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 352064, "time": 11259.531091213226, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 352156, "time": 11262.454674720764, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 352452, "time": 11271.264377832413, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 352584, "time": 11275.329160690308, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 352636, "time": 11277.25598192215, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 352772, "time": 11281.221514940262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352804, "time": 11282.19764661789, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 352960, "time": 11287.079706192017, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 353068, "time": 11290.50933265686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353188, "time": 11293.944058656693, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 353292, "time": 11297.338290929794, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 353928, "time": 11316.608350276947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354224, "time": 11325.846552371979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354236, "time": 11326.321095943451, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 354344, "time": 11329.301974773407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354448, "time": 11332.70684337616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355348, "time": 11360.104137897491, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 355392, "time": 11361.537104129791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355500, "time": 11364.92717051506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355604, "time": 11367.86053943634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356504, "time": 11395.281724691391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356548, "time": 11396.735689640045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356656, "time": 11400.343229293823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356760, "time": 11403.4060049057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356852, "time": 11406.344875335693, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 356980, "time": 11410.273371458054, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 357320, "time": 11420.552147388458, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 357704, "time": 11432.298906564713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357916, "time": 11439.1448802948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358136, "time": 11445.548390865326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358216, "time": 11448.007710695267, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 358476, "time": 11456.257601976395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358496, "time": 11456.761368751526, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 358860, "time": 11468.073148012161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359072, "time": 11474.454350233078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359456, "time": 11486.189994096756, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 359632, "time": 11491.66189956665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359652, "time": 11492.17139005661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360016, "time": 11503.400929450989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360060, "time": 11506.116520881653, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 360060, "time": 11506.454467058182, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 360060, "time": 11507.074448347092, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 360060, "time": 11508.867728948593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360060, "time": 11509.255559206009, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 360060, "time": 11510.098437786102, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360060, "time": 11510.389884471893, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 360060, "time": 11510.423451185226, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360128, "time": 11512.406063079834, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 360316, "time": 11518.26128077507, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 360460, "time": 11522.68953371048, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 360788, "time": 11532.687554597855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361172, "time": 11544.432975530624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361472, "time": 11553.755479812622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361544, "time": 11555.72006392479, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 361616, "time": 11558.15494632721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361868, "time": 11565.965471029282, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 361928, "time": 11567.47631573677, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 361944, "time": 11567.969053506851, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362064, "time": 11571.886244058609, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 362176, "time": 11575.314057826996, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 362256, "time": 11577.779832601547, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 362392, "time": 11581.762269973755, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 362628, "time": 11589.059378385544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362796, "time": 11594.420476675034, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 363100, "time": 11603.747477293015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363332, "time": 11610.622947692871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363548, "time": 11617.4880027771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363568, "time": 11617.995868444443, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 363812, "time": 11625.311893463135, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 363952, "time": 11629.700052022934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364256, "time": 11638.8981153965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364272, "time": 11639.411259174347, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 364968, "time": 11660.62396979332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365108, "time": 11665.003975629807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365412, "time": 11674.374757528305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365428, "time": 11674.8695063591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365816, "time": 11686.568427801132, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 366084, "time": 11694.843190193176, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 366124, "time": 11696.282333374023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366264, "time": 11700.2331366539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366460, "time": 11706.56857419014, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 366584, "time": 11710.050498008728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366708, "time": 11713.951350688934, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 366716, "time": 11714.414691925049, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 367240, "time": 11730.027141809464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367740, "time": 11745.632597208023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367864, "time": 11749.088073253632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367872, "time": 11749.55488872528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368100, "time": 11756.382719278336, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 368228, "time": 11760.305406808853, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 368396, "time": 11765.678654909134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369028, "time": 11784.916270494461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369256, "time": 11791.907294034958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369280, "time": 11792.864624977112, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 369384, "time": 11795.82831287384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369552, "time": 11801.228084564209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370060, "time": 11818.959592342377, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 370060, "time": 11820.827879667282, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370060, "time": 11820.834565639496, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370060, "time": 11820.839980602264, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370060, "time": 11822.437522411346, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 370060, "time": 11823.266152143478, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370060, "time": 11824.049987077713, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 370060, "time": 11825.048263788223, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370060, "time": 11825.053963661194, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370412, "time": 11835.650183200836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370436, "time": 11836.164586544037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370540, "time": 11839.544527292252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370556, "time": 11840.038072824478, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 370708, "time": 11844.453119039536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370756, "time": 11845.915780305862, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 371696, "time": 11874.817959308624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371712, "time": 11875.312143325806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371864, "time": 11879.754469156265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371912, "time": 11881.251264810562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371932, "time": 11882.192695856094, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 372100, "time": 11887.118936538696, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 372868, "time": 11910.544009923935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373020, "time": 11915.59962105751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373068, "time": 11917.07585644722, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 373068, "time": 11917.08261346817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373112, "time": 11918.095861673355, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 373240, "time": 11921.994151592255, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 373256, "time": 11922.479106664658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373408, "time": 11927.292051553726, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 373460, "time": 11928.768277645111, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 373764, "time": 11938.015744924545, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 374020, "time": 11945.892519950867, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 374324, "time": 11955.19773697853, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 374352, "time": 11956.186308383942, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 374476, "time": 11960.10301733017, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 374616, "time": 11964.07394194603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374672, "time": 11966.027304649353, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 374836, "time": 11970.943175077438, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 374920, "time": 11973.447135448456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375124, "time": 11979.811132907867, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 375240, "time": 11983.26734828949, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 375512, "time": 11991.637967824936, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 375600, "time": 11994.529386520386, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 375684, "time": 11997.01619052887, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 375792, "time": 12000.426437139511, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 375828, "time": 12001.467436552048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376176, "time": 12012.203795909882, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 376280, "time": 12015.17358803749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376300, "time": 12016.115728378296, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 376328, "time": 12016.651032209396, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 376448, "time": 12020.546495199203, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 376840, "time": 12032.216866254807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376984, "time": 12036.586696147919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377484, "time": 12052.234254837036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377604, "time": 12055.653249502182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377860, "time": 12063.437617063522, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 377996, "time": 12067.791599273682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378068, "time": 12069.764392614365, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 378176, "time": 12073.140709400177, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 378332, "time": 12078.008102416992, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 378368, "time": 12079.017628908157, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 378604, "time": 12086.30837392807, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 379152, "time": 12102.87336564064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379332, "time": 12108.257819890976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379488, "time": 12113.125254392624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379680, "time": 12118.977621555328, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 379760, "time": 12121.449138879776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380060, "time": 12132.33219242096, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 380060, "time": 12132.518455266953, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 380060, "time": 12132.55022096634, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 380060, "time": 12134.587914705276, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380060, "time": 12136.21835064888, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380060, "time": 12136.412719964981, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380060, "time": 12136.446338653564, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380060, "time": 12137.957071065903, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 380180, "time": 12141.448127508163, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 380308, "time": 12145.372434139252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380348, "time": 12146.814865350723, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 380452, "time": 12149.786724090576, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 380696, "time": 12157.12143278122, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 380916, "time": 12163.981538057327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381060, "time": 12168.37093091011, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 381504, "time": 12182.204433202744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381608, "time": 12185.168231964111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381852, "time": 12192.943452835083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382169, "time": 12203.220610618591, "train_stats/mean_log_entropy": 0.35063671177051153, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.777721002473304, "train/action_min": 0.0, "train/action_std": 1.77493670837364, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0025619430342881037, "train/actor_opt_grad_steps": 22790.0, "train/actor_opt_loss": 18.529876622160774, "train/adv_mag": 0.02910655100441458, "train/adv_max": 0.02776215012049555, "train/adv_mean": 0.004472976679480141, "train/adv_min": -0.01164629014592674, "train/adv_std": 0.0043829264091187385, "train/cont_avg": 0.9961673602386935, "train/cont_loss_mean": 0.024570798931933528, "train/cont_loss_std": 0.32559001243710706, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.427647360777244, "train/cont_pos_acc": 0.9999999862220419, "train/cont_pos_loss": 0.0037735966911735994, "train/cont_pred": 0.9962300181987896, "train/cont_rate": 0.9961673602386935, "train/dyn_loss_mean": 1.0000166467685796, "train/dyn_loss_std": 0.00037668489285214716, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.20145089911933445, "train/extr_critic_critic_opt_grad_steps": 22790.0, "train/extr_critic_critic_opt_loss": 10969.655470958307, "train/extr_critic_mag": 0.3013502928479832, "train/extr_critic_max": 0.3013502928479832, "train/extr_critic_mean": 0.29250507296329764, "train/extr_critic_min": 0.27984591045571333, "train/extr_critic_std": 0.0037388578531140433, "train/extr_return_normed_mag": 0.0453551719386374, "train/extr_return_normed_max": 0.04475623691201809, "train/extr_return_normed_mean": 0.017140407791482893, "train/extr_return_normed_min": 0.0004614304058515846, "train/extr_return_normed_std": 0.005937268380684095, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.32459389354715396, "train/extr_return_raw_max": 0.32459389354715396, "train/extr_return_raw_mean": 0.29697807926927977, "train/extr_return_raw_min": 0.28029908704098744, "train/extr_return_raw_std": 0.005937268370154065, "train/extr_reward_mag": 0.024398319685279425, "train/extr_reward_max": 0.024398319685279425, "train/extr_reward_mean": 0.0014604547374879465, "train/extr_reward_min": 1.8354636340884108e-06, "train/extr_reward_std": 0.0036341789735471783, "train/image_loss_mean": 0.15176249602481948, "train/image_loss_std": 0.10886046208029417, "train/model_loss_mean": 0.779909450504648, "train/model_loss_std": 0.40308662122068695, "train/model_opt_grad_norm": 29.760844187520856, "train/model_opt_grad_steps": 22768.69849246231, "train/model_opt_loss": 2439.6309231705404, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3128.140703517588, "train/policy_entropy_mag": 1.7108788813777904, "train/policy_entropy_max": 1.7108788813777904, "train/policy_entropy_mean": 0.6478659291962283, "train/policy_entropy_min": 0.06476457244786785, "train/policy_entropy_std": 0.3982954008794909, "train/policy_logprob_mag": 6.549771848036416, "train/policy_logprob_max": -0.0086203810136447, "train/policy_logprob_mean": -0.648130013116041, "train/policy_logprob_min": -6.549771848036416, "train/policy_logprob_std": 0.9400766003671004, "train/policy_randomness_mag": 0.8792178744646773, "train/policy_randomness_max": 0.8792178744646773, "train/policy_randomness_mean": 0.33293724853788786, "train/policy_randomness_min": 0.03328240840653678, "train/policy_randomness_std": 0.20468335857043912, "train/post_ent_mag": 70.59885126621879, "train/post_ent_max": 70.59885126621879, "train/post_ent_mean": 70.04552503806262, "train/post_ent_min": 69.38376283885246, "train/post_ent_std": 0.23026992395595092, "train/prior_ent_mag": 72.10192579719889, "train/prior_ent_max": 72.10192579719889, "train/prior_ent_mean": 68.69885012372654, "train/prior_ent_min": 65.97313063348358, "train/prior_ent_std": 0.9337884798720854, "train/rep_loss_mean": 1.0000166467685796, "train/rep_loss_std": 0.00037668489285214716, "train/reward_avg": 0.000317996229386149, "train/reward_loss_mean": 0.0035661414310092752, "train/reward_loss_std": 0.0899950939285611, "train/reward_max_data": 0.2805276370827277, "train/reward_max_pred": 0.013349341986766412, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00048519644440776533, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.91580544276671, "train/reward_pred": 0.00022861450072845922, "train/reward_rate": 0.0005201790201005025, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.03639376908540726, "report/cont_loss_std": 0.4316347539424896, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.613900661468506, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0035204465966671705, "report/cont_pred": 0.9964790344238281, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.13816171884536743, "report/image_loss_std": 0.11350531876087189, "report/model_loss_mean": 0.7752301692962646, "report/model_loss_std": 0.44177359342575073, "report/post_ent_mag": 67.6514663696289, "report/post_ent_max": 67.6514663696289, "report/post_ent_mean": 67.09776306152344, "report/post_ent_min": 66.3781509399414, "report/post_ent_std": 0.2143358588218689, "report/prior_ent_mag": 69.82038879394531, "report/prior_ent_max": 69.82038879394531, "report/prior_ent_mean": 65.55622863769531, "report/prior_ent_min": 62.937923431396484, "report/prior_ent_std": 0.7960087060928345, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0006746700964868069, "report/reward_loss_std": 0.0033330258447676897, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.013845324516296387, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0006746700964868069, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00033041019923985004, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014560080133378506, "eval/cont_loss_std": 0.2580168843269348, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.846651077270508, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0031469871755689383, "eval/cont_pred": 0.9968588352203369, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2015308141708374, "eval/image_loss_std": 0.12482786178588867, "eval/model_loss_mean": 0.8162013292312622, "eval/model_loss_std": 0.2879137396812439, "eval/post_ent_mag": 67.58528137207031, "eval/post_ent_max": 67.58528137207031, "eval/post_ent_mean": 67.00537872314453, "eval/post_ent_min": 66.34290313720703, "eval/post_ent_std": 0.21321630477905273, "eval/prior_ent_mag": 69.4287338256836, "eval/prior_ent_max": 69.4287338256836, "eval/prior_ent_mean": 65.45228576660156, "eval/prior_ent_min": 62.743934631347656, "eval/prior_ent_std": 0.8312674760818481, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00011043436825275421, "eval/reward_loss_std": 0.0011806732509285212, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.014841437339782715, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00011043436825275421, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.3040566854178905e-05, "eval/reward_rate": 0.0, "replay/size": 381657.0, "replay/inserts": 31920.0, "replay/samples": 31920.0, "replay/insert_wait_avg": 1.4761112686386683e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.770414041696037e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 88868.0, "eval_replay/inserts": 6080.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3326343737150494e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2559142112732, "timer/env.step_count": 7980.0, "timer/env.step_total": 36.13452672958374, "timer/env.step_frac": 0.03612528175659598, "timer/env.step_avg": 0.004528136181652098, "timer/env.step_min": 0.0032541751861572266, "timer/env.step_max": 0.027376174926757812, "timer/replay._sample_count": 31920.0, "timer/replay._sample_total": 15.755857229232788, "timer/replay._sample_frac": 0.015751826113076947, "timer/replay._sample_avg": 0.0004936045497879946, "timer/replay._sample_min": 0.0003688335418701172, "timer/replay._sample_max": 0.033905744552612305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9500.0, "timer/agent.policy_total": 85.90535545349121, "timer/agent.policy_frac": 0.08588337667688746, "timer/agent.policy_avg": 0.009042668995104338, "timer/agent.policy_min": 0.008033037185668945, "timer/agent.policy_max": 0.04348015785217285, "timer/dataset_train_count": 1995.0, "timer/dataset_train_total": 0.20541596412658691, "timer/dataset_train_frac": 0.00020536340871182206, "timer/dataset_train_avg": 0.00010296539555217389, "timer/dataset_train_min": 8.559226989746094e-05, "timer/dataset_train_max": 0.0010399818420410156, "timer/agent.train_count": 1995.0, "timer/agent.train_total": 864.1040015220642, "timer/agent.train_frac": 0.8638829216055491, "timer/agent.train_avg": 0.4331348378556713, "timer/agent.train_min": 0.42327380180358887, "timer/agent.train_max": 1.5232970714569092, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48103976249694824, "timer/agent.report_frac": 0.00048091668908177375, "timer/agent.report_avg": 0.24051988124847412, "timer/agent.report_min": 0.23321914672851562, "timer/agent.report_max": 0.24782061576843262, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.669604896106102e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 31.911149915911107}
{"step": 382216, "time": 12204.390413284302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382536, "time": 12214.20428609848, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 382764, "time": 12221.472703456879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382844, "time": 12223.920864582062, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 383008, "time": 12228.80834197998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383084, "time": 12231.234382629395, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 383112, "time": 12231.763788938522, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 383492, "time": 12243.49372792244, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 383692, "time": 12249.816696166992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384000, "time": 12259.12430357933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384048, "time": 12260.57698917389, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 384268, "time": 12267.363098144531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384284, "time": 12267.854823112488, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 384448, "time": 12272.82599568367, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 384604, "time": 12277.687448740005, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 384984, "time": 12288.947541713715, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 385156, "time": 12294.323780536652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385440, "time": 12303.375431537628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385604, "time": 12308.250518083572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385732, "time": 12312.179364442825, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 386044, "time": 12321.938834190369, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 386140, "time": 12324.8518512249, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386312, "time": 12329.779304504395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386524, "time": 12336.58823800087, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 386532, "time": 12336.623822689056, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 386888, "time": 12347.384334564209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387200, "time": 12357.052701234818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387212, "time": 12357.527019023895, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 387440, "time": 12364.375222206116, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 387528, "time": 12366.839332580566, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 387680, "time": 12371.690903663635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387688, "time": 12371.727462053299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388028, "time": 12382.38426041603, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 388084, "time": 12383.87130689621, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 388408, "time": 12393.69606256485, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 388596, "time": 12399.567605495453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388684, "time": 12402.456216096878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389184, "time": 12417.588045835495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389460, "time": 12426.121114730835, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 389564, "time": 12429.497352600098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389752, "time": 12434.935374498367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389812, "time": 12436.877117872238, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 389840, "time": 12437.837512016296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390060, "time": 12445.014856100082, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 390060, "time": 12445.203309059143, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 390060, "time": 12448.832523584366, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390060, "time": 12448.839225292206, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390060, "time": 12449.199852705002, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390060, "time": 12449.410834312439, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390060, "time": 12449.931277036667, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 390060, "time": 12452.851036071777, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390060, "time": 12452.857444524765, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390720, "time": 12472.848316192627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390884, "time": 12477.72123336792, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 390908, "time": 12478.67089009285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390968, "time": 12480.186337709427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390996, "time": 12481.221787929535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392040, "time": 12512.95524597168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392064, "time": 12513.917101860046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392124, "time": 12515.883981704712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392152, "time": 12516.424325704575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392244, "time": 12519.347156524658, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 392356, "time": 12522.7803440094, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 392500, "time": 12527.185477018356, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 393220, "time": 12549.259740829468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393280, "time": 12551.235459327698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393416, "time": 12555.193495750427, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 393512, "time": 12558.3028485775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393656, "time": 12562.71258187294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393796, "time": 12567.123262405396, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 394436, "time": 12586.755667924881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394572, "time": 12591.107100963593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394792, "time": 12597.48758816719, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 394812, "time": 12598.427920341492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394952, "time": 12602.450181484222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395728, "time": 12626.368192911148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395948, "time": 12633.17878651619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395968, "time": 12633.689281702042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396108, "time": 12638.094655752182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396228, "time": 12641.520141601562, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 396240, "time": 12641.994540691376, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 396388, "time": 12646.38491654396, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 397124, "time": 12668.89944267273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397384, "time": 12676.695874214172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397396, "time": 12677.194366455078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397544, "time": 12681.589625597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397704, "time": 12686.6369535923, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 398264, "time": 12703.73284816742, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 398280, "time": 12704.225082159042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398552, "time": 12712.540971755981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398700, "time": 12717.401661872864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398908, "time": 12723.839833498001, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 399404, "time": 12738.996652841568, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 399420, "time": 12739.498167037964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399436, "time": 12739.99327158928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399856, "time": 12752.69584608078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400060, "time": 12760.259778499603, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 400060, "time": 12761.78588104248, "eval_episode/length": 196.0, "eval_episode/score": 0.38749998807907104, "eval_episode/reward_rate": 0.005076142131979695}
{"step": 400060, "time": 12763.01582121849, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400060, "time": 12763.023405790329, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400060, "time": 12764.144031763077, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400060, "time": 12765.603175640106, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400060, "time": 12766.268307447433, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 400060, "time": 12766.799118995667, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400060, "time": 12766.806012630463, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400560, "time": 12781.95944929123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400576, "time": 12782.453256845474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400592, "time": 12782.961136102676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400940, "time": 12793.651551961899, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 401236, "time": 12802.491400957108, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 401716, "time": 12817.363268375397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401732, "time": 12817.857650279999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401748, "time": 12818.352576494217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402392, "time": 12837.923877716064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402872, "time": 12852.640820980072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402888, "time": 12853.138190507889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402904, "time": 12853.636740207672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403392, "time": 12868.73803305626, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 403756, "time": 12880.019790649414, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 404028, "time": 12888.298919677734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404044, "time": 12888.791232824326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404076, "time": 12889.769073963165, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 404096, "time": 12890.278155326843, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 404548, "time": 12903.903608560562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404956, "time": 12916.43188071251, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 405184, "time": 12923.227187871933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405232, "time": 12924.707234621048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405704, "time": 12938.962268352509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406112, "time": 12951.744182348251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406340, "time": 12958.56566977501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406388, "time": 12960.044305086136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406860, "time": 12974.64535522461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407268, "time": 12986.85256576538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407496, "time": 12993.727609872818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407544, "time": 12995.192125797272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408016, "time": 13009.766419649124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408424, "time": 13022.000330924988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408652, "time": 13029.295884370804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408700, "time": 13030.765192270279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409172, "time": 13044.968706846237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409580, "time": 13057.698040485382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409756, "time": 13063.067280054092, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 409808, "time": 13064.543579101562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409856, "time": 13066.017311573029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409928, "time": 13068.18114900589, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 409932, "time": 13068.631473064423, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 410020, "time": 13071.102873563766, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 410060, "time": 13073.013301610947, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 410060, "time": 13074.254680633545, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 410060, "time": 13076.7275121212, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410060, "time": 13076.734160900116, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410060, "time": 13076.977728366852, "eval_episode/length": 17.0, "eval_episode/score": 0.9468749761581421, "eval_episode/reward_rate": 0.05555555555555555}
{"step": 410060, "time": 13077.171479463577, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410060, "time": 13078.209203243256, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 410060, "time": 13078.358912467957, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410060, "time": 13078.364260673523, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 410304, "time": 13085.813351154327, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 410328, "time": 13086.33065700531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410836, "time": 13102.009192943573, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 411088, "time": 13109.825773477554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411176, "time": 13112.358007192612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411188, "time": 13112.833230733871, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 411460, "time": 13121.097025632858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411524, "time": 13123.051215171814, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 411692, "time": 13128.37032532692, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 411992, "time": 13137.199358463287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412196, "time": 13143.603863716125, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 412332, "time": 13147.949860811234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412632, "time": 13156.719896554947, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 412848, "time": 13163.506245851517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413352, "time": 13178.706841230392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413488, "time": 13183.075567007065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413548, "time": 13185.031615257263, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 413624, "time": 13187.00304055214, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 413680, "time": 13188.912368774414, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 413728, "time": 13190.390254735947, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 413788, "time": 13192.309281110764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414121, "time": 13203.331972837448, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.71956787109375, "train/action_min": 0.0, "train/action_std": 1.5834821182489396, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0020158492293558083, "train/actor_opt_grad_steps": 24785.0, "train/actor_opt_loss": 2.893161275088787, "train/adv_mag": 0.020190485566854478, "train/adv_max": 0.018476333618164063, "train/adv_mean": 0.0021179142913752003, "train/adv_min": -0.011896698474884034, "train/adv_std": 0.0032805771817220374, "train/cont_avg": 0.9964111328125, "train/cont_loss_mean": 0.023094687375705688, "train/cont_loss_std": 0.3110002440551762, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.4002290693755, "train/cont_pos_acc": 0.9999999839067459, "train/cont_pos_loss": 0.003775494541041553, "train/cont_pred": 0.9962272122502327, "train/cont_rate": 0.9964111328125, "train/dyn_loss_mean": 1.0000192409753799, "train/dyn_loss_std": 0.0005419960813924263, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16742106569698081, "train/extr_critic_critic_opt_grad_steps": 24785.0, "train/extr_critic_critic_opt_loss": 9653.064676513672, "train/extr_critic_mag": 0.4246911507844925, "train/extr_critic_max": 0.4246911507844925, "train/extr_critic_mean": 0.4163538609445095, "train/extr_critic_min": 0.4047298288345337, "train/extr_critic_std": 0.0032835519599029796, "train/extr_return_normed_mag": 0.03217198669910431, "train/extr_return_normed_max": 0.03207968071103096, "train/extr_return_normed_mean": 0.010721578717984813, "train/extr_return_normed_min": -0.0038852323591709137, "train/extr_return_normed_std": 0.004679456545272842, "train/extr_return_rate": 0.0004222005342671764, "train/extr_return_raw_mag": 0.4398298634588718, "train/extr_return_raw_max": 0.4398298634588718, "train/extr_return_raw_mean": 0.41847178190946577, "train/extr_return_raw_min": 0.40386495038867, "train/extr_return_raw_std": 0.004679456548765302, "train/extr_reward_mag": 0.016604961752891542, "train/extr_reward_max": 0.016604961752891542, "train/extr_reward_mean": 0.0014586574186978396, "train/extr_reward_min": 7.909536361694336e-07, "train/extr_reward_std": 0.003264302060706541, "train/image_loss_mean": 0.14114093087613583, "train/image_loss_std": 0.10934200026094913, "train/model_loss_mean": 0.7681890305876732, "train/model_loss_std": 0.39450916577130557, "train/model_opt_grad_norm": 28.039524483680726, "train/model_opt_grad_steps": 24762.385, "train/model_opt_loss": 2410.6664501953123, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3137.5, "train/policy_entropy_mag": 1.6511508083343507, "train/policy_entropy_max": 1.6511508083343507, "train/policy_entropy_mean": 0.44612174317240716, "train/policy_entropy_min": 0.06470506120473146, "train/policy_entropy_std": 0.344704537242651, "train/policy_logprob_mag": 6.550944836139679, "train/policy_logprob_max": -0.008611202337779105, "train/policy_logprob_mean": -0.4457553589344025, "train/policy_logprob_min": -6.550944836139679, "train/policy_logprob_std": 0.8873579353094101, "train/policy_randomness_mag": 0.8485237112641335, "train/policy_randomness_max": 0.8485237112641335, "train/policy_randomness_mean": 0.22926123902201653, "train/policy_randomness_min": 0.0332518257945776, "train/policy_randomness_std": 0.17714310117065907, "train/post_ent_mag": 64.03130884170533, "train/post_ent_max": 64.03130884170533, "train/post_ent_mean": 63.48428771972656, "train/post_ent_min": 62.80488996505737, "train/post_ent_std": 0.22464945942163467, "train/prior_ent_mag": 66.28600852966309, "train/prior_ent_max": 66.28600852966309, "train/prior_ent_mean": 62.64144458770752, "train/prior_ent_min": 59.46073184967041, "train/prior_ent_std": 1.1529900598526002, "train/rep_loss_mean": 1.0000192409753799, "train/rep_loss_std": 0.0005419960813924263, "train/reward_avg": 0.0003672790533164516, "train/reward_loss_mean": 0.003941846422385424, "train/reward_loss_std": 0.09626491404254921, "train/reward_max_data": 0.30545312523841855, "train/reward_max_pred": 0.011917195916175842, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00058609589257685, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.906005059519122, "train/reward_pred": 0.00028996141045354305, "train/reward_rate": 0.0005712890625, "train_stats/mean_log_entropy": 0.20244267468651136, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014505338855087757, "report/cont_loss_std": 0.23186944425106049, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.234460830688477, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0042901597917079926, "report/cont_pred": 0.9957221150398254, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.13328631222248077, "report/image_loss_std": 0.10517967492341995, "report/model_loss_mean": 0.7485389709472656, "report/model_loss_std": 0.2526003420352936, "report/post_ent_mag": 60.94512176513672, "report/post_ent_max": 60.94512176513672, "report/post_ent_mean": 60.377037048339844, "report/post_ent_min": 59.73333740234375, "report/post_ent_std": 0.243109330534935, "report/prior_ent_mag": 63.05236053466797, "report/prior_ent_max": 63.05236053466797, "report/prior_ent_mean": 58.52347183227539, "report/prior_ent_min": 55.56538391113281, "report/prior_ent_std": 1.0948967933654785, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0007473481819033623, "report/reward_loss_std": 0.0028108281549066305, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.00982522964477539, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0007473481819033623, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00035577721428126097, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020596884191036224, "eval/cont_loss_std": 0.3007014989852905, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.563817977905273, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004309260286390781, "eval/cont_pred": 0.9957060217857361, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20266930758953094, "eval/image_loss_std": 0.11881569027900696, "eval/model_loss_mean": 0.8317224979400635, "eval/model_loss_std": 0.5262457728385925, "eval/post_ent_mag": 60.91434860229492, "eval/post_ent_max": 60.91434860229492, "eval/post_ent_mean": 60.318756103515625, "eval/post_ent_min": 59.59148406982422, "eval/post_ent_std": 0.22034940123558044, "eval/prior_ent_mag": 63.8116455078125, "eval/prior_ent_max": 63.8116455078125, "eval/prior_ent_mean": 58.51039123535156, "eval/prior_ent_min": 55.685699462890625, "eval/prior_ent_std": 1.0931153297424316, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0002838134823832661, "eval/reward_loss_mean": 0.008456271141767502, "eval/reward_loss_std": 0.25552716851234436, "eval/reward_max_data": 0.2906250059604645, "eval/reward_max_pred": 0.008887052536010742, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00046742719132453203, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.18104362487793, "eval/reward_pred": 0.00022161821834743023, "eval/reward_rate": 0.0009765625, "replay/size": 413609.0, "replay/inserts": 31952.0, "replay/samples": 31952.0, "replay/insert_wait_avg": 1.6413886486200554e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.870230724886769e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 95116.0, "eval_replay/inserts": 6248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3233604870746139e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.817941665649414e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0900421142578, "timer/env.step_count": 7988.0, "timer/env.step_total": 36.26315379142761, "timer/env.step_frac": 0.03625988887437061, "timer/env.step_avg": 0.004539703779597848, "timer/env.step_min": 0.0034253597259521484, "timer/env.step_max": 0.02969217300415039, "timer/replay._sample_count": 31952.0, "timer/replay._sample_total": 15.85752820968628, "timer/replay._sample_frac": 0.015856100492874017, "timer/replay._sample_avg": 0.0004962921948449637, "timer/replay._sample_min": 0.00036144256591796875, "timer/replay._sample_max": 0.02808380126953125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9550.0, "timer/agent.policy_total": 86.66203761100769, "timer/agent.policy_frac": 0.08665423508047165, "timer/agent.policy_avg": 0.009074558912147403, "timer/agent.policy_min": 0.00758051872253418, "timer/agent.policy_max": 0.03925824165344238, "timer/dataset_train_count": 1997.0, "timer/dataset_train_total": 0.20967769622802734, "timer/dataset_train_frac": 0.0002096588181047724, "timer/dataset_train_avg": 0.00010499634262795561, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.005445241928100586, "timer/agent.train_count": 1997.0, "timer/agent.train_total": 862.8268144130707, "timer/agent.train_frac": 0.8627491306572722, "timer/agent.train_avg": 0.4320614994557189, "timer/agent.train_min": 0.4217820167541504, "timer/agent.train_max": 0.5300419330596924, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4842071533203125, "timer/agent.report_frac": 0.0004841635582098847, "timer/agent.report_avg": 0.24210357666015625, "timer/agent.report_min": 0.23626112937927246, "timer/agent.report_max": 0.24794602394104004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.1219253540039062e-05, "timer/dataset_eval_frac": 2.12173430856087e-08, "timer/dataset_eval_avg": 2.1219253540039062e-05, "timer/dataset_eval_min": 2.1219253540039062e-05, "timer/dataset_eval_max": 2.1219253540039062e-05, "fps": 31.948446590869803}
{"step": 414408, "time": 13211.852316379547, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 414704, "time": 13221.09512591362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414836, "time": 13225.033583164215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414884, "time": 13226.497468471527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415184, "time": 13235.811694383621, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 415564, "time": 13247.54219698906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415860, "time": 13256.380173921585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415992, "time": 13260.325508117676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416340, "time": 13271.120918273926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416720, "time": 13282.843044281006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417016, "time": 13291.724023342133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417148, "time": 13296.102518081665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417496, "time": 13306.428287506104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417876, "time": 13318.181159973145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418016, "time": 13322.640933990479, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 418172, "time": 13327.67187833786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418304, "time": 13331.606675624847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418652, "time": 13342.383199214935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419172, "time": 13358.085000753403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419328, "time": 13362.966862916946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419460, "time": 13366.90507698059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419808, "time": 13377.61962890625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420060, "time": 13385.692845344543, "eval_episode/length": 14.0, "eval_episode/score": 0.956250011920929, "eval_episode/reward_rate": 0.06666666666666667}
{"step": 420060, "time": 13387.127901792526, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 420060, "time": 13388.999808073044, "eval_episode/length": 254.0, "eval_episode/score": 0.20624999701976776, "eval_episode/reward_rate": 0.00392156862745098}
{"step": 420060, "time": 13389.47194314003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420060, "time": 13389.688992261887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420060, "time": 13391.162858486176, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420060, "time": 13392.949974775314, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420060, "time": 13393.4145257473, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420328, "time": 13401.268104553223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420484, "time": 13406.144189119339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420616, "time": 13410.090881824493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420904, "time": 13418.96826672554, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 420964, "time": 13420.92632484436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421640, "time": 13441.608418226242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421772, "time": 13445.973300933838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422060, "time": 13454.798013687134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422120, "time": 13456.305057525635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422352, "time": 13463.782696723938, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 422760, "time": 13476.078451633453, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 422928, "time": 13481.405135631561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423276, "time": 13492.14106297493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423332, "time": 13493.639213562012, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 423448, "time": 13497.081303834915, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 423556, "time": 13500.509589672089, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 424152, "time": 13518.620998382568, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 424232, "time": 13521.090843200684, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 424604, "time": 13532.906894922256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424712, "time": 13535.8966319561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425292, "time": 13554.032483577728, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 425296, "time": 13554.054161071777, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 425444, "time": 13558.466026067734, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 425868, "time": 13571.69842505455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426268, "time": 13584.127364873886, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 426336, "time": 13586.09137558937, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 426600, "time": 13593.963989496231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426984, "time": 13605.622961759567, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 427024, "time": 13607.069845676422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427452, "time": 13620.247248888016, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 427492, "time": 13621.31736111641, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427756, "time": 13629.568769216537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428180, "time": 13642.31411933899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428608, "time": 13655.597250699997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428648, "time": 13656.6091837883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428912, "time": 13664.930047750473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429336, "time": 13677.651584863663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429392, "time": 13679.601477622986, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 429404, "time": 13680.078708410263, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 429520, "time": 13683.604965209961, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 429764, "time": 13690.966608524323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430060, "time": 13700.331578969955, "eval_episode/length": 7.0, "eval_episode/score": 0.9781249761581421, "eval_episode/reward_rate": 0.125}
{"step": 430060, "time": 13701.20436501503, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 430060, "time": 13704.356217622757, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430060, "time": 13704.362344503403, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430060, "time": 13704.47444987297, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430060, "time": 13705.359174966812, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430060, "time": 13706.2505569458, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 430060, "time": 13707.19951081276, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 430064, "time": 13707.218356132507, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 430272, "time": 13713.635814666748, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 430492, "time": 13720.642385005951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430560, "time": 13722.641616106033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430676, "time": 13726.099085330963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430784, "time": 13729.51116657257, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 430948, "time": 13734.435050964355, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 430972, "time": 13735.383454322815, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 431428, "time": 13749.206557750702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431648, "time": 13756.015460014343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432104, "time": 13769.67451930046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432104, "time": 13769.680401325226, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 432128, "time": 13770.646479845047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432584, "time": 13784.32850241661, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 432804, "time": 13791.163589954376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432936, "time": 13795.0978910923, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 433260, "time": 13805.361191272736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433284, "time": 13805.888016939163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433404, "time": 13809.778924942017, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 434060, "time": 13829.81627202034, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 434092, "time": 13830.794479131699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434416, "time": 13840.642343521118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434440, "time": 13841.265801906586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435216, "time": 13865.380160570145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435248, "time": 13866.368777275085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435572, "time": 13876.172056674957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435596, "time": 13877.123232603073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436372, "time": 13900.697067975998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436404, "time": 13901.67320394516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436728, "time": 13911.427159070969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436752, "time": 13912.399320363998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437528, "time": 13935.946734189987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437560, "time": 13936.935935020447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437884, "time": 13947.186301469803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437908, "time": 13947.716139554977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438272, "time": 13959.009110927582, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 438620, "time": 13969.862339258194, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 439040, "time": 13982.666480779648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439064, "time": 13983.185273885727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439428, "time": 13994.455219984055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439776, "time": 14005.157827854156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440060, "time": 14015.941396951675, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 440060, "time": 14017.37867474556, "eval_episode/length": 258.0, "eval_episode/score": 0.19374999403953552, "eval_episode/reward_rate": 0.003861003861003861}
{"step": 440060, "time": 14017.80198764801, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440060, "time": 14017.810736894608, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440060, "time": 14019.745239257812, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440060, "time": 14021.181226015091, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440060, "time": 14021.578685760498, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440060, "time": 14021.584590911865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440196, "time": 14025.528744459152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440220, "time": 14026.483889341354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440584, "time": 14037.204976558685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440932, "time": 14048.05847811699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441016, "time": 14050.515805482864, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 441352, "time": 14060.852679491043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441740, "time": 14073.116928815842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442088, "time": 14083.362022161484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442172, "time": 14086.286504983902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442252, "time": 14090.07626247406, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 442896, "time": 14109.881070375443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443212, "time": 14119.603523254395, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 443292, "time": 14122.052987575531, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 443328, "time": 14123.064041376114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443408, "time": 14125.500388145447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444184, "time": 14149.054818153381, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 444368, "time": 14154.875280618668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444448, "time": 14157.318275690079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444484, "time": 14158.316783428192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444624, "time": 14162.713235139847, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 445524, "time": 14190.130392074585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445604, "time": 14192.665170907974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445640, "time": 14193.664180278778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445780, "time": 14198.081053256989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445929, "time": 14203.501279830933, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.907209693486966, "train/action_min": 0.0, "train/action_std": 1.6705870802079015, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004540024737970221, "train/actor_opt_grad_steps": 26780.0, "train/actor_opt_loss": 4.009659262252363, "train/adv_mag": 0.10505240990887935, "train/adv_max": 0.10359994011308679, "train/adv_mean": 0.0029321617751260024, "train/adv_min": -0.023297956990237213, "train/adv_std": 0.009396974748496585, "train/cont_avg": 0.9960593985552764, "train/cont_loss_mean": 0.024040488013763673, "train/cont_loss_std": 0.3161026967792355, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.123605579289083, "train/cont_pos_acc": 0.9999999802316254, "train/cont_pos_loss": 0.0038487137723526915, "train/cont_pred": 0.9961402104727587, "train/cont_rate": 0.9960593985552764, "train/dyn_loss_mean": 1.000014460266535, "train/dyn_loss_std": 0.00043321346373287914, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4214341159273482, "train/extr_critic_critic_opt_grad_steps": 26780.0, "train/extr_critic_critic_opt_loss": 12079.48574415044, "train/extr_critic_mag": 0.4964299255879081, "train/extr_critic_max": 0.4964299255879081, "train/extr_critic_mean": 0.48105426454663874, "train/extr_critic_min": 0.46474665912551494, "train/extr_critic_std": 0.0058780687664583995, "train/extr_return_normed_mag": 0.12682047052000037, "train/extr_return_normed_max": 0.12674149196950635, "train/extr_return_normed_mean": 0.01781452843046574, "train/extr_return_normed_min": -0.008242560241689635, "train/extr_return_normed_std": 0.011448696919075733, "train/extr_return_rate": 0.3484263819400028, "train/extr_return_raw_mag": 0.5929133570074436, "train/extr_return_raw_max": 0.5929133570074436, "train/extr_return_raw_mean": 0.483986417702095, "train/extr_return_raw_min": 0.45792930464648723, "train/extr_return_raw_std": 0.01144869695417583, "train/extr_reward_mag": 0.09443400972452595, "train/extr_reward_max": 0.09443400972452595, "train/extr_reward_mean": 0.0013717139611721515, "train/extr_reward_min": 9.30311691820921e-07, "train/extr_reward_std": 0.00503734953294335, "train/image_loss_mean": 0.1303035138764573, "train/image_loss_std": 0.10756868820394104, "train/model_loss_mean": 0.7592010426161876, "train/model_loss_std": 0.40907308474257964, "train/model_opt_grad_norm": 26.502055784668585, "train/model_opt_grad_steps": 26755.59296482412, "train/model_opt_loss": 2163.9940130339196, "train/model_opt_model_opt_grad_overflow": 0.005025125628140704, "train/model_opt_model_opt_grad_scale": 2839.1959798994976, "train/policy_entropy_mag": 1.7301031303166146, "train/policy_entropy_max": 1.7301031303166146, "train/policy_entropy_mean": 0.5056127603329605, "train/policy_entropy_min": 0.06470581608351751, "train/policy_entropy_std": 0.3587002617929449, "train/policy_logprob_mag": 6.5509531533897825, "train/policy_logprob_max": -0.00861132580637183, "train/policy_logprob_mean": -0.5055723004604704, "train/policy_logprob_min": -6.5509531533897825, "train/policy_logprob_std": 0.8958846549292905, "train/policy_randomness_mag": 0.8890971819959094, "train/policy_randomness_max": 0.8890971819959094, "train/policy_randomness_mean": 0.2598335749689658, "train/policy_randomness_min": 0.03325221354338392, "train/policy_randomness_std": 0.18433548038329312, "train/post_ent_mag": 58.106870852523116, "train/post_ent_max": 58.106870852523116, "train/post_ent_mean": 57.540552302221556, "train/post_ent_min": 56.81252049201697, "train/post_ent_std": 0.24970004808663124, "train/prior_ent_mag": 59.91272039748915, "train/prior_ent_max": 59.91272039748915, "train/prior_ent_mean": 56.3657374741444, "train/prior_ent_min": 53.3234730821159, "train/prior_ent_std": 1.1110857883889471, "train/rep_loss_mean": 1.000014460266535, "train/rep_loss_std": 0.00043321346373287914, "train/reward_avg": 0.0005085394027012274, "train/reward_loss_mean": 0.00484834647568963, "train/reward_loss_std": 0.11074643507693431, "train/reward_max_data": 0.37934987494094885, "train/reward_max_pred": 0.022409548711537115, "train/reward_neg_acc": 0.9999901700259453, "train/reward_neg_loss": 0.000692331842945341, "train/reward_pos_acc": 0.022935779816513763, "train/reward_pos_loss": 5.465688304616771, "train/reward_pred": 0.00034773990806735044, "train/reward_rate": 0.000755731783919598, "train_stats/mean_log_entropy": 0.2677724790992215, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.03490891680121422, "report/cont_loss_std": 0.3809433579444885, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.434362888336182, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004627523943781853, "report/cont_pred": 0.9952669143676758, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1394224911928177, "report/image_loss_std": 0.10933954268693924, "report/model_loss_mean": 0.7748815417289734, "report/model_loss_std": 0.39608079195022583, "report/post_ent_mag": 52.956459045410156, "report/post_ent_max": 52.956459045410156, "report/post_ent_mean": 52.413230895996094, "report/post_ent_min": 51.76899719238281, "report/post_ent_std": 0.24532970786094666, "report/prior_ent_mag": 56.688499450683594, "report/prior_ent_max": 56.688499450683594, "report/prior_ent_mean": 52.079505920410156, "report/prior_ent_min": 49.53984832763672, "report/prior_ent_std": 1.1389273405075073, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0005501038394868374, "report/reward_loss_std": 0.0027976101264357567, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.01505422592163086, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005501038394868374, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00026988517493009567, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.031539201736450195, "eval/cont_loss_std": 0.39106786251068115, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.604643821716309, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004193250555545092, "eval/cont_pred": 0.9958577752113342, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19074633717536926, "eval/image_loss_std": 0.13219252228736877, "eval/model_loss_mean": 0.8225149512290955, "eval/model_loss_std": 0.41522863507270813, "eval/post_ent_mag": 53.026912689208984, "eval/post_ent_max": 53.026912689208984, "eval/post_ent_mean": 52.33152770996094, "eval/post_ent_min": 51.686058044433594, "eval/post_ent_std": 0.24920859932899475, "eval/prior_ent_mag": 56.96138000488281, "eval/prior_ent_max": 56.96138000488281, "eval/prior_ent_mean": 52.06660842895508, "eval/prior_ent_min": 49.31109619140625, "eval/prior_ent_std": 1.283129334449768, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00022940593771636486, "eval/reward_loss_std": 0.0041116988286376, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.04995548725128174, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00022940593771636486, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 9.851926006376743e-05, "eval/reward_rate": 0.0, "replay/size": 445417.0, "replay/inserts": 31808.0, "replay/samples": 31808.0, "replay/insert_wait_avg": 1.4615880411635462e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.786081590403014e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2834794855348154e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1541278362274, "timer/env.step_count": 7952.0, "timer/env.step_total": 36.35732078552246, "timer/env.step_frac": 0.036351717973888, "timer/env.step_avg": 0.004572097684296084, "timer/env.step_min": 0.003350496292114258, "timer/env.step_max": 0.02943253517150879, "timer/replay._sample_count": 31808.0, "timer/replay._sample_total": 15.743754148483276, "timer/replay._sample_frac": 0.01574132797166366, "timer/replay._sample_avg": 0.0004949620896781714, "timer/replay._sample_min": 0.0003578662872314453, "timer/replay._sample_max": 0.010804414749145508, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9608.0, "timer/agent.policy_total": 86.83608794212341, "timer/agent.policy_frac": 0.08682270614628967, "timer/agent.policy_avg": 0.009037894248763886, "timer/agent.policy_min": 0.008024930953979492, "timer/agent.policy_max": 0.03876781463623047, "timer/dataset_train_count": 1988.0, "timer/dataset_train_total": 0.20526528358459473, "timer/dataset_train_frac": 0.00020523365136598863, "timer/dataset_train_avg": 0.00010325215472062109, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.0005500316619873047, "timer/agent.train_count": 1988.0, "timer/agent.train_total": 862.2923967838287, "timer/agent.train_frac": 0.8621595140034525, "timer/agent.train_avg": 0.4337486905351251, "timer/agent.train_min": 0.4229092597961426, "timer/agent.train_max": 1.7531609535217285, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4821629524230957, "timer/agent.report_frac": 0.0004820886491427335, "timer/agent.report_avg": 0.24108147621154785, "timer/agent.report_min": 0.23660612106323242, "timer/agent.report_max": 0.24555683135986328, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.66987658363667e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 31.802500825653357}
{"step": 446680, "time": 14226.119020462036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446760, "time": 14228.716035604477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446796, "time": 14230.131353378296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446936, "time": 14234.070496559143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447836, "time": 14261.877635717392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447916, "time": 14264.314707040787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447952, "time": 14265.329637527466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448092, "time": 14269.707807779312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448992, "time": 14297.12227487564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449072, "time": 14299.592386245728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449108, "time": 14300.586150884628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449248, "time": 14304.97303724289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450060, "time": 14334.274106264114, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450060, "time": 14334.280087709427, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450060, "time": 14334.286041736603, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450060, "time": 14334.29132771492, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450060, "time": 14338.175942659378, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450060, "time": 14338.182003259659, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450060, "time": 14338.187649726868, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450060, "time": 14338.193275690079, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450148, "time": 14340.678762435913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450228, "time": 14343.16983294487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450264, "time": 14344.160864591599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450404, "time": 14348.532924175262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451304, "time": 14376.086455583572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451384, "time": 14378.539448976517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451420, "time": 14379.96205163002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451560, "time": 14383.915176153183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452460, "time": 14411.755576133728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452540, "time": 14414.201410770416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452576, "time": 14415.201452493668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452716, "time": 14419.589925765991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453616, "time": 14446.965894699097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453696, "time": 14449.41021680832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453732, "time": 14450.419853925705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453872, "time": 14454.810528755188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454772, "time": 14482.181175231934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454852, "time": 14484.636009454727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454888, "time": 14485.625121355057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455028, "time": 14490.177348852158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455928, "time": 14517.660091876984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456008, "time": 14520.147794246674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456044, "time": 14521.63165974617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456184, "time": 14525.596779823303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457084, "time": 14553.450809001923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457164, "time": 14555.889852046967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457200, "time": 14556.894899129868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457340, "time": 14561.297554731369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458240, "time": 14588.730435609818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458320, "time": 14591.17037653923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458356, "time": 14592.17823600769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458496, "time": 14596.545027256012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459396, "time": 14624.074510335922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459476, "time": 14626.518908500671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459512, "time": 14627.512511730194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459652, "time": 14631.90837430954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460060, "time": 14648.528934955597, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460060, "time": 14648.53485417366, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460060, "time": 14648.54029583931, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460060, "time": 14648.545806646347, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460060, "time": 14652.620509624481, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460060, "time": 14652.626673936844, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460060, "time": 14652.632081747055, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460060, "time": 14652.637462377548, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460552, "time": 14667.301552295685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460632, "time": 14669.7673766613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460668, "time": 14671.206453084946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460808, "time": 14675.149394273758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461708, "time": 14703.106341362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461788, "time": 14705.546511173248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461824, "time": 14706.544004201889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461964, "time": 14710.933557033539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462148, "time": 14716.301395177841, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 462944, "time": 14740.726912736893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462980, "time": 14741.731411933899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463048, "time": 14743.7362844944, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 463120, "time": 14746.321353912354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463304, "time": 14751.719741344452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463820, "time": 14767.775378465652, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 464136, "time": 14777.099692106247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464204, "time": 14779.501649618149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464460, "time": 14787.355944156647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464976, "time": 14803.061410665512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465292, "time": 14812.862128973007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465360, "time": 14814.827454090118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465616, "time": 14822.67813205719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466132, "time": 14838.328988313675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466448, "time": 14848.07553434372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466516, "time": 14850.057945013046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466772, "time": 14857.895241737366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467248, "time": 14872.709221601486, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 467368, "time": 14876.158519983292, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 467520, "time": 14881.02996468544, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 467672, "time": 14885.504405021667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467856, "time": 14891.364316940308, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 467928, "time": 14893.340323209763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468676, "time": 14916.319742918015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468712, "time": 14917.312789678574, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 468828, "time": 14921.187770605087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469012, "time": 14926.586458921432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469832, "time": 14951.61140871048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469868, "time": 14953.052745103836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469984, "time": 14956.466990470886, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 469984, "time": 14956.47383928299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470060, "time": 14962.691076278687, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470060, "time": 14962.697066783905, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470060, "time": 14962.702724933624, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470060, "time": 14962.708281040192, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470060, "time": 14966.46439242363, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470060, "time": 14966.470375537872, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470060, "time": 14966.475860595703, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470060, "time": 14966.481237649918, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470168, "time": 14969.431447029114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470656, "time": 14984.56557917595, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 470924, "time": 14992.81372642517, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 470988, "time": 14994.783450126648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471140, "time": 14999.185776472092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471812, "time": 15019.910310983658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472080, "time": 15028.19495177269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472144, "time": 15030.17550945282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472296, "time": 15034.64252448082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472968, "time": 15055.141798257828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473236, "time": 15063.46787571907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473300, "time": 15065.431461572647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473452, "time": 15070.297197580338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474124, "time": 15090.826460838318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474260, "time": 15094.826035737991, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 474456, "time": 15100.683913946152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474608, "time": 15105.54449558258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475280, "time": 15126.042504549026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475416, "time": 15130.167099237442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475612, "time": 15136.471697330475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475764, "time": 15140.92326760292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476264, "time": 15156.123120069504, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 476436, "time": 15161.50380063057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476768, "time": 15171.767815589905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476920, "time": 15176.21534538269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477420, "time": 15191.907636642456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477532, "time": 15195.335216522217, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 477785, "time": 15203.725916862488, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9720232019472363, "train/action_min": 0.0, "train/action_std": 1.7373472679799526, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010077349746824433, "train/actor_opt_grad_steps": 28770.0, "train/actor_opt_loss": -2.3107238026270314, "train/adv_mag": 0.36026000587185425, "train/adv_max": 0.20347613216045513, "train/adv_mean": 0.005656600926889969, "train/adv_min": -0.26813317872771064, "train/adv_std": 0.02570654750899903, "train/cont_avg": 0.9957944016959799, "train/cont_loss_mean": 0.023218641959683005, "train/cont_loss_std": 0.30888000652006825, "train/cont_neg_acc": 0.04160654232508004, "train/cont_neg_loss": 4.6392569999502165, "train/cont_pos_acc": 0.9999556152065795, "train/cont_pos_loss": 0.0037498084866867667, "train/cont_pred": 0.996072276453277, "train/cont_rate": 0.9957944016959799, "train/dyn_loss_mean": 1.00009501998748, "train/dyn_loss_std": 0.0006522828636716714, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8251386975972497, "train/extr_critic_critic_opt_grad_steps": 28770.0, "train/extr_critic_critic_opt_loss": 9500.03626531093, "train/extr_critic_mag": 0.6364070177078247, "train/extr_critic_max": 0.6364070177078247, "train/extr_critic_mean": 0.6072978167677644, "train/extr_critic_min": 0.5745184703088885, "train/extr_critic_std": 0.012294494627680086, "train/extr_return_normed_mag": 0.3699767943003669, "train/extr_return_normed_max": 0.24781071780314998, "train/extr_return_normed_mean": 0.034688528569534555, "train/extr_return_normed_min": -0.2339753005372819, "train/extr_return_normed_std": 0.030598902106097895, "train/extr_return_rate": 0.999201105767159, "train/extr_return_raw_mag": 0.8260766264781281, "train/extr_return_raw_max": 0.8260766264781281, "train/extr_return_raw_mean": 0.6129544673852585, "train/extr_return_raw_min": 0.34429060813769624, "train/extr_return_raw_std": 0.030598902045257725, "train/extr_reward_mag": 0.2199865627528435, "train/extr_reward_max": 0.2199865627528435, "train/extr_reward_mean": 0.0019554711120667776, "train/extr_reward_min": 4.738419499229546e-07, "train/extr_reward_std": 0.011341950811396573, "train/image_loss_mean": 0.12754578233214478, "train/image_loss_std": 0.1081950314829697, "train/model_loss_mean": 0.7554009976099484, "train/model_loss_std": 0.3995340265820374, "train/model_opt_grad_norm": 26.80699304360241, "train/model_opt_grad_steps": 28744.040201005024, "train/model_opt_loss": 2399.4789106666144, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3178.391959798995, "train/policy_entropy_mag": 1.5318403567501049, "train/policy_entropy_max": 1.5318403567501049, "train/policy_entropy_mean": 0.34447285233430525, "train/policy_entropy_min": 0.06469305305175446, "train/policy_entropy_std": 0.27380169718409303, "train/policy_logprob_mag": 6.5510570775324375, "train/policy_logprob_max": -0.008609321417670754, "train/policy_logprob_mean": -0.343879790761363, "train/policy_logprob_min": -6.5510570775324375, "train/policy_logprob_std": 0.7831461414619906, "train/policy_randomness_mag": 0.7872102670933134, "train/policy_randomness_max": 0.7872102670933134, "train/policy_randomness_mean": 0.17702403709517053, "train/policy_randomness_min": 0.03324565469245216, "train/policy_randomness_std": 0.14070624678428448, "train/post_ent_mag": 53.53578812872345, "train/post_ent_max": 53.53578812872345, "train/post_ent_mean": 52.79781439316333, "train/post_ent_min": 52.080574304015194, "train/post_ent_std": 0.27455857306269543, "train/prior_ent_mag": 54.91767599594653, "train/prior_ent_max": 54.91767599594653, "train/prior_ent_mean": 51.63461575915466, "train/prior_ent_min": 49.035881866761784, "train/prior_ent_std": 0.9563224573231223, "train/rep_loss_mean": 1.00009501998748, "train/rep_loss_std": 0.0006522828636716714, "train/reward_avg": 0.00046161287509539076, "train/reward_loss_mean": 0.004579541327820239, "train/reward_loss_std": 0.10729775536804222, "train/reward_max_data": 0.348304020624664, "train/reward_max_pred": 0.04172780825265089, "train/reward_neg_acc": 0.9999508923621633, "train/reward_neg_loss": 0.0006678398747123478, "train/reward_pos_acc": 0.07110091770460847, "train/reward_pos_loss": 5.364269492823049, "train/reward_pred": 0.0003395608852116681, "train/reward_rate": 0.0007410097361809045, "train_stats/mean_log_entropy": 0.20436247626076573, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.022241415455937386, "report/cont_loss_std": 0.3021227717399597, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.9413726329803467, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030111356172710657, "report/cont_pred": 0.9966074228286743, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09377577900886536, "report/image_loss_std": 0.09617555886507034, "report/model_loss_mean": 0.718528687953949, "report/model_loss_std": 0.3335350751876831, "report/post_ent_mag": 48.91925811767578, "report/post_ent_max": 48.91925811767578, "report/post_ent_mean": 47.89170837402344, "report/post_ent_min": 47.06148910522461, "report/post_ent_std": 0.31500551104545593, "report/prior_ent_mag": 52.73967361450195, "report/prior_ent_max": 52.73967361450195, "report/prior_ent_mean": 48.708885192871094, "report/prior_ent_min": 44.634986877441406, "report/prior_ent_std": 1.3350547552108765, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004058837948832661, "report/reward_loss_mean": 0.0025114708114415407, "report/reward_loss_std": 0.06511624902486801, "report/reward_max_data": 0.4156250059604645, "report/reward_max_pred": 0.2307145595550537, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00047724455362185836, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 2.0835249423980713, "report/reward_pred": 0.0004750123480334878, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02440628968179226, "eval/cont_loss_std": 0.3920551836490631, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.136735439300537, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.0035081629175692797, "eval/cont_pred": 0.9968083500862122, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19718588888645172, "eval/image_loss_std": 0.1412968635559082, "eval/model_loss_mean": 0.8216364979743958, "eval/model_loss_std": 0.4127684533596039, "eval/post_ent_mag": 48.921470642089844, "eval/post_ent_max": 48.921470642089844, "eval/post_ent_mean": 47.73584747314453, "eval/post_ent_min": 46.98352813720703, "eval/post_ent_std": 0.3268088102340698, "eval/prior_ent_mag": 51.289710998535156, "eval/prior_ent_max": 51.289710998535156, "eval/prior_ent_mean": 48.13416290283203, "eval/prior_ent_min": 44.82731628417969, "eval/prior_ent_std": 1.1368598937988281, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 4.429696127772331e-05, "eval/reward_loss_std": 0.00026069869636557996, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0018182992935180664, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 4.429696127772331e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.2697611711919308e-05, "eval/reward_rate": 0.0, "replay/size": 477273.0, "replay/inserts": 31856.0, "replay/samples": 31856.0, "replay/insert_wait_avg": 1.463165299967867e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.760503793828514e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2346479994477973e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2065362930298, "timer/env.step_count": 7964.0, "timer/env.step_total": 36.302489042282104, "timer/env.step_frac": 0.036294992809011786, "timer/env.step_avg": 0.004558323586424172, "timer/env.step_min": 0.0034689903259277344, "timer/env.step_max": 0.03087615966796875, "timer/replay._sample_count": 31856.0, "timer/replay._sample_total": 15.592589378356934, "timer/replay._sample_frac": 0.015589369607747478, "timer/replay._sample_avg": 0.0004894710377435, "timer/replay._sample_min": 0.0003790855407714844, "timer/replay._sample_max": 0.02826404571533203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9698.0, "timer/agent.policy_total": 87.40691494941711, "timer/agent.policy_frac": 0.08738886597698615, "timer/agent.policy_avg": 0.009012880485607043, "timer/agent.policy_min": 0.007946968078613281, "timer/agent.policy_max": 0.04565143585205078, "timer/dataset_train_count": 1991.0, "timer/dataset_train_total": 0.22689199447631836, "timer/dataset_train_frac": 0.00022684514272144885, "timer/dataset_train_avg": 0.0001139588118916717, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.019959211349487305, "timer/agent.train_count": 1991.0, "timer/agent.train_total": 861.4351613521576, "timer/agent.train_frac": 0.8612572804661052, "timer/agent.train_avg": 0.4326645712466889, "timer/agent.train_min": 0.42026185989379883, "timer/agent.train_max": 0.5043973922729492, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4812192916870117, "timer/agent.report_frac": 0.00048111992296162045, "timer/agent.report_avg": 0.24060964584350586, "timer/agent.report_min": 0.2346506118774414, "timer/agent.report_max": 0.2465686798095703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.1219253540039062e-05, "timer/dataset_eval_frac": 2.1214871899039933e-08, "timer/dataset_eval_avg": 2.1219253540039062e-05, "timer/dataset_eval_min": 2.1219253540039062e-05, "timer/dataset_eval_max": 2.1219253540039062e-05, "fps": 31.848860601349077}
{"step": 477924, "time": 15207.807706832886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478076, "time": 15212.676074266434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478204, "time": 15216.556349277496, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 478576, "time": 15227.740935325623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478688, "time": 15231.159650087357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479080, "time": 15242.949267148972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479360, "time": 15251.736909866333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479732, "time": 15263.118917226791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479844, "time": 15266.52652645111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480060, "time": 15277.22179722786, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480060, "time": 15277.228039264679, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480060, "time": 15277.234279632568, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480060, "time": 15277.239703655243, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480060, "time": 15281.36360859871, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480060, "time": 15281.369570970535, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480060, "time": 15281.374704360962, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480060, "time": 15281.379954099655, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480236, "time": 15286.739972829819, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480516, "time": 15295.099480628967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480888, "time": 15306.382277965546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481000, "time": 15309.812511205673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481392, "time": 15322.047107696533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481656, "time": 15329.92397069931, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 481672, "time": 15330.419617891312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482044, "time": 15342.090709924698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482548, "time": 15357.137374162674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482812, "time": 15365.454272031784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482828, "time": 15365.964476823807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483020, "time": 15371.841001033783, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 483704, "time": 15392.57231426239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483968, "time": 15400.81338429451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483984, "time": 15401.31060385704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484176, "time": 15407.184903860092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484272, "time": 15410.131168365479, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 484796, "time": 15426.29951620102, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 485124, "time": 15436.088886976242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485256, "time": 15440.025309324265, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 485332, "time": 15442.489813566208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485428, "time": 15445.42558646202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486280, "time": 15471.499819040298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486412, "time": 15475.882267713547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486488, "time": 15477.889123916626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486584, "time": 15480.852098226547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487436, "time": 15507.390877485275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487568, "time": 15511.389832735062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487644, "time": 15513.833138227463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487740, "time": 15516.930704593658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488592, "time": 15542.919337749481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488724, "time": 15546.825781345367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488800, "time": 15549.26897096634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488896, "time": 15552.207355499268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489252, "time": 15562.960270166397, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 489748, "time": 15578.098713159561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489956, "time": 15584.432584285736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490052, "time": 15587.35839176178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490060, "time": 15591.563887834549, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490060, "time": 15591.569805145264, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490060, "time": 15591.575319290161, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490060, "time": 15591.580819368362, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490060, "time": 15595.346605300903, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490060, "time": 15595.352510929108, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490060, "time": 15595.3580160141, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490060, "time": 15595.36336684227, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490408, "time": 15605.622194290161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490904, "time": 15620.748220920563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491112, "time": 15627.076966047287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491208, "time": 15630.04017329216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491564, "time": 15641.261934041977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492060, "time": 15656.562478780746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492268, "time": 15662.928461790085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492364, "time": 15665.828122377396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492436, "time": 15667.813473463058, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 493216, "time": 15691.67828464508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493424, "time": 15698.025971889496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493520, "time": 15700.958623886108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493592, "time": 15702.957090854645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493696, "time": 15706.328336238861, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 493944, "time": 15713.689509391785, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 494372, "time": 15726.869481801987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494580, "time": 15733.192666769028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494748, "time": 15738.580637216568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495100, "time": 15749.343423366547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495528, "time": 15762.121507883072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495736, "time": 15768.485188007355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495904, "time": 15774.00307917595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496256, "time": 15784.863238334656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496684, "time": 15798.044981241226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496892, "time": 15804.391641139984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497060, "time": 15809.293246984482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497412, "time": 15820.03536939621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497840, "time": 15833.208810567856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498048, "time": 15839.547109365463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498216, "time": 15844.478903532028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498568, "time": 15855.22618985176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498996, "time": 15868.458272218704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499204, "time": 15874.88878250122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499372, "time": 15880.251417398453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499724, "time": 15891.004813671112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500036, "time": 15900.508441448212, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 500060, "time": 15905.453929185867, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500060, "time": 15905.480521917343, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500060, "time": 15905.503099918365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500060, "time": 15905.515483379364, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500060, "time": 15909.398973941803, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500060, "time": 15909.405007600784, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500060, "time": 15909.410402059555, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500060, "time": 15909.415609836578, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500152, "time": 15911.921965360641, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500360, "time": 15918.268276453018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500880, "time": 15934.376335859299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501192, "time": 15943.67695260048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501308, "time": 15947.54055762291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501516, "time": 15953.904476881027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501900, "time": 15965.738785505295, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 502036, "time": 15969.679725646973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502348, "time": 15979.495094060898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502672, "time": 15989.319844007492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503056, "time": 16001.083592891693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503192, "time": 16004.9955368042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503504, "time": 16014.708829402924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503828, "time": 16024.55885720253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504212, "time": 16036.389051675797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504348, "time": 16040.74736070633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504660, "time": 16050.020260095596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504984, "time": 16059.75351691246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505368, "time": 16071.437656641006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505504, "time": 16075.837029218674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505816, "time": 16085.273131847382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506140, "time": 16095.487295627594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506524, "time": 16107.23129606247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506660, "time": 16111.197211503983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506972, "time": 16120.851904392242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507296, "time": 16130.581605672836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507680, "time": 16142.31398677826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507816, "time": 16146.259490966797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 508128, "time": 16155.960010051727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 508452, "time": 16165.873832702637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 508836, "time": 16177.649182796478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 508972, "time": 16182.052925348282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509284, "time": 16191.35505604744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509608, "time": 16201.200899839401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509673, "time": 16204.137395381927, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5617718720555906, "train/action_min": 0.0, "train/action_std": 1.3080749017509383, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009523988960558857, "train/actor_opt_grad_steps": 30760.0, "train/actor_opt_loss": -6.490720699068589, "train/adv_mag": 0.475903300783742, "train/adv_max": 0.17390150969950996, "train/adv_mean": 0.0003675665089146272, "train/adv_min": -0.4401352552313301, "train/adv_std": 0.02639009753574416, "train/cont_avg": 0.996113379396985, "train/cont_loss_mean": 0.01845629844491618, "train/cont_loss_std": 0.2660581464879215, "train/cont_neg_acc": 0.16823372419695465, "train/cont_neg_loss": 3.924521307175865, "train/cont_pos_acc": 0.9999063901565782, "train/cont_pos_loss": 0.0032127812936499564, "train/cont_pred": 0.9962340835949883, "train/cont_rate": 0.996113379396985, "train/dyn_loss_mean": 1.0000106407769362, "train/dyn_loss_std": 0.0001964029361626681, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.529235220912039, "train/extr_critic_critic_opt_grad_steps": 30760.0, "train/extr_critic_critic_opt_loss": 11981.246724344379, "train/extr_critic_mag": 0.7398033495524421, "train/extr_critic_max": 0.7398033495524421, "train/extr_critic_mean": 0.6940011376112549, "train/extr_critic_min": 0.6697374264798571, "train/extr_critic_std": 0.012028929633533011, "train/extr_return_normed_mag": 0.46585918011976846, "train/extr_return_normed_max": 0.22183545330661025, "train/extr_return_normed_mean": 0.026464973797205013, "train/extr_return_normed_min": -0.4009101294991958, "train/extr_return_normed_std": 0.030150638656906, "train/extr_return_rate": 0.9965158152819877, "train/extr_return_raw_mag": 0.8897391644554522, "train/extr_return_raw_max": 0.8897391644554522, "train/extr_return_raw_mean": 0.6943687164603766, "train/extr_return_raw_min": 0.2669935816496461, "train/extr_return_raw_std": 0.030150638401845294, "train/extr_reward_mag": 0.19122871561865112, "train/extr_reward_max": 0.19122871561865112, "train/extr_reward_mean": 0.0017462169275562125, "train/extr_reward_min": 4.546726169298642e-07, "train/extr_reward_std": 0.00962820837583367, "train/image_loss_mean": 0.1251035455483288, "train/image_loss_std": 0.10931692418441101, "train/model_loss_mean": 0.7471137723731036, "train/model_loss_std": 0.3455882915974262, "train/model_opt_grad_norm": 24.672161950537905, "train/model_opt_grad_steps": 30732.78894472362, "train/model_opt_loss": 2634.398284758755, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3530.1507537688444, "train/policy_entropy_mag": 1.375956360419192, "train/policy_entropy_max": 1.375956360419192, "train/policy_entropy_mean": 0.1881474546301904, "train/policy_entropy_min": 0.0646871105210865, "train/policy_entropy_std": 0.21799599952134655, "train/policy_logprob_mag": 6.551078647824388, "train/policy_logprob_max": -0.008608337037789461, "train/policy_logprob_mean": -0.18733023384108616, "train/policy_logprob_min": -6.551078647824388, "train/policy_logprob_std": 0.7081125375613495, "train/policy_randomness_mag": 0.7071017347388531, "train/policy_randomness_max": 0.7071017347388531, "train/policy_randomness_mean": 0.09668867061635357, "train/policy_randomness_min": 0.03324260089041001, "train/policy_randomness_std": 0.11202778910572206, "train/post_ent_mag": 51.03005423617722, "train/post_ent_max": 51.03005423617722, "train/post_ent_mean": 49.9720683265571, "train/post_ent_min": 49.19108752150032, "train/post_ent_std": 0.3426805216463367, "train/prior_ent_mag": 52.10538808544676, "train/prior_ent_max": 52.10538808544676, "train/prior_ent_mean": 48.570705432987694, "train/prior_ent_min": 45.92371652114331, "train/prior_ent_std": 0.9773236378353445, "train/rep_loss_mean": 1.0000106407769362, "train/rep_loss_std": 0.0001964029361626681, "train/reward_avg": 0.0003740626975809734, "train/reward_loss_mean": 0.003547520546392355, "train/reward_loss_std": 0.08318820273215255, "train/reward_max_data": 0.29670226184567017, "train/reward_max_pred": 0.08237037886327235, "train/reward_neg_acc": 0.9998969169118297, "train/reward_neg_loss": 0.0006189019104156377, "train/reward_pos_acc": 0.21376811615798785, "train/reward_pos_loss": 4.726485438968824, "train/reward_pred": 0.0003263304640665351, "train/reward_rate": 0.0006232333542713568, "train_stats/mean_log_entropy": 0.13098683061762753, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.012183879502117634, "report/cont_loss_std": 0.2185453623533249, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 2.051504373550415, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0021773988846689463, "report/cont_pred": 0.9953051805496216, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12174741178750992, "report/image_loss_std": 0.1000746414065361, "report/model_loss_mean": 0.7341853976249695, "report/model_loss_std": 0.23917974531650543, "report/post_ent_mag": 50.011695861816406, "report/post_ent_max": 50.011695861816406, "report/post_ent_mean": 48.663787841796875, "report/post_ent_min": 47.74531555175781, "report/post_ent_std": 0.4179741144180298, "report/prior_ent_mag": 50.11716842651367, "report/prior_ent_max": 50.11716842651367, "report/prior_ent_mean": 47.06086730957031, "report/prior_ent_min": 44.674285888671875, "report/prior_ent_std": 0.8953851461410522, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00025410205125808716, "report/reward_loss_std": 0.0019207462901249528, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.016183018684387207, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00025410205125808716, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00012447708286345005, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03790382295846939, "eval/cont_loss_std": 0.5218278765678406, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.462388515472412, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0014735730364918709, "eval/cont_pred": 0.9985368251800537, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0000061988830566, "eval/dyn_loss_std": 0.00019655461073853076, "eval/image_loss_mean": 0.1460368037223816, "eval/image_loss_std": 0.12489520758390427, "eval/model_loss_mean": 0.784014105796814, "eval/model_loss_std": 0.5361716151237488, "eval/post_ent_mag": 50.00657653808594, "eval/post_ent_max": 50.00657653808594, "eval/post_ent_mean": 48.64714813232422, "eval/post_ent_min": 47.84423828125, "eval/post_ent_std": 0.4113280773162842, "eval/prior_ent_mag": 49.878822326660156, "eval/prior_ent_max": 49.878822326660156, "eval/prior_ent_mean": 46.87748718261719, "eval/prior_ent_min": 44.53215026855469, "eval/prior_ent_std": 0.8996201157569885, "eval/rep_loss_mean": 1.0000061988830566, "eval/rep_loss_std": 0.00019655461073853076, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 6.982032209634781e-05, "eval/reward_loss_std": 0.0006631120340898633, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.008639693260192871, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 6.982032209634781e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.245414700359106e-05, "eval/reward_rate": 0.0, "replay/size": 509161.0, "replay/inserts": 31888.0, "replay/samples": 31888.0, "replay/insert_wait_avg": 1.4736224106072302e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.719519266338128e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.9356384959325385e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.6987323760986328e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3952226638794, "timer/env.step_count": 7972.0, "timer/env.step_total": 36.24458193778992, "timer/env.step_frac": 0.036230262916766905, "timer/env.step_avg": 0.0045464854412681785, "timer/env.step_min": 0.003360271453857422, "timer/env.step_max": 0.01896357536315918, "timer/replay._sample_count": 31888.0, "timer/replay._sample_total": 15.427182912826538, "timer/replay._sample_frac": 0.015421088149288257, "timer/replay._sample_avg": 0.0004837927406179923, "timer/replay._sample_min": 0.00039887428283691406, "timer/replay._sample_max": 0.011105537414550781, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9706.0, "timer/agent.policy_total": 87.48976349830627, "timer/agent.policy_frac": 0.08745519922149984, "timer/agent.policy_avg": 0.009013987584824466, "timer/agent.policy_min": 0.008033514022827148, "timer/agent.policy_max": 0.04082989692687988, "timer/dataset_train_count": 1993.0, "timer/dataset_train_total": 0.20812559127807617, "timer/dataset_train_frac": 0.00020804336782404232, "timer/dataset_train_avg": 0.00010442829467038443, "timer/dataset_train_min": 8.487701416015625e-05, "timer/dataset_train_max": 0.00549626350402832, "timer/agent.train_count": 1993.0, "timer/agent.train_total": 861.6651048660278, "timer/agent.train_frac": 0.8613246898276491, "timer/agent.train_avg": 0.4323457626021213, "timer/agent.train_min": 0.4197673797607422, "timer/agent.train_max": 0.5139741897583008, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48005056381225586, "timer/agent.report_frac": 0.0004798609119043614, "timer/agent.report_avg": 0.24002528190612793, "timer/agent.report_min": 0.23334980010986328, "timer/agent.report_max": 0.24670076370239258, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.5977358281329817e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 31.87484655233383}
{"step": 509992, "time": 16213.602731704712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510060, "time": 16219.805394172668, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510060, "time": 16219.811126947403, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510060, "time": 16219.81705236435, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510060, "time": 16219.823213815689, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510060, "time": 16223.668196201324, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510060, "time": 16223.674219369888, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510060, "time": 16223.679622411728, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510060, "time": 16223.684938430786, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510128, "time": 16225.648544311523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510440, "time": 16235.00228047371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510764, "time": 16245.166427612305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511148, "time": 16256.795057058334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511284, "time": 16260.685447454453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511596, "time": 16270.420439720154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511920, "time": 16280.21120429039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512304, "time": 16292.192723751068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512440, "time": 16296.161123752594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512752, "time": 16305.949316263199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513076, "time": 16315.73568868637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513460, "time": 16327.531939268112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513596, "time": 16331.942278862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513908, "time": 16341.265191316605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514232, "time": 16351.163293123245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514336, "time": 16354.588867425919, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 514616, "time": 16362.958344697952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514752, "time": 16367.341269254684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515064, "time": 16376.655721664429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515492, "time": 16389.932846307755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515632, "time": 16394.335067987442, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 515772, "time": 16398.736423254013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515828, "time": 16400.246517419815, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 515908, "time": 16402.684421777725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516648, "time": 16425.406869649887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516928, "time": 16434.201313972473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516940, "time": 16434.679894924164, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 516984, "time": 16435.707074403763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517064, "time": 16438.160493135452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518084, "time": 16469.570831775665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518096, "time": 16470.055417776108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518140, "time": 16471.556483745575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518220, "time": 16474.027827739716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519240, "time": 16504.895438432693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519252, "time": 16505.377105474472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519296, "time": 16506.828594446182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519376, "time": 16509.28479027748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520060, "time": 16532.26557636261, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 520060, "time": 16534.67402791977, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520060, "time": 16534.680067062378, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520060, "time": 16534.685604572296, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520060, "time": 16536.487674474716, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520060, "time": 16538.60122847557, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520060, "time": 16538.60737490654, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520060, "time": 16538.613043546677, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520396, "time": 16548.920860528946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520408, "time": 16548.969571113586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520452, "time": 16550.516610860825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520532, "time": 16553.05846786499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521552, "time": 16584.421050071716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521564, "time": 16584.895940303802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521608, "time": 16585.914442062378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521688, "time": 16588.359492778778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522708, "time": 16619.706293821335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522720, "time": 16620.1916847229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522764, "time": 16621.679074287415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522844, "time": 16624.13938140869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523864, "time": 16655.156424999237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523876, "time": 16655.64063644409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523920, "time": 16657.10103869438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524000, "time": 16659.571121692657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525020, "time": 16691.112784147263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525032, "time": 16691.161521434784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525076, "time": 16692.64306139946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525156, "time": 16695.090871810913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526176, "time": 16726.467992782593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526188, "time": 16726.961471557617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526232, "time": 16727.982521772385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526312, "time": 16730.438722610474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527332, "time": 16761.836883306503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527344, "time": 16762.32412171364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527388, "time": 16763.786094665527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527468, "time": 16766.245655059814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528488, "time": 16797.17285013199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528500, "time": 16797.658714532852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528544, "time": 16799.119235754013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528624, "time": 16801.658992528915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529644, "time": 16833.135154485703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529656, "time": 16833.185299396515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529700, "time": 16834.639882087708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529780, "time": 16837.087682724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530060, "time": 16849.810863018036, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530060, "time": 16849.816911697388, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530060, "time": 16849.822268009186, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530060, "time": 16849.827678442, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530060, "time": 16853.5748295784, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530060, "time": 16853.580602169037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530060, "time": 16853.586198568344, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530060, "time": 16853.59215092659, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530680, "time": 16872.315557956696, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 530800, "time": 16876.190390110016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530812, "time": 16876.672578573227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530856, "time": 16877.718547344208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531836, "time": 16908.13422226906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531956, "time": 16911.630131959915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531968, "time": 16912.11221265793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532012, "time": 16913.563702344894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532992, "time": 16943.62842941284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533112, "time": 16947.093200683594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533124, "time": 16947.57198905945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533168, "time": 16949.029682397842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534148, "time": 16978.86643409729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534268, "time": 16982.85886144638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534280, "time": 16982.91134262085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534324, "time": 16984.365230321884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535304, "time": 17014.310044765472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535424, "time": 17018.206145763397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535436, "time": 17018.68487930298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535480, "time": 17019.726632356644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536460, "time": 17050.203485250473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536580, "time": 17053.649160385132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536592, "time": 17054.143463134766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536636, "time": 17055.603509902954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537616, "time": 17085.714742422104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537736, "time": 17089.19130706787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537748, "time": 17089.671359300613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537792, "time": 17091.121990203857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538772, "time": 17121.12223792076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538892, "time": 17125.04425215721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538904, "time": 17125.094933986664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538948, "time": 17126.564555883408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 539928, "time": 17156.563504695892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540048, "time": 17160.474907398224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540060, "time": 17160.95422387123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540060, "time": 17162.55167889595, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 540060, "time": 17164.85258936882, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 540060, "time": 17165.315851688385, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540060, "time": 17165.321804523468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540060, "time": 17165.327700138092, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540060, "time": 17166.419720888138, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 540060, "time": 17167.605348348618, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 540060, "time": 17169.25991845131, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540060, "time": 17169.266216278076, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540104, "time": 17170.293363809586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540480, "time": 17182.00391292572, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 541084, "time": 17200.769839525223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 541177, "time": 17204.213943719864, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5427314254838196, "train/action_min": 0.0, "train/action_std": 1.1674042643629354, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006223006568716716, "train/actor_opt_grad_steps": 32740.0, "train/actor_opt_loss": -8.318437124871966, "train/adv_mag": 0.3607397636181207, "train/adv_max": 0.16221342322790078, "train/adv_mean": -0.0015391106969176976, "train/adv_min": -0.3247965528880279, "train/adv_std": 0.01717119196046919, "train/cont_avg": 0.9962920368020305, "train/cont_loss_mean": 0.0152513577749357, "train/cont_loss_std": 0.22693393717704313, "train/cont_neg_acc": 0.26768443544293935, "train/cont_neg_loss": 3.2475447234715134, "train/cont_pos_acc": 0.9997959182347138, "train/cont_pos_loss": 0.003056990842542937, "train/cont_pred": 0.9961019820973352, "train/cont_rate": 0.9962920368020305, "train/dyn_loss_mean": 1.0000095331124244, "train/dyn_loss_std": 0.00021587919826775335, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.30046844391180627, "train/extr_critic_critic_opt_grad_steps": 32740.0, "train/extr_critic_critic_opt_loss": 8372.609455554013, "train/extr_critic_mag": 0.605665396917895, "train/extr_critic_max": 0.605665396917895, "train/extr_critic_mean": 0.5691181288152782, "train/extr_critic_min": 0.5444799891583205, "train/extr_critic_std": 0.008185390500011405, "train/extr_return_normed_mag": 0.35823253568658975, "train/extr_return_normed_max": 0.18575827694181257, "train/extr_return_normed_mean": 0.013394014248785476, "train/extr_return_normed_min": -0.3065037548844584, "train/extr_return_normed_std": 0.020081532057752916, "train/extr_return_rate": 0.9976972613842959, "train/extr_return_raw_mag": 0.7399432589559991, "train/extr_return_raw_max": 0.7399432589559991, "train/extr_return_raw_mean": 0.5675790231239978, "train/extr_return_raw_min": 0.24768122712972807, "train/extr_return_raw_std": 0.02008153219957869, "train/extr_reward_mag": 0.20575338692834536, "train/extr_reward_max": 0.20575338692834536, "train/extr_reward_mean": 0.0008740630448559626, "train/extr_reward_min": 3.170846077391339e-07, "train/extr_reward_std": 0.006592069688545029, "train/image_loss_mean": 0.11885477496585264, "train/image_loss_std": 0.10827279767863036, "train/model_loss_mean": 0.7378511595241914, "train/model_loss_std": 0.3165714971834633, "train/model_opt_grad_norm": 24.889451680449664, "train/model_opt_grad_steps": 32711.700507614212, "train/model_opt_loss": 2977.496780318052, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4035.532994923858, "train/policy_entropy_mag": 1.273345941214392, "train/policy_entropy_max": 1.273345941214392, "train/policy_entropy_mean": 0.18347190785680326, "train/policy_entropy_min": 0.0646866617469013, "train/policy_entropy_std": 0.21090995342598348, "train/policy_logprob_mag": 6.551079566103553, "train/policy_logprob_max": -0.008608217771888384, "train/policy_logprob_mean": -0.18315283394404475, "train/policy_logprob_min": -6.551079566103553, "train/policy_logprob_std": 0.7048574734460279, "train/policy_randomness_mag": 0.6543704080702689, "train/policy_randomness_max": 0.6543704080702689, "train/policy_randomness_mean": 0.09428591536462004, "train/policy_randomness_min": 0.03324237012015987, "train/policy_randomness_std": 0.10838628193448643, "train/post_ent_mag": 49.284186426153035, "train/post_ent_max": 49.284186426153035, "train/post_ent_mean": 47.8594161871121, "train/post_ent_min": 46.996917337330466, "train/post_ent_std": 0.42240577194896445, "train/prior_ent_mag": 49.58479328445977, "train/prior_ent_max": 49.58479328445977, "train/prior_ent_mean": 46.616336706326095, "train/prior_ent_min": 44.04882254818369, "train/prior_ent_std": 0.9815339666937813, "train/rep_loss_mean": 1.0000095331124244, "train/rep_loss_std": 0.00021587919826775335, "train/reward_avg": 0.0004395460749079289, "train/reward_loss_mean": 0.0037392839330820564, "train/reward_loss_std": 0.08833630026056936, "train/reward_max_data": 0.3444638329411521, "train/reward_max_pred": 0.11006733669242277, "train/reward_neg_acc": 0.9998313103835594, "train/reward_neg_loss": 0.000577841353098044, "train/reward_pos_acc": 0.31590909118002114, "train/reward_pos_loss": 4.2437468712980095, "train/reward_pred": 0.0003550454854804474, "train/reward_rate": 0.000753489847715736, "train_stats/mean_log_entropy": 0.12727497617847153, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.011056013405323029, "report/cont_loss_std": 0.19935669004917145, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.965505599975586, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00237496686168015, "report/cont_pred": 0.9966553449630737, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10434004664421082, "report/image_loss_std": 0.086752749979496, "report/model_loss_mean": 0.7159925699234009, "report/model_loss_std": 0.21590951085090637, "report/post_ent_mag": 49.27766418457031, "report/post_ent_max": 49.27766418457031, "report/post_ent_mean": 47.764366149902344, "report/post_ent_min": 46.91908645629883, "report/post_ent_std": 0.446860134601593, "report/prior_ent_mag": 48.8294677734375, "report/prior_ent_max": 48.8294677734375, "report/prior_ent_mean": 46.00404357910156, "report/prior_ent_min": 43.738704681396484, "report/prior_ent_std": 0.9428120851516724, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.000596512109041214, "report/reward_loss_std": 0.004463756922632456, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.04004859924316406, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000596512109041214, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00030086515471339226, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008210903033614159, "eval/cont_loss_std": 0.166720449924469, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.325191974639893, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0030134632252156734, "eval/cont_pred": 0.9970656633377075, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15719261765480042, "eval/image_loss_std": 0.11393338441848755, "eval/model_loss_mean": 0.7657073736190796, "eval/model_loss_std": 0.20140105485916138, "eval/post_ent_mag": 49.27839660644531, "eval/post_ent_max": 49.27839660644531, "eval/post_ent_mean": 47.63922882080078, "eval/post_ent_min": 46.90974426269531, "eval/post_ent_std": 0.42150673270225525, "eval/prior_ent_mag": 48.510643005371094, "eval/prior_ent_max": 48.510643005371094, "eval/prior_ent_mean": 45.68610382080078, "eval/prior_ent_min": 43.780250549316406, "eval/prior_ent_std": 0.8428186774253845, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0003038519062101841, "eval/reward_loss_std": 0.0027769291773438454, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.024816513061523438, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0003038519062101841, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001509947469457984, "eval/reward_rate": 0.0, "replay/size": 540665.0, "replay/inserts": 31504.0, "replay/samples": 31504.0, "replay/insert_wait_avg": 1.4748819713485975e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.745652346516575e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2686095848215492e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0576412677765, "timer/env.step_count": 7876.0, "timer/env.step_total": 35.870352268218994, "timer/env.step_frac": 0.035868284774811604, "timer/env.step_avg": 0.004554387032531615, "timer/env.step_min": 0.003545522689819336, "timer/env.step_max": 0.022188663482666016, "timer/replay._sample_count": 31504.0, "timer/replay._sample_total": 15.237144947052002, "timer/replay._sample_frac": 0.015236266709322696, "timer/replay._sample_avg": 0.0004836574703863637, "timer/replay._sample_min": 0.00038170814514160156, "timer/replay._sample_max": 0.030852556228637695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 10188.0, "timer/agent.policy_total": 92.38489866256714, "timer/agent.policy_frac": 0.09237957378681741, "timer/agent.policy_avg": 0.009068011254668938, "timer/agent.policy_min": 0.007987499237060547, "timer/agent.policy_max": 0.04792928695678711, "timer/dataset_train_count": 1969.0, "timer/dataset_train_total": 0.21757793426513672, "timer/dataset_train_frac": 0.00021756539352002992, "timer/dataset_train_avg": 0.00011050174416715932, "timer/dataset_train_min": 8.416175842285156e-05, "timer/dataset_train_max": 0.020379066467285156, "timer/agent.train_count": 1969.0, "timer/agent.train_total": 853.9573152065277, "timer/agent.train_frac": 0.8539080948613753, "timer/agent.train_avg": 0.4337010234670024, "timer/agent.train_min": 0.42206478118896484, "timer/agent.train_max": 0.5291659832000732, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48212432861328125, "timer/agent.report_frac": 0.0004820965399575274, "timer/agent.report_avg": 0.24106216430664062, "timer/agent.report_min": 0.2346959114074707, "timer/agent.report_max": 0.24742841720581055, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2411346435546875e-05, "timer/dataset_eval_frac": 2.2410054691583513e-08, "timer/dataset_eval_avg": 2.2411346435546875e-05, "timer/dataset_eval_min": 2.2411346435546875e-05, "timer/dataset_eval_max": 2.2411346435546875e-05, "fps": 31.50159249592472}
{"step": 541216, "time": 17205.347898721695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 541260, "time": 17206.81740641594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 541636, "time": 17218.077196598053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542240, "time": 17236.794486045837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542284, "time": 17238.251168489456, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 542372, "time": 17240.751301765442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542416, "time": 17242.218194007874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542600, "time": 17247.64333295822, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 542804, "time": 17254.116302728653, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 543024, "time": 17260.98316860199, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 543396, "time": 17272.281679868698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543572, "time": 17277.698171377182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543716, "time": 17282.176927804947, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 543816, "time": 17285.173634290695, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 543960, "time": 17289.616766691208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544032, "time": 17292.037562847137, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 544060, "time": 17292.9992146492, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 544156, "time": 17295.954777240753, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 544180, "time": 17296.47514796257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544516, "time": 17306.81407403946, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 544800, "time": 17315.66504049301, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 545188, "time": 17327.620291233063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545216, "time": 17328.59180188179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545336, "time": 17332.070038318634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545528, "time": 17337.968327760696, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 545664, "time": 17342.438264608383, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 545800, "time": 17346.4152200222, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 545956, "time": 17351.33203268051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545960, "time": 17351.35361981392, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 546144, "time": 17358.74960255623, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 546188, "time": 17360.22927570343, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 546372, "time": 17365.64386200905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 546564, "time": 17371.508640050888, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 546956, "time": 17383.717281103134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547000, "time": 17384.765285253525, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 547292, "time": 17394.024570703506, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 547300, "time": 17394.062891483307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547528, "time": 17400.93930864334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547576, "time": 17402.454200029373, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 548112, "time": 17419.09524178505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548324, "time": 17425.46847677231, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 548448, "time": 17429.382821559906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548460, "time": 17429.862898111343, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 548684, "time": 17436.792882442474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548696, "time": 17436.841883182526, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 548732, "time": 17438.27685022354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549008, "time": 17446.596325159073, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 549060, "time": 17448.08457303047, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 549300, "time": 17455.630609989166, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 549616, "time": 17465.421853780746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549888, "time": 17473.749891996384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550060, "time": 17479.733110666275, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 550060, "time": 17480.07819533348, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 550060, "time": 17480.17905139923, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 550060, "time": 17480.28059363365, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 550060, "time": 17481.019507408142, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 550060, "time": 17482.214431762695, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 550060, "time": 17483.080599546432, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550060, "time": 17483.60923218727, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 550216, "time": 17488.050656080246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550456, "time": 17495.460423231125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550772, "time": 17505.287225484848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551044, "time": 17513.61861371994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551372, "time": 17523.911655187607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551612, "time": 17531.243833065033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551712, "time": 17534.19513463974, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 551928, "time": 17540.66321182251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552120, "time": 17546.567811489105, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 552124, "time": 17547.02021598816, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 552200, "time": 17549.04954266548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552300, "time": 17552.467577695847, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 552544, "time": 17559.820875406265, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 552720, "time": 17565.195851802826, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 552768, "time": 17566.674433469772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553060, "time": 17575.511257648468, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 553356, "time": 17585.104691028595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553456, "time": 17588.07304406166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553876, "time": 17600.84806036949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554216, "time": 17611.205309152603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554512, "time": 17620.574132680893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554612, "time": 17623.5500831604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 555032, "time": 17636.40002632141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 555372, "time": 17647.276304006577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 555668, "time": 17656.163385629654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 555768, "time": 17659.131154060364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556188, "time": 17672.413642644882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556528, "time": 17682.76202249527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556824, "time": 17691.62983250618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556924, "time": 17695.01203894615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557344, "time": 17708.010977506638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557684, "time": 17718.293692350388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557980, "time": 17727.56977033615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558080, "time": 17730.544189214706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558500, "time": 17743.321746110916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558840, "time": 17753.652269124985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559136, "time": 17762.93352174759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559236, "time": 17765.894989728928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559656, "time": 17778.702741384506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559996, "time": 17789.448412418365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 560060, "time": 17791.734486341476, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 560060, "time": 17795.62367916107, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560060, "time": 17795.630243062973, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560060, "time": 17795.63729453087, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560060, "time": 17795.91860127449, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560060, "time": 17796.338371515274, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 560060, "time": 17799.49861907959, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560060, "time": 17799.50438475609, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560060, "time": 17799.50984477997, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560292, "time": 17806.413888931274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 560392, "time": 17809.36408829689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 560704, "time": 17819.141175031662, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 560812, "time": 17822.63910651207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561152, "time": 17833.039860010147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561156, "time": 17833.062575817108, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 561384, "time": 17839.95570397377, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 561812, "time": 17853.437970399857, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 561940, "time": 17857.379590511322, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 561968, "time": 17858.351467847824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562204, "time": 17865.73160648346, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 562312, "time": 17868.724306821823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562540, "time": 17876.0456430912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562592, "time": 17877.538737297058, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 562680, "time": 17880.02511358261, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 563360, "time": 17901.12266111374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563696, "time": 17911.44212460518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563748, "time": 17912.926504135132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563836, "time": 17915.835104703903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564240, "time": 17928.03334927559, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 564276, "time": 17929.044316768646, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 564852, "time": 17946.659831285477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564904, "time": 17948.14409685135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565396, "time": 17963.372913837433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565432, "time": 17964.37180185318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566008, "time": 17982.22821855545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566060, "time": 17984.17380452156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566408, "time": 17994.550803422928, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 566552, "time": 17999.021147966385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566588, "time": 18000.453491210938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566728, "time": 18004.447836875916, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 567216, "time": 18019.59122800827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 567564, "time": 18030.410220861435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 567744, "time": 18035.888810634613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 567884, "time": 18040.30218219757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568060, "time": 18045.72157239914, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 568372, "time": 18055.06513929367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568720, "time": 18065.88694024086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568896, "time": 18071.279027700424, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 568900, "time": 18071.301001548767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 569040, "time": 18075.717351675034, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 569076, "time": 18076.7281332016, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 569216, "time": 18081.12558913231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 569424, "time": 18087.507074832916, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 569876, "time": 18101.47668504715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570060, "time": 18111.303370714188, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570060, "time": 18111.31001472473, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570060, "time": 18111.316159963608, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570060, "time": 18111.321857213974, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570060, "time": 18115.266528606415, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570060, "time": 18115.27279138565, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570060, "time": 18115.278319597244, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570060, "time": 18115.283947229385, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570112, "time": 18116.77092218399, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 570196, "time": 18119.245943784714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570580, "time": 18131.05218744278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571032, "time": 18144.826454162598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571040, "time": 18145.294444322586, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 571196, "time": 18150.162333726883, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 571392, "time": 18156.08579301834, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 571736, "time": 18166.456861257553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571988, "time": 18174.307045936584, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 572196, "time": 18180.684243917465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572352, "time": 18185.630130290985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572548, "time": 18191.51942896843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572572, "time": 18192.479129076004, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 572696, "time": 18195.956582069397, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 572808, "time": 18199.40695142746, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 572920, "time": 18202.858077287674, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 572937, "time": 18204.34133386612, "train_stats/mean_log_entropy": 0.08634003555696261, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.765067095732569, "train/action_min": 0.0, "train/action_std": 1.474072710952567, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0073680802074087845, "train/actor_opt_grad_steps": 34720.0, "train/actor_opt_loss": -4.450533736141483, "train/adv_mag": 0.5501065508804129, "train/adv_max": 0.27522947231129785, "train/adv_mean": 0.001256541438645276, "train/adv_min": -0.5269072675824764, "train/adv_std": 0.025026302319020033, "train/cont_avg": 0.9959759736180904, "train/cont_loss_mean": 0.014678821729346361, "train/cont_loss_std": 0.2273040900320451, "train/cont_neg_acc": 0.38501483642242174, "train/cont_neg_loss": 2.882609724321149, "train/cont_pos_acc": 0.9997091374205584, "train/cont_pos_loss": 0.0029509196329356438, "train/cont_pred": 0.995873773816842, "train/cont_rate": 0.9959759736180904, "train/dyn_loss_mean": 1.0000051972854078, "train/dyn_loss_std": 0.00016500255685000114, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5280641049858014, "train/extr_critic_critic_opt_grad_steps": 34720.0, "train/extr_critic_critic_opt_loss": 5041.109989645493, "train/extr_critic_mag": 0.6588047509217382, "train/extr_critic_max": 0.6588047509217382, "train/extr_critic_mean": 0.6119054193472743, "train/extr_critic_min": 0.5887174103128251, "train/extr_critic_std": 0.00883111943743524, "train/extr_return_normed_mag": 0.5367975303875142, "train/extr_return_normed_max": 0.3174622463221526, "train/extr_return_normed_mean": 0.0209980496205682, "train/extr_return_normed_min": -0.5030949058844216, "train/extr_return_normed_std": 0.027226653359549578, "train/extr_return_rate": 0.9973827917971204, "train/extr_return_raw_mag": 0.9096261367725966, "train/extr_return_raw_max": 0.9096261367725966, "train/extr_return_raw_mean": 0.6131619721201796, "train/extr_return_raw_min": 0.0890689845660224, "train/extr_return_raw_std": 0.027226653556110123, "train/extr_reward_mag": 0.36412128671329824, "train/extr_reward_max": 0.36412128671329824, "train/extr_reward_mean": 0.0014089805804703142, "train/extr_reward_min": 3.761981599894001e-07, "train/extr_reward_std": 0.009552425079529721, "train/image_loss_mean": 0.11143457676148295, "train/image_loss_std": 0.10569644026720344, "train/model_loss_mean": 0.7297279274643366, "train/model_loss_std": 0.3139888898062347, "train/model_opt_grad_norm": 23.45031794351549, "train/model_opt_grad_steps": 34689.70854271357, "train/model_opt_loss": 2391.126066121624, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3291.457286432161, "train/policy_entropy_mag": 1.3716959360256866, "train/policy_entropy_max": 1.3716959360256866, "train/policy_entropy_mean": 0.1365664272227479, "train/policy_entropy_min": 0.06468656872534871, "train/policy_entropy_std": 0.1712204456029825, "train/policy_logprob_mag": 6.551080188559528, "train/policy_logprob_max": -0.008608140903127254, "train/policy_logprob_mean": -0.1357030854303034, "train/policy_logprob_min": -6.551080188559528, "train/policy_logprob_std": 0.6690437518172527, "train/policy_randomness_mag": 0.7049123096705681, "train/policy_randomness_max": 0.7049123096705681, "train/policy_randomness_mean": 0.07018126489304417, "train/policy_randomness_min": 0.03324232257940062, "train/policy_randomness_std": 0.0879899086103068, "train/post_ent_mag": 48.05282523763839, "train/post_ent_max": 48.05282523763839, "train/post_ent_mean": 46.39166612481352, "train/post_ent_min": 45.4675346451189, "train/post_ent_std": 0.481195886230948, "train/prior_ent_mag": 48.35593295456776, "train/prior_ent_max": 48.35593295456776, "train/prior_ent_mean": 45.04498678236151, "train/prior_ent_min": 42.558734663766835, "train/prior_ent_std": 0.9919748336226497, "train/rep_loss_mean": 1.0000051972854078, "train/rep_loss_std": 0.00016500255685000114, "train/reward_avg": 0.000430359193091702, "train/reward_loss_mean": 0.003611387838796717, "train/reward_loss_std": 0.08230583557195671, "train/reward_max_data": 0.32454459908320077, "train/reward_max_pred": 0.1137354397893551, "train/reward_neg_acc": 0.9999017655549935, "train/reward_neg_loss": 0.000554941652479275, "train/reward_pos_acc": 0.3028052806264103, "train/reward_pos_loss": 4.150375060515828, "train/reward_pred": 0.00034407710588663516, "train/reward_rate": 0.0006968435929648241, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.019321754574775696, "report/cont_loss_std": 0.30449220538139343, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.902574300765991, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0023281252942979336, "report/cont_pred": 0.9953111410140991, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09223931282758713, "report/image_loss_std": 0.09355954080820084, "report/model_loss_mean": 0.7118617296218872, "report/model_loss_std": 0.3262837529182434, "report/post_ent_mag": 46.88846206665039, "report/post_ent_max": 46.88846206665039, "report/post_ent_mean": 45.186859130859375, "report/post_ent_min": 44.23701477050781, "report/post_ent_std": 0.5233135223388672, "report/prior_ent_mag": 48.17420959472656, "report/prior_ent_max": 48.17420959472656, "report/prior_ent_mean": 44.77617645263672, "report/prior_ent_min": 42.85911178588867, "report/prior_ent_std": 0.9211781024932861, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0003006258048117161, "report/reward_loss_std": 0.0033036069944500923, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0487668514251709, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0003006258048117161, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0001526916166767478, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.043718282133340836, "eval/cont_loss_std": 0.6776557564735413, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.62717342376709, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0022145372349768877, "eval/cont_pred": 0.9979038238525391, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16243459284305573, "eval/image_loss_std": 0.14606480300426483, "eval/model_loss_mean": 0.8065518140792847, "eval/model_loss_std": 0.6885445713996887, "eval/post_ent_mag": 46.88780975341797, "eval/post_ent_max": 46.88780975341797, "eval/post_ent_mean": 45.031959533691406, "eval/post_ent_min": 44.2397346496582, "eval/post_ent_std": 0.5177247524261475, "eval/prior_ent_mag": 48.17420959472656, "eval/prior_ent_max": 48.17420959472656, "eval/prior_ent_mean": 44.537208557128906, "eval/prior_ent_min": 42.763118743896484, "eval/prior_ent_std": 0.8836318254470825, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0003989022225141525, "eval/reward_loss_std": 0.006483643781393766, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.08589291572570801, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0003989022225141525, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001858456525951624, "eval/reward_rate": 0.0, "replay/size": 572425.0, "replay/inserts": 31760.0, "replay/samples": 31760.0, "replay/insert_wait_avg": 1.455621995613617e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.787114126556166e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5940.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2512961622039076e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1074695587158, "timer/env.step_count": 7940.0, "timer/env.step_total": 36.61504530906677, "timer/env.step_frac": 0.036611110729152616, "timer/env.step_avg": 0.004611466663610425, "timer/env.step_min": 0.0034356117248535156, "timer/env.step_max": 0.031141281127929688, "timer/replay._sample_count": 31760.0, "timer/replay._sample_total": 15.572474241256714, "timer/replay._sample_frac": 0.015570800854160065, "timer/replay._sample_avg": 0.0004903171990320124, "timer/replay._sample_min": 0.0003688335418701172, "timer/replay._sample_max": 0.011041641235351562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9425.0, "timer/agent.policy_total": 85.63133454322815, "timer/agent.policy_frac": 0.08562213277040301, "timer/agent.policy_avg": 0.009085552736682032, "timer/agent.policy_min": 0.008077621459960938, "timer/agent.policy_max": 0.04007411003112793, "timer/dataset_train_count": 1985.0, "timer/dataset_train_total": 0.21466684341430664, "timer/dataset_train_frac": 0.0002146437757424465, "timer/dataset_train_avg": 0.00010814450549839126, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.0053594112396240234, "timer/agent.train_count": 1985.0, "timer/agent.train_total": 863.9162516593933, "timer/agent.train_frac": 0.8638234169379666, "timer/agent.train_avg": 0.4352222930274022, "timer/agent.train_min": 0.4229881763458252, "timer/agent.train_max": 1.9553203582763672, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4827728271484375, "timer/agent.report_frac": 0.0004827209493410289, "timer/agent.report_avg": 0.24138641357421875, "timer/agent.report_min": 0.2361891269683838, "timer/agent.report_max": 0.2465837001800537, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2172927856445312e-05, "timer/dataset_eval_frac": 2.217054519773642e-08, "timer/dataset_eval_avg": 2.2172927856445312e-05, "timer/dataset_eval_min": 2.2172927856445312e-05, "timer/dataset_eval_max": 2.2172927856445312e-05, "fps": 31.75597135725994}
{"step": 573168, "time": 18211.35766530037, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 573292, "time": 18215.257313728333, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 573508, "time": 18221.649532318115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574076, "time": 18239.395996570587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574228, "time": 18243.919550657272, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 574324, "time": 18246.835225105286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574352, "time": 18247.818342208862, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 574456, "time": 18250.77761721611, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 574552, "time": 18253.722012043, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 574732, "time": 18259.544798135757, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 574944, "time": 18265.946112394333, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 574996, "time": 18267.445912599564, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 575232, "time": 18274.868152856827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575288, "time": 18276.37787604332, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 575708, "time": 18289.545775175095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575776, "time": 18291.512944221497, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 576388, "time": 18310.221701145172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576444, "time": 18312.151763916016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576660, "time": 18318.554127931595, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 576932, "time": 18326.879348039627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577040, "time": 18330.283898830414, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 577332, "time": 18339.186789512634, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 577600, "time": 18347.46750640869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577616, "time": 18347.95582461357, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 577816, "time": 18354.029691696167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577928, "time": 18357.44908642769, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 577968, "time": 18358.876177072525, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 578132, "time": 18363.893126487732, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 578344, "time": 18370.21206831932, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 578600, "time": 18378.016054868698, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 578772, "time": 18383.37652516365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578828, "time": 18385.326396226883, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 578972, "time": 18389.707535982132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578996, "time": 18390.241534233093, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 579036, "time": 18391.690975427628, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 579288, "time": 18399.060259103775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 579608, "time": 18408.82640695572, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 579656, "time": 18410.312507390976, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 580060, "time": 18423.530957221985, "eval_episode/length": 14.0, "eval_episode/score": 0.956250011920929, "eval_episode/reward_rate": 0.06666666666666667}
{"step": 580060, "time": 18424.619002342224, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 580060, "time": 18424.919380426407, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 580060, "time": 18425.601111888885, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 580060, "time": 18425.67307162285, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 580060, "time": 18426.48901462555, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 580060, "time": 18426.9510781765, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 580060, "time": 18427.33155155182, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 580128, "time": 18429.31753063202, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 580128, "time": 18429.324897527695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580192, "time": 18431.29379439354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580444, "time": 18439.142316818237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580492, "time": 18440.61759710312, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 580696, "time": 18446.533628463745, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 580720, "time": 18447.49604654312, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 581348, "time": 18466.615149497986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581600, "time": 18474.392169475555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581816, "time": 18480.763471603394, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 581876, "time": 18482.747544527054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582504, "time": 18502.00214099884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582756, "time": 18509.801144123077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582764, "time": 18510.26496863365, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 582972, "time": 18516.622619628906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583032, "time": 18518.14400458336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583072, "time": 18519.586519241333, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 583116, "time": 18521.042854070663, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 583348, "time": 18527.916865110397, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 583472, "time": 18531.819422245026, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 583580, "time": 18535.22149348259, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 583792, "time": 18541.671038389206, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 584128, "time": 18551.94156718254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584272, "time": 18556.364625692368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584320, "time": 18557.83703684807, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 584628, "time": 18567.061081647873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584948, "time": 18576.808122873306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584992, "time": 18578.25728201866, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 585428, "time": 18591.432878017426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585476, "time": 18592.914041519165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585628, "time": 18597.7738301754, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 585980, "time": 18608.583408355713, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 586148, "time": 18613.69606947899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586500, "time": 18624.480260372162, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 586584, "time": 18626.944904327393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586632, "time": 18628.421895503998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586652, "time": 18629.362605810165, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 586824, "time": 18634.37866640091, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 586860, "time": 18635.808070898056, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 587028, "time": 18640.763439655304, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 587064, "time": 18641.76135444641, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 587136, "time": 18644.213365077972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587416, "time": 18652.61363720894, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 587808, "time": 18664.92525100708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587812, "time": 18664.94734954834, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 588068, "time": 18672.811018943787, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 588092, "time": 18673.773896217346, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 588184, "time": 18676.315745830536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588292, "time": 18679.765201091766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588536, "time": 18687.159857034683, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 589224, "time": 18708.381319999695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589248, "time": 18709.357013463974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589340, "time": 18712.282776355743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589588, "time": 18719.666919469833, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 589692, "time": 18723.1169090271, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590060, "time": 18734.624594926834, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 590060, "time": 18734.89110517502, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 590060, "time": 18734.961839675903, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 590060, "time": 18735.678265333176, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 590060, "time": 18735.736236333847, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 590060, "time": 18736.174748182297, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 590060, "time": 18738.50190258026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590060, "time": 18739.583585977554, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590380, "time": 18749.603264570236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590404, "time": 18750.12987446785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590744, "time": 18760.52834200859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590848, "time": 18763.930183410645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591040, "time": 18769.766044139862, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 591536, "time": 18784.91801381111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591560, "time": 18785.440112113953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591952, "time": 18797.628080129623, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 592004, "time": 18799.119543790817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592196, "time": 18804.997482299805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592400, "time": 18811.406253814697, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 592692, "time": 18820.22025322914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593108, "time": 18832.906693696976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593160, "time": 18834.398044347763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593304, "time": 18838.790016651154, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 593528, "time": 18845.65247154236, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 593556, "time": 18846.641561746597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593704, "time": 18851.048269033432, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 593848, "time": 18855.456269979477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594180, "time": 18865.79319858551, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 594316, "time": 18870.282163619995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594448, "time": 18874.243042707443, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 594648, "time": 18880.134504795074, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 594712, "time": 18882.11202120781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594860, "time": 18886.983229637146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594936, "time": 18888.987812042236, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 595096, "time": 18893.885853767395, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 595504, "time": 18906.623312711716, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 595604, "time": 18909.564953804016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595804, "time": 18915.918129444122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596092, "time": 18924.72504591942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596660, "time": 18941.90930056572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596760, "time": 18944.857182741165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596960, "time": 18951.151505708694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597032, "time": 18953.13115954399, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 597248, "time": 18959.966145277023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597300, "time": 18961.477842092514, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 597816, "time": 18977.114938020706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598116, "time": 18986.41601920128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598404, "time": 18995.425579547882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598456, "time": 18996.893157482147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598596, "time": 19001.28102517128, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 598960, "time": 19012.45823931694, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 598972, "time": 19012.937031269073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599112, "time": 19016.881520032883, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 599188, "time": 19019.332893371582, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 599272, "time": 19021.863977193832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599444, "time": 19027.209938526154, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 599560, "time": 19030.653562545776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600060, "time": 19046.695496082306, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 600060, "time": 19046.949677467346, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 600060, "time": 19050.086233377457, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600060, "time": 19050.092847585678, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600060, "time": 19050.631338834763, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600060, "time": 19050.897152662277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600060, "time": 19051.551162719727, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 600060, "time": 19054.391436100006, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600060, "time": 19054.39754962921, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600344, "time": 19062.811237812042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600428, "time": 19065.709458589554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600600, "time": 19070.63838839531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600716, "time": 19074.499611377716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600816, "time": 19077.463974952698, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 601500, "time": 19098.53634428978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601584, "time": 19101.00612425804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601684, "time": 19103.952854156494, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 601872, "time": 19109.8052816391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601908, "time": 19110.797513484955, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 601972, "time": 19112.78561067581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602168, "time": 19118.64886713028, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 602388, "time": 19125.673500299454, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 602740, "time": 19136.433106660843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603028, "time": 19145.28227829933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603252, "time": 19152.100424051285, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 603324, "time": 19154.535618066788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603544, "time": 19160.92428135872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603896, "time": 19171.688527584076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604408, "time": 19187.32064461708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604480, "time": 19189.740133285522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604696, "time": 19196.104197740555, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 604700, "time": 19196.55525827408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604744, "time": 19197.578531742096, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 604832, "time": 19200.490760326385, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 604936, "time": 19203.461978912354, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 604937, "time": 19204.454391002655, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6285000610351563, "train/action_min": 0.0, "train/action_std": 1.5268556797504425, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005999734998913482, "train/actor_opt_grad_steps": 36715.0, "train/actor_opt_loss": -1.8439614585787059, "train/adv_mag": 0.5519100126624107, "train/adv_max": 0.20247550904750825, "train/adv_mean": 0.0034474250759558346, "train/adv_min": -0.5273656848073006, "train/adv_std": 0.018158380314707755, "train/cont_avg": 0.996083984375, "train/cont_loss_mean": 0.013555880010244437, "train/cont_loss_std": 0.21776286008302123, "train/cont_neg_acc": 0.3817041618515499, "train/cont_neg_loss": 2.8776617803851883, "train/cont_pos_acc": 0.9998675724864006, "train/cont_pos_loss": 0.002559062108921353, "train/cont_pred": 0.9960879638791085, "train/cont_rate": 0.996083984375, "train/dyn_loss_mean": 1.00000796854496, "train/dyn_loss_std": 0.0002244028399582021, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.44283415634185075, "train/extr_critic_critic_opt_grad_steps": 36715.0, "train/extr_critic_critic_opt_loss": 9980.765010986328, "train/extr_critic_mag": 0.7042628699541091, "train/extr_critic_max": 0.7042628699541091, "train/extr_critic_mean": 0.6615637782216072, "train/extr_critic_min": 0.6059534323215484, "train/extr_critic_std": 0.009633509805426002, "train/extr_return_normed_mag": 0.5505714699625969, "train/extr_return_normed_max": 0.22848973989486696, "train/extr_return_normed_mean": 0.02379113262752071, "train/extr_return_normed_min": -0.5159598064422607, "train/extr_return_normed_std": 0.020973887969739737, "train/extr_return_rate": 0.9990583142638206, "train/extr_return_raw_mag": 0.8697097846865653, "train/extr_return_raw_max": 0.8697097846865653, "train/extr_return_raw_mean": 0.6650112080574035, "train/extr_return_raw_min": 0.12526023834943772, "train/extr_return_raw_std": 0.02097388804424554, "train/extr_reward_mag": 0.2897736829519272, "train/extr_reward_max": 0.2897736829519272, "train/extr_reward_mean": 0.0015594651077117305, "train/extr_reward_min": 2.580881118774414e-07, "train/extr_reward_std": 0.007491940440377221, "train/image_loss_mean": 0.10612574689090253, "train/image_loss_std": 0.10452970620244742, "train/model_loss_mean": 0.7234311872720718, "train/model_loss_std": 0.30802550084888936, "train/model_opt_grad_norm": 22.738161705247123, "train/model_opt_grad_steps": 36683.74, "train/model_opt_loss": 3336.9949407958984, "train/model_opt_model_opt_grad_overflow": 0.005, "train/model_opt_model_opt_grad_scale": 4600.0, "train/policy_entropy_mag": 1.3315960067510604, "train/policy_entropy_max": 1.3315960067510604, "train/policy_entropy_mean": 0.1234270054101944, "train/policy_entropy_min": 0.06468652937561274, "train/policy_entropy_std": 0.15992188904434443, "train/policy_logprob_mag": 6.551080234050751, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.12318907659500837, "train/policy_logprob_min": -6.551080234050751, "train/policy_logprob_std": 0.6583767369389534, "train/policy_randomness_mag": 0.6843050226569176, "train/policy_randomness_max": 0.6843050226569176, "train/policy_randomness_mean": 0.0634289370663464, "train/policy_randomness_min": 0.033242302741855384, "train/policy_randomness_std": 0.08218359788879752, "train/post_ent_mag": 47.89636169433594, "train/post_ent_max": 47.89636169433594, "train/post_ent_mean": 45.73604650497437, "train/post_ent_min": 44.59149660110474, "train/post_ent_std": 0.6317063882946968, "train/prior_ent_mag": 49.01428493499756, "train/prior_ent_max": 49.01428493499756, "train/prior_ent_mean": 44.40141641616821, "train/prior_ent_min": 41.89880374908447, "train/prior_ent_std": 1.1298935401439667, "train/rep_loss_mean": 1.00000796854496, "train/rep_loss_std": 0.0002244028399582021, "train/reward_avg": 0.0004758453351678327, "train/reward_loss_mean": 0.0037447556538973002, "train/reward_loss_std": 0.08326217377834837, "train/reward_max_data": 0.3422968751192093, "train/reward_max_pred": 0.12084436297416687, "train/reward_neg_acc": 0.9998876079916954, "train/reward_neg_loss": 0.0005785783071041806, "train/reward_pos_acc": 0.3035714288755339, "train/reward_pos_loss": 4.256983657272494, "train/reward_pred": 0.0003825691353995353, "train/reward_rate": 0.000732421875, "train_stats/mean_log_entropy": 0.08501680851692245, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.010066520422697067, "report/cont_loss_std": 0.19198831915855408, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 1.7241216897964478, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0016560445073992014, "report/cont_pred": 0.9954443573951721, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09650375694036484, "report/image_loss_std": 0.10368452221155167, "report/model_loss_mean": 0.711391031742096, "report/model_loss_std": 0.3206411600112915, "report/post_ent_mag": 49.10572052001953, "report/post_ent_max": 49.10572052001953, "report/post_ent_mean": 46.280067443847656, "report/post_ent_min": 44.80949020385742, "report/post_ent_std": 0.8294808864593506, "report/prior_ent_mag": 50.13898468017578, "report/prior_ent_max": 50.13898468017578, "report/prior_ent_mean": 44.51046371459961, "report/prior_ent_min": 41.844215393066406, "report/prior_ent_std": 1.4925289154052734, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007904052617959678, "report/reward_loss_mean": 0.0048207249492406845, "report/reward_loss_std": 0.1362345814704895, "report/reward_max_data": 0.809374988079071, "report/reward_max_pred": 0.025115251541137695, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005628445069305599, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.360632419586182, "report/reward_pred": 0.00032565020956099033, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.02534201741218567, "eval/cont_loss_std": 0.5394121408462524, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.093766212463379, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0017247498035430908, "eval/cont_pred": 0.99831223487854, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15341517329216003, "eval/image_loss_std": 0.14469201862812042, "eval/model_loss_mean": 0.7793431282043457, "eval/model_loss_std": 0.5617669820785522, "eval/post_ent_mag": 49.105960845947266, "eval/post_ent_max": 49.105960845947266, "eval/post_ent_mean": 46.23119354248047, "eval/post_ent_min": 44.966495513916016, "eval/post_ent_std": 0.7849289178848267, "eval/prior_ent_mag": 50.13898468017578, "eval/prior_ent_max": 50.13898468017578, "eval/prior_ent_mean": 44.3603401184082, "eval/prior_ent_min": 41.29331588745117, "eval/prior_ent_std": 1.3179452419281006, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0005859429948031902, "eval/reward_loss_std": 0.0035226019099354744, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.02355790138244629, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005859429948031902, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0003284015692770481, "eval/reward_rate": 0.0, "replay/size": 604425.0, "replay/inserts": 32000.0, "replay/samples": 32000.0, "replay/insert_wait_avg": 1.4671161770820618e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.762834429740906e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5036.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2654269660058905e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0933332443237, "timer/env.step_count": 8000.0, "timer/env.step_total": 36.85799217224121, "timer/env.step_frac": 0.03685455241729601, "timer/env.step_avg": 0.004607249021530152, "timer/env.step_min": 0.003452777862548828, "timer/env.step_max": 0.030482769012451172, "timer/replay._sample_count": 32000.0, "timer/replay._sample_total": 15.756482362747192, "timer/replay._sample_frac": 0.015755011896372545, "timer/replay._sample_avg": 0.0004923900738358498, "timer/replay._sample_min": 0.0003707408905029297, "timer/replay._sample_max": 0.010325193405151367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9259.0, "timer/agent.policy_total": 84.64779543876648, "timer/agent.policy_frac": 0.08463989572269946, "timer/agent.policy_avg": 0.009142217889487686, "timer/agent.policy_min": 0.008042335510253906, "timer/agent.policy_max": 0.07470202445983887, "timer/dataset_train_count": 2000.0, "timer/dataset_train_total": 0.20566201210021973, "timer/dataset_train_frac": 0.00020564281878877029, "timer/dataset_train_avg": 0.00010283100605010987, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.0003070831298828125, "timer/agent.train_count": 2000.0, "timer/agent.train_total": 865.4199573993683, "timer/agent.train_frac": 0.8653391924850932, "timer/agent.train_avg": 0.43270997869968414, "timer/agent.train_min": 0.4230806827545166, "timer/agent.train_max": 0.5115909576416016, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4807717800140381, "timer/agent.report_frac": 0.00048072691221168765, "timer/agent.report_avg": 0.24038589000701904, "timer/agent.report_min": 0.2343297004699707, "timer/agent.report_max": 0.24644207954406738, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.836916312705254e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 31.996390017585632}
{"step": 605052, "time": 19207.993154525757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605900, "time": 19233.77768445015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605988, "time": 19236.236035108566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606068, "time": 19238.674105644226, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 606092, "time": 19239.62462091446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606172, "time": 19242.051672935486, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 606208, "time": 19243.062680721283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606380, "time": 19248.39205813408, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 606492, "time": 19251.990478515625, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 607224, "time": 19274.11168408394, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 607248, "time": 19275.062391281128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607364, "time": 19278.49095606804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607536, "time": 19283.843514442444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608380, "time": 19309.746690750122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608404, "time": 19310.26534676552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608508, "time": 19313.66477203369, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 608572, "time": 19315.61742401123, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 608692, "time": 19319.099331617355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608704, "time": 19319.581253051758, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 609016, "time": 19328.98426580429, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 609296, "time": 19337.761523723602, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 609440, "time": 19342.252016067505, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 609536, "time": 19345.187802553177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609592, "time": 19346.700394392014, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 609848, "time": 19354.580517292023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609860, "time": 19355.058742523193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609968, "time": 19358.48334121704, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 610016, "time": 19359.953674316406, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 610060, "time": 19362.290156126022, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 610060, "time": 19362.56037068367, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 610060, "time": 19363.080324172974, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 610060, "time": 19363.16229534149, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 610060, "time": 19365.296829223633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610060, "time": 19365.30393910408, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610060, "time": 19366.927540302277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610060, "time": 19367.01307964325, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610148, "time": 19369.486300945282, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 610256, "time": 19372.885234832764, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 610476, "time": 19379.666691064835, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 610824, "time": 19390.125739336014, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 611016, "time": 19395.941670656204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611120, "time": 19399.311038017273, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 611172, "time": 19400.8012778759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611556, "time": 19412.53330183029, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 611628, "time": 19414.956069469452, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 611632, "time": 19414.977714538574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612328, "time": 19435.977442264557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612656, "time": 19446.335632801056, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 612712, "time": 19447.830597400665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612784, "time": 19450.260254621506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612788, "time": 19450.281213760376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612856, "time": 19452.24040865898, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 613160, "time": 19461.550505161285, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 613356, "time": 19467.82394218445, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 613812, "time": 19481.55014538765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613940, "time": 19485.483905553818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613944, "time": 19485.505338191986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614040, "time": 19488.44485807419, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 614196, "time": 19493.33012986183, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 614292, "time": 19496.274784326553, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 614464, "time": 19501.7091524601, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 614532, "time": 19503.711520195007, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 614660, "time": 19507.70083475113, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 615100, "time": 19521.43577504158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 615196, "time": 19524.375951051712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 615612, "time": 19537.172472715378, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 615688, "time": 19539.20123910904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 615860, "time": 19544.55460715294, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 615900, "time": 19545.993466615677, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 615976, "time": 19547.999695062637, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 616008, "time": 19548.980859279633, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 616256, "time": 19556.751745939255, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 616372, "time": 19560.19348716736, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 616652, "time": 19569.033812999725, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 616668, "time": 19569.52615594864, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 616932, "time": 19577.399532794952, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 617164, "time": 19584.701919317245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617168, "time": 19584.723257303238, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 617636, "time": 19599.030602931976, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 617808, "time": 19604.42279601097, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 617876, "time": 19606.39676785469, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 617884, "time": 19606.85978269577, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 618320, "time": 19620.100457906723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618764, "time": 19634.094877004623, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 619032, "time": 19641.98882842064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619040, "time": 19642.461392641068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619252, "time": 19648.845635175705, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 619476, "time": 19655.79183769226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619588, "time": 19659.202262878418, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 619712, "time": 19663.12289905548, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 619920, "time": 19669.46733045578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620060, "time": 19676.269830465317, "eval_episode/length": 179.0, "eval_episode/score": 0.44062501192092896, "eval_episode/reward_rate": 0.005555555555555556}
{"step": 620060, "time": 19676.452876091003, "eval_episode/length": 192.0, "eval_episode/score": 0.4000000059604645, "eval_episode/reward_rate": 0.0051813471502590676}
{"step": 620060, "time": 19676.591258764267, "eval_episode/length": 202.0, "eval_episode/score": 0.3687500059604645, "eval_episode/reward_rate": 0.0049261083743842365}
{"step": 620060, "time": 19676.649357557297, "eval_episode/length": 13.0, "eval_episode/score": 0.9593750238418579, "eval_episode/reward_rate": 0.07142857142857142}
{"step": 620060, "time": 19677.738255262375, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620060, "time": 19679.411892414093, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 620060, "time": 19679.790611743927, "eval_episode/length": 212.0, "eval_episode/score": 0.3375000059604645, "eval_episode/reward_rate": 0.004694835680751174}
{"step": 620060, "time": 19680.282972812653, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 620220, "time": 19685.25225710869, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 620400, "time": 19690.669509887695, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 620508, "time": 19694.10733127594, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 620744, "time": 19701.029313325882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620800, "time": 19702.982056856155, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 621048, "time": 19710.34542775154, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 621556, "time": 19726.04850792885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621664, "time": 19729.440730810165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621956, "time": 19738.264105796814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622204, "time": 19746.098106622696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622712, "time": 19761.287772893906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622720, "time": 19761.751133918762, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 623112, "time": 19773.742205619812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623160, "time": 19775.220347881317, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 623360, "time": 19781.491984128952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623536, "time": 19786.82271885872, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 623716, "time": 19792.161715984344, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 623808, "time": 19795.063341140747, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 623884, "time": 19797.464774608612, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 624268, "time": 19809.219447135925, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 624692, "time": 19821.885954856873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624872, "time": 19827.228267669678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625040, "time": 19832.64046049118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625136, "time": 19835.57017302513, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 625144, "time": 19835.604061365128, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 625664, "time": 19851.683653116226, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 626028, "time": 19862.957912921906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626248, "time": 19869.381539821625, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 626300, "time": 19871.304881811142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626396, "time": 19874.23092341423, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 626664, "time": 19882.058391571045, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 626772, "time": 19885.45102572441, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 626820, "time": 19886.911465644836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627508, "time": 19908.136928081512, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 627552, "time": 19909.599162340164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627820, "time": 19917.90827679634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627976, "time": 19922.43703699112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628544, "time": 19939.94625353813, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 628664, "time": 19943.399170398712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628976, "time": 19953.156514644623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629132, "time": 19958.021775722504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629400, "time": 19965.860569000244, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 629660, "time": 19974.102368593216, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 629744, "time": 19976.568764448166, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 629900, "time": 19981.455659866333, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 630060, "time": 19988.11435675621, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 630060, "time": 19989.820734262466, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 630060, "time": 19990.29167318344, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630060, "time": 19990.297896146774, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630060, "time": 19990.30398917198, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630060, "time": 19993.139581918716, "eval_episode/length": 203.0, "eval_episode/score": 0.3656249940395355, "eval_episode/reward_rate": 0.004901960784313725}
{"step": 630060, "time": 19993.82812166214, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630060, "time": 19994.322170972824, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630060, "time": 19994.328080415726, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630132, "time": 19996.321881055832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630432, "time": 20005.576156377792, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 630460, "time": 20006.541805028915, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 630816, "time": 20017.315664052963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630900, "time": 20019.8080163002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631368, "time": 20034.132376909256, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 631588, "time": 20040.985035181046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631616, "time": 20041.966445446014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632056, "time": 20055.207628965378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632152, "time": 20058.171184062958, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 632212, "time": 20060.11549639702, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 632524, "time": 20069.88388133049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632744, "time": 20076.387076854706, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 633308, "time": 20094.056431770325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 633368, "time": 20095.56956720352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 633536, "time": 20100.938153505325, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 633680, "time": 20105.395287513733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634088, "time": 20117.64571928978, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 634180, "time": 20120.578292369843, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 634296, "time": 20124.062072753906, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 634576, "time": 20132.922419309616, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 634596, "time": 20133.427553892136, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 634660, "time": 20135.381942033768, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 634692, "time": 20136.3875477314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634884, "time": 20142.263058423996, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 634984, "time": 20145.202612638474, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 635632, "time": 20165.50689792633, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 635732, "time": 20168.459587812424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635816, "time": 20170.955041885376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636040, "time": 20177.77934026718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636224, "time": 20183.606536865234, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 636316, "time": 20186.52617073059, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 636328, "time": 20186.574988365173, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 636524, "time": 20192.90035533905, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 636788, "time": 20200.79308462143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636889, "time": 20204.735093593597, "train_stats/mean_log_entropy": 0.09422075337061853, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4509844756006594, "train/action_min": 0.0, "train/action_std": 1.4268410954643134, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008002935150572703, "train/actor_opt_grad_steps": 38710.0, "train/actor_opt_loss": -3.1851955288038334, "train/adv_mag": 0.6262337301843729, "train/adv_max": 0.2432660643179812, "train/adv_mean": 0.002942122254741785, "train/adv_min": -0.597149063145096, "train/adv_std": 0.022746289916448857, "train/cont_avg": 0.9958925486809045, "train/cont_loss_mean": 0.013590920691954056, "train/cont_loss_std": 0.21616894481165438, "train/cont_neg_acc": 0.3891500711288987, "train/cont_neg_loss": 2.6911089248071445, "train/cont_pos_acc": 0.9998521741910197, "train/cont_pos_loss": 0.002549600973783819, "train/cont_pred": 0.995996862799678, "train/cont_rate": 0.9958925486809045, "train/dyn_loss_mean": 1.000004674322042, "train/dyn_loss_std": 0.00013539566249740499, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3014991737378003, "train/extr_critic_critic_opt_grad_steps": 38710.0, "train/extr_critic_critic_opt_loss": 12733.0830176272, "train/extr_critic_mag": 0.8094778755801407, "train/extr_critic_max": 0.8094778755801407, "train/extr_critic_mean": 0.7600940846318576, "train/extr_critic_min": 0.6910121237213288, "train/extr_critic_std": 0.012364220800786162, "train/extr_return_normed_mag": 0.625455078168131, "train/extr_return_normed_max": 0.28124482068584195, "train/extr_return_normed_mean": 0.02741591268261174, "train/extr_return_normed_min": -0.5850327829619748, "train/extr_return_normed_std": 0.0266062000569836, "train/extr_return_rate": 0.9990110508161574, "train/extr_return_raw_mag": 1.0168650282088236, "train/extr_return_raw_max": 1.0168650282088236, "train/extr_return_raw_mean": 0.7630361621104294, "train/extr_return_raw_min": 0.15058742456100693, "train/extr_return_raw_std": 0.026606200038263545, "train/extr_reward_mag": 0.3494138873402198, "train/extr_reward_max": 0.3494138873402198, "train/extr_reward_mean": 0.0013825252681272104, "train/extr_reward_min": 3.7979240992560456e-07, "train/extr_reward_std": 0.00910946243090424, "train/image_loss_mean": 0.10164494625288038, "train/image_loss_std": 0.10319247276489459, "train/model_loss_mean": 0.7194944006114748, "train/model_loss_std": 0.31752576540462935, "train/model_opt_grad_norm": 22.05890616699679, "train/model_opt_grad_steps": 38677.01507537688, "train/model_opt_loss": 3634.012069625471, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5050.251256281407, "train/policy_entropy_mag": 1.4207822306072293, "train/policy_entropy_max": 1.4207822306072293, "train/policy_entropy_mean": 0.13715648770931377, "train/policy_entropy_min": 0.06468665135565714, "train/policy_entropy_std": 0.1769572394577103, "train/policy_logprob_mag": 6.551080181371027, "train/policy_logprob_max": -0.008608185480250486, "train/policy_logprob_mean": -0.13721060464579857, "train/policy_logprob_min": -6.551080181371027, "train/policy_logprob_std": 0.6755436883499873, "train/policy_randomness_mag": 0.7301376764498764, "train/policy_randomness_max": 0.7301376764498764, "train/policy_randomness_mean": 0.0704844957170774, "train/policy_randomness_min": 0.03324236443743634, "train/policy_randomness_std": 0.09093803672784537, "train/post_ent_mag": 48.358776418407956, "train/post_ent_max": 48.358776418407956, "train/post_ent_mean": 45.64788459892848, "train/post_ent_min": 44.23503530684428, "train/post_ent_std": 0.7987379833082457, "train/prior_ent_mag": 49.78515320207605, "train/prior_ent_max": 49.78515320207605, "train/prior_ent_mean": 44.26670848903944, "train/prior_ent_min": 41.7181755525982, "train/prior_ent_std": 1.224024782827751, "train/rep_loss_mean": 1.000004674322042, "train/rep_loss_std": 0.00013539566249740499, "train/reward_avg": 0.0005569074624808898, "train/reward_loss_mean": 0.00425570828275025, "train/reward_loss_std": 0.09881431199657033, "train/reward_max_data": 0.4355213573979373, "train/reward_max_pred": 0.13678370768101372, "train/reward_neg_acc": 0.9998624881907324, "train/reward_neg_loss": 0.0006814637570130059, "train/reward_pos_acc": 0.24862258986008068, "train/reward_pos_loss": 4.2072219961930895, "train/reward_pred": 0.00043834994275628324, "train/reward_rate": 0.0008440640703517588, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0030703830998390913, "report/cont_loss_std": 0.0438498929142952, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 0.7275557518005371, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0016526035033166409, "report/cont_pred": 0.9972069263458252, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0000090599060059, "report/dyn_loss_std": 0.0002906094305217266, "report/image_loss_mean": 0.07468116283416748, "report/image_loss_std": 0.07837837189435959, "report/model_loss_mean": 0.6781580448150635, "report/model_loss_std": 0.08909327536821365, "report/post_ent_mag": 48.36011505126953, "report/post_ent_max": 48.36011505126953, "report/post_ent_mean": 45.3888053894043, "report/post_ent_min": 44.03497314453125, "report/post_ent_std": 0.8215515613555908, "report/prior_ent_mag": 51.739654541015625, "report/prior_ent_max": 51.739654541015625, "report/prior_ent_mean": 45.168704986572266, "report/prior_ent_min": 42.74391174316406, "report/prior_ent_std": 1.3026721477508545, "report/rep_loss_mean": 1.0000090599060059, "report/rep_loss_std": 0.0002906094305217266, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0004010079428553581, "report/reward_loss_std": 0.0027215653099119663, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.018970966339111328, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0004010079428553581, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00020038650836795568, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03512413799762726, "eval/cont_loss_std": 0.5283418893814087, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.132200241088867, "eval/cont_pos_acc": 0.9980391263961792, "eval/cont_pos_loss": 0.0033709004055708647, "eval/cont_pred": 0.9974295496940613, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19230596721172333, "eval/image_loss_std": 0.15744002163410187, "eval/model_loss_mean": 0.8277492523193359, "eval/model_loss_std": 0.5529819130897522, "eval/post_ent_mag": 48.35984420776367, "eval/post_ent_max": 48.35984420776367, "eval/post_ent_mean": 45.35087585449219, "eval/post_ent_min": 44.03986740112305, "eval/post_ent_std": 0.8430854678153992, "eval/prior_ent_mag": 51.739654541015625, "eval/prior_ent_max": 51.739654541015625, "eval/prior_ent_mean": 45.153770446777344, "eval/prior_ent_min": 42.23011779785156, "eval/prior_ent_std": 1.3537343740463257, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00031914515420794487, "eval/reward_loss_std": 0.0018758452497422695, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.013275384902954102, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00031914515420794487, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00016372604295611382, "eval/reward_rate": 0.0, "replay/size": 636377.0, "replay/inserts": 31952.0, "replay/samples": 31952.0, "replay/insert_wait_avg": 1.466148903683895e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.849263142035135e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5784.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2497189628632732e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2603213787079, "timer/env.step_count": 7988.0, "timer/env.step_total": 36.613126039505005, "timer/env.step_frac": 0.036603597340579636, "timer/env.step_avg": 0.004583516028981598, "timer/env.step_min": 0.0035059452056884766, "timer/env.step_max": 0.030666589736938477, "timer/replay._sample_count": 31952.0, "timer/replay._sample_total": 15.67569875717163, "timer/replay._sample_frac": 0.015671619099681018, "timer/replay._sample_avg": 0.0004906014883942048, "timer/replay._sample_min": 0.00040030479431152344, "timer/replay._sample_max": 0.009635210037231445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9434.0, "timer/agent.policy_total": 85.53324937820435, "timer/agent.policy_frac": 0.08551098903964287, "timer/agent.policy_avg": 0.009066488168136988, "timer/agent.policy_min": 0.00651097297668457, "timer/agent.policy_max": 0.04029965400695801, "timer/dataset_train_count": 1997.0, "timer/dataset_train_total": 0.2346818447113037, "timer/dataset_train_frac": 0.000234620767909528, "timer/dataset_train_avg": 0.00011751719815288118, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.02068018913269043, "timer/agent.train_count": 1997.0, "timer/agent.train_total": 864.1953365802765, "timer/agent.train_frac": 0.8639704266076591, "timer/agent.train_avg": 0.43274678847284753, "timer/agent.train_min": 0.42189693450927734, "timer/agent.train_max": 0.5316874980926514, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48165273666381836, "timer/agent.report_frac": 0.0004815273847911239, "timer/agent.report_avg": 0.24082636833190918, "timer/agent.report_min": 0.23429036140441895, "timer/agent.report_max": 0.24736237525939941, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2172927856445312e-05, "timer/dataset_eval_frac": 2.2167157271502362e-08, "timer/dataset_eval_avg": 2.2172927856445312e-05, "timer/dataset_eval_min": 2.2172927856445312e-05, "timer/dataset_eval_max": 2.2172927856445312e-05, "fps": 31.94303521319522}
{"step": 637216, "time": 20214.63644170761, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 637380, "time": 20219.56183362007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637472, "time": 20222.539366722107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637680, "time": 20228.925631284714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637792, "time": 20232.381884098053, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 637952, "time": 20237.30235362053, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 638268, "time": 20247.15343618393, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 638408, "time": 20251.205040454865, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 638536, "time": 20255.147454738617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 638948, "time": 20267.901328086853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639356, "time": 20280.79823565483, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 639424, "time": 20282.845952510834, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 639528, "time": 20285.83612680435, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 639692, "time": 20291.188161611557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639788, "time": 20294.148771762848, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 640060, "time": 20303.525297164917, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 640060, "time": 20303.859390735626, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 640060, "time": 20304.566673517227, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 640060, "time": 20305.55809354782, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 640060, "time": 20305.689670324326, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 640060, "time": 20306.453028678894, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640060, "time": 20306.459241867065, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640060, "time": 20306.77469277382, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 640156, "time": 20309.72348833084, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 640456, "time": 20318.59410381317, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 640512, "time": 20320.521451950073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640564, "time": 20322.007056713104, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 640684, "time": 20325.882324695587, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 640684, "time": 20325.890089273453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640748, "time": 20327.864110469818, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 640940, "time": 20333.72157382965, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 641048, "time": 20336.701281785965, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 641292, "time": 20344.55557370186, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 641400, "time": 20347.53956246376, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 641840, "time": 20361.164232730865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641904, "time": 20363.1360309124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642040, "time": 20367.07956457138, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 642280, "time": 20374.425355196, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 642292, "time": 20374.901834487915, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 642376, "time": 20377.35990357399, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 642524, "time": 20382.203365564346, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 642556, "time": 20383.183366537094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642676, "time": 20386.64444565773, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 642756, "time": 20389.08093047142, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 642984, "time": 20395.93314576149, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 643096, "time": 20399.394615888596, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 643372, "time": 20408.31896495819, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 643680, "time": 20417.56199169159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643712, "time": 20418.541223049164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643872, "time": 20423.39722752571, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 644096, "time": 20430.160181045532, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 644252, "time": 20435.043521881104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644528, "time": 20443.351629018784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644656, "time": 20447.253420829773, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 644736, "time": 20449.655703783035, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 644964, "time": 20456.496740579605, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 645028, "time": 20458.432880163193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645548, "time": 20474.534764051437, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 645792, "time": 20481.853288412094, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 645852, "time": 20483.781414031982, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 645892, "time": 20484.805130958557, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 645892, "time": 20484.812272548676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646064, "time": 20490.138257980347, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 646076, "time": 20490.61322259903, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 646128, "time": 20492.150176286697, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 646260, "time": 20496.05748128891, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 646380, "time": 20499.92656302452, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 646480, "time": 20502.84187555313, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 646496, "time": 20503.331943511963, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 646520, "time": 20503.86156463623, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 646644, "time": 20507.708366155624, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 646920, "time": 20515.945843458176, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 647020, "time": 20519.332219600677, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 647068, "time": 20520.79550051689, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 647084, "time": 20521.367069244385, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 647336, "time": 20528.73050403595, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 647636, "time": 20538.148538589478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647816, "time": 20543.526936769485, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 648092, "time": 20552.29056787491, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 648224, "time": 20556.211888074875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648492, "time": 20564.514629125595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648764, "time": 20572.80863714218, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 648972, "time": 20579.132611989975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 649112, "time": 20583.141189813614, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 649248, "time": 20587.485820770264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 649360, "time": 20590.878272533417, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 649372, "time": 20591.35185098648, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 649380, "time": 20591.38733768463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 649580, "time": 20597.71098446846, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 649644, "time": 20599.65883588791, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 649884, "time": 20606.94192314148, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 649920, "time": 20607.925308704376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650060, "time": 20612.938620328903, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 650060, "time": 20613.702746152878, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 650060, "time": 20614.0229575634, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 650060, "time": 20614.45744395256, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 650060, "time": 20615.06342124939, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 650060, "time": 20615.49514913559, "eval_episode/length": 208.0, "eval_episode/score": 0.3499999940395355, "eval_episode/reward_rate": 0.004784688995215311}
{"step": 650060, "time": 20615.65459918976, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 650060, "time": 20616.755566835403, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 650192, "time": 20620.66068148613, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 650452, "time": 20628.46618080139, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 650536, "time": 20630.925919532776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650736, "time": 20637.22739624977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651016, "time": 20645.58816885948, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 651132, "time": 20649.405096769333, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 651164, "time": 20650.38897418976, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 651348, "time": 20655.733320713043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651432, "time": 20658.182723522186, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 651544, "time": 20661.752851486206, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 651608, "time": 20663.70232129097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652020, "time": 20676.376153230667, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 652288, "time": 20684.658893346786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652480, "time": 20690.510926246643, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 652504, "time": 20691.032924175262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652700, "time": 20697.32342004776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652708, "time": 20697.358644723892, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 653052, "time": 20708.128576993942, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 653176, "time": 20711.616466999054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653448, "time": 20719.933880090714, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 653628, "time": 20725.725198745728, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 653660, "time": 20726.69681763649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653864, "time": 20732.64905357361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654208, "time": 20743.287627458572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654260, "time": 20744.759837388992, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 654356, "time": 20747.694794893265, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 654784, "time": 20760.832072734833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654816, "time": 20761.88780117035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655416, "time": 20779.990065574646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655512, "time": 20782.946766614914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655940, "time": 20796.326750040054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655972, "time": 20797.31492972374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656572, "time": 20815.683257102966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656668, "time": 20818.590692281723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656948, "time": 20826.974919319153, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 656996, "time": 20828.449424266815, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 657132, "time": 20832.8030025959, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 657208, "time": 20834.786839962006, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 657424, "time": 20841.54016852379, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 657668, "time": 20848.82239317894, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 657824, "time": 20853.70411849022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 657860, "time": 20854.700413942337, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 658004, "time": 20859.090085983276, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 658248, "time": 20866.425345897675, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 658288, "time": 20867.8584318161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658664, "time": 20879.029280662537, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 658768, "time": 20882.447541475296, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 658844, "time": 20884.88880968094, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 659092, "time": 20892.23314023018, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 659140, "time": 20893.703022241592, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 659316, "time": 20899.08235526085, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 659636, "time": 20908.77731513977, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 659732, "time": 20911.88339614868, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 659976, "time": 20919.225817918777, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 660060, "time": 20922.10429906845, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 660060, "time": 20922.878834724426, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 660060, "time": 20925.979402065277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660060, "time": 20925.985971927643, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660060, "time": 20925.9918718338, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660060, "time": 20926.731207847595, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660060, "time": 20927.20062971115, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 660060, "time": 20929.87931036949, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660060, "time": 20929.88636946678, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660160, "time": 20932.83773946762, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 660388, "time": 20939.648871660233, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 660596, "time": 20946.06876850128, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 660792, "time": 20951.90990614891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660888, "time": 20954.81483721733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660992, "time": 20958.210748672485, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 661064, "time": 20960.19794344902, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 661100, "time": 20961.630350112915, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 661876, "time": 20985.070025920868, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 661988, "time": 20988.452108860016, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 662084, "time": 20991.36850118637, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 662148, "time": 20993.333137989044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662220, "time": 20995.757941007614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662252, "time": 20996.722392320633, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 662256, "time": 20996.74351334572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662288, "time": 20997.716724157333, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 663096, "time": 21022.069224596024, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 663200, "time": 21025.452046871185, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 663408, "time": 21031.859712839127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663444, "time": 21032.84819793701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663492, "time": 21034.32743048668, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 663964, "time": 21050.70969080925, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 664144, "time": 21056.093168735504, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 664208, "time": 21058.04658794403, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 664284, "time": 21060.460942983627, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 664328, "time": 21061.50350379944, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 664356, "time": 21062.479372262955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664432, "time": 21064.903439044952, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 664484, "time": 21066.36060476303, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 664828, "time": 21077.027049541473, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 664908, "time": 21079.47610616684, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 665096, "time": 21084.9063475132, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 665316, "time": 21091.75071120262, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 665364, "time": 21093.223757743835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665656, "time": 21102.01510810852, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 665748, "time": 21104.93885421753, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 665760, "time": 21105.414410352707, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 665984, "time": 21112.209629297256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666020, "time": 21113.19357252121, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 666104, "time": 21115.646929979324, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 666356, "time": 21123.466936588287, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 666428, "time": 21125.869695663452, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 666488, "time": 21127.373732805252, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 666632, "time": 21131.772409439087, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 666888, "time": 21139.597790002823, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 667112, "time": 21146.421340465546, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 667512, "time": 21158.633885383606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667584, "time": 21161.03256702423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667644, "time": 21162.971358299255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667748, "time": 21165.92599081993, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 667884, "time": 21170.279596090317, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 667884, "time": 21170.284407138824, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 668072, "time": 21175.840876817703, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 668224, "time": 21180.707005739212, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 668572, "time": 21191.46748495102, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 668668, "time": 21194.398713588715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669001, "time": 21205.165096998215, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.499255128167755, "train/action_min": 0.0, "train/action_std": 1.4814970932196623, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007437959425753696, "train/actor_opt_grad_steps": 40710.0, "train/actor_opt_loss": -3.757204075635814, "train/adv_mag": 0.6778457012046036, "train/adv_max": 0.23262832769707067, "train/adv_mean": 0.0033092436206875867, "train/adv_min": -0.655380127590094, "train/adv_std": 0.023300233894764488, "train/cont_avg": 0.9959577114427861, "train/cont_loss_mean": 0.013878009770881033, "train/cont_loss_std": 0.21920914129256758, "train/cont_neg_acc": 0.3707261967658997, "train/cont_neg_loss": 2.795150368753821, "train/cont_pos_acc": 0.999873182963376, "train/cont_pos_loss": 0.002608401468313248, "train/cont_pred": 0.9960514013446978, "train/cont_rate": 0.9959577114427861, "train/dyn_loss_mean": 1.0000073292955238, "train/dyn_loss_std": 0.0002101825823603522, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.33224146954937656, "train/extr_critic_critic_opt_grad_steps": 40710.0, "train/extr_critic_critic_opt_loss": 6902.805096830301, "train/extr_critic_mag": 0.8924018482663738, "train/extr_critic_max": 0.8924018482663738, "train/extr_critic_mean": 0.8480069465305081, "train/extr_critic_min": 0.7825754412371128, "train/extr_critic_std": 0.011566779490523225, "train/extr_return_normed_mag": 0.6747081605949212, "train/extr_return_normed_max": 0.2615182402715161, "train/extr_return_normed_mean": 0.028240309916992685, "train/extr_return_normed_min": -0.641572104164617, "train/extr_return_normed_std": 0.027242801471877454, "train/extr_return_rate": 0.9989859085177901, "train/extr_return_raw_mag": 1.084594077435299, "train/extr_return_raw_max": 1.084594077435299, "train/extr_return_raw_mean": 0.8513161878087627, "train/extr_return_raw_min": 0.18150373299916586, "train/extr_return_raw_std": 0.027242801430176444, "train/extr_reward_mag": 0.31171089559052123, "train/extr_reward_max": 0.31171089559052123, "train/extr_reward_mean": 0.0019428569404176662, "train/extr_reward_min": 3.9202656911973334e-07, "train/extr_reward_std": 0.009608344251373366, "train/image_loss_mean": 0.09957234416879825, "train/image_loss_std": 0.102894628262935, "train/model_loss_mean": 0.7183583283898842, "train/model_loss_std": 0.32919332703844234, "train/model_opt_grad_norm": 22.14963856502552, "train/model_opt_grad_steps": 40675.0447761194, "train/model_opt_loss": 3662.7793782552085, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5099.502487562189, "train/policy_entropy_mag": 1.343239453894582, "train/policy_entropy_max": 1.343239453894582, "train/policy_entropy_mean": 0.12056777993244912, "train/policy_entropy_min": 0.06468653059865705, "train/policy_entropy_std": 0.155877391163686, "train/policy_logprob_mag": 6.551080155728468, "train/policy_logprob_max": -0.008608142062280309, "train/policy_logprob_mean": -0.12124811635533375, "train/policy_logprob_min": -6.551080155728468, "train/policy_logprob_std": 0.6614052626624036, "train/policy_randomness_mag": 0.6902885706863593, "train/policy_randomness_max": 0.6902885706863593, "train/policy_randomness_mean": 0.06195958564752963, "train/policy_randomness_min": 0.03324230239536632, "train/policy_randomness_std": 0.08010513743209602, "train/post_ent_mag": 48.38929902261763, "train/post_ent_max": 48.38929902261763, "train/post_ent_mean": 45.51648315505602, "train/post_ent_min": 43.946848589389475, "train/post_ent_std": 0.8714231860578356, "train/prior_ent_mag": 49.152169602427314, "train/prior_ent_max": 49.152169602427314, "train/prior_ent_mean": 44.86444723784034, "train/prior_ent_min": 42.23777721651751, "train/prior_ent_std": 1.1196655619203748, "train/rep_loss_mean": 1.0000073292955238, "train/rep_loss_std": 0.0002101825823603522, "train/reward_avg": 0.000597689045139644, "train/reward_loss_mean": 0.004903553566311611, "train/reward_loss_std": 0.10889016740274296, "train/reward_max_data": 0.4371735082188649, "train/reward_max_pred": 0.12743158008328717, "train/reward_neg_acc": 0.9998930072903041, "train/reward_neg_loss": 0.0007771868827035743, "train/reward_pos_acc": 0.2286821707736614, "train/reward_pos_loss": 4.306302503097889, "train/reward_pred": 0.0004750332020139739, "train/reward_rate": 0.0009376943407960199, "train_stats/mean_log_entropy": 0.08234140103061995, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.011393902823328972, "report/cont_loss_std": 0.17749829590320587, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.0381903648376465, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003445681184530258, "report/cont_pred": 0.9947373270988464, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09369900822639465, "report/image_loss_std": 0.10645812004804611, "report/model_loss_mean": 0.7066540122032166, "report/model_loss_std": 0.20518772304058075, "report/post_ent_mag": 47.328887939453125, "report/post_ent_max": 47.328887939453125, "report/post_ent_mean": 44.7422981262207, "report/post_ent_min": 43.07341766357422, "report/post_ent_std": 0.8378638029098511, "report/prior_ent_mag": 48.29772186279297, "report/prior_ent_max": 48.29772186279297, "report/prior_ent_mean": 45.61139678955078, "report/prior_ent_min": 43.03117370605469, "report/prior_ent_std": 0.9094731211662292, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0015610565897077322, "report/reward_loss_std": 0.011632545851171017, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.11550319194793701, "report/reward_neg_acc": 0.9990234375, "report/reward_neg_loss": 0.0015610565897077322, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0007337881252169609, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.022105049341917038, "eval/cont_loss_std": 0.4628935158252716, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.433639526367188, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0017302260966971517, "eval/cont_pred": 0.9983110427856445, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15463483333587646, "eval/image_loss_std": 0.1450207531452179, "eval/model_loss_mean": 0.7772866487503052, "eval/model_loss_std": 0.4894569218158722, "eval/post_ent_mag": 47.32890701293945, "eval/post_ent_max": 47.32890701293945, "eval/post_ent_mean": 44.399314880371094, "eval/post_ent_min": 43.018798828125, "eval/post_ent_std": 0.8362058997154236, "eval/prior_ent_mag": 48.351707458496094, "eval/prior_ent_max": 48.351707458496094, "eval/prior_ent_mean": 45.33625411987305, "eval/prior_ent_min": 42.981056213378906, "eval/prior_ent_std": 0.9157280921936035, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0005467033479362726, "eval/reward_loss_std": 0.0051712458953261375, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.04629015922546387, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005467033479362726, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002712714485824108, "eval/reward_rate": 0.0, "replay/size": 668489.0, "replay/inserts": 32112.0, "replay/samples": 32112.0, "replay/insert_wait_avg": 1.6374126499900191e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.820770879497443e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4768.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2700989742407062e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4025726318359, "timer/env.step_count": 8028.0, "timer/env.step_total": 37.099677085876465, "timer/env.step_frac": 0.03708474778136115, "timer/env.step_avg": 0.004621285137752424, "timer/env.step_min": 0.003423929214477539, "timer/env.step_max": 0.031841278076171875, "timer/replay._sample_count": 32112.0, "timer/replay._sample_total": 15.861305952072144, "timer/replay._sample_frac": 0.015854923193914412, "timer/replay._sample_avg": 0.0004939370313923812, "timer/replay._sample_min": 0.0003695487976074219, "timer/replay._sample_max": 0.009627580642700195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9220.0, "timer/agent.policy_total": 83.83187580108643, "timer/agent.policy_frac": 0.08379814096293602, "timer/agent.policy_avg": 0.009092394338512628, "timer/agent.policy_min": 0.007230997085571289, "timer/agent.policy_max": 0.04013991355895996, "timer/dataset_train_count": 2007.0, "timer/dataset_train_total": 0.2167072296142578, "timer/dataset_train_frac": 0.00021662002432095855, "timer/dataset_train_avg": 0.00010797569985762721, "timer/dataset_train_min": 8.654594421386719e-05, "timer/dataset_train_max": 0.005339145660400391, "timer/agent.train_count": 2007.0, "timer/agent.train_total": 866.6876487731934, "timer/agent.train_frac": 0.8663388844484191, "timer/agent.train_avg": 0.43183241094827773, "timer/agent.train_min": 0.41809844970703125, "timer/agent.train_max": 2.142122507095337, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4864671230316162, "timer/agent.report_frac": 0.00048627136348903, "timer/agent.report_avg": 0.2432335615158081, "timer/agent.report_min": 0.23659181594848633, "timer/agent.report_max": 0.24987530708312988, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.47955322265625e-05, "timer/dataset_eval_frac": 2.4785554240760285e-08, "timer/dataset_eval_avg": 2.47955322265625e-05, "timer/dataset_eval_min": 2.47955322265625e-05, "timer/dataset_eval_max": 2.47955322265625e-05, "fps": 32.098325420819585}
{"step": 669040, "time": 21206.305019140244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669228, "time": 21212.188252925873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669576, "time": 21222.500013828278, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 669728, "time": 21227.34123468399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669824, "time": 21230.267480134964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670060, "time": 21241.939408779144, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670060, "time": 21241.945625066757, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670060, "time": 21241.95103120804, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670060, "time": 21241.956792116165, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670060, "time": 21245.85870051384, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670060, "time": 21245.86484026909, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670060, "time": 21245.87081551552, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670060, "time": 21245.87589263916, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670100, "time": 21246.89138507843, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 670400, "time": 21256.115344285965, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 670732, "time": 21266.335734844208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670884, "time": 21270.7628633976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670980, "time": 21273.697646141052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671136, "time": 21278.580447912216, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 671324, "time": 21284.431116342545, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 671572, "time": 21291.780525922775, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 671756, "time": 21297.588494300842, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 671888, "time": 21301.621049404144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672196, "time": 21311.04459142685, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 672252, "time": 21312.970393419266, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 672728, "time": 21327.141261339188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672912, "time": 21332.991913318634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673352, "time": 21346.146055221558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673408, "time": 21348.076186180115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673740, "time": 21358.303144454956, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 673884, "time": 21362.704528093338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674352, "time": 21376.875241279602, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 674564, "time": 21383.250114440918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674896, "time": 21393.571669101715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675040, "time": 21397.980119228363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675508, "time": 21412.182094097137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675624, "time": 21415.59887599945, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 676052, "time": 21428.78467607498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676196, "time": 21433.350961446762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676228, "time": 21434.326806783676, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 676628, "time": 21446.537910699844, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 677208, "time": 21464.13259124756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677352, "time": 21468.516671419144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677384, "time": 21469.501081228256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677784, "time": 21481.74542427063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677848, "time": 21483.691276550293, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 678444, "time": 21502.211371183395, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 678508, "time": 21504.197147846222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678540, "time": 21505.173813819885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678804, "time": 21513.06921195984, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 678828, "time": 21514.042157411575, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 679004, "time": 21519.40420269966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679116, "time": 21522.791351795197, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 679432, "time": 21532.056046247482, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 679636, "time": 21538.413590669632, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 679984, "time": 21549.20330762863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680060, "time": 21555.497904777527, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680060, "time": 21555.50466275215, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680060, "time": 21555.510583400726, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680060, "time": 21555.516208171844, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680060, "time": 21556.974693775177, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 680060, "time": 21557.855304002762, "eval_episode/length": 170.0, "eval_episode/score": 0.46875, "eval_episode/reward_rate": 0.005847953216374269}
{"step": 680060, "time": 21559.461492538452, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680060, "time": 21559.467505693436, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680160, "time": 21562.40032672882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680588, "time": 21575.798393964767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680792, "time": 21581.68566942215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680928, "time": 21586.05091023445, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 681140, "time": 21592.367654323578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681164, "time": 21593.317486763, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 681628, "time": 21607.514110803604, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 681948, "time": 21617.273694992065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681976, "time": 21617.808025360107, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 682216, "time": 21625.161269426346, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 682256, "time": 21626.600290298462, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 682584, "time": 21636.387711286545, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 682784, "time": 21642.693379878998, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 682868, "time": 21645.160586595535, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 683256, "time": 21656.861739635468, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 683264, "time": 21657.32752776146, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 683408, "time": 21661.739562273026, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 683640, "time": 21668.60199379921, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 683680, "time": 21670.02901315689, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 683808, "time": 21673.917922258377, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 683820, "time": 21674.393651485443, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 683900, "time": 21676.8197722435, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 684160, "time": 21684.623911619186, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 684184, "time": 21685.146300554276, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 684420, "time": 21692.663920879364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684492, "time": 21695.0942363739, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 684892, "time": 21707.253154039383, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 684976, "time": 21709.7206530571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 685340, "time": 21720.86545920372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 685432, "time": 21723.42006278038, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 685500, "time": 21725.80516934395, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 685576, "time": 21727.80804181099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 685876, "time": 21737.060913562775, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 686048, "time": 21742.466621637344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686232, "time": 21747.89724636078, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 686416, "time": 21753.82680416107, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 686588, "time": 21759.193642139435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686656, "time": 21761.168717861176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686892, "time": 21768.50386238098, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 686992, "time": 21771.45750260353, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 687384, "time": 21783.211182117462, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 687500, "time": 21787.10500407219, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 687744, "time": 21794.45676112175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687812, "time": 21796.45820236206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 688168, "time": 21807.251259803772, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 688256, "time": 21810.145170211792, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 688284, "time": 21811.163293123245, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 688488, "time": 21817.320048332214, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 688536, "time": 21818.79680466652, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 688732, "time": 21825.09359073639, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 688820, "time": 21827.587469100952, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 688920, "time": 21830.559235334396, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 688960, "time": 21832.003777742386, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 689100, "time": 21836.432785511017, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 689200, "time": 21839.39083790779, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 689536, "time": 21849.789455890656, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 689576, "time": 21850.810979366302, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 689724, "time": 21855.67209172249, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 689740, "time": 21856.16922879219, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 689836, "time": 21859.131714105606, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 690060, "time": 21867.079152822495, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 690060, "time": 21867.989778280258, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 690060, "time": 21867.995054483414, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 690060, "time": 21868.095097064972, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 690060, "time": 21868.78856086731, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 690060, "time": 21869.30624938011, "eval_episode/length": 209.0, "eval_episode/score": 0.34687501192092896, "eval_episode/reward_rate": 0.004761904761904762}
{"step": 690060, "time": 21870.35497546196, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 690060, "time": 21870.58131670952, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 690552, "time": 21885.414335250854, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 690880, "time": 21895.67791080475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690896, "time": 21896.17406821251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690928, "time": 21897.158847332, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 691552, "time": 21916.39938020706, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 691636, "time": 21918.88832640648, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 691780, "time": 21923.26991033554, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 692084, "time": 21932.643628120422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692188, "time": 21936.07271671295, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 692412, "time": 21942.931354761124, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 692708, "time": 21951.954664230347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692708, "time": 21951.960345506668, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 692820, "time": 21955.43915438652, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 692936, "time": 21958.892238140106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 693192, "time": 21966.80042219162, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 693284, "time": 21969.72278523445, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 693284, "time": 21969.72836446762, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 693484, "time": 21976.065149068832, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 693636, "time": 21980.49079322815, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 693748, "time": 21983.92666554451, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 693856, "time": 21987.309166908264, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 694156, "time": 21996.550101041794, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 694352, "time": 22002.4372882843, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 694364, "time": 22002.914982557297, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 694392, "time": 22003.452228307724, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 694412, "time": 22004.392016410828, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 694628, "time": 22010.75806427002, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 694984, "time": 22021.52206134796, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 694988, "time": 22021.984931230545, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 694992, "time": 22022.00521826744, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 695392, "time": 22034.162227392197, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 695620, "time": 22041.006534337997, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 695764, "time": 22045.406903266907, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 695840, "time": 22047.84701681137, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 695912, "time": 22049.819138526917, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 696512, "time": 22068.300708055496, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 696548, "time": 22069.29371547699, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 696616, "time": 22071.433616399765, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 696748, "time": 22075.78307080269, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 697032, "time": 22084.12198638916, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 697060, "time": 22085.091449022293, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 697404, "time": 22095.861477136612, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 697588, "time": 22101.29642367363, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 697780, "time": 22107.131878614426, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 697996, "time": 22113.962680101395, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 698180, "time": 22119.3557844162, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 698184, "time": 22119.37778043747, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 698216, "time": 22120.38986515999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698352, "time": 22124.762374401093, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 698396, "time": 22126.201369047165, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 698636, "time": 22133.51717734337, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 699120, "time": 22148.3203933239, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 699340, "time": 22155.170740127563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699360, "time": 22155.678231716156, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 699372, "time": 22156.15479326248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699552, "time": 22161.54997444153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699892, "time": 22171.97383761406, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 700028, "time": 22176.380049943924, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 700060, "time": 22178.2274954319, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 700060, "time": 22178.65190577507, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 700060, "time": 22179.006284236908, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 700060, "time": 22179.631393671036, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 700060, "time": 22180.38132929802, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 700060, "time": 22180.483005285263, "eval_episode/length": 226.0, "eval_episode/score": 0.29374998807907104, "eval_episode/reward_rate": 0.004405286343612335}
{"step": 700060, "time": 22181.31009030342, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700060, "time": 22181.686284780502, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 700496, "time": 22194.936690092087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700516, "time": 22195.45171046257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700600, "time": 22197.93933749199, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 700800, "time": 22204.547878980637, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 700809, "time": 22205.5697722435, "train_stats/mean_log_entropy": 0.08530378319761332, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.602914168008009, "train/action_min": 0.0, "train/action_std": 1.5074189913332763, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010842905677012613, "train/actor_opt_grad_steps": 42710.0, "train/actor_opt_loss": -3.593573617725516, "train/adv_mag": 0.8410253554732356, "train/adv_max": 0.3066715669991383, "train/adv_mean": 0.005409040391192439, "train/adv_min": -0.8072983981975957, "train/adv_std": 0.03265998909371582, "train/cont_avg": 0.9959563442211056, "train/cont_loss_mean": 0.013257422842478482, "train/cont_loss_std": 0.2059911841774668, "train/cont_neg_acc": 0.4185666237214599, "train/cont_neg_loss": 2.5649850919652812, "train/cont_pos_acc": 0.9998571105937862, "train/cont_pos_loss": 0.0027040648630974654, "train/cont_pred": 0.995890505050295, "train/cont_rate": 0.9959563442211056, "train/dyn_loss_mean": 1.0000014155354333, "train/dyn_loss_std": 4.527823726840238e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3350855329134806, "train/extr_critic_critic_opt_grad_steps": 42710.0, "train/extr_critic_critic_opt_loss": 12829.588037845477, "train/extr_critic_mag": 1.07702017429486, "train/extr_critic_max": 1.07702017429486, "train/extr_critic_mean": 1.0028740125684883, "train/extr_critic_min": 0.8858546066523796, "train/extr_critic_std": 0.018920587867161436, "train/extr_return_normed_mag": 0.8261436882929586, "train/extr_return_normed_max": 0.3305412947232999, "train/extr_return_normed_mean": 0.04173049203415013, "train/extr_return_normed_min": -0.7868068059485163, "train/extr_return_normed_std": 0.038589280866198804, "train/extr_return_rate": 0.9989331861836227, "train/extr_return_raw_mag": 1.2970937933754083, "train/extr_return_raw_max": 1.2970937933754083, "train/extr_return_raw_mean": 1.0082830385347108, "train/extr_return_raw_min": 0.1797456927035921, "train/extr_return_raw_std": 0.03858928079599861, "train/extr_reward_mag": 0.3785784741741928, "train/extr_reward_max": 0.3785784741741928, "train/extr_reward_mean": 0.002586031202595428, "train/extr_reward_min": 3.690096601169912e-07, "train/extr_reward_std": 0.01365799939344127, "train/image_loss_mean": 0.09694510698318481, "train/image_loss_std": 0.10265092589148325, "train/model_loss_mean": 0.7158095486200036, "train/model_loss_std": 0.3279886319484543, "train/model_opt_grad_norm": 21.03999361847386, "train/model_opt_grad_steps": 42673.115577889446, "train/model_opt_loss": 3795.706782202026, "train/model_opt_model_opt_grad_overflow": 0.005025125628140704, "train/model_opt_model_opt_grad_scale": 5276.381909547738, "train/policy_entropy_mag": 1.3420401548021403, "train/policy_entropy_max": 1.3420401548021403, "train/policy_entropy_mean": 0.1195110150018529, "train/policy_entropy_min": 0.06468651492391998, "train/policy_entropy_std": 0.1549095305141492, "train/policy_logprob_mag": 6.551080238879027, "train/policy_logprob_max": -0.008608156356529974, "train/policy_logprob_mean": -0.11932912191853451, "train/policy_logprob_min": -6.551080238879027, "train/policy_logprob_std": 0.6549611214417309, "train/policy_randomness_mag": 0.6896722526406524, "train/policy_randomness_max": 0.6896722526406524, "train/policy_randomness_mean": 0.061416516146018875, "train/policy_randomness_min": 0.03324229361948056, "train/policy_randomness_std": 0.07960775561967687, "train/post_ent_mag": 48.97617205902559, "train/post_ent_max": 48.97617205902559, "train/post_ent_mean": 45.79385314634697, "train/post_ent_min": 43.954670239932575, "train/post_ent_std": 0.9978935128480346, "train/prior_ent_mag": 48.3777267992796, "train/prior_ent_max": 48.3777267992796, "train/prior_ent_mean": 45.34655499098888, "train/prior_ent_min": 42.73120546580559, "train/prior_ent_std": 1.0240183547513568, "train/rep_loss_mean": 1.0000014155354333, "train/rep_loss_std": 4.527823726840238e-05, "train/reward_avg": 0.0007422059043439283, "train/reward_loss_mean": 0.005606145421323839, "train/reward_loss_std": 0.11673073186106213, "train/reward_max_data": 0.48698178323070007, "train/reward_max_pred": 0.16997789018717244, "train/reward_neg_acc": 0.9998280097491777, "train/reward_neg_loss": 0.000908828868654126, "train/reward_pos_acc": 0.28097015041023937, "train/reward_pos_loss": 4.093345888515017, "train/reward_pred": 0.0005890656907307967, "train/reward_rate": 0.001133597675879397, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.008480554446578026, "report/cont_loss_std": 0.14393390715122223, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.6507863998413086, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.002040137769654393, "report/cont_pred": 0.9962671995162964, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11783614009618759, "report/image_loss_std": 0.11486627161502838, "report/model_loss_mean": 0.73299241065979, "report/model_loss_std": 0.3288445770740509, "report/post_ent_mag": 50.13751983642578, "report/post_ent_max": 50.13751983642578, "report/post_ent_mean": 46.719078063964844, "report/post_ent_min": 44.80320358276367, "report/post_ent_std": 1.1119472980499268, "report/prior_ent_mag": 52.831321716308594, "report/prior_ent_max": 52.831321716308594, "report/prior_ent_mean": 46.29529571533203, "report/prior_ent_min": 43.40135955810547, "report/prior_ent_std": 1.5571894645690918, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005950927734375, "report/reward_loss_mean": 0.006675670389086008, "report/reward_loss_std": 0.1617388278245926, "report/reward_max_data": 0.4781250059604645, "report/reward_max_pred": 0.2497847080230713, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00059723318554461, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 3.1127572059631348, "report/reward_pred": 0.0005420716479420662, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.041335027664899826, "eval/cont_loss_std": 0.6935455203056335, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.54168701171875, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.0046052951365709305, "eval/cont_pred": 0.997655987739563, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1888064444065094, "eval/image_loss_std": 0.163581982254982, "eval/model_loss_mean": 0.8416329622268677, "eval/model_loss_std": 0.9321777820587158, "eval/post_ent_mag": 50.13710403442383, "eval/post_ent_max": 50.13710403442383, "eval/post_ent_mean": 46.67219543457031, "eval/post_ent_min": 44.7364501953125, "eval/post_ent_std": 1.064084768295288, "eval/prior_ent_mag": 52.831321716308594, "eval/prior_ent_max": 52.831321716308594, "eval/prior_ent_mean": 46.17930221557617, "eval/prior_ent_min": 43.4305419921875, "eval/prior_ent_std": 1.5566128492355347, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007049560663290322, "eval/reward_loss_mean": 0.011491479352116585, "eval/reward_loss_std": 0.35455119609832764, "eval/reward_max_data": 0.721875011920929, "eval/reward_max_pred": 0.035814523696899414, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00040731029002927244, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 11.35059642791748, "eval/reward_pred": 0.00016926659736782312, "eval/reward_rate": 0.0009765625, "replay/size": 700297.0, "replay/inserts": 31808.0, "replay/samples": 31808.0, "replay/insert_wait_avg": 1.4730487431079088e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.784432568540516e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7088.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2827444291814456e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3855047225952, "timer/env.step_count": 7952.0, "timer/env.step_total": 36.8040030002594, "timer/env.step_frac": 0.03678982035077075, "timer/env.step_avg": 0.00462826999500244, "timer/env.step_min": 0.0034351348876953125, "timer/env.step_max": 0.029634714126586914, "timer/replay._sample_count": 31808.0, "timer/replay._sample_total": 15.857004165649414, "timer/replay._sample_frac": 0.015850893571320315, "timer/replay._sample_avg": 0.0004985225152681531, "timer/replay._sample_min": 0.00040411949157714844, "timer/replay._sample_max": 0.026309490203857422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9724.0, "timer/agent.policy_total": 89.09385681152344, "timer/agent.policy_frac": 0.08905952394445077, "timer/agent.policy_avg": 0.009162264172308046, "timer/agent.policy_min": 0.00804281234741211, "timer/agent.policy_max": 0.04289126396179199, "timer/dataset_train_count": 1988.0, "timer/dataset_train_total": 0.20862102508544922, "timer/dataset_train_frac": 0.00020854063168708085, "timer/dataset_train_avg": 0.00010494015346350564, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.001032114028930664, "timer/agent.train_count": 1988.0, "timer/agent.train_total": 858.7295672893524, "timer/agent.train_frac": 0.8583986505556939, "timer/agent.train_avg": 0.43195652278136437, "timer/agent.train_min": 0.42105603218078613, "timer/agent.train_max": 0.5119626522064209, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48061227798461914, "timer/agent.report_frac": 0.0004804270710798553, "timer/agent.report_avg": 0.24030613899230957, "timer/agent.report_min": 0.2346630096435547, "timer/agent.report_max": 0.24594926834106445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.050581798809896e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 31.795115830543097}
{"step": 700916, "time": 22208.717925310135, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 701016, "time": 22211.67081975937, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 701184, "time": 22217.030907392502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701384, "time": 22222.95533633232, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 701604, "time": 22229.78489780426, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 701620, "time": 22230.271202802658, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 701956, "time": 22240.606642007828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701960, "time": 22240.627379894257, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 702172, "time": 22247.495587825775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702280, "time": 22250.510995149612, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 702540, "time": 22258.835233926773, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 702564, "time": 22259.363096237183, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 702604, "time": 22260.82569551468, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 702776, "time": 22265.881893634796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702948, "time": 22271.270987033844, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 703020, "time": 22273.716009140015, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 703228, "time": 22280.142748594284, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 703668, "time": 22293.527668476105, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 703696, "time": 22294.503625392914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 703760, "time": 22296.47603583336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 703848, "time": 22298.975574970245, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 703996, "time": 22303.853086471558, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 704356, "time": 22314.664154291153, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 704580, "time": 22321.605313539505, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 704588, "time": 22322.084507465363, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 704844, "time": 22330.07324385643, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 704852, "time": 22330.112993478775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705064, "time": 22336.541611671448, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 705132, "time": 22338.996581315994, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 705164, "time": 22339.982091665268, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 705460, "time": 22348.88597011566, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 705576, "time": 22352.440616846085, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 705600, "time": 22353.397440195084, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 705732, "time": 22357.340098142624, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 705776, "time": 22358.80148792267, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 705864, "time": 22361.268509864807, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 706152, "time": 22370.075453042984, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 706344, "time": 22375.971053361893, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 706440, "time": 22378.916481733322, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 706524, "time": 22381.900349855423, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 706596, "time": 22383.89277791977, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 706708, "time": 22387.330986976624, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 706888, "time": 22392.750406742096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706888, "time": 22392.7556784153, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 707052, "time": 22398.11230325699, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 707376, "time": 22407.967052459717, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 707752, "time": 22419.31006836891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707780, "time": 22420.27495956421, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 708044, "time": 22428.563472032547, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 708124, "time": 22431.01668381691, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 708208, "time": 22433.469217538834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 708604, "time": 22445.74805545807, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 708888, "time": 22454.2851061821, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 708936, "time": 22455.77433490753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709088, "time": 22460.630405664444, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 709128, "time": 22461.63784956932, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 709200, "time": 22464.059067487717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709276, "time": 22466.494980335236, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 709308, "time": 22467.47665143013, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 709560, "time": 22474.931789636612, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 709736, "time": 22480.312769174576, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 709816, "time": 22482.76742219925, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 709992, "time": 22488.166566371918, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 710060, "time": 22490.959117412567, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 710060, "time": 22490.96351981163, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 710060, "time": 22491.434176445007, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 710060, "time": 22492.05050253868, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 710060, "time": 22494.507811784744, "eval_episode/length": 179.0, "eval_episode/score": 0.44062501192092896, "eval_episode/reward_rate": 0.005555555555555556}
{"step": 710060, "time": 22494.528376340866, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710060, "time": 22494.90588951111, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710060, "time": 22494.912889242172, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710296, "time": 22501.8270111084, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 710356, "time": 22503.778094291687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710880, "time": 22519.878209590912, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 710972, "time": 22522.795535564423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711452, "time": 22537.504823207855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711512, "time": 22539.02040696144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711520, "time": 22539.480056762695, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 711624, "time": 22542.426038742065, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 711628, "time": 22542.89384317398, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 711824, "time": 22548.802956581116, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 712676, "time": 22574.939326763153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712780, "time": 22578.345602989197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712784, "time": 22578.368239164352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712948, "time": 22583.290709733963, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 712980, "time": 22584.453533411026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713048, "time": 22586.448096990585, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 713160, "time": 22589.913518190384, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 713244, "time": 22592.92231297493, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 713456, "time": 22599.32297205925, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 713496, "time": 22600.334881305695, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 713604, "time": 22603.749629974365, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 713704, "time": 22606.700930595398, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 713832, "time": 22610.638332128525, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 713852, "time": 22611.59294319153, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 713868, "time": 22612.109417438507, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 713876, "time": 22612.144859313965, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 714060, "time": 22618.020179510117, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 714144, "time": 22620.484916448593, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 714320, "time": 22625.900931358337, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 715032, "time": 22647.450538158417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715216, "time": 22653.403700590134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715300, "time": 22655.888882875443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715388, "time": 22658.831961870193, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 715444, "time": 22660.332413434982, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 715476, "time": 22661.319808721542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715484, "time": 22661.779399633408, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 715640, "time": 22666.207309246063, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 715896, "time": 22674.03917980194, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 716052, "time": 22678.92257332802, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 716088, "time": 22679.927538633347, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 716188, "time": 22683.40241742134, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 716288, "time": 22686.355558156967, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 716732, "time": 22700.053604841232, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 716756, "time": 22700.59178185463, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 717052, "time": 22709.870218276978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717116, "time": 22712.111841201782, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 717344, "time": 22719.00318789482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717448, "time": 22721.982203245163, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 717824, "time": 22733.693026304245, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 717888, "time": 22735.665544509888, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 717912, "time": 22736.18748831749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718120, "time": 22742.666763067245, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 718272, "time": 22747.543488264084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719044, "time": 22771.08916068077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719064, "time": 22771.647080659866, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 719068, "time": 22772.09889149666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719128, "time": 22773.607343673706, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 719428, "time": 22782.91593313217, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 720060, "time": 22804.371618509293, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 720060, "time": 22804.430398225784, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 720060, "time": 22804.503930807114, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 720060, "time": 22805.957624435425, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 720060, "time": 22806.19250869751, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 720060, "time": 22806.382122516632, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 720060, "time": 22806.69624233246, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720060, "time": 22807.84753227234, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 720200, "time": 22811.77895140648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720220, "time": 22812.71967315674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720284, "time": 22814.686454296112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720332, "time": 22816.15143585205, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 720564, "time": 22823.029744148254, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 720580, "time": 22823.53202843666, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 720780, "time": 22829.87227511406, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 720792, "time": 22829.92109465599, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 720856, "time": 22831.948888778687, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 720940, "time": 22834.840126276016, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 721236, "time": 22843.82324552536, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 721328, "time": 22846.731837272644, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 721428, "time": 22849.67654275894, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 721432, "time": 22849.69610309601, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 721508, "time": 22852.12940430641, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 721564, "time": 22854.07623887062, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 721868, "time": 22863.437268018723, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 721924, "time": 22864.93225288391, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 722000, "time": 22867.377682209015, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 722392, "time": 22879.163060188293, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 722484, "time": 22882.092318296432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722720, "time": 22889.438593626022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722800, "time": 22891.946145534515, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 722864, "time": 22893.927194833755, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 723040, "time": 22899.34605240822, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 723052, "time": 22899.827091932297, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 723080, "time": 22900.36261153221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723120, "time": 22901.808887720108, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 723408, "time": 22910.628043413162, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 723620, "time": 22917.02345085144, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 723764, "time": 22921.50208377838, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 724196, "time": 22934.80693769455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724236, "time": 22936.273491859436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724276, "time": 22937.31192421913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724388, "time": 22940.81409716606, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 724492, "time": 22944.24586391449, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 724816, "time": 22954.13788509369, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 724916, "time": 22957.105823755264, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 724920, "time": 22957.127406835556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724992, "time": 22959.540885210037, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 725008, "time": 22960.033920764923, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 725192, "time": 22965.456080198288, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 725284, "time": 22968.59606862068, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 725444, "time": 22973.501525640488, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 725468, "time": 22974.457080841064, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 725492, "time": 22974.97399330139, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 725504, "time": 22975.45362329483, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 725724, "time": 22982.392409563065, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 725772, "time": 22983.87927365303, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 725980, "time": 22990.23427081108, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 726296, "time": 22999.577243089676, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 726328, "time": 23000.573710918427, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 726484, "time": 23005.4573366642, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 726600, "time": 23008.9098944664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 726648, "time": 23010.378901958466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727004, "time": 23021.685324907303, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 727484, "time": 23036.410062789917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727640, "time": 23040.894859075546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727700, "time": 23042.929362535477, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 727804, "time": 23046.324489355087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727956, "time": 23050.779315710068, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 728244, "time": 23059.63849592209, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 728400, "time": 23064.553993940353, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 728640, "time": 23071.981149435043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728796, "time": 23076.87297964096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728800, "time": 23076.893995285034, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 728804, "time": 23076.91455411911, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 729044, "time": 23084.330682992935, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 729468, "time": 23097.727762699127, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 729796, "time": 23107.63045668602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 729960, "time": 23112.54106426239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 730060, "time": 23116.36209511757, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 730060, "time": 23117.618583917618, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 730060, "time": 23117.90608906746, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 730060, "time": 23118.298063755035, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 730060, "time": 23120.01771259308, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730060, "time": 23120.0241420269, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730060, "time": 23120.045569181442, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 730060, "time": 23121.02959060669, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 730076, "time": 23121.526626110077, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 730200, "time": 23125.04610824585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 730232, "time": 23126.03678750992, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 730324, "time": 23128.96618962288, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 730444, "time": 23132.90348124504, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 730832, "time": 23144.709025621414, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 731124, "time": 23153.540314912796, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 731356, "time": 23160.901099443436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731464, "time": 23163.961712121964, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 731480, "time": 23164.479263067245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731988, "time": 23180.210717201233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732512, "time": 23196.6434571743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732620, "time": 23200.09262394905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732636, "time": 23200.59161758423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732777, "time": 23205.574271678925, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3291506958007813, "train/action_min": 0.0, "train/action_std": 1.4065211594104767, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006617799945524893, "train/actor_opt_grad_steps": 44705.0, "train/actor_opt_loss": -5.1266017121518965, "train/adv_mag": 0.7492245584726334, "train/adv_max": 0.2512399542331696, "train/adv_mean": 0.001990592077918336, "train/adv_min": -0.6925132498145103, "train/adv_std": 0.02099539901362732, "train/cont_avg": 0.995703125, "train/cont_loss_mean": 0.014146926696412265, "train/cont_loss_std": 0.21785949834389612, "train/cont_neg_acc": 0.37677183128893377, "train/cont_neg_loss": 2.6759956349851564, "train/cont_pos_acc": 0.9998577976226807, "train/cont_pos_loss": 0.002780209956690669, "train/cont_pred": 0.9957505637407302, "train/cont_rate": 0.995703125, "train/dyn_loss_mean": 1.000006404519081, "train/dyn_loss_std": 0.00013214475417044013, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16358114627655596, "train/extr_critic_critic_opt_grad_steps": 44705.0, "train/extr_critic_critic_opt_loss": 12865.669086914062, "train/extr_critic_mag": 1.1187463092803955, "train/extr_critic_max": 1.1187463092803955, "train/extr_critic_mean": 1.0668153643608094, "train/extr_critic_min": 0.9739052575826644, "train/extr_critic_std": 0.013708933177404105, "train/extr_return_normed_mag": 0.7563025563955307, "train/extr_return_normed_max": 0.260596564412117, "train/extr_return_normed_mean": 0.02804119132924825, "train/extr_return_normed_min": -0.6875539746880531, "train/extr_return_normed_std": 0.025697220582515, "train/extr_return_rate": 0.999446647465229, "train/extr_return_raw_mag": 1.3013612735271454, "train/extr_return_raw_max": 1.3013612735271454, "train/extr_return_raw_mean": 1.0688059419393539, "train/extr_return_raw_min": 0.35321073442697526, "train/extr_return_raw_std": 0.02569722043816, "train/extr_reward_mag": 0.3038045769929886, "train/extr_reward_max": 0.3038045769929886, "train/extr_reward_mean": 0.0019281228075851687, "train/extr_reward_min": 4.094839096069336e-07, "train/extr_reward_std": 0.00822291589807719, "train/image_loss_mean": 0.09585192181169987, "train/image_loss_std": 0.10219909589737654, "train/model_loss_mean": 0.7169718670845032, "train/model_loss_std": 0.3570114291459322, "train/model_opt_grad_norm": 20.01071668624878, "train/model_opt_grad_steps": 44666.205, "train/model_opt_loss": 3675.2646301269533, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5125.0, "train/policy_entropy_mag": 1.2507060223817825, "train/policy_entropy_max": 1.2507060223817825, "train/policy_entropy_mean": 0.10843916304409504, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13808063488453626, "train/policy_logprob_mag": 6.551080231666565, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1083876571059227, "train/policy_logprob_min": -6.551080231666565, "train/policy_logprob_std": 0.6443577134609222, "train/policy_randomness_mag": 0.6427357909083367, "train/policy_randomness_max": 0.6427357909083367, "train/policy_randomness_mean": 0.05572670880705118, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07095941307023168, "train/post_ent_mag": 49.55386762619018, "train/post_ent_max": 49.55386762619018, "train/post_ent_mean": 46.14011074066162, "train/post_ent_min": 43.9707887840271, "train/post_ent_std": 1.1520282465219498, "train/prior_ent_mag": 50.77807016372681, "train/prior_ent_max": 50.77807016372681, "train/prior_ent_mean": 45.54720983505249, "train/prior_ent_min": 42.82090341567993, "train/prior_ent_std": 1.284292708337307, "train/rep_loss_mean": 1.000006404519081, "train/rep_loss_std": 0.00013214475417044013, "train/reward_avg": 0.0009410247836058261, "train/reward_loss_mean": 0.006969152482924983, "train/reward_loss_std": 0.1404228679445805, "train/reward_max_data": 0.5651250026375055, "train/reward_max_pred": 0.20229561686515807, "train/reward_neg_acc": 0.9998581501841545, "train/reward_neg_loss": 0.0010541345218371134, "train/reward_pos_acc": 0.25573248563298756, "train/reward_pos_loss": 3.9643126038988683, "train/reward_pred": 0.0007068614469608292, "train/reward_rate": 0.0014697265625, "train_stats/mean_log_entropy": 0.074008408102017, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.011235259473323822, "report/cont_loss_std": 0.17091377079486847, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 1.8150255680084229, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002384472405537963, "report/cont_pred": 0.9956594705581665, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08186790347099304, "report/image_loss_std": 0.09198818355798721, "report/model_loss_mean": 0.6983052492141724, "report/model_loss_std": 0.317478746175766, "report/post_ent_mag": 49.65797424316406, "report/post_ent_max": 49.65797424316406, "report/post_ent_mean": 46.21420669555664, "report/post_ent_min": 44.102806091308594, "report/post_ent_std": 1.2219302654266357, "report/prior_ent_mag": 49.201969146728516, "report/prior_ent_max": 49.201969146728516, "report/prior_ent_mean": 46.15928649902344, "report/prior_ent_min": 43.52924346923828, "report/prior_ent_std": 1.1237800121307373, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008453369373455644, "report/reward_loss_mean": 0.005202050320804119, "report/reward_loss_std": 0.1473792940378189, "report/reward_max_data": 0.8656250238418579, "report/reward_max_pred": 0.024053573608398438, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000595098827034235, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.718113422393799, "report/reward_pred": 0.000305676250718534, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.027586184442043304, "eval/cont_loss_std": 0.5834810137748718, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 13.214845657348633, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0017794151790440083, "eval/cont_pred": 0.998238205909729, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1438671052455902, "eval/image_loss_std": 0.131259024143219, "eval/model_loss_mean": 0.7718185186386108, "eval/model_loss_std": 0.5965733528137207, "eval/post_ent_mag": 49.69297790527344, "eval/post_ent_max": 49.69297790527344, "eval/post_ent_mean": 45.9421501159668, "eval/post_ent_min": 43.836669921875, "eval/post_ent_std": 1.2176599502563477, "eval/prior_ent_mag": 49.445037841796875, "eval/prior_ent_max": 49.445037841796875, "eval/prior_ent_mean": 45.8773307800293, "eval/prior_ent_min": 43.34851837158203, "eval/prior_ent_std": 1.0514172315597534, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00036515388637781143, "eval/reward_loss_std": 0.0017785069067031145, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.009129047393798828, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00036515388637781143, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001865843078121543, "eval/reward_rate": 0.0, "replay/size": 732265.0, "replay/inserts": 31968.0, "replay/samples": 31968.0, "replay/insert_wait_avg": 1.4805325397380717e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.7087255349985e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4204.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2673501396723637e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9864814281464, "timer/env.step_count": 7992.0, "timer/env.step_total": 37.435263872146606, "timer/env.step_frac": 0.037435769950292574, "timer/env.step_avg": 0.004684092076094421, "timer/env.step_min": 0.0034804344177246094, "timer/env.step_max": 0.030272245407104492, "timer/replay._sample_count": 31968.0, "timer/replay._sample_total": 16.065263509750366, "timer/replay._sample_frac": 0.016065480692105467, "timer/replay._sample_avg": 0.0005025420267064053, "timer/replay._sample_min": 0.00032973289489746094, "timer/replay._sample_max": 0.023879051208496094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9043.0, "timer/agent.policy_total": 83.2042133808136, "timer/agent.policy_frac": 0.08320533819815663, "timer/agent.policy_avg": 0.009200952491519806, "timer/agent.policy_min": 0.008076190948486328, "timer/agent.policy_max": 0.04076504707336426, "timer/dataset_train_count": 1998.0, "timer/dataset_train_total": 0.21142911911010742, "timer/dataset_train_frac": 0.00021143197736848564, "timer/dataset_train_avg": 0.0001058203799349887, "timer/dataset_train_min": 8.535385131835938e-05, "timer/dataset_train_max": 0.0009667873382568359, "timer/agent.train_count": 1998.0, "timer/agent.train_total": 867.1467568874359, "timer/agent.train_frac": 0.8671584796316513, "timer/agent.train_avg": 0.4340073858295475, "timer/agent.train_min": 0.4235851764678955, "timer/agent.train_max": 0.5391156673431396, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4827542304992676, "timer/agent.report_frac": 0.00048276075673524564, "timer/agent.report_avg": 0.2413771152496338, "timer/agent.report_min": 0.2351689338684082, "timer/agent.report_max": 0.24758529663085938, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.765692905796397e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 31.967803755995963}
{"step": 732792, "time": 23205.653060674667, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 733108, "time": 23215.84605526924, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 733144, "time": 23216.850385427475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733188, "time": 23218.304203033447, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 733348, "time": 23223.233213424683, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 733580, "time": 23230.768890619278, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 733676, "time": 23233.687035560608, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 733780, "time": 23236.665865659714, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 733864, "time": 23239.160615205765, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 734100, "time": 23246.505712270737, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 734220, "time": 23250.4254655838, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 734580, "time": 23261.356046438217, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 734664, "time": 23263.832853794098, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 734832, "time": 23269.219237089157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735020, "time": 23275.099722385406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735232, "time": 23281.519317150116, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 735408, "time": 23286.900202274323, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 735452, "time": 23288.36939764023, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 735596, "time": 23292.77556991577, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 735940, "time": 23303.144987344742, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 736176, "time": 23310.50252008438, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 736564, "time": 23322.273540258408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 736608, "time": 23323.750492334366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 736820, "time": 23330.087815999985, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 736884, "time": 23332.033399820328, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 737028, "time": 23336.430899858475, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 737064, "time": 23337.417467832565, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 737964, "time": 23365.509732961655, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 738036, "time": 23367.50690793991, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 738040, "time": 23367.52979683876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 738220, "time": 23373.398513317108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 738504, "time": 23381.694076776505, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 738528, "time": 23382.666579961777, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 738740, "time": 23389.04670405388, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 738744, "time": 23389.068194627762, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 739376, "time": 23408.751304149628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739428, "time": 23410.25215435028, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 739600, "time": 23415.61644387245, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 739704, "time": 23418.58996796608, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 739856, "time": 23423.472009897232, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 739896, "time": 23424.484571933746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739976, "time": 23426.95569038391, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 740060, "time": 23433.90518116951, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740060, "time": 23433.9115524292, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740060, "time": 23433.91752552986, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740060, "time": 23433.92350935936, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740060, "time": 23434.98380446434, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 740060, "time": 23435.332281589508, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 740060, "time": 23435.489834070206, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 740060, "time": 23435.629589557648, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 740100, "time": 23436.63201856613, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 740344, "time": 23444.01311659813, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 740660, "time": 23453.788538455963, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 740756, "time": 23456.74332332611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741052, "time": 23466.01991558075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741256, "time": 23471.93339252472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741280, "time": 23472.876638650894, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 741560, "time": 23481.22545528412, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 741620, "time": 23483.161998033524, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 741816, "time": 23489.262027025223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742020, "time": 23495.634488344193, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 742096, "time": 23498.090530395508, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 742192, "time": 23501.064208745956, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 742436, "time": 23508.411472320557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742660, "time": 23515.24505853653, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 742712, "time": 23516.739624023438, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 742776, "time": 23518.684631347656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742848, "time": 23521.169184207916, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 743020, "time": 23526.57537817955, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 743100, "time": 23529.030719280243, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 743260, "time": 23533.929013967514, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 743280, "time": 23534.437901735306, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 743824, "time": 23551.029727697372, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 743976, "time": 23555.56019258499, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 744004, "time": 23556.534840106964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744256, "time": 23564.390383958817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744980, "time": 23586.38740849495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745132, "time": 23591.273515939713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745160, "time": 23591.809032440186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745412, "time": 23599.6407020092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745476, "time": 23601.594799041748, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 745836, "time": 23612.98125910759, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 746136, "time": 23621.90280842781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746252, "time": 23625.7855553627, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 746356, "time": 23628.76533317566, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 746468, "time": 23632.196403741837, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 746664, "time": 23638.09245109558, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 746904, "time": 23645.435916423798, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 747164, "time": 23653.699244976044, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 747300, "time": 23657.63505768776, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 747408, "time": 23661.067912817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747552, "time": 23665.446194648743, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 747668, "time": 23668.891113996506, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 747820, "time": 23673.853944778442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748332, "time": 23689.53345656395, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 748564, "time": 23696.41006565094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748708, "time": 23700.854226350784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748824, "time": 23704.41071486473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748896, "time": 23706.842433452606, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 749324, "time": 23720.105379104614, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 749572, "time": 23727.51406764984, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 749660, "time": 23730.41455435753, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 749864, "time": 23736.579256296158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 750000, "time": 23740.97902226448, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 750008, "time": 23741.013499736786, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 750052, "time": 23742.488468408585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 750060, "time": 23744.27681350708, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 750060, "time": 23745.889326334, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 750060, "time": 23747.279541254044, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750060, "time": 23747.28537249565, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750060, "time": 23747.290889263153, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750060, "time": 23747.7151389122, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 750060, "time": 23748.049681663513, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 750060, "time": 23748.15312218666, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 750092, "time": 23749.141295433044, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 750340, "time": 23756.523784160614, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 750344, "time": 23756.54678583145, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 750496, "time": 23761.46626472473, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 750732, "time": 23768.803453445435, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 750884, "time": 23773.23342704773, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 750992, "time": 23776.631631612778, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 751184, "time": 23782.444432497025, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 751248, "time": 23784.404593229294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751356, "time": 23787.794819831848, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 751596, "time": 23795.152180194855, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 751656, "time": 23796.682451486588, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 751776, "time": 23800.591807842255, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 752512, "time": 23823.158580064774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752752, "time": 23830.543048143387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752812, "time": 23832.48864722252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752932, "time": 23835.969352722168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752952, "time": 23836.476259469986, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 752960, "time": 23836.94687819481, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 753444, "time": 23851.68565607071, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 753668, "time": 23858.527239322662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753772, "time": 23861.926478862762, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 753792, "time": 23862.43561220169, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 754076, "time": 23871.388167619705, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 754080, "time": 23871.41108417511, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 754108, "time": 23872.38733434677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 754348, "time": 23879.76892733574, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 754520, "time": 23884.782346725464, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 754928, "time": 23897.50020647049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755020, "time": 23900.435802936554, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 755040, "time": 23900.94513773918, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 755264, "time": 23907.812048196793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755284, "time": 23908.317934274673, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 755304, "time": 23908.82560658455, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 755568, "time": 23917.20999121666, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 755628, "time": 23919.177552700043, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 755672, "time": 23920.20049405098, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 755924, "time": 23928.02216243744, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 756028, "time": 23931.42382478714, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 756036, "time": 23931.457698106766, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 756196, "time": 23936.377702713013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 756320, "time": 23940.295285463333, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 756408, "time": 23942.857495307922, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 756544, "time": 23947.2593228817, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 756792, "time": 23954.62571501732, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 756952, "time": 23959.539102315903, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 757080, "time": 23963.429018735886, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 757476, "time": 23975.65152001381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757512, "time": 23976.64631676674, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 757792, "time": 23985.413666009903, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 758108, "time": 23995.342720746994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 758196, "time": 23997.83228611946, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 758236, "time": 23999.276322364807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 758632, "time": 24011.087289094925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759264, "time": 24030.59651041031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759352, "time": 24033.161201238632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759392, "time": 24034.606056690216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759488, "time": 24037.573915481567, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 759564, "time": 24040.033484697342, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 759624, "time": 24041.556829690933, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 759752, "time": 24045.484163045883, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 759772, "time": 24046.423124551773, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 759784, "time": 24046.470996141434, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 760060, "time": 24056.428780317307, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 760060, "time": 24056.490877628326, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 760060, "time": 24056.729383468628, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 760060, "time": 24056.954806804657, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 760060, "time": 24057.77605509758, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 760060, "time": 24060.542338848114, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760060, "time": 24060.85286784172, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760060, "time": 24061.13144350052, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760136, "time": 24063.188048362732, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 760264, "time": 24067.117332220078, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 760420, "time": 24072.02066063881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 760684, "time": 24080.341396808624, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 760752, "time": 24082.347992420197, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 760908, "time": 24087.25919032097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 760996, "time": 24089.75406885147, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 761092, "time": 24092.743496656418, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 761228, "time": 24097.160925149918, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 761324, "time": 24100.128888607025, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 761576, "time": 24107.594180345535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 761616, "time": 24109.040096759796, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 761856, "time": 24116.38459253311, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 761944, "time": 24118.87690925598, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 762008, "time": 24120.84891319275, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 762152, "time": 24125.54670381546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 762348, "time": 24131.889510393143, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 762376, "time": 24132.41739630699, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 762820, "time": 24146.094532489777, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 763012, "time": 24152.01318526268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 763156, "time": 24156.427082061768, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 763164, "time": 24156.89821743965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 763528, "time": 24167.74935722351, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 763532, "time": 24168.207695007324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764048, "time": 24184.039878845215, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 764168, "time": 24187.517766475677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764264, "time": 24190.44519662857, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 764304, "time": 24191.886349201202, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 764320, "time": 24192.377492189407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764424, "time": 24195.32324028015, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 764672, "time": 24203.127727270126, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 764729, "time": 24205.595484495163, "train_stats/mean_log_entropy": 0.08169911980318527, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2445868870720793, "train/action_min": 0.0, "train/action_std": 1.2737653566964309, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006647912339639649, "train/actor_opt_grad_steps": 46700.0, "train/actor_opt_loss": -6.934407732987673, "train/adv_mag": 0.8091835250806569, "train/adv_max": 0.22725302789678525, "train/adv_mean": 0.0010968569214635671, "train/adv_min": -0.7878053721471049, "train/adv_std": 0.019625909694344103, "train/cont_avg": 0.9956177371231156, "train/cont_loss_mean": 0.014435101684824043, "train/cont_loss_std": 0.218727569315751, "train/cont_neg_acc": 0.3821861172589112, "train/cont_neg_loss": 2.6303764933729736, "train/cont_pos_acc": 0.9998669603362156, "train/cont_pos_loss": 0.002805681965295132, "train/cont_pred": 0.9956996863211819, "train/cont_rate": 0.9956177371231156, "train/dyn_loss_mean": 1.0000369602711356, "train/dyn_loss_std": 0.0005697475707663888, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12992459629667014, "train/extr_critic_critic_opt_grad_steps": 46700.0, "train/extr_critic_critic_opt_loss": 11063.793434948178, "train/extr_critic_mag": 1.1598462818855018, "train/extr_critic_max": 1.1598462818855018, "train/extr_critic_mean": 1.1085333093326895, "train/extr_critic_min": 1.0024911189199093, "train/extr_critic_std": 0.015164666284980187, "train/extr_return_normed_mag": 0.8170043361845927, "train/extr_return_normed_max": 0.24477952209549333, "train/extr_return_normed_mean": 0.028500826227895203, "train/extr_return_normed_min": -0.784439566746429, "train/extr_return_normed_std": 0.025461670647763727, "train/extr_return_rate": 0.9996359144622956, "train/extr_return_raw_mag": 1.3259088040596276, "train/extr_return_raw_max": 1.3259088040596276, "train/extr_return_raw_mean": 1.1096301677838043, "train/extr_return_raw_min": 0.2966897152177054, "train/extr_return_raw_std": 0.025461670849004282, "train/extr_reward_mag": 0.26715582519320386, "train/extr_reward_max": 0.26715582519320386, "train/extr_reward_mean": 0.00162765905717341, "train/extr_reward_min": 3.20487285978231e-07, "train/extr_reward_std": 0.007676489619613068, "train/image_loss_mean": 0.0962274834775745, "train/image_loss_std": 0.1036369875447834, "train/model_loss_mean": 0.7180456531107725, "train/model_loss_std": 0.3602339073117055, "train/model_opt_grad_norm": 19.850654987373737, "train/model_opt_grad_steps": 46659.19095477387, "train/model_opt_loss": 2687.1106306679885, "train/model_opt_model_opt_grad_overflow": 0.005025125628140704, "train/model_opt_model_opt_grad_scale": 3731.1557788944724, "train/policy_entropy_mag": 1.1890330745946223, "train/policy_entropy_max": 1.1890330745946223, "train/policy_entropy_mean": 0.10523892077968348, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1321578568324971, "train/policy_logprob_mag": 6.55108022929436, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10549405385651181, "train/policy_logprob_min": -6.55108022929436, "train/policy_logprob_std": 0.642687621128619, "train/policy_randomness_mag": 0.6110421592865757, "train/policy_randomness_max": 0.6110421592865757, "train/policy_randomness_mean": 0.05408210885809295, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06791570788277454, "train/post_ent_mag": 55.46520388425894, "train/post_ent_max": 55.46520388425894, "train/post_ent_mean": 50.65664047931307, "train/post_ent_min": 47.66891517830854, "train/post_ent_std": 1.579551788430717, "train/prior_ent_mag": 56.0478288468404, "train/prior_ent_max": 56.0478288468404, "train/prior_ent_mean": 50.80981945632091, "train/prior_ent_min": 46.34609000047847, "train/prior_ent_std": 1.7337252740284905, "train/rep_loss_mean": 1.0000369602711356, "train/rep_loss_std": 0.0005697475707663888, "train/reward_avg": 0.0009882021181305272, "train/reward_loss_mean": 0.007360865835839854, "train/reward_loss_std": 0.1430968439941243, "train/reward_max_data": 0.5899026385653559, "train/reward_max_pred": 0.17628726048685198, "train/reward_neg_acc": 0.9998771104980354, "train/reward_neg_loss": 0.0011899468817177167, "train/reward_pos_acc": 0.2133123702223196, "train/reward_pos_loss": 4.033822777136317, "train/reward_pred": 0.0007290910103419168, "train/reward_rate": 0.0015065562185929647, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.006880119442939758, "report/cont_loss_std": 0.11875307559967041, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.794241428375244, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0031779089476913214, "report/cont_pred": 0.99684739112854, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07369080185890198, "report/image_loss_std": 0.07841676473617554, "report/model_loss_mean": 0.6819599866867065, "report/model_loss_std": 0.14121408760547638, "report/post_ent_mag": 57.81825637817383, "report/post_ent_max": 57.81825637817383, "report/post_ent_mean": 53.05227279663086, "report/post_ent_min": 49.569740295410156, "report/post_ent_std": 1.6168978214263916, "report/prior_ent_mag": 58.78516387939453, "report/prior_ent_max": 58.78516387939453, "report/prior_ent_mean": 52.89625549316406, "report/prior_ent_min": 47.57783889770508, "report/prior_ent_std": 1.8782888650894165, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0013890191912651062, "report/reward_loss_std": 0.0068098255433142185, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.04841732978820801, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0013890191912651062, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0007116731721907854, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.06262515485286713, "eval/cont_loss_std": 0.8393377661705017, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.449694633483887, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0014047063887119293, "eval/cont_pred": 0.9986107349395752, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15878409147262573, "eval/image_loss_std": 0.1433531790971756, "eval/model_loss_mean": 0.8281735181808472, "eval/model_loss_std": 0.9137959480285645, "eval/post_ent_mag": 57.771446228027344, "eval/post_ent_max": 57.771446228027344, "eval/post_ent_mean": 52.40467834472656, "eval/post_ent_min": 49.59526062011719, "eval/post_ent_std": 1.6906825304031372, "eval/prior_ent_mag": 59.03199005126953, "eval/prior_ent_max": 59.03199005126953, "eval/prior_ent_mean": 52.067138671875, "eval/prior_ent_min": 47.11384582519531, "eval/prior_ent_std": 2.0410847663879395, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007507324335165322, "eval/reward_loss_mean": 0.006764239631593227, "eval/reward_loss_std": 0.2052568942308426, "eval/reward_max_data": 0.768750011920929, "eval/reward_max_pred": 0.014703035354614258, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0003470908268354833, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.571507453918457, "eval/reward_pred": 0.00018234027083963156, "eval/reward_rate": 0.0009765625, "replay/size": 764217.0, "replay/inserts": 31952.0, "replay/samples": 31952.0, "replay/insert_wait_avg": 1.4969212565949755e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.901794025763071e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4716.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3488141837213078e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.003655910492, "timer/env.step_count": 7988.0, "timer/env.step_total": 37.43787956237793, "timer/env.step_frac": 0.03743774269334162, "timer/env.step_avg": 0.004686765092936646, "timer/env.step_min": 0.0035409927368164062, "timer/env.step_max": 0.029848814010620117, "timer/replay._sample_count": 31952.0, "timer/replay._sample_total": 16.136444807052612, "timer/replay._sample_frac": 0.01613638581387041, "timer/replay._sample_avg": 0.0005050214323689475, "timer/replay._sample_min": 0.000392913818359375, "timer/replay._sample_max": 0.03242325782775879, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9167.0, "timer/agent.policy_total": 84.26686573028564, "timer/agent.policy_frac": 0.08426655765929338, "timer/agent.policy_avg": 0.009192414719132284, "timer/agent.policy_min": 0.007708549499511719, "timer/agent.policy_max": 0.040776729583740234, "timer/dataset_train_count": 1997.0, "timer/dataset_train_total": 0.21831059455871582, "timer/dataset_train_frac": 0.00021830979643764053, "timer/dataset_train_avg": 0.00010931927619364838, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.005369901657104492, "timer/agent.train_count": 1997.0, "timer/agent.train_total": 864.9380645751953, "timer/agent.train_frac": 0.8649349024506106, "timer/agent.train_avg": 0.4331187103531273, "timer/agent.train_min": 0.42330265045166016, "timer/agent.train_max": 0.5156457424163818, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47936344146728516, "timer/agent.report_frac": 0.00047936168896385703, "timer/agent.report_avg": 0.23968172073364258, "timer/agent.report_min": 0.23367905616760254, "timer/agent.report_max": 0.24568438529968262, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.963180541992188e-05, "timer/dataset_eval_frac": 7.963151429423327e-08, "timer/dataset_eval_avg": 7.963180541992188e-05, "timer/dataset_eval_min": 7.963180541992188e-05, "timer/dataset_eval_max": 7.963180541992188e-05, "fps": 31.95123675292397}
{"step": 764792, "time": 24207.2831056118, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 764988, "time": 24213.676443338394, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 765236, "time": 24221.09438228607, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 765388, "time": 24225.94930124283, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 765476, "time": 24228.42744231224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 765828, "time": 24239.182870149612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766072, "time": 24246.61157989502, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 766392, "time": 24256.600489616394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766400, "time": 24257.07045340538, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 766544, "time": 24261.488353013992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766624, "time": 24263.93444776535, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 766640, "time": 24264.425561904907, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 766772, "time": 24268.365701436996, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 766872, "time": 24271.383602380753, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 767152, "time": 24280.15965819359, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 767368, "time": 24286.53236556053, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 767520, "time": 24291.398439884186, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 767548, "time": 24292.360740184784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767560, "time": 24292.411053419113, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 767812, "time": 24300.222866535187, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 767824, "time": 24300.70335483551, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 768080, "time": 24308.54220890999, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 768180, "time": 24311.5019159317, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 768564, "time": 24323.201167583466, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 768704, "time": 24327.573276519775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 768716, "time": 24328.0482981205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 768800, "time": 24330.52940273285, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 769028, "time": 24337.489470481873, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 769236, "time": 24343.853434324265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769572, "time": 24354.149353265762, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 769720, "time": 24358.577231407166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769808, "time": 24361.502408981323, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 769860, "time": 24362.99321770668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769956, "time": 24365.979232549667, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 770060, "time": 24370.100462913513, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 770060, "time": 24371.244642019272, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 770060, "time": 24371.441789388657, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 770060, "time": 24371.826387166977, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 770060, "time": 24372.357409000397, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 770060, "time": 24372.582551002502, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 770060, "time": 24373.270297288895, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 770060, "time": 24373.544152021408, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770184, "time": 24377.01488661766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 770228, "time": 24378.502945184708, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 770308, "time": 24381.0608355999, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 770964, "time": 24401.40503168106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771012, "time": 24402.89072394371, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 771284, "time": 24411.283613443375, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 771340, "time": 24413.237107038498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771384, "time": 24414.26889705658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771388, "time": 24414.72284245491, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 771488, "time": 24417.67126226425, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 771568, "time": 24420.143142700195, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 771692, "time": 24424.13104701042, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 771816, "time": 24427.615419387817, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 772216, "time": 24439.896374225616, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 772236, "time": 24440.84437441826, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 772540, "time": 24450.16889834404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 772588, "time": 24451.704820394516, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 772692, "time": 24454.697664260864, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 772848, "time": 24459.603611946106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773008, "time": 24464.468952655792, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 773104, "time": 24467.41815328598, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 773268, "time": 24472.354221105576, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 773476, "time": 24478.711494207382, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 773548, "time": 24481.187066316605, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 773616, "time": 24483.17302417755, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 773696, "time": 24485.635733127594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773760, "time": 24487.61724615097, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 773852, "time": 24490.527160406113, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 773968, "time": 24493.987905740738, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 774048, "time": 24496.45696592331, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 774164, "time": 24499.90789461136, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 774264, "time": 24502.856575727463, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 774456, "time": 24508.901252508163, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 774488, "time": 24509.88953256607, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 774580, "time": 24512.896770715714, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 774948, "time": 24524.104640483856, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 774972, "time": 24525.05671787262, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 775196, "time": 24531.91609096527, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 775332, "time": 24535.870872735977, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 775420, "time": 24538.77767944336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 775568, "time": 24543.279074907303, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 775672, "time": 24546.259623765945, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 776028, "time": 24557.485609292984, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 776128, "time": 24560.464687108994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 776244, "time": 24563.884371995926, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 776488, "time": 24571.261139392853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 776892, "time": 24583.96806693077, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 777184, "time": 24592.831721305847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777284, "time": 24595.839354991913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777332, "time": 24597.31280708313, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 777400, "time": 24599.290103912354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777408, "time": 24599.75508093834, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 777712, "time": 24609.11756491661, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 777804, "time": 24612.051256895065, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 777816, "time": 24612.09896016121, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 778072, "time": 24619.99680352211, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 778148, "time": 24622.444209098816, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 778292, "time": 24626.878798246384, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 778332, "time": 24628.32217168808, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 778564, "time": 24635.4985806942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778772, "time": 24641.8611433506, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 778780, "time": 24642.326701641083, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 778984, "time": 24648.269023656845, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 779172, "time": 24654.199917793274, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 779304, "time": 24658.1309838295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 779428, "time": 24662.13399863243, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 779456, "time": 24663.100981473923, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 779720, "time": 24670.956580877304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 779988, "time": 24679.275895357132, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 780004, "time": 24679.764251947403, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 780060, "time": 24683.083803892136, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 780060, "time": 24683.089012622833, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 780060, "time": 24683.809581041336, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 780060, "time": 24684.33234643936, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 780060, "time": 24684.771983385086, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 780060, "time": 24684.830229997635, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 780060, "time": 24685.169511318207, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 780060, "time": 24686.60093808174, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 780092, "time": 24687.58154940605, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 780612, "time": 24703.29843568802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780708, "time": 24706.229455709457, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 780936, "time": 24713.107919216156, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 781160, "time": 24719.99153280258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 781164, "time": 24720.443209648132, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 781184, "time": 24720.95186638832, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 781408, "time": 24727.90326166153, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 781592, "time": 24733.345222473145, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 781736, "time": 24737.768628120422, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 781864, "time": 24741.73023033142, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 782000, "time": 24746.1120762825, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 782320, "time": 24755.962424755096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782740, "time": 24768.940250635147, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 782836, "time": 24771.896373987198, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 782892, "time": 24773.84187936783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 783064, "time": 24778.82785797119, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 783156, "time": 24781.806243658066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 783280, "time": 24785.704899311066, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 783584, "time": 24795.050431489944, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 783932, "time": 24805.82141661644, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 784220, "time": 24814.672540664673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784404, "time": 24820.12103009224, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 784436, "time": 24821.118362426758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784556, "time": 24825.022046804428, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 784608, "time": 24826.533794641495, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 784760, "time": 24830.980154514313, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 784868, "time": 24834.395516633987, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 785008, "time": 24838.82304406166, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 785168, "time": 24843.81508255005, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 785180, "time": 24844.296585559845, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 785300, "time": 24847.75067138672, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 785468, "time": 24853.118460416794, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 785492, "time": 24853.645292520523, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 785536, "time": 24855.115919351578, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 785548, "time": 24855.613321065903, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 785976, "time": 24868.43845820427, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 786004, "time": 24869.411100387573, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 786008, "time": 24869.432485818863, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 786016, "time": 24869.900099277496, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 786340, "time": 24879.822355508804, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 786420, "time": 24882.26763868332, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 786812, "time": 24894.643712997437, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 786884, "time": 24896.662181138992, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 787048, "time": 24901.707503080368, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 787496, "time": 24915.529081583023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 787576, "time": 24918.002068042755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 787588, "time": 24918.484641075134, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 787600, "time": 24918.966874837875, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 787828, "time": 24925.850744009018, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 787860, "time": 24926.83220767975, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 787888, "time": 24927.805974006653, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 788324, "time": 24941.16260576248, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 788328, "time": 24941.18386220932, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 788344, "time": 24941.68303489685, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 788428, "time": 24944.60776782036, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 788692, "time": 24952.525272130966, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 788780, "time": 24955.482478380203, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 788868, "time": 24957.997022867203, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 789016, "time": 24962.49621629715, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 789028, "time": 24962.97786784172, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 789132, "time": 24966.411859750748, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 789608, "time": 24980.659111738205, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 789800, "time": 24986.52076935768, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 790024, "time": 24993.4272005558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 790060, "time": 24997.014572620392, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 790060, "time": 24997.087426185608, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 790060, "time": 24997.25041794777, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 790060, "time": 24997.388184547424, "eval_episode/length": 183.0, "eval_episode/score": 0.4281249940395355, "eval_episode/reward_rate": 0.005434782608695652}
{"step": 790060, "time": 24998.564106941223, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 790060, "time": 24998.59817624092, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 790060, "time": 24999.206846237183, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 790060, "time": 25000.09326171875, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 790172, "time": 25003.503741502762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 790220, "time": 25004.985389471054, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 790348, "time": 25008.911742448807, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 790388, "time": 25009.92123556137, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 790400, "time": 25010.401158571243, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 790536, "time": 25014.349087953568, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 790588, "time": 25016.26004052162, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 790740, "time": 25020.69017148018, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 790972, "time": 25028.226966381073, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 791008, "time": 25029.233730316162, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 791240, "time": 25036.084386348724, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 791676, "time": 25049.801435709, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 791692, "time": 25050.29780960083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 792020, "time": 25060.25928235054, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 792128, "time": 25063.69459795952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 792148, "time": 25064.208421230316, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 792164, "time": 25064.70959877968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 792260, "time": 25067.662968873978, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 792500, "time": 25075.05970978737, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 792572, "time": 25077.47368478775, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 792888, "time": 25086.878049373627, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 793284, "time": 25099.10262274742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 793304, "time": 25099.614438533783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 793356, "time": 25101.52314567566, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 793456, "time": 25104.47408747673, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 793544, "time": 25106.95302271843, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 793784, "time": 25114.409588575363, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 793908, "time": 25118.347497940063, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 794012, "time": 25121.73447561264, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 794084, "time": 25123.726684093475, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 794320, "time": 25131.040108442307, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 794336, "time": 25131.53536081314, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 794700, "time": 25142.930579185486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794748, "time": 25144.40610909462, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 794772, "time": 25144.92922759056, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 794848, "time": 25147.372997283936, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 795108, "time": 25155.370884895325, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 795240, "time": 25159.31102871895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 795332, "time": 25162.240518331528, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 795648, "time": 25172.12597155571, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 795904, "time": 25182.00320792198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 795944, "time": 25183.00390815735, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 796020, "time": 25185.449291229248, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 796396, "time": 25197.19403195381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 796496, "time": 25200.184215545654, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 796648, "time": 25204.66651892662, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 796649, "time": 25205.66040277481, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3532452392578125, "train/action_min": 0.0, "train/action_std": 1.403401836156845, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007106637022225186, "train/actor_opt_grad_steps": 48695.0, "train/actor_opt_loss": -8.314370316267013, "train/adv_mag": 0.8194832527637481, "train/adv_max": 0.23644757866859437, "train/adv_mean": 0.00042243802827215406, "train/adv_min": -0.7693312168121338, "train/adv_std": 0.020093722005840392, "train/cont_avg": 0.995634765625, "train/cont_loss_mean": 0.013923306226497517, "train/cont_loss_std": 0.21232547208433972, "train/cont_neg_acc": 0.39890053366596373, "train/cont_neg_loss": 2.554210052325919, "train/cont_pos_acc": 0.9999214413762093, "train/cont_pos_loss": 0.002797762149129994, "train/cont_pred": 0.9955870780348778, "train/cont_rate": 0.995634765625, "train/dyn_loss_mean": 1.0000070005655288, "train/dyn_loss_std": 0.00021766322170151397, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1021919553913176, "train/extr_critic_critic_opt_grad_steps": 48695.0, "train/extr_critic_critic_opt_loss": 8156.507119140625, "train/extr_critic_mag": 1.19423095703125, "train/extr_critic_max": 1.19423095703125, "train/extr_critic_mean": 1.1452718263864516, "train/extr_critic_min": 0.9560348653793335, "train/extr_critic_std": 0.015908380602486432, "train/extr_return_normed_mag": 0.8335560536384583, "train/extr_return_normed_max": 0.22466587960720064, "train/extr_return_normed_mean": 0.02925008206628263, "train/extr_return_normed_min": -0.7808522939682007, "train/extr_return_normed_std": 0.026311709210276604, "train/extr_return_rate": 0.9995319387316703, "train/extr_return_raw_mag": 1.3411099952459336, "train/extr_return_raw_max": 1.3411099952459336, "train/extr_return_raw_mean": 1.1456942498683929, "train/extr_return_raw_min": 0.33559182167053225, "train/extr_return_raw_std": 0.026311709280125797, "train/extr_reward_mag": 0.24887641489505768, "train/extr_reward_max": 0.24887641489505768, "train/extr_reward_mean": 0.0015167244194890372, "train/extr_reward_min": 2.0623207092285156e-07, "train/extr_reward_std": 0.0062205981300212446, "train/image_loss_mean": 0.09379119273275137, "train/image_loss_std": 0.10228967463597655, "train/model_loss_mean": 0.7149614995718002, "train/model_loss_std": 0.3533775220066309, "train/model_opt_grad_norm": 19.719027886390688, "train/model_opt_grad_steps": 48653.045, "train/model_opt_loss": 3897.819219970703, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5450.0, "train/policy_entropy_mag": 1.2052946186065674, "train/policy_entropy_max": 1.2052946186065674, "train/policy_entropy_mean": 0.09772217862308025, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12107928406447171, "train/policy_logprob_mag": 6.5510802698135375, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09814519200474024, "train/policy_logprob_min": -6.5510802698135375, "train/policy_logprob_std": 0.6369733870029449, "train/policy_randomness_mag": 0.6193989410996437, "train/policy_randomness_max": 0.6193989410996437, "train/policy_randomness_mean": 0.05021926749497652, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.062222446929663416, "train/post_ent_mag": 57.27227367401123, "train/post_ent_max": 57.27227367401123, "train/post_ent_mean": 52.105413093566895, "train/post_ent_min": 48.793374919891356, "train/post_ent_std": 1.7323516136407853, "train/prior_ent_mag": 58.85591474533081, "train/prior_ent_max": 58.85591474533081, "train/prior_ent_mean": 52.39235416412353, "train/prior_ent_min": 47.32505481719971, "train/prior_ent_std": 2.09179668366909, "train/rep_loss_mean": 1.0000070005655288, "train/rep_loss_std": 0.00021766322170151397, "train/reward_avg": 0.0008989410371941631, "train/reward_loss_mean": 0.007242773318430409, "train/reward_loss_std": 0.1408656698820414, "train/reward_max_data": 0.517734373100102, "train/reward_max_pred": 0.1481867265701294, "train/reward_neg_acc": 0.9998728474974632, "train/reward_neg_loss": 0.0012706215238722507, "train/reward_pos_acc": 0.16317567702483488, "train/reward_pos_loss": 4.243763133078008, "train/reward_pred": 0.0007379178976407274, "train/reward_rate": 0.00142578125, "train_stats/mean_log_entropy": 0.06974054218031639, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.008077016100287437, "report/cont_loss_std": 0.13877727091312408, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.7211544513702393, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0027676669415086508, "report/cont_pred": 0.9969867467880249, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09167295694351196, "report/image_loss_std": 0.10502517968416214, "report/model_loss_mean": 0.7015116214752197, "report/model_loss_std": 0.17688198387622833, "report/post_ent_mag": 56.71391677856445, "report/post_ent_max": 56.71391677856445, "report/post_ent_mean": 51.5313606262207, "report/post_ent_min": 48.469970703125, "report/post_ent_std": 1.7793042659759521, "report/prior_ent_mag": 58.84601974487305, "report/prior_ent_max": 58.84601974487305, "report/prior_ent_mean": 52.301822662353516, "report/prior_ent_min": 47.76591491699219, "report/prior_ent_std": 1.9761971235275269, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0017616290133446455, "report/reward_loss_std": 0.013587710447609425, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.10303294658660889, "report/reward_neg_acc": 0.9990234375, "report/reward_neg_loss": 0.0017616290133446455, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0007553240284323692, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.06325863301753998, "eval/cont_loss_std": 0.8776493072509766, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.565629005432129, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0019123587990179658, "eval/cont_pred": 0.9982442855834961, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13258983194828033, "eval/image_loss_std": 0.13497181236743927, "eval/model_loss_mean": 0.7966347932815552, "eval/model_loss_std": 0.8854263424873352, "eval/post_ent_mag": 56.691741943359375, "eval/post_ent_max": 56.691741943359375, "eval/post_ent_mean": 50.87791442871094, "eval/post_ent_min": 47.68454360961914, "eval/post_ent_std": 1.8713809251785278, "eval/prior_ent_mag": 58.84430694580078, "eval/prior_ent_max": 58.84430694580078, "eval/prior_ent_mean": 51.573272705078125, "eval/prior_ent_min": 46.54186248779297, "eval/prior_ent_std": 2.223724842071533, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0007863000500947237, "eval/reward_loss_std": 0.013698305934667587, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.15370142459869385, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.0007863000500947237, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00031813245732337236, "eval/reward_rate": 0.0, "replay/size": 796137.0, "replay/inserts": 31920.0, "replay/samples": 31920.0, "replay/insert_wait_avg": 1.4857017904295958e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.759268543176483e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.25730037689209e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0433650016785, "timer/env.step_count": 7980.0, "timer/env.step_total": 37.48434114456177, "timer/env.step_frac": 0.03748271570653224, "timer/env.step_avg": 0.004697285857714507, "timer/env.step_min": 0.003549814224243164, "timer/env.step_max": 0.03065180778503418, "timer/replay._sample_count": 31920.0, "timer/replay._sample_total": 16.13418960571289, "timer/replay._sample_frac": 0.016133489976892963, "timer/replay._sample_avg": 0.0005054570678481482, "timer/replay._sample_min": 0.0004076957702636719, "timer/replay._sample_max": 0.028441429138183594, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 8980.0, "timer/agent.policy_total": 82.41474223136902, "timer/agent.policy_frac": 0.08241116847090996, "timer/agent.policy_avg": 0.009177588221756015, "timer/agent.policy_min": 0.008081436157226562, "timer/agent.policy_max": 0.04326939582824707, "timer/dataset_train_count": 1995.0, "timer/dataset_train_total": 0.21123933792114258, "timer/dataset_train_frac": 0.00021123017792412234, "timer/dataset_train_avg": 0.00010588437991034715, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0009698867797851562, "timer/agent.train_count": 1995.0, "timer/agent.train_total": 867.987720489502, "timer/agent.train_frac": 0.8679500818327465, "timer/agent.train_avg": 0.4350815641551388, "timer/agent.train_min": 0.4237487316131592, "timer/agent.train_max": 2.4648733139038086, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48302507400512695, "timer/agent.report_frac": 0.00048300412853028254, "timer/agent.report_avg": 0.24151253700256348, "timer/agent.report_min": 0.23499608039855957, "timer/agent.report_max": 0.24802899360656738, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.0754663028087727e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 31.91797458830774}
{"step": 796824, "time": 25210.695140123367, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 796988, "time": 25216.065589427948, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 797016, "time": 25216.6084690094, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 797060, "time": 25218.07140135765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797100, "time": 25219.534745693207, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 797176, "time": 25221.54721069336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797560, "time": 25233.47868704796, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 797640, "time": 25235.946590185165, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 797952, "time": 25245.74736380577, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 798144, "time": 25251.628440380096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 798200, "time": 25253.135267734528, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 798208, "time": 25253.599507808685, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 798264, "time": 25255.09258389473, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 798640, "time": 25266.87483906746, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 798660, "time": 25267.38515639305, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 798664, "time": 25267.406249284744, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 798696, "time": 25268.410545110703, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 798920, "time": 25275.293532848358, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 799204, "time": 25284.247163295746, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 799308, "time": 25287.655287742615, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 799440, "time": 25291.65561413765, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 799536, "time": 25294.607305288315, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 799820, "time": 25303.4284324646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 800008, "time": 25308.867217063904, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 800016, "time": 25309.3365650177, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 800028, "time": 25309.816169977188, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 800060, "time": 25311.478036880493, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 800060, "time": 25312.163472414017, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 800060, "time": 25312.308698177338, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 800060, "time": 25314.909264326096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800060, "time": 25315.903279304504, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800060, "time": 25316.548638105392, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800060, "time": 25316.691791296005, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800060, "time": 25317.84342813492, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 800316, "time": 25325.81324481964, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 800416, "time": 25328.75324320793, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 800556, "time": 25333.138540267944, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 800700, "time": 25337.543476104736, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 800720, "time": 25338.053897619247, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 800784, "time": 25340.043467760086, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 800980, "time": 25345.92523932457, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 801164, "time": 25351.844726085663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801288, "time": 25355.32133412361, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 801304, "time": 25355.81624341011, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 801412, "time": 25359.245342493057, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 801788, "time": 25370.949118614197, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 801832, "time": 25371.978296279907, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 801992, "time": 25376.870818138123, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 802008, "time": 25377.371905088425, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 802252, "time": 25385.33283662796, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 802320, "time": 25387.325769901276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802360, "time": 25388.360316991806, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 802420, "time": 25390.29779601097, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 802664, "time": 25397.64812707901, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 802716, "time": 25399.572504520416, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 802756, "time": 25400.58881020546, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 802784, "time": 25401.555824518204, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 802944, "time": 25406.446838378906, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 802952, "time": 25406.482001066208, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 803472, "time": 25422.964884996414, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 803548, "time": 25425.380838871002, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 804100, "time": 25442.15951037407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804108, "time": 25442.64195227623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804328, "time": 25449.065004110336, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 804556, "time": 25456.354522705078, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 804584, "time": 25456.89154624939, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 804704, "time": 25460.791167497635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804880, "time": 25466.15300989151, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 805256, "time": 25477.379124403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 805616, "time": 25488.601479053497, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 805740, "time": 25492.50863957405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 805860, "time": 25495.955748081207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 806000, "time": 25500.34283399582, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 806036, "time": 25501.449326753616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 806064, "time": 25502.418318271637, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 806112, "time": 25503.88537621498, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 806340, "time": 25510.75386953354, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 806480, "time": 25515.162257432938, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 806536, "time": 25516.696140527725, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 806704, "time": 25522.065094947815, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 806828, "time": 25525.992129087448, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 806900, "time": 25527.984591007233, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 807156, "time": 25535.886015176773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 807352, "time": 25541.991386651993, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 807392, "time": 25543.426191806793, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 807476, "time": 25545.904102802277, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 807612, "time": 25550.281422376633, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 807724, "time": 25553.711911678314, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 807864, "time": 25557.677984952927, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 807916, "time": 25559.593008995056, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 808072, "time": 25564.144485473633, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 808116, "time": 25565.612173318863, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 808128, "time": 25566.097359657288, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 808172, "time": 25567.549928188324, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 808232, "time": 25569.058441400528, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 808416, "time": 25574.861838817596, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 808692, "time": 25583.167915821075, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 808700, "time": 25583.63281106949, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 809004, "time": 25592.96089529991, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 809276, "time": 25601.304844617844, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 809284, "time": 25601.34107732773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809388, "time": 25604.737640857697, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 809452, "time": 25606.688153505325, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 809748, "time": 25615.512917518616, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 809848, "time": 25618.44172859192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809924, "time": 25620.884944200516, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 810000, "time": 25623.40636897087, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 810036, "time": 25624.41973042488, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 810060, "time": 25626.662081956863, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 810060, "time": 25626.795678138733, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 810060, "time": 25627.289975643158, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 810060, "time": 25627.972203731537, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 810060, "time": 25628.004578113556, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 810060, "time": 25629.1256775856, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 810060, "time": 25629.345452070236, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810060, "time": 25629.48810005188, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 810084, "time": 25630.0130610466, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 810228, "time": 25634.41019010544, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 810320, "time": 25637.32334256172, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 810452, "time": 25641.313586950302, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 810476, "time": 25642.261378526688, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 810792, "time": 25651.668340444565, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 810792, "time": 25651.67363524437, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 811000, "time": 25658.042045116425, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 811112, "time": 25661.459022521973, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 811148, "time": 25662.894805431366, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 811240, "time": 25665.370642900467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 811556, "time": 25675.310026407242, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 811876, "time": 25685.130511045456, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 811948, "time": 25687.57240176201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812268, "time": 25697.404532670975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812304, "time": 25698.40957403183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812340, "time": 25699.410394906998, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 812544, "time": 25705.78756070137, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 812628, "time": 25708.253390073776, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 812788, "time": 25713.186957359314, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 812936, "time": 25717.65500497818, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 813092, "time": 25722.56448864937, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 813440, "time": 25733.295239686966, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 813456, "time": 25733.7888944149, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 813496, "time": 25734.79745197296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813748, "time": 25742.65544438362, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 813784, "time": 25743.648012399673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 814040, "time": 25751.503682136536, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 814176, "time": 25755.880666732788, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 814196, "time": 25756.401433229446, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 814652, "time": 25770.58362340927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 814940, "time": 25779.538146734238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 814976, "time": 25780.539456367493, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 814980, "time": 25780.561663150787, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 815332, "time": 25791.353005170822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 815332, "time": 25791.360115289688, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 815372, "time": 25792.96777033806, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 815392, "time": 25793.47693681717, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 815620, "time": 25800.36160182953, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 815752, "time": 25804.387500286102, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 815828, "time": 25806.828486680984, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 816120, "time": 25815.680315971375, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 816172, "time": 25817.594966173172, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 816368, "time": 25823.48689889908, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 816472, "time": 25826.465013742447, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 816776, "time": 25835.84989476204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 816984, "time": 25842.232422828674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817036, "time": 25844.141882181168, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 817256, "time": 25850.567002534866, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 817524, "time": 25858.903936624527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817560, "time": 25859.92989754677, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 817620, "time": 25861.965363502502, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 817908, "time": 25870.783203125, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 818140, "time": 25878.142897605896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 818256, "time": 25881.61543917656, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 818628, "time": 25892.951032161713, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 818712, "time": 25895.43340086937, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 818716, "time": 25895.88854932785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 818772, "time": 25897.390400648117, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 819052, "time": 25906.22992658615, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 819180, "time": 25910.17567038536, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 819296, "time": 25913.64614367485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819460, "time": 25918.6838889122, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 819504, "time": 25920.26810312271, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 820016, "time": 25936.10789871216, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 820052, "time": 25937.102957963943, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 820060, "time": 25938.786390304565, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 820060, "time": 25938.86196899414, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 820060, "time": 25939.967225551605, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 820060, "time": 25940.876740455627, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 820060, "time": 25941.681067228317, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820060, "time": 25941.687492370605, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820060, "time": 25942.94655442238, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820060, "time": 25943.492168188095, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 820208, "time": 25947.93604707718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820452, "time": 25955.38378381729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820520, "time": 25957.359280586243, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 820620, "time": 25960.744962215424, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 820696, "time": 25962.748916387558, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 820896, "time": 25969.10304093361, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 820908, "time": 25969.600626945496, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 820972, "time": 25971.561366081238, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 821356, "time": 25983.398540258408, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 821776, "time": 25996.107584953308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822064, "time": 26004.942651748657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822128, "time": 26006.90029501915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822512, "time": 26018.814159154892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822524, "time": 26019.29560637474, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 822624, "time": 26022.255932807922, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 823284, "time": 26042.471311092377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823556, "time": 26050.92355298996, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 823668, "time": 26054.453510284424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823680, "time": 26054.93702197075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823780, "time": 26057.895723342896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824056, "time": 26066.23518514633, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 824128, "time": 26068.690096855164, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 824168, "time": 26069.70578980446, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 824312, "time": 26074.179260730743, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 824532, "time": 26081.054437160492, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 825012, "time": 26095.74408888817, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 825028, "time": 26096.239582777023, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 825072, "time": 26097.720014095306, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 825212, "time": 26102.17760848999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825380, "time": 26107.117192029953, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 825536, "time": 26111.994830846786, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 825660, "time": 26115.895013570786, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 825728, "time": 26117.87594795227, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 825804, "time": 26120.305688619614, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 826112, "time": 26129.602163791656, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 826184, "time": 26131.666352272034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 826240, "time": 26133.61422610283, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 826364, "time": 26137.528515338898, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 826440, "time": 26139.532366752625, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 826660, "time": 26146.36624622345, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 826728, "time": 26148.359706163406, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 826884, "time": 26153.242201566696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 826968, "time": 26155.710862874985, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 827292, "time": 26166.03955078125, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 827396, "time": 26169.0308508873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827548, "time": 26173.941964626312, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 827664, "time": 26177.587151765823, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 827792, "time": 26181.52320241928, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 827984, "time": 26187.43646812439, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 828020, "time": 26188.4265024662, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 828040, "time": 26188.936453819275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 828264, "time": 26195.921448946, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 828420, "time": 26200.813824653625, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 828532, "time": 26204.266073942184, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 828553, "time": 26205.754996061325, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3173650233589824, "train/action_min": 0.0, "train/action_std": 1.395691785381068, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009819483386245017, "train/actor_opt_grad_steps": 50690.0, "train/actor_opt_loss": -7.838659852293867, "train/adv_mag": 0.9124354207935046, "train/adv_max": 0.30187393732406387, "train/adv_mean": 0.0016062711165135048, "train/adv_min": -0.8632649470813311, "train/adv_std": 0.027992437179457753, "train/cont_avg": 0.9954312578517588, "train/cont_loss_mean": 0.015374974814482295, "train/cont_loss_std": 0.22212366775221112, "train/cont_neg_acc": 0.32191358566886247, "train/cont_neg_loss": 2.705808720391507, "train/cont_pos_acc": 0.9998718479170872, "train/cont_pos_loss": 0.0029358105147819047, "train/cont_pred": 0.9957176360053632, "train/cont_rate": 0.9954312578517588, "train/dyn_loss_mean": 1.0000008907749425, "train/dyn_loss_std": 2.6257186993516645e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16298834612621135, "train/extr_critic_critic_opt_grad_steps": 50690.0, "train/extr_critic_critic_opt_loss": 4741.102395522535, "train/extr_critic_mag": 1.2355345733201684, "train/extr_critic_max": 1.2355345733201684, "train/extr_critic_mean": 1.1820114994767923, "train/extr_critic_min": 0.9549917461884082, "train/extr_critic_std": 0.016560814797354103, "train/extr_return_normed_mag": 0.9203552942180154, "train/extr_return_normed_max": 0.2855119765104361, "train/extr_return_normed_mean": 0.0337698192256105, "train/extr_return_normed_min": -0.8734364419726272, "train/extr_return_normed_std": 0.03364229228010579, "train/extr_return_rate": 0.9993303519996566, "train/extr_return_raw_mag": 1.4353598961279022, "train/extr_return_raw_max": 1.4353598961279022, "train/extr_return_raw_mean": 1.1836178033196147, "train/extr_return_raw_min": 0.27641147764483887, "train/extr_return_raw_std": 0.03364229219586556, "train/extr_reward_mag": 0.3062021864119487, "train/extr_reward_max": 0.3062021864119487, "train/extr_reward_mean": 0.0019226809890458745, "train/extr_reward_min": 2.7256395349550484e-07, "train/extr_reward_std": 0.00874152592378645, "train/image_loss_mean": 0.09466429998227699, "train/image_loss_std": 0.10417374830000364, "train/model_loss_mean": 0.7187869243286363, "train/model_loss_std": 0.3801159757240933, "train/model_opt_grad_norm": 19.05873703597179, "train/model_opt_grad_steps": 50646.09547738694, "train/model_opt_loss": 3612.059470938678, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5025.125628140703, "train/policy_entropy_mag": 1.2254757425892893, "train/policy_entropy_max": 1.2254757425892893, "train/policy_entropy_mean": 0.09830608080379927, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1227743442933164, "train/policy_logprob_mag": 6.551080258048359, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09766719479057658, "train/policy_logprob_min": -6.551080258048359, "train/policy_logprob_std": 0.6321449531382651, "train/policy_randomness_mag": 0.6297699910911483, "train/policy_randomness_max": 0.6297699910911483, "train/policy_randomness_mean": 0.05051933358137931, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0630935357331331, "train/post_ent_mag": 57.833514496309675, "train/post_ent_max": 57.833514496309675, "train/post_ent_mean": 51.75046238348113, "train/post_ent_min": 47.88934698056935, "train/post_ent_std": 2.0386554673688497, "train/prior_ent_mag": 58.608560782581115, "train/prior_ent_max": 58.608560782581115, "train/prior_ent_mean": 51.64533314153777, "train/prior_ent_min": 46.68191302122183, "train/prior_ent_std": 2.217725521356017, "train/rep_loss_mean": 1.0000008907749425, "train/rep_loss_std": 2.6257186993516645e-05, "train/reward_avg": 0.0011996168560750933, "train/reward_loss_mean": 0.008747094480470572, "train/reward_loss_std": 0.15930573936334189, "train/reward_max_data": 0.6111494982661914, "train/reward_max_pred": 0.17225595514977995, "train/reward_neg_acc": 0.9998426464334804, "train/reward_neg_loss": 0.0014255037513706628, "train/reward_pos_acc": 0.17312717910219982, "train/reward_pos_loss": 4.053054496645927, "train/reward_pred": 0.0008623616117048054, "train/reward_rate": 0.0018059045226130653, "train_stats/mean_log_entropy": 0.0700912087986415, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.02022470161318779, "report/cont_loss_std": 0.26796916127204895, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 2.938964605331421, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003021912882104516, "report/cont_pred": 0.9957401156425476, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10085073113441467, "report/image_loss_std": 0.10511887818574905, "report/model_loss_mean": 0.7311142683029175, "report/model_loss_std": 0.4381261169910431, "report/post_ent_mag": 60.76326370239258, "report/post_ent_max": 60.76326370239258, "report/post_ent_mean": 53.350006103515625, "report/post_ent_min": 47.658714294433594, "report/post_ent_std": 2.6328063011169434, "report/prior_ent_mag": 58.91322326660156, "report/prior_ent_max": 58.91322326660156, "report/prior_ent_mean": 52.15541076660156, "report/prior_ent_min": 47.031105041503906, "report/prior_ent_std": 2.3112268447875977, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0012481689918786287, "report/reward_loss_mean": 0.010038753971457481, "report/reward_loss_std": 0.19509980082511902, "report/reward_max_data": 0.6499999761581421, "report/reward_max_pred": 0.03103172779083252, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0014266821090131998, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.4108076095581055, "report/reward_pred": 0.0007117687491700053, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.031940262764692307, "eval/cont_loss_std": 0.5782329440116882, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.163888931274414, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002169602084904909, "eval/cont_pred": 0.9978633522987366, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1213206872344017, "eval/image_loss_std": 0.12379100918769836, "eval/model_loss_mean": 0.7606062889099121, "eval/model_loss_std": 0.6978126764297485, "eval/post_ent_mag": 60.91835021972656, "eval/post_ent_max": 60.91835021972656, "eval/post_ent_mean": 52.34130096435547, "eval/post_ent_min": 47.40967559814453, "eval/post_ent_std": 2.7458810806274414, "eval/prior_ent_mag": 59.016693115234375, "eval/prior_ent_max": 59.016693115234375, "eval/prior_ent_mean": 51.35767364501953, "eval/prior_ent_min": 46.1870231628418, "eval/prior_ent_std": 2.42170786857605, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005218505975790322, "eval/reward_loss_mean": 0.0073452964425086975, "eval/reward_loss_std": 0.21562646329402924, "eval/reward_max_data": 0.534375011920929, "eval/reward_max_pred": 0.03962814807891846, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0006051960517652333, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.902467727661133, "eval/reward_pred": 0.0002657044678926468, "eval/reward_rate": 0.0009765625, "replay/size": 828041.0, "replay/inserts": 31904.0, "replay/samples": 31904.0, "replay/insert_wait_avg": 1.480670247895787e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.87325345405724e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4764.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2957879618173082e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0754330158234, "timer/env.step_count": 7976.0, "timer/env.step_total": 37.407021284103394, "timer/env.step_frac": 0.0374041997725101, "timer/env.step_avg": 0.00468994750302199, "timer/env.step_min": 0.003406047821044922, "timer/env.step_max": 0.0312955379486084, "timer/replay._sample_count": 31904.0, "timer/replay._sample_total": 16.066345691680908, "timer/replay._sample_frac": 0.016065133850184984, "timer/replay._sample_avg": 0.0005035840550301188, "timer/replay._sample_min": 0.0003676414489746094, "timer/replay._sample_max": 0.011573076248168945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9167.0, "timer/agent.policy_total": 84.30892252922058, "timer/agent.policy_frac": 0.08430256333262676, "timer/agent.policy_avg": 0.009197002566730728, "timer/agent.policy_min": 0.006478548049926758, "timer/agent.policy_max": 0.04260540008544922, "timer/dataset_train_count": 1994.0, "timer/dataset_train_total": 0.2244570255279541, "timer/dataset_train_frac": 0.00022444009533469133, "timer/dataset_train_avg": 0.00011256621139817157, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.010411262512207031, "timer/agent.train_count": 1994.0, "timer/agent.train_total": 865.2148253917694, "timer/agent.train_frac": 0.865149564550977, "timer/agent.train_avg": 0.4339091401162334, "timer/agent.train_min": 0.4255387783050537, "timer/agent.train_max": 0.5321369171142578, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48172950744628906, "timer/agent.report_frac": 0.0004816931718776328, "timer/agent.report_avg": 0.24086475372314453, "timer/agent.report_min": 0.23386693000793457, "timer/agent.report_max": 0.2478625774383545, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9084872690728724e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 31.90098239644366}
{"step": 828676, "time": 26209.346425056458, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 828716, "time": 26210.79005098343, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 828828, "time": 26214.24315571785, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 828884, "time": 26215.754846572876, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 829108, "time": 26222.726802110672, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 829360, "time": 26230.610298395157, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 829476, "time": 26234.08864235878, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 829872, "time": 26246.416635751724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829956, "time": 26248.886360406876, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 829984, "time": 26249.865568876266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 830040, "time": 26251.474801778793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 830060, "time": 26253.932330608368, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 830060, "time": 26254.212028980255, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 830060, "time": 26255.258333921432, "eval_episode/length": 184.0, "eval_episode/score": 0.42500001192092896, "eval_episode/reward_rate": 0.005405405405405406}
{"step": 830060, "time": 26255.752597093582, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 830060, "time": 26256.690783262253, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830060, "time": 26256.844434976578, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 830060, "time": 26257.591064214706, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 830060, "time": 26258.49547767639, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830212, "time": 26262.94039940834, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 830320, "time": 26266.338735103607, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 830764, "time": 26280.043010234833, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 831112, "time": 26290.462273836136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831180, "time": 26292.898777484894, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 831196, "time": 26293.39798092842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831368, "time": 26298.364567518234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831440, "time": 26300.79187631607, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 831592, "time": 26305.226278543472, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 831628, "time": 26306.675993442535, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 832044, "time": 26319.638498306274, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 832084, "time": 26320.6559612751, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 832128, "time": 26322.136274576187, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 832268, "time": 26326.546236515045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832340, "time": 26328.550915002823, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 832588, "time": 26336.389946699142, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 832648, "time": 26337.89994955063, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 832768, "time": 26341.90734744072, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 832924, "time": 26346.784172534943, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 833236, "time": 26356.173520088196, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 833240, "time": 26356.19495844841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 833244, "time": 26356.646435022354, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 833376, "time": 26360.590622901917, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 833392, "time": 26361.10067296028, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 833584, "time": 26367.001642227173, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 833660, "time": 26369.438999652863, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 833840, "time": 26374.89938545227, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 833956, "time": 26378.35538625717, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 834024, "time": 26380.33237838745, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 834212, "time": 26386.23602938652, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 834296, "time": 26388.719395160675, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 834460, "time": 26394.094606161118, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 834532, "time": 26396.103060007095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834740, "time": 26402.581601381302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834940, "time": 26408.928721427917, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 834968, "time": 26409.47083377838, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 835208, "time": 26416.856741189957, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 835452, "time": 26424.631960392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 835616, "time": 26429.5352332592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 835872, "time": 26437.622364759445, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 836116, "time": 26445.014497995377, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 836124, "time": 26445.480674743652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 836364, "time": 26452.8086540699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 836472, "time": 26455.812348127365, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 836752, "time": 26464.680387735367, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 836764, "time": 26465.160885095596, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 836772, "time": 26465.19731259346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 837040, "time": 26473.542904615402, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 837284, "time": 26480.96764278412, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 837604, "time": 26490.800020217896, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 837628, "time": 26491.819365739822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 837908, "time": 26500.208131074905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838084, "time": 26505.591373205185, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 838120, "time": 26506.589510202408, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 838196, "time": 26509.047110557556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838328, "time": 26512.981117486954, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 838616, "time": 26521.90807390213, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 838668, "time": 26523.848808526993, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 838680, "time": 26523.897201776505, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 838760, "time": 26526.34702682495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838976, "time": 26533.114884376526, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 839484, "time": 26548.786551952362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839508, "time": 26549.307730913162, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 839768, "time": 26557.150416851044, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 839836, "time": 26559.578152418137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839916, "time": 26562.056432008743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 840036, "time": 26565.70096182823, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 840060, "time": 26567.466912031174, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 840060, "time": 26568.325821876526, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 840060, "time": 26568.450975894928, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 840060, "time": 26569.335449934006, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 840060, "time": 26569.354074954987, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 840060, "time": 26569.505692481995, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 840060, "time": 26570.075689554214, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 840060, "time": 26570.414150714874, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 840168, "time": 26573.41862344742, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 840248, "time": 26575.886910915375, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 840308, "time": 26577.8517639637, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 840424, "time": 26581.38849377632, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 840596, "time": 26586.799046278, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 840936, "time": 26597.128717422485, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 841072, "time": 26601.530306100845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 841580, "time": 26617.343040943146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 841752, "time": 26622.285019636154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842052, "time": 26631.53382563591, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 842092, "time": 26632.968693971634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842204, "time": 26636.399693489075, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 842228, "time": 26636.917274951935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842372, "time": 26641.434733629227, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 842424, "time": 26642.921406030655, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 842464, "time": 26644.364633321762, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 842572, "time": 26647.802224874496, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 842872, "time": 26656.66521692276, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 842908, "time": 26658.095838308334, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 843428, "time": 26673.912304401398, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 843464, "time": 26674.914834737778, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 843528, "time": 26676.89685368538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843580, "time": 26678.824763059616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843776, "time": 26684.730514526367, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 843920, "time": 26689.144902467728, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 843944, "time": 26689.66513323784, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 844076, "time": 26694.201503038406, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 844232, "time": 26698.68185710907, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 844436, "time": 26705.10165143013, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 844684, "time": 26712.900670528412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 844828, "time": 26717.314883232117, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 845100, "time": 26725.661779642105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845388, "time": 26734.56871676445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845444, "time": 26736.06047487259, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 845456, "time": 26736.54091334343, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 845764, "time": 26745.830032110214, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 845840, "time": 26748.25584244728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845856, "time": 26748.746230363846, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 845968, "time": 26752.167681455612, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 846040, "time": 26754.16154408455, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 846104, "time": 26756.10261631012, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 846148, "time": 26757.551000595093, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 846224, "time": 26759.97542476654, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 846228, "time": 26759.99442768097, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 846236, "time": 26760.455379486084, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 846584, "time": 26770.74411535263, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 846628, "time": 26772.195351839066, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 846632, "time": 26772.21619296074, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 846752, "time": 26776.074486494064, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 846984, "time": 26782.97199511528, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 847144, "time": 26787.910139083862, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 847144, "time": 26787.915303707123, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 847384, "time": 26795.370659828186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 847560, "time": 26800.760318040848, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 847720, "time": 26805.65943145752, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 847788, "time": 26808.06827521324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 847832, "time": 26809.085122823715, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 847900, "time": 26811.477164030075, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 848132, "time": 26818.433745622635, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 848180, "time": 26820.003098726273, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 848456, "time": 26828.358521938324, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 848540, "time": 26831.263837575912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848644, "time": 26834.25132584572, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 848724, "time": 26836.697673797607, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 848756, "time": 26837.695795059204, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 848988, "time": 26845.02061676979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 849120, "time": 26848.945930957794, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 849144, "time": 26849.464975118637, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 849288, "time": 26853.9456782341, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 849500, "time": 26860.72179198265, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 849628, "time": 26864.66488313675, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 849800, "time": 26869.61390733719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 849892, "time": 26872.53498530388, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 850052, "time": 26877.4342110157, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 850060, "time": 26878.668725013733, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 850060, "time": 26879.309546470642, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 850060, "time": 26879.51745080948, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 850060, "time": 26879.736722946167, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 850060, "time": 26880.151805639267, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 850060, "time": 26880.625605106354, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 850060, "time": 26880.664133548737, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 850060, "time": 26880.93689417839, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 850276, "time": 26887.398213863373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850472, "time": 26893.26560664177, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 850568, "time": 26896.23986530304, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 850856, "time": 26905.100647449493, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 850980, "time": 26909.007959604263, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 851048, "time": 26911.014062404633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851292, "time": 26918.862163305283, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 851612, "time": 26928.70024371147, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 851628, "time": 26929.208292245865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852012, "time": 26941.020902633667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852076, "time": 26943.04963684082, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 852392, "time": 26952.57977104187, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 852448, "time": 26954.53722023964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852784, "time": 26964.829734802246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852860, "time": 26967.24037194252, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 853168, "time": 26976.62343764305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 853180, "time": 26977.102836847305, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 853356, "time": 26982.48048877716, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 853412, "time": 26983.986141204834, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 853604, "time": 26989.836399555206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 853784, "time": 26995.20705461502, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 853936, "time": 27000.08698105812, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 854044, "time": 27003.587380170822, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 854388, "time": 27013.91679430008, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 854568, "time": 27019.3316321373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 854764, "time": 27025.62804389, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 855092, "time": 27035.578761577606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855180, "time": 27038.510313510895, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 855200, "time": 27039.020167589188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855316, "time": 27042.479729652405, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 855336, "time": 27042.989827871323, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 855448, "time": 27046.40842270851, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 855716, "time": 27054.72132539749, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 855724, "time": 27055.185161352158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855812, "time": 27057.661933660507, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 856068, "time": 27065.6020758152, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 856084, "time": 27066.093995332718, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 856116, "time": 27067.08624100685, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 856276, "time": 27071.98128437996, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 856520, "time": 27079.495414972305, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 856544, "time": 27080.44862151146, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 856612, "time": 27082.429330825806, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 856732, "time": 27086.3125808239, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 856900, "time": 27091.301042079926, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 856936, "time": 27092.318162441254, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 857076, "time": 27096.718867778778, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 857112, "time": 27097.722044944763, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 857232, "time": 27101.622410535812, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 857416, "time": 27107.029151916504, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 857636, "time": 27113.850855588913, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 857892, "time": 27121.75147652626, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 857892, "time": 27121.756466150284, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 858056, "time": 27126.6850502491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858232, "time": 27132.068295955658, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 858240, "time": 27132.53177833557, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 858268, "time": 27133.4948220253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858656, "time": 27145.21825361252, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 858888, "time": 27152.23010778427, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 859032, "time": 27156.656450748444, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 859048, "time": 27157.150765895844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 859260, "time": 27163.982412576675, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 859508, "time": 27171.357048749924, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 859812, "time": 27180.695883512497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860052, "time": 27188.039093494415, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 860060, "time": 27189.240573883057, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 860060, "time": 27189.588302850723, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 860060, "time": 27189.73579621315, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 860060, "time": 27189.831500291824, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 860060, "time": 27190.094557523727, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 860060, "time": 27190.13867545128, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 860060, "time": 27190.966428518295, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 860060, "time": 27191.011564731598, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 860176, "time": 27194.463586568832, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 860204, "time": 27195.442689418793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860416, "time": 27201.80547118187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860521, "time": 27205.92891716957, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.316924743652344, "train/action_min": 0.0, "train/action_std": 1.4129421216249467, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007995750504778697, "train/actor_opt_grad_steps": 52685.0, "train/actor_opt_loss": -8.19725643992424, "train/adv_mag": 0.8823505529761314, "train/adv_max": 0.29247282922267914, "train/adv_mean": 0.000505178384937608, "train/adv_min": -0.8213795974850655, "train/adv_std": 0.02234982535941526, "train/cont_avg": 0.9954833984375, "train/cont_loss_mean": 0.015405069655971602, "train/cont_loss_std": 0.2232514998689294, "train/cont_neg_acc": 0.3526385604361793, "train/cont_neg_loss": 2.723968657365434, "train/cont_pos_acc": 0.9998137018084526, "train/cont_pos_loss": 0.0032671019551344218, "train/cont_pred": 0.9953459802269936, "train/cont_rate": 0.9954833984375, "train/dyn_loss_mean": 1.0000000351667404, "train/dyn_loss_std": 1.1170784637215547e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2058412722032517, "train/extr_critic_critic_opt_grad_steps": 52685.0, "train/extr_critic_critic_opt_loss": 3325.5560913085938, "train/extr_critic_mag": 1.2471628046035768, "train/extr_critic_max": 1.2471628046035768, "train/extr_critic_mean": 1.1985897600650788, "train/extr_critic_min": 0.9767126226425171, "train/extr_critic_std": 0.015592441307380795, "train/extr_return_normed_mag": 0.9077537083625793, "train/extr_return_normed_max": 0.2715860253572464, "train/extr_return_normed_mean": 0.028730121552944184, "train/extr_return_normed_min": -0.8385968136787415, "train/extr_return_normed_std": 0.028165956689044834, "train/extr_return_rate": 0.99955635368824, "train/extr_return_raw_mag": 1.4419507688283921, "train/extr_return_raw_max": 1.4419507688283921, "train/extr_return_raw_mean": 1.1990949237346649, "train/extr_return_raw_min": 0.33176792979240416, "train/extr_return_raw_std": 0.028165956735610963, "train/extr_reward_mag": 0.29912529945373534, "train/extr_reward_max": 0.29912529945373534, "train/extr_reward_mean": 0.001890712583262939, "train/extr_reward_min": 2.753734588623047e-07, "train/extr_reward_std": 0.0076588791026733815, "train/image_loss_mean": 0.09403228038921953, "train/image_loss_std": 0.10449034668505192, "train/model_loss_mean": 0.7179820549488067, "train/model_loss_std": 0.3725614542514086, "train/model_opt_grad_norm": 18.897076923847198, "train/model_opt_grad_steps": 52639.21, "train/model_opt_loss": 3912.3358569335937, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5450.0, "train/policy_entropy_mag": 1.2128546035289764, "train/policy_entropy_max": 1.2128546035289764, "train/policy_entropy_mean": 0.0964774300903082, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11856045976281165, "train/policy_logprob_mag": 6.551080267429352, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09689647886902093, "train/policy_logprob_min": -6.551080267429352, "train/policy_logprob_std": 0.6358416676521301, "train/policy_randomness_mag": 0.6232840073108673, "train/policy_randomness_max": 0.6232840073108673, "train/policy_randomness_mean": 0.04957959247753024, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06092802761122584, "train/post_ent_mag": 59.07241228103638, "train/post_ent_max": 59.07241228103638, "train/post_ent_mean": 51.54457639694214, "train/post_ent_min": 46.70500761032105, "train/post_ent_std": 2.5071345561742784, "train/prior_ent_mag": 60.023489246368406, "train/prior_ent_max": 60.023489246368406, "train/prior_ent_mean": 51.75548610687256, "train/prior_ent_min": 45.90822645187378, "train/prior_ent_std": 2.691911269426346, "train/rep_loss_mean": 1.0000000351667404, "train/rep_loss_std": 1.1170784637215547e-06, "train/reward_avg": 0.0011639404296511203, "train/reward_loss_mean": 0.008544662229251116, "train/reward_loss_std": 0.1517675260186661, "train/reward_max_data": 0.6043906254693866, "train/reward_max_pred": 0.2057325291633606, "train/reward_neg_acc": 0.9998581013083458, "train/reward_neg_loss": 0.001625077832431998, "train/reward_pos_acc": 0.20629564860115754, "train/reward_pos_loss": 3.866132928549878, "train/reward_pred": 0.0009774984070099891, "train/reward_rate": 0.0017822265625, "train_stats/mean_log_entropy": 0.07153109268850932, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.010021282359957695, "report/cont_loss_std": 0.15312017500400543, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.5805602073669434, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0024682790972292423, "report/cont_pred": 0.9971315860748291, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1154182031750679, "report/image_loss_std": 0.11340266466140747, "report/model_loss_mean": 0.7352253198623657, "report/model_loss_std": 0.3649170994758606, "report/post_ent_mag": 65.16847229003906, "report/post_ent_max": 65.16847229003906, "report/post_ent_mean": 54.68241882324219, "report/post_ent_min": 48.85630416870117, "report/post_ent_std": 3.00164794921875, "report/prior_ent_mag": 61.77509307861328, "report/prior_ent_max": 61.77509307861328, "report/prior_ent_mean": 52.82366943359375, "report/prior_ent_min": 45.95676803588867, "report/prior_ent_std": 2.5083158016204834, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0013427734375, "report/reward_loss_mean": 0.00978577509522438, "report/reward_loss_std": 0.18565699458122253, "report/reward_max_data": 0.7562500238418579, "report/reward_max_pred": 0.05273032188415527, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0015953489346429706, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.195093154907227, "report/reward_pred": 0.0008233119733631611, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02355222962796688, "eval/cont_loss_std": 0.41778698563575745, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.476591110229492, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0016529954737052321, "eval/cont_pred": 0.998410701751709, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1346597969532013, "eval/image_loss_std": 0.1395830512046814, "eval/model_loss_mean": 0.7586055397987366, "eval/model_loss_std": 0.44079887866973877, "eval/post_ent_mag": 64.22455596923828, "eval/post_ent_max": 64.22455596923828, "eval/post_ent_mean": 53.73509216308594, "eval/post_ent_min": 47.78435516357422, "eval/post_ent_std": 3.1997103691101074, "eval/prior_ent_mag": 61.01908493041992, "eval/prior_ent_max": 61.01908493041992, "eval/prior_ent_mean": 51.804054260253906, "eval/prior_ent_min": 46.16632080078125, "eval/prior_ent_std": 2.784991502761841, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00039348332211375237, "eval/reward_loss_std": 0.0022395385894924402, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.018261313438415527, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00039348332211375237, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00020027603022754192, "eval/reward_rate": 0.0, "replay/size": 860009.0, "replay/inserts": 31968.0, "replay/samples": 31968.0, "replay/insert_wait_avg": 1.4791826347450356e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.945346880006838e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4388.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2678891393197268e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1561722755432, "timer/env.step_count": 7992.0, "timer/env.step_total": 37.38351893424988, "timer/env.step_frac": 0.03737768157666352, "timer/env.step_avg": 0.0046776174842655, "timer/env.step_min": 0.0034332275390625, "timer/env.step_max": 0.03169870376586914, "timer/replay._sample_count": 31968.0, "timer/replay._sample_total": 16.168229579925537, "timer/replay._sample_frac": 0.016165704944998516, "timer/replay._sample_avg": 0.000505762937309983, "timer/replay._sample_min": 0.00039696693420410156, "timer/replay._sample_max": 0.010927438735961914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9089.0, "timer/agent.policy_total": 83.35094356536865, "timer/agent.policy_frac": 0.08333792849143709, "timer/agent.policy_avg": 0.009170529603407267, "timer/agent.policy_min": 0.007616519927978516, "timer/agent.policy_max": 0.03831768035888672, "timer/dataset_train_count": 1998.0, "timer/dataset_train_total": 0.21801400184631348, "timer/dataset_train_frac": 0.00021797995942002802, "timer/dataset_train_avg": 0.00010911611704019694, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.005359172821044922, "timer/agent.train_count": 1998.0, "timer/agent.train_total": 866.9085402488708, "timer/agent.train_frac": 0.8667731743098591, "timer/agent.train_avg": 0.43388815828271815, "timer/agent.train_min": 0.42200136184692383, "timer/agent.train_max": 0.5321781635284424, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4837014675140381, "timer/agent.report_frac": 0.00048362593855070293, "timer/agent.report_avg": 0.24185073375701904, "timer/agent.report_min": 0.23638486862182617, "timer/agent.report_max": 0.24731659889221191, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.0265579223632812e-05, "timer/dataset_eval_frac": 2.026241479620609e-08, "timer/dataset_eval_avg": 2.0265579223632812e-05, "timer/dataset_eval_min": 2.0265579223632812e-05, "timer/dataset_eval_max": 2.0265579223632812e-05, "fps": 31.962405620366173}
{"step": 860708, "time": 27211.505908966064, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 860800, "time": 27214.46826338768, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 860992, "time": 27220.359359025955, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 861156, "time": 27225.25537443161, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 861268, "time": 27228.689462184906, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 861332, "time": 27230.653680324554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 861420, "time": 27233.571764230728, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 861528, "time": 27236.54874420166, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 861724, "time": 27242.952634334564, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 861852, "time": 27246.86504673958, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 861952, "time": 27249.821563482285, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 862024, "time": 27251.82296872139, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 862212, "time": 27257.7072660923, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 862424, "time": 27264.109290122986, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 862428, "time": 27264.56477379799, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 862488, "time": 27266.071317911148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862628, "time": 27270.46505856514, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 862744, "time": 27273.978222370148, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 862960, "time": 27280.823180913925, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 862980, "time": 27281.329617977142, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 863120, "time": 27285.733251333237, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 863144, "time": 27286.251383066177, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 863156, "time": 27286.744037628174, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 863324, "time": 27292.10003733635, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 863492, "time": 27297.022530555725, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 863524, "time": 27298.002267837524, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 863700, "time": 27303.46457719803, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 863756, "time": 27305.410071849823, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 863816, "time": 27306.942767620087, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 863892, "time": 27309.37481546402, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 864068, "time": 27314.799911737442, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 864172, "time": 27318.206498861313, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 864396, "time": 27325.09413266182, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 864472, "time": 27327.114793777466, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 864492, "time": 27328.05185031891, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 864624, "time": 27332.213074684143, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 864872, "time": 27339.609107732773, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 864964, "time": 27342.55233979225, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 865148, "time": 27348.424010276794, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 865224, "time": 27350.43762397766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865280, "time": 27352.39963746071, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 865780, "time": 27367.628556489944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865856, "time": 27370.07027411461, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 866120, "time": 27377.925616264343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 866324, "time": 27384.274262666702, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 866380, "time": 27386.21128964424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 866556, "time": 27391.645486831665, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 866948, "time": 27403.361166238785, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 867012, "time": 27405.335387945175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 867276, "time": 27413.62312602997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 867440, "time": 27418.567144155502, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 867536, "time": 27421.6155834198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 867804, "time": 27429.955089330673, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 868168, "time": 27440.80597472191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868288, "time": 27444.701633691788, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 868432, "time": 27449.134585380554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868452, "time": 27449.643723726273, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 868596, "time": 27454.151257276535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868636, "time": 27455.79709672928, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 868800, "time": 27460.725066661835, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 868844, "time": 27462.175627470016, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 868988, "time": 27466.58121085167, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 869588, "time": 27484.690718650818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 869752, "time": 27489.596355438232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870000, "time": 27497.419713020325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870060, "time": 27499.37788105011, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 870060, "time": 27500.416119337082, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 870060, "time": 27500.473457813263, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 870060, "time": 27501.31553220749, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 870060, "time": 27502.092883110046, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 870060, "time": 27502.30846095085, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 870060, "time": 27503.573130607605, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870060, "time": 27503.593541145325, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 870060, "time": 27504.645186901093, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870144, "time": 27507.108177423477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870336, "time": 27513.052327394485, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 870400, "time": 27515.051548480988, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 870408, "time": 27515.086581707, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 870748, "time": 27525.757148981094, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 870812, "time": 27527.709705352783, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 870908, "time": 27530.66771864891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870964, "time": 27532.161728858948, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 871148, "time": 27538.03411245346, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 871180, "time": 27539.01328778267, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 871232, "time": 27540.490224123, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 871400, "time": 27545.425169944763, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 871448, "time": 27546.89661026001, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 871636, "time": 27552.77161669731, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 871660, "time": 27553.72429251671, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 871768, "time": 27556.70470905304, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 871820, "time": 27558.64400744438, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 872072, "time": 27566.006267547607, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 872288, "time": 27572.92491555214, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 872304, "time": 27573.41506409645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 872576, "time": 27581.75820016861, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 872600, "time": 27582.298367023468, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 872816, "time": 27589.265179157257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 872952, "time": 27593.19800710678, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 873244, "time": 27602.478568553925, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 873348, "time": 27605.42842054367, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 873396, "time": 27606.912590265274, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 873460, "time": 27608.868583917618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 873648, "time": 27614.720735549927, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 873840, "time": 27620.580689430237, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 874032, "time": 27626.45568561554, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 874092, "time": 27628.405817508698, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 874356, "time": 27636.35524058342, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 874372, "time": 27636.848547935486, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 874616, "time": 27644.20945739746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874636, "time": 27645.14187526703, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 874652, "time": 27645.633380889893, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 874756, "time": 27648.59459590912, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 874936, "time": 27653.980336666107, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 874988, "time": 27655.930491924286, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 875192, "time": 27661.964480876923, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 875368, "time": 27667.363681793213, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 875512, "time": 27671.777364730835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 875668, "time": 27676.666373968124, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 875808, "time": 27681.07660794258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 875808, "time": 27681.08310317993, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 875948, "time": 27685.49263739586, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 876176, "time": 27692.43691945076, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 876324, "time": 27696.86057829857, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 876348, "time": 27697.825363874435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876600, "time": 27705.25622844696, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 876900, "time": 27714.74067401886, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 877104, "time": 27721.205228567123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 877332, "time": 27728.160619974136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 877380, "time": 27729.632521629333, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 877492, "time": 27733.067269802094, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 877504, "time": 27733.54666686058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 877616, "time": 27736.982937335968, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 877744, "time": 27740.910672426224, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 877820, "time": 27743.35378408432, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 877880, "time": 27744.885863780975, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 877980, "time": 27748.249621391296, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 878152, "time": 27753.202245235443, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 878356, "time": 27759.584913253784, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 878648, "time": 27768.414044618607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 878900, "time": 27776.256949186325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879036, "time": 27780.640214681625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879076, "time": 27781.714070558548, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 879256, "time": 27787.118705511093, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 879296, "time": 27788.560831308365, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 879756, "time": 27802.786159038544, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 879804, "time": 27804.274047136307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879836, "time": 27805.259155988693, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 880060, "time": 27813.189085006714, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 880060, "time": 27813.302814006805, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 880060, "time": 27813.416278362274, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 880060, "time": 27814.965081453323, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 880060, "time": 27816.049909830093, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880060, "time": 27816.492639541626, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 880060, "time": 27817.184390068054, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880060, "time": 27817.245000600815, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 880116, "time": 27818.75834417343, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 880192, "time": 27821.192873716354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 880376, "time": 27826.59201836586, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 880476, "time": 27829.990841388702, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 880620, "time": 27834.430518865585, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 880832, "time": 27840.800852537155, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 880892, "time": 27842.828733444214, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 880952, "time": 27844.514359235764, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 881048, "time": 27847.42747950554, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 881136, "time": 27850.334531068802, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 881272, "time": 27854.27469921112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 881384, "time": 27857.68947482109, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 881424, "time": 27859.144280910492, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 881620, "time": 27865.03964614868, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 882136, "time": 27880.76548910141, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 882204, "time": 27883.19680404663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882292, "time": 27885.67886543274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882540, "time": 27893.500535726547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882540, "time": 27893.50591993332, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 882696, "time": 27897.959607839584, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 882780, "time": 27900.867524147034, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 882832, "time": 27902.452961206436, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 883292, "time": 27916.63062763214, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 883696, "time": 27928.880514621735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 883712, "time": 27929.37083053589, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 883852, "time": 27933.842767953873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 883936, "time": 27936.321115016937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 884128, "time": 27942.213686704636, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 884232, "time": 27945.20690727234, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 884288, "time": 27947.15746641159, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 884444, "time": 27952.075671434402, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 884784, "time": 27962.457087516785, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 884840, "time": 27963.964485645294, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 885008, "time": 27969.512776613235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885028, "time": 27970.02203631401, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 885444, "time": 27982.848984718323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885564, "time": 27986.760941505432, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 885756, "time": 27992.684618473053, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 886008, "time": 28000.109431266785, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 886012, "time": 28000.5642721653, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 886164, "time": 28005.000975608826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 886184, "time": 28005.509655475616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 886220, "time": 28006.97098350525, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 886328, "time": 28009.966551303864, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 886504, "time": 28015.36291575432, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 886648, "time": 28019.783516168594, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 886892, "time": 28027.633890867233, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 886960, "time": 28029.604007720947, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 886968, "time": 28029.638207912445, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 887196, "time": 28036.935294628143, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 887368, "time": 28041.893543958664, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 887376, "time": 28042.365080833435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887424, "time": 28043.846653938293, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 887556, "time": 28047.7824177742, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 887620, "time": 28049.74138236046, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 888524, "time": 28077.733365774155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 888580, "time": 28079.219472885132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 888712, "time": 28083.212599992752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 888776, "time": 28085.18158006668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 888828, "time": 28087.08484530449, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 889084, "time": 28094.893246412277, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 889116, "time": 28096.050381422043, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 889200, "time": 28098.515991687775, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 889228, "time": 28099.500898122787, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 889352, "time": 28102.985157728195, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 889404, "time": 28104.924513578415, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 889444, "time": 28105.926484823227, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 889516, "time": 28108.361342906952, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 889664, "time": 28112.84584593773, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 889696, "time": 28113.83201789856, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 889892, "time": 28119.72039580345, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 889920, "time": 28120.690450429916, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 889980, "time": 28122.631349802017, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 890060, "time": 28126.2539999485, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 890060, "time": 28126.52624630928, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 890060, "time": 28127.30880665779, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 890060, "time": 28127.89802289009, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 890060, "time": 28127.902802228928, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 890060, "time": 28128.43427824974, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 890060, "time": 28129.057689905167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890060, "time": 28129.252817630768, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 890156, "time": 28132.16517186165, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 890176, "time": 28132.671636104584, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 890256, "time": 28135.137398958206, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 890672, "time": 28147.949805021286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890704, "time": 28148.936853170395, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 890740, "time": 28149.932946443558, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 890780, "time": 28151.376663923264, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 890904, "time": 28154.866935253143, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 891028, "time": 28158.787845134735, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 891316, "time": 28167.58493590355, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 891332, "time": 28168.074998617172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 891460, "time": 28172.01747250557, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 891480, "time": 28172.54253435135, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 891804, "time": 28182.750020742416, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 891844, "time": 28183.757205724716, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 891856, "time": 28184.241246700287, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 891896, "time": 28185.25198698044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 892180, "time": 28194.069717168808, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 892232, "time": 28195.551861286163, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 892336, "time": 28198.964770555496, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 892541, "time": 28205.934990882874, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.288277587890625, "train/action_min": 0.0, "train/action_std": 1.3812803560495377, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009482704136753456, "train/actor_opt_grad_steps": 54685.0, "train/actor_opt_loss": -8.9722549238801, "train/adv_mag": 0.8503716227412224, "train/adv_max": 0.3119081711769104, "train/adv_mean": 0.00019814691404462792, "train/adv_min": -0.7990406620502472, "train/adv_std": 0.025165809406898915, "train/cont_avg": 0.995302734375, "train/cont_loss_mean": 0.015265534730860963, "train/cont_loss_std": 0.21544255815446378, "train/cont_neg_acc": 0.3523829520197969, "train/cont_neg_loss": 2.570103992027524, "train/cont_pos_acc": 0.9998773115873337, "train/cont_pos_loss": 0.0030521520844195038, "train/cont_pred": 0.9953955340385438, "train/cont_rate": 0.995302734375, "train/dyn_loss_mean": 1.0000024235248566, "train/dyn_loss_std": 7.748935779090971e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16034726176410913, "train/extr_critic_critic_opt_grad_steps": 54685.0, "train/extr_critic_critic_opt_loss": 3523.939874267578, "train/extr_critic_mag": 1.2412412428855897, "train/extr_critic_max": 1.2412412428855897, "train/extr_critic_mean": 1.1878959393501283, "train/extr_critic_min": 0.9690281122922897, "train/extr_critic_std": 0.015457727266475558, "train/extr_return_normed_mag": 0.8745732581615449, "train/extr_return_normed_max": 0.3087980484962463, "train/extr_return_normed_mean": 0.028768759686499834, "train/extr_return_normed_min": -0.8127718913555145, "train/extr_return_normed_std": 0.030515089426189662, "train/extr_return_rate": 0.9994411188364029, "train/extr_return_raw_mag": 1.46812331199646, "train/extr_return_raw_max": 1.46812331199646, "train/extr_return_raw_mean": 1.1880940985679627, "train/extr_return_raw_min": 0.3465533721446991, "train/extr_return_raw_std": 0.030515089379623533, "train/extr_reward_mag": 0.33393789291381837, "train/extr_reward_max": 0.33393789291381837, "train/extr_reward_mean": 0.0018813500952091998, "train/extr_reward_min": 2.2292137145996095e-07, "train/extr_reward_std": 0.008472122225211933, "train/image_loss_mean": 0.09210702862590552, "train/image_loss_std": 0.10285495351999999, "train/model_loss_mean": 0.7164308285713196, "train/model_loss_std": 0.37935376066714527, "train/model_opt_grad_norm": 17.434620044231416, "train/model_opt_grad_steps": 54637.3, "train/model_opt_loss": 3636.5300708007812, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5075.0, "train/policy_entropy_mag": 1.206750940680504, "train/policy_entropy_max": 1.206750940680504, "train/policy_entropy_mean": 0.09675910141319037, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11879745341837405, "train/policy_logprob_mag": 6.551080241203308, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09640537466853857, "train/policy_logprob_min": -6.551080241203308, "train/policy_logprob_std": 0.6314732304215431, "train/policy_randomness_mag": 0.6201473453640938, "train/policy_randomness_max": 0.6201473453640938, "train/policy_randomness_mean": 0.04972434353083372, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06104981753975153, "train/post_ent_mag": 58.799769229888916, "train/post_ent_max": 58.799769229888916, "train/post_ent_mean": 50.733533992767335, "train/post_ent_min": 45.73108722686768, "train/post_ent_std": 2.693846672773361, "train/prior_ent_mag": 60.4799711227417, "train/prior_ent_max": 60.4799711227417, "train/prior_ent_mean": 51.32883516311645, "train/prior_ent_min": 45.36228343963623, "train/prior_ent_std": 2.9003927946090697, "train/rep_loss_mean": 1.0000024235248566, "train/rep_loss_std": 7.748935779090971e-05, "train/reward_avg": 0.001228271485233563, "train/reward_loss_mean": 0.009056786671280861, "train/reward_loss_std": 0.16433159677195364, "train/reward_max_data": 0.6366718759387732, "train/reward_max_pred": 0.19671134114265443, "train/reward_neg_acc": 0.9998434367775917, "train/reward_neg_loss": 0.0015662416401028168, "train/reward_pos_acc": 0.19473180191955347, "train/reward_pos_loss": 3.9898201295699196, "train/reward_pred": 0.0009504684928106144, "train/reward_rate": 0.001865234375, "train_stats/mean_log_entropy": 0.07177015732781127, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.009776594117283821, "report/cont_loss_std": 0.16893048584461212, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.402950763702393, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0045046741142869, "report/cont_pred": 0.9955570101737976, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06074972450733185, "report/image_loss_std": 0.07596035301685333, "report/model_loss_mean": 0.673173189163208, "report/model_loss_std": 0.18422551453113556, "report/post_ent_mag": 56.24235916137695, "report/post_ent_max": 56.24235916137695, "report/post_ent_mean": 49.61604309082031, "report/post_ent_min": 45.40385818481445, "report/post_ent_std": 2.3460521697998047, "report/prior_ent_mag": 58.9040641784668, "report/prior_ent_max": 58.9040641784668, "report/prior_ent_mean": 51.132755279541016, "report/prior_ent_min": 45.06052017211914, "report/prior_ent_std": 2.703446626663208, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00264689396135509, "report/reward_loss_std": 0.010614639148116112, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.03735816478729248, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00264689396135509, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0012890759389847517, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.00992572121322155, "eval/cont_loss_std": 0.15352080762386322, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.89811372756958, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005147433374077082, "eval/cont_pred": 0.9949654340744019, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16899941861629486, "eval/image_loss_std": 0.17879901826381683, "eval/model_loss_mean": 0.7804925441741943, "eval/model_loss_std": 0.2384103387594223, "eval/post_ent_mag": 57.251670837402344, "eval/post_ent_max": 57.251670837402344, "eval/post_ent_mean": 48.99854278564453, "eval/post_ent_min": 44.22283935546875, "eval/post_ent_std": 2.3265011310577393, "eval/prior_ent_mag": 59.07732391357422, "eval/prior_ent_max": 59.07732391357422, "eval/prior_ent_mean": 50.439456939697266, "eval/prior_ent_min": 44.45534896850586, "eval/prior_ent_std": 2.753674268722534, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015674172900617123, "eval/reward_loss_std": 0.009473543614149094, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.11496222019195557, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.0015674172900617123, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000716017559170723, "eval/reward_rate": 0.0, "replay/size": 892029.0, "replay/inserts": 32020.0, "replay/samples": 32016.0, "replay/insert_wait_avg": 1.4758646153122987e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.907594221344833e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4196.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2370378659723826e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9833238124847, "timer/env.step_count": 8005.0, "timer/env.step_total": 37.274635791778564, "timer/env.step_frac": 0.03727525740096066, "timer/env.step_avg": 0.0046564192119648426, "timer/env.step_min": 0.003537416458129883, "timer/env.step_max": 0.030835390090942383, "timer/replay._sample_count": 32016.0, "timer/replay._sample_total": 16.122743129730225, "timer/replay._sample_frac": 0.01612301200010165, "timer/replay._sample_avg": 0.0005035839308386502, "timer/replay._sample_min": 0.0004069805145263672, "timer/replay._sample_max": 0.011678457260131836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9054.0, "timer/agent.policy_total": 82.60468196868896, "timer/agent.policy_frac": 0.08260605952282746, "timer/agent.policy_avg": 0.009123556656581508, "timer/agent.policy_min": 0.00801396369934082, "timer/agent.policy_max": 0.041565656661987305, "timer/dataset_train_count": 2001.0, "timer/dataset_train_total": 0.21155738830566406, "timer/dataset_train_frac": 0.00021156091633517578, "timer/dataset_train_avg": 0.00010572583123721343, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0009474754333496094, "timer/agent.train_count": 2001.0, "timer/agent.train_total": 868.0634698867798, "timer/agent.train_frac": 0.8680779461173871, "timer/agent.train_avg": 0.4338148275296251, "timer/agent.train_min": 0.4223942756652832, "timer/agent.train_max": 0.5302510261535645, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48151206970214844, "timer/agent.report_frac": 0.0004815200996216221, "timer/agent.report_avg": 0.24075603485107422, "timer/agent.report_min": 0.23384761810302734, "timer/agent.report_max": 0.2476644515991211, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2172927856445312e-05, "timer/dataset_eval_frac": 2.2173297622514296e-08, "timer/dataset_eval_avg": 2.2172927856445312e-05, "timer/dataset_eval_min": 2.2172927856445312e-05, "timer/dataset_eval_max": 2.2172927856445312e-05, "fps": 32.019888625584805}
{"step": 892692, "time": 28210.479219436646, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 893000, "time": 28219.814601182938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 893052, "time": 28221.73678946495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 893180, "time": 28225.64901447296, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 893452, "time": 28234.15954899788, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 893492, "time": 28235.164538145065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 893512, "time": 28235.668144226074, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 893828, "time": 28245.46532034874, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 893904, "time": 28247.919202804565, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 894024, "time": 28251.359932422638, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 894032, "time": 28251.851558208466, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 894208, "time": 28257.237862110138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 894580, "time": 28268.48892569542, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 894636, "time": 28270.40990948677, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 894796, "time": 28275.284742832184, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 894804, "time": 28275.321701288223, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 894984, "time": 28280.705829143524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895088, "time": 28284.096358060837, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 895336, "time": 28291.508685588837, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 895668, "time": 28301.74610066414, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 895792, "time": 28305.646371364594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895960, "time": 28310.574661254883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896136, "time": 28315.979969263077, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 896148, "time": 28316.46537256241, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 896200, "time": 28317.949933052063, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 896492, "time": 28327.3076710701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896568, "time": 28329.321545124054, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 896780, "time": 28336.104942321777, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 896808, "time": 28336.640970230103, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 896908, "time": 28340.048241615295, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 897336, "time": 28353.014770269394, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 897528, "time": 28358.871019363403, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 897676, "time": 28363.73008608818, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 897724, "time": 28365.210079193115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 897856, "time": 28369.113642454147, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 897964, "time": 28372.540907859802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 898084, "time": 28376.019224882126, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 898112, "time": 28376.993237495422, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 898184, "time": 28378.976232767105, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 898372, "time": 28384.906270503998, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 898508, "time": 28389.264672756195, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 898580, "time": 28391.23565506935, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 898704, "time": 28395.13314962387, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 898856, "time": 28399.574410438538, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 899092, "time": 28406.902590036392, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 899120, "time": 28407.869433641434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 899132, "time": 28408.347135543823, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 899240, "time": 28411.440900087357, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 899564, "time": 28421.69800543785, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 899680, "time": 28425.138165473938, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 899704, "time": 28425.664804697037, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 899856, "time": 28430.547654390335, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 899892, "time": 28431.54226708412, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 900060, "time": 28438.58197402954, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 900060, "time": 28439.677302122116, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 900060, "time": 28440.0629196167, "eval_episode/length": 200.0, "eval_episode/score": 0.375, "eval_episode/reward_rate": 0.004975124378109453}
{"step": 900060, "time": 28440.913054466248, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 900060, "time": 28441.37420988083, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900060, "time": 28441.380366563797, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900060, "time": 28441.68216919899, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 900060, "time": 28443.14738702774, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 900152, "time": 28445.66920208931, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 900196, "time": 28447.126217842102, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 900288, "time": 28450.083604335785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 900380, "time": 28452.998663663864, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 900556, "time": 28458.40854024887, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 900584, "time": 28458.95011281967, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 900804, "time": 28465.870735406876, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 900884, "time": 28468.339801073074, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 901184, "time": 28477.791195869446, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 901308, "time": 28481.69587635994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 901728, "time": 28494.644854784012, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 901740, "time": 28495.119802951813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 901948, "time": 28501.475769758224, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 902056, "time": 28504.46030163765, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 902084, "time": 28505.425990343094, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 902348, "time": 28513.73246049881, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 902464, "time": 28517.17552280426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 902668, "time": 28523.53246307373, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 902688, "time": 28524.037860631943, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 902848, "time": 28528.915289878845, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 902896, "time": 28530.377733707428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903132, "time": 28537.723009586334, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 903180, "time": 28539.21097111702, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 903228, "time": 28540.678265333176, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 903288, "time": 28542.17777132988, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 903444, "time": 28547.07751560211, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 903452, "time": 28547.542058706284, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 903568, "time": 28550.998683214188, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 903644, "time": 28553.45401597023, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 903756, "time": 28556.88521504402, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 903856, "time": 28559.860726833344, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 903940, "time": 28562.408044576645, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 904052, "time": 28565.83601284027, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 904060, "time": 28566.30088210106, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 904192, "time": 28570.243052959442, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 904220, "time": 28571.211403608322, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 904540, "time": 28581.03414607048, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 904580, "time": 28582.048445224762, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 904952, "time": 28593.420773267746, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 905096, "time": 28597.822211503983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905132, "time": 28599.24886083603, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 905348, "time": 28605.613852262497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905528, "time": 28611.201905965805, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 905664, "time": 28615.5988008976, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 905896, "time": 28622.543415308, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 906108, "time": 28629.37211585045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 906252, "time": 28633.777410507202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 906528, "time": 28642.14614224434, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 906744, "time": 28648.601631641388, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 906820, "time": 28651.03902721405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 906900, "time": 28653.57576942444, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 907024, "time": 28657.52539396286, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 907028, "time": 28657.546221494675, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 907112, "time": 28659.99479341507, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 907480, "time": 28671.26099395752, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 907548, "time": 28673.681292772293, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 907624, "time": 28675.687252044678, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 907920, "time": 28685.03023958206, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 908032, "time": 28688.460483312607, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 908180, "time": 28692.882881879807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 908184, "time": 28692.90379834175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 908380, "time": 28699.255415439606, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 908436, "time": 28700.766893148422, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 908600, "time": 28705.68910765648, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 908636, "time": 28707.113692760468, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 908680, "time": 28708.13757109642, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 908944, "time": 28716.54507637024, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 909168, "time": 28723.385115385056, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 909336, "time": 28728.28188276291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 909420, "time": 28731.169466257095, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 909536, "time": 28734.587675094604, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 909544, "time": 28734.622491836548, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 909768, "time": 28741.71832871437, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 909792, "time": 28742.67944908142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910060, "time": 28752.365894794464, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 910060, "time": 28752.62031197548, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 910060, "time": 28753.135279893875, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 910060, "time": 28753.750796318054, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 910060, "time": 28754.547922611237, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 910060, "time": 28754.756412267685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910060, "time": 28755.506954193115, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 910060, "time": 28756.22624731064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910080, "time": 28756.7315762043, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 910188, "time": 28760.147862434387, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 910304, "time": 28763.578539848328, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 910700, "time": 28775.90004181862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910712, "time": 28775.947504281998, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 910864, "time": 28780.82194018364, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 910960, "time": 28783.754198789597, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 911236, "time": 28792.135677337646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911460, "time": 28799.063020706177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911500, "time": 28800.518109321594, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 911540, "time": 28801.602920293808, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 911708, "time": 28806.980224370956, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 911812, "time": 28809.98123884201, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 911856, "time": 28811.435639619827, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 911868, "time": 28811.91898536682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912016, "time": 28816.36608195305, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 912476, "time": 28830.56732058525, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 912552, "time": 28832.65569281578, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 912656, "time": 28836.07369017601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912656, "time": 28836.079187631607, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 912976, "time": 28845.853712558746, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 913012, "time": 28846.85438466072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 913584, "time": 28864.615900039673, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 913632, "time": 28866.09295940399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 913812, "time": 28871.664798736572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 913928, "time": 28875.110530376434, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 914132, "time": 28881.495208978653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 914228, "time": 28884.441030025482, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 914276, "time": 28885.91020131111, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 914408, "time": 28889.840402126312, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 914480, "time": 28892.335540533066, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 914588, "time": 28895.749781847, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 914596, "time": 28895.78304195404, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 914752, "time": 28900.684892892838, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 914756, "time": 28900.70542407036, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 914772, "time": 28901.192930698395, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 914796, "time": 28902.14324426651, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 914892, "time": 28905.06985974312, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 914900, "time": 28905.103839159012, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 915164, "time": 28913.367472410202, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 915184, "time": 28913.873929739, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 915212, "time": 28914.838069677353, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 915352, "time": 28918.795476198196, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 915408, "time": 28920.739044189453, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 915500, "time": 28923.677414894104, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 915684, "time": 28929.106124401093, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 915696, "time": 28929.58589220047, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 915996, "time": 28938.89337348938, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 916012, "time": 28939.384450674057, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 916320, "time": 28948.675488948822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 916328, "time": 28948.711674690247, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 916556, "time": 28956.080858707428, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 916648, "time": 28958.611214876175, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 916692, "time": 28960.06056046486, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 916952, "time": 28967.920469760895, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 917100, "time": 28972.76565885544, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 917168, "time": 28974.74601316452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 917184, "time": 28975.24328827858, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 917576, "time": 28987.126368045807, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 917712, "time": 28991.50556588173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 917716, "time": 28991.525497198105, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 917716, "time": 28991.530087709427, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 917836, "time": 28995.558506011963, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 917900, "time": 28997.541578769684, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 918224, "time": 29007.326914310455, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 918248, "time": 29007.850996017456, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 918380, "time": 29012.217232465744, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 918480, "time": 29015.146127700806, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 918724, "time": 29022.492602825165, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 918992, "time": 29030.788507938385, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 919404, "time": 29043.52969264984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 919416, "time": 29043.5785279274, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 919636, "time": 29050.432478427887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 919772, "time": 29054.797149658203, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 919820, "time": 29056.27955389023, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 919872, "time": 29057.753014087677, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 919880, "time": 29057.789059877396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 920060, "time": 29064.719631433487, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 920060, "time": 29064.93253016472, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 920060, "time": 29065.12035727501, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 920060, "time": 29065.96374297142, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 920060, "time": 29066.05195093155, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 920060, "time": 29066.36208987236, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 920060, "time": 29066.48696064949, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 920060, "time": 29067.782200813293, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920168, "time": 29070.763781309128, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 920204, "time": 29072.207494974136, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 920368, "time": 29077.144938230515, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 920488, "time": 29080.61723089218, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 920864, "time": 29092.347100496292, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 920976, "time": 29095.791177988052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921004, "time": 29096.762206554413, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 921188, "time": 29102.251304626465, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 921324, "time": 29106.630464315414, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 921600, "time": 29114.96706366539, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 921624, "time": 29115.48868227005, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 921644, "time": 29116.430073738098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921784, "time": 29120.396423578262, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 921832, "time": 29121.865349292755, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 922444, "time": 29141.078735351562, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 922452, "time": 29141.114850997925, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 922756, "time": 29150.37882041931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 922780, "time": 29151.334378004074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 922972, "time": 29157.20734667778, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 923000, "time": 29157.766209602356, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 923004, "time": 29158.22194671631, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 923120, "time": 29161.71727991104, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 923140, "time": 29162.22450685501, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 923220, "time": 29164.68580889702, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 923348, "time": 29168.59394979477, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 923408, "time": 29170.542170524597, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 923688, "time": 29178.897769212723, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 924296, "time": 29197.595257759094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924376, "time": 29200.041248083115, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 924376, "time": 29200.049313545227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924545, "time": 29205.937350034714, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.28896728515625, "train/action_min": 0.0, "train/action_std": 1.370989139676094, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009206302511738613, "train/actor_opt_grad_steps": 56685.0, "train/actor_opt_loss": -8.6694452342391, "train/adv_mag": 0.9169517043232918, "train/adv_max": 0.34106954097747805, "train/adv_mean": 0.0005874062759539811, "train/adv_min": -0.8723531296849251, "train/adv_std": 0.026828310212586075, "train/cont_avg": 0.9953857421875, "train/cont_loss_mean": 0.015227864452172071, "train/cont_loss_std": 0.21501559467287734, "train/cont_neg_acc": 0.3302222278341651, "train/cont_neg_loss": 2.5923010961397086, "train/cont_pos_acc": 0.999906771183014, "train/cont_pos_loss": 0.003306233362527564, "train/cont_pred": 0.9952740857005119, "train/cont_rate": 0.9953857421875, "train/dyn_loss_mean": 1.0000031858682632, "train/dyn_loss_std": 0.00010189239808823914, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1499717526510358, "train/extr_critic_critic_opt_grad_steps": 56685.0, "train/extr_critic_critic_opt_loss": 4242.19150390625, "train/extr_critic_mag": 1.2413170003890992, "train/extr_critic_max": 1.2413170003890992, "train/extr_critic_mean": 1.1825545632839203, "train/extr_critic_min": 0.914867804646492, "train/extr_critic_std": 0.01629162047058344, "train/extr_return_normed_mag": 0.9423847717046737, "train/extr_return_normed_max": 0.3354735285043716, "train/extr_return_normed_mean": 0.031050267969258128, "train/extr_return_normed_min": -0.8987788832187653, "train/extr_return_normed_std": 0.032249741973355416, "train/extr_return_rate": 0.9994072690606117, "train/extr_return_raw_mag": 1.4875651866197586, "train/extr_return_raw_max": 1.4875651866197586, "train/extr_return_raw_mean": 1.1831419742107392, "train/extr_return_raw_min": 0.2533127748966217, "train/extr_return_raw_std": 0.03224974201992154, "train/extr_reward_mag": 0.3595842432975769, "train/extr_reward_max": 0.3595842432975769, "train/extr_reward_mean": 0.001932693959097378, "train/extr_reward_min": 2.0682811737060548e-07, "train/extr_reward_std": 0.00879255983280018, "train/image_loss_mean": 0.09087432220578194, "train/image_loss_std": 0.10330431263893843, "train/model_loss_mean": 0.7163959035277366, "train/model_loss_std": 0.39397104647010567, "train/model_opt_grad_norm": 17.91421854795523, "train/model_opt_grad_steps": 56635.365, "train/model_opt_loss": 3709.9247216796875, "train/model_opt_model_opt_grad_overflow": 0.005, "train/model_opt_model_opt_grad_scale": 5150.0, "train/policy_entropy_mag": 1.1956794661283494, "train/policy_entropy_max": 1.1956794661283494, "train/policy_entropy_mean": 0.09242636796087027, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11082918845117092, "train/policy_logprob_mag": 6.551080255508423, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09258164782077075, "train/policy_logprob_min": -6.551080255508423, "train/policy_logprob_std": 0.6304995334148407, "train/policy_randomness_mag": 0.614457732141018, "train/policy_randomness_max": 0.614457732141018, "train/policy_randomness_mean": 0.04749775864183903, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05695493975654244, "train/post_ent_mag": 58.50077035903931, "train/post_ent_max": 58.50077035903931, "train/post_ent_mean": 50.58291063308716, "train/post_ent_min": 45.20183013916016, "train/post_ent_std": 2.7816685795783997, "train/prior_ent_mag": 59.84039049148559, "train/prior_ent_max": 59.84039049148559, "train/prior_ent_mean": 50.83214433670044, "train/prior_ent_min": 44.78002065658569, "train/prior_ent_std": 2.875016574859619, "train/rep_loss_mean": 1.0000031858682632, "train/rep_loss_std": 0.00010189239808823914, "train/reward_avg": 0.0013709869457670721, "train/reward_loss_mean": 0.01029177990858443, "train/reward_loss_std": 0.17818598624668083, "train/reward_max_data": 0.6693437495082617, "train/reward_max_pred": 0.19443897664546966, "train/reward_neg_acc": 0.9997992563247681, "train/reward_neg_loss": 0.0018016741672181524, "train/reward_pos_acc": 0.15767790385511485, "train/reward_pos_loss": 4.082991399122088, "train/reward_pred": 0.0010812960029579698, "train/reward_rate": 0.00208984375, "train_stats/mean_log_entropy": 0.07086019676465255, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.009945770725607872, "report/cont_loss_std": 0.17193438112735748, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.9539850950241089, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.002322086598724127, "report/cont_pred": 0.9960219860076904, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07928793132305145, "report/image_loss_std": 0.10583318769931793, "report/model_loss_mean": 0.6962997913360596, "report/model_loss_std": 0.33639416098594666, "report/post_ent_mag": 58.3409538269043, "report/post_ent_max": 58.3409538269043, "report/post_ent_mean": 50.625144958496094, "report/post_ent_min": 45.395721435546875, "report/post_ent_std": 2.7511651515960693, "report/prior_ent_mag": 59.991573333740234, "report/prior_ent_max": 59.991573333740234, "report/prior_ent_mean": 50.251319885253906, "report/prior_ent_min": 44.560447692871094, "report/prior_ent_std": 2.704586982727051, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.000335693359375, "report/reward_loss_mean": 0.0070661092177033424, "report/reward_loss_std": 0.19172553718090057, "report/reward_max_data": 0.34375, "report/reward_max_pred": 0.037055015563964844, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.001074265455827117, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.136722087860107, "report/reward_pred": 0.000605872250162065, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.04469582438468933, "eval/cont_loss_std": 0.5389913320541382, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.3134660720825195, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.001547947176732123, "eval/cont_pred": 0.9984360933303833, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11903955787420273, "eval/image_loss_std": 0.11371300369501114, "eval/model_loss_mean": 0.7959820628166199, "eval/model_loss_std": 1.0167995691299438, "eval/post_ent_mag": 58.60805892944336, "eval/post_ent_max": 58.60805892944336, "eval/post_ent_mean": 50.48353576660156, "eval/post_ent_min": 45.32675552368164, "eval/post_ent_std": 2.866537094116211, "eval/prior_ent_mag": 59.92202377319336, "eval/prior_ent_max": 59.92202377319336, "eval/prior_ent_mean": 50.116615295410156, "eval/prior_ent_min": 44.81385040283203, "eval/prior_ent_std": 2.801712989807129, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0022521973587572575, "eval/reward_loss_mean": 0.03224661573767662, "eval/reward_loss_std": 0.5554056763648987, "eval/reward_max_data": 0.6875, "eval/reward_max_pred": 0.008769631385803223, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.000372404174413532, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.160173416137695, "eval/reward_pred": 0.0002049930626526475, "eval/reward_rate": 0.00390625, "replay/size": 924033.0, "replay/inserts": 32004.0, "replay/samples": 32000.0, "replay/insert_wait_avg": 1.4737194410757248e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.908567786216736e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4400.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.275756142356179e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9867694377899, "timer/env.step_count": 8001.0, "timer/env.step_total": 37.18702149391174, "timer/env.step_frac": 0.03718751350562262, "timer/env.step_avg": 0.004647796712149949, "timer/env.step_min": 0.0034284591674804688, "timer/env.step_max": 0.030566930770874023, "timer/replay._sample_count": 32000.0, "timer/replay._sample_total": 16.060457229614258, "timer/replay._sample_frac": 0.01606066972130414, "timer/replay._sample_avg": 0.0005018892884254456, "timer/replay._sample_min": 0.00037980079650878906, "timer/replay._sample_max": 0.011169195175170898, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9101.0, "timer/agent.policy_total": 83.44325828552246, "timer/agent.policy_frac": 0.08344436230134897, "timer/agent.policy_avg": 0.009168581286179811, "timer/agent.policy_min": 0.006903409957885742, "timer/agent.policy_max": 0.0440981388092041, "timer/dataset_train_count": 2000.0, "timer/dataset_train_total": 0.21593618392944336, "timer/dataset_train_frac": 0.0002159390409243579, "timer/dataset_train_avg": 0.00010796809196472168, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.005359172821044922, "timer/agent.train_count": 2000.0, "timer/agent.train_total": 866.8277907371521, "timer/agent.train_frac": 0.8668392595079012, "timer/agent.train_avg": 0.43341389536857605, "timer/agent.train_min": 0.4230184555053711, "timer/agent.train_max": 0.5239789485931396, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4794013500213623, "timer/agent.report_frac": 0.0004794076928546666, "timer/agent.report_avg": 0.23970067501068115, "timer/agent.report_min": 0.23413991928100586, "timer/agent.report_max": 0.24526143074035645, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9087451493727146e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 32.00382663179757}
{"step": 924564, "time": 29206.544425964355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924844, "time": 29215.42812395096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924888, "time": 29216.45944261551, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 924924, "time": 29217.896915197372, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 925044, "time": 29221.461839914322, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 925108, "time": 29223.444638490677, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 925316, "time": 29229.834880828857, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 925464, "time": 29234.252970457077, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 925552, "time": 29237.172561883926, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 925600, "time": 29238.661254405975, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 925804, "time": 29245.04794549942, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 925988, "time": 29250.694978952408, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 926000, "time": 29251.205468416214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 926124, "time": 29255.10830307007, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 926216, "time": 29257.612784147263, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 926380, "time": 29262.935769081116, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 926456, "time": 29264.90505027771, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 926516, "time": 29266.860028743744, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 926708, "time": 29272.714144706726, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 926732, "time": 29273.66901397705, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 926960, "time": 29280.544996261597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 926984, "time": 29281.1000957489, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 927580, "time": 29299.68501329422, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 927672, "time": 29302.20245552063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 927864, "time": 29308.10265660286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 927956, "time": 29311.056495189667, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 928080, "time": 29315.04415154457, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 928116, "time": 29316.063158988953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 928216, "time": 29319.00786757469, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 928436, "time": 29325.834460496902, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 928884, "time": 29339.513204336166, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 929112, "time": 29346.418164730072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 929200, "time": 29349.301292181015, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 929236, "time": 29350.308430433273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 929272, "time": 29351.300537586212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 929604, "time": 29361.500246047974, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 929612, "time": 29361.96192574501, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 929712, "time": 29364.914850711823, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 929784, "time": 29366.883571624756, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 930024, "time": 29374.20868086815, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 930060, "time": 29376.5825817585, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 930060, "time": 29377.481447935104, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 930060, "time": 29377.67026782036, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 930060, "time": 29377.782370090485, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 930060, "time": 29378.187634944916, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 930060, "time": 29378.526165008545, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 930060, "time": 29379.115092992783, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 930060, "time": 29379.375651359558, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 930104, "time": 29380.40077495575, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 930320, "time": 29387.232293605804, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 930428, "time": 29390.661156892776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 930460, "time": 29391.639333963394, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 930768, "time": 29400.957184791565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 930780, "time": 29401.47830247879, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 930880, "time": 29404.460703372955, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 930940, "time": 29406.415468215942, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 931204, "time": 29414.341564416885, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 931276, "time": 29416.744812726974, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 931924, "time": 29436.392289876938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931936, "time": 29436.87611746788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 932156, "time": 29443.742552042007, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 932360, "time": 29449.626475334167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 932432, "time": 29452.065037727356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 932480, "time": 29453.543089151382, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 932540, "time": 29455.47005867958, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 932568, "time": 29456.00118780136, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 932748, "time": 29461.926161766052, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 932868, "time": 29465.378834486008, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 933004, "time": 29469.74357318878, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 933032, "time": 29470.278556346893, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 933080, "time": 29471.7581884861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 933292, "time": 29478.54964375496, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 933352, "time": 29480.057388305664, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 933480, "time": 29483.975911140442, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 933504, "time": 29484.924516677856, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 933576, "time": 29486.916874170303, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 933752, "time": 29492.254177570343, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 933776, "time": 29493.20359325409, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 933920, "time": 29497.573811769485, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 933996, "time": 29499.997502565384, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 934008, "time": 29500.05059814453, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 934212, "time": 29506.586178064346, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 934468, "time": 29514.454739570618, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 934636, "time": 29519.858253717422, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 934660, "time": 29520.38968539238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934860, "time": 29526.811720609665, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 934924, "time": 29528.76886820793, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 934940, "time": 29529.26381087303, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 935164, "time": 29536.141289949417, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 935356, "time": 29542.02509522438, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 935428, "time": 29544.007833957672, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 935596, "time": 29549.332822561264, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 935624, "time": 29549.870625972748, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 935680, "time": 29551.904429912567, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 935840, "time": 29556.80908179283, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 936112, "time": 29565.143945217133, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 936136, "time": 29565.661733150482, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 936180, "time": 29567.123512268066, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 936476, "time": 29576.347407579422, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 936484, "time": 29576.381727457047, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 936596, "time": 29579.82424545288, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 936696, "time": 29582.836651802063, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 936952, "time": 29590.674991607666, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 937032, "time": 29593.125114679337, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 937248, "time": 29599.96730518341, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 937512, "time": 29607.80840563774, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 937608, "time": 29610.751080989838, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 937752, "time": 29615.230811595917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 938000, "time": 29623.03210544586, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 938292, "time": 29632.01851606369, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 938404, "time": 29635.450928926468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 938592, "time": 29641.40750193596, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 938668, "time": 29643.839876651764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 938872, "time": 29649.753895759583, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 938908, "time": 29651.191888809204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939252, "time": 29661.466884851456, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 939260, "time": 29661.927994012833, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 939264, "time": 29661.948675632477, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 939536, "time": 29670.232523441315, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 939656, "time": 29673.710407733917, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 940060, "time": 29687.47491335869, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 940060, "time": 29688.654854297638, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 940060, "time": 29688.979581832886, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 940060, "time": 29689.724495649338, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 940060, "time": 29689.904698610306, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 940060, "time": 29690.19202709198, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940060, "time": 29690.909821510315, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 940060, "time": 29691.25942850113, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 940416, "time": 29702.01785635948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 940420, "time": 29702.039214849472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 940492, "time": 29704.45685172081, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 940692, "time": 29710.33899307251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 940760, "time": 29712.33721613884, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 940768, "time": 29712.80429124832, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 940944, "time": 29718.21236348152, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 941288, "time": 29728.541087388992, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 941292, "time": 29728.995120048523, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 941572, "time": 29737.358194828033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 941700, "time": 29741.233340263367, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 941848, "time": 29745.632423877716, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 941864, "time": 29746.130259513855, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 942004, "time": 29750.488394260406, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 942160, "time": 29755.35778403282, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 942180, "time": 29755.865508556366, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 942452, "time": 29764.471858263016, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 942476, "time": 29765.426965236664, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 942728, "time": 29772.826026201248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 942756, "time": 29773.79327225685, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 942896, "time": 29778.184773683548, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 943060, "time": 29783.085145950317, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 943348, "time": 29791.96070790291, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 943352, "time": 29791.98033809662, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 943656, "time": 29801.30413532257, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 943828, "time": 29806.66595697403, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 943832, "time": 29806.686212539673, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 943884, "time": 29810.86966896057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944056, "time": 29815.81584095955, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 944136, "time": 29818.27555990219, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 944204, "time": 29820.689050912857, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 944224, "time": 29821.22790503502, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 944448, "time": 29828.17182660103, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 944456, "time": 29828.204790830612, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 944480, "time": 29829.15509223938, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 944632, "time": 29833.60907793045, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 944776, "time": 29838.072385549545, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 944792, "time": 29838.573573589325, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 944816, "time": 29839.53507566452, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 944880, "time": 29841.505850076675, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 945024, "time": 29845.92643404007, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 945200, "time": 29851.405477523804, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 945284, "time": 29853.88923883438, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 945400, "time": 29857.355721235275, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 945432, "time": 29858.341328144073, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 945624, "time": 29864.22144818306, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 945768, "time": 29868.644912481308, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 945860, "time": 29871.5921125412, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 945864, "time": 29871.614308834076, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 946028, "time": 29876.98822760582, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 946348, "time": 29886.82693338394, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 946504, "time": 29891.435069799423, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 946516, "time": 29891.930425167084, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 946660, "time": 29896.318746566772, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 946736, "time": 29898.74673128128, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 946828, "time": 29901.67641735077, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 946932, "time": 29904.632709741592, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 946948, "time": 29905.132721424103, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 947048, "time": 29908.107989549637, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 947248, "time": 29914.546763181686, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 947312, "time": 29916.52692937851, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 947444, "time": 29920.47341442108, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 947564, "time": 29924.379461288452, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 947584, "time": 29924.887315511703, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 947664, "time": 29927.33845114708, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 947716, "time": 29928.830847978592, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 947776, "time": 29930.775591135025, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 947800, "time": 29931.314926862717, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 947968, "time": 29936.654621124268, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 948064, "time": 29939.595206975937, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 948088, "time": 29940.119728565216, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 948156, "time": 29942.628249645233, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 948188, "time": 29943.61043024063, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 948244, "time": 29945.118230104446, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 948436, "time": 29950.997958898544, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 948768, "time": 29961.223705530167, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 948788, "time": 29961.7322909832, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 948900, "time": 29965.141232967377, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 948928, "time": 29966.12400817871, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 949088, "time": 29970.985978364944, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 949096, "time": 29971.018501520157, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 949320, "time": 29977.858127832413, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 949352, "time": 29978.8319272995, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 949400, "time": 29980.311915159225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 949776, "time": 29992.04045176506, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 949796, "time": 29992.55276942253, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 949804, "time": 29993.01879310608, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 949992, "time": 29998.425123929977, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 950060, "time": 30002.29495573044, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 950060, "time": 30002.507189273834, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 950060, "time": 30002.64768099785, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 950060, "time": 30002.741439819336, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 950060, "time": 30004.078191041946, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 950060, "time": 30004.097047567368, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 950060, "time": 30004.22617483139, "eval_episode/length": 237.0, "eval_episode/score": 0.2593750059604645, "eval_episode/reward_rate": 0.004201680672268907}
{"step": 950060, "time": 30004.37960958481, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 950068, "time": 30004.41237139702, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 950228, "time": 30009.283584356308, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 950244, "time": 30009.776788949966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 950516, "time": 30018.098905801773, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 950584, "time": 30020.2668967247, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 950776, "time": 30026.183608055115, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 950924, "time": 30031.04758810997, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 950936, "time": 30031.137036561966, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 950956, "time": 30032.121619462967, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 951200, "time": 30039.504487752914, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 951328, "time": 30043.43568921089, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 951460, "time": 30047.347812652588, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 951524, "time": 30049.32697749138, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 951756, "time": 30056.632855653763, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 951760, "time": 30056.654015302658, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 951768, "time": 30056.778899669647, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 951924, "time": 30061.711844682693, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 951984, "time": 30063.670209169388, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 952200, "time": 30070.043853998184, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 952296, "time": 30072.96968436241, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 952424, "time": 30076.862850904465, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 952428, "time": 30077.330825805664, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 952428, "time": 30077.33637547493, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 952516, "time": 30079.820081472397, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 952752, "time": 30087.148364305496, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 952788, "time": 30088.13321852684, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 952888, "time": 30091.092379808426, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 953008, "time": 30095.02878022194, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 953248, "time": 30102.361396312714, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 953408, "time": 30107.234450101852, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 953468, "time": 30109.186659812927, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 953620, "time": 30113.606776475906, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 953944, "time": 30123.444355726242, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 953944, "time": 30123.450982809067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 954076, "time": 30127.815331220627, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 954128, "time": 30129.297988176346, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 954228, "time": 30132.262368440628, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 954480, "time": 30140.139973163605, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 954560, "time": 30142.616013288498, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 954848, "time": 30151.709683179855, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 954920, "time": 30153.70838546753, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 955020, "time": 30157.121170520782, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 955152, "time": 30161.076139211655, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 955204, "time": 30162.561047792435, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 955212, "time": 30163.025082826614, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 955424, "time": 30169.377234697342, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 955664, "time": 30176.722340345383, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 955688, "time": 30177.242701530457, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 955748, "time": 30179.185855150223, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 955992, "time": 30186.586780786514, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 956004, "time": 30187.06849503517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956088, "time": 30189.509801387787, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 956236, "time": 30194.36864376068, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 956352, "time": 30197.81022119522, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 956432, "time": 30200.28214263916, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 956460, "time": 30201.24711704254, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 956601, "time": 30206.16791176796, "train_stats/mean_log_entropy": 0.07086027752666268, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3555987154073383, "train/action_min": 0.0, "train/action_std": 1.4447358817010376, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007260480000225095, "train/actor_opt_grad_steps": 58690.0, "train/actor_opt_loss": -8.714140934953049, "train/adv_mag": 0.8803835656512436, "train/adv_max": 0.36173604910646506, "train/adv_mean": 0.0018313529811469682, "train/adv_min": -0.8163353086110965, "train/adv_std": 0.02321342565582611, "train/cont_avg": 0.9950345926616916, "train/cont_loss_mean": 0.017960267464644207, "train/cont_loss_std": 0.24363426561119841, "train/cont_neg_acc": 0.2941562078930252, "train/cont_neg_loss": 2.874496073438902, "train/cont_pos_acc": 0.9998534843696291, "train/cont_pos_loss": 0.0036464672233325556, "train/cont_pred": 0.9950988989564317, "train/cont_rate": 0.9950345926616916, "train/dyn_loss_mean": 1.0000020419780296, "train/dyn_loss_std": 6.532179029827557e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.21782055368359707, "train/extr_critic_critic_opt_grad_steps": 58690.0, "train/extr_critic_critic_opt_loss": 4632.454055406561, "train/extr_critic_mag": 1.2757724244796222, "train/extr_critic_max": 1.2757724244796222, "train/extr_critic_mean": 1.2152045733893095, "train/extr_critic_min": 0.8904134693430431, "train/extr_critic_std": 0.019252905673092575, "train/extr_return_normed_mag": 0.9030897403830913, "train/extr_return_normed_max": 0.3056610348212778, "train/extr_return_normed_mean": 0.03716762662304575, "train/extr_return_normed_min": -0.8381902477634486, "train/extr_return_normed_std": 0.03119403298999836, "train/extr_return_rate": 0.9995566173572445, "train/extr_return_raw_mag": 1.485529287537532, "train/extr_return_raw_max": 1.485529287537532, "train/extr_return_raw_mean": 1.2170359507128967, "train/extr_return_raw_min": 0.34167800495280554, "train/extr_return_raw_std": 0.031194033022432482, "train/extr_reward_mag": 0.32669217313700055, "train/extr_reward_max": 0.32669217313700055, "train/extr_reward_mean": 0.001981398687855484, "train/extr_reward_min": 3.3331154590815453e-07, "train/extr_reward_std": 0.008011744144507012, "train/image_loss_mean": 0.0924860016252864, "train/image_loss_std": 0.10412995272607946, "train/model_loss_mean": 0.7219334994975607, "train/model_loss_std": 0.42127089521185085, "train/model_opt_grad_norm": 16.921569302307432, "train/model_opt_grad_steps": 58638.388059701494, "train/model_opt_loss": 3645.389704310479, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5074.626865671642, "train/policy_entropy_mag": 1.2091259167562076, "train/policy_entropy_max": 1.2091259167562076, "train/policy_entropy_mean": 0.08923049830826954, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10485848335929178, "train/policy_logprob_mag": 6.551080241132138, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08938470119564094, "train/policy_logprob_min": -6.551080241132138, "train/policy_logprob_std": 0.6279076948687805, "train/policy_randomness_mag": 0.6213678416624591, "train/policy_randomness_max": 0.6213678416624591, "train/policy_randomness_mean": 0.0458554066346949, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05388660386056449, "train/post_ent_mag": 59.34513836001875, "train/post_ent_max": 59.34513836001875, "train/post_ent_mean": 51.33608316070405, "train/post_ent_min": 45.83662852956288, "train/post_ent_std": 2.821615829396604, "train/prior_ent_mag": 59.84407491351835, "train/prior_ent_max": 59.84407491351835, "train/prior_ent_mean": 51.06055072765445, "train/prior_ent_min": 45.0643996623025, "train/prior_ent_std": 2.9237713440140682, "train/rep_loss_mean": 1.0000020419780296, "train/rep_loss_std": 6.532179029827557e-05, "train/reward_avg": 0.0016161562721140738, "train/reward_loss_mean": 0.011485985311128162, "train/reward_loss_std": 0.18656009597476775, "train/reward_max_data": 0.7080068420711442, "train/reward_max_pred": 0.2383846347011737, "train/reward_neg_acc": 0.9998149177921352, "train/reward_neg_loss": 0.002066953223550794, "train/reward_pos_acc": 0.18888889090285274, "train/reward_pos_loss": 3.8817743971699574, "train/reward_pred": 0.0012679502630921367, "train/reward_rate": 0.0024341184701492536, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.009753677062690258, "report/cont_loss_std": 0.1005677729845047, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 1.3564362525939941, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004472569562494755, "report/cont_pred": 0.9941970109939575, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09106145054101944, "report/image_loss_std": 0.09745293110609055, "report/model_loss_mean": 0.7121915817260742, "report/model_loss_std": 0.2824641168117523, "report/post_ent_mag": 56.833648681640625, "report/post_ent_max": 56.833648681640625, "report/post_ent_mean": 50.13567352294922, "report/post_ent_min": 45.31175994873047, "report/post_ent_std": 2.36649751663208, "report/prior_ent_mag": 53.53215026855469, "report/prior_ent_max": 53.53215026855469, "report/prior_ent_mean": 48.72039794921875, "report/prior_ent_min": 44.332550048828125, "report/prior_ent_std": 1.8452270030975342, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001910400460474193, "report/reward_loss_mean": 0.011376433074474335, "report/reward_loss_std": 0.14924226701259613, "report/reward_max_data": 0.7093750238418579, "report/reward_max_pred": 0.1354503631591797, "report/reward_neg_acc": 0.999020516872406, "report/reward_neg_loss": 0.003400177927687764, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 2.7259621620178223, "report/reward_pred": 0.0018601214978843927, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03690817579627037, "eval/cont_loss_std": 0.6345390677452087, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.467565536499023, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0033215200528502464, "eval/cont_pred": 0.9968783855438232, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14319229125976562, "eval/image_loss_std": 0.13533414900302887, "eval/model_loss_mean": 0.7812936902046204, "eval/model_loss_std": 0.6431819796562195, "eval/post_ent_mag": 57.039398193359375, "eval/post_ent_max": 57.039398193359375, "eval/post_ent_mean": 49.869178771972656, "eval/post_ent_min": 45.7121696472168, "eval/post_ent_std": 2.3035616874694824, "eval/prior_ent_mag": 53.51207733154297, "eval/prior_ent_max": 53.51207733154297, "eval/prior_ent_mean": 48.51662063598633, "eval/prior_ent_min": 44.57792282104492, "eval/prior_ent_std": 1.8037129640579224, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001193199073895812, "eval/reward_loss_std": 0.009199935011565685, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.07195043563842773, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001193199073895812, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0005398064386099577, "eval/reward_rate": 0.0, "replay/size": 956089.0, "replay/inserts": 32056.0, "replay/samples": 32064.0, "replay/insert_wait_avg": 1.4730022826455375e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.865939311638563e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3508.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2404834394987796e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2105464935303, "timer/env.step_count": 8014.0, "timer/env.step_total": 37.369157791137695, "timer/env.step_frac": 0.03736129150221814, "timer/env.step_avg": 0.004662984501015435, "timer/env.step_min": 0.0034639835357666016, "timer/env.step_max": 0.030173063278198242, "timer/replay._sample_count": 32064.0, "timer/replay._sample_total": 16.173032999038696, "timer/replay._sample_frac": 0.016169628540447817, "timer/replay._sample_avg": 0.0005043984842514563, "timer/replay._sample_min": 0.00040650367736816406, "timer/replay._sample_max": 0.02591419219970703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 8891.0, "timer/agent.policy_total": 81.00855565071106, "timer/agent.policy_frac": 0.08099150317371209, "timer/agent.policy_avg": 0.009111298577292887, "timer/agent.policy_min": 0.0074045658111572266, "timer/agent.policy_max": 0.04151749610900879, "timer/dataset_train_count": 2004.0, "timer/dataset_train_total": 0.22568202018737793, "timer/dataset_train_frac": 0.00022563451363171336, "timer/dataset_train_avg": 0.00011261577853661573, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.005400419235229492, "timer/agent.train_count": 2004.0, "timer/agent.train_total": 870.3295974731445, "timer/agent.train_frac": 0.870146391201619, "timer/agent.train_avg": 0.4342962063239244, "timer/agent.train_min": 0.42336368560791016, "timer/agent.train_max": 2.7071774005889893, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47946715354919434, "timer/agent.report_frac": 0.0004793662246714729, "timer/agent.report_avg": 0.23973357677459717, "timer/agent.report_min": 0.2344362735748291, "timer/agent.report_max": 0.24503087997436523, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.1219253540039062e-05, "timer/dataset_eval_frac": 2.1214786841058685e-08, "timer/dataset_eval_avg": 2.1219253540039062e-05, "timer/dataset_eval_min": 2.1219253540039062e-05, "timer/dataset_eval_max": 2.1219253540039062e-05, "fps": 32.04867146464766}
{"step": 956676, "time": 30208.297404527664, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 956704, "time": 30209.266959667206, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 956844, "time": 30213.716487407684, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 956936, "time": 30216.193613767624, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 957036, "time": 30219.573450565338, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 957172, "time": 30223.531040906906, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 957252, "time": 30225.992304325104, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 957308, "time": 30227.911046743393, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 957560, "time": 30235.313447475433, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 957560, "time": 30235.31909418106, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 957716, "time": 30240.23636341095, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 957872, "time": 30245.18667268753, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 957992, "time": 30248.628390550613, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 958220, "time": 30255.957661390305, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 958252, "time": 30256.94472193718, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 958444, "time": 30262.835967302322, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 958476, "time": 30263.82574224472, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 958720, "time": 30271.318913698196, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 958748, "time": 30272.463806390762, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 958908, "time": 30277.39051437378, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 959116, "time": 30283.75652050972, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 959176, "time": 30285.28451514244, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 959256, "time": 30287.737173080444, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 959396, "time": 30292.147613286972, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 959404, "time": 30292.611063718796, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 959536, "time": 30296.556611061096, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 959556, "time": 30297.07281780243, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 959676, "time": 30300.97495174408, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 959860, "time": 30306.427290439606, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 959964, "time": 30309.85248017311, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 30311.37264442444, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 960060, "time": 30313.89008283615, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 960060, "time": 30314.11428117752, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 960060, "time": 30315.454394340515, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 960060, "time": 30315.839064598083, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 960060, "time": 30316.0491604805, "eval_episode/length": 205.0, "eval_episode/score": 0.359375, "eval_episode/reward_rate": 0.0048543689320388345}
{"step": 960060, "time": 30316.460510969162, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 960060, "time": 30317.341938734055, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 960060, "time": 30317.37451338768, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 960256, "time": 30323.305638074875, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 960352, "time": 30326.270466566086, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 960436, "time": 30328.763167381287, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 960548, "time": 30332.22996520996, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 960848, "time": 30341.588238954544, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 961080, "time": 30348.470521450043, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 961228, "time": 30353.374581813812, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 961412, "time": 30358.82486128807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 961500, "time": 30361.78715443611, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 961508, "time": 30361.82768893242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 961584, "time": 30364.283405303955, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 961628, "time": 30365.73922109604, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 961812, "time": 30371.16302895546, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 962136, "time": 30381.007848262787, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 962224, "time": 30383.95764064789, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 962396, "time": 30389.3176009655, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 962408, "time": 30389.365453243256, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 962492, "time": 30392.327968358994, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 962568, "time": 30394.3503844738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 962716, "time": 30399.195420742035, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 962820, "time": 30402.221821546555, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 963036, "time": 30409.129292488098, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 963148, "time": 30412.563515901566, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 963232, "time": 30415.032616376877, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 963472, "time": 30422.480531692505, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 963644, "time": 30427.862170934677, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 963892, "time": 30435.254578351974, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 964004, "time": 30438.687875509262, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 964192, "time": 30444.54347205162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 964300, "time": 30447.94807124138, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 964376, "time": 30449.93999838829, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 964644, "time": 30458.323323249817, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 964748, "time": 30461.720113039017, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 964932, "time": 30467.118123054504, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 965048, "time": 30470.53397154808, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 965248, "time": 30476.881186962128, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 965532, "time": 30485.716994285583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 965648, "time": 30489.156797647476, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 965800, "time": 30493.571930885315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 965936, "time": 30497.93626356125, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 966180, "time": 30505.279550790787, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 966204, "time": 30506.24498963356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 966540, "time": 30516.61644244194, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 966608, "time": 30518.60122203827, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 966904, "time": 30527.42448759079, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 966956, "time": 30529.497311115265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 967148, "time": 30535.383816480637, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 967244, "time": 30538.331665992737, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 967276, "time": 30539.32169818878, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 967336, "time": 30540.856474876404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 967492, "time": 30545.82473874092, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 967624, "time": 30549.73982357979, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 967652, "time": 30550.72702741623, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 967772, "time": 30554.60255265236, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 967816, "time": 30555.640117645264, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 968116, "time": 30564.98360967636, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 968204, "time": 30567.893215179443, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 968252, "time": 30569.367330789566, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 968396, "time": 30573.888305664062, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 968420, "time": 30574.414153814316, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 968484, "time": 30576.40023303032, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 968664, "time": 30581.800550699234, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 968744, "time": 30584.252351522446, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 968768, "time": 30585.22708940506, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 968952, "time": 30590.680369615555, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 969276, "time": 30600.968529462814, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 969520, "time": 30608.35471725464, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 969820, "time": 30617.612319231033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969924, "time": 30620.603353500366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969924, "time": 30620.609304904938, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 970060, "time": 30625.89474916458, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 970060, "time": 30625.928193092346, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 970060, "time": 30626.320824623108, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 970060, "time": 30626.561475992203, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 970060, "time": 30627.063420772552, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 970060, "time": 30628.48198390007, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 970060, "time": 30628.65321469307, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 970060, "time": 30629.564292907715, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 970384, "time": 30639.47368836403, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 970564, "time": 30644.867104768753, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 970676, "time": 30648.28498506546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 970740, "time": 30650.23615527153, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 971016, "time": 30658.66143465042, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 971080, "time": 30660.693495988846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 971116, "time": 30662.169122219086, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 971692, "time": 30679.742165327072, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 971832, "time": 30683.711181163788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972172, "time": 30694.423728466034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972212, "time": 30695.42228293419, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 972288, "time": 30697.86607480049, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 972296, "time": 30697.900209903717, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 972392, "time": 30700.851327896118, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 972476, "time": 30703.74446249008, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 972720, "time": 30711.07616186142, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 972756, "time": 30712.082922697067, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 972860, "time": 30715.458112239838, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 973000, "time": 30719.416016340256, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 973340, "time": 30730.21117067337, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 973472, "time": 30734.15866279602, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 973548, "time": 30736.629405498505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 973736, "time": 30742.094549179077, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 973820, "time": 30744.99825668335, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 974000, "time": 30750.41464328766, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 974016, "time": 30750.908197402954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 974176, "time": 30755.864819526672, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 974496, "time": 30765.64460349083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 974572, "time": 30768.086025953293, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 974600, "time": 30768.627175092697, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 974776, "time": 30774.055325508118, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 975052, "time": 30782.927165031433, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 975124, "time": 30785.082022428513, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 975200, "time": 30787.518694639206, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 975232, "time": 30788.497881650925, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 975576, "time": 30798.836121320724, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 975664, "time": 30801.76588487625, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 975880, "time": 30808.170115232468, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 975940, "time": 30810.13231420517, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 975960, "time": 30810.657336473465, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 976040, "time": 30813.176506519318, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 976152, "time": 30816.611510515213, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 976232, "time": 30819.05602312088, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 976344, "time": 30822.47415113449, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 976356, "time": 30822.959918260574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 976508, "time": 30827.846484422684, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 976632, "time": 30831.351780176163, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 976912, "time": 30840.16354084015, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 977056, "time": 30844.628457307816, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 977112, "time": 30846.148977041245, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 977388, "time": 30854.967332839966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 977476, "time": 30857.44363617897, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 977788, "time": 30867.238985061646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 977940, "time": 30871.740818977356, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 977948, "time": 30872.209911823273, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 978544, "time": 30890.32632780075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 978544, "time": 30890.33274626732, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 978876, "time": 30900.595702409744, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 978944, "time": 30902.639870882034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 979076, "time": 30906.589537620544, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 979096, "time": 30907.095218658447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 979340, "time": 30915.06188893318, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 979548, "time": 30921.446241617203, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 979552, "time": 30921.466839551926, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 979620, "time": 30923.452938318253, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 979676, "time": 30925.42427587509, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 979876, "time": 30931.424557209015, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 979916, "time": 30932.883005857468, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 980052, "time": 30936.86921095848, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 980060, "time": 30939.04871582985, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 980060, "time": 30939.396679878235, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 980060, "time": 30940.75641489029, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 980060, "time": 30941.186791181564, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980060, "time": 30941.19283604622, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980060, "time": 30942.776317358017, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 980060, "time": 30942.91105890274, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980060, "time": 30943.533069610596, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 980276, "time": 30949.92671251297, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 980388, "time": 30953.343230724335, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 980752, "time": 30964.648402929306, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 980768, "time": 30965.141483545303, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 981016, "time": 30972.512044906616, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 981088, "time": 30974.948554754257, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 981116, "time": 30975.914005994797, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 981320, "time": 30981.83641219139, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 981344, "time": 30982.807458877563, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 981440, "time": 30985.811855316162, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 981584, "time": 30990.240962266922, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 981668, "time": 30992.741985797882, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 981688, "time": 30993.252506017685, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 981852, "time": 30998.61834025383, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 981940, "time": 31001.130950450897, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 981968, "time": 31002.098925113678, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 982356, "time": 31013.865303993225, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 982476, "time": 31017.752165079117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 982520, "time": 31018.790428876877, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 982544, "time": 31019.744730949402, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 982844, "time": 31029.052874326706, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 982876, "time": 31030.035655021667, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 983104, "time": 31036.937284708023, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 983216, "time": 31040.429677248, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 983432, "time": 31046.978633403778, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 983480, "time": 31048.45976948738, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 983636, "time": 31053.430733680725, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 983744, "time": 31056.849012374878, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 984132, "time": 31068.634449720383, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 984136, "time": 31068.65535736084, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 984412, "time": 31077.416490793228, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 984420, "time": 31077.451656341553, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 984424, "time": 31077.472549915314, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 984588, "time": 31082.931985139847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 984692, "time": 31085.89232993126, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 984812, "time": 31089.7869284153, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 984904, "time": 31092.268226623535, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 984960, "time": 31094.231105089188, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 984984, "time": 31094.758499622345, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 985156, "time": 31100.142300367355, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 985228, "time": 31102.58763742447, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 985384, "time": 31107.041298866272, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 985440, "time": 31108.984115600586, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 985828, "time": 31120.830374002457, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 985924, "time": 31123.773337602615, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 985968, "time": 31125.225214004517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986104, "time": 31129.206960201263, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 986116, "time": 31129.684955120087, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 986320, "time": 31136.065932512283, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 986332, "time": 31136.548715114594, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 986536, "time": 31142.634463071823, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 986552, "time": 31143.132391691208, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 986596, "time": 31144.594893455505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986636, "time": 31146.044903755188, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 987012, "time": 31157.403038740158, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 987016, "time": 31157.42255139351, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 987232, "time": 31164.243772506714, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 987508, "time": 31172.922607421875, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 987660, "time": 31177.86043572426, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 987792, "time": 31181.808237075806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 987820, "time": 31182.778512716293, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 987916, "time": 31185.71421480179, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 987988, "time": 31187.72707772255, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 988172, "time": 31193.58460521698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 988236, "time": 31195.55139374733, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 988252, "time": 31196.042903900146, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 988432, "time": 31201.52471089363, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 988484, "time": 31203.012335538864, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 988569, "time": 31206.462689638138, "train_stats/mean_log_entropy": 0.07191177141390928, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3350210525282664, "train/action_min": 0.0, "train/action_std": 1.4608433743817124, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008037852598401021, "train/actor_opt_grad_steps": 60690.0, "train/actor_opt_loss": -9.454760336995724, "train/adv_mag": 0.9274673785396557, "train/adv_max": 0.41987165194659976, "train/adv_mean": 0.004448843356625565, "train/adv_min": -0.8496345125850121, "train/adv_std": 0.024023592200635664, "train/cont_avg": 0.995097558103015, "train/cont_loss_mean": 0.017662181416011634, "train/cont_loss_std": 0.23905106058728007, "train/cont_neg_acc": 0.308365244549423, "train/cont_neg_loss": 2.8162422341027824, "train/cont_pos_acc": 0.9998865295295141, "train/cont_pos_loss": 0.003572498595028479, "train/cont_pred": 0.9951068887758494, "train/cont_rate": 0.995097558103015, "train/dyn_loss_mean": 1.000006227637056, "train/dyn_loss_std": 0.0001450965431666273, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10945538044836953, "train/extr_critic_critic_opt_grad_steps": 60690.0, "train/extr_critic_critic_opt_loss": 11792.781880594379, "train/extr_critic_mag": 1.400584552755308, "train/extr_critic_max": 1.400584552755308, "train/extr_critic_mean": 1.3281876411869298, "train/extr_critic_min": 0.8778758390464975, "train/extr_critic_std": 0.025388206753074825, "train/extr_return_normed_mag": 0.95453378243662, "train/extr_return_normed_max": 0.28421844489610376, "train/extr_return_normed_mean": 0.0512237893557878, "train/extr_return_normed_min": -0.8993310628823898, "train/extr_return_normed_std": 0.03502183207240536, "train/extr_return_rate": 0.9996208647387711, "train/extr_return_raw_mag": 1.5656310769181754, "train/extr_return_raw_max": 1.5656310769181754, "train/extr_return_raw_mean": 1.3326364899400491, "train/extr_return_raw_min": 0.3820815691396819, "train/extr_return_raw_std": 0.03502183211920549, "train/extr_reward_mag": 0.27229053530860786, "train/extr_reward_max": 0.27229053530860786, "train/extr_reward_mean": 0.0022199364646979087, "train/extr_reward_min": 2.9952082801703834e-07, "train/extr_reward_std": 0.00837242890186795, "train/image_loss_mean": 0.09221744277144796, "train/image_loss_std": 0.10412142583023963, "train/model_loss_mean": 0.7214825695483529, "train/model_loss_std": 0.4227111075616362, "train/model_opt_grad_norm": 16.534192369441794, "train/model_opt_grad_steps": 60636.43216080402, "train/model_opt_loss": 3662.2213153168186, "train/model_opt_model_opt_grad_overflow": 0.005025125628140704, "train/model_opt_model_opt_grad_scale": 5050.251256281407, "train/policy_entropy_mag": 1.1996557556804102, "train/policy_entropy_max": 1.1996557556804102, "train/policy_entropy_mean": 0.09030095817305935, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10716276144112774, "train/policy_logprob_mag": 6.551080243671359, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0904877632856369, "train/policy_logprob_min": -6.551080243671359, "train/policy_logprob_std": 0.6289447698760872, "train/policy_randomness_mag": 0.6165011408340991, "train/policy_randomness_max": 0.6165011408340991, "train/policy_randomness_mean": 0.046405514149959366, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05507076849889515, "train/post_ent_mag": 57.86009737714451, "train/post_ent_max": 57.86009737714451, "train/post_ent_mean": 51.067168671881134, "train/post_ent_min": 45.897356387957856, "train/post_ent_std": 2.5209271176975574, "train/prior_ent_mag": 57.266528086446634, "train/prior_ent_max": 57.266528086446634, "train/prior_ent_mean": 50.747826657702575, "train/prior_ent_min": 45.70927385109753, "train/prior_ent_std": 2.229172262714137, "train/rep_loss_mean": 1.000006227637056, "train/rep_loss_std": 0.0001450965431666273, "train/reward_avg": 0.0015278571808445105, "train/reward_loss_mean": 0.01159918355058186, "train/reward_loss_std": 0.19075478593954565, "train/reward_max_data": 0.7060301530750552, "train/reward_max_pred": 0.20635910369643015, "train/reward_neg_acc": 0.9997490878081202, "train/reward_neg_loss": 0.002150663469822132, "train/reward_pos_acc": 0.16960784434315992, "train/reward_pos_loss": 3.9929368400318737, "train/reward_pred": 0.001262214231941306, "train/reward_rate": 0.0023162688442211056, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.018762528896331787, "report/cont_loss_std": 0.23395267128944397, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.4100117683410645, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00466872425749898, "report/cont_pred": 0.9934910535812378, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07678251713514328, "report/image_loss_std": 0.0956362783908844, "report/model_loss_mean": 0.7061270475387573, "report/model_loss_std": 0.38600990176200867, "report/post_ent_mag": 58.977996826171875, "report/post_ent_max": 58.977996826171875, "report/post_ent_mean": 52.43672180175781, "report/post_ent_min": 47.39080047607422, "report/post_ent_std": 2.5457375049591064, "report/prior_ent_mag": 58.73039245605469, "report/prior_ent_max": 58.73039245605469, "report/prior_ent_mean": 51.230918884277344, "report/prior_ent_min": 45.81219482421875, "report/prior_ent_std": 2.429889678955078, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0012451171642169356, "report/reward_loss_mean": 0.010581960901618004, "report/reward_loss_std": 0.17834512889385223, "report/reward_max_data": 0.800000011920929, "report/reward_max_pred": 0.054491639137268066, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0027389703318476677, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.018350124359131, "report/reward_pred": 0.0015124711208045483, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.025047417730093002, "eval/cont_loss_std": 0.3528198003768921, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.679812431335449, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.008432045578956604, "eval/cont_pred": 0.9949274063110352, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1403934359550476, "eval/image_loss_std": 0.13689923286437988, "eval/model_loss_mean": 0.7777731418609619, "eval/model_loss_std": 0.5362424254417419, "eval/post_ent_mag": 59.771034240722656, "eval/post_ent_max": 59.771034240722656, "eval/post_ent_mean": 51.63780212402344, "eval/post_ent_min": 46.44855880737305, "eval/post_ent_std": 2.6632065773010254, "eval/prior_ent_mag": 58.81027603149414, "eval/prior_ent_max": 58.81027603149414, "eval/prior_ent_mean": 50.68048858642578, "eval/prior_ent_min": 45.700077056884766, "eval/prior_ent_std": 2.424647808074951, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0015624999068677425, "eval/reward_loss_mean": 0.012332247570157051, "eval/reward_loss_std": 0.22381359338760376, "eval/reward_max_data": 0.809374988079071, "eval/reward_max_pred": 0.42436516284942627, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.002567579271271825, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.002078056335449, "eval/reward_pred": 0.001171948853880167, "eval/reward_rate": 0.001953125, "replay/size": 988057.0, "replay/inserts": 31968.0, "replay/samples": 31968.0, "replay/insert_wait_avg": 1.6116224848352992e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.927820489213273e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4408.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.244503876258587e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.27299451828, "timer/env.step_count": 7992.0, "timer/env.step_total": 37.27058696746826, "timer/env.step_frac": 0.03726041507840302, "timer/env.step_avg": 0.004663486857791324, "timer/env.step_min": 0.0035614967346191406, "timer/env.step_max": 0.030296802520751953, "timer/replay._sample_count": 31968.0, "timer/replay._sample_total": 16.01278257369995, "timer/replay._sample_frac": 0.016008412364877975, "timer/replay._sample_avg": 0.0005009003557839074, "timer/replay._sample_min": 0.00040984153747558594, "timer/replay._sample_max": 0.009729385375976562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 9094.0, "timer/agent.policy_total": 83.45441102981567, "timer/agent.policy_frac": 0.08343163465090483, "timer/agent.policy_avg": 0.009176865079152812, "timer/agent.policy_min": 0.007979393005371094, "timer/agent.policy_max": 0.04535818099975586, "timer/dataset_train_count": 1998.0, "timer/dataset_train_total": 0.21772027015686035, "timer/dataset_train_frac": 0.0002176608499379831, "timer/dataset_train_avg": 0.00010896910418261279, "timer/dataset_train_min": 8.535385131835938e-05, "timer/dataset_train_max": 0.005464792251586914, "timer/agent.train_count": 1998.0, "timer/agent.train_total": 867.0886785984039, "timer/agent.train_frac": 0.8668520327453045, "timer/agent.train_avg": 0.43397831761681877, "timer/agent.train_min": 0.42410850524902344, "timer/agent.train_max": 0.5279946327209473, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4835631847381592, "timer/agent.report_frac": 0.0004834312106676814, "timer/agent.report_avg": 0.2417815923690796, "timer/agent.report_min": 0.23483991622924805, "timer/agent.report_max": 0.24872326850891113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.511543273925781e-05, "timer/dataset_eval_frac": 8.509220303428108e-08, "timer/dataset_eval_avg": 8.511543273925781e-05, "timer/dataset_eval_min": 8.511543273925781e-05, "timer/dataset_eval_max": 8.511543273925781e-05, "fps": 31.958676895628308}
{"step": 988664, "time": 31209.094395399094, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 988888, "time": 31215.945159196854, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 988936, "time": 31217.433181524277, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 989044, "time": 31220.83178114891, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 989088, "time": 31222.310117959976, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 989272, "time": 31227.711579799652, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 989328, "time": 31229.651163101196, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 989408, "time": 31232.181656599045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 989440, "time": 31233.163147687912, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 990060, "time": 31253.349834680557, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 990060, "time": 31253.790653705597, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 990060, "time": 31254.290733337402, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 990060, "time": 31254.60012793541, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 990060, "time": 31254.61905193329, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 990060, "time": 31255.743187189102, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 990060, "time": 31256.304044246674, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990060, "time": 31257.208299398422, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 990088, "time": 31257.738449573517, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 990196, "time": 31261.222052574158, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 990204, "time": 31261.69354915619, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 990212, "time": 31261.731021881104, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 990388, "time": 31267.122601747513, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 990472, "time": 31269.57499909401, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 990540, "time": 31272.00431251526, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 990636, "time": 31274.933115959167, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 990756, "time": 31278.42417860031, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 990864, "time": 31281.859449863434, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 990956, "time": 31284.79329586029, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 991012, "time": 31286.317769050598, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 991072, "time": 31288.259330272675, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 991252, "time": 31293.66989994049, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 991272, "time": 31294.176535844803, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 991272, "time": 31294.181699991226, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 991696, "time": 31307.578780174255, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 991772, "time": 31310.020550251007, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 991792, "time": 31310.551023721695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 991836, "time": 31312.00169444084, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 992180, "time": 31322.396468162537, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 992248, "time": 31324.369030952454, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 992764, "time": 31340.48200583458, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 992872, "time": 31343.46222925186, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 992916, "time": 31344.932022094727, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 992992, "time": 31347.367609739304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 993160, "time": 31352.38914012909, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 993296, "time": 31356.783777475357, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 993584, "time": 31365.591511964798, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 993652, "time": 31367.551430940628, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 994148, "time": 31382.730446338654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 994316, "time": 31388.08208680153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 994740, "time": 31400.82531261444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 994808, "time": 31402.792366981506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 994912, "time": 31406.236658334732, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 995000, "time": 31408.733939886093, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 995032, "time": 31409.71505188942, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 995284, "time": 31417.61466550827, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 995304, "time": 31418.13111972809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 995500, "time": 31424.471034765244, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 995568, "time": 31426.437563419342, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 995612, "time": 31428.060537338257, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 995764, "time": 31432.495038986206, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 995924, "time": 31437.392954349518, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 996188, "time": 31445.78562450409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 996404, "time": 31452.18241930008, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 996452, "time": 31453.66143488884, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 996548, "time": 31456.61845254898, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 996720, "time": 31462.011168956757, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 996724, "time": 31462.032715797424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 996744, "time": 31462.540974617004, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 996908, "time": 31467.872012853622, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 996976, "time": 31469.83421397209, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 997012, "time": 31470.829215049744, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 997172, "time": 31475.820295333862, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 997332, "time": 31480.728343248367, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 997372, "time": 31482.181792736053, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 997376, "time": 31482.20308804512, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 997412, "time": 31483.22103524208, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 997816, "time": 31495.488623857498, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 998172, "time": 31506.785794973373, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 998488, "time": 31516.1286277771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 998500, "time": 31516.607758522034, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 998544, "time": 31518.09854030609, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 998764, "time": 31524.904029369354, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 998924, "time": 31529.79698729515, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 999004, "time": 31532.31819486618, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 999088, "time": 31534.777963876724, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 999472, "time": 31546.528218507767, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 999700, "time": 31553.55757379532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999980, "time": 31562.40412545204, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1000060, "time": 31565.205145597458, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 1000060, "time": 31565.78916835785, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1000060, "time": 31565.88862967491, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1000060, "time": 31566.056460380554, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1000060, "time": 31566.30132126808, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1000060, "time": 31567.07625746727, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1000060, "time": 31567.22685289383, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1000060, "time": 31568.082163095474, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1000080, "time": 31568.585290670395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000224, "time": 31573.0103931427, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1000244, "time": 31573.52272748947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000324, "time": 31575.984361886978, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1000616, "time": 31584.787920475006, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1000832, "time": 31591.667993545532, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 1000860, "time": 31592.637964248657, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1000944, "time": 31595.12363433838, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1000952, "time": 31595.158786296844, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1001136, "time": 31601.01787519455, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1001388, "time": 31608.874294757843, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 1001424, "time": 31609.871025323868, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1001432, "time": 31609.90495991707, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1001744, "time": 31619.699682235718, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1001748, "time": 31619.720914125443, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1001772, "time": 31620.675366401672, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1001940, "time": 31625.693289279938, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1002144, "time": 31632.070075273514, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1002144, "time": 31632.075338602066, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1002208, "time": 31634.071492433548, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1002360, "time": 31638.534152030945, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1002536, "time": 31643.954701662064, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1002588, "time": 31645.88120985031, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1002624, "time": 31646.881717205048, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1002852, "time": 31653.839200496674, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1002988, "time": 31658.25196313858, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1003120, "time": 31662.174588918686, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1003212, "time": 31665.114597558975, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1003388, "time": 31670.501143217087, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1003656, "time": 31678.368411302567, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1003692, "time": 31679.80348777771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1003712, "time": 31680.310858488083, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1003896, "time": 31685.969428300858, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1003972, "time": 31688.421050786972, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1004320, "time": 31699.205218315125, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1004368, "time": 31700.679135799408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1004416, "time": 31702.16258096695, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1004800, "time": 31713.966470003128, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1004820, "time": 31714.480609178543, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1004912, "time": 31717.433687210083, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1005196, "time": 31726.246352672577, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1005228, "time": 31727.249103546143, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1005420, "time": 31733.121898174286, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1005440, "time": 31733.633453130722, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1005440, "time": 31733.639130353928, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1005540, "time": 31736.581300020218, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1005576, "time": 31737.59060573578, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1006128, "time": 31754.75199365616, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1006244, "time": 31758.206525087357, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1006432, "time": 31764.108345746994, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1006472, "time": 31765.11268401146, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1006544, "time": 31767.5586810112, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1006576, "time": 31768.546893835068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1006752, "time": 31773.956532239914, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1006808, "time": 31775.46619296074, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1006912, "time": 31778.888691663742, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1006968, "time": 31780.388495206833, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1007268, "time": 31789.691772699356, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1007284, "time": 31790.19053387642, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1007352, "time": 31792.17562365532, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1007356, "time": 31792.629494190216, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1007832, "time": 31806.922330379486, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1008068, "time": 31814.416575670242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1008452, "time": 31826.19455599785, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1008476, "time": 31827.14860033989, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 1008512, "time": 31828.1430644989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1008792, "time": 31836.645479679108, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1008808, "time": 31837.136261940002, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1008876, "time": 31839.528182268143, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1008988, "time": 31842.960428476334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1009244, "time": 31850.79766893387, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1009276, "time": 31851.771204948425, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1009380, "time": 31854.717437028885, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1009668, "time": 31863.614330530167, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1009668, "time": 31863.621239185333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1009760, "time": 31866.564591646194, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1009896, "time": 31870.51869750023, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1010060, "time": 31876.79962182045, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1010060, "time": 31877.208523750305, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1010060, "time": 31877.375478982925, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1010060, "time": 31878.08443927765, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1010060, "time": 31878.57498908043, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 1010060, "time": 31878.893406391144, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1010060, "time": 31879.264598846436, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1010060, "time": 31879.73643064499, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1010160, "time": 31882.668701648712, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1010268, "time": 31886.08401799202, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1010356, "time": 31888.55810523033, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 1010652, "time": 31897.846668958664, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1010812, "time": 31902.75056695938, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1010856, "time": 31903.800437688828, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 1010980, "time": 31907.718993902206, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1011084, "time": 31911.139868974686, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1011120, "time": 31912.132363557816, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1011176, "time": 31913.63251709938, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1011284, "time": 31917.058331489563, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1011384, "time": 31920.02914428711, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1011476, "time": 31922.98736357689, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1011612, "time": 31927.366461515427, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1011616, "time": 31927.387519598007, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1011916, "time": 31936.639983177185, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1011920, "time": 31936.661602020264, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1012084, "time": 31941.82003426552, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1012204, "time": 31945.71954536438, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1012252, "time": 31947.18697118759, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1012540, "time": 31956.082718610764, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1012540, "time": 31956.08864927292, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1012544, "time": 31956.110528469086, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1012748, "time": 31962.48486852646, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1012960, "time": 31968.903732061386, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1013220, "time": 31976.767466306686, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1013280, "time": 31978.722759008408, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1013320, "time": 31979.727219820023, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1013696, "time": 31991.45324611664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1013820, "time": 31995.34820008278, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1013972, "time": 31999.815172433853, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1014016, "time": 32001.26584482193, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1014112, "time": 32004.21366095543, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1014212, "time": 32007.151710271835, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1014276, "time": 32009.10057425499, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1014480, "time": 32015.495313167572, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1014536, "time": 32016.999648094177, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1014660, "time": 32020.878822803497, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1014732, "time": 32023.28385901451, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1014744, "time": 32023.33108472824, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1014976, "time": 32030.630869865417, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1014976, "time": 32030.63769030571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1015156, "time": 32036.039368629456, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1015300, "time": 32040.440348148346, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1015380, "time": 32042.958562374115, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1015436, "time": 32044.87948036194, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1015532, "time": 32047.8335146904, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1015888, "time": 32058.5885617733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1016048, "time": 32063.496252059937, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1016488, "time": 32076.918134450912, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1016488, "time": 32076.925188064575, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1016688, "time": 32083.2908744812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1016816, "time": 32087.219036340714, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1016820, "time": 32087.238850831985, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1017044, "time": 32094.111439466476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1017424, "time": 32105.944397211075, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1017464, "time": 32106.949362516403, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1017484, "time": 32107.891927957535, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1017668, "time": 32113.296550750732, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1017848, "time": 32118.678522348404, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1018200, "time": 32129.46179127693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018268, "time": 32131.92604470253, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1018620, "time": 32142.70562839508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018640, "time": 32143.220685005188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018688, "time": 32144.707983970642, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1019004, "time": 32154.52157354355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1019212, "time": 32160.89506149292, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1019248, "time": 32161.96236348152, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1019420, "time": 32167.34056162834, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1019524, "time": 32170.31814789772, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1019736, "time": 32176.696039676666, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1019832, "time": 32179.65721964836, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1019844, "time": 32180.140429735184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1019868, "time": 32181.090395212173, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
