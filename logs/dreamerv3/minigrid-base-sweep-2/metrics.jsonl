{"step": 1560, "time": 166.73693251609802, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 166.76128458976746, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 167.95151376724243, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 167.98380398750305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 167.98967719078064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 167.99724507331848, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 168.00476121902466, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 168.01156044006348, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 287.6627776622772, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8275146484375, "train/action_min": 0.0, "train/action_std": 2.114354133605957, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0003980385954491794, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.1733213663101196, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.7651342153549194, "train/cont_loss_std": 0.28553566336631775, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.4404296875, "train/cont_pos_loss": 0.7651342153549194, "train/cont_pred": 0.4835958480834961, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.586332321166992, "train/dyn_loss_std": 0.3709510564804077, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.104316234588623, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 25081.341796875, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 4694.1640625, "train/image_loss_std": 38.364501953125, "train/model_loss_mean": 4706.822265625, "train/model_loss_std": 38.33745574951172, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 47068224.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9425047636032104, "train/policy_entropy_max": 1.9425047636032104, "train/policy_entropy_mean": 1.7393710613250732, "train/policy_entropy_min": 1.0134804248809814, "train/policy_entropy_std": 0.11191672831773758, "train/policy_logprob_mag": 4.4042558670043945, "train/policy_logprob_max": -0.2955591380596161, "train/policy_logprob_mean": -1.741578459739685, "train/policy_logprob_min": -4.4042558670043945, "train/policy_logprob_std": 0.6194933652877808, "train/policy_randomness_mag": 0.9982500076293945, "train/policy_randomness_max": 0.9982500076293945, "train/policy_randomness_mean": 0.8938599824905396, "train/policy_randomness_min": 0.5208259224891663, "train/policy_randomness_std": 0.05751382187008858, "train/post_ent_mag": 105.79784393310547, "train/post_ent_max": 105.79784393310547, "train/post_ent_mean": 105.53977966308594, "train/post_ent_min": 105.23077392578125, "train/post_ent_std": 0.09880734235048294, "train/prior_ent_mag": 106.73025512695312, "train/prior_ent_max": 106.73025512695312, "train/prior_ent_mean": 105.59172821044922, "train/prior_ent_min": 104.78196716308594, "train/prior_ent_std": 0.3269680440425873, "train/rep_loss_mean": 10.586332321166992, "train/rep_loss_std": 0.3709510564804077, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.7833071947097778, "report/cont_loss_std": 0.27650412917137146, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.4033203125, "report/cont_pos_loss": 0.7833071947097778, "report/cont_pred": 0.473987877368927, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.558968544006348, "report/dyn_loss_std": 0.3934602737426758, "report/image_loss_mean": 4694.986328125, "report/image_loss_std": 39.666866302490234, "report/model_loss_mean": 4707.646484375, "report/model_loss_std": 39.647926330566406, "report/post_ent_mag": 105.83910369873047, "report/post_ent_max": 105.83910369873047, "report/post_ent_mean": 105.57254791259766, "report/post_ent_min": 105.29734802246094, "report/post_ent_std": 0.09061485528945923, "report/prior_ent_mag": 106.59532165527344, "report/prior_ent_max": 106.59532165527344, "report/prior_ent_mean": 105.61180877685547, "report/prior_ent_min": 104.38037109375, "report/prior_ent_std": 0.3070438504219055, "report/rep_loss_mean": 10.558968544006348, "report/rep_loss_std": 0.3934602737426758, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.7884132862091064, "eval/cont_loss_std": 0.2793652415275574, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.4033203125, "eval/cont_pos_loss": 0.7884132862091064, "eval/cont_pred": 0.4717293381690979, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 10.605881690979004, "eval/dyn_loss_std": 0.4045250415802002, "eval/image_loss_mean": 4698.45849609375, "eval/image_loss_std": 38.59494400024414, "eval/model_loss_mean": 4711.15234375, "eval/model_loss_std": 38.60401916503906, "eval/post_ent_mag": 105.85612487792969, "eval/post_ent_max": 105.85612487792969, "eval/post_ent_mean": 105.5518798828125, "eval/post_ent_min": 105.27615356445312, "eval/post_ent_std": 0.0970260426402092, "eval/prior_ent_mag": 106.5096206665039, "eval/prior_ent_max": 106.5096206665039, "eval/prior_ent_mean": 105.57290649414062, "eval/prior_ent_min": 104.67662811279297, "eval/prior_ent_std": 0.32564783096313477, "eval/rep_loss_mean": 10.605881690979004, "eval/rep_loss_std": 0.4045250415802002, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.5408110821596722e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.876328059605189e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.3430158202835048e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.706535611833845e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 147.1220452785492, "timer/env.step_count": 196.0, "timer/env.step_total": 1.3611814975738525, "timer/env.step_frac": 0.00925205665131082, "timer/env.step_avg": 0.006944803559050268, "timer/env.step_min": 0.006395101547241211, "timer/env.step_max": 0.016733884811401367, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.10085129737854004, "timer/replay._sample_frac": 0.0006854941228392809, "timer/replay._sample_avg": 0.0009004580123083932, "timer/replay._sample_min": 0.0003757476806640625, "timer/replay._sample_max": 0.013013362884521484, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.1273579597473145, "timer/agent.save_frac": 0.014459817736489074, "timer/agent.save_avg": 2.1273579597473145, "timer/agent.save_min": 2.1273579597473145, "timer/agent.save_max": 2.1273579597473145, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 22.381921529769897, "timer/agent.policy_frac": 0.1521316637992202, "timer/agent.policy_avg": 0.07717903975782724, "timer/agent.policy_min": 0.009361982345581055, "timer/agent.policy_max": 17.19659662246704, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.3855438232421875e-05, "timer/dataset_train_frac": 2.3011805041401292e-07, "timer/dataset_train_avg": 3.3855438232421875e-05, "timer/dataset_train_min": 3.3855438232421875e-05, "timer/dataset_train_max": 3.3855438232421875e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 92.49875664710999, "timer/agent.train_frac": 0.6287212529704858, "timer/agent.train_avg": 92.49875664710999, "timer/agent.train_min": 92.49875664710999, "timer/agent.train_max": 92.49875664710999, "timer/agent.report_count": 2.0, "timer/agent.report_total": 24.821059703826904, "timer/agent.report_frac": 0.1687106759346139, "timer/agent.report_avg": 12.410529851913452, "timer/agent.report_min": 0.24529242515563965, "timer/agent.report_max": 24.575767278671265, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.743171691894531e-05, "timer/dataset_eval_frac": 2.5442629517605653e-07, "timer/dataset_eval_avg": 3.743171691894531e-05, "timer/dataset_eval_min": 3.743171691894531e-05, "timer/dataset_eval_max": 3.743171691894531e-05}
{"step": 2312, "time": 310.6318745613098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 310.6390371322632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 310.64684224128723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 310.6531128883362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 310.66053581237793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 310.66655111312866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 310.67564821243286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 310.6824975013733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4264, "time": 371.144410610199, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 382.5797595977783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 382.5873680114746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 382.59578704833984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 382.60510182380676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 382.615327835083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 382.62542963027954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 382.63305473327637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6576, "time": 442.53523540496826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 453.3435654640198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 453.3549256324768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 453.4160189628601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 453.45567893981934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 453.46873927116394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 453.47528982162476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 453.4835705757141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8888, "time": 514.0165958404541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 525.23601770401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 525.2434918880463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 525.2520961761475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 525.2607402801514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 525.2698338031769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 525.2793514728546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 525.2883937358856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 556.5579466819763, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 556.6326220035553, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 556.6417851448059, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 556.6492211818695, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 556.6566777229309, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 556.6643857955933, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 556.6707918643951, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 556.6782341003418, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10424, "time": 567.0856955051422, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 11080, "time": 587.1894423961639, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 11200, "time": 591.2316951751709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 602.207225561142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 602.2152020931244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 602.2236340045929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 602.2324783802032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 602.2415409088135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 12736, "time": 638.4359345436096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13392, "time": 658.5690402984619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13512, "time": 662.037435054779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 673.2327637672424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 673.2400350570679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 673.2493622303009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 673.2600471973419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 673.2690989971161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15048, "time": 709.115311384201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15704, "time": 729.3301906585693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15824, "time": 733.2352340221405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 744.2067379951477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 744.2389574050903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 744.2663910388947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 744.2761707305908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 744.2876124382019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 17008, "time": 770.332471370697, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 18016, "time": 801.3263311386108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18136, "time": 804.8045423030853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 816.099531173706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 816.1075217723846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 816.1162004470825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 816.1342015266418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 816.144082069397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 19320, "time": 841.3472628593445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 867.1745374202728, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 20072, "time": 870.8991396427155, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 870.9061970710754, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 870.9139580726624, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 870.922351360321, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 870.9297122955322, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 870.9390292167664, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 870.9481589794159, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20288, "time": 877.7838246822357, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 20328, "time": 878.7847137451172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20448, "time": 882.683265209198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 893.6020579338074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 893.6111650466919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 893.6294069290161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 893.6454167366028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21632, "time": 919.2474327087402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22600, "time": 948.9775648117065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22640, "time": 950.5644533634186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22760, "time": 954.0421431064606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 965.3024017810822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 965.3106958866119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 965.3204145431519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 965.3316686153412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23944, "time": 990.6340501308441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24912, "time": 1021.3225588798523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24952, "time": 1022.3267006874084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25072, "time": 1026.297768354416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1037.1958763599396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1037.2077882289886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1037.2173981666565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1037.228630065918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26088, "time": 1057.402143239975, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 26256, "time": 1062.7602317333221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27224, "time": 1092.289407491684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27264, "time": 1093.7399055957794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27384, "time": 1097.1942479610443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1108.5468227863312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1108.5560557842255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1108.5653667449951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28400, "time": 1128.6252574920654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28568, "time": 1133.679092168808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29536, "time": 1163.9542260169983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29576, "time": 1165.0014517307281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29696, "time": 1168.9769246578217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1179.9339318275452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1179.964340686798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1179.973747253418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1185.9853327274323, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1185.9944958686829, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1186.0096759796143, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1186.0352582931519, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1186.0462052822113, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1186.0557975769043, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1186.0653145313263, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1186.0752050876617, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30712, "time": 1206.296058177948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30880, "time": 1211.6660788059235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31848, "time": 1241.2161118984222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31888, "time": 1242.656887769699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32008, "time": 1246.1243240833282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1257.4399464130402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1257.4974150657654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1257.5078661441803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32537, "time": 1263.415045261383, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.998297973000324, "train/action_min": 0.0, "train/action_std": 2.0010009886687286, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00013886094411127536, "train/actor_opt_grad_steps": 970.0, "train/actor_opt_loss": -2.0788372055834903, "train/adv_mag": 0.0003157959227797169, "train/adv_max": 0.00031576208144914087, "train/adv_mean": 0.00018787385744648675, "train/adv_min": 2.6647374353841502e-05, "train/adv_std": 8.7249634188174e-05, "train/cont_avg": 0.996903335492228, "train/cont_loss_mean": 0.025136697772653475, "train/cont_loss_std": 0.3037084656330574, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.781614169231436, "train/cont_pos_acc": 0.9970500626712265, "train/cont_pos_loss": 0.0072203647874368865, "train/cont_pred": 0.9941671503022544, "train/cont_rate": 0.996903335492228, "train/dyn_loss_mean": 1.0628355698264325, "train/dyn_loss_std": 0.004913852306007842, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.363565814464203, "train/extr_critic_critic_opt_grad_steps": 970.0, "train/extr_critic_critic_opt_loss": 5758.077717361055, "train/extr_critic_mag": 0.0011531089871658561, "train/extr_critic_max": 0.0011531028105187292, "train/extr_critic_mean": 0.0011485118602277957, "train/extr_critic_min": 0.0011459002223039537, "train/extr_critic_std": 7.387915006532869e-07, "train/extr_return_normed_mag": 0.00048408942772764247, "train/extr_return_normed_max": 0.0004840821396462525, "train/extr_return_normed_mean": 0.0003577400300931834, "train/extr_return_normed_min": 0.00019762250029109588, "train/extr_return_normed_std": 8.725126447189334e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0014627401520741893, "train/extr_return_raw_max": 0.0014627279523992012, "train/extr_return_raw_mean": 0.0013363859213565755, "train/extr_return_raw_min": 0.0011762683125999577, "train/extr_return_raw_std": 8.72512645520293e-05, "train/extr_reward_mag": 3.322418489604416e-05, "train/extr_reward_max": 3.3222949566618764e-05, "train/extr_reward_mean": 3.314404225371369e-05, "train/extr_reward_min": 3.291967619268388e-05, "train/extr_reward_std": 3.520641487035719e-08, "train/image_loss_mean": 25.396591218950835, "train/image_loss_std": 0.3625740518918927, "train/model_loss_mean": 26.16865244862947, "train/model_loss_std": 0.6351819986120407, "train/model_opt_grad_norm": 110.34941112995148, "train/model_opt_grad_steps": 960.0, "train/model_opt_loss": 498.1689979523575, "train/model_opt_model_opt_grad_overflow": 0.0051813471502590676, "train/model_opt_model_opt_grad_scale": 14.420741580310882, "train/policy_entropy_mag": 1.9457631469390553, "train/policy_entropy_max": 1.9457631469390553, "train/policy_entropy_mean": 1.9411014954660841, "train/policy_entropy_min": 1.8387003923944858, "train/policy_entropy_std": 0.0035829794673982603, "train/policy_logprob_mag": 2.512654369976854, "train/policy_logprob_max": -1.3919858472334907, "train/policy_logprob_mean": -1.9410345041690096, "train/policy_logprob_min": -2.512654369976854, "train/policy_logprob_std": 0.08526325194946842, "train/policy_randomness_mag": 0.9999245151954611, "train/policy_randomness_max": 0.9999245151954611, "train/policy_randomness_mean": 0.9975289019895959, "train/policy_randomness_min": 0.9449051386951782, "train/policy_randomness_std": 0.0018412873312985342, "train/post_ent_mag": 82.97379046029995, "train/post_ent_max": 82.97379046029995, "train/post_ent_mean": 82.92677702434322, "train/post_ent_min": 82.85017798231056, "train/post_ent_std": 0.017200443046794807, "train/prior_ent_mag": 88.11969602910966, "train/prior_ent_max": 88.11969602910966, "train/prior_ent_mean": 87.98809881655046, "train/prior_ent_min": 87.83155866237502, "train/prior_ent_std": 0.04444365470713593, "train/rep_loss_mean": 1.0628355698264325, "train/rep_loss_std": 0.004913852306007842, "train/reward_avg": 6.255312752487726e-05, "train/reward_loss_mean": 0.10922291722158307, "train/reward_loss_std": 0.05368856351846079, "train/reward_max_data": 0.06133419560953743, "train/reward_max_pred": 3.324024417857432e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.10748892361473128, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.807207338737719, "train/reward_pred": 3.312664755518727e-05, "train/reward_rate": 0.00017709682642487047, "train_stats/mean_log_entropy": 1.9286107708300864, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014229202643036842, "report/cont_loss_std": 0.26231899857521057, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.944031238555908, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002624893095344305, "report/cont_pred": 0.9973783493041992, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2728898227214813, "report/image_loss_std": 0.0849536880850792, "report/model_loss_mean": 0.8877389430999756, "report/model_loss_std": 0.2803066372871399, "report/post_ent_mag": 66.70120239257812, "report/post_ent_max": 66.70120239257812, "report/post_ent_mean": 66.50595092773438, "report/post_ent_min": 66.48223876953125, "report/post_ent_std": 0.02854623645544052, "report/prior_ent_mag": 76.1278076171875, "report/prior_ent_max": 76.1278076171875, "report/prior_ent_mean": 75.97932434082031, "report/prior_ent_min": 75.92908477783203, "report/prior_ent_std": 0.03030604124069214, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.000619916245341301, "report/reward_loss_std": 4.511101963089459e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 5.221366882324219e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000619916245341301, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.1971408538520336e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.002624883083626628, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002624883083626628, "eval/cont_pred": 0.997378408908844, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26539120078086853, "eval/image_loss_std": 0.08254612982273102, "eval/model_loss_mean": 0.8686360120773315, "eval/model_loss_std": 0.08254612982273102, "eval/post_ent_mag": 66.69879913330078, "eval/post_ent_max": 66.69879913330078, "eval/post_ent_mean": 66.50532531738281, "eval/post_ent_min": 66.48192596435547, "eval/post_ent_std": 0.026750199496746063, "eval/prior_ent_mag": 76.1456298828125, "eval/prior_ent_max": 76.1456298828125, "eval/prior_ent_mean": 75.97647857666016, "eval/prior_ent_min": 75.92288970947266, "eval/prior_ent_std": 0.03302584961056709, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0006199306808412075, "eval/reward_loss_std": 4.5023034545010887e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 5.233287811279297e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0006199306808412075, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.197315476834774e-05, "eval/reward_rate": 0.0, "replay/size": 32033.0, "replay/inserts": 30976.0, "replay/samples": 30976.0, "replay/insert_wait_avg": 1.3606622815132141e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.534763223868757e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2490163624905385e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 975.7424538135529, "timer/env.step_count": 3872.0, "timer/env.step_total": 39.50534129142761, "timer/env.step_frac": 0.04048746791433181, "timer/env.step_avg": 0.010202825746752998, "timer/env.step_min": 0.008429288864135742, "timer/env.step_max": 0.03675365447998047, "timer/replay._sample_count": 30976.0, "timer/replay._sample_total": 16.627986669540405, "timer/replay._sample_frac": 0.017041368451841208, "timer/replay._sample_avg": 0.000536802255602415, "timer/replay._sample_min": 0.0003426074981689453, "timer/replay._sample_max": 0.011878490447998047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4739.0, "timer/agent.policy_total": 52.49072861671448, "timer/agent.policy_frac": 0.053795679804196084, "timer/agent.policy_avg": 0.011076330157567942, "timer/agent.policy_min": 0.00929713249206543, "timer/agent.policy_max": 0.08835506439208984, "timer/dataset_train_count": 1936.0, "timer/dataset_train_total": 0.22295188903808594, "timer/dataset_train_frac": 0.0002284946075336885, "timer/dataset_train_avg": 0.00011516109970975513, "timer/dataset_train_min": 8.296966552734375e-05, "timer/dataset_train_max": 0.0005881786346435547, "timer/agent.train_count": 1936.0, "timer/agent.train_total": 868.3184819221497, "timer/agent.train_frac": 0.8899054033453688, "timer/agent.train_avg": 0.44851161256309385, "timer/agent.train_min": 0.436920166015625, "timer/agent.train_max": 0.6855518817901611, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4772460460662842, "timer/agent.report_frac": 0.0004891106707523433, "timer/agent.report_avg": 0.2386230230331421, "timer/agent.report_min": 0.23145651817321777, "timer/agent.report_max": 0.2457895278930664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.347537581177692e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 31.74559214892126}
{"step": 33024, "time": 1279.0694417953491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33192, "time": 1284.1172375679016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34160, "time": 1314.0582766532898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34200, "time": 1315.0914182662964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34320, "time": 1319.0037355422974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1330.00141954422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1330.0098314285278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1330.0215518474579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35336, "time": 1350.1685993671417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35504, "time": 1355.5639357566833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36472, "time": 1384.9977071285248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36512, "time": 1386.4380176067352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36632, "time": 1389.8859906196594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1401.5447688102722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1401.5517420768738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1401.558909893036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37648, "time": 1421.5335533618927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37816, "time": 1426.435965538025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38320, "time": 1442.136866569519, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 38784, "time": 1456.2819051742554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38824, "time": 1457.2829377651215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1472.1149809360504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1472.1224133968353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1472.1310772895813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39944, "time": 1491.7462182044983, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 39960, "time": 1492.259848833084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 1500.4705739021301, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.4781639575958, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.4856877326965, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.4961071014404, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.5032765865326, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.512395620346, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.5240650177002, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1500.5312821865082, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40128, "time": 1503.4506981372833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40632, "time": 1518.5964035987854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41096, "time": 1533.363897562027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41136, "time": 1534.8109605312347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1549.4548797607422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1549.4618241786957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42256, "time": 1569.0939235687256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42272, "time": 1569.5896496772766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42440, "time": 1574.5261664390564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42944, "time": 1590.2952346801758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43408, "time": 1604.4656522274017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43448, "time": 1605.4745540618896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1620.315951347351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1620.339908361435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44568, "time": 1639.8916153907776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44584, "time": 1640.4853324890137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44752, "time": 1645.854166507721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45256, "time": 1660.952464580536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45720, "time": 1675.2419998645782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45760, "time": 1676.6825323104858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1691.3512344360352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1691.3697535991669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46880, "time": 1710.9901976585388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46896, "time": 1711.4805381298065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47064, "time": 1716.3833503723145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47568, "time": 1732.1101982593536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48032, "time": 1746.3131756782532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48072, "time": 1747.3129694461823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1762.0621061325073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1762.06902217865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49192, "time": 1782.0078735351562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49208, "time": 1782.49746799469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49376, "time": 1787.8242094516754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49880, "time": 1803.1946377754211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 1813.24232339859, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1813.2489023208618, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1813.2547767162323, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1813.2606661319733, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1813.2687730789185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1813.2782430648804, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1813.2865588665009, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1813.2946667671204, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50344, "time": 1823.1587481498718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50384, "time": 1824.6325414180756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1839.2579762935638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1839.2668368816376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51504, "time": 1858.920244693756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51520, "time": 1859.4165589809418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51688, "time": 1864.3909101486206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52192, "time": 1879.9497590065002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52656, "time": 1894.2881155014038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52696, "time": 1895.294835805893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1910.0352082252502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1910.045719385147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53816, "time": 1929.7286360263824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53832, "time": 1930.2286643981934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54000, "time": 1935.6342153549194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54504, "time": 1950.9545147418976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54968, "time": 1965.0925657749176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55008, "time": 1966.5514650344849, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55480, "time": 1980.815199136734, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1981.2914912700653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1981.2995374202728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56128, "time": 2000.8945219516754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56144, "time": 2001.394026517868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56312, "time": 2006.2752120494843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56816, "time": 2021.7604751586914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57320, "time": 2036.9064197540283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57792, "time": 2052.0858561992645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2052.1164712905884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2052.1248948574066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58440, "time": 2071.830497980118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58456, "time": 2072.316248655319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58624, "time": 2077.6195542812347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59128, "time": 2092.8075087070465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59632, "time": 2108.2506124973297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 2121.5836956501007, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 60008, "time": 2125.702539920807, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2125.710832834244, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2125.7208001613617, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2125.7307999134064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2125.7392270565033, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2125.7488758563995, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2125.7572803497314, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60104, "time": 2128.664089679718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2129.152834177017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2129.1640808582306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60752, "time": 2148.6950459480286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60768, "time": 2149.1892473697662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60936, "time": 2154.2229504585266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61440, "time": 2169.8499596118927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61944, "time": 2185.026172876358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62416, "time": 2199.5003955364227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2199.5302040576935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2199.538563966751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63064, "time": 2219.1250636577606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63080, "time": 2219.619215488434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63248, "time": 2224.952821969986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63752, "time": 2240.0494611263275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64256, "time": 2255.6306989192963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64489, "time": 2263.477620601654, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9974325561523436, "train/action_min": 0.0, "train/action_std": 1.9996624457836152, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 8.528433680112358e-05, "train/actor_opt_grad_steps": 2935.0, "train/actor_opt_loss": -2.3131749202683567, "train/adv_mag": 0.00031347721349447963, "train/adv_max": 0.00031347721349447963, "train/adv_mean": 0.00017707803650409914, "train/adv_min": 8.420399390161037e-06, "train/adv_std": 8.261778830274125e-05, "train/cont_avg": 0.9966015625, "train/cont_loss_mean": 0.02280581042636186, "train/cont_loss_std": 0.3194404413620805, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.690133997631557, "train/cont_pos_acc": 0.9999999877810478, "train/cont_pos_loss": 0.0034771590324817227, "train/cont_pred": 0.996529158949852, "train/cont_rate": 0.9966015625, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08082394718192518, "train/extr_critic_critic_opt_grad_steps": 2935.0, "train/extr_critic_critic_opt_loss": 3862.7862158203125, "train/extr_critic_mag": 0.007881911396980286, "train/extr_critic_max": 0.007881911396980286, "train/extr_critic_mean": 0.007855742946267128, "train/extr_critic_min": 0.007839009165763855, "train/extr_critic_std": 5.59166347613882e-06, "train/extr_return_normed_mag": 0.0006128944223746657, "train/extr_return_normed_max": 0.0006128944223746657, "train/extr_return_normed_mean": 0.00048723780761065425, "train/extr_return_normed_min": 0.0003253930294886231, "train/extr_return_normed_std": 8.242932284701965e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.00815847436664626, "train/extr_return_raw_max": 0.00815847436664626, "train/extr_return_raw_mean": 0.008032818164210767, "train/extr_return_raw_min": 0.007870972973760217, "train/extr_return_raw_std": 8.242932281063987e-05, "train/extr_reward_mag": 5.1639676094055176e-05, "train/extr_reward_max": 5.1639676094055176e-05, "train/extr_reward_mean": 5.159262886081706e-05, "train/extr_reward_min": 5.1530003547668455e-05, "train/extr_reward_std": 1.8694976192668022e-08, "train/image_loss_mean": 0.2680722114443779, "train/image_loss_std": 0.08593073654919862, "train/model_loss_mean": 0.8927690887451172, "train/model_loss_std": 0.36677137922495606, "train/model_opt_grad_norm": 86.05810651779174, "train/model_opt_grad_steps": 2925.0, "train/model_opt_loss": 50.15914306640625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 56.25, "train/policy_entropy_mag": 1.9458897471427918, "train/policy_entropy_max": 1.9458897471427918, "train/policy_entropy_mean": 1.9448920518159867, "train/policy_entropy_min": 1.9183827120065688, "train/policy_entropy_std": 0.0008273066981928423, "train/policy_logprob_mag": 2.2525013840198516, "train/policy_logprob_max": -1.6345290702581405, "train/policy_logprob_mean": -1.944905942082405, "train/policy_logprob_min": -2.2525013840198516, "train/policy_logprob_std": 0.04484540453180671, "train/policy_randomness_mag": 0.9999895748496056, "train/policy_randomness_max": 0.9999895748496056, "train/policy_randomness_mean": 0.9994768592715263, "train/policy_randomness_min": 0.9858537542819977, "train/policy_randomness_std": 0.00042515157081652433, "train/post_ent_mag": 55.44766485214233, "train/post_ent_max": 55.44766485214233, "train/post_ent_mean": 55.248623600006106, "train/post_ent_min": 55.221216411590575, "train/post_ent_std": 0.02922819757834077, "train/prior_ent_mag": 63.336242485046384, "train/prior_ent_max": 63.336242485046384, "train/prior_ent_mean": 63.104204158782956, "train/prior_ent_min": 63.043454532623294, "train/prior_ent_std": 0.052045583883300425, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 7.360839779721573e-05, "train/reward_loss_mean": 0.001891043654177338, "train/reward_loss_std": 0.04470664009077715, "train/reward_max_data": 0.06631249964237212, "train/reward_max_pred": 5.1676034927368165e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00034568225557450203, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.190235908214863, "train/reward_pred": 5.160406115464866e-05, "train/reward_rate": 0.0001513671875, "train_stats/mean_log_entropy": 1.937830563025041, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020015105605125427, "report/cont_loss_std": 0.3166830241680145, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.862224102020264, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002848963951691985, "report/cont_pred": 0.9971551299095154, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.26442772150039673, "report/image_loss_std": 0.08984760195016861, "report/model_loss_mean": 0.8846674561500549, "report/model_loss_std": 0.33096903562545776, "report/post_ent_mag": 46.10298538208008, "report/post_ent_max": 46.10298538208008, "report/post_ent_mean": 45.93965148925781, "report/post_ent_min": 45.910377502441406, "report/post_ent_std": 0.023286964744329453, "report/prior_ent_mag": 55.70112991333008, "report/prior_ent_max": 55.70112991333008, "report/prior_ent_mean": 55.512779235839844, "report/prior_ent_min": 55.4648551940918, "report/prior_ent_std": 0.04255116730928421, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00022459030151367188, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 5.3048133850097656e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00022459030151367188, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.3048133850097656e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.002848963951691985, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002848963951691985, "eval/cont_pred": 0.9971551299095154, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.28786635398864746, "eval/image_loss_std": 0.09667656570672989, "eval/model_loss_mean": 0.8909399509429932, "eval/model_loss_std": 0.09667656570672989, "eval/post_ent_mag": 46.10298538208008, "eval/post_ent_max": 46.10298538208008, "eval/post_ent_mean": 45.93877410888672, "eval/post_ent_min": 45.90838623046875, "eval/post_ent_std": 0.021523961797356606, "eval/prior_ent_mag": 55.723121643066406, "eval/prior_ent_max": 55.723121643066406, "eval/prior_ent_mean": 55.51133346557617, "eval/prior_ent_min": 55.45995330810547, "eval/prior_ent_std": 0.040283381938934326, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00022459030151367188, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 5.3048133850097656e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00022459030151367188, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.3048133850097656e-05, "eval/reward_rate": 0.0, "replay/size": 63985.0, "replay/inserts": 31952.0, "replay/samples": 31952.0, "replay/insert_wait_avg": 1.3745854840495912e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.602976858705416e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1736683917018095e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0485932826996, "timer/env.step_count": 3994.0, "timer/env.step_total": 40.504329442977905, "timer/env.step_frac": 0.04050236130028524, "timer/env.step_avg": 0.010141294302197772, "timer/env.step_min": 0.008423089981079102, "timer/env.step_max": 0.03654766082763672, "timer/replay._sample_count": 31952.0, "timer/replay._sample_total": 17.42908000946045, "timer/replay._sample_frac": 0.017428233114401767, "timer/replay._sample_avg": 0.0005454769657442554, "timer/replay._sample_min": 0.0003554821014404297, "timer/replay._sample_max": 0.028524398803710938, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4861.0, "timer/agent.policy_total": 52.98423194885254, "timer/agent.policy_frac": 0.05298165739619679, "timer/agent.policy_avg": 0.010899862569194103, "timer/agent.policy_min": 0.008664369583129883, "timer/agent.policy_max": 0.08473658561706543, "timer/dataset_train_count": 1997.0, "timer/dataset_train_total": 0.2207801342010498, "timer/dataset_train_frac": 0.0002207694062908785, "timer/dataset_train_avg": 0.00011055590095195283, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0006818771362304688, "timer/agent.train_count": 1997.0, "timer/agent.train_total": 891.6400516033173, "timer/agent.train_frac": 0.8915967259915571, "timer/agent.train_avg": 0.44648976044232214, "timer/agent.train_min": 0.43451499938964844, "timer/agent.train_max": 0.8405742645263672, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4776327610015869, "timer/agent.report_frac": 0.00047760955238558783, "timer/agent.report_avg": 0.23881638050079346, "timer/agent.report_min": 0.23199796676635742, "timer/agent.report_max": 0.2456347942352295, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051609524775674e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 31.949914668848514}
{"step": 64728, "time": 2270.6426117420197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2271.112552165985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2271.1240723133087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65376, "time": 2290.5469205379486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65392, "time": 2291.0575687885284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65560, "time": 2296.414567708969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66064, "time": 2312.0635941028595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66568, "time": 2327.1756587028503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67040, "time": 2341.870272397995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2341.89973115921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2341.909398317337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67688, "time": 2361.4104714393616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67704, "time": 2361.8994143009186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67872, "time": 2367.2032449245453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68376, "time": 2382.288577079773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68880, "time": 2397.916685819626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69352, "time": 2412.0496833324432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69360, "time": 2412.518615961075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69360, "time": 2412.527528524399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70000, "time": 2432.2223222255707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70016, "time": 2432.7123436927795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 2440.637554168701, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2440.646935939789, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2440.656350135803, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2440.6666774749756, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2440.6771669387817, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2440.6862790584564, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2440.695505619049, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2440.7061896324158, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70184, "time": 2443.1583998203278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70688, "time": 2458.8551836013794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71192, "time": 2473.953428030014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71664, "time": 2488.597002029419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 2488.6282839775085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 2488.6383244991302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72312, "time": 2507.9942309856415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72328, "time": 2508.490526676178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72496, "time": 2513.896903038025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73000, "time": 2528.999746322632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73504, "time": 2544.6243052482605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73976, "time": 2559.198869228363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73984, "time": 2559.6702427864075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73984, "time": 2559.6785769462585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74624, "time": 2579.394566297531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74640, "time": 2579.888003587723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74808, "time": 2584.7847847938538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75312, "time": 2600.387213945389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75816, "time": 2615.551253557205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76288, "time": 2630.1167454719543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76296, "time": 2630.1492404937744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76296, "time": 2630.1566803455353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76432, "time": 2634.62757897377, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 76792, "time": 2645.404891014099, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 76936, "time": 2649.796240091324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76952, "time": 2650.2867307662964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77120, "time": 2655.632264137268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77624, "time": 2670.812679052353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78600, "time": 2700.5561542510986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78608, "time": 2701.0272057056427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78744, "time": 2704.943642139435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79104, "time": 2716.07755446434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79248, "time": 2720.5909476280212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79264, "time": 2721.080860376358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79432, "time": 2725.971309185028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79936, "time": 2741.5195755958557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80064, "time": 2745.3923304080963, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 2751.3453521728516, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2751.359534263611, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2751.3666574954987, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2751.37247133255, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2751.3776586055756, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2751.3838229179382, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2751.3891184329987, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2751.394740343094, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80912, "time": 2776.6673650741577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81056, "time": 2781.1123428344727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81416, "time": 2791.8294203281403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81560, "time": 2796.1929252147675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81576, "time": 2796.6824564933777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81744, "time": 2802.0101068019867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82248, "time": 2817.671152830124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82376, "time": 2821.5465762615204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83224, "time": 2847.416543006897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83368, "time": 2851.769294023514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83728, "time": 2863.4767487049103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83872, "time": 2867.847011089325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83888, "time": 2868.3360521793365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84056, "time": 2873.316609621048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84560, "time": 2888.8711450099945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84688, "time": 2892.8162121772766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85536, "time": 2918.6712799072266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85680, "time": 2923.043966770172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86040, "time": 2933.9174258708954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86184, "time": 2938.269905090332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86200, "time": 2938.7821276187897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86368, "time": 2944.095747232437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86872, "time": 2959.232650279999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87000, "time": 2963.2331671714783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87848, "time": 2989.162333250046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87992, "time": 2993.6441724300385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88352, "time": 3004.8139429092407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88496, "time": 3009.1880345344543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88512, "time": 3009.6801614761353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88680, "time": 3014.5834176540375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89184, "time": 3030.16748547554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89312, "time": 3034.070746898651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 3063.2785093784332, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3063.2878634929657, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3063.331066131592, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3063.341346502304, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3063.3499977588654, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3063.3575150966644, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3063.3665816783905, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3063.378057718277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90160, "time": 3066.848274707794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90304, "time": 3071.2080912590027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90664, "time": 3082.0840270519257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90808, "time": 3086.4402260780334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90824, "time": 3086.9315910339355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90992, "time": 3092.2687306404114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91496, "time": 3107.3503124713898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91624, "time": 3111.310608625412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92472, "time": 3137.061171770096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92616, "time": 3141.5786414146423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92976, "time": 3152.722898006439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93120, "time": 3157.0890924930573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93136, "time": 3157.579909324646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93304, "time": 3162.5137434005737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93808, "time": 3178.1866748332977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93936, "time": 3182.080258369446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94784, "time": 3208.000305891037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94928, "time": 3212.383819580078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95288, "time": 3223.103910923004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95432, "time": 3227.4980731010437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95448, "time": 3227.9942107200623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95616, "time": 3233.484262228012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96120, "time": 3248.598288297653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96248, "time": 3252.4891352653503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96448, "time": 3258.7771124839783, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 96585, "time": 3263.7889156341553, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0005556932136193, "train/action_min": 0.0, "train/action_std": 1.999282816156226, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.638593292105752e-05, "train/actor_opt_grad_steps": 4940.0, "train/actor_opt_loss": -3.9405597545280684, "train/adv_mag": 0.00019278575142669442, "train/adv_max": 0.0001883058998715225, "train/adv_mean": 9.184851922586982e-05, "train/adv_min": -2.7895395398436496e-05, "train/adv_std": 4.782614187330924e-05, "train/cont_avg": 0.9963901197139303, "train/cont_loss_mean": 0.023973102894477287, "train/cont_loss_std": 0.32877085888549795, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.677298478405885, "train/cont_pos_acc": 0.999999986952217, "train/cont_pos_loss": 0.0034927528853115823, "train/cont_pred": 0.9965135552989903, "train/cont_rate": 0.9963901197139303, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.022224811568337294, "train/extr_critic_critic_opt_grad_steps": 4940.0, "train/extr_critic_critic_opt_loss": 5557.36669436023, "train/extr_critic_mag": 0.01311278876973622, "train/extr_critic_max": 0.01311278876973622, "train/extr_critic_mean": 0.013069555154116593, "train/extr_critic_min": 0.0130453501174699, "train/extr_critic_std": 9.818866121080628e-06, "train/extr_return_normed_mag": 0.0003526880271473334, "train/extr_return_normed_max": 0.0003513872150832148, "train/extr_return_normed_mean": 0.0002731690468437899, "train/extr_return_normed_min": 0.00017616510002025918, "train/extr_return_normed_std": 4.573468461093222e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.013239624891522809, "train/extr_return_raw_max": 0.013239624891522809, "train/extr_return_raw_mean": 0.01316140746391976, "train/extr_return_raw_min": 0.013064402776459852, "train/extr_return_raw_std": 4.5734684286274284e-05, "train/extr_reward_mag": 5.382981466416696e-05, "train/extr_reward_max": 5.382981466416696e-05, "train/extr_reward_mean": 5.379056952435023e-05, "train/extr_reward_min": 5.373551477840291e-05, "train/extr_reward_std": 1.8091382843993448e-08, "train/image_loss_mean": 0.260048454599594, "train/image_loss_std": 0.08504610208433065, "train/model_loss_mean": 0.8855622846688798, "train/model_loss_std": 0.3734709888474265, "train/model_opt_grad_norm": 70.61602668382635, "train/model_opt_grad_steps": 4930.0, "train/model_opt_loss": 199.56970097176472, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 225.43532338308458, "train/policy_entropy_mag": 1.945899568980013, "train/policy_entropy_max": 1.945899568980013, "train/policy_entropy_mean": 1.9453426142830161, "train/policy_entropy_min": 1.932453921778285, "train/policy_entropy_std": 0.0004454722708503516, "train/policy_logprob_mag": 2.145824976821444, "train/policy_logprob_max": -1.7290085743908858, "train/policy_logprob_mean": -1.945319232655995, "train/policy_logprob_min": -2.145824976821444, "train/policy_logprob_std": 0.033590909232621764, "train/policy_randomness_mag": 0.9999946240168899, "train/policy_randomness_max": 0.9999946240168899, "train/policy_randomness_mean": 0.9997083974714897, "train/policy_randomness_min": 0.9930849253241696, "train/policy_randomness_std": 0.0002289274728431862, "train/post_ent_mag": 41.16529563410365, "train/post_ent_max": 41.16529563410365, "train/post_ent_mean": 41.05387878417969, "train/post_ent_min": 41.00368306174207, "train/post_ent_std": 0.021713554947196845, "train/prior_ent_mag": 50.00737449304381, "train/prior_ent_max": 50.00737449304381, "train/prior_ent_mean": 49.91684626109564, "train/prior_ent_min": 49.82728787322542, "train/prior_ent_std": 0.02662489537279404, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 6.458794829014003e-05, "train/reward_loss_mean": 0.0015407079501791082, "train/reward_loss_std": 0.0434259132825863, "train/reward_max_data": 0.06613805904910339, "train/reward_max_pred": 5.390276363239953e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001829885256497551, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.350225837142379, "train/reward_pred": 5.382979960546861e-05, "train/reward_rate": 0.00013118003731343284, "train_stats/mean_log_entropy": 1.9370109734327896, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0144851915538311, "report/cont_loss_std": 0.251281201839447, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.694775581359863, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003369161393493414, "report/cont_pred": 0.9966364502906799, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.28568315505981445, "report/image_loss_std": 0.07082764059305191, "report/model_loss_mean": 0.9003084897994995, "report/model_loss_std": 0.262416273355484, "report/post_ent_mag": 37.71526336669922, "report/post_ent_max": 37.71526336669922, "report/post_ent_mean": 37.691261291503906, "report/post_ent_min": 37.58974838256836, "report/post_ent_std": 0.02220851741731167, "report/prior_ent_mag": 45.44863510131836, "report/prior_ent_max": 45.44863510131836, "report/prior_ent_mean": 45.332183837890625, "report/prior_ent_min": 45.29554748535156, "report/prior_ent_std": 0.022152744233608246, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00014019012451171875, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.9696693420410156e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00014019012451171875, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.9696693420410156e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003369161393493414, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003369161393493414, "eval/cont_pred": 0.9966364502906799, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26736825704574585, "eval/image_loss_std": 0.06880949437618256, "eval/model_loss_mean": 0.8708776235580444, "eval/model_loss_std": 0.06880950927734375, "eval/post_ent_mag": 37.719451904296875, "eval/post_ent_max": 37.719451904296875, "eval/post_ent_mean": 37.69202423095703, "eval/post_ent_min": 37.5983772277832, "eval/post_ent_std": 0.021283946931362152, "eval/prior_ent_mag": 45.43452453613281, "eval/prior_ent_max": 45.43452453613281, "eval/prior_ent_mean": 45.332008361816406, "eval/prior_ent_min": 45.29888916015625, "eval/prior_ent_std": 0.022740930318832397, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00014019012451171875, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.9696693420410156e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00014019012451171875, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.9696693420410156e-05, "eval/reward_rate": 0.0, "replay/size": 96081.0, "replay/inserts": 32096.0, "replay/samples": 32096.0, "replay/insert_wait_avg": 1.3243314157335732e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.55197400181505e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1578563175399412e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2949962615967, "timer/env.step_count": 4012.0, "timer/env.step_total": 40.2643678188324, "timer/env.step_frac": 0.040252493483734754, "timer/env.step_avg": 0.0100359840027, "timer/env.step_min": 0.008288383483886719, "timer/env.step_max": 0.06870365142822266, "timer/replay._sample_count": 32096.0, "timer/replay._sample_total": 17.146829843521118, "timer/replay._sample_frac": 0.017141773084544037, "timer/replay._sample_avg": 0.0005342357254337338, "timer/replay._sample_min": 0.0003528594970703125, "timer/replay._sample_max": 0.028650283813476562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4879.0, "timer/agent.policy_total": 52.369243144989014, "timer/agent.policy_frac": 0.05235379897001247, "timer/agent.policy_avg": 0.010733601792373235, "timer/agent.policy_min": 0.009047746658325195, "timer/agent.policy_max": 0.09908795356750488, "timer/dataset_train_count": 2006.0, "timer/dataset_train_total": 0.2209923267364502, "timer/dataset_train_frac": 0.00022092715405191968, "timer/dataset_train_avg": 0.00011016566636911775, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0005793571472167969, "timer/agent.train_count": 2006.0, "timer/agent.train_total": 893.2128887176514, "timer/agent.train_frac": 0.892949471961628, "timer/agent.train_avg": 0.4452706324614414, "timer/agent.train_min": 0.43462634086608887, "timer/agent.train_max": 0.9569594860076904, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47889161109924316, "timer/agent.report_frac": 0.00047875038152645486, "timer/agent.report_avg": 0.23944580554962158, "timer/agent.report_min": 0.2313985824584961, "timer/agent.report_max": 0.24749302864074707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.217701607925822e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 32.0860172748397}
{"step": 97096, "time": 3279.219096660614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97240, "time": 3283.6763157844543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97600, "time": 3295.0111014842987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97744, "time": 3299.39599108696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97760, "time": 3299.888261079788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97928, "time": 3304.759378671646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98432, "time": 3320.918310403824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98760, "time": 3330.6835329532623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99408, "time": 3350.679467201233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99552, "time": 3355.0654051303864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99912, "time": 3365.812164783478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 3373.1605315208435, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 100048, "time": 3376.3642840385437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.3720479011536, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.379669189453, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.4354660511017, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.4450001716614, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.454794406891, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3376.4644203186035, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100056, "time": 3376.495892763138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100072, "time": 3376.9883584976196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100240, "time": 3382.464129447937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100744, "time": 3397.6868970394135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101072, "time": 3407.86421251297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101720, "time": 3427.4376499652863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101864, "time": 3431.810412168503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102224, "time": 3443.0707788467407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102368, "time": 3447.451395750046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102384, "time": 3447.944444179535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102552, "time": 3452.8398847579956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103056, "time": 3468.5179374217987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103384, "time": 3478.5003876686096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104032, "time": 3498.4258506298065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104176, "time": 3502.931885957718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104536, "time": 3513.6480741500854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104680, "time": 3518.031852245331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104696, "time": 3518.5242614746094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104864, "time": 3523.8699226379395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105368, "time": 3539.142266511917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105696, "time": 3549.3022611141205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106344, "time": 3568.9351868629456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106488, "time": 3573.3120346069336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106848, "time": 3585.0447447299957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106992, "time": 3589.4203627109528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107008, "time": 3589.9134182929993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107176, "time": 3594.9032702445984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107680, "time": 3610.441619157791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108008, "time": 3620.1878402233124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108448, "time": 3633.8982796669006, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 108656, "time": 3640.2064044475555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108800, "time": 3644.5865755081177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109160, "time": 3655.4070677757263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109304, "time": 3659.8027861118317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109320, "time": 3660.2968323230743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109856, "time": 3676.7768499851227, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 109992, "time": 3680.811843395233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 3687.421040058136, "eval_episode/length": 273.0, "eval_episode/score": 0.14687499403953552, "eval_episode/reward_rate": 0.0036496350364963502}
{"step": 110032, "time": 3687.726264476776, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3687.7338740825653, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3687.7416756153107, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3687.7514815330505, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3687.760008096695, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3687.768294811249, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3687.800183534622, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110320, "time": 3696.522920846939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110760, "time": 3709.741396665573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111112, "time": 3720.5084993839264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111472, "time": 3731.723539352417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111616, "time": 3736.0776510238647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111632, "time": 3736.5850994586945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112168, "time": 3752.7997517585754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112304, "time": 3757.1818373203278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112632, "time": 3766.956669330597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113072, "time": 3780.666172504425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113424, "time": 3791.3328347206116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113784, "time": 3802.126651287079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113928, "time": 3806.5043828487396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113944, "time": 3806.998946905136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114480, "time": 3823.491024017334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114616, "time": 3827.402728319168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114944, "time": 3838.235358476639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115384, "time": 3851.392156600952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115512, "time": 3855.3357062339783, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 115736, "time": 3862.2541999816895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115760, "time": 3863.204206943512, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 116240, "time": 3877.82329082489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116256, "time": 3878.317712545395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116792, "time": 3894.5247559547424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116928, "time": 3898.874423980713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117696, "time": 3922.25745511055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117824, "time": 3926.1666629314423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118048, "time": 3932.9796278476715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118072, "time": 3933.4911227226257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118552, "time": 3948.0777254104614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118568, "time": 3948.573185443878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118624, "time": 3950.6523582935333, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 119104, "time": 3965.3551573753357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119240, "time": 3969.2770121097565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120008, "time": 3992.7814598083496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 3998.8422067165375, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3998.8481566905975, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3998.855638027191, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3998.862105846405, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3998.871479034424, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3998.8790543079376, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3998.88600230217, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3998.8936405181885, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120136, "time": 4002.35213470459, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120360, "time": 4009.13586974144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120864, "time": 4024.898815393448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120880, "time": 4025.402456521988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120936, "time": 4026.9161138534546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121416, "time": 4041.7543227672577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121552, "time": 4046.1327266693115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122320, "time": 4069.509310722351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122448, "time": 4073.5379750728607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122672, "time": 4080.3417689800262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123176, "time": 4096.049264669418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123192, "time": 4096.544980049133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123248, "time": 4098.477526187897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123728, "time": 4113.1664798259735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123864, "time": 4117.0912663936615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124632, "time": 4140.498326539993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124760, "time": 4144.387382030487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124984, "time": 4151.177362918854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125488, "time": 4166.878217697144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125504, "time": 4167.3737626075745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125560, "time": 4168.894650936127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126040, "time": 4183.502573013306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126176, "time": 4187.8528118133545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126944, "time": 4211.294016122818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127072, "time": 4215.193932533264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127296, "time": 4222.096627235413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127800, "time": 4237.335442066193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127816, "time": 4237.826846599579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127872, "time": 4239.741559743881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128352, "time": 4254.436790943146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128488, "time": 4258.353742599487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128649, "time": 4264.213468313217, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000594482421875, "train/action_min": 0.0, "train/action_std": 2.0000533092021944, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 3.9964029815564574e-05, "train/actor_opt_grad_steps": 6945.0, "train/actor_opt_loss": -4.4046282581985, "train/adv_mag": 0.0001865725964307785, "train/adv_max": 0.00016843643505126237, "train/adv_mean": 6.75090525884059e-05, "train/adv_min": -5.435749422758818e-05, "train/adv_std": 4.483021319799718e-05, "train/cont_avg": 0.9961376953125, "train/cont_loss_mean": 0.025360654165269808, "train/cont_loss_std": 0.34306262381840497, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.686501893130216, "train/cont_pos_acc": 0.9999999842047691, "train/cont_pos_loss": 0.003442681593587622, "train/cont_pred": 0.996563375890255, "train/cont_rate": 0.9961376953125, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0121423932723701, "train/extr_critic_critic_opt_grad_steps": 6945.0, "train/extr_critic_critic_opt_loss": 6338.721701660156, "train/extr_critic_mag": 0.01591186463832855, "train/extr_critic_max": 0.01591186463832855, "train/extr_critic_mean": 0.015863596596755087, "train/extr_critic_min": 0.015833428502082823, "train/extr_critic_std": 1.1810910749678883e-05, "train/extr_return_normed_mag": 0.00029722430277615784, "train/extr_return_normed_max": 0.0002817284828051925, "train/extr_return_normed_mean": 0.0002072033078705715, "train/extr_return_normed_min": 0.0001153141399845481, "train/extr_return_normed_std": 4.15047718463768e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.016005610711872578, "train/extr_return_raw_max": 0.016005610711872578, "train/extr_return_raw_mean": 0.015931086386553942, "train/extr_return_raw_min": 0.015839196369051935, "train/extr_return_raw_std": 4.150477170519196e-05, "train/extr_reward_mag": 5.8383941650390624e-05, "train/extr_reward_max": 5.8383941650390624e-05, "train/extr_reward_mean": 5.833804337271431e-05, "train/extr_reward_min": 5.827903747558594e-05, "train/extr_reward_std": 2.1521644739119773e-08, "train/image_loss_mean": 0.256410596743226, "train/image_loss_std": 0.08418478280305862, "train/model_loss_mean": 0.8835047060251235, "train/model_loss_std": 0.38949372962117196, "train/model_opt_grad_norm": 59.707602729797365, "train/model_opt_grad_steps": 6935.0, "train/model_opt_loss": 799.4470762634278, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 904.6875, "train/policy_entropy_mag": 1.945902281999588, "train/policy_entropy_max": 1.945902281999588, "train/policy_entropy_mean": 1.945487111210823, "train/policy_entropy_min": 1.9374967235326768, "train/policy_entropy_std": 0.00031476488220505416, "train/policy_logprob_mag": 2.1009999120235445, "train/policy_logprob_max": -1.7708021688461304, "train/policy_logprob_mean": -1.945465418100357, "train/policy_logprob_min": -2.1009999120235445, "train/policy_logprob_std": 0.02905942527577281, "train/policy_randomness_mag": 0.9999960163235664, "train/policy_randomness_max": 0.9999960163235664, "train/policy_randomness_mean": 0.9997826564311981, "train/policy_randomness_min": 0.9956764110922813, "train/policy_randomness_std": 0.00016175715791177936, "train/post_ent_mag": 37.816859283447265, "train/post_ent_max": 37.816859283447265, "train/post_ent_mean": 37.78118543624878, "train/post_ent_min": 37.56659021377563, "train/post_ent_std": 0.05111899606883526, "train/prior_ent_mag": 45.5280320930481, "train/prior_ent_max": 45.5280320930481, "train/prior_ent_mean": 45.444750461578366, "train/prior_ent_min": 45.40522815704346, "train/prior_ent_std": 0.018562159221619367, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 7.713317863817792e-05, "train/reward_loss_mean": 0.0017334355600178242, "train/reward_loss_std": 0.04946056634966788, "train/reward_max_data": 0.07782812483608723, "train/reward_max_pred": 5.840063095092773e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00015692091998062096, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.411829725901287, "train/reward_pred": 5.834251642227173e-05, "train/reward_rate": 0.0001513671875, "train_stats/mean_log_entropy": 1.9383335908253987, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020102079957723618, "report/cont_loss_std": 0.3023267984390259, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.597464561462402, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003714141435921192, "report/cont_pred": 0.9962928891181946, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2547762989997864, "report/image_loss_std": 0.08073778450489044, "report/model_loss_mean": 0.8749995231628418, "report/model_loss_std": 0.3098966181278229, "report/post_ent_mag": 43.514286041259766, "report/post_ent_max": 43.514286041259766, "report/post_ent_mean": 43.446022033691406, "report/post_ent_min": 42.79805374145508, "report/post_ent_std": 0.13613304495811462, "report/prior_ent_mag": 45.635948181152344, "report/prior_ent_max": 45.635948181152344, "report/prior_ent_mean": 45.56095886230469, "report/prior_ent_min": 45.49347686767578, "report/prior_ent_std": 0.016351506114006042, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00012111663818359375, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.851818084716797e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00012111663818359375, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.851818084716797e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003714141435921192, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003714141435921192, "eval/cont_pred": 0.9962928891181946, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2356036901473999, "eval/image_loss_std": 0.08215641975402832, "eval/model_loss_mean": 0.8394389748573303, "eval/model_loss_std": 0.08215640485286713, "eval/post_ent_mag": 43.515907287597656, "eval/post_ent_max": 43.515907287597656, "eval/post_ent_mean": 43.454444885253906, "eval/post_ent_min": 42.796173095703125, "eval/post_ent_std": 0.12558142840862274, "eval/prior_ent_mag": 45.66611099243164, "eval/prior_ent_max": 45.66611099243164, "eval/prior_ent_mean": 45.560028076171875, "eval/prior_ent_min": 45.51540756225586, "eval/prior_ent_std": 0.017147129401564598, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00012111663818359375, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.851818084716797e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00012111663818359375, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.851818084716797e-05, "eval/reward_rate": 0.0, "replay/size": 128145.0, "replay/inserts": 32064.0, "replay/samples": 32064.0, "replay/insert_wait_avg": 1.3309398929991883e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.489795311720309e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2249545105050867e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4064638614655, "timer/env.step_count": 4008.0, "timer/env.step_total": 39.58061170578003, "timer/env.step_frac": 0.03956453015407654, "timer/env.step_avg": 0.009875402122200606, "timer/env.step_min": 0.00812220573425293, "timer/env.step_max": 0.04424428939819336, "timer/replay._sample_count": 32064.0, "timer/replay._sample_total": 17.107288360595703, "timer/replay._sample_frac": 0.017100337691305333, "timer/replay._sample_avg": 0.000533535689888838, "timer/replay._sample_min": 0.0003647804260253906, "timer/replay._sample_max": 0.026989221572875977, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4875.0, "timer/agent.policy_total": 52.05573320388794, "timer/agent.policy_frac": 0.052034583026341306, "timer/agent.policy_avg": 0.010678099118746244, "timer/agent.policy_min": 0.009148120880126953, "timer/agent.policy_max": 0.07677841186523438, "timer/dataset_train_count": 2004.0, "timer/dataset_train_total": 0.21818900108337402, "timer/dataset_train_frac": 0.0002181003511724495, "timer/dataset_train_avg": 0.00010887674704759183, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0007565021514892578, "timer/agent.train_count": 2004.0, "timer/agent.train_total": 894.2559018135071, "timer/agent.train_frac": 0.8938925667890747, "timer/agent.train_avg": 0.4462354799468598, "timer/agent.train_min": 0.43704938888549805, "timer/agent.train_max": 0.8297276496887207, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47573113441467285, "timer/agent.report_frac": 0.0004755378454657319, "timer/agent.report_avg": 0.23786556720733643, "timer/agent.report_min": 0.23114395141601562, "timer/agent.report_max": 0.24458718299865723, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2888395971591604e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 32.05042134146304}
{"step": 129256, "time": 4282.609878778458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129384, "time": 4286.524133682251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129608, "time": 4293.361515045166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 4311.739412784576, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4311.749429702759, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4311.797427177429, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4311.811641216278, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4311.821235179901, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4311.830132484436, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4311.839152336121, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4311.848076105118, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130112, "time": 4315.277406692505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130128, "time": 4315.767695903778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130184, "time": 4317.240695953369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130664, "time": 4331.789479494095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130800, "time": 4336.157062530518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131568, "time": 4360.081107616425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131696, "time": 4364.04132771492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131920, "time": 4370.9085521698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132424, "time": 4386.03396487236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132440, "time": 4386.546821117401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132496, "time": 4388.467677593231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132976, "time": 4403.086785793304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133112, "time": 4406.99204492569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133880, "time": 4430.32728266716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134008, "time": 4434.263461828232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134232, "time": 4441.082293272018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134640, "time": 4453.713166713715, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 134736, "time": 4456.642807483673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134752, "time": 4457.131547212601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134808, "time": 4458.6101541519165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135424, "time": 4477.798050880432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136192, "time": 4501.211795806885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136320, "time": 4505.104927062988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136544, "time": 4511.907553195953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136952, "time": 4524.243467569351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137048, "time": 4527.1587653160095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137064, "time": 4527.650727033615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137120, "time": 4529.596777439117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137736, "time": 4548.808922290802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137896, "time": 4553.773387432098, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 138296, "time": 4565.958984375, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 138632, "time": 4576.198050737381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138856, "time": 4583.183074712753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139360, "time": 4599.336420536041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139376, "time": 4599.825489044189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139432, "time": 4601.303492307663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140048, "time": 4620.421298503876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 4627.180102109909, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4627.188776731491, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4627.198811531067, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4627.207450628281, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4627.215546607971, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4627.225883960724, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4627.235458850861, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4627.247601985931, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140208, "time": 4631.147403001785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140608, "time": 4643.425341129303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140944, "time": 4653.672121286392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141168, "time": 4660.552854299545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141672, "time": 4675.793198347092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141688, "time": 4676.289883613586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141744, "time": 4678.249425411224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142360, "time": 4696.859400510788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142520, "time": 4701.818024158478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142920, "time": 4713.912553310394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143256, "time": 4724.211573839188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143480, "time": 4731.173292160034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143984, "time": 4746.7754871845245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144000, "time": 4747.270572900772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144056, "time": 4748.7636342048645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144672, "time": 4767.9647653102875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144832, "time": 4772.838551044464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145232, "time": 4785.076615095139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145568, "time": 4795.503198862076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145792, "time": 4802.327411413193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146296, "time": 4817.5187084674835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146312, "time": 4818.014267206192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146368, "time": 4819.955181598663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146984, "time": 4838.593187093735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147144, "time": 4843.5099885463715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147544, "time": 4856.392908573151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147880, "time": 4866.685472249985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148104, "time": 4873.528831005096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148608, "time": 4889.221068620682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148624, "time": 4889.716320991516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148680, "time": 4891.211755037308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149296, "time": 4910.369034767151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149456, "time": 4915.412128686905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149856, "time": 4927.610488414764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 4938.291853904724, "eval_episode/length": 203.0, "eval_episode/score": 0.3656249940395355, "eval_episode/reward_rate": 0.004901960784313725}
{"step": 150072, "time": 4939.289236068726, "eval_episode/length": 248.0, "eval_episode/score": 0.22499999403953552, "eval_episode/reward_rate": 0.004016064257028112}
{"step": 150072, "time": 4940.123320817947, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4940.133821249008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4940.145796537399, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4940.177808046341, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4940.236389398575, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4940.261437892914, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150192, "time": 4944.265940904617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150416, "time": 4951.143826723099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150920, "time": 4966.357216835022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150936, "time": 4966.851969957352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150992, "time": 4968.800938844681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151608, "time": 4987.445649862289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151768, "time": 4992.319186925888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152168, "time": 5004.664475440979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152504, "time": 5015.097339630127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152728, "time": 5021.905021190643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153232, "time": 5037.611195087433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153248, "time": 5038.102378845215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153304, "time": 5039.589485406876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153920, "time": 5058.693987607956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154080, "time": 5063.726390838623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154480, "time": 5075.915505170822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154816, "time": 5086.154631614685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155040, "time": 5093.076424837112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155544, "time": 5108.279238462448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155560, "time": 5108.769166469574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155616, "time": 5110.690657377243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156232, "time": 5129.930994272232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156320, "time": 5132.852943897247, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 156392, "time": 5134.823192834854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156632, "time": 5142.166850805283, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 156792, "time": 5147.039771080017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157352, "time": 5164.24223947525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157384, "time": 5165.212488651276, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 157856, "time": 5179.813244104385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157928, "time": 5181.896550416946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158632, "time": 5203.3668892383575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158704, "time": 5205.797356128693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158944, "time": 5213.261823177338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159104, "time": 5218.145612478256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159664, "time": 5235.320527076721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159696, "time": 5236.294563770294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 5252.9707589149475, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5252.9790070056915, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5252.989226818085, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5252.99884724617, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5253.006119728088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5253.014012813568, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5253.022031068802, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5253.029413700104, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160168, "time": 5256.462157487869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160240, "time": 5258.878180742264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160393, "time": 5264.336820602417, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9979081587357954, "train/action_min": 0.0, "train/action_std": 1.9991621019864323, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 3.9496774064386356e-05, "train/actor_opt_grad_steps": 8935.0, "train/actor_opt_loss": -5.739323852207474, "train/adv_mag": 0.0001911759903334608, "train/adv_max": 0.00011442331691281963, "train/adv_mean": -2.3473382645759077e-06, "train/adv_min": -0.00012697769573541602, "train/adv_std": 4.352499715625729e-05, "train/cont_avg": 0.996517913510101, "train/cont_loss_mean": 0.023200254932027122, "train/cont_loss_std": 0.323728583254912, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.672936332469084, "train/cont_pos_acc": 0.999999984948322, "train/cont_pos_loss": 0.003482373498351962, "train/cont_pred": 0.9965238234009406, "train/cont_rate": 0.996517913510101, "train/dyn_loss_mean": 1.0023256130892821, "train/dyn_loss_std": 6.176428304928722e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.007821244742095734, "train/extr_critic_critic_opt_grad_steps": 8935.0, "train/extr_critic_critic_opt_loss": 6641.039893564552, "train/extr_critic_mag": 0.017050344534594603, "train/extr_critic_max": 0.017050344534594603, "train/extr_critic_mean": 0.016996552951332896, "train/extr_critic_min": 0.01695670925005518, "train/extr_critic_std": 1.5166729297669632e-05, "train/extr_return_normed_mag": 0.00022694430869035046, "train/extr_return_normed_max": 0.00013540202582424337, "train/extr_return_normed_mean": 5.276638496579812e-05, "train/extr_return_normed_min": -2.9800205745480277e-05, "train/extr_return_normed_std": 3.882545696006958e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.017076828874497102, "train/extr_return_raw_max": 0.017076828874497102, "train/extr_return_raw_mean": 0.016994194014731682, "train/extr_return_raw_min": 0.016911626642927377, "train/extr_return_raw_std": 3.8825456898058574e-05, "train/extr_reward_mag": 5.0743420918782554e-05, "train/extr_reward_max": 5.0743420918782554e-05, "train/extr_reward_mean": 5.071247631698351e-05, "train/extr_reward_min": 5.068863281095871e-05, "train/extr_reward_std": 1.2710108268895485e-08, "train/image_loss_mean": 0.2525227978976086, "train/image_loss_std": 0.0849506820392127, "train/model_loss_mean": 0.878844741920028, "train/model_loss_std": 0.3720563537243641, "train/model_opt_grad_norm": 53.114899490818836, "train/model_opt_grad_steps": 8924.575757575758, "train/model_opt_loss": 2235.6856042110558, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2544.191919191919, "train/policy_entropy_mag": 1.9458951667101696, "train/policy_entropy_max": 1.9458951667101696, "train/policy_entropy_mean": 1.9451325602001615, "train/policy_entropy_min": 1.932210780755438, "train/policy_entropy_std": 0.0005566123243882274, "train/policy_logprob_mag": 2.1564394909926135, "train/policy_logprob_max": -1.735226162154265, "train/policy_logprob_mean": -1.94517841784641, "train/policy_logprob_min": -2.1564394909926135, "train/policy_logprob_std": 0.03909134626802471, "train/policy_randomness_mag": 0.9999923594672271, "train/policy_randomness_max": 0.9999923594672271, "train/policy_randomness_mean": 0.9996004486926878, "train/policy_randomness_min": 0.9929599758952555, "train/policy_randomness_std": 0.0002860421565598855, "train/post_ent_mag": 45.43158583207564, "train/post_ent_max": 45.43158583207564, "train/post_ent_mean": 45.39318531691426, "train/post_ent_min": 45.308063275886305, "train/post_ent_std": 0.02028190242973241, "train/prior_ent_mag": 45.95859656671081, "train/prior_ent_max": 45.95859656671081, "train/prior_ent_mean": 45.930114033246284, "train/prior_ent_min": 45.864244961979416, "train/prior_ent_std": 0.013495085953800666, "train/rep_loss_mean": 1.0023256130892821, "train/rep_loss_std": 6.176428304928722e-05, "train/reward_avg": 7.077612084538836e-05, "train/reward_loss_mean": 0.0017263024970136508, "train/reward_loss_std": 0.04819843793231028, "train/reward_max_data": 0.06840277801860463, "train/reward_max_pred": 5.073679818047417e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00012830241875501933, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.446184839521136, "train/reward_pred": 5.069215466842206e-05, "train/reward_rate": 0.000152896148989899, "train_stats/mean_log_entropy": 1.9381442261593682, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020013896748423576, "report/cont_loss_std": 0.3154163658618927, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.83885383605957, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002916426630690694, "report/cont_pred": 0.9970877170562744, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24014531075954437, "report/image_loss_std": 0.08287317305803299, "report/model_loss_mean": 0.8604004979133606, "report/model_loss_std": 0.3264467120170593, "report/post_ent_mag": 45.56757736206055, "report/post_ent_max": 45.56757736206055, "report/post_ent_mean": 45.537784576416016, "report/post_ent_min": 45.52163314819336, "report/post_ent_std": 0.005333653185516596, "report/prior_ent_mag": 45.925384521484375, "report/prior_ent_max": 45.925384521484375, "report/prior_ent_mean": 45.90376663208008, "report/prior_ent_min": 45.84001159667969, "report/prior_ent_std": 0.01263637188822031, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00024127960205078125, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.00010454654693603516, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00024127960205078125, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00010454654693603516, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.002916426630690694, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002916426630690694, "eval/cont_pred": 0.9970877170562744, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24710312485694885, "eval/image_loss_std": 0.0819232240319252, "eval/model_loss_mean": 0.850260853767395, "eval/model_loss_std": 0.0819232240319252, "eval/post_ent_mag": 45.565269470214844, "eval/post_ent_max": 45.565269470214844, "eval/post_ent_mean": 45.538089752197266, "eval/post_ent_min": 45.52477264404297, "eval/post_ent_std": 0.00497422507032752, "eval/prior_ent_mag": 45.92744827270508, "eval/prior_ent_max": 45.92744827270508, "eval/prior_ent_mean": 45.903594970703125, "eval/prior_ent_min": 45.84001159667969, "eval/prior_ent_std": 0.011527868919074535, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00024127960205078125, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00010454654693603516, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00024127960205078125, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00010454654693603516, "eval/reward_rate": 0.0, "replay/size": 159889.0, "replay/inserts": 31744.0, "replay/samples": 31744.0, "replay/insert_wait_avg": 1.3477138934596892e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.242655425302444e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 40360.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2128462428452646e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.07537317276, "timer/env.step_count": 3968.0, "timer/env.step_total": 39.58488488197327, "timer/env.step_frac": 0.03958190146847571, "timer/env.step_avg": 0.009976029456142456, "timer/env.step_min": 0.008143424987792969, "timer/env.step_max": 0.052648305892944336, "timer/replay._sample_count": 31744.0, "timer/replay._sample_total": 16.598652362823486, "timer/replay._sample_frac": 0.016597401364023108, "timer/replay._sample_avg": 0.0005228910144538649, "timer/replay._sample_min": 0.0003712177276611328, "timer/replay._sample_max": 0.01181483268737793, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5124.0, "timer/agent.policy_total": 55.82410025596619, "timer/agent.policy_frac": 0.055819892933532664, "timer/agent.policy_avg": 0.010894633149095665, "timer/agent.policy_min": 0.009064912796020508, "timer/agent.policy_max": 0.08097481727600098, "timer/dataset_train_count": 1984.0, "timer/dataset_train_total": 0.21900558471679688, "timer/dataset_train_frac": 0.0002189890788151268, "timer/dataset_train_avg": 0.00011038587939354681, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.00027942657470703125, "timer/agent.train_count": 1984.0, "timer/agent.train_total": 886.8200936317444, "timer/agent.train_frac": 0.8867532562253674, "timer/agent.train_avg": 0.44698593429019373, "timer/agent.train_min": 0.43573474884033203, "timer/agent.train_max": 1.1099662780761719, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4789450168609619, "timer/agent.report_frac": 0.00047890891997620026, "timer/agent.report_avg": 0.23947250843048096, "timer/agent.report_min": 0.2317509651184082, "timer/agent.report_max": 0.2471940517425537, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2184082362310924e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 31.740591773681764}
{"step": 160944, "time": 5281.411141395569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161016, "time": 5283.384603023529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161256, "time": 5290.7206473350525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161416, "time": 5295.60999584198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161976, "time": 5312.894350528717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162008, "time": 5313.8796491622925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162480, "time": 5328.598002195358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162552, "time": 5330.688064575195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163256, "time": 5352.116949796677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163328, "time": 5354.563344955444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163568, "time": 5362.0011694431305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163728, "time": 5366.8689115047455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164288, "time": 5384.376430034637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164320, "time": 5385.351397037506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164792, "time": 5399.575820684433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164864, "time": 5401.9831557273865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165568, "time": 5423.532668828964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165640, "time": 5425.495195150375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165880, "time": 5432.829877853394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166040, "time": 5437.749949216843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166600, "time": 5454.977053403854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166632, "time": 5455.958799362183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167104, "time": 5470.579076766968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167176, "time": 5472.557450532913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167880, "time": 5494.0048179626465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167952, "time": 5496.421817302704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168192, "time": 5503.664845466614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168352, "time": 5508.515397310257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168912, "time": 5525.715983867645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168944, "time": 5526.689190149307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169416, "time": 5540.917332410812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169488, "time": 5543.364680767059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 5563.339942216873, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 170040, "time": 5566.333167314529, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5566.34055185318, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5566.348408699036, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5566.357033729553, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5566.366359472275, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5566.372481107712, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5566.380835056305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170192, "time": 5571.349456310272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170264, "time": 5573.311306476593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170504, "time": 5580.687604427338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170664, "time": 5585.5780420303345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171224, "time": 5602.705459833145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171256, "time": 5603.6953065395355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171728, "time": 5618.405264377594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171800, "time": 5620.408300161362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171888, "time": 5623.308147907257, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 172504, "time": 5642.42525267601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172576, "time": 5644.84751200676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172816, "time": 5652.1292283535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172976, "time": 5656.97336268425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173536, "time": 5673.958710670471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173568, "time": 5674.947845458984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174040, "time": 5689.0274085998535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174200, "time": 5694.052865982056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174816, "time": 5713.018033981323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174888, "time": 5715.036065340042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175128, "time": 5722.488756895065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175288, "time": 5727.385595321655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175848, "time": 5744.397207021713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175872, "time": 5745.352530479431, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 175880, "time": 5745.381851673126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176352, "time": 5760.036611557007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176512, "time": 5764.925822019577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177200, "time": 5785.942732334137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177440, "time": 5793.236289024353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177600, "time": 5798.124812602997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178160, "time": 5815.197947263718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178184, "time": 5815.710500001907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178192, "time": 5816.2002029418945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178664, "time": 5830.297683238983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178824, "time": 5835.1921854019165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179512, "time": 5856.172854423523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179752, "time": 5863.457306861877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179912, "time": 5868.325724840164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 5876.062595367432, "eval_episode/length": 232.0, "eval_episode/score": 0.2750000059604645, "eval_episode/reward_rate": 0.004291845493562232}
{"step": 180024, "time": 5877.086092472076, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5877.09330201149, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5877.099035024643, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5877.105054855347, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5877.1109483242035, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5877.118143558502, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5877.123685598373, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180472, "time": 5891.175806522369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180496, "time": 5892.134533405304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180504, "time": 5892.162976741791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180976, "time": 5906.849191188812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181136, "time": 5911.7425968647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181824, "time": 5932.821798086166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182064, "time": 5940.106472969055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182224, "time": 5944.9931581020355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182784, "time": 5962.082768917084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182808, "time": 5962.594152212143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182816, "time": 5963.065279960632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183288, "time": 5977.221937894821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183448, "time": 5982.10426235199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184136, "time": 6003.221551179886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184376, "time": 6010.452387332916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184536, "time": 6015.299548625946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185096, "time": 6032.336816310883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185120, "time": 6033.287677526474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185128, "time": 6033.324981212616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185600, "time": 6047.924895524979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185760, "time": 6052.873891830444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186448, "time": 6073.749409198761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186688, "time": 6081.13502407074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186848, "time": 6085.998692989349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187408, "time": 6103.012088060379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187432, "time": 6103.52596449852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187440, "time": 6103.994770765305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187912, "time": 6118.197282552719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188072, "time": 6123.035125494003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188760, "time": 6144.489862203598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189000, "time": 6151.743701934814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189160, "time": 6156.59965133667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189720, "time": 6173.687083721161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189744, "time": 6174.638858556747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189752, "time": 6174.676731586456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 6187.714621067047, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6187.72323346138, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6187.730530261993, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6187.738676786423, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6187.750092506409, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6187.761971473694, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6187.772801876068, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6187.786177873611, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190224, "time": 6194.559156417847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190384, "time": 6199.4108102321625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191072, "time": 6220.338259458542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191312, "time": 6227.642832994461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191472, "time": 6232.6164293289185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192032, "time": 6249.7042899131775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192056, "time": 6250.211891889572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192064, "time": 6250.679237365723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192489, "time": 6264.425412893295, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.001558673915578, "train/action_min": 0.0, "train/action_std": 1.9997625493291598, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.94341281122257e-05, "train/actor_opt_grad_steps": 10930.0, "train/actor_opt_loss": -4.5984951296626635, "train/adv_mag": 0.0002710526503288924, "train/adv_max": 0.00022514511956207788, "train/adv_mean": 5.7287401787887766e-05, "train/adv_min": -0.00013245492061572287, "train/adv_std": 6.284543324180963e-05, "train/cont_avg": 0.9962492226368159, "train/cont_loss_mean": 0.02473185906436906, "train/cont_loss_std": 0.33717201857952706, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.668735795021057, "train/cont_pos_acc": 0.9999999848764334, "train/cont_pos_loss": 0.0034888724075973184, "train/cont_pred": 0.9965172967507472, "train/cont_rate": 0.9962492226368159, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.009146940090522096, "train/extr_critic_critic_opt_grad_steps": 10930.0, "train/extr_critic_critic_opt_loss": 7017.676186936412, "train/extr_critic_mag": 0.01858978188453029, "train/extr_critic_max": 0.01858978188453029, "train/extr_critic_mean": 0.01850296940598915, "train/extr_critic_min": 0.018436444932548562, "train/extr_critic_std": 2.4288599406215657e-05, "train/extr_return_normed_mag": 0.0003621360907951991, "train/extr_return_normed_max": 0.0003288740764802961, "train/extr_return_normed_mean": 0.00021331279008992527, "train/extr_return_normed_min": 8.387803401223462e-05, "train/extr_return_normed_std": 5.5024099249599947e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.018675797540156996, "train/extr_return_raw_max": 0.018675797540156996, "train/extr_return_raw_mean": 0.018560237246588687, "train/extr_return_raw_min": 0.018430801497688935, "train/extr_return_raw_std": 5.502409913195387e-05, "train/extr_reward_mag": 6.476029827820128e-05, "train/extr_reward_max": 6.476029827820128e-05, "train/extr_reward_mean": 6.46920665920207e-05, "train/extr_reward_min": 6.46470197990759e-05, "train/extr_reward_std": 2.5937773142128738e-08, "train/image_loss_mean": 0.248708978740137, "train/image_loss_std": 0.08471730877807485, "train/model_loss_mean": 0.8747429930748631, "train/model_loss_std": 0.37413707846284505, "train/model_opt_grad_norm": 48.89150876666776, "train/model_opt_grad_steps": 10917.6815920398, "train/model_opt_loss": 2241.979041559779, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2562.1890547263683, "train/policy_entropy_mag": 1.945888458199762, "train/policy_entropy_max": 1.945888458199762, "train/policy_entropy_mean": 1.9447368691809734, "train/policy_entropy_min": 1.9292126680488018, "train/policy_entropy_std": 0.0008669288751358787, "train/policy_logprob_mag": 2.183440188270303, "train/policy_logprob_max": -1.7085528711774456, "train/policy_logprob_mean": -1.9447747172407843, "train/policy_logprob_min": -2.183440188270303, "train/policy_logprob_std": 0.04629425847189343, "train/policy_randomness_mag": 0.9999889105706665, "train/policy_randomness_max": 0.9999889105706665, "train/policy_randomness_mean": 0.9993971079143126, "train/policy_randomness_min": 0.9914192498026796, "train/policy_randomness_std": 0.0004455133369343068, "train/post_ent_mag": 48.10521808073889, "train/post_ent_max": 48.10521808073889, "train/post_ent_mean": 48.023873760925596, "train/post_ent_min": 47.99720898908169, "train/post_ent_std": 0.017724836458317676, "train/prior_ent_mag": 46.351478348917034, "train/prior_ent_max": 46.351478348917034, "train/prior_ent_mean": 46.26898832937971, "train/prior_ent_min": 46.190884224811, "train/prior_ent_std": 0.0244423877494178, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 5.549340771247091e-05, "train/reward_loss_mean": 0.0013021340556628076, "train/reward_loss_std": 0.034802685343879626, "train/reward_max_data": 0.05220771236206168, "train/reward_max_pred": 6.474784357630791e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00015525239741601124, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.258370989844913, "train/reward_pred": 6.46700034270165e-05, "train/reward_rate": 0.00011174595771144279, "train_stats/mean_log_entropy": 1.9364619893687112, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025559527799487114, "report/cont_loss_std": 0.34527090191841125, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.539093971252441, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003937828354537487, "report/cont_pred": 0.9960699081420898, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24555188417434692, "report/image_loss_std": 0.08073107153177261, "report/model_loss_mean": 0.8712831139564514, "report/model_loss_std": 0.35054999589920044, "report/post_ent_mag": 51.29829788208008, "report/post_ent_max": 51.29829788208008, "report/post_ent_mean": 51.056434631347656, "report/post_ent_min": 50.97623062133789, "report/post_ent_std": 0.0596223846077919, "report/prior_ent_mag": 47.08460998535156, "report/prior_ent_max": 47.08460998535156, "report/prior_ent_mean": 46.908424377441406, "report/prior_ent_min": 46.79039001464844, "report/prior_ent_std": 0.047060418874025345, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.000171661376953125, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.11679458618164e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000171661376953125, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.11679458618164e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003937828820198774, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003937828820198774, "eval/cont_pred": 0.9960699081420898, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22813522815704346, "eval/image_loss_std": 0.07817984372377396, "eval/model_loss_mean": 0.8322447538375854, "eval/model_loss_std": 0.07817984372377396, "eval/post_ent_mag": 51.30128479003906, "eval/post_ent_max": 51.30128479003906, "eval/post_ent_mean": 51.058292388916016, "eval/post_ent_min": 50.9779052734375, "eval/post_ent_std": 0.06525217741727829, "eval/prior_ent_mag": 47.33739471435547, "eval/prior_ent_max": 47.33739471435547, "eval/prior_ent_mean": 46.911964416503906, "eval/prior_ent_min": 46.761497497558594, "eval/prior_ent_std": 0.05262027308344841, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.000171661376953125, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.11679458618164e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000171661376953125, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.11679458618164e-05, "eval/reward_rate": 0.0, "replay/size": 191985.0, "replay/inserts": 32096.0, "replay/samples": 32096.0, "replay/insert_wait_avg": 1.29445481038878e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.813304276433091e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47296.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1136168839609747e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.092001914978, "timer/env.step_count": 4012.0, "timer/env.step_total": 39.45705771446228, "timer/env.step_frac": 0.03945342792354087, "timer/env.step_avg": 0.009834760148171057, "timer/env.step_min": 0.007956743240356445, "timer/env.step_max": 0.03889584541320801, "timer/replay._sample_count": 32096.0, "timer/replay._sample_total": 16.67114496231079, "timer/replay._sample_frac": 0.016669611326146846, "timer/replay._sample_avg": 0.0005194150349673103, "timer/replay._sample_min": 0.0003807544708251953, "timer/replay._sample_max": 0.02428913116455078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4879.0, "timer/agent.policy_total": 51.460365772247314, "timer/agent.policy_frac": 0.0514556317555894, "timer/agent.policy_avg": 0.01054731825625073, "timer/agent.policy_min": 0.00862741470336914, "timer/agent.policy_max": 0.09322929382324219, "timer/dataset_train_count": 2006.0, "timer/dataset_train_total": 0.21951675415039062, "timer/dataset_train_frac": 0.00021949656004653526, "timer/dataset_train_avg": 0.00010943008681475105, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0010771751403808594, "timer/agent.train_count": 2006.0, "timer/agent.train_total": 895.1730217933655, "timer/agent.train_frac": 0.8950906717374867, "timer/agent.train_avg": 0.44624776759390106, "timer/agent.train_min": 0.43436741828918457, "timer/agent.train_max": 0.7063941955566406, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47972798347473145, "timer/agent.report_frac": 0.00047968385164179637, "timer/agent.report_avg": 0.23986399173736572, "timer/agent.report_min": 0.2339344024658203, "timer/agent.report_max": 0.24579358100891113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8607597538431042e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 32.092560078410536}
{"step": 192536, "time": 6265.602883577347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192696, "time": 6270.438547849655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193384, "time": 6291.350526332855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193624, "time": 6298.615542173386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193784, "time": 6303.463325023651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194344, "time": 6320.554748535156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194368, "time": 6321.525775909424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194376, "time": 6321.553178310394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194432, "time": 6323.469570636749, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 194848, "time": 6336.04700088501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195696, "time": 6361.773005723953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195936, "time": 6369.044983625412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196096, "time": 6373.9037663936615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196656, "time": 6391.465163707733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196680, "time": 6391.9740335941315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196688, "time": 6392.442636489868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196744, "time": 6393.9133644104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197160, "time": 6406.508032798767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197816, "time": 6426.55202126503, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 197880, "time": 6428.505263328552, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 198008, "time": 6432.380058050156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198408, "time": 6445.350586175919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198968, "time": 6462.315732240677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198992, "time": 6463.28338766098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199000, "time": 6463.311808347702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199416, "time": 6476.002135276794, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 199472, "time": 6477.9654586315155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 6502.874306201935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6502.884586811066, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6502.892487287521, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6502.903249740601, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6502.914448261261, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6502.926458358765, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6502.936049461365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6502.945078134537, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200128, "time": 6503.942589521408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200320, "time": 6509.724156141281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200720, "time": 6521.809153556824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201280, "time": 6538.836560726166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201304, "time": 6539.346206903458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201312, "time": 6539.814472913742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201352, "time": 6540.808754682541, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 201728, "time": 6552.428706169128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201784, "time": 6553.9024493694305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202440, "time": 6574.034806728363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203032, "time": 6592.102460861206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203592, "time": 6609.001917600632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203616, "time": 6609.950546979904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203624, "time": 6609.978011608124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203664, "time": 6611.419030427933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204040, "time": 6622.612512350082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204096, "time": 6624.515316724777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204752, "time": 6644.385304927826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205344, "time": 6662.917164325714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205904, "time": 6679.897558450699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205928, "time": 6680.499351501465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205936, "time": 6680.966722011566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205976, "time": 6681.958023071289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206056, "time": 6684.389948129654, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 206352, "time": 6693.548646211624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206408, "time": 6695.016466617584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207064, "time": 6715.019323825836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207656, "time": 6732.967348814011, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208216, "time": 6750.040160179138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208240, "time": 6751.0099976062775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208288, "time": 6752.519636154175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208368, "time": 6754.988796472549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208664, "time": 6763.821999073029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208720, "time": 6765.745518922806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209376, "time": 6785.8870005607605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209968, "time": 6803.9661693573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 6812.717159986496, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6812.753501415253, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6812.7624723911285, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6812.773117780685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6812.78115606308, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6812.79106593132, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6812.7996945381165, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6812.81015586853, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210528, "time": 6826.407157897949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210552, "time": 6826.918025493622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210600, "time": 6828.3705360889435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210680, "time": 6830.884441137314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210976, "time": 6840.053857803345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211032, "time": 6841.547668457031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211688, "time": 6861.484210729599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212280, "time": 6879.455854415894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212840, "time": 6896.4864366054535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212864, "time": 6897.435216188431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212912, "time": 6898.911557197571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212992, "time": 6901.47431063652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213288, "time": 6910.611725330353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213344, "time": 6912.525554180145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214000, "time": 6932.416409254074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214592, "time": 6950.3250041008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215152, "time": 6967.343649625778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215176, "time": 6967.847991943359, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 215176, "time": 6967.857880353928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215224, "time": 6969.310457229614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215304, "time": 6971.723328828812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215600, "time": 6981.0362112522125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215656, "time": 6982.527894735336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216904, "time": 7020.386250257492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217152, "time": 7028.117848396301, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 217464, "time": 7037.3398542404175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217488, "time": 7038.2917268276215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217488, "time": 7038.300323009491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217536, "time": 7039.756003379822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217616, "time": 7042.299463510513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217912, "time": 7051.051753520966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219216, "time": 7090.858292579651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219464, "time": 7098.157994747162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219776, "time": 7107.885723352432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219800, "time": 7108.4167585372925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219800, "time": 7108.4245727062225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219848, "time": 7109.892427206039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219928, "time": 7112.315216779709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 7121.898071050644, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7121.9487228393555, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7121.987071275711, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7121.997497081757, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7122.007625102997, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7122.017075538635, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7122.028036594391, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7122.045231103897, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220224, "time": 7126.868788480759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221528, "time": 7166.986897230148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221776, "time": 7174.712134361267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222088, "time": 7183.925903558731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222112, "time": 7184.872936248779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222112, "time": 7184.882699728012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222160, "time": 7186.347213745117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222240, "time": 7188.7976706027985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222536, "time": 7197.645583868027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223840, "time": 7237.592624425888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224088, "time": 7244.893629312515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224400, "time": 7254.664831399918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224424, "time": 7255.17111325264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224424, "time": 7255.178886890411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224472, "time": 7256.650812625885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224552, "time": 7259.067761659622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224697, "time": 7264.433938741684, "train_stats/mean_log_entropy": 1.9063819667212984, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0474847442475124, "train/action_min": 0.0, "train/action_std": 1.9748257469775072, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0002568435197984522, "train/actor_opt_grad_steps": 12940.0, "train/actor_opt_loss": -4.130445086392597, "train/adv_mag": 0.000908066615907114, "train/adv_max": 0.000812802695442195, "train/adv_mean": 8.786089049444532e-05, "train/adv_min": -0.0005290716775317691, "train/adv_std": 0.0001687152159967302, "train/cont_avg": 0.9964921486318408, "train/cont_loss_mean": 0.023362951121520047, "train/cont_loss_std": 0.3226292220150487, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.655849725461853, "train/cont_pos_acc": 0.9999999860625955, "train/cont_pos_loss": 0.0035392781673230936, "train/cont_pred": 0.9964671007436307, "train/cont_rate": 0.9964921486318408, "train/dyn_loss_mean": 1.0000015431968727, "train/dyn_loss_std": 4.938122800745959e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.007193885601573943, "train/extr_critic_critic_opt_grad_steps": 12940.0, "train/extr_critic_critic_opt_loss": 7429.748163479478, "train/extr_critic_mag": 0.02068009601896675, "train/extr_critic_max": 0.02068009601896675, "train/extr_critic_mean": 0.02021494221442671, "train/extr_critic_min": 0.01984998539312562, "train/extr_critic_std": 9.33209882727106e-05, "train/extr_return_normed_mag": 0.001055918040856793, "train/extr_return_normed_max": 0.0010347245492745394, "train/extr_return_normed_mean": 0.00036384817066214935, "train/extr_return_normed_min": -4.530981627862845e-05, "train/extr_return_normed_std": 0.00015748191220322114, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.020973689103526854, "train/extr_return_raw_max": 0.020973689103526854, "train/extr_return_raw_mean": 0.020302813824507136, "train/extr_return_raw_min": 0.01989365473797369, "train/extr_return_raw_std": 0.0001574819137778687, "train/extr_reward_mag": 0.00011556836503062082, "train/extr_reward_max": 0.00011556836503062082, "train/extr_reward_mean": 7.107814209252209e-05, "train/extr_reward_min": 5.722579671375787e-05, "train/extr_reward_std": 1.3817547760327968e-05, "train/image_loss_mean": 0.21284494582396835, "train/image_loss_std": 0.09232637586433497, "train/model_loss_mean": 0.8376628439224775, "train/model_loss_std": 0.36680410001704944, "train/model_opt_grad_norm": 42.55904662132263, "train/model_opt_grad_steps": 12925.726368159205, "train/model_opt_loss": 2136.848433613184, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 2537.313432835821, "train/policy_entropy_mag": 1.9436935737951477, "train/policy_entropy_max": 1.9436935737951477, "train/policy_entropy_mean": 1.9149732423658987, "train/policy_entropy_min": 1.7483198619007472, "train/policy_entropy_std": 0.017859376423681777, "train/policy_logprob_mag": 3.00890053445427, "train/policy_logprob_max": -1.0849367135496282, "train/policy_logprob_mean": -1.915074739883195, "train/policy_logprob_min": -3.00890053445427, "train/policy_logprob_std": 0.20866851623526853, "train/policy_randomness_mag": 0.9988609644310984, "train/policy_randomness_max": 0.9988609644310984, "train/policy_randomness_mean": 0.9841016332308451, "train/policy_randomness_min": 0.8984587320047824, "train/policy_randomness_std": 0.009177904466018821, "train/post_ent_mag": 56.82923604481256, "train/post_ent_max": 56.82923604481256, "train/post_ent_mean": 56.25642167276411, "train/post_ent_min": 55.776060626281435, "train/post_ent_std": 0.2072512632541692, "train/prior_ent_mag": 56.42341888959135, "train/prior_ent_max": 56.42341888959135, "train/prior_ent_mean": 53.269794559004296, "train/prior_ent_min": 51.43500501718094, "train/prior_ent_std": 0.8175821996187392, "train/rep_loss_mean": 1.0000015431968727, "train/rep_loss_std": 4.938122800745959e-05, "train/reward_avg": 6.747269484304837e-05, "train/reward_loss_mean": 0.001454003011594661, "train/reward_loss_std": 0.03862217935319094, "train/reward_max_data": 0.058784203817002216, "train/reward_max_pred": 0.00010880724114565114, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001545415389634187, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.216507206792416, "train/reward_pred": 6.382939213451314e-05, "train/reward_rate": 0.00012632151741293532, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.031081248074769974, "report/cont_loss_std": 0.39291489124298096, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.640276908874512, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0035582075361162424, "report/cont_pred": 0.996448278427124, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.20052991807460785, "report/image_loss_std": 0.09152248501777649, "report/model_loss_mean": 0.8317253589630127, "report/model_loss_std": 0.4039919972419739, "report/post_ent_mag": 58.086402893066406, "report/post_ent_max": 58.086402893066406, "report/post_ent_mean": 57.46755599975586, "report/post_ent_min": 56.92123031616211, "report/post_ent_std": 0.24540004134178162, "report/prior_ent_mag": 58.019447326660156, "report/prior_ent_max": 58.019447326660156, "report/prior_ent_mean": 54.08619689941406, "report/prior_ent_min": 50.895973205566406, "report/prior_ent_std": 1.3695621490478516, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001141885295510292, "report/reward_loss_std": 6.74429174978286e-05, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.00015413761138916016, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001141885295510292, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.370161332190037e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020072031766176224, "eval/cont_loss_std": 0.30464911460876465, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.640276908874512, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0035582073032855988, "eval/cont_pred": 0.996448278427124, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21030178666114807, "eval/image_loss_std": 0.09277878701686859, "eval/model_loss_mean": 0.8305023908615112, "eval/model_loss_std": 0.3158666491508484, "eval/post_ent_mag": 58.06105422973633, "eval/post_ent_max": 58.06105422973633, "eval/post_ent_mean": 57.454689025878906, "eval/post_ent_min": 56.92121124267578, "eval/post_ent_std": 0.2456338107585907, "eval/prior_ent_mag": 59.395851135253906, "eval/prior_ent_max": 59.395851135253906, "eval/prior_ent_mean": 54.25690460205078, "eval/prior_ent_min": 51.232818603515625, "eval/prior_ent_std": 1.3861132860183716, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00012859748676419258, "eval/reward_loss_std": 8.709004032425582e-05, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0001627206802368164, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00012859748676419258, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.914985038340092e-05, "eval/reward_rate": 0.0, "replay/size": 224193.0, "replay/inserts": 32208.0, "replay/samples": 32208.0, "replay/insert_wait_avg": 1.247174634426551e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.621429479364963e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54232.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0861863726975596e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9922103881836, "timer/env.step_count": 4026.0, "timer/env.step_total": 38.115097761154175, "timer/env.step_frac": 0.03811539466528285, "timer/env.step_avg": 0.0094672373972067, "timer/env.step_min": 0.007689237594604492, "timer/env.step_max": 0.03806257247924805, "timer/replay._sample_count": 32208.0, "timer/replay._sample_total": 16.796834707260132, "timer/replay._sample_frac": 0.016796965549101452, "timer/replay._sample_avg": 0.0005215112614027612, "timer/replay._sample_min": 0.0003790855407714844, "timer/replay._sample_max": 0.027547121047973633, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4893.0, "timer/agent.policy_total": 50.7988600730896, "timer/agent.policy_frac": 0.050799255779572686, "timer/agent.policy_avg": 0.010381945651561333, "timer/agent.policy_min": 0.006778717041015625, "timer/agent.policy_max": 0.1443774700164795, "timer/dataset_train_count": 2013.0, "timer/dataset_train_total": 0.21225786209106445, "timer/dataset_train_frac": 0.00021225951551029462, "timer/dataset_train_avg": 0.00010544354798363858, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0005743503570556641, "timer/agent.train_count": 2013.0, "timer/agent.train_total": 897.2034049034119, "timer/agent.train_frac": 0.8972103938240974, "timer/agent.train_avg": 0.4457046224060665, "timer/agent.train_min": 0.4350883960723877, "timer/agent.train_max": 1.2066562175750732, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4712393283843994, "timer/agent.report_frac": 0.0004712429991844343, "timer/agent.report_avg": 0.2356196641921997, "timer/agent.report_min": 0.22890710830688477, "timer/agent.report_max": 0.24233222007751465, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6703088866071567e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 32.20773160633204}
{"step": 224848, "time": 7269.015836715698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225464, "time": 7287.585382699966, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 226152, "time": 7308.408651590347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226400, "time": 7316.257990837097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226712, "time": 7325.575353145599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226736, "time": 7326.538450241089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226784, "time": 7328.024013519287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226864, "time": 7330.482768774033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227160, "time": 7339.280800580978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227776, "time": 7358.313177585602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228464, "time": 7379.341313123703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228712, "time": 7386.695805072784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229024, "time": 7396.33250617981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229048, "time": 7396.8427011966705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229096, "time": 7398.313114643097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229176, "time": 7400.8221600055695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229472, "time": 7410.52641749382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 7433.542888879776, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7433.646348237991, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7433.673665523529, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7433.684422492981, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7433.693738937378, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7433.702928304672, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7433.713536977768, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7433.723505020142, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230088, "time": 7434.722349643707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230776, "time": 7455.583120107651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231024, "time": 7463.440838098526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231336, "time": 7472.681308031082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231360, "time": 7473.631804704666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231408, "time": 7475.095116853714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231488, "time": 7477.540204524994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231784, "time": 7486.344200849533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232400, "time": 7505.355987548828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233088, "time": 7526.2407994270325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233336, "time": 7533.538802146912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233648, "time": 7543.294206380844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233672, "time": 7543.80607175827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233720, "time": 7545.284024000168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233800, "time": 7547.7165451049805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234096, "time": 7557.011551618576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234712, "time": 7575.541918992996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235400, "time": 7596.5641667842865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235648, "time": 7604.3673458099365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235960, "time": 7613.762582540512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235984, "time": 7614.712683200836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236032, "time": 7616.167805194855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236112, "time": 7618.599664926529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236408, "time": 7627.331876277924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237024, "time": 7646.232116222382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237712, "time": 7667.600170850754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237960, "time": 7674.980543375015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238272, "time": 7684.680801868439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238296, "time": 7685.197715997696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238344, "time": 7686.662451267242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238424, "time": 7689.111429691315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238720, "time": 7698.316538333893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239336, "time": 7716.854490041733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240024, "time": 7737.880133152008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 7744.447530508041, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7744.457226514816, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7744.469207763672, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7744.481778383255, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7744.490295886993, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7744.502815723419, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7744.513354063034, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7744.524210929871, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240272, "time": 7751.80567574501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240584, "time": 7761.14213681221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240608, "time": 7762.124712705612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240656, "time": 7763.577783346176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240736, "time": 7765.996282815933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241032, "time": 7774.732112407684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241648, "time": 7793.700473308563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242336, "time": 7814.534545183182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242584, "time": 7821.878419876099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242896, "time": 7831.547146320343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242920, "time": 7832.0572855472565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242968, "time": 7833.509651660919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243048, "time": 7835.959128379822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243344, "time": 7845.143040895462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243896, "time": 7861.72411942482, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 243960, "time": 7863.675189733505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244648, "time": 7884.656643629074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245208, "time": 7901.671288013458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245232, "time": 7902.639966964722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245280, "time": 7904.093586206436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245360, "time": 7906.510096549988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245656, "time": 7915.367312431335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246208, "time": 7932.881716012955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246272, "time": 7934.850432634354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246960, "time": 7955.8980531692505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247144, "time": 7961.2831444740295, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 247520, "time": 7973.0403044223785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247544, "time": 7973.547221422195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247592, "time": 7974.9971125125885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247672, "time": 7977.42569231987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247792, "time": 7981.28107047081, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 247968, "time": 7986.624559640884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249272, "time": 8025.97940826416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249456, "time": 8031.821249485016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249832, "time": 8042.969665765762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249856, "time": 8043.925900220871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249904, "time": 8045.400017499924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249984, "time": 8047.818402767181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 8054.036671161652, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8054.043201684952, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8054.099634885788, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8054.1065056324005, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8054.11199092865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8054.11714887619, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8054.123840808868, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8054.129283428192, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250104, "time": 8056.574044466019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250280, "time": 8062.032346963882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251200, "time": 8090.338442325592, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 251344, "time": 8094.78352689743, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 251584, "time": 8102.0923619270325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252144, "time": 8119.203633308411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252168, "time": 8119.719336032867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252216, "time": 8121.2829604148865, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 252216, "time": 8121.292484283447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252296, "time": 8123.754150867462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252416, "time": 8127.596139192581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252568, "time": 8131.977609395981, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 253592, "time": 8163.115695714951, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 253896, "time": 8172.365832090378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254456, "time": 8189.9559206962585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254480, "time": 8190.909308195114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254528, "time": 8192.393922328949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254608, "time": 8194.813621997833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254728, "time": 8198.277088403702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254880, "time": 8203.198265075684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255904, "time": 8234.462541341782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256208, "time": 8243.759243488312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256768, "time": 8260.751830339432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256792, "time": 8261.26617360115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256840, "time": 8262.722205877304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256873, "time": 8264.682275533676, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.2903269298041047, "train/action_min": 0.0, "train/action_std": 1.8835940242406741, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0013034310576590519, "train/actor_opt_grad_steps": 14950.0, "train/actor_opt_loss": 4.2616196775169515, "train/adv_mag": 0.005241846832544056, "train/adv_max": 0.005063784452368371, "train/adv_mean": 0.0008691964277426251, "train/adv_min": -0.0020119291521720033, "train/adv_std": 0.0009784623957354928, "train/cont_avg": 0.9964581389925373, "train/cont_loss_mean": 0.023528500603725067, "train/cont_loss_std": 0.3256612297782294, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.67692232850808, "train/cont_pos_acc": 0.9999999819110282, "train/cont_pos_loss": 0.0034518627605090537, "train/cont_pred": 0.9965541739368913, "train/cont_rate": 0.9964581389925373, "train/dyn_loss_mean": 1.0000032975305966, "train/dyn_loss_std": 7.614664876322721e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.06475167158256698, "train/extr_critic_critic_opt_grad_steps": 14950.0, "train/extr_critic_critic_opt_loss": 10948.85549547186, "train/extr_critic_mag": 0.04318523703522943, "train/extr_critic_max": 0.04318523703522943, "train/extr_critic_mean": 0.041928582217785254, "train/extr_critic_min": 0.039795363720376696, "train/extr_critic_std": 0.00045649128136646686, "train/extr_return_normed_mag": 0.00771167064409944, "train/extr_return_normed_max": 0.007702338958705836, "train/extr_return_normed_mean": 0.003294691393624708, "train/extr_return_normed_min": 0.0004680459179095368, "train/extr_return_normed_std": 0.0010701704035346298, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.047205442692435796, "train/extr_return_raw_max": 0.047205442692435796, "train/extr_return_raw_mean": 0.042797797364159604, "train/extr_return_raw_min": 0.0399711496516395, "train/extr_return_raw_std": 0.0010701703997699553, "train/extr_reward_mag": 0.0014844699878597733, "train/extr_reward_max": 0.0014844699878597733, "train/extr_reward_mean": 0.0002506105409257041, "train/extr_reward_min": 9.933514381522563e-06, "train/extr_reward_std": 0.00032003962581288604, "train/image_loss_mean": 0.18834986415371965, "train/image_loss_std": 0.10359053391574034, "train/model_loss_mean": 0.8135246809442245, "train/model_loss_std": 0.37649420215122736, "train/model_opt_grad_norm": 40.47523953072467, "train/model_opt_grad_steps": 14934.089552238805, "train/model_opt_loss": 2607.091461029812, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3208.955223880597, "train/policy_entropy_mag": 1.9037014222263697, "train/policy_entropy_max": 1.9037014222263697, "train/policy_entropy_mean": 1.510400374730428, "train/policy_entropy_min": 0.7514239329455504, "train/policy_entropy_std": 0.1723841199864499, "train/policy_logprob_mag": 5.433312506224978, "train/policy_logprob_max": -0.22960005842371664, "train/policy_logprob_mean": -1.5108677190334643, "train/policy_logprob_min": -5.433312506224978, "train/policy_logprob_std": 0.7845355460596322, "train/policy_randomness_mag": 0.9783090608036933, "train/policy_randomness_max": 0.9783090608036933, "train/policy_randomness_mean": 0.7761922923486624, "train/policy_randomness_min": 0.38615553666703145, "train/policy_randomness_std": 0.08858791907405972, "train/post_ent_mag": 56.91534881212225, "train/post_ent_max": 56.91534881212225, "train/post_ent_mean": 56.02077535373061, "train/post_ent_min": 55.32350883673673, "train/post_ent_std": 0.29413712002448184, "train/prior_ent_mag": 58.51573424078339, "train/prior_ent_max": 58.51573424078339, "train/prior_ent_mean": 55.379029743707, "train/prior_ent_min": 52.46700250805907, "train/prior_ent_std": 1.0409296504893706, "train/rep_loss_mean": 1.0000032975305966, "train/rep_loss_std": 7.614664876322721e-05, "train/reward_avg": 0.00011217107881087606, "train/reward_loss_mean": 0.0016443183928246225, "train/reward_loss_std": 0.04664667965470702, "train/reward_max_data": 0.1091106972884183, "train/reward_max_pred": 0.0010201770867874374, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00014858949510366146, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.83477125745831, "train/reward_pred": 6.136359862371612e-05, "train/reward_rate": 0.00017004819651741295, "train_stats/mean_log_entropy": 1.4783958217553925, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014772115275263786, "report/cont_loss_std": 0.2438652515411377, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.527421474456787, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003984153736382723, "report/cont_pred": 0.9960238933563232, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.17016221582889557, "report/image_loss_std": 0.09169337898492813, "report/model_loss_mean": 0.7850600481033325, "report/model_loss_std": 0.2628716826438904, "report/post_ent_mag": 49.90576934814453, "report/post_ent_max": 49.90576934814453, "report/post_ent_mean": 49.305789947509766, "report/post_ent_min": 48.90059280395508, "report/post_ent_std": 0.18856728076934814, "report/prior_ent_mag": 55.05317687988281, "report/prior_ent_max": 55.05317687988281, "report/prior_ent_mean": 52.62217712402344, "report/prior_ent_min": 50.164794921875, "report/prior_ent_std": 0.8981764316558838, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00012568384408950806, "report/reward_loss_std": 0.000400207209168002, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0011070966720581055, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00012568384408950806, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.166733171790838e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020166093483567238, "eval/cont_loss_std": 0.2985265552997589, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.527421474456787, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003984153736382723, "eval/cont_pred": 0.9960238933563232, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20689529180526733, "eval/image_loss_std": 0.10349186509847641, "eval/model_loss_mean": 0.8271774649620056, "eval/model_loss_std": 0.3157692849636078, "eval/post_ent_mag": 49.93535614013672, "eval/post_ent_max": 49.93535614013672, "eval/post_ent_mean": 49.30026626586914, "eval/post_ent_min": 48.862159729003906, "eval/post_ent_std": 0.20381557941436768, "eval/prior_ent_mag": 55.001426696777344, "eval/prior_ent_max": 55.001426696777344, "eval/prior_ent_mean": 52.75725555419922, "eval/prior_ent_min": 50.36053466796875, "eval/prior_ent_std": 0.9032809138298035, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00011606048792600632, "eval/reward_loss_std": 0.00035469510476104915, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0010906457901000977, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00011606048792600632, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.769815132021904e-05, "eval/reward_rate": 0.0, "replay/size": 256369.0, "replay/inserts": 32176.0, "replay/samples": 32176.0, "replay/insert_wait_avg": 1.250037739135803e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.414420643355466e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61168.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1404286618876209e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2320513725281, "timer/env.step_count": 4022.0, "timer/env.step_total": 38.08509159088135, "timer/env.step_frac": 0.03807625594342894, "timer/env.step_avg": 0.009469192339851155, "timer/env.step_min": 0.0076503753662109375, "timer/env.step_max": 0.03777337074279785, "timer/replay._sample_count": 32176.0, "timer/replay._sample_total": 16.84538698196411, "timer/replay._sample_frac": 0.016841478893671432, "timer/replay._sample_avg": 0.0005235388793499537, "timer/replay._sample_min": 0.00038170814514160156, "timer/replay._sample_max": 0.028357267379760742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4889.0, "timer/agent.policy_total": 51.27894878387451, "timer/agent.policy_frac": 0.05126705219404742, "timer/agent.policy_avg": 0.01048863750948548, "timer/agent.policy_min": 0.008962392807006836, "timer/agent.policy_max": 0.08884811401367188, "timer/dataset_train_count": 2011.0, "timer/dataset_train_total": 0.21348786354064941, "timer/dataset_train_frac": 0.00021343833488208993, "timer/dataset_train_avg": 0.00010616005148714541, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.00020575523376464844, "timer/agent.train_count": 2011.0, "timer/agent.train_total": 896.9351103305817, "timer/agent.train_frac": 0.8967270235939737, "timer/agent.train_avg": 0.4460144755497671, "timer/agent.train_min": 0.43323802947998047, "timer/agent.train_max": 0.7074663639068604, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4752521514892578, "timer/agent.report_frac": 0.00047514189416057224, "timer/agent.report_avg": 0.2376260757446289, "timer/agent.report_min": 0.22925925254821777, "timer/agent.report_max": 0.24599289894104004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098722465519105e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 32.167994101563735}
{"step": 256920, "time": 8265.88502907753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257040, "time": 8269.7468957901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257192, "time": 8274.290031194687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258216, "time": 8305.496235847473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258520, "time": 8314.71890258789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259080, "time": 8331.75970196724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259104, "time": 8332.712095737457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259152, "time": 8334.19600057602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259232, "time": 8336.613785266876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259352, "time": 8340.073877334595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259504, "time": 8344.924548864365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 8365.304666757584, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8365.332398891449, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8365.338969230652, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8365.34750533104, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8365.354027032852, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8365.362098455429, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8365.370646238327, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8365.378394842148, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260528, "time": 8381.335201263428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260832, "time": 8390.690741062164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261392, "time": 8407.798843622208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261416, "time": 8408.308338880539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261464, "time": 8409.760089874268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261544, "time": 8412.174691677094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261664, "time": 8416.051901817322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261816, "time": 8420.560837984085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262840, "time": 8452.17463684082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263144, "time": 8461.382118940353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263200, "time": 8463.30964255333, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 263504, "time": 8472.525340080261, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 263728, "time": 8479.30311512947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263776, "time": 8480.841183423996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263976, "time": 8486.71908211708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264128, "time": 8491.55294084549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265152, "time": 8522.658311843872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265456, "time": 8531.923884868622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265512, "time": 8533.39661359787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265816, "time": 8542.711420297623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266040, "time": 8549.514286756516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266088, "time": 8550.96175646782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266288, "time": 8557.239670276642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266440, "time": 8561.626959323883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267464, "time": 8592.653768539429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267768, "time": 8602.79724407196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267824, "time": 8604.733205080032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268128, "time": 8613.92416381836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268352, "time": 8620.696995258331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268400, "time": 8622.145989179611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268600, "time": 8627.983702659607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 268752, "time": 8632.90968132019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269224, "time": 8646.950304985046, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 269776, "time": 8664.039383888245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 8679.223451852798, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8679.231023073196, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8679.239302873611, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8679.247344255447, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8679.254682064056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8679.26331949234, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8679.2709171772, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8679.278230667114, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270136, "time": 8680.727524757385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270440, "time": 8690.46818614006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270664, "time": 8697.22097992897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270712, "time": 8698.694617271423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270912, "time": 8704.959325313568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271064, "time": 8709.34399318695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271536, "time": 8723.993885993958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272088, "time": 8740.447701454163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272448, "time": 8751.779431581497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272752, "time": 8761.006052494049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272976, "time": 8767.803857088089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273024, "time": 8769.26082777977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273224, "time": 8775.06948184967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273376, "time": 8779.900610685349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273848, "time": 8794.108049631119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274400, "time": 8811.0929646492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274760, "time": 8821.844351053238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275064, "time": 8831.121015787125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275288, "time": 8837.907284736633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275336, "time": 8839.38944864273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275472, "time": 8843.809279680252, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 275688, "time": 8850.159620046616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276160, "time": 8864.730582475662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276560, "time": 8876.955664634705, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 276712, "time": 8881.350839614868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277072, "time": 8892.521012067795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277600, "time": 8908.615474939346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277648, "time": 8910.070414543152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277784, "time": 8913.969848155975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278000, "time": 8920.71575641632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278472, "time": 8934.897420883179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278872, "time": 8947.53167438507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279024, "time": 8952.344202280045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279384, "time": 8963.121557474136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279912, "time": 8979.105266809464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279960, "time": 8980.577638864517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 8985.18903684616, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 280072, "time": 8989.28551197052, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8989.292831659317, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8989.301123142242, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8989.309693574905, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8989.317942142487, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8989.325699090958, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 8989.333917617798, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280096, "time": 8990.323962688446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280312, "time": 8996.726093530655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280584, "time": 9004.948214292526, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 280784, "time": 9011.229192733765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281184, "time": 9023.549499988556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281336, "time": 9027.940234422684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282224, "time": 9055.125855445862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282272, "time": 9056.58259177208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282408, "time": 9060.488611459732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282624, "time": 9067.26555967331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282768, "time": 9071.633017539978, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 282896, "time": 9075.521420240402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283096, "time": 9081.421877622604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283496, "time": 9093.492974042892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283648, "time": 9098.29722070694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284208, "time": 9115.359898805618, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 284536, "time": 9125.162538766861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284584, "time": 9126.6265707016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284936, "time": 9137.374451875687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285080, "time": 9141.885418176651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285208, "time": 9145.793294668198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285408, "time": 9152.10536813736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285808, "time": 9164.248855352402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286520, "time": 9185.710843324661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286848, "time": 9196.36281967163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286896, "time": 9197.811067819595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287248, "time": 9208.591771364212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287392, "time": 9212.97755599022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287520, "time": 9216.87768149376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287720, "time": 9222.720545053482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288120, "time": 9234.967925071716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288832, "time": 9256.739202260971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289081, "time": 9265.116667985916, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6669278286471227, "train/action_min": 0.0, "train/action_std": 1.9289968633415675, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0018029069122547136, "train/actor_opt_grad_steps": 16965.0, "train/actor_opt_loss": 3.154189393164055, "train/adv_mag": 0.012430950040274327, "train/adv_max": 0.012107255601204268, "train/adv_mean": 0.001243092658148388, "train/adv_min": -0.0037840532489342264, "train/adv_std": 0.0018907883018658652, "train/cont_avg": 0.996470838490099, "train/cont_loss_mean": 0.023454573074595468, "train/cont_loss_std": 0.32579240660266123, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6646160914166135, "train/cont_pos_acc": 0.9999999861315926, "train/cont_pos_loss": 0.003478558095504004, "train/cont_pred": 0.996527486803508, "train/cont_rate": 0.996470838490099, "train/dyn_loss_mean": 1.0000007069937074, "train/dyn_loss_std": 2.2596747344728595e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09358195101267124, "train/extr_critic_critic_opt_grad_steps": 16965.0, "train/extr_critic_critic_opt_loss": 12963.748452970298, "train/extr_critic_mag": 0.07459287655235518, "train/extr_critic_max": 0.07459287655235518, "train/extr_critic_mean": 0.07122336495852116, "train/extr_critic_min": 0.06715507082419821, "train/extr_critic_std": 0.0012382996884649528, "train/extr_return_normed_mag": 0.017798661411103634, "train/extr_return_normed_max": 0.017776652174715947, "train/extr_return_normed_mean": 0.005666764388501863, "train/extr_return_normed_min": 0.0005586663869642975, "train/extr_return_normed_std": 0.0023223211889968963, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08457635280371893, "train/extr_return_raw_max": 0.08457635280371893, "train/extr_return_raw_mean": 0.07246646899176706, "train/extr_return_raw_min": 0.06735836699752525, "train/extr_return_raw_std": 0.002322321199514617, "train/extr_reward_mag": 0.009130860909376995, "train/extr_reward_max": 0.009130860909376995, "train/extr_reward_mean": 0.0003870291012651368, "train/extr_reward_min": -3.1477153891384015e-05, "train/extr_reward_std": 0.0010803668686427351, "train/image_loss_mean": 0.1726266758719293, "train/image_loss_std": 0.10650681435029105, "train/model_loss_mean": 0.7975421102330236, "train/model_loss_std": 0.37271042986966596, "train/model_opt_grad_norm": 38.54937184683167, "train/model_opt_grad_steps": 16947.39108910891, "train/model_opt_loss": 2152.446333177019, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2698.019801980198, "train/policy_entropy_mag": 1.839081858054246, "train/policy_entropy_max": 1.839081858054246, "train/policy_entropy_mean": 1.3441003037266213, "train/policy_entropy_min": 0.5312702613006725, "train/policy_entropy_std": 0.22080898129999046, "train/policy_logprob_mag": 5.544077693825901, "train/policy_logprob_max": -0.14262817452873777, "train/policy_logprob_mean": -1.3443820590134894, "train/policy_logprob_min": -5.544077693825901, "train/policy_logprob_std": 0.7944400953774405, "train/policy_randomness_mag": 0.9451011723220939, "train/policy_randomness_max": 0.9451011723220939, "train/policy_randomness_mean": 0.6907309621277422, "train/policy_randomness_min": 0.2730189221219556, "train/policy_randomness_std": 0.11347337603790335, "train/post_ent_mag": 48.042895534250995, "train/post_ent_max": 48.042895534250995, "train/post_ent_mean": 47.42238301569873, "train/post_ent_min": 46.8996468534564, "train/post_ent_std": 0.21190620523573148, "train/prior_ent_mag": 49.97644186492013, "train/prior_ent_max": 49.97644186492013, "train/prior_ent_mean": 47.24427753863949, "train/prior_ent_min": 45.012876397312276, "train/prior_ent_std": 0.7991597050487405, "train/rep_loss_mean": 1.0000007069937074, "train/rep_loss_std": 2.2596747344728595e-05, "train/reward_avg": 8.624992785758643e-05, "train/reward_loss_mean": 0.0014604137320587836, "train/reward_loss_std": 0.03994823071976984, "train/reward_max_data": 0.08338490143270776, "train/reward_max_pred": 0.0036033787349663156, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00015742308218844722, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.646910235285759, "train/reward_pred": 6.42344060510692e-05, "train/reward_rate": 0.00016920637376237623, "train_stats/mean_log_entropy": 1.4104962417509703, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.04182315617799759, "report/cont_loss_std": 0.45856374502182007, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.5669379234313965, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0037938517052680254, "report/cont_pred": 0.9962129592895508, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.21054962277412415, "report/image_loss_std": 0.11432786285877228, "report/model_loss_mean": 0.8524421453475952, "report/model_loss_std": 0.4702759385108948, "report/post_ent_mag": 44.24599075317383, "report/post_ent_max": 44.24599075317383, "report/post_ent_mean": 43.65435791015625, "report/post_ent_min": 43.113304138183594, "report/post_ent_std": 0.2125285267829895, "report/prior_ent_mag": 46.62417221069336, "report/prior_ent_max": 46.62417221069336, "report/prior_ent_mean": 43.283653259277344, "report/prior_ent_min": 41.2611083984375, "report/prior_ent_std": 0.9158039093017578, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 6.932578980922699e-05, "report/reward_loss_std": 0.0003409534110687673, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0030721426010131836, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 6.932578980922699e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 2.7522561140358448e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020377883687615395, "eval/cont_loss_std": 0.30562278628349304, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.658444404602051, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003811578033491969, "eval/cont_pred": 0.9961967468261719, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20793449878692627, "eval/image_loss_std": 0.11192598938941956, "eval/model_loss_mean": 0.8284052610397339, "eval/model_loss_std": 0.33529382944107056, "eval/post_ent_mag": 44.25348663330078, "eval/post_ent_max": 44.25348663330078, "eval/post_ent_mean": 43.666725158691406, "eval/post_ent_min": 43.12646484375, "eval/post_ent_std": 0.20812766253948212, "eval/prior_ent_mag": 47.24480438232422, "eval/prior_ent_max": 47.24480438232422, "eval/prior_ent_mean": 43.29401397705078, "eval/prior_ent_min": 41.420127868652344, "eval/prior_ent_std": 0.9150137901306152, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 9.279279038310051e-05, "eval/reward_loss_std": 0.000538140011485666, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0041391849517822266, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 9.279279038310051e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.711809404194355e-05, "eval/reward_rate": 0.0, "replay/size": 288577.0, "replay/inserts": 32208.0, "replay/samples": 32208.0, "replay/insert_wait_avg": 1.245027919699171e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.617136049910202e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68104.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1217291654874984e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4153180122375, "timer/env.step_count": 4026.0, "timer/env.step_total": 37.70975732803345, "timer/env.step_frac": 0.03769410228839795, "timer/env.step_avg": 0.009366556713371447, "timer/env.step_min": 0.007655620574951172, "timer/env.step_max": 0.03606724739074707, "timer/replay._sample_count": 32208.0, "timer/replay._sample_total": 16.85364580154419, "timer/replay._sample_frac": 0.016846649084733455, "timer/replay._sample_avg": 0.0005232751428696035, "timer/replay._sample_min": 0.0003933906555175781, "timer/replay._sample_max": 0.010419130325317383, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4893.0, "timer/agent.policy_total": 50.7475266456604, "timer/agent.policy_frac": 0.050726459033526745, "timer/agent.policy_avg": 0.01037145445445747, "timer/agent.policy_min": 0.008733034133911133, "timer/agent.policy_max": 0.08951330184936523, "timer/dataset_train_count": 2013.0, "timer/dataset_train_total": 0.21318864822387695, "timer/dataset_train_frac": 0.00021310014389570666, "timer/dataset_train_avg": 0.00010590593553098707, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.00043272972106933594, "timer/agent.train_count": 2013.0, "timer/agent.train_total": 898.4645159244537, "timer/agent.train_frac": 0.8980915223385887, "timer/agent.train_avg": 0.4463311057746914, "timer/agent.train_min": 0.43584418296813965, "timer/agent.train_max": 1.3794612884521484, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4649794101715088, "timer/agent.report_frac": 0.00046478637601770603, "timer/agent.report_avg": 0.2324897050857544, "timer/agent.report_min": 0.22297286987304688, "timer/agent.report_max": 0.24200654029846191, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.695487976074219e-05, "timer/dataset_eval_frac": 3.693953810520336e-08, "timer/dataset_eval_avg": 3.695487976074219e-05, "timer/dataset_eval_min": 3.695487976074219e-05, "timer/dataset_eval_max": 3.695487976074219e-05, "fps": 32.19411115914196}
{"step": 289160, "time": 9267.27614068985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289168, "time": 9267.7477684021, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 289560, "time": 9279.376690149307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289704, "time": 9283.708404302597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289832, "time": 9287.621781110764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289856, "time": 9288.565730810165, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 289856, "time": 9288.574037313461, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 290032, "time": 9294.008916854858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 9299.863431453705, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9299.878386735916, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9299.890009403229, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9299.900082826614, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9299.914457321167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9299.922686815262, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9299.930699825287, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9299.941769361496, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290088, "time": 9300.905987501144, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 290432, "time": 9311.488996267319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291120, "time": 9332.321568965912, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 291144, "time": 9332.833307266235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292016, "time": 9359.396653652191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292144, "time": 9363.265621900558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292168, "time": 9363.777735471725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292168, "time": 9363.78654384613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292344, "time": 9369.122029066086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292744, "time": 9381.291288852692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293432, "time": 9402.145951747894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293456, "time": 9403.095358133316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294120, "time": 9422.936243772507, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 294328, "time": 9429.183933258057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294456, "time": 9433.077447652817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294480, "time": 9434.031385660172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294656, "time": 9439.341975450516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295056, "time": 9451.98821234703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295200, "time": 9456.332050561905, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 295744, "time": 9472.792359113693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295768, "time": 9473.300033807755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296048, "time": 9481.956980466843, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 296432, "time": 9493.638179540634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296528, "time": 9496.536178827286, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 296720, "time": 9502.473353147507, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 296768, "time": 9503.956179380417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296792, "time": 9504.466994524002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296968, "time": 9509.771004915237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297088, "time": 9513.611287117004, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 297368, "time": 9521.795949220657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297672, "time": 9531.085230588913, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 297928, "time": 9538.822318792343, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 298080, "time": 9543.629014253616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298720, "time": 9563.153779745102, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 298840, "time": 9566.581581115723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299080, "time": 9573.819481134415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299104, "time": 9574.769482374191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299232, "time": 9578.634001970291, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 299280, "time": 9580.083367586136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299680, "time": 9592.243163585663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299696, "time": 9592.73180103302, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 299912, "time": 9599.083086967468, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 299984, "time": 9601.482789039612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299992, "time": 9601.50857758522, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 9603.578938245773, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 300040, "time": 9605.199362754822, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 300040, "time": 9608.361231088638, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9608.368024587631, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9608.37474656105, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9608.381361246109, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9608.390343427658, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9608.398052215576, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300312, "time": 9616.588950157166, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 301032, "time": 9638.376738071442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301152, "time": 9642.215109825134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301416, "time": 9649.936646223068, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 301416, "time": 9649.943278074265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301464, "time": 9651.48983335495, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 301592, "time": 9655.343762159348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301688, "time": 9658.216827392578, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 301784, "time": 9661.141508579254, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 301936, "time": 9665.939885377884, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 302192, "time": 9673.673692464828, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 302224, "time": 9674.63966870308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302296, "time": 9676.59710597992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302480, "time": 9682.496804475784, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 302624, "time": 9686.843448638916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302752, "time": 9690.7192568779, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 303640, "time": 9717.967574596405, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 303728, "time": 9720.835491895676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303928, "time": 9726.667543888092, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 304000, "time": 9729.069501399994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304096, "time": 9731.95389866829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304248, "time": 9736.358489513397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304536, "time": 9745.178493022919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304608, "time": 9747.58239197731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305952, "time": 9788.150913953781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306040, "time": 9790.609978437424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306240, "time": 9796.856766700745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306312, "time": 9798.801047801971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306408, "time": 9801.815542936325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306560, "time": 9806.644214391708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306696, "time": 9810.537685394287, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 306920, "time": 9817.326980829239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308000, "time": 9850.156751394272, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 308032, "time": 9851.125692367554, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 308336, "time": 9860.306950807571, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 308352, "time": 9860.862352371216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308552, "time": 9866.67996263504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308624, "time": 9869.082905292511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308848, "time": 9875.85342335701, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 309008, "time": 9880.687415361404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309496, "time": 9895.285434246063, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 9911.752059936523, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 310024, "time": 9913.763237953186, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 310024, "time": 9914.370792388916, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 310024, "time": 9914.66369843483, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 310024, "time": 9916.193097352982, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 310024, "time": 9917.235276222229, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9917.246737718582, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9917.2573158741, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9917.266113758087, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9917.276000022888, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9917.284895658493, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310312, "time": 9926.089517831802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310344, "time": 9927.053045511246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310648, "time": 9936.221431970596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310664, "time": 9936.709421396255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310936, "time": 9944.884692430496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311160, "time": 9951.731983184814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311320, "time": 9957.014454364777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311624, "time": 9966.16125535965, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 311808, "time": 9971.950431585312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312008, "time": 9977.75111246109, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 312624, "time": 9996.611193656921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312656, "time": 9997.576802492142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312960, "time": 10006.722257852554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312976, "time": 10007.206617355347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313248, "time": 10015.453714132309, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 313632, "time": 10027.077767848969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313752, "time": 10030.499665498734, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 313936, "time": 10036.264944314957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314120, "time": 10041.689431905746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314320, "time": 10047.913054704666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314680, "time": 10058.56194806099, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 314936, "time": 10066.24322462082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315272, "time": 10076.424212217331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315288, "time": 10076.920036315918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315536, "time": 10084.63902759552, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 315616, "time": 10087.05933189392, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 315944, "time": 10096.789560079575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316064, "time": 10100.715677022934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316080, "time": 10101.20268702507, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 316248, "time": 10106.065171718597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316632, "time": 10117.659834861755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316992, "time": 10128.724570274353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317216, "time": 10135.591270923615, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 317216, "time": 10135.601155519485, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 317448, "time": 10142.38144493103, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 317584, "time": 10146.700723648071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317600, "time": 10147.18659734726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317712, "time": 10150.583750009537, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 318256, "time": 10167.057786464691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318376, "time": 10170.471283912659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318560, "time": 10176.226744890213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318616, "time": 10177.69049358368, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 319008, "time": 10189.814799547195, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 319152, "time": 10194.255381822586, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 319304, "time": 10198.59569478035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319488, "time": 10204.550019025803, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 319528, "time": 10205.876960754395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319760, "time": 10213.083836317062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319896, "time": 10216.970949172974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 10221.334838628769, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 320008, "time": 10221.915984630585, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 320008, "time": 10222.391594648361, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 320008, "time": 10222.474682569504, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 320008, "time": 10222.860721349716, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 320008, "time": 10222.947510957718, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 320008, "time": 10224.303264856339, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 320008, "time": 10224.540180921555, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 320480, "time": 10238.969086647034, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 320568, "time": 10241.400922060013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320792, "time": 10248.171573162079, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 321329, "time": 10265.12819981575, "train_stats/mean_log_entropy": 0.47412963057386465, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.38496239505597, "train/action_min": 0.0, "train/action_std": 1.6746463473163433, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004018015089787691, "train/actor_opt_grad_steps": 18980.0, "train/actor_opt_loss": 15.849320661767724, "train/adv_mag": 0.05491348263339617, "train/adv_max": 0.05365736864099455, "train/adv_mean": 0.006458416036199124, "train/adv_min": -0.010982615326470997, "train/adv_std": 0.00744619878039079, "train/cont_avg": 0.9963852611940298, "train/cont_loss_mean": 0.023713468682873457, "train/cont_loss_std": 0.3224307444857072, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.579852939257162, "train/cont_pos_acc": 0.9999999839868119, "train/cont_pos_loss": 0.003551931243241575, "train/cont_pred": 0.9964534954645148, "train/cont_rate": 0.9963852611940298, "train/dyn_loss_mean": 1.0000048810569802, "train/dyn_loss_std": 0.00012496664606970713, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.6131120060816111, "train/extr_critic_critic_opt_grad_steps": 18980.0, "train/extr_critic_critic_opt_loss": 10198.672402756723, "train/extr_critic_mag": 0.19499511801781347, "train/extr_critic_max": 0.19499511801781347, "train/extr_critic_mean": 0.18832774100760322, "train/extr_critic_min": 0.17807735435998262, "train/extr_critic_std": 0.0032382857117313076, "train/extr_return_normed_mag": 0.06835253881429558, "train/extr_return_normed_max": 0.06746147791692866, "train/extr_return_normed_mean": 0.018275961117807077, "train/extr_return_normed_min": 0.0009935094942500936, "train/extr_return_normed_std": 0.008269784434591953, "train/extr_return_rate": 0.0018190300133078133, "train/extr_return_raw_mag": 0.2439716486491967, "train/extr_return_raw_max": 0.2439716486491967, "train/extr_return_raw_mean": 0.19478614127902844, "train/extr_return_raw_min": 0.17750368037478842, "train/extr_return_raw_std": 0.008269784446175567, "train/extr_reward_mag": 0.04488124894858593, "train/extr_reward_max": 0.04488124894858593, "train/extr_reward_mean": 0.0013907192618472749, "train/extr_reward_min": 8.415819993659632e-07, "train/extr_reward_std": 0.004244358160802909, "train/image_loss_mean": 0.15987249804818215, "train/image_loss_std": 0.10781007630759804, "train/model_loss_mean": 0.7857225869425494, "train/model_loss_std": 0.3807971396330577, "train/model_opt_grad_norm": 35.22895007346993, "train/model_opt_grad_steps": 18960.572139303484, "train/model_opt_loss": 2170.107706705729, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2773.63184079602, "train/policy_entropy_mag": 1.6427996603410635, "train/policy_entropy_max": 1.6427996603410635, "train/policy_entropy_mean": 0.4931417239542624, "train/policy_entropy_min": 0.0668280833766828, "train/policy_entropy_std": 0.33734849480847223, "train/policy_logprob_mag": 6.539890652272239, "train/policy_logprob_max": -0.008952088371401106, "train/policy_logprob_mean": -0.49320745386591003, "train/policy_logprob_min": -6.539890652272239, "train/policy_logprob_std": 0.8912390959796621, "train/policy_randomness_mag": 0.8442320725811061, "train/policy_randomness_max": 0.8442320725811061, "train/policy_randomness_mean": 0.25342472916960124, "train/policy_randomness_min": 0.034342843075445044, "train/policy_randomness_std": 0.1733628434698973, "train/post_ent_mag": 41.23393500029151, "train/post_ent_max": 41.23393500029151, "train/post_ent_mean": 40.732405800131424, "train/post_ent_min": 40.341881196890306, "train/post_ent_std": 0.15676071694982585, "train/prior_ent_mag": 42.85205981506044, "train/prior_ent_max": 42.85205981506044, "train/prior_ent_mean": 40.33257234867533, "train/prior_ent_min": 38.90920052599551, "train/prior_ent_std": 0.6587021936528126, "train/rep_loss_mean": 1.0000048810569802, "train/rep_loss_std": 0.00012496664606970713, "train/reward_avg": 0.00017095916798518998, "train/reward_loss_mean": 0.002133665586687365, "train/reward_loss_std": 0.0551254445295917, "train/reward_max_data": 0.14884950227998384, "train/reward_max_pred": 0.011023532098798609, "train/reward_neg_acc": 0.9999951414800995, "train/reward_neg_loss": 0.00021641040880760682, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.866804786350416, "train/reward_pred": 9.806656663245823e-05, "train/reward_rate": 0.0002769356343283582, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.033909253776073456, "report/cont_loss_std": 0.3951299786567688, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.173854351043701, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003614886198192835, "report/cont_pred": 0.9963811635971069, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1348610669374466, "report/image_loss_std": 0.10354814678430557, "report/model_loss_mean": 0.7690415978431702, "report/model_loss_std": 0.40499016642570496, "report/post_ent_mag": 39.86668395996094, "report/post_ent_max": 39.86668395996094, "report/post_ent_mean": 39.396644592285156, "report/post_ent_min": 39.03521728515625, "report/post_ent_std": 0.13666968047618866, "report/prior_ent_mag": 41.71769714355469, "report/prior_ent_max": 41.71769714355469, "report/prior_ent_mean": 39.361080169677734, "report/prior_ent_min": 38.132198333740234, "report/prior_ent_std": 0.6946854591369629, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00027123885229229927, "report/reward_loss_std": 0.001295986003242433, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.012538433074951172, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00027123885229229927, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00010504957754164934, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03829772025346756, "eval/cont_loss_std": 0.45162713527679443, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.912991523742676, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003672810737043619, "eval/cont_pred": 0.9963412880897522, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2064284086227417, "eval/image_loss_std": 0.12306788563728333, "eval/model_loss_mean": 0.8449344635009766, "eval/model_loss_std": 0.46243804693222046, "eval/post_ent_mag": 39.870147705078125, "eval/post_ent_max": 39.870147705078125, "eval/post_ent_mean": 39.389610290527344, "eval/post_ent_min": 39.062286376953125, "eval/post_ent_std": 0.14427968859672546, "eval/prior_ent_mag": 41.76374053955078, "eval/prior_ent_max": 41.76374053955078, "eval/prior_ent_mean": 39.19337844848633, "eval/prior_ent_min": 38.10469436645508, "eval/prior_ent_std": 0.5335590839385986, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.000208304263651371, "eval/reward_loss_std": 0.0008228334481827915, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.004566073417663574, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000208304263651371, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.889512926340103e-05, "eval/reward_rate": 0.0, "replay/size": 320825.0, "replay/inserts": 32248.0, "replay/samples": 32240.0, "replay/insert_wait_avg": 1.2689904284163758e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.822850797667397e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 76760.0, "eval_replay/inserts": 8656.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1468385372056097e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.995911359787, "timer/env.step_count": 4031.0, "timer/env.step_total": 38.5425591468811, "timer/env.step_frac": 0.038542716734182664, "timer/env.step_avg": 0.009561537868241404, "timer/env.step_min": 0.007751941680908203, "timer/env.step_max": 0.03868889808654785, "timer/replay._sample_count": 32240.0, "timer/replay._sample_total": 16.96768283843994, "timer/replay._sample_frac": 0.016967752213473967, "timer/replay._sample_avg": 0.0005262928920111644, "timer/replay._sample_min": 0.00038623809814453125, "timer/replay._sample_max": 0.011895418167114258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5113.0, "timer/agent.policy_total": 53.12405753135681, "timer/agent.policy_frac": 0.05312427473740279, "timer/agent.policy_avg": 0.010389997561384081, "timer/agent.policy_min": 0.008517026901245117, "timer/agent.policy_max": 0.08795619010925293, "timer/dataset_train_count": 2015.0, "timer/dataset_train_total": 0.21520614624023438, "timer/dataset_train_frac": 0.00021520702614433559, "timer/dataset_train_avg": 0.00010680205768746122, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0007367134094238281, "timer/agent.train_count": 2015.0, "timer/agent.train_total": 892.4340715408325, "timer/agent.train_frac": 0.8924377203975837, "timer/agent.train_avg": 0.44289532086393674, "timer/agent.train_min": 0.43361496925354004, "timer/agent.train_max": 0.7069258689880371, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4764556884765625, "timer/agent.report_frac": 0.00047645763654041506, "timer/agent.report_avg": 0.23822784423828125, "timer/agent.report_min": 0.2293074131011963, "timer/agent.report_max": 0.2471482753753662, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.12329615626473e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 32.24759484302868}
{"step": 321616, "time": 10274.084072113037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321800, "time": 10279.444053649902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321840, "time": 10280.979724407196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322072, "time": 10287.828889846802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322208, "time": 10292.191458940506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322792, "time": 10309.620540618896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322880, "time": 10312.584235429764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323104, "time": 10319.388679981232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323928, "time": 10344.2630610466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324112, "time": 10350.094276428223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324152, "time": 10351.090529203415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324384, "time": 10358.323522806168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324520, "time": 10362.230053186417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325104, "time": 10380.284475326538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325192, "time": 10382.729062795639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325416, "time": 10389.519593000412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326240, "time": 10414.79186463356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326424, "time": 10420.175333976746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326464, "time": 10421.635826349258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326696, "time": 10428.521728992462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326832, "time": 10433.051178693771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327416, "time": 10450.588009357452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327504, "time": 10453.494243144989, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327728, "time": 10460.899916172028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328552, "time": 10485.799188613892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328736, "time": 10491.680536270142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328776, "time": 10492.70247888565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329008, "time": 10500.008706092834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329144, "time": 10503.939819812775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329728, "time": 10522.010966062546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329816, "time": 10524.47760105133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330040, "time": 10531.372512578964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 10534.832125663757, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 330096, "time": 10534.922037124634, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 330096, "time": 10536.560797691345, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 330096, "time": 10538.034789800644, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 330096, "time": 10539.085841655731, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10539.11851978302, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10539.127310991287, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10539.135116577148, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10539.144981384277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10539.15362405777, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330272, "time": 10544.488782644272, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 330312, "time": 10545.484419345856, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 330792, "time": 10560.211620092392, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 330864, "time": 10562.656892061234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331048, "time": 10568.052605867386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331200, "time": 10572.898619174957, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 331320, "time": 10576.34781241417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331560, "time": 10583.751897096634, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 332352, "time": 10608.039626121521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332584, "time": 10615.013313293457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332624, "time": 10616.46677327156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333104, "time": 10631.059275388718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333360, "time": 10638.836658716202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333496, "time": 10642.826030015945, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 333512, "time": 10643.31563949585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333632, "time": 10647.205297470093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333872, "time": 10654.505548238754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334200, "time": 10664.30918264389, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 334664, "time": 10678.484639644623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334896, "time": 10685.799127578735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335168, "time": 10694.072643518448, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 335416, "time": 10701.464195013046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335640, "time": 10708.321215867996, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 335672, "time": 10709.303158283234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335808, "time": 10713.669972896576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335824, "time": 10714.163332223892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336160, "time": 10724.896275758743, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 336184, "time": 10725.409729719162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336200, "time": 10725.902684211731, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 336344, "time": 10730.352252721786, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 336512, "time": 10735.710093259811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336584, "time": 10737.669711828232, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 336584, "time": 10737.678551197052, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 337480, "time": 10765.009885072708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337728, "time": 10772.80359864235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338472, "time": 10795.24895453453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338496, "time": 10796.208763837814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338656, "time": 10801.082685709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338736, "time": 10803.51973605156, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 338824, "time": 10805.971854925156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338896, "time": 10808.391099214554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338896, "time": 10808.401340961456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339056, "time": 10813.283257484436, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 339304, "time": 10820.657616138458, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 339336, "time": 10821.658317804337, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 339528, "time": 10827.514755010605, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 339792, "time": 10835.795147180557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 10850.135117292404, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10850.18780040741, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10850.197482585907, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10850.205273389816, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10850.215731620789, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10850.235668182373, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10850.252368927002, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10850.261580467224, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340584, "time": 10865.47047996521, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 341016, "time": 10878.617728710175, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 341048, "time": 10879.585752248764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341208, "time": 10884.544670820236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341368, "time": 10889.389964580536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341616, "time": 10897.163253545761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341648, "time": 10898.146313428879, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 341648, "time": 10898.153519630432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341792, "time": 10902.53581905365, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 341840, "time": 10904.002141952515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341864, "time": 10904.514705896378, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 342064, "time": 10910.891656398773, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 342104, "time": 10911.881849765778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342192, "time": 10914.779250383377, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 342336, "time": 10919.135266542435, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 343056, "time": 10941.254581212997, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 343336, "time": 10949.612465381622, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 343360, "time": 10950.57205414772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343592, "time": 10957.410422801971, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 343680, "time": 10960.323655366898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343832, "time": 10964.757472515106, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 343848, "time": 10965.25451374054, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 343960, "time": 10968.68592429161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343984, "time": 10969.636010885239, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 344104, "time": 10973.704981327057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344152, "time": 10975.198789596558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344592, "time": 10988.773920536041, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 344648, "time": 10990.241420030594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344736, "time": 10993.111045122147, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 345176, "time": 11006.533480167389, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 345368, "time": 11012.387943983078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345536, "time": 11017.697417497635, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 345904, "time": 11028.867393255234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346144, "time": 11036.226288557053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346280, "time": 11041.240914344788, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 346344, "time": 11043.170392751694, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 346416, "time": 11045.586840629578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346464, "time": 11047.05202960968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346800, "time": 11057.209671497345, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 346904, "time": 11060.18499660492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347048, "time": 11064.62659072876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347200, "time": 11069.488022565842, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 347400, "time": 11075.336129665375, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 347488, "time": 11078.273937940598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347520, "time": 11079.275957345963, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 347808, "time": 11088.141302108765, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 347848, "time": 11089.14939904213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347888, "time": 11090.714876174927, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 347960, "time": 11092.730159282684, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 348224, "time": 11101.080667257309, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 348360, "time": 11105.049896240234, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 348472, "time": 11108.489243984222, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 348656, "time": 11114.31057190895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348736, "time": 11116.736515283585, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 348776, "time": 11117.753157377243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348912, "time": 11122.23167681694, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 349056, "time": 11126.589091300964, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 349080, "time": 11127.12327337265, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 349512, "time": 11140.328403949738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349800, "time": 11149.099771261215, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 349832, "time": 11150.073881864548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349976, "time": 11154.551229953766, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 11159.407206058502, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 350064, "time": 11159.493442773819, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 350064, "time": 11160.055129289627, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 350064, "time": 11161.846547365189, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 350064, "time": 11162.062716245651, "eval_episode/length": 198.0, "eval_episode/score": 0.3812499940395355, "eval_episode/reward_rate": 0.005025125628140704}
{"step": 350064, "time": 11163.112759828568, "eval_episode/length": 187.0, "eval_episode/score": 0.4156250059604645, "eval_episode/reward_rate": 0.005319148936170213}
{"step": 350064, "time": 11163.196412801743, "eval_episode/length": 187.0, "eval_episode/score": 0.4156250059604645, "eval_episode/reward_rate": 0.005319148936170213}
{"step": 350064, "time": 11163.810883522034, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 350112, "time": 11165.290921926498, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 350200, "time": 11167.76287484169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350232, "time": 11168.734094619751, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 350552, "time": 11178.476647377014, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 350672, "time": 11182.495619297028, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 350768, "time": 11185.41295170784, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 350792, "time": 11185.928037881851, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 351088, "time": 11195.176335573196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351256, "time": 11200.093530416489, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 351544, "time": 11208.945213079453, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 351608, "time": 11210.980830192566, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 351696, "time": 11213.897695064545, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 352280, "time": 11231.890503644943, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 352456, "time": 11237.213571310043, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 352512, "time": 11239.129364013672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352544, "time": 11240.09580039978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352984, "time": 11253.370950460434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353000, "time": 11253.862981796265, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 353080, "time": 11256.33183646202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353104, "time": 11257.292603492737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353160, "time": 11258.778184890747, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 353337, "time": 11265.158556461334, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2755191040039064, "train/action_min": 0.0, "train/action_std": 1.537913928627968, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00834965032641776, "train/actor_opt_grad_steps": 20985.0, "train/actor_opt_loss": 6.905823311246931, "train/adv_mag": 0.1860241225361824, "train/adv_max": 0.16354351446032525, "train/adv_mean": 0.011836655442421034, "train/adv_min": -0.06971429973840713, "train/adv_std": 0.023715483060805127, "train/cont_avg": 0.9964208984375, "train/cont_loss_mean": 0.022284973664209246, "train/cont_loss_std": 0.3064657601917861, "train/cont_neg_acc": 0.005668358754385546, "train/cont_neg_loss": 5.216059279320809, "train/cont_pos_acc": 0.9999803555011749, "train/cont_pos_loss": 0.003695384936290793, "train/cont_pred": 0.9962858685851097, "train/cont_rate": 0.9964208984375, "train/dyn_loss_mean": 1.39170225918293, "train/dyn_loss_std": 0.13362147365740384, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.6500758063979446, "train/extr_critic_critic_opt_grad_steps": 20985.0, "train/extr_critic_critic_opt_loss": 10550.33279296875, "train/extr_critic_mag": 0.41311845421791077, "train/extr_critic_max": 0.41311845421791077, "train/extr_critic_mean": 0.40331766426563265, "train/extr_critic_min": 0.38600639283657073, "train/extr_critic_std": 0.00590639360336354, "train/extr_return_normed_mag": 0.2088501825928688, "train/extr_return_normed_max": 0.19093827530741692, "train/extr_return_normed_mean": 0.03404441418868373, "train/extr_return_normed_min": -0.04276660665869713, "train/extr_return_normed_std": 0.024875913719879465, "train/extr_return_rate": 0.07942643632803083, "train/extr_return_raw_mag": 0.5720481289923192, "train/extr_return_raw_max": 0.5720481289923192, "train/extr_return_raw_mean": 0.4151542852818966, "train/extr_return_raw_min": 0.3383432471752167, "train/extr_return_raw_std": 0.024875913680298255, "train/extr_reward_mag": 0.16367912590503692, "train/extr_reward_max": 0.16367912590503692, "train/extr_reward_mean": 0.00279134541446183, "train/extr_reward_min": 3.2126903533935545e-07, "train/extr_reward_std": 0.012201402340906498, "train/image_loss_mean": 0.14186160791665314, "train/image_loss_std": 0.10957953307777643, "train/model_loss_mean": 1.0021353900432586, "train/model_loss_std": 0.452527111582458, "train/model_opt_grad_norm": 133.46010333538055, "train/model_opt_grad_steps": 20962.695, "train/model_opt_loss": 1764.843463125229, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2282.03125, "train/policy_entropy_mag": 1.3809894740581512, "train/policy_entropy_max": 1.3809894740581512, "train/policy_entropy_mean": 0.18221018433570862, "train/policy_entropy_min": 0.06469334870576858, "train/policy_entropy_std": 0.21179930947721004, "train/policy_logprob_mag": 6.551065514087677, "train/policy_logprob_max": -0.008609371008351446, "train/policy_logprob_mean": -0.18195583295077086, "train/policy_logprob_min": -6.551065514087677, "train/policy_logprob_std": 0.7097589987516403, "train/policy_randomness_mag": 0.7096882423758507, "train/policy_randomness_max": 0.7096882423758507, "train/policy_randomness_mean": 0.09363751674070954, "train/policy_randomness_min": 0.033245806712657214, "train/policy_randomness_std": 0.10884332034736871, "train/post_ent_mag": 38.43689569473267, "train/post_ent_max": 38.43689569473267, "train/post_ent_mean": 37.971507663726804, "train/post_ent_min": 37.41585018157959, "train/post_ent_std": 0.1851441688090563, "train/prior_ent_mag": 40.4974556350708, "train/prior_ent_max": 40.4974556350708, "train/prior_ent_mean": 38.27118730545044, "train/prior_ent_min": 36.86642889022827, "train/prior_ent_std": 0.6088019232451916, "train/rep_loss_mean": 1.39170225918293, "train/rep_loss_std": 0.13362147365740384, "train/reward_avg": 0.00029206848339526916, "train/reward_loss_mean": 0.0029674291977426037, "train/reward_loss_std": 0.07213291492204008, "train/reward_max_data": 0.22885937601327896, "train/reward_max_pred": 0.031118590235710144, "train/reward_neg_acc": 0.9999658203125, "train/reward_neg_loss": 0.0003413376105891075, "train/reward_pos_acc": 0.05714285714285714, "train/reward_pos_loss": 5.566985714435577, "train/reward_pred": 0.00017092093708924948, "train/reward_rate": 0.00046875, "train_stats/mean_log_entropy": 0.17733556340322082, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.018963469192385674, "report/cont_loss_std": 0.3045816421508789, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.568178176879883, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002658235374838114, "report/cont_pred": 0.9973396062850952, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.133100688457489, "report/image_loss_std": 0.1032538041472435, "report/model_loss_mean": 0.7521995902061462, "report/model_loss_std": 0.3218025267124176, "report/post_ent_mag": 36.82745361328125, "report/post_ent_max": 36.82745361328125, "report/post_ent_mean": 36.505470275878906, "report/post_ent_min": 36.28166198730469, "report/post_ent_std": 0.0893167033791542, "report/prior_ent_mag": 41.63212203979492, "report/prior_ent_max": 41.63212203979492, "report/prior_ent_mean": 38.590904235839844, "report/prior_ent_min": 37.00055694580078, "report/prior_ent_std": 0.854715883731842, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00013540126383304596, "report/reward_loss_std": 0.0009101993637159467, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.006994128227233887, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00013540126383304596, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.527092773467302e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.007106010802090168, "eval/cont_loss_std": 0.14737007021903992, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.719893455505371, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002499180845916271, "eval/cont_pred": 0.9975010752677917, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1645476073026657, "eval/image_loss_std": 0.10492400079965591, "eval/model_loss_mean": 0.771726667881012, "eval/model_loss_std": 0.18812872469425201, "eval/post_ent_mag": 36.822933197021484, "eval/post_ent_max": 36.822933197021484, "eval/post_ent_mean": 36.492958068847656, "eval/post_ent_min": 36.29975891113281, "eval/post_ent_std": 0.08401580899953842, "eval/prior_ent_mag": 41.63212203979492, "eval/prior_ent_max": 41.63212203979492, "eval/prior_ent_mean": 38.55299377441406, "eval/prior_ent_min": 36.92572021484375, "eval/prior_ent_std": 0.8326697945594788, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 7.307063788175583e-05, "eval/reward_loss_std": 0.00045913277426734567, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.003508925437927246, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 7.307063788175583e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.5023665986955166e-05, "eval/reward_rate": 0.0, "replay/size": 352833.0, "replay/inserts": 32008.0, "replay/samples": 32016.0, "replay/insert_wait_avg": 1.2973805303366236e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.79328496381082e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83680.0, "eval_replay/inserts": 6920.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.202153332660653e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0132491588593, "timer/env.step_count": 4001.0, "timer/env.step_total": 38.74223780632019, "timer/env.step_frac": 0.03874172451105766, "timer/env.step_avg": 0.009683138666913319, "timer/env.step_min": 0.007817745208740234, "timer/env.step_max": 0.05000710487365723, "timer/replay._sample_count": 32016.0, "timer/replay._sample_total": 17.031409978866577, "timer/replay._sample_frac": 0.017031184329999827, "timer/replay._sample_avg": 0.0005319655790500555, "timer/replay._sample_min": 0.0003695487976074219, "timer/replay._sample_max": 0.010438919067382812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4866.0, "timer/agent.policy_total": 51.605958461761475, "timer/agent.policy_frac": 0.05160527473527853, "timer/agent.policy_avg": 0.010605416864315962, "timer/agent.policy_min": 0.009041070938110352, "timer/agent.policy_max": 0.08920049667358398, "timer/dataset_train_count": 2001.0, "timer/dataset_train_total": 0.2198476791381836, "timer/dataset_train_frac": 0.00021984476637994946, "timer/dataset_train_avg": 0.00010986890511653353, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0005657672882080078, "timer/agent.train_count": 2001.0, "timer/agent.train_total": 894.8959169387817, "timer/agent.train_frac": 0.8948840604777039, "timer/agent.train_avg": 0.44722434629624275, "timer/agent.train_min": 0.43541455268859863, "timer/agent.train_max": 1.5388462543487549, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47298312187194824, "timer/agent.report_frac": 0.0004729768553264553, "timer/agent.report_avg": 0.23649156093597412, "timer/agent.report_min": 0.22604894638061523, "timer/agent.report_max": 0.246934175491333, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.980192753722306e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 32.006998316138514}
{"step": 353360, "time": 11265.805609703064, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 353376, "time": 11266.373849153519, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 353600, "time": 11273.278204917908, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 353696, "time": 11276.20551276207, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 353856, "time": 11281.075946807861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 354184, "time": 11290.796466827393, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 354408, "time": 11297.600242137909, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 354464, "time": 11299.527338027954, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 354480, "time": 11300.018629550934, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 354568, "time": 11302.60852766037, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 354632, "time": 11304.549808263779, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 355072, "time": 11318.138283729553, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 355192, "time": 11321.545112848282, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 355296, "time": 11324.895977258682, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 355312, "time": 11325.402397871017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355560, "time": 11332.770359277725, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 355560, "time": 11332.779118061066, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 355664, "time": 11336.156451940536, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 355664, "time": 11336.175399065018, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 355672, "time": 11336.208463668823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355816, "time": 11340.551607370377, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 356120, "time": 11349.834627389908, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 356136, "time": 11350.323778629303, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 356272, "time": 11354.656498908997, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 356360, "time": 11357.086881875992, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 356680, "time": 11366.933836221695, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 356848, "time": 11372.27683711052, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 357176, "time": 11382.041501998901, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 357208, "time": 11383.014874696732, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 357256, "time": 11384.480318784714, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 357920, "time": 11404.815908908844, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 357976, "time": 11406.291142702103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358128, "time": 11411.107639074326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358448, "time": 11420.868250370026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358528, "time": 11423.304518461227, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 358584, "time": 11424.799311161041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358792, "time": 11431.135226011276, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 358856, "time": 11433.08416724205, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 359080, "time": 11439.880870580673, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 359104, "time": 11440.833577156067, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 359128, "time": 11441.346193790436, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 359416, "time": 11450.059951782227, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 359488, "time": 11452.57045674324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359520, "time": 11453.54128742218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359568, "time": 11454.983327388763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359616, "time": 11456.437157154083, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 359888, "time": 11464.69799542427, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 11471.26424741745, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 360048, "time": 11471.53294301033, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 360048, "time": 11471.558205604553, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 360048, "time": 11471.876855134964, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 360048, "time": 11471.941098451614, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 360048, "time": 11472.2464761734, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 360048, "time": 11473.03255724907, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 360048, "time": 11473.078629016876, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 360280, "time": 11479.962242126465, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 360304, "time": 11481.041254281998, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 360344, "time": 11482.027442455292, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 360424, "time": 11484.449330329895, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 360616, "time": 11490.720853567123, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 360656, "time": 11492.1549077034, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 360944, "time": 11500.879047632217, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 361168, "time": 11507.649726390839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361232, "time": 11509.598008871078, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 361392, "time": 11514.544333457947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361416, "time": 11515.049884796143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361440, "time": 11515.993309020996, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 361664, "time": 11522.762164354324, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 361784, "time": 11526.192650556564, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 362200, "time": 11538.841777801514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362568, "time": 11550.11461186409, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 362656, "time": 11552.990654945374, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 362656, "time": 11552.999526500702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362864, "time": 11559.331664323807, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 362968, "time": 11562.252909898758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363480, "time": 11577.871354341507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363696, "time": 11584.646023511887, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 363728, "time": 11585.628512144089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364096, "time": 11596.814350605011, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 364096, "time": 11596.862695455551, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364312, "time": 11603.380165576935, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 364472, "time": 11608.241025686264, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 364768, "time": 11617.424605846405, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 364856, "time": 11619.855024337769, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 365104, "time": 11627.665040969849, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 365176, "time": 11629.611457586288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365248, "time": 11632.099800109863, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 365496, "time": 11639.399781942368, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 365576, "time": 11641.844516515732, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 365592, "time": 11642.333444595337, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 365928, "time": 11652.536747455597, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 365992, "time": 11654.474780082703, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 366008, "time": 11654.965771913528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366408, "time": 11667.183900356293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366744, "time": 11677.276052474976, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 367064, "time": 11686.937262773514, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 367080, "time": 11687.428926706314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367144, "time": 11689.359001636505, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 367272, "time": 11693.310207366943, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 367464, "time": 11699.137519598007, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 367488, "time": 11700.108211755753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367552, "time": 11702.039100885391, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 367704, "time": 11706.464205026627, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 367808, "time": 11709.847591400146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367944, "time": 11713.713634729385, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 368128, "time": 11719.512771844864, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 368184, "time": 11721.096489667892, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 368264, "time": 11723.517850399017, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 368608, "time": 11734.172819375992, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 368720, "time": 11737.992672920227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368792, "time": 11739.963328838348, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 369120, "time": 11750.095966339111, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 369296, "time": 11755.50632071495, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 369392, "time": 11758.428572416306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369456, "time": 11760.360865831375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369680, "time": 11767.135891914368, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 369936, "time": 11774.855965614319, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 11778.981395244598, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 370032, "time": 11779.042870283127, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 370032, "time": 11779.336259126663, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 370032, "time": 11779.987041473389, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 370032, "time": 11780.121767520905, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 370032, "time": 11781.024345874786, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 370032, "time": 11781.652792215347, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 370032, "time": 11782.357627153397, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 370440, "time": 11794.494460582733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370496, "time": 11796.420481681824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370592, "time": 11799.333927154541, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 371032, "time": 11812.529006242752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371104, "time": 11814.9209253788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371184, "time": 11817.34732413292, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 371224, "time": 11818.333253860474, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 371248, "time": 11819.275584697723, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 371288, "time": 11820.265651464462, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 371664, "time": 11831.87583565712, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 371704, "time": 11832.866020441055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371768, "time": 11834.80262184143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371992, "time": 11841.768282651901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 372032, "time": 11843.205727100372, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 372128, "time": 11846.120463609695, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 372264, "time": 11849.999255180359, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 372272, "time": 11850.49321603775, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 372448, "time": 11855.820724725723, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 372600, "time": 11860.22183227539, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 372808, "time": 11866.496138811111, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 372960, "time": 11871.40732049942, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 373296, "time": 11881.64618062973, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 373600, "time": 11890.863937616348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373736, "time": 11894.797835588455, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 373976, "time": 11902.193846702576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374040, "time": 11904.16742014885, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 374344, "time": 11913.382490873337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374576, "time": 11920.618723869324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374912, "time": 11930.839838266373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375272, "time": 11941.48241353035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375912, "time": 11960.960510015488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376048, "time": 11965.320769309998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376288, "time": 11972.624071359634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376352, "time": 11974.567977666855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376656, "time": 11983.770391225815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376888, "time": 11991.122931718826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377224, "time": 12001.246513843536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377584, "time": 12012.379470825195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378224, "time": 12031.843099355698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378360, "time": 12035.740417718887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378600, "time": 12042.981051206589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378664, "time": 12044.907558202744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378968, "time": 12054.234075069427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379200, "time": 12061.533933639526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379536, "time": 12071.761877536774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379896, "time": 12082.642719268799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 12091.906673192978, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12091.914897203445, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12091.924658060074, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12091.933472156525, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12091.94315648079, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12091.950778722763, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12091.959388494492, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12091.968111753464, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380536, "time": 12107.570100545883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380672, "time": 12112.053973913193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380912, "time": 12119.371358156204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380976, "time": 12121.31330037117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381280, "time": 12130.575277805328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381512, "time": 12137.390956163406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381848, "time": 12147.662793636322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382208, "time": 12158.901575088501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382848, "time": 12178.416574954987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382984, "time": 12182.32473373413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383224, "time": 12189.62863111496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383288, "time": 12191.5673661232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383592, "time": 12200.94786119461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383824, "time": 12208.222719430923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384160, "time": 12218.384858608246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384520, "time": 12229.117705821991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385160, "time": 12249.051433801651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385296, "time": 12253.378118038177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385536, "time": 12260.663417816162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385600, "time": 12262.611909866333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385673, "time": 12265.556909322739, "train_stats/mean_log_entropy": 0.10257317121539797, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2505882943030633, "train/action_min": 0.0, "train/action_std": 1.2076492921108066, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009507494683822358, "train/actor_opt_grad_steps": 22995.0, "train/actor_opt_loss": 2.2906924088918927, "train/adv_mag": 0.43761066723578046, "train/adv_max": 0.20690974253829164, "train/adv_mean": 0.006320664210626533, "train/adv_min": -0.38990811324945773, "train/adv_std": 0.03006225561902923, "train/cont_avg": 0.9961565980816832, "train/cont_loss_mean": 0.01947029789743742, "train/cont_loss_std": 0.27236131101957345, "train/cont_neg_acc": 0.12446910647017445, "train/cont_neg_loss": 4.084921393988292, "train/cont_pos_acc": 0.9998640282319324, "train/cont_pos_loss": 0.003647898577411871, "train/cont_pred": 0.9960045239122788, "train/cont_rate": 0.9961565980816832, "train/dyn_loss_mean": 1.0000238430382002, "train/dyn_loss_std": 0.0006080252450653398, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1299049703238329, "train/extr_critic_critic_opt_grad_steps": 22995.0, "train/extr_critic_critic_opt_loss": 8457.207294728496, "train/extr_critic_mag": 0.6351217881287679, "train/extr_critic_max": 0.6351217881287679, "train/extr_critic_mean": 0.6079071360354377, "train/extr_critic_min": 0.5897359281483263, "train/extr_critic_std": 0.006692220141078428, "train/extr_return_normed_mag": 0.42720844589247564, "train/extr_return_normed_max": 0.24061054035578625, "train/extr_return_normed_mean": 0.03203578269248022, "train/extr_return_normed_min": -0.3498025170647272, "train/extr_return_normed_std": 0.030919355649206014, "train/extr_return_rate": 0.9840147055519541, "train/extr_return_raw_mag": 0.8228025274111492, "train/extr_return_raw_max": 0.8228025274111492, "train/extr_return_raw_mean": 0.6142277983155581, "train/extr_return_raw_min": 0.2323894701381721, "train/extr_return_raw_std": 0.030919355649206014, "train/extr_reward_mag": 0.2101325498949183, "train/extr_reward_max": 0.2101325498949183, "train/extr_reward_mean": 0.0026563628685083375, "train/extr_reward_min": 3.2162902378799894e-07, "train/extr_reward_std": 0.011646287877900447, "train/image_loss_mean": 0.12295153534205833, "train/image_loss_std": 0.10622605401100499, "train/model_loss_mean": 0.7464861509823563, "train/model_loss_std": 0.3622097463374681, "train/model_opt_grad_norm": 31.369585117491166, "train/model_opt_grad_steps": 22967.0, "train/model_opt_loss": 59.39555302232799, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 80.05878712871286, "train/policy_entropy_mag": 1.3220394888136646, "train/policy_entropy_max": 1.3220394888136646, "train/policy_entropy_mean": 0.12289724299813261, "train/policy_entropy_min": 0.06468698031979032, "train/policy_entropy_std": 0.14455324761329755, "train/policy_logprob_mag": 6.551078565049879, "train/policy_logprob_max": -0.008608308339509929, "train/policy_logprob_mean": -0.1224330437581728, "train/policy_logprob_min": -6.551078565049879, "train/policy_logprob_std": 0.6565360037407072, "train/policy_randomness_mag": 0.6793939390099875, "train/policy_randomness_max": 0.6793939390099875, "train/policy_randomness_mean": 0.06315669284598661, "train/policy_randomness_min": 0.03324253410838618, "train/policy_randomness_std": 0.07428567839491337, "train/post_ent_mag": 35.23792502903702, "train/post_ent_max": 35.23792502903702, "train/post_ent_mean": 34.94759223484757, "train/post_ent_min": 34.76698901865742, "train/post_ent_std": 0.07809543233401704, "train/prior_ent_mag": 38.77505570591086, "train/prior_ent_max": 38.77505570591086, "train/prior_ent_mean": 36.23649506521697, "train/prior_ent_min": 34.532352239778724, "train/prior_ent_std": 0.7092670920756784, "train/rep_loss_mean": 1.0000238430382002, "train/rep_loss_std": 0.0006080252450653398, "train/reward_avg": 0.00045282345175533327, "train/reward_loss_mean": 0.004049984764741125, "train/reward_loss_std": 0.0962695548346031, "train/reward_max_data": 0.35642017475744286, "train/reward_max_pred": 0.06455368747805605, "train/reward_neg_acc": 0.9999661206608952, "train/reward_neg_loss": 0.0006001633363045432, "train/reward_pos_acc": 0.16037735877172002, "train/reward_pos_loss": 4.998765200938818, "train/reward_pred": 0.0003355438146730977, "train/reward_rate": 0.0006864944306930693, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.012502366676926613, "report/cont_loss_std": 0.2027226835489273, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 3.088473320007324, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00346425361931324, "report/cont_pred": 0.9956613779067993, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11576753854751587, "report/image_loss_std": 0.09676732867956161, "report/model_loss_mean": 0.7329840660095215, "report/model_loss_std": 0.3319174647331238, "report/post_ent_mag": 34.46394348144531, "report/post_ent_max": 34.46394348144531, "report/post_ent_mean": 34.19168472290039, "report/post_ent_min": 34.02276611328125, "report/post_ent_std": 0.07738133519887924, "report/prior_ent_mag": 35.7601432800293, "report/prior_ent_max": 35.7601432800293, "report/prior_ent_mean": 34.581695556640625, "report/prior_ent_min": 33.478912353515625, "report/prior_ent_std": 0.3081059157848358, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005310058477334678, "report/reward_loss_mean": 0.004714124370366335, "report/reward_loss_std": 0.13518397510051727, "report/reward_max_data": 0.543749988079071, "report/reward_max_pred": 0.023371577262878418, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0004889119300059974, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.327106475830078, "report/reward_pred": 0.00026480795349925756, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.016497090458869934, "eval/cont_loss_std": 0.32290104031562805, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.2898759841918945, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0022634726483374834, "eval/cont_pred": 0.9977490305900574, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24967993795871735, "eval/image_loss_std": 0.14432822167873383, "eval/model_loss_mean": 0.8662930727005005, "eval/model_loss_std": 0.353218674659729, "eval/post_ent_mag": 34.46097183227539, "eval/post_ent_max": 34.46097183227539, "eval/post_ent_mean": 34.17820739746094, "eval/post_ent_min": 34.013648986816406, "eval/post_ent_std": 0.07518026977777481, "eval/prior_ent_mag": 35.754852294921875, "eval/prior_ent_max": 35.754852294921875, "eval/prior_ent_mean": 34.37990951538086, "eval/prior_ent_min": 33.26956558227539, "eval/prior_ent_std": 0.33149003982543945, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00011597294360399246, "eval/reward_loss_std": 0.0012621184578165412, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.018648982048034668, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00011597294360399246, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.772709846496582e-05, "eval/reward_rate": 0.0, "replay/size": 385169.0, "replay/inserts": 32336.0, "replay/samples": 32336.0, "replay/insert_wait_avg": 1.27531377942417e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.95881268059128e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 89360.0, "eval_replay/inserts": 5680.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1580091127207581e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3804972171783, "timer/env.step_count": 4042.0, "timer/env.step_total": 38.317216873168945, "timer/env.step_frac": 0.03830264282416378, "timer/env.step_avg": 0.009479766668275345, "timer/env.step_min": 0.007613420486450195, "timer/env.step_max": 0.04597306251525879, "timer/replay._sample_count": 32336.0, "timer/replay._sample_total": 17.093780040740967, "timer/replay._sample_frac": 0.017087278378868656, "timer/replay._sample_avg": 0.0005286300111560171, "timer/replay._sample_min": 0.0003993511199951172, "timer/replay._sample_max": 0.028428316116333008, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4752.0, "timer/agent.policy_total": 49.06481623649597, "timer/agent.policy_frac": 0.049046154311267236, "timer/agent.policy_avg": 0.010325087591855213, "timer/agent.policy_min": 0.00875401496887207, "timer/agent.policy_max": 0.07514142990112305, "timer/dataset_train_count": 2021.0, "timer/dataset_train_total": 0.21642374992370605, "timer/dataset_train_frac": 0.00021634143261063733, "timer/dataset_train_avg": 0.00010708745666685109, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0006113052368164062, "timer/agent.train_count": 2021.0, "timer/agent.train_total": 900.5705344676971, "timer/agent.train_frac": 0.9002280002187879, "timer/agent.train_avg": 0.44560640003349683, "timer/agent.train_min": 0.4333338737487793, "timer/agent.train_max": 0.6993160247802734, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46939945220947266, "timer/agent.report_frac": 0.0004692209149570896, "timer/agent.report_avg": 0.23469972610473633, "timer/agent.report_min": 0.22211956977844238, "timer/agent.report_max": 0.24727988243103027, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9790987000044798e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 32.32316518101183}
{"step": 385904, "time": 12272.52153134346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386136, "time": 12279.319032907486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386472, "time": 12289.507194042206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386832, "time": 12300.819262742996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387472, "time": 12320.202276945114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387608, "time": 12324.16754603386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387848, "time": 12331.441365480423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387912, "time": 12333.374451875687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388216, "time": 12342.578114748001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388448, "time": 12349.87284207344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388784, "time": 12360.170209169388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389144, "time": 12370.98880815506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389784, "time": 12390.533141374588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389920, "time": 12394.939164876938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 12403.355256795883, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12403.365872383118, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12403.377680301666, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12403.385481357574, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12403.396431446075, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12403.4063539505, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12403.415943145752, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12403.42482471466, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390160, "time": 12408.293445110321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390224, "time": 12410.339780807495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390264, "time": 12411.390318393707, "episode/length": 4.0, "episode/score": 0.987500011920929, "episode/reward_rate": 0.2, "episode/intrinsic_return": 0.0}
{"step": 390528, "time": 12419.691994190216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390760, "time": 12426.557260513306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391096, "time": 12436.779269218445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391456, "time": 12448.074587583542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391544, "time": 12450.544177532196, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 391568, "time": 12451.496170759201, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 391680, "time": 12454.917171955109, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 391968, "time": 12463.74069595337, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 392232, "time": 12471.626256227493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392472, "time": 12478.943647623062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392792, "time": 12488.70840215683, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 392840, "time": 12490.168046236038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393144, "time": 12499.414620399475, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 393264, "time": 12503.901284217834, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 393408, "time": 12508.258223772049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393768, "time": 12518.917737722397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393800, "time": 12519.88707280159, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 393856, "time": 12521.802175998688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393992, "time": 12525.701500415802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394280, "time": 12534.518169164658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394584, "time": 12543.731356620789, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 394704, "time": 12547.600979089737, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 394848, "time": 12551.974301576614, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 395136, "time": 12560.793519496918, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 395152, "time": 12561.303799390793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395184, "time": 12562.275438785553, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 395576, "time": 12573.93544626236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395720, "time": 12578.302832603455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396112, "time": 12590.46822810173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396216, "time": 12593.381172895432, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 396248, "time": 12594.346275091171, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 396304, "time": 12596.273279428482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396528, "time": 12603.089866638184, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 396624, "time": 12606.055397987366, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 396640, "time": 12606.55453157425, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 396896, "time": 12614.419209241867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397448, "time": 12631.033623218536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397488, "time": 12632.467047452927, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 397496, "time": 12632.494588375092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397888, "time": 12644.786894798279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398176, "time": 12653.57232928276, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 398528, "time": 12664.27178144455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398840, "time": 12673.549748897552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398952, "time": 12676.932290554047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399208, "time": 12684.804401874542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399392, "time": 12690.608927488327, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 399800, "time": 12702.745604991913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399808, "time": 12703.212327241898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399848, "time": 12704.199560642242, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 12712.652427434921, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 400088, "time": 12717.062948226929, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12717.084266424179, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12717.093299150467, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12717.10444021225, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12717.112844467163, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12717.125190734863, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12717.133744001389, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400200, "time": 12720.54035449028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400432, "time": 12727.86338710785, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 400488, "time": 12729.339856147766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400776, "time": 12738.07696557045, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 401152, "time": 12749.812121152878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401264, "time": 12753.225474119186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401520, "time": 12761.48962020874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402112, "time": 12779.569583654404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402120, "time": 12779.597825288773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402512, "time": 12791.710906744003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402608, "time": 12794.605675697327, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 402632, "time": 12795.11457157135, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 402744, "time": 12798.510755777359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403088, "time": 12809.315148353577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403160, "time": 12811.299602746964, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 403544, "time": 12822.924800157547, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 403576, "time": 12823.901146650314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403832, "time": 12831.816576004028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404112, "time": 12840.5152592659, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 404240, "time": 12844.358095884323, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 404432, "time": 12850.180605649948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404880, "time": 12863.80471420288, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 404920, "time": 12864.820587396622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405056, "time": 12869.14365029335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405472, "time": 12881.741604566574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405856, "time": 12893.48566699028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405888, "time": 12894.470703840256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405944, "time": 12895.935652017593, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 406016, "time": 12898.330634593964, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 406056, "time": 12899.348845243454, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 406184, "time": 12903.215240955353, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 406240, "time": 12905.147407054901, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 406376, "time": 12909.057958364487, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 406424, "time": 12910.527994394302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407016, "time": 12928.568347930908, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 407024, "time": 12929.037274837494, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 407592, "time": 12946.05666232109, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 407784, "time": 12951.955303430557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407792, "time": 12952.443063259125, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 408024, "time": 12959.231793642044, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 408144, "time": 12963.101360559464, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 408168, "time": 12963.61057472229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408200, "time": 12964.585380792618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408328, "time": 12968.473834514618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408552, "time": 12975.279391765594, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 408744, "time": 12981.186247587204, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 408872, "time": 12985.063294649124, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 409320, "time": 12998.689177036285, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 409904, "time": 13017.172819375992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410064, "time": 13022.023873090744, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 13022.951483011246, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 410072, "time": 13023.329777240753, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 410072, "time": 13025.791112661362, "eval_episode/length": 192.0, "eval_episode/score": 0.4000000059604645, "eval_episode/reward_rate": 0.0051813471502590676}
{"step": 410072, "time": 13027.608556509018, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13027.616291046143, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13027.625728845596, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13027.634682655334, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13027.641857624054, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410096, "time": 13028.592967033386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410104, "time": 13028.622097730637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410336, "time": 13035.858012914658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410512, "time": 13041.306858301163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410864, "time": 13051.93883895874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411632, "time": 13075.291146039963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411816, "time": 13080.648253917694, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 412152, "time": 13090.825407743454, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 412184, "time": 13091.816340446472, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 412216, "time": 13092.789293766022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412376, "time": 13097.634603977203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412408, "time": 13098.610171079636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412416, "time": 13099.077156543732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412624, "time": 13105.492270231247, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 412648, "time": 13106.001620054245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412824, "time": 13111.333164930344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413016, "time": 13117.134452104568, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 413128, "time": 13120.531452178955, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 413264, "time": 13124.86568069458, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 413968, "time": 13146.305686712265, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 414464, "time": 13161.465604066849, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414688, "time": 13168.287416696548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414960, "time": 13176.552870988846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415136, "time": 13181.883332014084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415328, "time": 13187.797756910324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415376, "time": 13189.272367715836, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 415440, "time": 13191.352688074112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415576, "time": 13195.293800592422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416016, "time": 13208.84910273552, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 416280, "time": 13216.647350549698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416320, "time": 13218.10077214241, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 416408, "time": 13220.643412351608, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 416776, "time": 13231.770914316177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416984, "time": 13238.060901165009, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 417272, "time": 13246.776959180832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417448, "time": 13252.233346939087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417448, "time": 13252.243819475174, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 417640, "time": 13258.065759658813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417688, "time": 13259.519938230515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417849, "time": 13265.854387521744, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1317454475668534, "train/action_min": 0.0, "train/action_std": 1.4117671796931557, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006886303243551644, "train/actor_opt_grad_steps": 25010.0, "train/actor_opt_loss": -1.312439846514321, "train/adv_mag": 0.5004366950609198, "train/adv_max": 0.20691709494709376, "train/adv_mean": 0.00392796048833421, "train/adv_min": -0.4582272100804457, "train/adv_std": 0.02250343366451932, "train/cont_avg": 0.9961277596393034, "train/cont_loss_mean": 0.015359395987525656, "train/cont_loss_std": 0.22832350442139662, "train/cont_neg_acc": 0.30208887696871295, "train/cont_neg_loss": 3.1631134436820365, "train/cont_pos_acc": 0.9998290328244072, "train/cont_pos_loss": 0.0030682939602831257, "train/cont_pred": 0.9960014778583204, "train/cont_rate": 0.9961277596393034, "train/dyn_loss_mean": 1.0000124558880554, "train/dyn_loss_std": 0.000364465386472383, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7663982499075767, "train/extr_critic_critic_opt_grad_steps": 25010.0, "train/extr_critic_critic_opt_loss": 11135.556718361318, "train/extr_critic_mag": 0.6772901460305968, "train/extr_critic_max": 0.6772901460305968, "train/extr_critic_mean": 0.6456148206298031, "train/extr_critic_min": 0.6212736486795529, "train/extr_critic_std": 0.008394868710815018, "train/extr_return_normed_mag": 0.4982058076716181, "train/extr_return_normed_max": 0.2442547584054482, "train/extr_return_normed_mean": 0.027486973561149826, "train/extr_return_normed_min": -0.43134925733158247, "train/extr_return_normed_std": 0.024409544100493785, "train/extr_return_rate": 0.9977184777236103, "train/extr_return_raw_mag": 0.8663105596950398, "train/extr_return_raw_max": 0.8663105596950398, "train/extr_return_raw_mean": 0.6495428106084985, "train/extr_return_raw_min": 0.19070654395800918, "train/extr_return_raw_std": 0.02440954398929109, "train/extr_reward_mag": 0.2360025543478591, "train/extr_reward_max": 0.2360025543478591, "train/extr_reward_mean": 0.0022184592743546977, "train/extr_reward_min": 3.9024732599210976e-07, "train/extr_reward_std": 0.009177984156360878, "train/image_loss_mean": 0.10753718214989895, "train/image_loss_std": 0.10183952774722778, "train/model_loss_mean": 0.7270168837030135, "train/model_loss_std": 0.3199410907442297, "train/model_opt_grad_norm": 30.272563464605987, "train/model_opt_grad_steps": 24982.0, "train/model_opt_loss": 234.1367104373761, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 322.6057213930348, "train/policy_entropy_mag": 1.3797218390365145, "train/policy_entropy_max": 1.3797218390365145, "train/policy_entropy_mean": 0.1265164926203329, "train/policy_entropy_min": 0.06468671589941527, "train/policy_entropy_std": 0.16028946048733014, "train/policy_logprob_mag": 6.551080001527398, "train/policy_logprob_max": -0.008608258574904494, "train/policy_logprob_mean": -0.1266819538539322, "train/policy_logprob_min": -6.551080001527398, "train/policy_logprob_std": 0.6633642959357494, "train/policy_randomness_mag": 0.709036808108809, "train/policy_randomness_max": 0.709036808108809, "train/policy_randomness_mean": 0.06501662010206512, "train/policy_randomness_min": 0.03324239767754256, "train/policy_randomness_std": 0.0823724926704198, "train/post_ent_mag": 34.018217305045816, "train/post_ent_max": 34.018217305045816, "train/post_ent_mean": 33.747985137635794, "train/post_ent_min": 33.58951722330122, "train/post_ent_std": 0.07188315585774568, "train/prior_ent_mag": 35.16061530421622, "train/prior_ent_max": 35.16061530421622, "train/prior_ent_mean": 33.72966179918887, "train/prior_ent_min": 32.181106377596876, "train/prior_ent_std": 0.47531312051697155, "train/rep_loss_mean": 1.0000124558880554, "train/rep_loss_std": 0.000364465386472383, "train/reward_avg": 0.0005166428581381736, "train/reward_loss_mean": 0.004112808645438792, "train/reward_loss_std": 0.08958411280995938, "train/reward_max_data": 0.37195273737112683, "train/reward_max_pred": 0.09824607502761765, "train/reward_neg_acc": 0.999922172643652, "train/reward_neg_loss": 0.000703500098432559, "train/reward_pos_acc": 0.2638888891648363, "train/reward_pos_loss": 4.220818759114654, "train/reward_pred": 0.0004425171255342551, "train/reward_rate": 0.0007919387437810945, "train_stats/mean_log_entropy": 0.11238576902016517, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.022534824907779694, "report/cont_loss_std": 0.35503843426704407, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 3.9538466930389404, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00324477581307292, "report/cont_pred": 0.9951696991920471, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10649227350950241, "report/image_loss_std": 0.11983554810285568, "report/model_loss_mean": 0.7322348356246948, "report/model_loss_std": 0.38682740926742554, "report/post_ent_mag": 33.4206428527832, "report/post_ent_max": 33.4206428527832, "report/post_ent_mean": 33.13667297363281, "report/post_ent_min": 32.96366882324219, "report/post_ent_std": 0.07489842176437378, "report/prior_ent_mag": 34.64557647705078, "report/prior_ent_max": 34.64557647705078, "report/prior_ent_mean": 33.04292297363281, "report/prior_ent_min": 31.6028995513916, "report/prior_ent_std": 0.4873761534690857, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009307861328125, "report/reward_loss_mean": 0.0032077226787805557, "report/reward_loss_std": 0.08458460122346878, "report/reward_max_data": 0.953125, "report/reward_max_pred": 0.37351810932159424, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005644922493956983, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 2.7072324752807617, "report/reward_pred": 0.0006584693910554051, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02352328598499298, "eval/cont_loss_std": 0.3840363025665283, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.765453338623047, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.003713499754667282, "eval/cont_pred": 0.9975409507751465, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23060497641563416, "eval/image_loss_std": 0.14050188660621643, "eval/model_loss_mean": 0.8587836027145386, "eval/model_loss_std": 0.5142748951911926, "eval/post_ent_mag": 33.419769287109375, "eval/post_ent_max": 33.419769287109375, "eval/post_ent_mean": 33.13165283203125, "eval/post_ent_min": 32.96818542480469, "eval/post_ent_std": 0.0710439383983612, "eval/prior_ent_mag": 34.3271484375, "eval/prior_ent_max": 34.3271484375, "eval/prior_ent_mean": 32.91103744506836, "eval/prior_ent_min": 31.544261932373047, "eval/prior_ent_std": 0.4607792794704437, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0003570556582417339, "eval/reward_loss_mean": 0.004655311815440655, "eval/reward_loss_std": 0.14486655592918396, "eval/reward_max_data": 0.3656249940395355, "eval/reward_max_pred": 0.037434935569763184, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00012613485159818083, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.638003349304199, "eval/reward_pred": 0.00010174338240176439, "eval/reward_rate": 0.0009765625, "replay/size": 417345.0, "replay/inserts": 32176.0, "replay/samples": 32176.0, "replay/insert_wait_avg": 1.2743716095289385e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.816477832006969e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 96296.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1567907212377283e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2794663906097, "timer/env.step_count": 4022.0, "timer/env.step_total": 38.356393337249756, "timer/env.step_frac": 0.03834567700930048, "timer/env.step_avg": 0.009536646777038726, "timer/env.step_min": 0.0077245235443115234, "timer/env.step_max": 0.043810129165649414, "timer/replay._sample_count": 32176.0, "timer/replay._sample_total": 17.03291964530945, "timer/replay._sample_frac": 0.01702816084665891, "timer/replay._sample_avg": 0.0005293672192102638, "timer/replay._sample_min": 0.0003566741943359375, "timer/replay._sample_max": 0.028725385665893555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4889.0, "timer/agent.policy_total": 50.90560841560364, "timer/agent.policy_frac": 0.05089138598364966, "timer/agent.policy_avg": 0.010412274169687796, "timer/agent.policy_min": 0.008620262145996094, "timer/agent.policy_max": 0.08922839164733887, "timer/dataset_train_count": 2011.0, "timer/dataset_train_total": 0.21479225158691406, "timer/dataset_train_frac": 0.0002147322411425344, "timer/dataset_train_avg": 0.00010680867806410446, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0002758502960205078, "timer/agent.train_count": 2011.0, "timer/agent.train_total": 896.9866750240326, "timer/agent.train_frac": 0.8967360674319378, "timer/agent.train_avg": 0.4460401168692355, "timer/agent.train_min": 0.4358406066894531, "timer/agent.train_max": 0.6866505146026611, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46759653091430664, "timer/agent.report_frac": 0.0004674658899093205, "timer/agent.report_avg": 0.23379826545715332, "timer/agent.report_min": 0.2239084243774414, "timer/agent.report_max": 0.24368810653686523, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027069990265541e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 32.16643462270591}
{"step": 418128, "time": 13274.340229034424, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 418312, "time": 13279.6937789917, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 418560, "time": 13287.57730126381, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 418592, "time": 13288.546401500702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418632, "time": 13289.557677984238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419088, "time": 13303.66160273552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419088, "time": 13303.679553747177, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 419328, "time": 13311.193627119064, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 419520, "time": 13317.011717796326, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 419584, "time": 13318.94302368164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419624, "time": 13319.93756866455, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 419768, "time": 13324.306537866592, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 13333.90306854248, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 420056, "time": 13333.92757844925, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 420056, "time": 13334.767305612564, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 420056, "time": 13334.847140550613, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 420056, "time": 13335.527462482452, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 420056, "time": 13335.731810569763, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 420056, "time": 13336.535247087479, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 420056, "time": 13337.662261009216, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 420120, "time": 13339.622516870499, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 420304, "time": 13345.496064662933, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 420440, "time": 13349.401796340942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420448, "time": 13349.870070695877, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 420480, "time": 13350.843576192856, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 420912, "time": 13363.972086668015, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 421400, "time": 13378.667707920074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421896, "time": 13393.670283079147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421936, "time": 13395.104883909225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422328, "time": 13406.900355815887, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 422432, "time": 13410.286110639572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422616, "time": 13415.653540611267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422664, "time": 13417.110988378525, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 422752, "time": 13420.027483940125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422792, "time": 13421.017681837082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422896, "time": 13424.410078048706, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 423224, "time": 13434.189019203186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423240, "time": 13434.679320335388, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 423272, "time": 13435.650991916656, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 423304, "time": 13436.622479200363, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 423328, "time": 13437.593757390976, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 423512, "time": 13442.963591814041, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 423792, "time": 13451.71583724022, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 423832, "time": 13452.725148439407, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 423888, "time": 13454.684244394302, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 423976, "time": 13457.13710975647, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 424008, "time": 13458.111351013184, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 424248, "time": 13465.525277614594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424248, "time": 13465.536100625992, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 424360, "time": 13468.957355260849, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 424656, "time": 13478.150399446487, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 424704, "time": 13479.612218618393, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 424776, "time": 13481.593222379684, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 424920, "time": 13485.983301639557, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 424928, "time": 13486.455080509186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425016, "time": 13488.902907848358, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 425136, "time": 13492.867682695389, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 426104, "time": 13522.670961618423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426672, "time": 13540.248514175415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426760, "time": 13542.689655065536, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 427016, "time": 13550.641521215439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427088, "time": 13553.04354095459, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427232, "time": 13557.403817892075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427240, "time": 13557.431634187698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427328, "time": 13560.342230558395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427448, "time": 13563.784845352173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427480, "time": 13564.78687787056, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 427920, "time": 13578.392385959625, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 427968, "time": 13579.876689910889, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 428000, "time": 13580.932289123535, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 428160, "time": 13585.83104467392, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 428416, "time": 13593.604217529297, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 428640, "time": 13600.430847883224, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 429016, "time": 13611.80564546585, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 429072, "time": 13613.765280246735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429216, "time": 13618.143292188644, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 429328, "time": 13621.565346479416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429400, "time": 13623.597073078156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429496, "time": 13626.565802812576, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 429608, "time": 13629.994673490524, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 429680, "time": 13632.399544477463, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 429688, "time": 13632.425888061523, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 13644.313650131226, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 430040, "time": 13644.601172208786, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 430040, "time": 13645.51733803749, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 430040, "time": 13645.591800451279, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 430040, "time": 13645.620958089828, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 430040, "time": 13645.629118680954, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 430040, "time": 13647.288189172745, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 430040, "time": 13647.811389446259, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 430184, "time": 13652.176453590393, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 430280, "time": 13655.099828481674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430472, "time": 13660.976026535034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430656, "time": 13666.78501367569, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 430712, "time": 13668.27790236473, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 430792, "time": 13670.802539348602, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 431448, "time": 13690.778108596802, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 431640, "time": 13696.64126777649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431712, "time": 13699.055325508118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431728, "time": 13699.546529054642, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 431920, "time": 13705.514153003693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432000, "time": 13707.975613832474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432176, "time": 13713.32945561409, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 432600, "time": 13725.995858669281, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 432752, "time": 13730.929978847504, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 432784, "time": 13731.91693854332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432880, "time": 13734.843585014343, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 433024, "time": 13739.252362012863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433104, "time": 13741.710403203964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433128, "time": 13742.222043037415, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 433184, "time": 13744.159223079681, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 433696, "time": 13759.75159406662, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 433984, "time": 13768.641755342484, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 434040, "time": 13770.146645069122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434312, "time": 13778.92439198494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434584, "time": 13787.214616537094, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 434648, "time": 13789.160460472107, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 434824, "time": 13794.63536119461, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 434984, "time": 13799.503581523895, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 435096, "time": 13802.914463996887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435216, "time": 13808.129481554031, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 435336, "time": 13811.569130659103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435392, "time": 13813.494678735733, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 435440, "time": 13814.96224617958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435496, "time": 13816.474828004837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435568, "time": 13818.904470443726, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 435600, "time": 13819.878988981247, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 435928, "time": 13829.774248361588, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 435952, "time": 13830.757104873657, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 436120, "time": 13835.65140748024, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 436352, "time": 13842.942878246307, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 436648, "time": 13851.817935228348, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 436656, "time": 13852.290620326996, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 436704, "time": 13853.745962619781, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 436960, "time": 13861.525019645691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437240, "time": 13869.840814352036, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 437520, "time": 13878.589761018753, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 437704, "time": 13884.079824447632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437800, "time": 13887.019164800644, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 437880, "time": 13889.477313041687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438264, "time": 13901.270792245865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438296, "time": 13902.253743171692, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 438424, "time": 13906.158188581467, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 438576, "time": 13911.098022937775, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 439016, "time": 13924.278872728348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439032, "time": 13924.769911289215, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 439272, "time": 13932.082651853561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439384, "time": 13935.505850791931, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 439568, "time": 13941.411412239075, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 439648, "time": 13943.849179267883, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 13955.405241012573, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 440024, "time": 13955.594767093658, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 440024, "time": 13955.965572834015, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 440024, "time": 13956.864431619644, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 440024, "time": 13957.653756380081, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 440024, "time": 13958.17835354805, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 440024, "time": 13958.599748849869, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 440024, "time": 13959.440222024918, "eval_episode/length": 214.0, "eval_episode/score": 0.33125001192092896, "eval_episode/reward_rate": 0.004651162790697674}
{"step": 440112, "time": 13962.373187541962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440144, "time": 13963.348253965378, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 440192, "time": 13964.820651769638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440464, "time": 13973.217900753021, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 440576, "time": 13976.617077827454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440832, "time": 13984.423749923706, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 440976, "time": 13988.803759098053, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 441208, "time": 13995.641246080399, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 441328, "time": 13999.530179023743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441584, "time": 14007.435342550278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441696, "time": 14010.820822954178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441960, "time": 14018.617116212845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442024, "time": 14020.563699960709, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 442176, "time": 14025.398125648499, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 442216, "time": 14026.40750002861, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 442224, "time": 14026.8797082901, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 442456, "time": 14034.284688711166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442672, "time": 14041.099791765213, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 442848, "time": 14046.45598268509, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 442984, "time": 14050.41073513031, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 443288, "time": 14059.662508487701, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 443520, "time": 14067.068572759628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443640, "time": 14070.50567817688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443656, "time": 14070.996025800705, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 443808, "time": 14075.82320022583, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 444272, "time": 14089.896733522415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444336, "time": 14091.929857730865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444496, "time": 14096.797828912735, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 444928, "time": 14109.98686337471, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 444984, "time": 14111.476242303848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445496, "time": 14127.167566537857, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 445600, "time": 14130.578201532364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445832, "time": 14137.396889209747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445920, "time": 14140.291851043701, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 445968, "time": 14141.746877670288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446032, "time": 14143.695835113525, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 446120, "time": 14146.134949684143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446176, "time": 14148.052505016327, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 446216, "time": 14149.078150749207, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 446472, "time": 14156.950612306595, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 446496, "time": 14157.911591768265, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 446584, "time": 14160.382394313812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446768, "time": 14166.227536439896, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 446808, "time": 14167.219393968582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447000, "time": 14173.094480276108, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 447032, "time": 14174.083853960037, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 447464, "time": 14187.414913415909, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 447800, "time": 14197.648610115051, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 447808, "time": 14198.123650312424, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 447816, "time": 14198.153695821762, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 448432, "time": 14217.211441040039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448624, "time": 14223.045302391052, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 448704, "time": 14225.49359202385, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 448776, "time": 14227.481911182404, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 448784, "time": 14227.95576786995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448808, "time": 14228.47988319397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449120, "time": 14238.221765756607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449328, "time": 14244.666498422623, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 449504, "time": 14250.061957597733, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 449544, "time": 14251.06505537033, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 449688, "time": 14255.491606712341, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 449776, "time": 14258.420841693878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449784, "time": 14258.447933197021, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 449848, "time": 14260.40827035904, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 14266.430146694183, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 450008, "time": 14266.771657466888, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 450008, "time": 14266.858588218689, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 450008, "time": 14266.884911775589, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 450008, "time": 14266.989125967026, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 450008, "time": 14267.054051399231, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 450008, "time": 14267.856093883514, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 450008, "time": 14268.19507408142, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 450009, "time": 14269.210465669632, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3764961204718595, "train/action_min": 0.0, "train/action_std": 1.6136072405535191, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01092696711780105, "train/actor_opt_grad_steps": 27020.0, "train/actor_opt_loss": -1.4702241192409649, "train/adv_mag": 0.7058326355853484, "train/adv_max": 0.32110799693349584, "train/adv_mean": 0.007400024487615337, "train/adv_min": -0.6789612224446008, "train/adv_std": 0.03909099787538547, "train/cont_avg": 0.9958896921641791, "train/cont_loss_mean": 0.014625097539238817, "train/cont_loss_std": 0.22796357899385306, "train/cont_neg_acc": 0.3739743924885988, "train/cont_neg_loss": 2.9236480309069157, "train/cont_pos_acc": 0.9998389684145723, "train/cont_pos_loss": 0.0027200106907269883, "train/cont_pred": 0.9959701866059754, "train/cont_rate": 0.9958896921641791, "train/dyn_loss_mean": 1.000004545966191, "train/dyn_loss_std": 0.00014382175535348183, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7868190542864266, "train/extr_critic_critic_opt_grad_steps": 27020.0, "train/extr_critic_critic_opt_loss": 9568.645864913713, "train/extr_critic_mag": 0.8349382942588768, "train/extr_critic_max": 0.8349382942588768, "train/extr_critic_mean": 0.812707062680923, "train/extr_critic_min": 0.7836238810079015, "train/extr_critic_std": 0.00970495975719978, "train/extr_return_normed_mag": 0.6879026504298348, "train/extr_return_normed_max": 0.367160160743182, "train/extr_return_normed_mean": 0.04138183163997917, "train/extr_return_normed_min": -0.6460535870262639, "train/extr_return_normed_std": 0.04120896952180424, "train/extr_return_rate": 0.9962638444568387, "train/extr_return_raw_mag": 1.1458854304617316, "train/extr_return_raw_max": 1.1458854304617316, "train/extr_return_raw_mean": 0.820107143316696, "train/extr_return_raw_min": 0.1326716826922858, "train/extr_return_raw_std": 0.04120896968397483, "train/extr_reward_mag": 0.3347101122585695, "train/extr_reward_max": 0.3347101122585695, "train/extr_reward_mean": 0.003097110263139139, "train/extr_reward_min": 2.265569582507385e-07, "train/extr_reward_std": 0.014396138485771284, "train/image_loss_mean": 0.09739287201296631, "train/image_loss_std": 0.09776295964323466, "train/model_loss_mean": 0.7171489664571202, "train/model_loss_std": 0.3373988876443597, "train/model_opt_grad_norm": 28.92479705810547, "train/model_opt_grad_steps": 26992.0, "train/model_opt_loss": 929.6245648588114, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1299.7512437810944, "train/policy_entropy_mag": 1.361194955175789, "train/policy_entropy_max": 1.361194955175789, "train/policy_entropy_mean": 0.1269471815124673, "train/policy_entropy_min": 0.06468664973381147, "train/policy_entropy_std": 0.1637265937615983, "train/policy_logprob_mag": 6.551080193685655, "train/policy_logprob_max": -0.008608171484660154, "train/policy_logprob_mean": -0.12728042819013644, "train/policy_logprob_min": -6.551080193685655, "train/policy_logprob_std": 0.6645391859225372, "train/policy_randomness_mag": 0.6995158732233949, "train/policy_randomness_max": 0.6995158732233949, "train/policy_randomness_mean": 0.06523795021855416, "train/policy_randomness_min": 0.033242364298200135, "train/policy_randomness_std": 0.08413883055842931, "train/post_ent_mag": 33.41421497401907, "train/post_ent_max": 33.41421497401907, "train/post_ent_mean": 33.13903113977233, "train/post_ent_min": 32.98397491227335, "train/post_ent_std": 0.07285821567572172, "train/prior_ent_mag": 34.62950081137282, "train/prior_ent_max": 34.62950081137282, "train/prior_ent_mean": 32.796485407435476, "train/prior_ent_min": 31.258753335297996, "train/prior_ent_std": 0.5242413664931682, "train/rep_loss_mean": 1.000004545966191, "train/rep_loss_std": 0.00014382175535348183, "train/reward_avg": 0.0006419167585586387, "train/reward_loss_mean": 0.005128246007501078, "train/reward_loss_std": 0.10837468780277167, "train/reward_max_data": 0.42467350664720016, "train/reward_max_pred": 0.0902740575780916, "train/reward_neg_acc": 0.9999465026072601, "train/reward_neg_loss": 0.0008152486305117412, "train/reward_pos_acc": 0.12350427403918698, "train/reward_pos_loss": 4.664235937799144, "train/reward_pred": 0.0004857556931489143, "train/reward_rate": 0.0009376943407960199, "train_stats/mean_log_entropy": 0.11389887319746042, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.01515200175344944, "report/cont_loss_std": 0.21507270634174347, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 1.7708845138549805, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0030673129949718714, "report/cont_pred": 0.9936696887016296, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09525895118713379, "report/image_loss_std": 0.0959208607673645, "report/model_loss_mean": 0.714562177658081, "report/model_loss_std": 0.2985623776912689, "report/post_ent_mag": 32.903045654296875, "report/post_ent_max": 32.903045654296875, "report/post_ent_mean": 32.62623977661133, "report/post_ent_min": 32.48020553588867, "report/post_ent_std": 0.08034977316856384, "report/prior_ent_mag": 34.830501556396484, "report/prior_ent_max": 34.830501556396484, "report/prior_ent_mean": 32.59309005737305, "report/prior_ent_min": 30.950965881347656, "report/prior_ent_std": 0.5608548521995544, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007263183360919356, "report/reward_loss_mean": 0.004151244182139635, "report/reward_loss_std": 0.10737108439207077, "report/reward_max_data": 0.7437499761581421, "report/reward_max_pred": 0.03955495357513428, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0007978525245562196, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.434670925140381, "report/reward_pred": 0.0004639334511011839, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03950197994709015, "eval/cont_loss_std": 0.592501163482666, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.46493911743164, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0025394808035343885, "eval/cont_pred": 0.9976849555969238, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2644028663635254, "eval/image_loss_std": 0.1600584089756012, "eval/model_loss_mean": 0.9039394855499268, "eval/model_loss_std": 0.6036644577980042, "eval/post_ent_mag": 32.90354537963867, "eval/post_ent_max": 32.90354537963867, "eval/post_ent_mean": 32.614463806152344, "eval/post_ent_min": 32.46540451049805, "eval/post_ent_std": 0.07437783479690552, "eval/prior_ent_mag": 34.32471466064453, "eval/prior_ent_max": 34.32471466064453, "eval/prior_ent_mean": 32.32502746582031, "eval/prior_ent_min": 30.949243545532227, "eval/prior_ent_std": 0.5518804788589478, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 3.465358167886734e-05, "eval/reward_loss_std": 0.0003829837660305202, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.004244565963745117, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 3.465358167886734e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 1.8538907170295715e-05, "eval/reward_rate": 0.0, "replay/size": 449505.0, "replay/inserts": 32160.0, "replay/samples": 32160.0, "replay/insert_wait_avg": 1.2939471510512318e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.837417706921326e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6360.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.180434376938538e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1003.3371138572693, "timer/env.step_count": 4020.0, "timer/env.step_total": 38.90367770195007, "timer/env.step_frac": 0.03877428350316597, "timer/env.step_avg": 0.009677531766654247, "timer/env.step_min": 0.007857322692871094, "timer/env.step_max": 0.03560447692871094, "timer/replay._sample_count": 32160.0, "timer/replay._sample_total": 17.36215353012085, "timer/replay._sample_frac": 0.01730440675454842, "timer/replay._sample_avg": 0.0005398679580261458, "timer/replay._sample_min": 0.0003802776336669922, "timer/replay._sample_max": 0.028366565704345703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4815.0, "timer/agent.policy_total": 51.07143568992615, "timer/agent.policy_frac": 0.050901571350814565, "timer/agent.policy_avg": 0.010606736384200654, "timer/agent.policy_min": 0.00883936882019043, "timer/agent.policy_max": 0.09373760223388672, "timer/dataset_train_count": 2010.0, "timer/dataset_train_total": 0.22023630142211914, "timer/dataset_train_frac": 0.00021950379227519444, "timer/dataset_train_avg": 0.00010957029921498464, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0005099773406982422, "timer/agent.train_count": 2010.0, "timer/agent.train_total": 899.5946002006531, "timer/agent.train_frac": 0.896602535455123, "timer/agent.train_avg": 0.4475595025873896, "timer/agent.train_min": 0.43743038177490234, "timer/agent.train_max": 1.7802612781524658, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4821817874908447, "timer/agent.report_frac": 0.00048057804384124276, "timer/agent.report_avg": 0.24109089374542236, "timer/agent.report_min": 0.23360180854797363, "timer/agent.report_max": 0.2485799789428711, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8752697047537857e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 32.05246846114106}
{"step": 450112, "time": 14272.482126712799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450224, "time": 14275.90256690979, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 450304, "time": 14278.358896017075, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 450488, "time": 14283.754863500595, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 450632, "time": 14288.658675193787, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 451016, "time": 14300.470039367676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451384, "time": 14311.662298440933, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 451640, "time": 14319.47644662857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451856, "time": 14326.2755215168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452088, "time": 14333.190162658691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452096, "time": 14333.658805131912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452128, "time": 14334.646708250046, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 452328, "time": 14340.48824095726, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 452560, "time": 14347.73833990097, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 452616, "time": 14349.238023996353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452648, "time": 14350.211853027344, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 452736, "time": 14353.09916806221, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 452800, "time": 14355.051972866058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453336, "time": 14371.21789097786, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 453456, "time": 14375.069810390472, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 454168, "time": 14396.541328430176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454248, "time": 14398.985544204712, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 454400, "time": 14403.87452173233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454424, "time": 14404.396251678467, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 454928, "time": 14419.948435783386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454960, "time": 14421.069893836975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455048, "time": 14423.537050247192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455200, "time": 14428.387621164322, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 455728, "time": 14444.462544679642, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 455768, "time": 14445.461698293686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455792, "time": 14446.436913251877, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 456184, "time": 14458.203682422638, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 456576, "time": 14470.362812280655, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 456712, "time": 14474.278839588165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457272, "time": 14491.40148115158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457512, "time": 14498.689260721207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458040, "time": 14514.80382514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458080, "time": 14516.235524654388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458104, "time": 14516.75005531311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458272, "time": 14522.174611330032, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 458704, "time": 14535.494339704514, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 458736, "time": 14536.46913933754, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 458888, "time": 14541.540594816208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458976, "time": 14544.458662986755, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 459024, "time": 14545.939828634262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459112, "time": 14548.418957948685, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 459344, "time": 14555.75170993805, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 459416, "time": 14557.729821920395, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 459568, "time": 14562.618136644363, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 459584, "time": 14563.11397242546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459640, "time": 14564.620572805405, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 459752, "time": 14568.03904056549, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 459824, "time": 14570.63340997696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 14580.842002391815, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 460096, "time": 14582.32630610466, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 460096, "time": 14584.745776414871, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14584.753078460693, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14584.764309883118, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14584.775587558746, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14584.850898265839, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14584.861363649368, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460400, "time": 14594.138791561127, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 460872, "time": 14608.401315927505, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 461136, "time": 14616.662219047546, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 461200, "time": 14618.599877357483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461656, "time": 14632.350377559662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461880, "time": 14639.14924955368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461896, "time": 14639.637111186981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462064, "time": 14644.958660125732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462712, "time": 14664.507168531418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463184, "time": 14679.010788440704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463448, "time": 14686.797441005707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463512, "time": 14688.775948047638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463968, "time": 14702.989013910294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464192, "time": 14709.814115524292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464208, "time": 14710.305516004562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464376, "time": 14715.221153020859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465024, "time": 14735.31929564476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465496, "time": 14749.479293823242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465760, "time": 14757.888050079346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465824, "time": 14759.827683448792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466280, "time": 14773.51464676857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466504, "time": 14780.34493637085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466520, "time": 14780.907707214355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466688, "time": 14786.225904226303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467336, "time": 14806.264619588852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467664, "time": 14816.661554813385, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 467808, "time": 14821.044910669327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468072, "time": 14828.806881427765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468136, "time": 14830.760060310364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468232, "time": 14833.664610385895, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 468832, "time": 14852.289246082306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469000, "time": 14857.182224273682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469208, "time": 14863.504261016846, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 469328, "time": 14867.377851009369, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 469648, "time": 14877.142229795456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469976, "time": 14886.905244112015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470048, "time": 14889.336944818497, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 14891.586619138718, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 470080, "time": 14892.184223651886, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 470080, "time": 14892.323915243149, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 470080, "time": 14892.740834474564, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 470080, "time": 14893.592425823212, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 470080, "time": 14893.937510490417, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 470080, "time": 14894.17118382454, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 470080, "time": 14894.500613212585, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 470120, "time": 14895.49249124527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470384, "time": 14903.874015569687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470592, "time": 14910.277649641037, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 471048, "time": 14923.93054986, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 471312, "time": 14932.266763925552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471520, "time": 14938.565878152847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471640, "time": 14941.99401807785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471712, "time": 14944.39018535614, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 471968, "time": 14952.169067144394, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 472168, "time": 14958.028436422348, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 472288, "time": 14962.026802301407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472360, "time": 14963.990947723389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472432, "time": 14966.428312778473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472904, "time": 14980.539261817932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473728, "time": 15005.884067058563, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 473952, "time": 15012.67499923706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474024, "time": 15014.659268856049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474280, "time": 15022.6104991436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474528, "time": 15030.37827372551, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 474576, "time": 15031.838329315186, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 474672, "time": 15034.780413627625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474744, "time": 15036.735753536224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474832, "time": 15039.66090297699, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 474944, "time": 15043.058941841125, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 475160, "time": 15049.872715473175, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 475216, "time": 15051.880417108536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475336, "time": 15055.33506822586, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 475384, "time": 15056.811562299728, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 475928, "time": 15073.420527458191, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 476040, "time": 15076.830406665802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476264, "time": 15083.765677452087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477144, "time": 15110.616909742355, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 477144, "time": 15110.624767541885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477256, "time": 15114.05435872078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477472, "time": 15120.826389074326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477576, "time": 15123.79635643959, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 477632, "time": 15125.731973409653, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 477648, "time": 15126.223804950714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477824, "time": 15131.56872844696, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 478088, "time": 15139.360416173935, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 478240, "time": 15144.336990594864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478352, "time": 15147.78577876091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478576, "time": 15154.63397860527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479888, "time": 15194.671124458313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479944, "time": 15196.156127691269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479960, "time": 15196.665323972702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 15201.052206993103, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 480064, "time": 15205.851441383362, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15205.858721971512, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15205.866157531738, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15205.873331785202, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15205.87984585762, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15205.886136054993, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15205.892183065414, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480136, "time": 15207.875132083893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480400, "time": 15216.105897665024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480552, "time": 15220.522291660309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480664, "time": 15223.927258491516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480888, "time": 15230.80328321457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481144, "time": 15238.581637144089, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 482121, "time": 15269.279022932053, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.0739278461209576, "train/action_min": 0.0, "train/action_std": 1.3371598008853287, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013014651823960319, "train/actor_opt_grad_steps": 29030.0, "train/actor_opt_loss": -8.535995147740051, "train/adv_mag": 0.8295097911535804, "train/adv_max": 0.29565152837269343, "train/adv_mean": 0.0007937274433368937, "train/adv_min": -0.8159038560900522, "train/adv_std": 0.04260730643789122, "train/cont_avg": 0.9960305892412935, "train/cont_loss_mean": 0.01282400265509791, "train/cont_loss_std": 0.20348781069383878, "train/cont_neg_acc": 0.4112947222901814, "train/cont_neg_loss": 2.5242459347476807, "train/cont_pos_acc": 0.9998097870480361, "train/cont_pos_loss": 0.0027596616908439914, "train/cont_pred": 0.9957956650956946, "train/cont_rate": 0.9960305892412935, "train/dyn_loss_mean": 1.0000069775984655, "train/dyn_loss_std": 0.0002119912934534145, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.46328981348605297, "train/extr_critic_critic_opt_grad_steps": 29030.0, "train/extr_critic_critic_opt_loss": 8303.703932728933, "train/extr_critic_mag": 0.9839750125040463, "train/extr_critic_max": 0.9839750125040463, "train/extr_critic_mean": 0.9149607135288751, "train/extr_critic_min": 0.8788575621979746, "train/extr_critic_std": 0.015115043046462596, "train/extr_return_normed_mag": 0.8055564829366124, "train/extr_return_normed_max": 0.36234955823243553, "train/extr_return_normed_mean": 0.030109789275329105, "train/extr_return_normed_min": -0.779441983842138, "train/extr_return_normed_std": 0.04655332887424758, "train/extr_return_rate": 0.997631680609575, "train/extr_return_raw_mag": 1.2479941874594238, "train/extr_return_raw_max": 1.2479941874594238, "train/extr_return_raw_mean": 0.9157544709556732, "train/extr_return_raw_min": 0.10620264538485019, "train/extr_return_raw_std": 0.04655332866574253, "train/extr_reward_mag": 0.31977221265954164, "train/extr_reward_max": 0.31977221265954164, "train/extr_reward_mean": 0.0019414169740352308, "train/extr_reward_min": 2.117299321872085e-07, "train/extr_reward_std": 0.013044757584911488, "train/image_loss_mean": 0.09254413800527207, "train/image_loss_std": 0.0978336643372009, "train/model_loss_mean": 0.7102259842317495, "train/model_loss_std": 0.31045718235311226, "train/model_opt_grad_norm": 27.954736856678824, "train/model_opt_grad_steps": 29001.800995024874, "train/model_opt_loss": 3010.3167335927783, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4241.293532338308, "train/policy_entropy_mag": 1.3003762930779907, "train/policy_entropy_max": 1.3003762930779907, "train/policy_entropy_mean": 0.1356041183444991, "train/policy_entropy_min": 0.06468656503442508, "train/policy_entropy_std": 0.1717692470520883, "train/policy_logprob_mag": 6.5510802079196, "train/policy_logprob_max": -0.008608143239175503, "train/policy_logprob_mean": -0.1355387528811521, "train/policy_logprob_min": -6.5510802079196, "train/policy_logprob_std": 0.6693419600600627, "train/policy_randomness_mag": 0.668261260239046, "train/policy_randomness_max": 0.668261260239046, "train/policy_randomness_mean": 0.06968673546590022, "train/policy_randomness_min": 0.03324232089208133, "train/policy_randomness_std": 0.08827193604031605, "train/post_ent_mag": 33.21082148385878, "train/post_ent_max": 33.21082148385878, "train/post_ent_mean": 32.92818236469629, "train/post_ent_min": 32.77296073875617, "train/post_ent_std": 0.07500912226847749, "train/prior_ent_mag": 34.67860329091845, "train/prior_ent_max": 34.67860329091845, "train/prior_ent_mean": 32.60999698544023, "train/prior_ent_min": 31.07672854561118, "train/prior_ent_std": 0.5308890698561027, "train/rep_loss_mean": 1.0000069775984655, "train/rep_loss_std": 0.0002119912934534145, "train/reward_avg": 0.0006268857157657697, "train/reward_loss_mean": 0.004853633055185426, "train/reward_loss_std": 0.10188010293238597, "train/reward_max_data": 0.44734141723581805, "train/reward_max_pred": 0.0979398251765996, "train/reward_neg_acc": 0.9998929696296578, "train/reward_neg_loss": 0.0009447527058661188, "train/reward_pos_acc": 0.17493112964078414, "train/reward_pos_loss": 4.2794726781608645, "train/reward_pred": 0.0005636025093894322, "train/reward_rate": 0.0008939676616915423, "train_stats/mean_log_entropy": 0.1292753220129181, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.01502316165715456, "report/cont_loss_std": 0.23446916043758392, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.565164804458618, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0025102009531110525, "report/cont_pred": 0.9956824779510498, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07911736518144608, "report/image_loss_std": 0.07671605795621872, "report/model_loss_mean": 0.7034626007080078, "report/model_loss_std": 0.41484442353248596, "report/post_ent_mag": 32.583152770996094, "report/post_ent_max": 32.583152770996094, "report/post_ent_mean": 32.29319763183594, "report/post_ent_min": 32.11918258666992, "report/post_ent_std": 0.08600544184446335, "report/prior_ent_mag": 34.45137023925781, "report/prior_ent_max": 34.45137023925781, "report/prior_ent_mean": 32.53904724121094, "report/prior_ent_min": 30.831777572631836, "report/prior_ent_std": 0.5548407435417175, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0015747069846838713, "report/reward_loss_mean": 0.009322093799710274, "report/reward_loss_std": 0.19308529794216156, "report/reward_max_data": 0.84375, "report/reward_max_pred": 0.024095773696899414, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0007924790843389928, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.367955684661865, "report/reward_pred": 0.00045332114677876234, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.036113373935222626, "eval/cont_loss_std": 0.574617326259613, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.691162109375, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0021720060613006353, "eval/cont_pred": 0.9983127117156982, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2140333354473114, "eval/image_loss_std": 0.1517295390367508, "eval/model_loss_mean": 0.8502458930015564, "eval/model_loss_std": 0.5909342169761658, "eval/post_ent_mag": 32.57912063598633, "eval/post_ent_max": 32.57912063598633, "eval/post_ent_mean": 32.2741813659668, "eval/post_ent_min": 32.13285827636719, "eval/post_ent_std": 0.08078832179307938, "eval/prior_ent_mag": 33.62514877319336, "eval/prior_ent_max": 33.62514877319336, "eval/prior_ent_mean": 32.26302719116211, "eval/prior_ent_min": 30.897552490234375, "eval/prior_ent_std": 0.47732284665107727, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 9.917980059981346e-05, "eval/reward_loss_std": 0.0006321397377178073, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0063697099685668945, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 9.917980059981346e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.2247196435928345e-05, "eval/reward_rate": 0.0, "replay/size": 481617.0, "replay/inserts": 32112.0, "replay/samples": 32112.0, "replay/insert_wait_avg": 1.2938321141621696e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.092956514458307e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6096.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1287727380987853e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0530371665955, "timer/env.step_count": 4014.0, "timer/env.step_total": 38.765191316604614, "timer/env.step_frac": 0.038763135429733066, "timer/env.step_avg": 0.009657496591082365, "timer/env.step_min": 0.007877826690673828, "timer/env.step_max": 0.03480648994445801, "timer/replay._sample_count": 32112.0, "timer/replay._sample_total": 17.119495630264282, "timer/replay._sample_frac": 0.017118587708876087, "timer/replay._sample_avg": 0.0005331183243106715, "timer/replay._sample_min": 0.0003752708435058594, "timer/replay._sample_max": 0.010094165802001953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4776.0, "timer/agent.policy_total": 50.72077965736389, "timer/agent.policy_frac": 0.05071808971359035, "timer/agent.policy_avg": 0.01061992873897904, "timer/agent.policy_min": 0.009126663208007812, "timer/agent.policy_max": 0.09078431129455566, "timer/dataset_train_count": 2007.0, "timer/dataset_train_total": 0.2194051742553711, "timer/dataset_train_frac": 0.0002193935382437333, "timer/dataset_train_avg": 0.00010931996724233736, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0004994869232177734, "timer/agent.train_count": 2007.0, "timer/agent.train_total": 897.0646116733551, "timer/agent.train_frac": 0.8970170364313549, "timer/agent.train_avg": 0.4469679181232462, "timer/agent.train_min": 0.4336733818054199, "timer/agent.train_max": 0.6886627674102783, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4698760509490967, "timer/agent.report_frac": 0.0004698511313763668, "timer/agent.report_avg": 0.23493802547454834, "timer/agent.report_min": 0.229278564453125, "timer/agent.report_max": 0.24059748649597168, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908552403660678e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 32.109775705601656}
{"step": 482200, "time": 15271.462283611298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482272, "time": 15273.844120025635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482448, "time": 15279.160250663757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482712, "time": 15287.00027513504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482864, "time": 15291.948416471481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482976, "time": 15295.369100093842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483200, "time": 15302.259015083313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483456, "time": 15310.583065271378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484512, "time": 15342.980829000473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484584, "time": 15344.950446844101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484760, "time": 15350.409116983414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485024, "time": 15358.647854328156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485176, "time": 15363.043053627014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485288, "time": 15366.459068536758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485512, "time": 15373.249297618866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485768, "time": 15381.121351718903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486080, "time": 15390.873757123947, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 486824, "time": 15413.265367031097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486896, "time": 15415.67731833458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487072, "time": 15420.983930110931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487192, "time": 15424.416058301926, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 487336, "time": 15428.796444654465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487600, "time": 15437.007988929749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487648, "time": 15438.473697423935, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 487824, "time": 15443.921215295792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488080, "time": 15451.65718793869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488392, "time": 15460.887339830399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489208, "time": 15485.622967720032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489456, "time": 15493.401752471924, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 489504, "time": 15494.851038217545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489648, "time": 15499.200931072235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489912, "time": 15507.073831558228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489960, "time": 15508.517110347748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489960, "time": 15508.525298833847, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 15516.746535778046, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15516.756278276443, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15516.765662670135, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15516.775430679321, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15516.783572912216, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15516.790087223053, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15516.800453424454, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15516.806972503662, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490392, "time": 15526.985017299652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490704, "time": 15536.761392831802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491008, "time": 15545.970554351807, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 491768, "time": 15569.359766244888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491816, "time": 15570.873341560364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491960, "time": 15575.316610336304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492224, "time": 15583.513122797012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492272, "time": 15584.985142230988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492272, "time": 15584.993453502655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492408, "time": 15588.884112358093, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 493016, "time": 15607.320409297943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493320, "time": 15616.543005943298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494128, "time": 15641.292316675186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494272, "time": 15645.631830453873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494536, "time": 15653.529017686844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494584, "time": 15654.974638938904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494584, "time": 15654.983110189438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494720, "time": 15659.370532035828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495328, "time": 15677.825177669525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495632, "time": 15687.142504692078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495648, "time": 15687.629143476486, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 496440, "time": 15711.43783068657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496584, "time": 15715.78216266632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496848, "time": 15723.968169689178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496896, "time": 15725.432795286179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497032, "time": 15729.33347439766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497120, "time": 15732.227682590485, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 497640, "time": 15747.867389917374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497824, "time": 15753.669069290161, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 497960, "time": 15757.588156223297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498896, "time": 15786.210094928741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499160, "time": 15793.94707274437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499208, "time": 15795.395961999893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499344, "time": 15799.742367506027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499432, "time": 15802.270310163498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499784, "time": 15813.475891590118, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 15826.654831171036, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15826.662914037704, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15826.672036886215, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15826.680250167847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15826.69045162201, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15826.697588682175, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15826.70549583435, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 15826.713240623474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500136, "time": 15829.67590045929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500272, "time": 15834.145073413849, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501208, "time": 15862.385226488113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501472, "time": 15870.660600185394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501520, "time": 15872.122044563293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501656, "time": 15876.021296977997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501744, "time": 15878.919981002808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502096, "time": 15889.527287721634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502448, "time": 15900.36126613617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502512, "time": 15902.315775632858, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 502584, "time": 15904.271187067032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503208, "time": 15923.369749069214, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 503384, "time": 15928.706793308258, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 503536, "time": 15933.528728485107, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 503784, "time": 15940.754476308823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503832, "time": 15942.21952199936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503968, "time": 15946.559062480927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504088, "time": 15949.963260650635, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 504128, "time": 15951.539727449417, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 504392, "time": 15959.359753847122, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 504824, "time": 15972.411585092545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504896, "time": 15974.803349256516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505520, "time": 15993.804768562317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505696, "time": 15999.11547446251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506040, "time": 16009.28655910492, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 506280, "time": 16016.659046888351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506400, "time": 16020.525467395782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506704, "time": 16029.762895822525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507136, "time": 16042.886963367462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507160, "time": 16043.411711215973, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 507208, "time": 16044.86160326004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507360, "time": 16049.671647310257, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 507528, "time": 16054.545540809631, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 507728, "time": 16060.826958656311, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 507832, "time": 16063.795559883118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507912, "time": 16066.465153694153, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 508008, "time": 16069.703054904938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 508216, "time": 16076.118169307709, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 508224, "time": 16076.586894273758, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 508376, "time": 16080.9607360363, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 508472, "time": 16083.87413907051, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 508712, "time": 16091.140738487244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 508776, "time": 16093.098569869995, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 508928, "time": 16097.928795337677, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 509176, "time": 16105.268865823746, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 509520, "time": 16115.824304580688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509536, "time": 16116.309602975845, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 509840, "time": 16125.476491212845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 16131.525957584381, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 510016, "time": 16132.308670043945, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 510016, "time": 16132.316192865372, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 510016, "time": 16132.70088839531, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 510016, "time": 16133.123157024384, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 510016, "time": 16134.574140548706, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 510016, "time": 16135.086555480957, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 510016, "time": 16135.566726922989, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 510224, "time": 16141.882150411606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510288, "time": 16143.812679052353, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 510536, "time": 16151.106570243835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510784, "time": 16158.825679063797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511024, "time": 16166.185006856918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511088, "time": 16168.119530439377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511488, "time": 16180.18898177147, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 511832, "time": 16190.45064496994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511848, "time": 16190.94127702713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511944, "time": 16193.839104890823, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 512312, "time": 16205.01524925232, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 512536, "time": 16211.783949613571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512560, "time": 16212.72954750061, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 512600, "time": 16213.746090650558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513096, "time": 16228.910207509995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513336, "time": 16236.122634887695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513800, "time": 16250.144785165787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514144, "time": 16260.831070184708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514160, "time": 16261.321907281876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514409, "time": 16269.62851023674, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4758046971689356, "train/action_min": 0.0, "train/action_std": 1.4977670276519095, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007038567703341752, "train/actor_opt_grad_steps": 31045.0, "train/actor_opt_loss": -7.501378851066722, "train/adv_mag": 0.6540610326988863, "train/adv_max": 0.21504034323267418, "train/adv_mean": 0.00027966445635107753, "train/adv_min": -0.6284005476696657, "train/adv_std": 0.02539500240282626, "train/cont_avg": 0.99609375, "train/cont_loss_mean": 0.012784892686246203, "train/cont_loss_std": 0.20048889801791397, "train/cont_neg_acc": 0.41947222866117956, "train/cont_neg_loss": 2.51511466212949, "train/cont_pos_acc": 0.9998300892881827, "train/cont_pos_loss": 0.0026861288455674553, "train/cont_pred": 0.9959492754228044, "train/cont_rate": 0.99609375, "train/dyn_loss_mean": 1.000004256715869, "train/dyn_loss_std": 0.0001310184851546984, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.274720276300196, "train/extr_critic_critic_opt_grad_steps": 31045.0, "train/extr_critic_critic_opt_loss": 8713.125635732518, "train/extr_critic_mag": 0.8885620820640338, "train/extr_critic_max": 0.8885620820640338, "train/extr_critic_mean": 0.8318944723889379, "train/extr_critic_min": 0.7985621578622573, "train/extr_critic_std": 0.01385857191600717, "train/extr_return_normed_mag": 0.6463970471136641, "train/extr_return_normed_max": 0.2555197766511747, "train/extr_return_normed_mean": 0.0246333446322553, "train/extr_return_normed_min": -0.6062234896834534, "train/extr_return_normed_std": 0.030022308507030554, "train/extr_return_rate": 0.9987514603255999, "train/extr_return_raw_mag": 1.0630605185385977, "train/extr_return_raw_max": 1.0630605185385977, "train/extr_return_raw_mean": 0.8321741199729467, "train/extr_return_raw_min": 0.20131725249904217, "train/extr_return_raw_std": 0.030022308465535982, "train/extr_reward_mag": 0.26990047834887365, "train/extr_reward_max": 0.26990047834887365, "train/extr_reward_mean": 0.0011864361796223518, "train/extr_reward_min": 1.6406030938176824e-07, "train/extr_reward_std": 0.008203026709506418, "train/image_loss_mean": 0.08975254393892713, "train/image_loss_std": 0.09602873196991363, "train/model_loss_mean": 0.7079797812027506, "train/model_loss_std": 0.3185726255547292, "train/model_opt_grad_norm": 26.601415265904794, "train/model_opt_grad_steps": 31014.762376237624, "train/model_opt_loss": 2681.1469774907177, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3787.128712871287, "train/policy_entropy_mag": 1.2202922867076231, "train/policy_entropy_max": 1.2202922867076231, "train/policy_entropy_mean": 0.11239745560111386, "train/policy_entropy_min": 0.06468654482966603, "train/policy_entropy_std": 0.14131625833930356, "train/policy_logprob_mag": 6.551080243422254, "train/policy_logprob_max": -0.008608152001801104, "train/policy_logprob_mean": -0.11271895136278455, "train/policy_logprob_min": -6.551080243422254, "train/policy_logprob_std": 0.6511447798497606, "train/policy_randomness_mag": 0.6271062218906855, "train/policy_randomness_max": 0.6271062218906855, "train/policy_randomness_mean": 0.05776086905141278, "train/policy_randomness_min": 0.0332423103143378, "train/policy_randomness_std": 0.07262219545791054, "train/post_ent_mag": 33.279769123190704, "train/post_ent_max": 33.279769123190704, "train/post_ent_mean": 32.99333873597702, "train/post_ent_min": 32.83177042479562, "train/post_ent_std": 0.07933678389480799, "train/prior_ent_mag": 33.90606396741206, "train/prior_ent_max": 33.90606396741206, "train/prior_ent_mean": 32.375093677256366, "train/prior_ent_min": 31.03096635270827, "train/prior_ent_std": 0.45341169362020967, "train/rep_loss_mean": 1.000004256715869, "train/rep_loss_std": 0.0001310184851546984, "train/reward_avg": 0.0006887001574868198, "train/reward_loss_mean": 0.005439771331228906, "train/reward_loss_std": 0.11431014658404874, "train/reward_max_data": 0.46587252506230137, "train/reward_max_pred": 0.10986489647685892, "train/reward_neg_acc": 0.999796733997836, "train/reward_neg_loss": 0.0009474516885861118, "train/reward_pos_acc": 0.1772609823202902, "train/reward_pos_loss": 4.486633452334146, "train/reward_pred": 0.0005533250191682341, "train/reward_rate": 0.0009959003712871287, "train_stats/mean_log_entropy": 0.10622437722491522, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.013246230781078339, "report/cont_loss_std": 0.17779682576656342, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 1.9028271436691284, "report/cont_pos_acc": 0.999018669128418, "report/cont_pos_loss": 0.003974489867687225, "report/cont_pred": 0.9950015544891357, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07767088711261749, "report/image_loss_std": 0.08676304668188095, "report/model_loss_mean": 0.6971440315246582, "report/model_loss_std": 0.3048369884490967, "report/post_ent_mag": 33.52231979370117, "report/post_ent_max": 33.52231979370117, "report/post_ent_mean": 33.23202896118164, "report/post_ent_min": 33.06756591796875, "report/post_ent_std": 0.08385027945041656, "report/prior_ent_mag": 33.395240783691406, "report/prior_ent_max": 33.395240783691406, "report/prior_ent_mean": 32.03596115112305, "report/prior_ent_min": 30.932889938354492, "report/prior_ent_std": 0.3676764965057373, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018310546875, "report/reward_loss_mean": 0.006226873025298119, "report/reward_loss_std": 0.16819074749946594, "report/reward_max_data": 0.1875, "report/reward_max_pred": 0.06475412845611572, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0009721406968310475, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.381817817687988, "report/reward_pred": 0.0005610797088593245, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.07135102152824402, "eval/cont_loss_std": 0.9101433157920837, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.843769073486328, "eval/cont_pos_acc": 0.9990177154541016, "eval/cont_pos_loss": 0.001965450355783105, "eval/cont_pred": 0.9983220100402832, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1744970977306366, "eval/image_loss_std": 0.14059937000274658, "eval/model_loss_mean": 0.845928966999054, "eval/model_loss_std": 0.928528368473053, "eval/post_ent_mag": 33.51873779296875, "eval/post_ent_max": 33.51873779296875, "eval/post_ent_mean": 33.23646545410156, "eval/post_ent_min": 33.081626892089844, "eval/post_ent_std": 0.07713740319013596, "eval/prior_ent_mag": 33.84709930419922, "eval/prior_ent_max": 33.84709930419922, "eval/prior_ent_mean": 32.03237533569336, "eval/prior_ent_min": 30.773204803466797, "eval/prior_ent_std": 0.41165459156036377, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 8.084578439593315e-05, "eval/reward_loss_std": 0.000771399587392807, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.007281184196472168, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 8.084578439593315e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.145095590502024e-05, "eval/reward_rate": 0.0, "replay/size": 513905.0, "replay/inserts": 32288.0, "replay/samples": 32288.0, "replay/insert_wait_avg": 1.2908850836210373e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.975296411807284e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6296.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0803815218817626e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3363587856293, "timer/env.step_count": 4036.0, "timer/env.step_total": 38.5903263092041, "timer/env.step_frac": 0.03857735047844438, "timer/env.step_avg": 0.009561527826859291, "timer/env.step_min": 0.007823944091796875, "timer/env.step_max": 0.04430508613586426, "timer/replay._sample_count": 32288.0, "timer/replay._sample_total": 17.13668942451477, "timer/replay._sample_frac": 0.01713092728661594, "timer/replay._sample_avg": 0.0005307448409475585, "timer/replay._sample_min": 0.00042700767517089844, "timer/replay._sample_max": 0.011255741119384766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4823.0, "timer/agent.policy_total": 50.35788130760193, "timer/agent.policy_frac": 0.050340948687234065, "timer/agent.policy_avg": 0.010441194548538655, "timer/agent.policy_min": 0.009007930755615234, "timer/agent.policy_max": 0.08939409255981445, "timer/dataset_train_count": 2018.0, "timer/dataset_train_total": 0.2179851531982422, "timer/dataset_train_frac": 0.00021791185663077163, "timer/dataset_train_avg": 0.00010802039306156699, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0010776519775390625, "timer/agent.train_count": 2018.0, "timer/agent.train_total": 898.2023015022278, "timer/agent.train_frac": 0.8979002848527985, "timer/agent.train_avg": 0.44509529311309604, "timer/agent.train_min": 0.432159423828125, "timer/agent.train_max": 0.7104275226593018, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.477431058883667, "timer/agent.report_frac": 0.0004772705247495456, "timer/agent.report_avg": 0.2387155294418335, "timer/agent.report_min": 0.23188567161560059, "timer/agent.report_max": 0.2455453872680664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00011658668518066406, "timer/dataset_eval_frac": 1.165474834106759e-07, "timer/dataset_eval_avg": 0.00011658668518066406, "timer/dataset_eval_min": 0.00011658668518066406, "timer/dataset_eval_max": 0.00011658668518066406, "fps": 32.276601352456254}
{"step": 514656, "time": 16277.109441041946, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 514848, "time": 16283.105085849762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514872, "time": 16283.623746395111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514912, "time": 16285.07723236084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515152, "time": 16292.441521644592, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 515408, "time": 16300.174046039581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515440, "time": 16301.144355297089, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 515648, "time": 16307.462612867355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516112, "time": 16322.031615018845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516632, "time": 16337.663982391357, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 517000, "time": 16348.955781936646, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 517160, "time": 16353.840739488602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517184, "time": 16354.798545122147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517224, "time": 16355.797565698624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517464, "time": 16363.150971412659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517680, "time": 16369.964149475098, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 517720, "time": 16371.118273496628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517752, "time": 16372.089576244354, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 517752, "time": 16372.099605321884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518296, "time": 16388.553213834763, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 519312, "time": 16419.803799390793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519472, "time": 16424.658234357834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519536, "time": 16426.596053123474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519776, "time": 16434.006378173828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519992, "time": 16440.410766124725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 16442.023753643036, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 520000, "time": 16442.870620250702, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 520000, "time": 16446.405598163605, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16446.41376209259, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16446.421644687653, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16446.429971933365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16446.439007520676, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16446.44700193405, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520032, "time": 16447.428262233734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520064, "time": 16448.403848409653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520360, "time": 16457.208616018295, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 520560, "time": 16463.544314146042, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 520560, "time": 16463.55158662796, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 520592, "time": 16464.543439149857, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 520608, "time": 16465.037291526794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520616, "time": 16465.065441846848, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 521624, "time": 16495.682565927505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521848, "time": 16502.457991600037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522088, "time": 16509.756221055984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522408, "time": 16519.497881412506, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 522872, "time": 16533.782685756683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522872, "time": 16533.791976213455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522904, "time": 16534.763912677765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522920, "time": 16535.250420808792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522928, "time": 16535.722774505615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523240, "time": 16544.965358018875, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 523808, "time": 16562.437530755997, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 523936, "time": 16566.30365371704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524160, "time": 16573.165647506714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524296, "time": 16577.338825941086, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 524472, "time": 16583.093695878983, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 524720, "time": 16590.863023281097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524808, "time": 16593.362955331802, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 525024, "time": 16600.2329082489, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 525032, "time": 16600.261280059814, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 525184, "time": 16605.083722114563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525184, "time": 16605.090396165848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525216, "time": 16606.053211927414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525240, "time": 16606.579273462296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525304, "time": 16608.507130622864, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 525512, "time": 16614.89363336563, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 525520, "time": 16615.36184167862, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 525904, "time": 16627.07844877243, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 526104, "time": 16632.96621823311, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 526560, "time": 16647.19431090355, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 527120, "time": 16664.119961977005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527144, "time": 16664.631385803223, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 527344, "time": 16671.03541970253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527512, "time": 16675.915595531464, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 527616, "time": 16679.276915550232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528112, "time": 16694.34422802925, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 528216, "time": 16697.258685112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528416, "time": 16703.6687104702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528456, "time": 16704.683839797974, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 528616, "time": 16709.52371239662, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 528656, "time": 16710.957632780075, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 528872, "time": 16717.289026737213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529312, "time": 16730.873863697052, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 529376, "time": 16732.798617124557, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 529656, "time": 16741.067539215088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529824, "time": 16746.36008286476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530080, "time": 16754.082230091095, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 16754.609260559082, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 530088, "time": 16755.053350925446, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 530088, "time": 16756.231540203094, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 530088, "time": 16756.873448848724, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 530088, "time": 16757.408968687057, "eval_episode/length": 178.0, "eval_episode/score": 0.4437499940395355, "eval_episode/reward_rate": 0.00558659217877095}
{"step": 530088, "time": 16757.88385105133, "eval_episode/length": 204.0, "eval_episode/score": 0.36250001192092896, "eval_episode/reward_rate": 0.004878048780487805}
{"step": 530088, "time": 16758.940569400787, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 530088, "time": 16759.40253019333, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 16759.412207603455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530648, "time": 16776.42547392845, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 530728, "time": 16778.85509467125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530768, "time": 16780.278378725052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530928, "time": 16785.107990026474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531184, "time": 16792.971534967422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531504, "time": 16802.621439933777, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 531624, "time": 16806.03224492073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531704, "time": 16808.499140501022, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 532136, "time": 16821.61766076088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532336, "time": 16827.890956163406, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 532392, "time": 16829.37059688568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532408, "time": 16829.86591076851, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 532512, "time": 16833.722581624985, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 533040, "time": 16849.679985284805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533240, "time": 16855.607355117798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533792, "time": 16872.481395721436, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 534016, "time": 16879.22949552536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534448, "time": 16892.389273166656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534648, "time": 16898.19195008278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534704, "time": 16900.119636535645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534720, "time": 16900.6092813015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534824, "time": 16903.562233924866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534992, "time": 16908.92371249199, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 535152, "time": 16913.839248418808, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 535160, "time": 16913.865348100662, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 535216, "time": 16915.766630411148, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 535352, "time": 16919.731429576874, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 535352, "time": 16919.740485668182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536104, "time": 16942.56268310547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536328, "time": 16949.334867715836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536568, "time": 16956.585320711136, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 536760, "time": 16962.395436525345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536824, "time": 16964.32746577263, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 537064, "time": 16971.66943359375, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 537456, "time": 16983.739646673203, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 537528, "time": 16985.707310199738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537664, "time": 16990.04053711891, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 537664, "time": 16990.09153199196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537936, "time": 16998.29707980156, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 537968, "time": 16999.25693464279, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 538080, "time": 17002.74278330803, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 538104, "time": 17003.257457733154, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 538328, "time": 17010.066654205322, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 538416, "time": 17012.962731599808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538640, "time": 17019.73645234108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538856, "time": 17026.048420906067, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 539128, "time": 17034.389909029007, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 539840, "time": 17057.639441251755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 17066.080727815628, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 540072, "time": 17066.562193870544, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 540072, "time": 17067.50484609604, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 540072, "time": 17067.97504043579, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 540072, "time": 17069.11056637764, "eval_episode/length": 232.0, "eval_episode/score": 0.2750000059604645, "eval_episode/reward_rate": 0.004291845493562232}
{"step": 540072, "time": 17069.44145655632, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 540072, "time": 17069.658700227737, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 540072, "time": 17070.214506149292, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17070.22199821472, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17070.229591846466, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540248, "time": 17075.56810092926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540280, "time": 17076.566447734833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540392, "time": 17079.928211927414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540592, "time": 17086.207461357117, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 540728, "time": 17090.658284425735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540952, "time": 17097.423951387405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 541088, "time": 17101.769310474396, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 541168, "time": 17104.20438361168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 541400, "time": 17111.017822027206, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 541440, "time": 17112.444081306458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 541584, "time": 17116.83623957634, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 541640, "time": 17118.303239107132, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 541960, "time": 17128.168738126755, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 542000, "time": 17129.61897802353, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 542376, "time": 17140.831485509872, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 542560, "time": 17146.639751911163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542704, "time": 17151.11141896248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542744, "time": 17152.103214025497, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 543040, "time": 17161.271587371826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543256, "time": 17167.583929777145, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 543288, "time": 17168.551327466965, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 543400, "time": 17171.950754404068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543896, "time": 17186.992437839508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544232, "time": 17197.115555524826, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 544272, "time": 17198.55356001854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544312, "time": 17199.535576820374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544384, "time": 17201.901591062546, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 544504, "time": 17205.29606127739, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 544608, "time": 17208.649152755737, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 544904, "time": 17217.43044757843, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 544952, "time": 17218.89949965477, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 545056, "time": 17222.25219798088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545264, "time": 17228.61093068123, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 545872, "time": 17247.028338432312, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 546112, "time": 17254.251645565033, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 546112, "time": 17254.26124572754, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 546536, "time": 17266.88074040413, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 546544, "time": 17267.348779678345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 546601, "time": 17269.82358956337, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.512920322702892, "train/action_min": 0.0, "train/action_std": 1.6026906783307964, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004185867296886255, "train/actor_opt_grad_steps": 33060.0, "train/actor_opt_loss": -7.70128871181711, "train/adv_mag": 0.6120478703607968, "train/adv_max": 0.12987890676479436, "train/adv_mean": -0.001145045326688774, "train/adv_min": -0.5971044488807222, "train/adv_std": 0.014561243295039408, "train/cont_avg": 0.9958702580845771, "train/cont_loss_mean": 0.01335686686436011, "train/cont_loss_std": 0.21118312250285304, "train/cont_neg_acc": 0.3970726708221675, "train/cont_neg_loss": 2.6201051505292465, "train/cont_pos_acc": 0.9998877472545377, "train/cont_pos_loss": 0.0025127735944576006, "train/cont_pred": 0.9959700721413342, "train/cont_rate": 0.9958702580845771, "train/dyn_loss_mean": 1.0000006844155231, "train/dyn_loss_std": 2.188937560729312e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11262748666821205, "train/extr_critic_critic_opt_grad_steps": 33060.0, "train/extr_critic_critic_opt_loss": 10435.657265430658, "train/extr_critic_mag": 0.8566714857348162, "train/extr_critic_max": 0.8566714857348162, "train/extr_critic_mean": 0.8076810516528229, "train/extr_critic_min": 0.7598920230248675, "train/extr_critic_std": 0.01048927732849892, "train/extr_return_normed_mag": 0.6150430325251907, "train/extr_return_normed_max": 0.15025160472784468, "train/extr_return_normed_mean": 0.01624425298656541, "train/extr_return_normed_min": -0.5908181957937592, "train/extr_return_normed_std": 0.018344046876983558, "train/extr_return_rate": 0.9995171027397042, "train/extr_return_raw_mag": 0.9405433114488326, "train/extr_return_raw_max": 0.9405433114488326, "train/extr_return_raw_mean": 0.8065360069867984, "train/extr_return_raw_min": 0.1994735109272288, "train/extr_return_raw_std": 0.01834404684454944, "train/extr_reward_mag": 0.19436082733211232, "train/extr_reward_max": 0.19436082733211232, "train/extr_reward_mean": 0.0008755308756632591, "train/extr_reward_min": 1.3878096395464086e-07, "train/extr_reward_std": 0.004433032288563563, "train/image_loss_mean": 0.08761647134203816, "train/image_loss_std": 0.09684964076648304, "train/model_loss_mean": 0.7067226281213523, "train/model_loss_std": 0.33427380722257033, "train/model_opt_grad_norm": 25.516355685333707, "train/model_opt_grad_steps": 33028.42288557214, "train/model_opt_loss": 3586.7114027032803, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5074.626865671642, "train/policy_entropy_mag": 1.1820238069515323, "train/policy_entropy_max": 1.1820238069515323, "train/policy_entropy_mean": 0.09673938992901228, "train/policy_entropy_min": 0.06468657144711386, "train/policy_entropy_std": 0.11543264303041335, "train/policy_logprob_mag": 6.551080252993759, "train/policy_logprob_max": -0.008608144416070697, "train/policy_logprob_mean": -0.09676103260534913, "train/policy_logprob_min": -6.551080252993759, "train/policy_logprob_std": 0.6353482188870064, "train/policy_randomness_mag": 0.6074401115007069, "train/policy_randomness_max": 0.6074401115007069, "train/policy_randomness_mean": 0.049714214543798076, "train/policy_randomness_min": 0.03324232493244594, "train/policy_randomness_std": 0.05932064771429816, "train/post_ent_mag": 33.46227480760261, "train/post_ent_max": 33.46227480760261, "train/post_ent_mean": 33.17260265824807, "train/post_ent_min": 33.00571246170879, "train/post_ent_std": 0.08565724326010367, "train/prior_ent_mag": 34.48034130874558, "train/prior_ent_max": 34.48034130874558, "train/prior_ent_mean": 32.681583499433984, "train/prior_ent_min": 31.405540485287187, "train/prior_ent_std": 0.46730516398724037, "train/rep_loss_mean": 1.0000006844155231, "train/rep_loss_std": 2.188937560729312e-05, "train/reward_avg": 0.0007618918351189637, "train/reward_loss_mean": 0.005748858214912019, "train/reward_loss_std": 0.12244524295031746, "train/reward_max_data": 0.5119247509175865, "train/reward_max_pred": 0.15000406307960623, "train/reward_neg_acc": 0.9998296893651213, "train/reward_neg_loss": 0.0009160453474076131, "train/reward_pos_acc": 0.24229885123927017, "train/reward_pos_loss": 4.222065464381514, "train/reward_pred": 0.0005995890105940143, "train/reward_rate": 0.001146610696517413, "train_stats/mean_log_entropy": 0.09293019690296866, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.007621659431606531, "report/cont_loss_std": 0.135895237326622, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 0.9438486099243164, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030278083868324757, "report/cont_pred": 0.9934357404708862, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06676226109266281, "report/image_loss_std": 0.07481266558170319, "report/model_loss_mean": 0.6826075315475464, "report/model_loss_std": 0.33423367142677307, "report/post_ent_mag": 33.63489532470703, "report/post_ent_max": 33.63489532470703, "report/post_ent_mean": 33.32617950439453, "report/post_ent_min": 33.16825866699219, "report/post_ent_std": 0.09036651998758316, "report/prior_ent_mag": 34.19035339355469, "report/prior_ent_max": 34.19035339355469, "report/prior_ent_mean": 32.766395568847656, "report/prior_ent_min": 31.735355377197266, "report/prior_ent_std": 0.40639179944992065, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0012634277809411287, "report/reward_loss_mean": 0.00822361558675766, "report/reward_loss_std": 0.1826864629983902, "report/reward_max_data": 0.846875011920929, "report/reward_max_pred": 0.6495765447616577, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0010118777863681316, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 3.6934218406677246, "report/reward_pred": 0.0011820504441857338, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.013181294314563274, "eval/cont_loss_std": 0.35403871536254883, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.328137397766113, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0021207306999713182, "eval/cont_pred": 0.9979737997055054, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24849575757980347, "eval/image_loss_std": 0.1708783060312271, "eval/model_loss_mean": 0.8620938658714294, "eval/model_loss_std": 0.3909187614917755, "eval/post_ent_mag": 33.63493347167969, "eval/post_ent_max": 33.63493347167969, "eval/post_ent_mean": 33.325279235839844, "eval/post_ent_min": 33.17035675048828, "eval/post_ent_std": 0.08402843773365021, "eval/prior_ent_mag": 34.125572204589844, "eval/prior_ent_max": 34.125572204589844, "eval/prior_ent_mean": 32.74531555175781, "eval/prior_ent_min": 31.589515686035156, "eval/prior_ent_std": 0.3972436785697937, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00041682273149490356, "eval/reward_loss_std": 0.004089806694537401, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.053305745124816895, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00041682273149490356, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022398494184017181, "eval/reward_rate": 0.0, "replay/size": 546097.0, "replay/inserts": 32192.0, "replay/samples": 32192.0, "replay/insert_wait_avg": 1.2956604094912944e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.950199053254326e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1027890505675213e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.176691532135, "timer/env.step_count": 4024.0, "timer/env.step_total": 38.107250928878784, "timer/env.step_frac": 0.038100518889821, "timer/env.step_avg": 0.009469992775566299, "timer/env.step_min": 0.0076351165771484375, "timer/env.step_max": 0.05337953567504883, "timer/replay._sample_count": 32192.0, "timer/replay._sample_total": 17.175910472869873, "timer/replay._sample_frac": 0.017172876171068042, "timer/replay._sample_avg": 0.0005335459267168822, "timer/replay._sample_min": 0.0003764629364013672, "timer/replay._sample_max": 0.03517341613769531, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4891.0, "timer/agent.policy_total": 50.644105434417725, "timer/agent.policy_frac": 0.05063515863065937, "timer/agent.policy_avg": 0.010354550283054124, "timer/agent.policy_min": 0.008807182312011719, "timer/agent.policy_max": 0.0784754753112793, "timer/dataset_train_count": 2012.0, "timer/dataset_train_total": 0.2168724536895752, "timer/dataset_train_frac": 0.00021683414093299455, "timer/dataset_train_avg": 0.00010778948990535547, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0004942417144775391, "timer/agent.train_count": 2012.0, "timer/agent.train_total": 897.6261067390442, "timer/agent.train_frac": 0.8974675318258044, "timer/agent.train_avg": 0.4461362359537993, "timer/agent.train_min": 0.43159914016723633, "timer/agent.train_max": 1.9879658222198486, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4750087261199951, "timer/agent.report_frac": 0.0004749248109275034, "timer/agent.report_avg": 0.23750436305999756, "timer/agent.report_min": 0.23006725311279297, "timer/agent.report_max": 0.24494147300720215, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908192811995367e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 32.18576582193103}
{"step": 546816, "time": 17276.450582265854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 546832, "time": 17276.956410884857, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 546880, "time": 17278.420627117157, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 547216, "time": 17288.685279130936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547264, "time": 17290.142588615417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547576, "time": 17299.410259008408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548496, "time": 17327.742807388306, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 548704, "time": 17334.16607284546, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 548848, "time": 17338.521136283875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548856, "time": 17338.550021886826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549128, "time": 17347.369101285934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549136, "time": 17347.83862066269, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 549144, "time": 17347.86697459221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549376, "time": 17355.14391207695, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 549528, "time": 17359.53988146782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549904, "time": 17371.33527827263, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 17378.504897356033, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 550056, "time": 17378.5294008255, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 550056, "time": 17379.613084077835, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 550056, "time": 17379.850895166397, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 550056, "time": 17381.03707408905, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 550056, "time": 17381.668426036835, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17381.674677848816, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17381.682818174362, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17381.688500881195, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17381.69535923004, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550184, "time": 17385.576231718063, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 550224, "time": 17387.03477692604, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 550344, "time": 17390.546582698822, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 550616, "time": 17398.82342362404, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 550808, "time": 17404.646898269653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551160, "time": 17415.374961853027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551168, "time": 17415.84366941452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551440, "time": 17424.233822107315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551840, "time": 17436.467042207718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552232, "time": 17448.190311908722, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 552496, "time": 17456.52396464348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552504, "time": 17456.552849054337, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 552656, "time": 17461.420068740845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552920, "time": 17469.25323009491, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 552928, "time": 17469.723183631897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553120, "time": 17475.55302286148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553512, "time": 17487.321244239807, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 553752, "time": 17494.57279920578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553992, "time": 17501.869158744812, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 554152, "time": 17506.74408197403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554184, "time": 17507.713985919952, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 554512, "time": 17517.966945171356, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 554544, "time": 17518.937289237976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554704, "time": 17523.751269340515, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 554968, "time": 17531.49058651924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 555056, "time": 17534.38001513481, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 555240, "time": 17539.712166547775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 555432, "time": 17545.61894583702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 555816, "time": 17557.224539279938, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 555976, "time": 17562.064123868942, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 556168, "time": 17567.86245083809, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 556304, "time": 17572.31743645668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556496, "time": 17578.11657333374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556656, "time": 17582.976044416428, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 556824, "time": 17587.85218644142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557016, "time": 17593.65712785721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557368, "time": 17604.845418691635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557792, "time": 17617.936832666397, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 558128, "time": 17628.11260652542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558288, "time": 17633.045201301575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558472, "time": 17638.40015912056, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 558480, "time": 17638.86943936348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558616, "time": 17642.747824192047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558968, "time": 17653.36377286911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559048, "time": 17655.773679971695, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 559136, "time": 17658.630044460297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559176, "time": 17659.62828183174, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 559464, "time": 17668.399507284164, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 559576, "time": 17671.793548822403, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 559840, "time": 17680.03531074524, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 559896, "time": 17681.508120059967, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 17687.806834459305, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 560040, "time": 17688.007633447647, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 560040, "time": 17688.788484334946, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 560040, "time": 17689.80289721489, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 560040, "time": 17691.216792583466, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17691.2261197567, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17691.233781814575, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17691.243787765503, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17691.251650094986, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17691.26213812828, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560360, "time": 17700.94819164276, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 560792, "time": 17713.992789506912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 560816, "time": 17714.94065284729, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 560928, "time": 17718.321415424347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561136, "time": 17724.660984277725, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 561200, "time": 17726.582751989365, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 561288, "time": 17729.0257499218, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 561360, "time": 17731.417744398117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561528, "time": 17736.253502607346, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 561768, "time": 17743.49356675148, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 561928, "time": 17748.329550027847, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 562672, "time": 17771.163749217987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563240, "time": 17788.457629680634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563448, "time": 17794.780930042267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563600, "time": 17799.597160339355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563672, "time": 17801.56210541725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563840, "time": 17806.84561753273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564080, "time": 17814.1900370121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564240, "time": 17819.006194114685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564424, "time": 17824.339577913284, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 564984, "time": 17841.2821559906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565552, "time": 17859.170750379562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565760, "time": 17865.478818655014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565912, "time": 17869.847311735153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566152, "time": 17877.196401834488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566160, "time": 17877.66093468666, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 566280, "time": 17881.06913471222, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 566304, "time": 17882.01930975914, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 566392, "time": 17884.47548890114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566688, "time": 17893.68879199028, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 566736, "time": 17895.13556790352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566912, "time": 17900.57934641838, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 567440, "time": 17916.536877155304, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 567664, "time": 17923.32685661316, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 567808, "time": 17927.681663513184, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 567864, "time": 17929.15329527855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568152, "time": 17937.93616437912, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 568464, "time": 17947.610295057297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568616, "time": 17951.966605901718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568704, "time": 17954.850410461426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 569048, "time": 17965.235100984573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 569120, "time": 17967.65142226219, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 569240, "time": 17971.0718896389, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 569976, "time": 17993.306626081467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 17996.64793920517, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 570024, "time": 17996.76414513588, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 570024, "time": 17999.16124677658, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 570024, "time": 18000.081328868866, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18000.09095811844, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18000.09889602661, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18000.109487771988, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18000.11885881424, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18000.129516601562, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570464, "time": 18013.633025169373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570776, "time": 18022.91552090645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570928, "time": 18027.70547413826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571016, "time": 18030.146420955658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571360, "time": 18040.68989777565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571432, "time": 18042.62254166603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571552, "time": 18046.442631721497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571848, "time": 18055.18468928337, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 572288, "time": 18068.691888809204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572776, "time": 18083.314343452454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573088, "time": 18092.944624185562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573240, "time": 18097.300466299057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573328, "time": 18100.167548894882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573744, "time": 18113.272366285324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573864, "time": 18116.66824030876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574160, "time": 18125.90557408333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574600, "time": 18138.9430437088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575024, "time": 18151.994288921356, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 575088, "time": 18153.925774097443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575400, "time": 18163.16735482216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575640, "time": 18170.496379852295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575912, "time": 18178.692780017853, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 576056, "time": 18183.07825922966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576176, "time": 18186.94297838211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576320, "time": 18191.28618121147, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 576472, "time": 18195.655791282654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577336, "time": 18221.88691163063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577400, "time": 18223.843704223633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577632, "time": 18231.25426054001, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 577712, "time": 18233.697598934174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577952, "time": 18240.949900865555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578024, "time": 18242.89527130127, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 578320, "time": 18252.02682161331, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 578368, "time": 18253.495579004288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578488, "time": 18256.899460077286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578632, "time": 18261.342313289642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578784, "time": 18266.137842416763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578889, "time": 18270.058844566345, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5610877310875617, "train/action_min": 0.0, "train/action_std": 1.624083414526269, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004325728398104576, "train/actor_opt_grad_steps": 35075.0, "train/actor_opt_loss": -6.159423607134141, "train/adv_mag": 0.5682420267326997, "train/adv_max": 0.1801416077236138, "train/adv_mean": 0.0001381065649409288, "train/adv_min": -0.536039006296951, "train/adv_std": 0.01507229939342873, "train/cont_avg": 0.9958133508663366, "train/cont_loss_mean": 0.013381747135864847, "train/cont_loss_std": 0.21077628561645967, "train/cont_neg_acc": 0.41897783185069887, "train/cont_neg_loss": 2.584658743799594, "train/cont_pos_acc": 0.9998931698869951, "train/cont_pos_loss": 0.002531215252578351, "train/cont_pred": 0.9958430794205996, "train/cont_rate": 0.9958133508663366, "train/dyn_loss_mean": 1.0000052198325053, "train/dyn_loss_std": 9.957526777041062e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11536445658617091, "train/extr_critic_critic_opt_grad_steps": 35075.0, "train/extr_critic_critic_opt_loss": 12513.245890702352, "train/extr_critic_mag": 0.8450900056574604, "train/extr_critic_max": 0.8450900056574604, "train/extr_critic_mean": 0.7770559902828519, "train/extr_critic_min": 0.7131437134034563, "train/extr_critic_std": 0.011584319324131207, "train/extr_return_normed_mag": 0.5767719680720037, "train/extr_return_normed_max": 0.20685279369354248, "train/extr_return_normed_mean": 0.018644845517730286, "train/extr_return_normed_min": -0.5289913111984139, "train/extr_return_normed_std": 0.01958629453905148, "train/extr_return_rate": 0.9996142464108987, "train/extr_return_raw_mag": 0.9654020310038387, "train/extr_return_raw_max": 0.9654020310038387, "train/extr_return_raw_mean": 0.7771941284732063, "train/extr_return_raw_min": 0.22955792611188228, "train/extr_return_raw_std": 0.019586294465283358, "train/extr_reward_mag": 0.25222549580111364, "train/extr_reward_max": 0.25222549580111364, "train/extr_reward_mean": 0.001006698156266109, "train/extr_reward_min": 1.0622609959970607e-07, "train/extr_reward_std": 0.0057565861722767946, "train/image_loss_mean": 0.08361391180960259, "train/image_loss_std": 0.09496154031246015, "train/model_loss_mean": 0.7027542239958697, "train/model_loss_std": 0.32899492632339494, "train/model_opt_grad_norm": 25.56816826716508, "train/model_opt_grad_steps": 35041.430693069306, "train/model_opt_loss": 3531.738037109375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5049.504950495049, "train/policy_entropy_mag": 1.2273993309181515, "train/policy_entropy_max": 1.2273993309181515, "train/policy_entropy_mean": 0.11125614678505624, "train/policy_entropy_min": 0.06468658307843869, "train/policy_entropy_std": 0.13738960437107794, "train/policy_logprob_mag": 6.551080245782833, "train/policy_logprob_max": -0.008608154343939063, "train/policy_logprob_mean": -0.11165383155688201, "train/policy_logprob_min": -6.551080245782833, "train/policy_logprob_std": 0.649547413729205, "train/policy_randomness_mag": 0.6307585177445175, "train/policy_randomness_max": 0.6307585177445175, "train/policy_randomness_mean": 0.05717435298432218, "train/policy_randomness_min": 0.03324233028705757, "train/policy_randomness_std": 0.07060429383770074, "train/post_ent_mag": 33.339891018253745, "train/post_ent_max": 33.339891018253745, "train/post_ent_mean": 33.036932822501306, "train/post_ent_min": 32.86332187086049, "train/post_ent_std": 0.09291250044756597, "train/prior_ent_mag": 34.294466264177075, "train/prior_ent_max": 34.294466264177075, "train/prior_ent_mean": 32.54575112786623, "train/prior_ent_min": 31.258383996415848, "train/prior_ent_std": 0.4903251103835531, "train/rep_loss_mean": 1.0000052198325053, "train/rep_loss_std": 9.957526777041062e-05, "train/reward_avg": 0.0007458375287812784, "train/reward_loss_mean": 0.005755409535532356, "train/reward_loss_std": 0.11692067216257657, "train/reward_max_data": 0.47824876371881747, "train/reward_max_pred": 0.15090910042866623, "train/reward_neg_acc": 0.9997676923723504, "train/reward_neg_loss": 0.0010164283254324449, "train/reward_pos_acc": 0.22519084060465105, "train/reward_pos_loss": 4.2478932397056175, "train/reward_pred": 0.0006347801374953868, "train/reward_rate": 0.0011022586633663365, "train_stats/mean_log_entropy": 0.10094515606760979, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.006804106757044792, "report/cont_loss_std": 0.12365119159221649, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.9568092823028564, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029429092537611723, "report/cont_pred": 0.9970641732215881, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0618300698697567, "report/image_loss_std": 0.07948549091815948, "report/model_loss_mean": 0.6767075061798096, "report/model_loss_std": 0.3680146634578705, "report/post_ent_mag": 33.415748596191406, "report/post_ent_max": 33.415748596191406, "report/post_ent_mean": 33.11307907104492, "report/post_ent_min": 32.93914031982422, "report/post_ent_std": 0.09308909624814987, "report/prior_ent_mag": 34.25248718261719, "report/prior_ent_max": 34.25248718261719, "report/prior_ent_mean": 32.62327575683594, "report/prior_ent_min": 31.163681030273438, "report/prior_ent_std": 0.535882294178009, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002349853457417339, "report/reward_loss_mean": 0.008073247969150543, "report/reward_loss_std": 0.22392889857292175, "report/reward_max_data": 0.24062499403953552, "report/reward_max_pred": 0.025837182998657227, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.001073548337444663, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 7.168766021728516, "report/reward_pred": 0.0005547389155253768, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0479753240942955, "eval/cont_loss_std": 0.6691156029701233, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.806100368499756, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0022496378514915705, "eval/cont_pred": 0.9976072311401367, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20451344549655914, "eval/image_loss_std": 0.15123696625232697, "eval/model_loss_mean": 0.8633915185928345, "eval/model_loss_std": 0.8596698045730591, "eval/post_ent_mag": 33.41549301147461, "eval/post_ent_max": 33.41549301147461, "eval/post_ent_mean": 33.11579895019531, "eval/post_ent_min": 32.92744445800781, "eval/post_ent_std": 0.09647977352142334, "eval/prior_ent_mag": 34.279727935791016, "eval/prior_ent_max": 34.279727935791016, "eval/prior_ent_mean": 32.51414489746094, "eval/prior_ent_min": 30.633407592773438, "eval/prior_ent_std": 0.5709484219551086, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0012176514137536287, "eval/reward_loss_mean": 0.010902749374508858, "eval/reward_loss_std": 0.256371408700943, "eval/reward_max_data": 0.6656249761581421, "eval/reward_max_pred": 0.1069566011428833, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0008708634995855391, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 5.137195587158203, "eval/reward_pred": 0.0005480591207742691, "eval/reward_rate": 0.001953125, "replay/size": 578385.0, "replay/inserts": 32288.0, "replay/samples": 32288.0, "replay/insert_wait_avg": 1.2769660108507683e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.972195079943352e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0663181577724294e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2176990509033, "timer/env.step_count": 4036.0, "timer/env.step_total": 38.073569774627686, "timer/env.step_frac": 0.03806528299864651, "timer/env.step_avg": 0.00943349102443699, "timer/env.step_min": 0.0076749324798583984, "timer/env.step_max": 0.0449063777923584, "timer/replay._sample_count": 32288.0, "timer/replay._sample_total": 17.029683113098145, "timer/replay._sample_frac": 0.017025976574157248, "timer/replay._sample_avg": 0.0005274307207971427, "timer/replay._sample_min": 0.0003826618194580078, "timer/replay._sample_max": 0.028342247009277344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4903.0, "timer/agent.policy_total": 50.95912051200867, "timer/agent.policy_frac": 0.050948029174412005, "timer/agent.policy_avg": 0.010393457171529404, "timer/agent.policy_min": 0.008514642715454102, "timer/agent.policy_max": 0.08690929412841797, "timer/dataset_train_count": 2018.0, "timer/dataset_train_total": 0.21515822410583496, "timer/dataset_train_frac": 0.0002151113945594009, "timer/dataset_train_avg": 0.0001066195362268756, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0005052089691162109, "timer/agent.train_count": 2018.0, "timer/agent.train_total": 897.6418604850769, "timer/agent.train_frac": 0.897446487236569, "timer/agent.train_avg": 0.4448175720936952, "timer/agent.train_min": 0.43435096740722656, "timer/agent.train_max": 0.7381043434143066, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47399115562438965, "timer/agent.report_frac": 0.0004738879906585888, "timer/agent.report_avg": 0.23699557781219482, "timer/agent.report_min": 0.23041200637817383, "timer/agent.report_max": 0.24357914924621582, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8842369114906944e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 32.280402402828976}
{"step": 578928, "time": 18271.215444803238, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 579400, "time": 18285.301980257034, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 579464, "time": 18287.247086524963, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 579568, "time": 18290.754113674164, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 18306.02657842636, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 580008, "time": 18306.087260723114, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 580008, "time": 18306.271411180496, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 580008, "time": 18306.7729742527, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 580008, "time": 18307.160661935806, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 580008, "time": 18307.840542554855, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 580008, "time": 18308.570741653442, "eval_episode/length": 196.0, "eval_episode/score": 0.38749998807907104, "eval_episode/reward_rate": 0.005076142131979695}
{"step": 580008, "time": 18309.56248807907, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 580024, "time": 18310.05499124527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580240, "time": 18316.77922987938, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 580264, "time": 18317.2869348526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580632, "time": 18328.527193784714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580744, "time": 18331.915447711945, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 580840, "time": 18334.832545280457, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 580944, "time": 18338.201523065567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581096, "time": 18342.5747756958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581160, "time": 18344.508750915527, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 581168, "time": 18344.97422194481, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 581184, "time": 18345.473101615906, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 581232, "time": 18346.952985048294, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 581240, "time": 18346.98042178154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581656, "time": 18360.0568959713, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 581864, "time": 18366.358895540237, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 581992, "time": 18370.261999368668, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 582336, "time": 18381.089022159576, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 582368, "time": 18382.078187465668, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 582568, "time": 18387.893842220306, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 582952, "time": 18399.489147663116, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 583080, "time": 18403.36359190941, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 583248, "time": 18408.66266822815, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 583408, "time": 18413.599259138107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583512, "time": 18416.52623772621, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 583552, "time": 18417.961023569107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583632, "time": 18420.39586162567, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 583696, "time": 18422.330979824066, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 584008, "time": 18431.536618471146, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 584176, "time": 18436.817069768906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584304, "time": 18440.798543691635, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 584368, "time": 18442.74107503891, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 584472, "time": 18445.693155527115, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 584680, "time": 18452.015567541122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584880, "time": 18458.353649377823, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 585152, "time": 18466.58510494232, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 585568, "time": 18479.27736377716, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 585576, "time": 18479.30318379402, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 585704, "time": 18483.148591279984, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 585824, "time": 18487.029135227203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585864, "time": 18488.02893090248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586240, "time": 18499.576724767685, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 586496, "time": 18507.371467590332, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 586616, "time": 18510.776527881622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586680, "time": 18512.733892917633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587072, "time": 18524.750155448914, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 587192, "time": 18528.161704063416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587416, "time": 18535.00191783905, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 587880, "time": 18549.063235282898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587888, "time": 18549.52890563011, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588032, "time": 18553.901862859726, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 588120, "time": 18556.360720157623, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 588176, "time": 18558.266746282578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588808, "time": 18577.233516693115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588896, "time": 18580.101571559906, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 588928, "time": 18581.087136745453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588936, "time": 18581.11377310753, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 588992, "time": 18583.015325307846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589256, "time": 18590.853778600693, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 589600, "time": 18601.44805765152, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 589648, "time": 18602.89515042305, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 589760, "time": 18606.29267692566, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 589800, "time": 18607.278848171234, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 18617.745349407196, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 590096, "time": 18618.22424554825, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 590096, "time": 18618.487245559692, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 590096, "time": 18619.113909482956, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 590096, "time": 18619.137668848038, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 590096, "time": 18619.341666698456, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 590096, "time": 18619.36562037468, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 590096, "time": 18619.791880130768, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 590192, "time": 18622.786484241486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590200, "time": 18622.814772367477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590344, "time": 18627.14502811432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591040, "time": 18648.334628105164, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 591120, "time": 18650.830418348312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591424, "time": 18660.006592273712, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 591912, "time": 18674.532033205032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591960, "time": 18675.996355056763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591992, "time": 18676.978696107864, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 592072, "time": 18679.396817445755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592112, "time": 18680.931258678436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592512, "time": 18693.101142406464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592968, "time": 18706.62427330017, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 593152, "time": 18712.522362947464, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 593304, "time": 18716.90322947502, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 593320, "time": 18717.39121580124, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 593352, "time": 18718.366441249847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593696, "time": 18729.0515460968, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 593736, "time": 18730.05576467514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593888, "time": 18734.84509396553, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 594224, "time": 18745.083474874496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594272, "time": 18746.530064821243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594304, "time": 18747.49805045128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594312, "time": 18747.524557590485, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 594432, "time": 18751.36103773117, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 594632, "time": 18757.153727054596, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 594848, "time": 18763.89021587372, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 594920, "time": 18765.833649158478, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 594920, "time": 18765.84033513069, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 595072, "time": 18770.721634864807, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 595464, "time": 18782.305314302444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595552, "time": 18785.215074539185, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 595632, "time": 18787.645104646683, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 595920, "time": 18796.335979938507, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 596048, "time": 18800.217526197433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596200, "time": 18804.683586359024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596432, "time": 18811.92352414131, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 596472, "time": 18812.91334939003, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 596504, "time": 18813.881606817245, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 596944, "time": 18827.431596279144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597232, "time": 18836.260462760925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597384, "time": 18840.60303902626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597496, "time": 18843.989073991776, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 597648, "time": 18848.810040473938, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 597800, "time": 18853.166524887085, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 597976, "time": 18858.47636294365, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 598048, "time": 18861.527552604675, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 598232, "time": 18866.910619020462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598296, "time": 18868.838122844696, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 598360, "time": 18870.787043571472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598376, "time": 18871.274712085724, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 598536, "time": 18876.10732960701, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 598608, "time": 18878.507556438446, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 598744, "time": 18882.408692121506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598992, "time": 18890.136221647263, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 599256, "time": 18897.996228933334, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 599320, "time": 18899.948112249374, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 599464, "time": 18904.288652181625, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 599544, "time": 18906.726629018784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599592, "time": 18908.171494483948, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 599672, "time": 18910.60391020775, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 599720, "time": 18912.048615455627, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 599784, "time": 18913.968514204025, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 600048, "time": 18922.300433397293, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 18923.269107103348, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 18924.18276309967, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 600080, "time": 18924.67728948593, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 600080, "time": 18924.858627796173, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 600080, "time": 18925.2916970253, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 600080, "time": 18925.357434511185, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 600080, "time": 18927.514414548874, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 600080, "time": 18927.61307668686, "eval_episode/length": 234.0, "eval_episode/score": 0.26875001192092896, "eval_episode/reward_rate": 0.00425531914893617}
{"step": 600080, "time": 18928.32493543625, "eval_episode/length": 272.0, "eval_episode/score": 0.15000000596046448, "eval_episode/reward_rate": 0.003663003663003663}
{"step": 600352, "time": 18936.554280519485, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 600400, "time": 18938.00567483902, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 600496, "time": 18940.913217782974, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 600504, "time": 18940.940294742584, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 600608, "time": 18944.301691770554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601152, "time": 18960.881313562393, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 601240, "time": 18963.34425520897, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 601368, "time": 18967.199665546417, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 601672, "time": 18976.38902592659, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 601696, "time": 18977.33452105522, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 602032, "time": 18987.562613010406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602160, "time": 18991.407299995422, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 602184, "time": 18991.91411423683, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 602544, "time": 19002.99893784523, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 602808, "time": 19010.837881565094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602816, "time": 19011.30058646202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602872, "time": 19012.776958942413, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 602920, "time": 19014.22527050972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603008, "time": 19017.100588798523, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 603040, "time": 19018.06558918953, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 603112, "time": 19020.011977910995, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 603464, "time": 19030.67482304573, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 603528, "time": 19032.621249437332, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 603584, "time": 19034.527661323547, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 603968, "time": 19046.172291994095, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 604008, "time": 19047.1603808403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604288, "time": 19055.80908703804, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 604352, "time": 19057.73104906082, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 604360, "time": 19057.757919549942, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 604768, "time": 19070.45701122284, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 604776, "time": 19070.48361134529, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 604952, "time": 19075.769770383835, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 605128, "time": 19081.059235095978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605352, "time": 19087.829556941986, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 605384, "time": 19088.80318880081, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 605424, "time": 19090.259612321854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605664, "time": 19097.48315358162, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 605880, "time": 19103.89626646042, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 606080, "time": 19110.15700340271, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 606192, "time": 19113.55036187172, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 606280, "time": 19116.461956501007, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 606320, "time": 19117.89506983757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606712, "time": 19129.519063949585, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 606840, "time": 19133.508355617523, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 606880, "time": 19134.929935455322, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 607264, "time": 19146.594724416733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607696, "time": 19159.653415441513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607736, "time": 19160.737954378128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608392, "time": 19180.64603614807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608504, "time": 19184.02910733223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608904, "time": 19196.196989774704, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 609024, "time": 19200.043517827988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609088, "time": 19201.993490457535, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 609152, "time": 19203.94318127632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609192, "time": 19204.938893795013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610008, "time": 19229.61698102951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 19232.16670203209, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 610064, "time": 19232.393916130066, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 610064, "time": 19232.885417222977, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 610064, "time": 19232.92725968361, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 610064, "time": 19233.074080705643, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 610064, "time": 19233.284242391586, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 610064, "time": 19233.32851600647, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 610064, "time": 19233.754283428192, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 610288, "time": 19240.504880666733, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 610624, "time": 19250.785487890244, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 610704, "time": 19253.224241495132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610816, "time": 19256.59059357643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610840, "time": 19257.115616559982, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 611216, "time": 19268.676367759705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611241, "time": 19270.17731142044, "train_stats/mean_log_entropy": 0.08490513543082025, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.49259087590888, "train/action_min": 0.0, "train/action_std": 1.6814536458194846, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007815340862927572, "train/actor_opt_grad_steps": 37095.0, "train/actor_opt_loss": -5.146314999033319, "train/adv_mag": 0.7180388279185437, "train/adv_max": 0.27806302314937703, "train/adv_mean": 0.004339329453686522, "train/adv_min": -0.6903384168549339, "train/adv_std": 0.028745320565666598, "train/cont_avg": 0.9956103032178217, "train/cont_loss_mean": 0.014503344439320488, "train/cont_loss_std": 0.22116036595555372, "train/cont_neg_acc": 0.38244199966735176, "train/cont_neg_loss": 2.681627800586212, "train/cont_pos_acc": 0.9998736186782913, "train/cont_pos_loss": 0.002768192476002813, "train/cont_pred": 0.9956815965694956, "train/cont_rate": 0.9956103032178217, "train/dyn_loss_mean": 1.0000069855463387, "train/dyn_loss_std": 0.0001910484780898631, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.38879733469042155, "train/extr_critic_critic_opt_grad_steps": 37095.0, "train/extr_critic_critic_opt_loss": 6249.420305006575, "train/extr_critic_mag": 0.9229954965043776, "train/extr_critic_max": 0.9229954965043776, "train/extr_critic_mean": 0.8743423686759306, "train/extr_critic_min": 0.7717303250095632, "train/extr_critic_std": 0.013597842891433157, "train/extr_return_normed_mag": 0.7068114304306483, "train/extr_return_normed_max": 0.29614789208563247, "train/extr_return_normed_mean": 0.03541242013256628, "train/extr_return_normed_min": -0.6677090360386537, "train/extr_return_normed_std": 0.0328406869286284, "train/extr_return_rate": 0.9984398003261868, "train/extr_return_raw_mag": 1.1394171130539168, "train/extr_return_raw_max": 1.1394171130539168, "train/extr_return_raw_mean": 0.8786816844845763, "train/extr_return_raw_min": 0.17556018492963055, "train/extr_return_raw_std": 0.03284068679953418, "train/extr_reward_mag": 0.3238734183925213, "train/extr_reward_max": 0.3238734183925213, "train/extr_reward_mean": 0.001995897051673106, "train/extr_reward_min": 4.308058483765857e-08, "train/extr_reward_std": 0.010076841228240456, "train/image_loss_mean": 0.08145116708508812, "train/image_loss_std": 0.09496920308706784, "train/model_loss_mean": 0.7028585374355316, "train/model_loss_std": 0.355299145794741, "train/model_opt_grad_norm": 24.59067112384456, "train/model_opt_grad_steps": 37059.4702970297, "train/model_opt_loss": 3669.384789797339, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5222.772277227723, "train/policy_entropy_mag": 1.33602106512183, "train/policy_entropy_max": 1.33602106512183, "train/policy_entropy_mean": 0.10718550245360572, "train/policy_entropy_min": 0.06468650779806741, "train/policy_entropy_std": 0.13732592621357134, "train/policy_logprob_mag": 6.551080238701093, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10672508161699418, "train/policy_logprob_min": -6.551080238701093, "train/policy_logprob_std": 0.6436186919708063, "train/policy_randomness_mag": 0.6865790509941554, "train/policy_randomness_max": 0.6865790509941554, "train/policy_randomness_mean": 0.05508245549874731, "train/policy_randomness_min": 0.03324228986212523, "train/policy_randomness_std": 0.07057157029757405, "train/post_ent_mag": 33.45826976134045, "train/post_ent_max": 33.45826976134045, "train/post_ent_mean": 33.154447498888075, "train/post_ent_min": 32.977852660830656, "train/post_ent_std": 0.09505999243200415, "train/prior_ent_mag": 34.4147104508806, "train/prior_ent_max": 34.4147104508806, "train/prior_ent_mean": 32.641318019073786, "train/prior_ent_min": 31.24493175922054, "train/prior_ent_std": 0.5035660588505244, "train/rep_loss_mean": 1.0000069855463387, "train/rep_loss_std": 0.0001910484780898631, "train/reward_avg": 0.0008947391332113322, "train/reward_loss_mean": 0.0068998082735723274, "train/reward_loss_std": 0.13813210486222316, "train/reward_max_data": 0.54226485189825, "train/reward_max_pred": 0.14558936994854765, "train/reward_neg_acc": 0.9997918210407295, "train/reward_neg_loss": 0.0011410894047291396, "train/reward_pos_acc": 0.18914988886990003, "train/reward_pos_loss": 4.39374093401352, "train/reward_pred": 0.0006831383925060382, "train/reward_rate": 0.0013101407797029704, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.007511513773351908, "report/cont_loss_std": 0.13116846978664398, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 1.1069481372833252, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0031999987550079823, "report/cont_pred": 0.9941393733024597, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0715675950050354, "report/image_loss_std": 0.08999987691640854, "report/model_loss_mean": 0.6861276626586914, "report/model_loss_std": 0.3150794804096222, "report/post_ent_mag": 34.00332260131836, "report/post_ent_max": 34.00332260131836, "report/post_ent_mean": 33.718116760253906, "report/post_ent_min": 33.561012268066406, "report/post_ent_std": 0.08733494579792023, "report/prior_ent_mag": 34.76396942138672, "report/prior_ent_max": 34.76396942138672, "report/prior_ent_mean": 33.25532150268555, "report/prior_ent_min": 32.312923431396484, "report/prior_ent_std": 0.3834120035171509, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006591796991415322, "report/reward_loss_mean": 0.007048518862575293, "report/reward_loss_std": 0.1564348340034485, "report/reward_max_data": 0.675000011920929, "report/reward_max_pred": 0.10953092575073242, "report/reward_neg_acc": 0.9990224838256836, "report/reward_neg_loss": 0.0021703364327549934, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.997428894042969, "report/reward_pred": 0.0010658575920388103, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04199478402733803, "eval/cont_loss_std": 0.6609734892845154, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.51762866973877, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0009138647583313286, "eval/cont_pred": 0.9990928769111633, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15836994349956512, "eval/image_loss_std": 0.14190791547298431, "eval/model_loss_mean": 0.8082720041275024, "eval/model_loss_std": 0.8233361840248108, "eval/post_ent_mag": 34.00213623046875, "eval/post_ent_max": 34.00213623046875, "eval/post_ent_mean": 33.69371795654297, "eval/post_ent_min": 33.52691650390625, "eval/post_ent_std": 0.09661417454481125, "eval/prior_ent_mag": 34.76396942138672, "eval/prior_ent_max": 34.76396942138672, "eval/prior_ent_mean": 33.271446228027344, "eval/prior_ent_min": 32.313270568847656, "eval/prior_ent_std": 0.38004061579704285, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0003723144473042339, "eval/reward_loss_mean": 0.007907269522547722, "eval/reward_loss_std": 0.24487687647342682, "eval/reward_max_data": 0.3812499940395355, "eval/reward_max_pred": 0.018587470054626465, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002513691724743694, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.839892864227295, "eval/reward_pred": 0.0001262597506865859, "eval/reward_rate": 0.0009765625, "replay/size": 610737.0, "replay/inserts": 32352.0, "replay/samples": 32352.0, "replay/insert_wait_avg": 1.3059445469834566e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.953918534381689e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6080.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1112344892401443e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0986332893372, "timer/env.step_count": 4044.0, "timer/env.step_total": 38.340893030166626, "timer/env.step_frac": 0.038337111714734515, "timer/env.step_avg": 0.009480932994601045, "timer/env.step_min": 0.007674455642700195, "timer/env.step_max": 0.04399847984313965, "timer/replay._sample_count": 32352.0, "timer/replay._sample_total": 16.949687242507935, "timer/replay._sample_frac": 0.016948015603981178, "timer/replay._sample_avg": 0.0005239146650132274, "timer/replay._sample_min": 0.0003719329833984375, "timer/replay._sample_max": 0.026144027709960938, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4804.0, "timer/agent.policy_total": 49.99575233459473, "timer/agent.policy_frac": 0.04999082157542607, "timer/agent.policy_avg": 0.010407109145419386, "timer/agent.policy_min": 0.008671998977661133, "timer/agent.policy_max": 0.11702752113342285, "timer/dataset_train_count": 2022.0, "timer/dataset_train_total": 0.21686792373657227, "timer/dataset_train_frac": 0.00021684653544949952, "timer/dataset_train_avg": 0.00010725416604182604, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0010764598846435547, "timer/agent.train_count": 2022.0, "timer/agent.train_total": 899.0315420627594, "timer/agent.train_frac": 0.8989428763699369, "timer/agent.train_avg": 0.4446248971625912, "timer/agent.train_min": 0.435467004776001, "timer/agent.train_max": 1.0417795181274414, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47832727432250977, "timer/agent.report_frac": 0.00047828009998302396, "timer/agent.report_avg": 0.23916363716125488, "timer/agent.report_min": 0.23088860511779785, "timer/agent.report_max": 0.24743866920471191, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9799383176512396e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 32.34824601673903}
{"step": 611328, "time": 19272.803228378296, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 611400, "time": 19274.7551984787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611448, "time": 19276.197909593582, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 611464, "time": 19276.686232805252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611504, "time": 19278.13924574852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611584, "time": 19280.630930185318, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 611824, "time": 19287.889705896378, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 611896, "time": 19289.845345258713, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 612400, "time": 19305.353219032288, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 612648, "time": 19312.747593402863, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 613016, "time": 19323.87197446823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613296, "time": 19332.540058851242, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 613392, "time": 19335.449497699738, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 613528, "time": 19339.356843948364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613776, "time": 19347.228769779205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613816, "time": 19348.22624731064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613896, "time": 19350.66479921341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613904, "time": 19351.13106942177, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 614064, "time": 19355.994625091553, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 614136, "time": 19357.961745738983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614488, "time": 19369.09406042099, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 614520, "time": 19370.08176255226, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 614784, "time": 19378.33692216873, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 614824, "time": 19379.32223558426, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 615112, "time": 19388.04406619072, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 615608, "time": 19403.072105169296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 615616, "time": 19403.538277864456, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 615800, "time": 19408.90268945694, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 615840, "time": 19410.333039045334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 615992, "time": 19414.726338148117, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 616128, "time": 19419.065168619156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 616168, "time": 19420.057858228683, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 616296, "time": 19423.922650575638, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 616448, "time": 19428.75679039955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 616512, "time": 19430.82114505768, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 616560, "time": 19432.293449640274, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 616688, "time": 19436.203942537308, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 616776, "time": 19438.64285993576, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 616848, "time": 19441.022763729095, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 617096, "time": 19448.317137479782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617200, "time": 19451.67555785179, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 618112, "time": 19479.349263191223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618472, "time": 19489.965069055557, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 618480, "time": 19490.561163663864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618608, "time": 19494.43880033493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618808, "time": 19500.244844436646, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 618824, "time": 19500.733570575714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618888, "time": 19502.674140930176, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 619088, "time": 19508.94015455246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619160, "time": 19510.92215704918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619408, "time": 19518.651749134064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619440, "time": 19519.621730566025, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 619928, "time": 19534.22971534729, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 19538.573279619217, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 620048, "time": 19539.304933547974, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 620048, "time": 19539.676094532013, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 620048, "time": 19540.915354013443, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 620048, "time": 19541.2554397583, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 620048, "time": 19541.278415203094, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 620048, "time": 19543.450346708298, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 19543.46321797371, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 19543.480435848236, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 19543.490723371506, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620472, "time": 19556.209866523743, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 620920, "time": 19569.85224533081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621136, "time": 19576.595929145813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621200, "time": 19578.524876117706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621400, "time": 19584.516676187515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621432, "time": 19585.486845493317, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 621472, "time": 19586.91602253914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621752, "time": 19595.17687869072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621952, "time": 19601.459355831146, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 622128, "time": 19606.8105134964, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 622472, "time": 19617.12283396721, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 622664, "time": 19623.404727220535, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 622688, "time": 19624.37001657486, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 622784, "time": 19627.277983427048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623048, "time": 19635.045782327652, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 623712, "time": 19655.43397140503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623744, "time": 19656.407865047455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623784, "time": 19657.405476093292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624216, "time": 19670.6334297657, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 624264, "time": 19672.090095043182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624368, "time": 19675.4737701416, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 624416, "time": 19676.915798425674, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 624976, "time": 19693.83452796936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625000, "time": 19694.34201335907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625016, "time": 19694.83233809471, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 625096, "time": 19697.268623113632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625360, "time": 19705.53796672821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625576, "time": 19711.975769996643, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 625872, "time": 19721.14179444313, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 625928, "time": 19722.611058712006, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 625944, "time": 19723.097805261612, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 626152, "time": 19729.38638329506, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 626528, "time": 19741.06093645096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626680, "time": 19745.4446349144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626680, "time": 19745.453810214996, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 626728, "time": 19746.903450489044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626792, "time": 19748.834332466125, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 626880, "time": 19751.712948799133, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 627224, "time": 19761.986384391785, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 627248, "time": 19762.9371445179, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 627464, "time": 19769.231239318848, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 627576, "time": 19772.666746377945, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 627864, "time": 19781.377160787582, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 627984, "time": 19785.2331430912, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 627992, "time": 19785.259171009064, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 628184, "time": 19791.137795448303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628240, "time": 19793.052649497986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628616, "time": 19804.21171593666, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 628696, "time": 19806.63126349449, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 629072, "time": 19818.20312523842, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 629080, "time": 19818.22948408127, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 629088, "time": 19818.694184064865, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 629192, "time": 19821.68650650978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629432, "time": 19828.93858242035, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 629472, "time": 19830.374846935272, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 629560, "time": 19832.82840704918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629664, "time": 19836.181175231934, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 19848.49139213562, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 630032, "time": 19848.499673604965, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 630032, "time": 19848.81801009178, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 630032, "time": 19848.87593483925, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 630032, "time": 19849.45870256424, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 630032, "time": 19849.521881341934, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 630032, "time": 19850.566937685013, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 630032, "time": 19851.42266535759, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 630048, "time": 19852.04890370369, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 630088, "time": 19853.043825626373, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 630176, "time": 19855.933310985565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630192, "time": 19856.44110441208, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 631008, "time": 19881.760618925095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631176, "time": 19886.645607233047, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 631400, "time": 19893.426281690598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631672, "time": 19901.672950983047, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 631872, "time": 19907.93398451805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632256, "time": 19919.62727022171, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 632320, "time": 19921.58317232132, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 632320, "time": 19921.592215299606, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 632360, "time": 19922.63657784462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632488, "time": 19926.590265512466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632504, "time": 19927.084963321686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 633320, "time": 19951.876042842865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 633416, "time": 19954.79750227928, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 633488, "time": 19957.202389001846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 633504, "time": 19957.696214914322, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 633568, "time": 19959.66090297699, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 634096, "time": 19975.692230701447, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 634416, "time": 19985.37514925003, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 634568, "time": 19989.752946853638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634632, "time": 19991.67949295044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634632, "time": 19991.688653230667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635264, "time": 20011.073410987854, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 635360, "time": 20013.972096204758, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 635744, "time": 20025.617419958115, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 635816, "time": 20027.612469911575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635880, "time": 20029.545394420624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636136, "time": 20037.454099416733, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 636392, "time": 20045.170474767685, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 636408, "time": 20045.660935878754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636648, "time": 20052.918015003204, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 636728, "time": 20055.336970567703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636880, "time": 20060.148168087006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636944, "time": 20062.19068622589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637216, "time": 20070.40112042427, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 637256, "time": 20071.40873670578, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 637280, "time": 20072.360891819, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 637352, "time": 20074.318658590317, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 637360, "time": 20074.791974306107, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 637608, "time": 20082.129984855652, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 637664, "time": 20084.03437924385, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 637768, "time": 20086.958304405212, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 637912, "time": 20091.374253988266, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 638264, "time": 20101.993145227432, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 638560, "time": 20111.246831417084, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 638568, "time": 20111.274023771286, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 638688, "time": 20115.12682056427, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 638744, "time": 20116.59744477272, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 638928, "time": 20122.523522138596, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 639392, "time": 20137.094836473465, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 639560, "time": 20141.981946706772, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 639568, "time": 20142.44889307022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639616, "time": 20143.89385700226, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 639664, "time": 20145.35459136963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 20156.526729106903, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 640016, "time": 20156.833333730698, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 640016, "time": 20157.828162908554, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 640016, "time": 20158.42738890648, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 640016, "time": 20158.834698438644, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 640016, "time": 20160.233345746994, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 640016, "time": 20161.71953892708, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 20161.726319551468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 20161.734794139862, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 20161.741961717606, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640080, "time": 20163.6765127182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640096, "time": 20164.180919647217, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 640240, "time": 20168.583057165146, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 640576, "time": 20178.73409318924, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 640624, "time": 20180.23068380356, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 640720, "time": 20183.203510284424, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 640808, "time": 20185.680400133133, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 641288, "time": 20200.25016450882, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 641704, "time": 20212.943824529648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641872, "time": 20218.271664619446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641976, "time": 20221.201365947723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642080, "time": 20224.593393564224, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 642264, "time": 20229.95263671875, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 642304, "time": 20231.376880645752, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 642552, "time": 20238.68350291252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642632, "time": 20241.223385334015, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 642888, "time": 20248.979454517365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642904, "time": 20249.467697620392, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 642976, "time": 20251.848484516144, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 643032, "time": 20253.336928606033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643120, "time": 20256.200284957886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643561, "time": 20270.351471185684, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3486249564897896, "train/action_min": 0.0, "train/action_std": 1.6675623944490263, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011217888805434329, "train/actor_opt_grad_steps": 39115.0, "train/actor_opt_loss": -7.15281846880507, "train/adv_mag": 0.8453795558745318, "train/adv_max": 0.3271871533724341, "train/adv_mean": 0.005438710937407522, "train/adv_min": -0.824419382775184, "train/adv_std": 0.03739789081737399, "train/cont_avg": 0.9955861308787128, "train/cont_loss_mean": 0.014335951842782595, "train/cont_loss_std": 0.2179542993204576, "train/cont_neg_acc": 0.3875578697955254, "train/cont_neg_loss": 2.642002627188283, "train/cont_pos_acc": 0.9998931622151102, "train/cont_pos_loss": 0.002760410785160977, "train/cont_pred": 0.9956398358439454, "train/cont_rate": 0.9955861308787128, "train/dyn_loss_mean": 1.0000001174388546, "train/dyn_loss_std": 3.75620836373603e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3283230799831229, "train/extr_critic_critic_opt_grad_steps": 39115.0, "train/extr_critic_critic_opt_loss": 12204.63270130724, "train/extr_critic_mag": 1.0991654213112179, "train/extr_critic_max": 1.0991654213112179, "train/extr_critic_mean": 1.0041670359597348, "train/extr_critic_min": 0.8998450625060809, "train/extr_critic_std": 0.020491920508407424, "train/extr_return_normed_mag": 0.8336502048048643, "train/extr_return_normed_max": 0.37506353324002556, "train/extr_return_normed_mean": 0.04597687840664593, "train/extr_return_normed_min": -0.7968635951528454, "train/extr_return_normed_std": 0.04382718500155624, "train/extr_return_rate": 0.998621255159378, "train/extr_return_raw_mag": 1.338692292128459, "train/extr_return_raw_max": 1.338692292128459, "train/extr_return_raw_mean": 1.0096056909844426, "train/extr_return_raw_min": 0.166765163735588, "train/extr_return_raw_std": 0.043827185019998265, "train/extr_reward_mag": 0.3809403971870347, "train/extr_reward_max": 0.3809403971870347, "train/extr_reward_mean": 0.002297122493941835, "train/extr_reward_min": 3.0097394886583385e-08, "train/extr_reward_std": 0.013158072588393594, "train/image_loss_mean": 0.07854797595208234, "train/image_loss_std": 0.09372739316803394, "train/model_loss_mean": 0.699861350921121, "train/model_loss_std": 0.3542983525312773, "train/model_opt_grad_norm": 23.42203707270103, "train/model_opt_grad_steps": 39077.5198019802, "train/model_opt_loss": 3551.8871683555076, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5074.257425742574, "train/policy_entropy_mag": 1.3843357875795648, "train/policy_entropy_max": 1.3843357875795648, "train/policy_entropy_mean": 0.12189898846468122, "train/policy_entropy_min": 0.06468650779806741, "train/policy_entropy_std": 0.1585188594711299, "train/policy_logprob_mag": 6.551080243422254, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.12194704330793701, "train/policy_logprob_min": -6.551080243422254, "train/policy_logprob_std": 0.6586101654142437, "train/policy_randomness_mag": 0.7114079087087424, "train/policy_randomness_max": 0.7114079087087424, "train/policy_randomness_mean": 0.06264369151010962, "train/policy_randomness_min": 0.03324228995433538, "train/policy_randomness_std": 0.08146258393800494, "train/post_ent_mag": 33.48902730658503, "train/post_ent_max": 33.48902730658503, "train/post_ent_mean": 33.184994234897125, "train/post_ent_min": 33.00316918250358, "train/post_ent_std": 0.09920999938898747, "train/prior_ent_mag": 33.84466429984216, "train/prior_ent_max": 33.84466429984216, "train/prior_ent_mean": 32.56275154340385, "train/prior_ent_min": 31.50915329055031, "train/prior_ent_std": 0.3755628627420652, "train/rep_loss_mean": 1.0000001174388546, "train/rep_loss_std": 3.75620836373603e-06, "train/reward_avg": 0.0008882428179402827, "train/reward_loss_mean": 0.006977332707512939, "train/reward_loss_std": 0.14146967123246448, "train/reward_max_data": 0.5531404731002184, "train/reward_max_pred": 0.13976812421685397, "train/reward_neg_acc": 0.9997724459903075, "train/reward_neg_loss": 0.0012088642846954305, "train/reward_pos_acc": 0.17964205925896665, "train/reward_pos_loss": 4.4986595771456726, "train/reward_pred": 0.000730717659577506, "train/reward_rate": 0.0013101407797029704, "train_stats/mean_log_entropy": 0.09347327683675796, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.012801013886928558, "report/cont_loss_std": 0.2472742795944214, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.740239143371582, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0021051783114671707, "report/cont_pred": 0.995957612991333, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06296346336603165, "report/image_loss_std": 0.07480382174253464, "report/model_loss_mean": 0.6767191886901855, "report/model_loss_std": 0.2580246031284332, "report/post_ent_mag": 33.40191650390625, "report/post_ent_max": 33.40191650390625, "report/post_ent_mean": 33.09893035888672, "report/post_ent_min": 32.907127380371094, "report/post_ent_std": 0.0998399555683136, "report/prior_ent_mag": 33.647003173828125, "report/prior_ent_max": 33.647003173828125, "report/prior_ent_mean": 32.54605484008789, "report/prior_ent_min": 31.374439239501953, "report/prior_ent_std": 0.36392027139663696, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.000954698771238327, "report/reward_loss_std": 0.003994546830654144, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.016077876091003418, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000954698771238327, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0004900823114439845, "report/reward_rate": 0.0, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.06486847996711731, "eval/cont_loss_std": 0.8055450916290283, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.243075370788574, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.001694996259175241, "eval/cont_pred": 0.998310923576355, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21111105382442474, "eval/image_loss_std": 0.1615729182958603, "eval/model_loss_mean": 0.8877487778663635, "eval/model_loss_std": 0.9261705279350281, "eval/post_ent_mag": 33.4036865234375, "eval/post_ent_max": 33.4036865234375, "eval/post_ent_mean": 33.082279205322266, "eval/post_ent_min": 32.922386169433594, "eval/post_ent_std": 0.10768921673297882, "eval/prior_ent_mag": 33.706993103027344, "eval/prior_ent_max": 33.706993103027344, "eval/prior_ent_mean": 32.52522277832031, "eval/prior_ent_min": 31.462175369262695, "eval/prior_ent_std": 0.3665180206298828, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0013885498046875, "eval/reward_loss_mean": 0.011769233271479607, "eval/reward_loss_std": 0.25115248560905457, "eval/reward_max_data": 0.762499988079071, "eval/reward_max_pred": 0.018016695976257324, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0007428768440149724, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.646237373352051, "eval/reward_pred": 0.0003900871379300952, "eval/reward_rate": 0.001953125, "replay/size": 643057.0, "replay/inserts": 32320.0, "replay/samples": 32320.0, "replay/insert_wait_avg": 1.2903594144500128e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.023463853515021e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6112.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.095118322921673e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1119518280029, "timer/env.step_count": 4040.0, "timer/env.step_total": 38.42476415634155, "timer/env.step_frac": 0.03842046291528547, "timer/env.step_avg": 0.009511080236718206, "timer/env.step_min": 0.007794857025146484, "timer/env.step_max": 0.05680441856384277, "timer/replay._sample_count": 32320.0, "timer/replay._sample_total": 17.007875204086304, "timer/replay._sample_frac": 0.0170059713545062, "timer/replay._sample_avg": 0.0005262337625026702, "timer/replay._sample_min": 0.0003960132598876953, "timer/replay._sample_max": 0.02504444122314453, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4804.0, "timer/agent.policy_total": 50.30155372619629, "timer/agent.policy_frac": 0.05029592300567471, "timer/agent.policy_avg": 0.010470764722355598, "timer/agent.policy_min": 0.008923530578613281, "timer/agent.policy_max": 0.08901262283325195, "timer/dataset_train_count": 2020.0, "timer/dataset_train_total": 0.22032809257507324, "timer/dataset_train_frac": 0.0002203034292034586, "timer/dataset_train_avg": 0.00010907331315597685, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0010802745819091797, "timer/agent.train_count": 2020.0, "timer/agent.train_total": 898.128696680069, "timer/agent.train_frac": 0.8980281607858709, "timer/agent.train_avg": 0.44461816667330145, "timer/agent.train_min": 0.43550992012023926, "timer/agent.train_max": 0.7076272964477539, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.50408935546875, "timer/agent.report_frac": 0.0005040329280610799, "timer/agent.report_avg": 0.252044677734375, "timer/agent.report_min": 0.23124313354492188, "timer/agent.report_max": 0.2728462219238281, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.0990945790170377e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 32.315328238711004}
{"step": 643688, "time": 20273.972791671753, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 643712, "time": 20274.92280435562, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 643840, "time": 20278.801006555557, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 643936, "time": 20281.6939702034, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 644080, "time": 20286.039790391922, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 644384, "time": 20295.237961530685, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 644568, "time": 20300.67178797722, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 645024, "time": 20314.672985315323, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 645288, "time": 20322.443001031876, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 645288, "time": 20322.45107793808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645432, "time": 20326.795523881912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645496, "time": 20328.727125644684, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 645592, "time": 20331.73895096779, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 645624, "time": 20332.727408885956, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 645968, "time": 20343.34418606758, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 646024, "time": 20344.8199095726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646392, "time": 20355.91375041008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646424, "time": 20356.88203239441, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 646568, "time": 20361.315735578537, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 646576, "time": 20361.781160354614, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 646688, "time": 20365.18696451187, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 646880, "time": 20370.975167274475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646960, "time": 20373.38325047493, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 647056, "time": 20376.287778377533, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 647208, "time": 20381.142996311188, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 647744, "time": 20397.547693490982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647864, "time": 20400.96213698387, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 647936, "time": 20403.351062059402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647984, "time": 20404.815304756165, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 648032, "time": 20406.262687921524, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 648152, "time": 20409.669087171555, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 648160, "time": 20410.13669013977, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 648880, "time": 20431.926302671432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648888, "time": 20431.9532725811, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 649152, "time": 20440.150468826294, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 649176, "time": 20440.659342765808, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 649312, "time": 20444.97983598709, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 649832, "time": 20460.49161720276, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 649864, "time": 20461.46058154106, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 20466.916060209274, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 650000, "time": 20467.29613494873, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 650000, "time": 20468.2235519886, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 650000, "time": 20468.29956316948, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 650000, "time": 20468.396141290665, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 650000, "time": 20468.89109992981, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 650000, "time": 20469.297923088074, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 650000, "time": 20469.876002550125, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 650176, "time": 20475.175987243652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650344, "time": 20480.024742603302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650472, "time": 20484.026849746704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650488, "time": 20484.51334118843, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 651112, "time": 20503.32238674164, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 651192, "time": 20505.7508957386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651520, "time": 20515.944537639618, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 651552, "time": 20516.913491249084, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 651624, "time": 20518.866689920425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651776, "time": 20523.67540693283, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 651912, "time": 20527.58884215355, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 652024, "time": 20530.9890935421, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 652080, "time": 20532.890892267227, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 652144, "time": 20534.834660053253, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 652272, "time": 20538.69878578186, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 652560, "time": 20547.43316745758, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 652800, "time": 20554.682421445847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652808, "time": 20554.708542346954, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 652952, "time": 20559.05802488327, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 653248, "time": 20568.2032661438, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 653456, "time": 20574.568284988403, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 653480, "time": 20575.07411789894, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 653832, "time": 20585.69707775116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653848, "time": 20586.18515610695, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 654064, "time": 20594.588694810867, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 654216, "time": 20599.01239991188, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 654584, "time": 20610.267438173294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654632, "time": 20611.707688093185, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 654904, "time": 20619.936848640442, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 655264, "time": 20631.138729810715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655560, "time": 20640.382581472397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655584, "time": 20641.328879356384, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 655648, "time": 20643.27667951584, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 655792, "time": 20647.672510385513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656080, "time": 20656.329047203064, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 656096, "time": 20656.818273067474, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 656160, "time": 20658.76119685173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656392, "time": 20665.63752746582, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 656520, "time": 20669.554585695267, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 656528, "time": 20670.02907896042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656544, "time": 20670.52433490753, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 656728, "time": 20675.922869443893, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 656944, "time": 20682.71573996544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 657224, "time": 20691.08854675293, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 657360, "time": 20695.42293024063, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 657368, "time": 20695.44912672043, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 657688, "time": 20705.148041009903, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 657728, "time": 20706.607421398163, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 657896, "time": 20711.509672880173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 657968, "time": 20713.921322584152, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 658408, "time": 20727.104962587357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658424, "time": 20727.597320318222, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 658576, "time": 20732.438655614853, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 658856, "time": 20740.670775175095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659120, "time": 20748.833010673523, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 659536, "time": 20761.502250909805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659672, "time": 20765.389379024506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659680, "time": 20765.853992700577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659920, "time": 20773.071536302567, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 20778.553267002106, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 660088, "time": 20779.159123420715, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 660088, "time": 20782.122856378555, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 660088, "time": 20783.828883886337, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 20783.838514328003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 20783.84842300415, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 20783.859786510468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 20783.86813402176, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 20783.877366304398, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660208, "time": 20787.738770723343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660224, "time": 20788.22504377365, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 660736, "time": 20803.742407798767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660760, "time": 20804.2786693573, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 661056, "time": 20813.49330353737, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 661168, "time": 20816.875640392303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 661192, "time": 20817.380786180496, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 661264, "time": 20819.783420324326, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 661744, "time": 20834.27813434601, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 661848, "time": 20837.16725754738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 661984, "time": 20841.56934452057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 661992, "time": 20841.59841275215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662208, "time": 20848.34489798546, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 662536, "time": 20858.025591373444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662576, "time": 20859.45670890808, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 662976, "time": 20871.62512755394, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 663240, "time": 20879.36482334137, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 663480, "time": 20886.634093761444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663576, "time": 20889.984330177307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663976, "time": 20902.13514304161, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 664056, "time": 20904.548042535782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664296, "time": 20911.798530817032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664304, "time": 20912.264007091522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664848, "time": 20928.62885785103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665552, "time": 20949.958988189697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665632, "time": 20952.375674962997, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 665792, "time": 20957.225172519684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665888, "time": 20960.141011953354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666288, "time": 20972.315024137497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666552, "time": 20980.048558473587, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 666608, "time": 20981.952888727188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666616, "time": 20981.980563402176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666640, "time": 20982.925431728363, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 666888, "time": 20990.238201379776, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 667160, "time": 20998.517695188522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667224, "time": 21000.447733163834, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 667328, "time": 21003.829722881317, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 667400, "time": 21005.810217142105, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 667752, "time": 21016.45428276062, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 667864, "time": 21019.858429193497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667944, "time": 21022.38230252266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668480, "time": 21038.79800772667, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 668552, "time": 21040.7519261837, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 668952, "time": 21052.864742279053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668968, "time": 21053.348749876022, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 669200, "time": 21060.585614204407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669280, "time": 21063.03259205818, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 669536, "time": 21070.785028219223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669640, "time": 21073.715734004974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670048, "time": 21086.417637109756, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 21087.95655274391, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 670072, "time": 21088.579122781754, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 670072, "time": 21089.443206310272, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 670072, "time": 21090.121896266937, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 670072, "time": 21090.322823762894, "eval_episode/length": 178.0, "eval_episode/score": 0.4437499940395355, "eval_episode/reward_rate": 0.00558659217877095}
{"step": 670072, "time": 21090.788529634476, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 670072, "time": 21090.8865942955, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 670072, "time": 21092.11786365509, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 670176, "time": 21095.45205593109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670192, "time": 21095.955288410187, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 670256, "time": 21097.877569913864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670504, "time": 21105.122580766678, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 670760, "time": 21112.990822792053, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 670920, "time": 21117.8207051754, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 671168, "time": 21125.526711940765, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 671176, "time": 21125.55309033394, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 671264, "time": 21128.40497279167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671280, "time": 21128.89471912384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671304, "time": 21129.401512384415, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 671592, "time": 21138.086805343628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671640, "time": 21139.547548294067, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 671848, "time": 21146.411381483078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671944, "time": 21149.29829144478, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 672184, "time": 21156.54242682457, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 672488, "time": 21165.746843099594, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 672840, "time": 21176.504860639572, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 673480, "time": 21195.81445813179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673488, "time": 21196.283277273178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673592, "time": 21199.2147936821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673616, "time": 21200.18702340126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674256, "time": 21219.694393396378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674336, "time": 21222.094906568527, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 674384, "time": 21223.554538965225, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 674496, "time": 21226.918776750565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674560, "time": 21228.864548921585, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 674800, "time": 21236.13021659851, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674976, "time": 21241.429892778397, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 675064, "time": 21243.945332050323, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 675152, "time": 21246.831514835358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675488, "time": 21256.92670416832, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 675552, "time": 21258.850543022156, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 675913, "time": 21270.56292963028, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4166951698831993, "train/action_min": 0.0, "train/action_std": 1.6374853153039914, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008684775603031464, "train/actor_opt_grad_steps": 41135.0, "train/actor_opt_loss": -9.737438195265165, "train/adv_mag": 0.7942314457775342, "train/adv_max": 0.2790965437889099, "train/adv_mean": 0.0004912322422227373, "train/adv_min": -0.758294670298548, "train/adv_std": 0.025580079778844474, "train/cont_avg": 0.9956973236386139, "train/cont_loss_mean": 0.01450703703420292, "train/cont_loss_std": 0.21639034961636114, "train/cont_neg_acc": 0.3610696570567824, "train/cont_neg_loss": 2.698633752557083, "train/cont_pos_acc": 0.9998931734278651, "train/cont_pos_loss": 0.002966998781234321, "train/cont_pred": 0.9955693834488935, "train/cont_rate": 0.9956973236386139, "train/dyn_loss_mean": 1.0000002012394442, "train/dyn_loss_std": 6.43517042851389e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16497945168175468, "train/extr_critic_critic_opt_grad_steps": 41135.0, "train/extr_critic_critic_opt_loss": 11551.25361618193, "train/extr_critic_mag": 1.1808144125607933, "train/extr_critic_max": 1.1808144125607933, "train/extr_critic_mean": 1.1007684557744772, "train/extr_critic_min": 0.9195128425513164, "train/extr_critic_std": 0.01849942473178305, "train/extr_return_normed_mag": 0.7950539807281872, "train/extr_return_normed_max": 0.27355066738506356, "train/extr_return_normed_mean": 0.03277602915347803, "train/extr_return_normed_min": -0.7464921211842264, "train/extr_return_normed_std": 0.03221924340647488, "train/extr_return_rate": 0.9992877590184165, "train/extr_return_raw_mag": 1.3420342667268055, "train/extr_return_raw_max": 1.3420342667268055, "train/extr_return_raw_mean": 1.101259684798741, "train/extr_return_raw_min": 0.32199147815751555, "train/extr_return_raw_std": 0.03221924336498032, "train/extr_reward_mag": 0.303362236754729, "train/extr_reward_max": 0.303362236754729, "train/extr_reward_mean": 0.0014437915966788418, "train/extr_reward_min": 7.553855971534654e-08, "train/extr_reward_std": 0.008099161209492474, "train/image_loss_mean": 0.07799978664900997, "train/image_loss_std": 0.09352787668899734, "train/model_loss_mean": 0.7003378575981254, "train/model_loss_std": 0.36622942150524346, "train/model_opt_grad_norm": 23.164220605916643, "train/model_opt_grad_steps": 41095.574257425746, "train/model_opt_loss": 3638.683458384901, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5173.267326732674, "train/policy_entropy_mag": 1.3702831681412044, "train/policy_entropy_max": 1.3702831681412044, "train/policy_entropy_mean": 0.11582752523740919, "train/policy_entropy_min": 0.06468650355640024, "train/policy_entropy_std": 0.1513582065996557, "train/policy_logprob_mag": 6.551080238701093, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11548011303685679, "train/policy_logprob_min": -6.551080238701093, "train/policy_logprob_std": 0.6506584469634707, "train/policy_randomness_mag": 0.7041862902074757, "train/policy_randomness_max": 0.7041862902074757, "train/policy_randomness_mean": 0.05952357650172002, "train/policy_randomness_min": 0.03324228774129164, "train/policy_randomness_std": 0.07778273615064007, "train/post_ent_mag": 33.591676353227975, "train/post_ent_max": 33.591676353227975, "train/post_ent_mean": 33.2804527849254, "train/post_ent_min": 33.07970045108606, "train/post_ent_std": 0.1054649085249051, "train/prior_ent_mag": 33.81718531693562, "train/prior_ent_max": 33.81718531693562, "train/prior_ent_mean": 32.513479827654244, "train/prior_ent_min": 31.519196189276062, "train/prior_ent_std": 0.3439375469000033, "train/rep_loss_mean": 1.0000002012394442, "train/rep_loss_std": 6.43517042851389e-06, "train/reward_avg": 0.0010013089325517591, "train/reward_loss_mean": 0.00783089302609315, "train/reward_loss_std": 0.15369099170997702, "train/reward_max_data": 0.5993966587846822, "train/reward_max_pred": 0.152024769546962, "train/reward_neg_acc": 0.9998741400713967, "train/reward_neg_loss": 0.0013097424896048972, "train/reward_pos_acc": 0.19500998126532504, "train/reward_pos_loss": 4.284726311703642, "train/reward_pred": 0.0007929828532021677, "train/reward_rate": 0.0015228573638613862, "train_stats/mean_log_entropy": 0.09841829534228994, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.018563441932201385, "report/cont_loss_std": 0.2476380318403244, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.766023635864258, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0038675209507346153, "report/cont_pred": 0.9959900379180908, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08605282753705978, "report/image_loss_std": 0.11002126336097717, "report/model_loss_mean": 0.7063181400299072, "report/model_loss_std": 0.2682325541973114, "report/post_ent_mag": 33.398983001708984, "report/post_ent_max": 33.398983001708984, "report/post_ent_mean": 33.08347702026367, "report/post_ent_min": 32.86435317993164, "report/post_ent_std": 0.11157751828432083, "report/prior_ent_mag": 33.65161895751953, "report/prior_ent_max": 33.65161895751953, "report/prior_ent_mean": 32.28965759277344, "report/prior_ent_min": 31.43678092956543, "report/prior_ent_std": 0.3573320209980011, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0017017768695950508, "report/reward_loss_std": 0.006466325838118792, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.027275562286376953, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0017017768695950508, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0008624428883194923, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02535713091492653, "eval/cont_loss_std": 0.43250200152397156, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.06283712387085, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0016807394567877054, "eval/cont_pred": 0.9982787370681763, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15715435147285461, "eval/image_loss_std": 0.1260269284248352, "eval/model_loss_mean": 0.7880034446716309, "eval/model_loss_std": 0.5121101140975952, "eval/post_ent_mag": 33.39875793457031, "eval/post_ent_max": 33.39875793457031, "eval/post_ent_mean": 33.05487060546875, "eval/post_ent_min": 32.845115661621094, "eval/post_ent_std": 0.11177219450473785, "eval/prior_ent_mag": 33.44448471069336, "eval/prior_ent_max": 33.44448471069336, "eval/prior_ent_mean": 32.20447540283203, "eval/prior_ent_min": 31.396591186523438, "eval/prior_ent_std": 0.3369925320148468, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005615234258584678, "eval/reward_loss_mean": 0.005491890944540501, "eval/reward_loss_std": 0.1533532291650772, "eval/reward_max_data": 0.574999988079071, "eval/reward_max_pred": 0.02248966693878174, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0006987328524701297, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.908892631530762, "eval/reward_pred": 0.00036366935819387436, "eval/reward_rate": 0.0009765625, "replay/size": 675409.0, "replay/inserts": 32352.0, "replay/samples": 32352.0, "replay/insert_wait_avg": 1.2674388262921342e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.813676646390136e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1607805887858074e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2229928970337, "timer/env.step_count": 4044.0, "timer/env.step_total": 38.221132040023804, "timer/env.step_frac": 0.03821261089921617, "timer/env.step_avg": 0.009451318506435165, "timer/env.step_min": 0.007645130157470703, "timer/env.step_max": 0.04372739791870117, "timer/replay._sample_count": 32352.0, "timer/replay._sample_total": 16.979392051696777, "timer/replay._sample_frac": 0.016975606611999462, "timer/replay._sample_avg": 0.0005248328403714385, "timer/replay._sample_min": 0.0003826618194580078, "timer/replay._sample_max": 0.025794029235839844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4794.0, "timer/agent.policy_total": 49.972734451293945, "timer/agent.policy_frac": 0.04996159337084776, "timer/agent.policy_avg": 0.010424016364475167, "timer/agent.policy_min": 0.008608818054199219, "timer/agent.policy_max": 0.08717560768127441, "timer/dataset_train_count": 2022.0, "timer/dataset_train_total": 0.21827149391174316, "timer/dataset_train_frac": 0.0002182228317702878, "timer/dataset_train_avg": 0.00010794831548553074, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.001077890396118164, "timer/agent.train_count": 2022.0, "timer/agent.train_total": 898.9190275669098, "timer/agent.train_frac": 0.8987186196982851, "timer/agent.train_avg": 0.44456925201133024, "timer/agent.train_min": 0.4339442253112793, "timer/agent.train_max": 2.1190030574798584, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47894883155822754, "timer/agent.report_frac": 0.000478842053181567, "timer/agent.report_avg": 0.23947441577911377, "timer/agent.report_min": 0.23157453536987305, "timer/agent.report_max": 0.2473742961883545, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027240901371228e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 32.34420191852124}
{"step": 675928, "time": 21270.616663217545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675952, "time": 21271.976385593414, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 675960, "time": 21272.001976251602, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 676376, "time": 21284.552139759064, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 676504, "time": 21288.44043111801, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 676648, "time": 21292.852872133255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676696, "time": 21294.299996376038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677104, "time": 21306.86051750183, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 677112, "time": 21306.88876104355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677288, "time": 21312.212647914886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677320, "time": 21313.179182052612, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 678192, "time": 21339.861788988113, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 678256, "time": 21341.78605079651, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 678264, "time": 21341.81460762024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678272, "time": 21342.28199982643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678640, "time": 21353.50230073929, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 678688, "time": 21354.97541308403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678960, "time": 21363.142934560776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679120, "time": 21367.957651138306, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 679416, "time": 21376.65941619873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679600, "time": 21382.529408216476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 21397.84520983696, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 680056, "time": 21398.279250621796, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 680056, "time": 21398.534950733185, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 680056, "time": 21399.406043052673, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 680056, "time": 21400.090262651443, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 680056, "time": 21401.944183588028, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 21401.95440363884, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 21401.967266082764, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 21401.9754178524, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680120, "time": 21403.931287050247, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 680192, "time": 21406.30948615074, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 680568, "time": 21417.506363391876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680584, "time": 21417.993434906006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680736, "time": 21422.788056850433, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 680952, "time": 21429.108481884003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681000, "time": 21430.549634456635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681272, "time": 21438.768575906754, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 681272, "time": 21438.791882753372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681392, "time": 21442.717937231064, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 681576, "time": 21448.053795576096, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 681616, "time": 21449.47356557846, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 681656, "time": 21450.461458444595, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 681800, "time": 21454.807755947113, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 682064, "time": 21463.034220695496, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 682288, "time": 21469.77197957039, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 682296, "time": 21469.798753499985, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 682424, "time": 21473.795781612396, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 682432, "time": 21474.264201402664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 682488, "time": 21475.7299387455, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 683264, "time": 21499.31093621254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683264, "time": 21499.328158140182, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 683352, "time": 21501.833000421524, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 683584, "time": 21509.0248131752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683784, "time": 21514.826085805893, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 683832, "time": 21516.29752087593, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 684096, "time": 21524.467516183853, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 684192, "time": 21527.36853170395, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 684296, "time": 21530.332666873932, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 684376, "time": 21532.802543640137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684496, "time": 21536.658184289932, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 684600, "time": 21539.58897304535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684608, "time": 21540.060294866562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684800, "time": 21545.883619070053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684840, "time": 21546.879106760025, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 685240, "time": 21559.010126829147, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 685440, "time": 21565.397773742676, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 685576, "time": 21569.27364206314, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 685680, "time": 21572.611887454987, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 685760, "time": 21575.04097366333, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 685992, "time": 21581.79368829727, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 686360, "time": 21593.036735534668, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 686408, "time": 21594.496339797974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686632, "time": 21601.235472917557, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 686664, "time": 21602.204706907272, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 686808, "time": 21606.556302785873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686888, "time": 21608.985864639282, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 686912, "time": 21609.933537006378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687304, "time": 21621.593861341476, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 687352, "time": 21623.051865577698, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 687376, "time": 21623.99999141693, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 687552, "time": 21629.314601898193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687752, "time": 21635.149697303772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687936, "time": 21640.8989443779, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 688016, "time": 21643.327563524246, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 688128, "time": 21646.848430395126, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 688280, "time": 21651.609442710876, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 688392, "time": 21654.976783275604, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 688672, "time": 21663.646102190018, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 688672, "time": 21663.66584801674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 688944, "time": 21671.89782309532, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 689096, "time": 21676.270896434784, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 689200, "time": 21679.62808585167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 689224, "time": 21680.136419534683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 689392, "time": 21685.537590265274, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 689400, "time": 21686.247805833817, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 689664, "time": 21694.434630393982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 689664, "time": 21694.45497083664, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 689768, "time": 21697.38244819641, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 689920, "time": 21702.19561266899, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 21706.506052017212, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 690040, "time": 21707.113213062286, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 690040, "time": 21707.193135738373, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 690040, "time": 21707.4407184124, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 690040, "time": 21707.648684501648, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 690040, "time": 21707.797776460648, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 690040, "time": 21707.941340208054, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 690040, "time": 21708.429347753525, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 690984, "time": 21736.968281030655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691256, "time": 21745.219969511032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691536, "time": 21753.899040460587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691704, "time": 21758.75750350952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691704, "time": 21758.808789014816, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 691744, "time": 21760.2330930233, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 691976, "time": 21767.049232006073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691976, "time": 21767.07618021965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692080, "time": 21770.618493318558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692152, "time": 21772.627382040024, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 692232, "time": 21775.107434511185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692632, "time": 21787.383051872253, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 692768, "time": 21791.76363348961, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 693344, "time": 21809.278457403183, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 693400, "time": 21810.763437271118, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 693536, "time": 21815.074071645737, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 694016, "time": 21829.60071849823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694056, "time": 21830.70473051071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694288, "time": 21837.879919052124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694376, "time": 21840.319935321808, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 694392, "time": 21840.808740377426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694432, "time": 21842.228857517242, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 694464, "time": 21843.194413900375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694736, "time": 21851.450759410858, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 694944, "time": 21857.73322057724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694976, "time": 21858.70380282402, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 695096, "time": 21862.220745801926, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 695232, "time": 21866.56279850006, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 695712, "time": 21881.024898290634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 695856, "time": 21885.373512029648, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 695928, "time": 21887.316569805145, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 695992, "time": 21889.25560259819, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 696328, "time": 21899.642077684402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696640, "time": 21909.598932027817, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 696640, "time": 21909.60828757286, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 696680, "time": 21910.59983944893, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 696744, "time": 21912.530119895935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696824, "time": 21914.9562458992, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 697384, "time": 21931.97291135788, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 697424, "time": 21933.42861509323, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 697544, "time": 21936.824306488037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697672, "time": 21940.680058002472, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 697824, "time": 21945.493054628372, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 698304, "time": 21960.063774347305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698472, "time": 21964.912979125977, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 698640, "time": 21970.214985609055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698648, "time": 21970.242267608643, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 698864, "time": 21976.97641658783, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 698896, "time": 21977.945061922073, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 698992, "time": 21980.906379699707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699056, "time": 21982.839767456055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699416, "time": 21993.479292154312, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 699416, "time": 21993.488204717636, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 699464, "time": 21994.940441846848, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 699736, "time": 22003.190460920334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699968, "time": 22010.52183699608, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 22013.39507675171, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 700024, "time": 22013.402636766434, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 700024, "time": 22014.335284233093, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 700024, "time": 22015.154897928238, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 700024, "time": 22015.773979902267, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 700024, "time": 22016.12407207489, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 700024, "time": 22017.21734213829, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 700024, "time": 22017.31884288788, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22017.327825307846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22017.336229801178, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22017.346158504486, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 22017.354647159576, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700136, "time": 22020.765597581863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700176, "time": 22022.194925785065, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 700344, "time": 22027.08140230179, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 700808, "time": 22041.25385284424, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 700856, "time": 22042.705897808075, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 701016, "time": 22047.5369246006, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 701360, "time": 22058.162435293198, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 701664, "time": 22067.332342147827, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 701728, "time": 22069.276688575745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701728, "time": 22069.286172151566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701728, "time": 22069.294635295868, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 701776, "time": 22070.817784547806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702032, "time": 22078.540009975433, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 702280, "time": 22085.82071375847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702608, "time": 22095.94694876671, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 702888, "time": 22104.258295059204, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 703120, "time": 22111.47671198845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 703136, "time": 22111.964231967926, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 703656, "time": 22127.423919677734, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 703672, "time": 22127.91072821617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 703976, "time": 22137.124086141586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 704040, "time": 22139.058790445328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 704040, "time": 22139.066841602325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 704312, "time": 22147.26803469658, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 704344, "time": 22148.234219789505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 704440, "time": 22151.135710954666, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 704920, "time": 22166.136994361877, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 705296, "time": 22177.693631887436, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 705448, "time": 22182.048869371414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705552, "time": 22185.410603046417, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 705696, "time": 22189.72406935692, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 706136, "time": 22202.875101566315, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 706264, "time": 22206.77763581276, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 706280, "time": 22207.27260518074, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 706288, "time": 22207.749410629272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706352, "time": 22209.71365714073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706624, "time": 22217.9206366539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707224, "time": 22235.915499687195, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 707232, "time": 22236.38360118866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707536, "time": 22245.521209955215, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 708048, "time": 22261.015451431274, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 708345, "time": 22270.71224951744, "train_stats/mean_log_entropy": 0.09891530296745453, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4743366711245383, "train/action_min": 0.0, "train/action_std": 1.6235881585792955, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008556432385465561, "train/actor_opt_grad_steps": 43160.0, "train/actor_opt_loss": -10.12281976309903, "train/adv_mag": 0.8128859841177616, "train/adv_max": 0.3077752601924201, "train/adv_mean": -0.0005805001703373115, "train/adv_min": -0.7755257548957035, "train/adv_std": 0.02490242335284725, "train/cont_avg": 0.9956704125615764, "train/cont_loss_mean": 0.014470044614659998, "train/cont_loss_std": 0.21101287408075822, "train/cont_neg_acc": 0.39918474561654693, "train/cont_neg_loss": 2.5559152923977506, "train/cont_pos_acc": 0.999888778613706, "train/cont_pos_loss": 0.003053681235049342, "train/cont_pred": 0.9954101660568726, "train/cont_rate": 0.9956704125615764, "train/dyn_loss_mean": 1.0000048406018411, "train/dyn_loss_std": 0.0001145636954165885, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11923996494449858, "train/extr_critic_critic_opt_grad_steps": 43160.0, "train/extr_critic_critic_opt_loss": 12419.9970703125, "train/extr_critic_mag": 1.1720792037512868, "train/extr_critic_max": 1.1720792037512868, "train/extr_critic_mean": 1.083005262713127, "train/extr_critic_min": 0.903099907442854, "train/extr_critic_std": 0.01753218653680656, "train/extr_return_normed_mag": 0.8171635413991993, "train/extr_return_normed_max": 0.2906766801044859, "train/extr_return_normed_mean": 0.029082120520067332, "train/extr_return_normed_min": -0.7690960585777395, "train/extr_return_normed_std": 0.030870386628718504, "train/extr_return_rate": 0.9993669590339285, "train/extr_return_raw_mag": 1.3440193701260195, "train/extr_return_raw_max": 1.3440193701260195, "train/extr_return_raw_mean": 1.0824248696782905, "train/extr_return_raw_min": 0.28424663144379414, "train/extr_return_raw_std": 0.030870386738825608, "train/extr_reward_mag": 0.3180895497646238, "train/extr_reward_max": 0.3180895497646238, "train/extr_reward_mean": 0.0014718958317747183, "train/extr_reward_min": -2.5838466700661947e-08, "train/extr_reward_std": 0.00795564039729609, "train/image_loss_mean": 0.07697615243971641, "train/image_loss_std": 0.09363939132302852, "train/model_loss_mean": 0.699308327853386, "train/model_loss_std": 0.3530432160925395, "train/model_opt_grad_norm": 23.123515899545453, "train/model_opt_grad_steps": 43118.62561576354, "train/model_opt_loss": 3633.256510015779, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5197.04433497537, "train/policy_entropy_mag": 1.3459803553050376, "train/policy_entropy_max": 1.3459803553050376, "train/policy_entropy_mean": 0.11425750353947062, "train/policy_entropy_min": 0.06468649777432381, "train/policy_entropy_std": 0.14793454859350702, "train/policy_logprob_mag": 6.5510802386429505, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11437153673083911, "train/policy_logprob_min": -6.5510802386429505, "train/policy_logprob_std": 0.6507704992012437, "train/policy_randomness_mag": 0.691697115087744, "train/policy_randomness_max": 0.691697115087744, "train/policy_randomness_mean": 0.058716744312952304, "train/policy_randomness_min": 0.03324228468273074, "train/policy_randomness_std": 0.07602332292005347, "train/post_ent_mag": 33.51612393609409, "train/post_ent_max": 33.51612393609409, "train/post_ent_mean": 33.20270816445938, "train/post_ent_min": 32.99272354952807, "train/post_ent_std": 0.10919611537691408, "train/prior_ent_mag": 34.0805055965931, "train/prior_ent_max": 34.0805055965931, "train/prior_ent_mean": 32.726829942224064, "train/prior_ent_min": 31.588910051167304, "train/prior_ent_std": 0.4007432995171383, "train/rep_loss_mean": 1.0000048406018411, "train/rep_loss_std": 0.0001145636954165885, "train/reward_avg": 0.0010887409078377056, "train/reward_loss_mean": 0.007859202963758829, "train/reward_loss_std": 0.14373880969314592, "train/reward_max_data": 0.5854371937331307, "train/reward_max_pred": 0.19961306849136728, "train/reward_neg_acc": 0.9996867379531484, "train/reward_neg_loss": 0.0014518065357424796, "train/reward_pos_acc": 0.26121593393244835, "train/reward_pos_loss": 3.9520520729088933, "train/reward_pred": 0.0009029949166504621, "train/reward_rate": 0.0015923260467980295, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.010110331699252129, "report/cont_loss_std": 0.20664578676223755, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.363247394561768, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0015914732357487082, "report/cont_pred": 0.9983505010604858, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09382019937038422, "report/image_loss_std": 0.11287905275821686, "report/model_loss_mean": 0.7052912712097168, "report/model_loss_std": 0.24197155237197876, "report/post_ent_mag": 33.05550765991211, "report/post_ent_max": 33.05550765991211, "report/post_ent_mean": 32.71343231201172, "report/post_ent_min": 32.46364212036133, "report/post_ent_std": 0.11621969193220139, "report/prior_ent_mag": 34.1097412109375, "report/prior_ent_max": 34.1097412109375, "report/prior_ent_mean": 32.9241943359375, "report/prior_ent_min": 31.367679595947266, "report/prior_ent_std": 0.3523717522621155, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0013606525026261806, "report/reward_loss_std": 0.005900285206735134, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.030045390129089355, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0013606525026261806, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000705377315171063, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.022420544177293777, "eval/cont_loss_std": 0.4395149350166321, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.979911804199219, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001977375941351056, "eval/cont_pred": 0.9980425834655762, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12862485647201538, "eval/image_loss_std": 0.13763384521007538, "eval/model_loss_mean": 0.7613500952720642, "eval/model_loss_std": 0.5767603516578674, "eval/post_ent_mag": 33.05587387084961, "eval/post_ent_max": 33.05587387084961, "eval/post_ent_mean": 32.702735900878906, "eval/post_ent_min": 32.480133056640625, "eval/post_ent_std": 0.11605749279260635, "eval/prior_ent_mag": 34.1097412109375, "eval/prior_ent_max": 34.1097412109375, "eval/prior_ent_mean": 32.9108772277832, "eval/prior_ent_min": 31.861743927001953, "eval/prior_ent_std": 0.34968551993370056, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0014801025390625, "eval/reward_loss_mean": 0.010304674506187439, "eval/reward_loss_std": 0.20262809097766876, "eval/reward_max_data": 0.793749988079071, "eval/reward_max_pred": 0.06731045246124268, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015410305932164192, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.488527297973633, "eval/reward_pred": 0.0008355783065780997, "eval/reward_rate": 0.001953125, "replay/size": 707841.0, "replay/inserts": 32432.0, "replay/samples": 32432.0, "replay/insert_wait_avg": 1.2745013893326928e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.802415611594547e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5848.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1032566978569397e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1296937465668, "timer/env.step_count": 4054.0, "timer/env.step_total": 38.405547857284546, "timer/env.step_frac": 0.0384005675438095, "timer/env.step_avg": 0.009473494784727317, "timer/env.step_min": 0.007584571838378906, "timer/env.step_max": 0.054070472717285156, "timer/replay._sample_count": 32432.0, "timer/replay._sample_total": 16.848965167999268, "timer/replay._sample_frac": 0.016846780245951584, "timer/replay._sample_avg": 0.0005195166862357939, "timer/replay._sample_min": 0.00040912628173828125, "timer/replay._sample_max": 0.01652812957763672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4785.0, "timer/agent.policy_total": 49.09049582481384, "timer/agent.policy_frac": 0.049084129920107536, "timer/agent.policy_avg": 0.010259246776345632, "timer/agent.policy_min": 0.007946014404296875, "timer/agent.policy_max": 0.07895731925964355, "timer/dataset_train_count": 2027.0, "timer/dataset_train_total": 0.21881461143493652, "timer/dataset_train_frac": 0.00021878623622826284, "timer/dataset_train_avg": 0.00010794998097431501, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0005640983581542969, "timer/agent.train_count": 2027.0, "timer/agent.train_total": 898.907924413681, "timer/agent.train_frac": 0.8987913567952365, "timer/agent.train_avg": 0.4434671556061574, "timer/agent.train_min": 0.43038105964660645, "timer/agent.train_max": 0.6849563121795654, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4784541130065918, "timer/agent.report_frac": 0.00047839206854689414, "timer/agent.report_avg": 0.2392270565032959, "timer/agent.report_min": 0.23147296905517578, "timer/agent.report_max": 0.24698114395141602, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122878368434794e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 32.42721027452303}
{"step": 708424, "time": 22272.850613832474, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 708448, "time": 22273.81201505661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 708576, "time": 22277.65156531334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 708592, "time": 22278.163678646088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 708600, "time": 22278.192640542984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 708664, "time": 22280.137890815735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 708888, "time": 22286.989905834198, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 709072, "time": 22292.744593143463, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 709072, "time": 22292.753076314926, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 709608, "time": 22308.61161327362, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 709816, "time": 22314.957891464233, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 709880, "time": 22316.888081550598, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 710000, "time": 22320.715080976486, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 22321.95828104019, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 710008, "time": 22322.83093214035, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 710008, "time": 22324.126755714417, "eval_episode/length": 183.0, "eval_episode/score": 0.4281249940395355, "eval_episode/reward_rate": 0.005434782608695652}
{"step": 710008, "time": 22324.96647119522, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 710008, "time": 22326.78011250496, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 22326.78775024414, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 22326.797261953354, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 22326.805753469467, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 22326.812784910202, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 22326.820251703262, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710360, "time": 22337.398088932037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710440, "time": 22339.79173350334, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 710536, "time": 22342.769399881363, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 710560, "time": 22343.706147909164, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 710912, "time": 22354.33079123497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710928, "time": 22354.819697856903, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 711016, "time": 22357.294098615646, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 711200, "time": 22363.087353229523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711384, "time": 22368.407990932465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711496, "time": 22371.863659858704, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 711536, "time": 22373.286018371582, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 711544, "time": 22373.31351709366, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 712096, "time": 22390.258231163025, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 712312, "time": 22396.551943063736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712376, "time": 22398.4803917408, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 712480, "time": 22401.927640914917, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 712752, "time": 22410.604046821594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712848, "time": 22413.491958141327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713240, "time": 22425.101764678955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713264, "time": 22426.044704914093, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 713272, "time": 22426.070322990417, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 713680, "time": 22438.65560746193, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 713696, "time": 22439.14514040947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714408, "time": 22460.477313280106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714792, "time": 22472.022936344147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714992, "time": 22478.26859664917, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 715016, "time": 22478.772143125534, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 715408, "time": 22490.83072400093, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 715456, "time": 22492.272891283035, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 715472, "time": 22492.78527355194, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 715560, "time": 22495.22621512413, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 715576, "time": 22495.712263822556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715584, "time": 22496.182417154312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715752, "time": 22501.007197618484, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 715904, "time": 22505.78753876686, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 715944, "time": 22506.765907526016, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 715944, "time": 22506.771444559097, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 716168, "time": 22513.505762577057, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 716472, "time": 22522.726493358612, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 716568, "time": 22525.61138701439, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 716680, "time": 22528.995800495148, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 717104, "time": 22541.96605372429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717512, "time": 22554.06561756134, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 717728, "time": 22560.774610042572, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 717872, "time": 22565.107593774796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717888, "time": 22565.5931828022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718216, "time": 22575.203526973724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718256, "time": 22576.626186847687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718664, "time": 22588.793116092682, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 718784, "time": 22592.62824845314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718992, "time": 22598.88482069969, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 719416, "time": 22611.581501722336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719576, "time": 22616.424824476242, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 719824, "time": 22624.153115034103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719880, "time": 22625.62240409851, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 719880, "time": 22625.630497932434, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 720040, "time": 22630.449479579926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720080, "time": 22631.865854024887, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 22633.694422006607, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 720096, "time": 22633.720789909363, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 720096, "time": 22635.521253585815, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 720096, "time": 22636.510010242462, "eval_episode/length": 224.0, "eval_episode/score": 0.30000001192092896, "eval_episode/reward_rate": 0.0044444444444444444}
{"step": 720096, "time": 22637.645461320877, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 22637.653914928436, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 22637.662853240967, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 22637.671269893646, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 22637.682137727737, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720200, "time": 22640.666427373886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720376, "time": 22645.95844244957, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 720376, "time": 22645.968222141266, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 720400, "time": 22646.917607307434, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 720448, "time": 22648.376408576965, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 720568, "time": 22651.75233054161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720616, "time": 22653.211419582367, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 721032, "time": 22666.29972743988, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 721240, "time": 22672.78098630905, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 721520, "time": 22681.374517917633, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 722192, "time": 22701.65474843979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722352, "time": 22706.456528425217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722440, "time": 22708.862386465073, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 722576, "time": 22713.18740963936, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 722688, "time": 22716.580127477646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722760, "time": 22718.525751829147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722880, "time": 22722.354108810425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722984, "time": 22725.267302274704, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 723024, "time": 22726.726335525513, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 723088, "time": 22728.65959239006, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 723344, "time": 22736.503761529922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723456, "time": 22739.876853466034, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 723464, "time": 22739.902435302734, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 723624, "time": 22744.736729621887, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 723632, "time": 22745.227128744125, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 723656, "time": 22745.736044168472, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 723936, "time": 22754.431166410446, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 724608, "time": 22774.98621916771, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 724752, "time": 22779.380452394485, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 724776, "time": 22779.888322114944, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 724824, "time": 22781.343572854996, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 724848, "time": 22782.296711921692, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 724880, "time": 22783.26872777939, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 725000, "time": 22786.67923951149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 725192, "time": 22792.58411884308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 725520, "time": 22802.725808620453, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 725544, "time": 22803.237433433533, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 725624, "time": 22805.68679833412, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 725968, "time": 22816.305366754532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 726064, "time": 22819.224968910217, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 726128, "time": 22821.263751506805, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 727088, "time": 22850.49792098999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727192, "time": 22853.457773447037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727280, "time": 22856.340218305588, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 727312, "time": 22857.332855463028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727832, "time": 22872.857736825943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727856, "time": 22873.80629348755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727952, "time": 22876.719898939133, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 727992, "time": 22877.704085111618, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 728280, "time": 22886.51372218132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728376, "time": 22889.410722970963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728832, "time": 22903.41182422638, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 728840, "time": 22903.438285589218, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 728856, "time": 22903.921142101288, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 729024, "time": 22909.17862868309, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 729400, "time": 22920.865904808044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 729408, "time": 22921.331707715988, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 729504, "time": 22924.22495532036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 729832, "time": 22933.86682486534, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 22942.600838422775, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 730080, "time": 22943.34646463394, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 730080, "time": 22943.70354938507, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 730080, "time": 22943.747927427292, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 730080, "time": 22943.975020885468, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 730080, "time": 22944.178577184677, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 730080, "time": 22945.510335206985, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 730080, "time": 22945.92079758644, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 730088, "time": 22945.946247816086, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 730304, "time": 22952.781066417694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 730672, "time": 22964.061792612076, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 731088, "time": 22976.708753824234, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 731144, "time": 22978.184854507446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731152, "time": 22978.67475771904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731336, "time": 22984.02804160118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731720, "time": 22995.624551057816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731816, "time": 22998.560950279236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732128, "time": 23008.521671056747, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 732144, "time": 23009.021889448166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732440, "time": 23017.87017083168, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 732736, "time": 23027.042804718018, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 732896, "time": 23032.039226531982, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 732984, "time": 23034.529122829437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733344, "time": 23045.639095067978, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 733400, "time": 23047.135918855667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733456, "time": 23049.053292036057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733464, "time": 23049.081681728363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733544, "time": 23051.500413417816, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 734008, "time": 23065.6515750885, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 734048, "time": 23067.10662150383, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 734128, "time": 23069.528979063034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 734184, "time": 23071.007120132446, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 734192, "time": 23071.493316173553, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 734288, "time": 23074.379234552383, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 734720, "time": 23087.42611026764, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 734736, "time": 23087.914886713028, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 735024, "time": 23096.644180059433, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 735048, "time": 23097.1526389122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735096, "time": 23098.59913444519, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 735208, "time": 23102.044065237045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735312, "time": 23105.480523347855, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 735704, "time": 23117.16180562973, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 735776, "time": 23119.561913251877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735824, "time": 23121.116277456284, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 735856, "time": 23122.092664957047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 736240, "time": 23133.71583008766, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 736504, "time": 23141.498893499374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 736592, "time": 23144.409809827805, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 736984, "time": 23156.156883001328, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 737048, "time": 23158.100911140442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 737120, "time": 23160.52202153206, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 737408, "time": 23169.733797311783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 737448, "time": 23170.720306396484, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 737496, "time": 23172.17463517189, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 737624, "time": 23176.068825006485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 737640, "time": 23176.562356233597, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 737776, "time": 23181.05304980278, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 738040, "time": 23188.887966632843, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 738176, "time": 23193.205484628677, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 738224, "time": 23194.673162460327, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 738608, "time": 23206.28146958351, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 738776, "time": 23211.168457746506, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 738816, "time": 23212.576296567917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739288, "time": 23226.55942773819, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 739296, "time": 23227.02406978607, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 739440, "time": 23231.355915546417, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 739808, "time": 23242.5369951725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739960, "time": 23246.88791871071, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 740032, "time": 23249.291553258896, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 23250.72568130493, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 740064, "time": 23250.827481985092, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 740064, "time": 23251.2477517128, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 740064, "time": 23252.71422982216, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 740064, "time": 23252.85451078415, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 740064, "time": 23253.098893642426, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 740064, "time": 23253.285781145096, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 740064, "time": 23255.801589012146, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 740088, "time": 23256.31269812584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 740352, "time": 23264.486919879913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 740408, "time": 23265.950425624847, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 740537, "time": 23270.876863241196, "train_stats/mean_log_entropy": 0.100738116184768, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5048311907260574, "train/action_min": 0.0, "train/action_std": 1.5792554100947593, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010173616878716136, "train/actor_opt_grad_steps": 45180.0, "train/actor_opt_loss": -10.648749002769812, "train/adv_mag": 0.841091889054028, "train/adv_max": 0.35863532830233597, "train/adv_mean": 0.0005006568558942196, "train/adv_min": -0.7932716797833419, "train/adv_std": 0.02968552607153334, "train/cont_avg": 0.9953261038557214, "train/cont_loss_mean": 0.016657845344190573, "train/cont_loss_std": 0.23689367089754165, "train/cont_neg_acc": 0.31001145659542795, "train/cont_neg_loss": 2.923231000636718, "train/cont_pos_acc": 0.9998926019194114, "train/cont_pos_loss": 0.0031306138042064002, "train/cont_pred": 0.9954823798208094, "train/cont_rate": 0.9953261038557214, "train/dyn_loss_mean": 1.0000013196053197, "train/dyn_loss_std": 4.2200450199327215e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1302355878536974, "train/extr_critic_critic_opt_grad_steps": 45180.0, "train/extr_critic_critic_opt_loss": 12680.33016071984, "train/extr_critic_mag": 1.1695601014948602, "train/extr_critic_max": 1.1695601014948602, "train/extr_critic_mean": 1.0765731666811662, "train/extr_critic_min": 0.8315988209710192, "train/extr_critic_std": 0.018948097342615995, "train/extr_return_normed_mag": 0.8286577006477621, "train/extr_return_normed_max": 0.3099254636622187, "train/extr_return_normed_mean": 0.03288876558121164, "train/extr_return_normed_min": -0.780616380682039, "train/extr_return_normed_std": 0.0356669219034673, "train/extr_return_rate": 0.9990416154339539, "train/extr_return_raw_mag": 1.3541104965542086, "train/extr_return_raw_max": 1.3541104965542086, "train/extr_return_raw_mean": 1.077073852814252, "train/extr_return_raw_min": 0.2635686522099509, "train/extr_return_raw_std": 0.035666922023936884, "train/extr_reward_mag": 0.36120476355007036, "train/extr_reward_max": 0.36120476355007036, "train/extr_reward_mean": 0.0014475299873961535, "train/extr_reward_min": 8.303134595576804e-09, "train/extr_reward_std": 0.008843409652770752, "train/image_loss_mean": 0.0753822015292609, "train/image_loss_std": 0.09197928228262645, "train/model_loss_mean": 0.7007163828285179, "train/model_loss_std": 0.38964132857115114, "train/model_opt_grad_norm": 21.603796479713857, "train/model_opt_grad_steps": 45136.64179104478, "train/model_opt_loss": 3554.820889449238, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5074.626865671642, "train/policy_entropy_mag": 1.3323932832746364, "train/policy_entropy_max": 1.3323932832746364, "train/policy_entropy_mean": 0.11454708284851331, "train/policy_entropy_min": 0.06468649694130789, "train/policy_entropy_std": 0.14924325449253195, "train/policy_logprob_mag": 6.551080260110732, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11422585343840111, "train/policy_logprob_min": -6.551080260110732, "train/policy_logprob_std": 0.6498647228402284, "train/policy_randomness_mag": 0.6847147387058581, "train/policy_randomness_max": 0.6847147387058581, "train/policy_randomness_mean": 0.05886555904179663, "train/policy_randomness_min": 0.033242284065455346, "train/policy_randomness_std": 0.07669586603024706, "train/post_ent_mag": 33.60149003973055, "train/post_ent_max": 33.60149003973055, "train/post_ent_mean": 33.28301168792876, "train/post_ent_min": 33.07007642527718, "train/post_ent_std": 0.11265288682571098, "train/prior_ent_mag": 34.0378652354378, "train/prior_ent_max": 34.0378652354378, "train/prior_ent_mean": 32.67943923153094, "train/prior_ent_min": 31.462454999857282, "train/prior_ent_std": 0.37813337124995333, "train/rep_loss_mean": 1.0000013196053197, "train/rep_loss_std": 4.2200450199327215e-05, "train/reward_avg": 0.0011753063288109553, "train/reward_loss_mean": 0.008675524561239675, "train/reward_loss_std": 0.16418347658649718, "train/reward_max_data": 0.658146766065365, "train/reward_max_pred": 0.21275722328110122, "train/reward_neg_acc": 0.9997372514572903, "train/reward_neg_loss": 0.0014752009223256983, "train/reward_pos_acc": 0.21730249078774994, "train/reward_pos_loss": 4.14783606136387, "train/reward_pred": 0.0009351920814888172, "train/reward_rate": 0.001744208644278607, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.02014206163585186, "report/cont_loss_std": 0.2824935019016266, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 3.0077972412109375, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0025330944918096066, "report/cont_pred": 0.9955418705940247, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07482985407114029, "report/image_loss_std": 0.0925733894109726, "report/model_loss_mean": 0.7062779664993286, "report/model_loss_std": 0.4931994378566742, "report/post_ent_mag": 34.331878662109375, "report/post_ent_max": 34.331878662109375, "report/post_ent_mean": 34.027687072753906, "report/post_ent_min": 33.78975296020508, "report/post_ent_std": 0.13110283017158508, "report/prior_ent_mag": 34.17243957519531, "report/prior_ent_max": 34.17243957519531, "report/prior_ent_mean": 33.22627639770508, "report/prior_ent_min": 31.809036254882812, "report/prior_ent_std": 0.4002310335636139, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014739990001544356, "report/reward_loss_mean": 0.011305997148156166, "report/reward_loss_std": 0.24172520637512207, "report/reward_max_data": 0.840624988079071, "report/reward_max_pred": 0.026496052742004395, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0006157647585496306, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.4740142822265625, "report/reward_pred": 0.0003329013707116246, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.014860937371850014, "eval/cont_loss_std": 0.39262786507606506, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.570316314697266, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0025877654552459717, "eval/cont_pred": 0.9974480867385864, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08731836080551147, "eval/image_loss_std": 0.11169007420539856, "eval/model_loss_mean": 0.7153642177581787, "eval/model_loss_std": 0.8083265423774719, "eval/post_ent_mag": 34.324623107910156, "eval/post_ent_max": 34.324623107910156, "eval/post_ent_mean": 33.985511779785156, "eval/post_ent_min": 33.763023376464844, "eval/post_ent_std": 0.11821620911359787, "eval/prior_ent_mag": 34.17243957519531, "eval/prior_ent_max": 34.17243957519531, "eval/prior_ent_mean": 33.218746185302734, "eval/prior_ent_min": 31.6414852142334, "eval/prior_ent_std": 0.37283724546432495, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007690429920330644, "eval/reward_loss_mean": 0.013184932060539722, "eval/reward_loss_std": 0.3932267427444458, "eval/reward_max_data": 0.7875000238418579, "eval/reward_max_pred": 0.09266221523284912, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0008948180475272238, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.58597183227539, "eval/reward_pred": 0.00039548054337501526, "eval/reward_rate": 0.0009765625, "replay/size": 740033.0, "replay/inserts": 32192.0, "replay/samples": 32192.0, "replay/insert_wait_avg": 1.2703610224941853e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.753343752790872e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8656.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1077264320387638e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1487398147583, "timer/env.step_count": 4024.0, "timer/env.step_total": 37.96464014053345, "timer/env.step_frac": 0.03795899412677862, "timer/env.step_avg": 0.00943455271882044, "timer/env.step_min": 0.0076105594635009766, "timer/env.step_max": 0.03506016731262207, "timer/replay._sample_count": 32192.0, "timer/replay._sample_total": 16.734121322631836, "timer/replay._sample_frac": 0.016731632662688983, "timer/replay._sample_avg": 0.0005198223571891102, "timer/replay._sample_min": 0.0003974437713623047, "timer/replay._sample_max": 0.03133869171142578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5106.0, "timer/agent.policy_total": 52.86057901382446, "timer/agent.policy_frac": 0.052852717710382746, "timer/agent.policy_avg": 0.010352639838195156, "timer/agent.policy_min": 0.008295059204101562, "timer/agent.policy_max": 0.10292792320251465, "timer/dataset_train_count": 2012.0, "timer/dataset_train_total": 0.21663188934326172, "timer/dataset_train_frac": 0.00021659967234811996, "timer/dataset_train_avg": 0.00010766992512090542, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0010800361633300781, "timer/agent.train_count": 2012.0, "timer/agent.train_total": 893.449551820755, "timer/agent.train_frac": 0.8933166800632419, "timer/agent.train_avg": 0.4440604134297987, "timer/agent.train_min": 0.4315056800842285, "timer/agent.train_max": 0.6631598472595215, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47464632987976074, "timer/agent.report_frac": 0.00047457574157187056, "timer/agent.report_avg": 0.23732316493988037, "timer/agent.report_min": 0.23023033142089844, "timer/agent.report_max": 0.2444159984588623, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.812920840073755e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 32.18663235103036}
{"step": 741128, "time": 23288.49230480194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741600, "time": 23303.005339622498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741608, "time": 23303.034695148468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741928, "time": 23312.709180355072, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 742272, "time": 23323.308133363724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742296, "time": 23323.824603557587, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 742344, "time": 23325.308186531067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742400, "time": 23327.250128269196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742592, "time": 23333.109142780304, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 742664, "time": 23335.047664165497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742720, "time": 23336.96073269844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742880, "time": 23341.75902032852, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 743376, "time": 23356.688586950302, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 743664, "time": 23365.49541902542, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 744256, "time": 23383.48030948639, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 744528, "time": 23391.802422761917, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 744584, "time": 23393.273122549057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744608, "time": 23394.239906311035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744656, "time": 23395.682817935944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744728, "time": 23397.629070281982, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 744976, "time": 23405.3412566185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745192, "time": 23411.64181804657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745304, "time": 23415.034846544266, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 745320, "time": 23415.519098758698, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 745520, "time": 23422.26677083969, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 745632, "time": 23425.646989822388, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 745688, "time": 23427.119194746017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746400, "time": 23448.75653409958, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 746416, "time": 23449.239993333817, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 746536, "time": 23452.73445057869, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 746840, "time": 23461.895474910736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746968, "time": 23465.750335216522, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 746968, "time": 23465.759679317474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747040, "time": 23468.16260576248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747632, "time": 23486.049577474594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748584, "time": 23514.481020450592, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 748712, "time": 23518.33199453354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748728, "time": 23518.821140050888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748848, "time": 23522.67846083641, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 749056, "time": 23529.01455640793, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 749152, "time": 23531.911031246185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 749280, "time": 23535.772471427917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 749280, "time": 23535.7821290493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 749352, "time": 23537.741595745087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 749360, "time": 23538.209749937057, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 749536, "time": 23543.580726623535, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 749808, "time": 23551.768099069595, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 23559.539759874344, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 750048, "time": 23560.530591487885, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 750048, "time": 23561.141897201538, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 750048, "time": 23561.393203020096, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 750048, "time": 23561.399451732635, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 750048, "time": 23561.450258731842, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 750048, "time": 23564.23502254486, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 750048, "time": 23564.84223842621, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 750088, "time": 23565.8342397213, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 750552, "time": 23579.935049533844, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 750552, "time": 23579.94249367714, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 751040, "time": 23594.910015821457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751088, "time": 23596.36034321785, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 751224, "time": 23600.28217101097, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 751464, "time": 23607.54973077774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751592, "time": 23611.402987480164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751592, "time": 23611.411863088608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751776, "time": 23617.189613819122, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 751848, "time": 23619.17212986946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751984, "time": 23623.50082707405, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 752624, "time": 23642.92596054077, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 752728, "time": 23645.837779283524, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 752928, "time": 23652.0947971344, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 752976, "time": 23653.528623104095, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 753336, "time": 23664.224752426147, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 753400, "time": 23666.21575808525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753536, "time": 23670.56245326996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753896, "time": 23681.626021385193, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 754088, "time": 23687.39562177658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 754160, "time": 23689.767224550247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 754480, "time": 23699.45613217354, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 754560, "time": 23701.86226940155, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 754792, "time": 23708.585363149643, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 754816, "time": 23709.527770757675, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 755024, "time": 23715.81188225746, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 755496, "time": 23729.911333322525, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 755648, "time": 23734.719434022903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755656, "time": 23734.75704932213, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 756184, "time": 23750.903764247894, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 756208, "time": 23751.855754375458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 756296, "time": 23754.305332660675, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 756792, "time": 23769.256828069687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 756848, "time": 23771.14963245392, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 756872, "time": 23771.65277314186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 756888, "time": 23772.136882781982, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 757104, "time": 23778.879645824432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757128, "time": 23779.383969068527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757232, "time": 23782.82133078575, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 757616, "time": 23794.375842809677, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 757952, "time": 23804.481177330017, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 758496, "time": 23820.981434822083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759056, "time": 23837.963685035706, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 759104, "time": 23839.416204452515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759160, "time": 23841.014808416367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759200, "time": 23842.44465327263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759416, "time": 23848.77370119095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759544, "time": 23852.63334918022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759672, "time": 23856.50528407097, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 759928, "time": 23864.22599387169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759960, "time": 23865.212150335312, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 23868.47767305374, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 760032, "time": 23868.556794643402, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 760032, "time": 23869.11594390869, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 760032, "time": 23869.209874868393, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 760032, "time": 23869.729519605637, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 760032, "time": 23869.823749780655, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 760032, "time": 23870.139466524124, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 760032, "time": 23871.31468629837, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 760104, "time": 23873.26146173477, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 760256, "time": 23878.0550801754, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 760288, "time": 23879.032806396484, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 760456, "time": 23883.874477386475, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 760704, "time": 23891.57245516777, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 760904, "time": 23897.391583681107, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 760960, "time": 23899.328145742416, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 761104, "time": 23903.797760248184, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 761184, "time": 23906.209250211716, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 761312, "time": 23910.11068558693, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 761336, "time": 23910.625912189484, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 761416, "time": 23913.067234754562, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 761536, "time": 23916.940752983093, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 761720, "time": 23922.330588579178, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 761816, "time": 23925.25579047203, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 761936, "time": 23929.58938574791, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 761984, "time": 23931.119357824326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 762128, "time": 23935.46635913849, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 762240, "time": 23938.841616392136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 762336, "time": 23941.72740960121, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 762408, "time": 23943.689700126648, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 762488, "time": 23946.116840600967, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 762944, "time": 23960.218985557556, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 762976, "time": 23961.27223420143, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 763104, "time": 23965.13123178482, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 763144, "time": 23966.108437776566, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 763456, "time": 23975.701937675476, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 763496, "time": 23976.707762002945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 763544, "time": 23978.150183439255, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 763760, "time": 23984.886589050293, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 763880, "time": 23988.287497758865, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 764032, "time": 23993.194112300873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764136, "time": 23996.126612901688, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 764368, "time": 24003.333752393723, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 764456, "time": 24005.83623957634, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 764552, "time": 24008.72816967964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764800, "time": 24016.44009399414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764920, "time": 24019.860229730606, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 764936, "time": 24020.41880440712, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 764968, "time": 24021.389882564545, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 765240, "time": 24029.607325077057, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 765256, "time": 24030.100221157074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 765400, "time": 24034.46470093727, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 765496, "time": 24037.349853754044, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 765560, "time": 24039.28990006447, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 765808, "time": 24047.007717847824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766160, "time": 24057.791112422943, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 766176, "time": 24058.278420209885, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 766344, "time": 24063.11679458618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767048, "time": 24084.494107961655, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 767136, "time": 24087.36142063141, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 767144, "time": 24087.387957572937, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 767280, "time": 24091.707488059998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767280, "time": 24091.714522361755, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 767552, "time": 24099.93194460869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767568, "time": 24100.416823387146, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 767592, "time": 24100.923616170883, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 767712, "time": 24104.772442102432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767976, "time": 24112.606083869934, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 768232, "time": 24120.306725025177, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 768328, "time": 24123.21598982811, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 768488, "time": 24128.05151462555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769592, "time": 24161.81517791748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769592, "time": 24161.832458257675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769864, "time": 24170.060619592667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769880, "time": 24170.66521334648, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 769904, "time": 24171.615829229355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 24175.906836032867, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 770016, "time": 24176.186902999878, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 770016, "time": 24176.62603211403, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 770016, "time": 24177.936341762543, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 770016, "time": 24179.181582689285, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 770016, "time": 24180.3371758461, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 24180.347136974335, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 24180.35882282257, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 24180.36761856079, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 24180.37766623497, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770024, "time": 24180.407767534256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 770360, "time": 24191.066634655, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 770456, "time": 24193.967116832733, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 770480, "time": 24194.921036720276, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 770544, "time": 24196.87794470787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 770640, "time": 24199.781594514847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 770736, "time": 24202.832918405533, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 770800, "time": 24204.778748750687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 770896, "time": 24207.69310235977, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 770960, "time": 24209.6301984787, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 770960, "time": 24209.636737585068, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 770992, "time": 24210.629649162292, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 771264, "time": 24218.852221012115, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 771408, "time": 24223.21914243698, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 772176, "time": 24246.706785440445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 772216, "time": 24247.702427864075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 772312, "time": 24250.621571540833, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 772376, "time": 24252.549957036972, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 772864, "time": 24267.62181711197, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 772953, "time": 24271.080166339874, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4073236775515703, "train/action_min": 0.0, "train/action_std": 1.5312480926513672, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006971650986858814, "train/actor_opt_grad_steps": 47200.0, "train/actor_opt_loss": -10.034964441665874, "train/adv_mag": 0.7498787612163375, "train/adv_max": 0.263523182845468, "train/adv_mean": -0.0018217405254671321, "train/adv_min": -0.7055330537810114, "train/adv_std": 0.019509154454497576, "train/cont_avg": 0.9951797259852216, "train/cont_loss_mean": 0.01609028165407589, "train/cont_loss_std": 0.2299612327639399, "train/cont_neg_acc": 0.34081551679732774, "train/cont_neg_loss": 2.692481705817477, "train/cont_pos_acc": 0.9998548174726551, "train/cont_pos_loss": 0.0031634716356053875, "train/cont_pred": 0.99524064251942, "train/cont_rate": 0.9951797259852216, "train/dyn_loss_mean": 1.0000008890781495, "train/dyn_loss_std": 1.7773093348323125e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.07589061266004012, "train/extr_critic_critic_opt_grad_steps": 47200.0, "train/extr_critic_critic_opt_loss": 13053.24478044181, "train/extr_critic_mag": 1.1273842539106096, "train/extr_critic_max": 1.1273842539106096, "train/extr_critic_mean": 1.0373028340598045, "train/extr_critic_min": 0.8307817258271091, "train/extr_critic_std": 0.015564561417794286, "train/extr_return_normed_mag": 0.7611199024275606, "train/extr_return_normed_max": 0.22230260654036046, "train/extr_return_normed_mean": 0.02236328361867904, "train/extr_return_normed_min": -0.7103066350438912, "train/extr_return_normed_std": 0.025164605531235926, "train/extr_return_rate": 0.9995225027864203, "train/extr_return_raw_mag": 1.2354203785581541, "train/extr_return_raw_max": 1.2354203785581541, "train/extr_return_raw_mean": 1.0354811067651646, "train/extr_return_raw_min": 0.30281113682709304, "train/extr_return_raw_std": 0.025164605535823722, "train/extr_reward_mag": 0.3091256477562665, "train/extr_reward_max": 0.3091256477562665, "train/extr_reward_mean": 0.001125933248905254, "train/extr_reward_min": 5.872378795604988e-09, "train/extr_reward_std": 0.006458347036475728, "train/image_loss_mean": 0.07601929597299674, "train/image_loss_std": 0.0936826796000227, "train/model_loss_mean": 0.7013258634529678, "train/model_loss_std": 0.3892142112031946, "train/model_opt_grad_norm": 21.22548380978589, "train/model_opt_grad_steps": 47154.67980295567, "train/model_opt_loss": 3643.640104246844, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5221.674876847291, "train/policy_entropy_mag": 1.299485527235886, "train/policy_entropy_max": 1.299485527235886, "train/policy_entropy_mean": 0.10493729127745323, "train/policy_entropy_min": 0.06468649212215921, "train/policy_entropy_std": 0.13428457481373707, "train/policy_logprob_mag": 6.551080262132466, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10484857295681103, "train/policy_logprob_min": -6.551080262132466, "train/policy_logprob_std": 0.6416553514344352, "train/policy_randomness_mag": 0.6678034974436454, "train/policy_randomness_max": 0.6678034974436454, "train/policy_randomness_mean": 0.05392710284646509, "train/policy_randomness_min": 0.033242281544678315, "train/policy_randomness_std": 0.06900862426373172, "train/post_ent_mag": 33.87011840895479, "train/post_ent_max": 33.87011840895479, "train/post_ent_mean": 33.504657613820044, "train/post_ent_min": 33.25925235090585, "train/post_ent_std": 0.13006310010778493, "train/prior_ent_mag": 34.59305360164549, "train/prior_ent_max": 34.59305360164549, "train/prior_ent_mean": 33.55180745993929, "train/prior_ent_min": 32.395123758926765, "train/prior_ent_std": 0.32434602962632486, "train/rep_loss_mean": 1.0000008890781495, "train/rep_loss_std": 1.7773093348323125e-05, "train/reward_avg": 0.0012914197264368796, "train/reward_loss_mean": 0.009215731029238167, "train/reward_loss_std": 0.16743931904884762, "train/reward_max_data": 0.6417333764836118, "train/reward_max_pred": 0.2206279368236147, "train/reward_neg_acc": 0.9998022952103263, "train/reward_neg_loss": 0.001505625765114619, "train/reward_pos_acc": 0.23295454638586802, "train/reward_pos_loss": 4.032367138022726, "train/reward_pred": 0.000976640465577578, "train/reward_rate": 0.001905018472906404, "train_stats/mean_log_entropy": 0.09646187493124524, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.011134305968880653, "report/cont_loss_std": 0.2080739438533783, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 1.8652889728546143, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0020363943185657263, "report/cont_pred": 0.9951233863830566, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0882917046546936, "report/image_loss_std": 0.10762519389390945, "report/model_loss_mean": 0.7055829763412476, "report/model_loss_std": 0.3481428623199463, "report/post_ent_mag": 35.089622497558594, "report/post_ent_max": 35.089622497558594, "report/post_ent_mean": 34.71478271484375, "report/post_ent_min": 34.474422454833984, "report/post_ent_std": 0.13696400821208954, "report/prior_ent_mag": 35.91530990600586, "report/prior_ent_max": 35.91530990600586, "report/prior_ent_mean": 34.800228118896484, "report/prior_ent_min": 33.26612854003906, "report/prior_ent_std": 0.45922818779945374, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001190185546875, "report/reward_loss_mean": 0.006156942807137966, "report/reward_loss_std": 0.15796415507793427, "report/reward_max_data": 0.784375011920929, "report/reward_max_pred": 0.4256277084350586, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00044050958240404725, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.9272541999816895, "report/reward_pred": 0.000633950112387538, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.06772788614034653, "eval/cont_loss_std": 0.7420516014099121, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.018251419067383, "eval/cont_pos_acc": 0.999015748500824, "eval/cont_pos_loss": 0.005125333089381456, "eval/cont_pred": 0.9956854581832886, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1553928554058075, "eval/image_loss_std": 0.1434512585401535, "eval/model_loss_mean": 0.8452614545822144, "eval/model_loss_std": 0.9758662581443787, "eval/post_ent_mag": 35.087615966796875, "eval/post_ent_max": 35.087615966796875, "eval/post_ent_mean": 34.697540283203125, "eval/post_ent_min": 34.46920394897461, "eval/post_ent_std": 0.1427954137325287, "eval/prior_ent_mag": 35.90616989135742, "eval/prior_ent_max": 35.90616989135742, "eval/prior_ent_mean": 34.7911376953125, "eval/prior_ent_min": 32.99365234375, "eval/prior_ent_std": 0.4605340361595154, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002215576358139515, "eval/reward_loss_mean": 0.022140756249427795, "eval/reward_loss_std": 0.3938712775707245, "eval/reward_max_data": 0.8343750238418579, "eval/reward_max_pred": 0.20785343647003174, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.0011591908987611532, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.162867546081543, "eval/reward_pred": 0.0005283011123538017, "eval/reward_rate": 0.0029296875, "replay/size": 772449.0, "replay/inserts": 32416.0, "replay/samples": 32416.0, "replay/insert_wait_avg": 1.266878190186511e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.752722601782299e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5984.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1867539767913002e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1761617660522, "timer/env.step_count": 4052.0, "timer/env.step_total": 38.33306527137756, "timer/env.step_frac": 0.03832631364028042, "timer/env.step_avg": 0.009460282643479161, "timer/env.step_min": 0.00762486457824707, "timer/env.step_max": 0.03536343574523926, "timer/replay._sample_count": 32416.0, "timer/replay._sample_total": 16.727867126464844, "timer/replay._sample_frac": 0.016724920834873487, "timer/replay._sample_avg": 0.0005160373619960773, "timer/replay._sample_min": 0.00039315223693847656, "timer/replay._sample_max": 0.01096034049987793, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4800.0, "timer/agent.policy_total": 50.1585648059845, "timer/agent.policy_frac": 0.050149730340920594, "timer/agent.policy_avg": 0.01044970100124677, "timer/agent.policy_min": 0.008888959884643555, "timer/agent.policy_max": 0.08634662628173828, "timer/dataset_train_count": 2026.0, "timer/dataset_train_total": 0.22057795524597168, "timer/dataset_train_frac": 0.00022053910468780629, "timer/dataset_train_avg": 0.00010887362055576095, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0010764598846435547, "timer/agent.train_count": 2026.0, "timer/agent.train_total": 898.6838629245758, "timer/agent.train_frac": 0.8985255770720757, "timer/agent.train_avg": 0.4435754506044303, "timer/agent.train_min": 0.43246889114379883, "timer/agent.train_max": 0.6766066551208496, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4854884147644043, "timer/agent.report_frac": 0.0004854029053313542, "timer/agent.report_avg": 0.24274420738220215, "timer/agent.report_min": 0.23559308052062988, "timer/agent.report_max": 0.24989533424377441, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.289596890403749e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 32.40944517413587}
{"step": 773112, "time": 24275.638680696487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773208, "time": 24278.521755456924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773272, "time": 24280.457146167755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773304, "time": 24281.43011879921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773304, "time": 24281.439237594604, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 773576, "time": 24289.658804178238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773840, "time": 24297.981924772263, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 774064, "time": 24304.77344584465, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 774472, "time": 24316.91020822525, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 774688, "time": 24323.732937812805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 774712, "time": 24324.237081050873, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 775112, "time": 24336.247730731964, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 775176, "time": 24338.185596704483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 775424, "time": 24345.84262919426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 775504, "time": 24348.2637321949, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 775520, "time": 24348.753160476685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 775616, "time": 24351.731518745422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 775904, "time": 24360.39395213127, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 775920, "time": 24360.880726337433, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 775936, "time": 24361.366044282913, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 776120, "time": 24366.709137916565, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 776328, "time": 24372.969829797745, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 776376, "time": 24374.40473151207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 776640, "time": 24382.641921043396, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 776864, "time": 24389.388474941254, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 777024, "time": 24394.205180168152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777160, "time": 24398.106742620468, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 777296, "time": 24402.402017593384, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 777488, "time": 24408.163900375366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777696, "time": 24414.463157892227, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 777832, "time": 24418.336896896362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778160, "time": 24428.452848911285, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 778224, "time": 24430.38565993309, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 778232, "time": 24430.414474487305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778248, "time": 24431.13830256462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778352, "time": 24434.766676425934, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 778600, "time": 24442.095659971237, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 778688, "time": 24445.02294754982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778720, "time": 24445.998451709747, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 779184, "time": 24460.112328767776, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 779248, "time": 24462.048764944077, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 779608, "time": 24472.772070407867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 779688, "time": 24475.20420384407, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 779968, "time": 24483.877472162247, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 24485.584040641785, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 780000, "time": 24485.786573648453, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 780000, "time": 24486.10773396492, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 780000, "time": 24486.64043021202, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 780000, "time": 24486.764684438705, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 780000, "time": 24486.80783557892, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 780000, "time": 24487.019988059998, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 780000, "time": 24487.103429317474, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 780472, "time": 24501.130279302597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780560, "time": 24504.01869559288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780664, "time": 24506.929345607758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780848, "time": 24512.68604683876, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 780912, "time": 24514.632559776306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 781032, "time": 24518.008992671967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 781312, "time": 24526.652717590332, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 781496, "time": 24532.06378340721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 781568, "time": 24534.459827661514, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 781792, "time": 24541.190301656723, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 781920, "time": 24546.97166609764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782072, "time": 24551.410124063492, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 782296, "time": 24558.23484492302, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 782368, "time": 24560.747185707092, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 782552, "time": 24566.08754849434, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 782616, "time": 24568.02117204666, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 782728, "time": 24571.4192340374, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 782784, "time": 24573.335099458694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782872, "time": 24575.800850868225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782920, "time": 24577.2593998909, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 783344, "time": 24590.228975057602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 783872, "time": 24606.15767431259, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 784072, "time": 24611.954147577286, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 784320, "time": 24619.62879872322, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 784344, "time": 24620.144902944565, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 784384, "time": 24621.671523571014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784680, "time": 24630.39190554619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784936, "time": 24638.1114423275, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 785096, "time": 24642.911700725555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 785264, "time": 24648.1769592762, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 785504, "time": 24655.462554454803, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 785656, "time": 24659.82643699646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 785816, "time": 24664.67289018631, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 785976, "time": 24669.50696206093, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 786440, "time": 24683.783255577087, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 786632, "time": 24689.811930179596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 786656, "time": 24690.761028766632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 786888, "time": 24697.5090880394, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 786928, "time": 24698.932673692703, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 786992, "time": 24700.88428592682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 787376, "time": 24712.54181933403, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 787576, "time": 24718.355364084244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 787912, "time": 24728.478977441788, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 788008, "time": 24731.37096619606, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 788080, "time": 24733.747246980667, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 788288, "time": 24740.017073869705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 788288, "time": 24740.025030612946, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 788312, "time": 24740.628952503204, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 788832, "time": 24756.50255203247, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 788944, "time": 24759.915685892105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 789144, "time": 24765.71436214447, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 789224, "time": 24768.121123075485, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 789240, "time": 24768.625393629074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 789304, "time": 24770.62739276886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 789384, "time": 24773.018933534622, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 789584, "time": 24779.26898574829, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 24794.966512203217, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 790088, "time": 24795.435165166855, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 790088, "time": 24795.52366542816, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 790088, "time": 24796.61719584465, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 790088, "time": 24798.113230466843, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 790088, "time": 24798.977174043655, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 790088, "time": 24799.963138580322, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 24799.9704079628, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 24799.977695465088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790224, "time": 24804.441470384598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 790480, "time": 24812.172539711, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 790784, "time": 24821.338138103485, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 791256, "time": 24835.412225484848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791456, "time": 24841.644268989563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791552, "time": 24844.55295085907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791616, "time": 24846.493906259537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791896, "time": 24854.708181381226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 792448, "time": 24871.665847063065, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 792536, "time": 24874.08929657936, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 792536, "time": 24874.0980656147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 792792, "time": 24881.845155000687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 793480, "time": 24902.648625850677, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 793568, "time": 24905.529087543488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 793664, "time": 24908.415998458862, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 793864, "time": 24914.219239234924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794208, "time": 24924.926659584045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794496, "time": 24933.58625483513, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 794760, "time": 24941.777299404144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794848, "time": 24944.65895986557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794896, "time": 24946.109650611877, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 795000, "time": 24949.04537844658, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 795104, "time": 24952.5222158432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 795480, "time": 24963.715269327164, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 795792, "time": 24973.377825021744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 795880, "time": 24975.803170681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 795944, "time": 24977.725469589233, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 796128, "time": 24983.580941915512, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 796272, "time": 24987.901027202606, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 796608, "time": 24997.998228549957, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 797096, "time": 25012.52468442917, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 797160, "time": 25014.45616364479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797192, "time": 25015.42213845253, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 797208, "time": 25015.907408714294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797440, "time": 25023.119106054306, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 797480, "time": 25024.106353759766, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 797792, "time": 25033.73105096817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797816, "time": 25034.236664295197, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 797880, "time": 25036.208435297012, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 797888, "time": 25036.679344415665, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 797968, "time": 25039.12344813347, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 798192, "time": 25045.94165277481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 798248, "time": 25047.403295993805, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 798640, "time": 25059.40928220749, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 798960, "time": 25069.009234666824, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 799120, "time": 25073.9278986454, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 799640, "time": 25089.332639932632, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 799792, "time": 25094.120965003967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 799912, "time": 25097.49644589424, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 25103.439234018326, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 800072, "time": 25103.990587949753, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 800072, "time": 25105.157400608063, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 800072, "time": 25105.313684225082, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 800072, "time": 25105.520783662796, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 800072, "time": 25106.58104133606, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 800072, "time": 25107.574862718582, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 800072, "time": 25108.453431367874, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 25108.46180343628, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 25108.467997074127, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 25108.475226402283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800128, "time": 25110.39774608612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 800192, "time": 25112.317576885223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 800200, "time": 25112.34555721283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 800280, "time": 25114.757536888123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 800408, "time": 25118.588396787643, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 800504, "time": 25121.474029302597, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 800568, "time": 25123.398851394653, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 800784, "time": 25130.119464874268, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 800944, "time": 25135.026709079742, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 800952, "time": 25135.054528474808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801128, "time": 25140.357652664185, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 801592, "time": 25154.302936553955, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 801600, "time": 25154.76527786255, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 801896, "time": 25163.52242088318, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 801904, "time": 25163.987289905548, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 802104, "time": 25169.779950857162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802648, "time": 25186.137196540833, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 802656, "time": 25186.59811067581, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 802656, "time": 25186.60696864128, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 802720, "time": 25188.545931577682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802816, "time": 25191.68225002289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802880, "time": 25193.968503713608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 803216, "time": 25204.077651500702, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 803264, "time": 25205.521932840347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 803592, "time": 25215.138288259506, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 803816, "time": 25221.965932369232, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 804032, "time": 25228.67593574524, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 804216, "time": 25233.984659194946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804664, "time": 25247.397424459457, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 804960, "time": 25256.59206008911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804968, "time": 25256.619784593582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 805032, "time": 25258.53930926323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 805128, "time": 25261.43543124199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 805312, "time": 25267.19608259201, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 805417, "time": 25271.094324827194, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4838942353948585, "train/action_min": 0.0, "train/action_std": 1.562660384060714, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00884435812511431, "train/actor_opt_grad_steps": 49230.0, "train/actor_opt_loss": -9.981170164540483, "train/adv_mag": 0.7529107995808418, "train/adv_max": 0.322624834300262, "train/adv_mean": 0.0007116775718016811, "train/adv_min": -0.7099317737988063, "train/adv_std": 0.023864890136778942, "train/cont_avg": 0.9953384775246306, "train/cont_loss_mean": 0.016315126370666136, "train/cont_loss_std": 0.22807629132331372, "train/cont_neg_acc": 0.33482130147113004, "train/cont_neg_loss": 2.7333885912870612, "train/cont_pos_acc": 0.9998549948184948, "train/cont_pos_loss": 0.003298687959649586, "train/cont_pred": 0.9953587836232679, "train/cont_rate": 0.9953384775246306, "train/dyn_loss_mean": 1.0000001885033594, "train/dyn_loss_std": 6.029913385439976e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12204784205816503, "train/extr_critic_critic_opt_grad_steps": 49230.0, "train/extr_critic_critic_opt_loss": 13353.5843403633, "train/extr_critic_mag": 1.1425708526460996, "train/extr_critic_max": 1.1425708526460996, "train/extr_critic_mean": 1.0280748432492974, "train/extr_critic_min": 0.7911187698101175, "train/extr_critic_std": 0.018814726140845586, "train/extr_return_normed_mag": 0.7554006967051276, "train/extr_return_normed_max": 0.30382340911573963, "train/extr_return_normed_mean": 0.03421330358374295, "train/extr_return_normed_min": -0.7093861672678604, "train/extr_return_normed_std": 0.030971009142036213, "train/extr_return_rate": 0.9993804293900288, "train/extr_return_raw_mag": 1.2983965163160427, "train/extr_return_raw_max": 1.2983965163160427, "train/extr_return_raw_mean": 1.0287864645713656, "train/extr_return_raw_min": 0.28518693993244265, "train/extr_return_raw_std": 0.030971009109921642, "train/extr_reward_mag": 0.3498366830384203, "train/extr_reward_max": 0.3498366830384203, "train/extr_reward_mean": 0.0014727419615594734, "train/extr_reward_min": 1.1744757591209976e-08, "train/extr_reward_std": 0.008115567683283552, "train/image_loss_mean": 0.07404627491320882, "train/image_loss_std": 0.09231226392127023, "train/model_loss_mean": 0.6995126798822375, "train/model_loss_std": 0.3843997252985762, "train/model_opt_grad_norm": 21.357305648878878, "train/model_opt_grad_steps": 49182.704433497536, "train/model_opt_loss": 3531.382541900785, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5049.261083743842, "train/policy_entropy_mag": 1.3226239833925746, "train/policy_entropy_max": 1.3226239833925746, "train/policy_entropy_mean": 0.10438224027309512, "train/policy_entropy_min": 0.0646864927093971, "train/policy_entropy_std": 0.13360906862126196, "train/policy_logprob_mag": 6.551080257434563, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10404248018129705, "train/policy_logprob_min": -6.551080257434563, "train/policy_logprob_std": 0.6403402057774549, "train/policy_randomness_mag": 0.6796943151892112, "train/policy_randomness_max": 0.6796943151892112, "train/policy_randomness_mean": 0.05364186302047645, "train/policy_randomness_min": 0.033242281838297257, "train/policy_randomness_std": 0.06866148272024587, "train/post_ent_mag": 34.94614166109433, "train/post_ent_max": 34.94614166109433, "train/post_ent_mean": 34.58352971194413, "train/post_ent_min": 34.32878802445134, "train/post_ent_std": 0.13418744695304063, "train/prior_ent_mag": 35.896223885672434, "train/prior_ent_max": 35.896223885672434, "train/prior_ent_mean": 34.80914513348359, "train/prior_ent_min": 33.13260321781553, "train/prior_ent_std": 0.4369244942524163, "train/rep_loss_mean": 1.0000001885033594, "train/rep_loss_std": 6.029913385439976e-06, "train/reward_avg": 0.0012543927294272686, "train/reward_loss_mean": 0.009151138850428127, "train/reward_loss_std": 0.16253951011945866, "train/reward_max_data": 0.635791257794561, "train/reward_max_pred": 0.18227629825986666, "train/reward_neg_acc": 0.9997204436457215, "train/reward_neg_loss": 0.0016061973387003863, "train/reward_pos_acc": 0.19854651278881139, "train/reward_pos_loss": 4.0057427155417065, "train/reward_pred": 0.0009832300625401986, "train/reward_rate": 0.0018713439039408867, "train_stats/mean_log_entropy": 0.08531190695169845, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.013161489740014076, "report/cont_loss_std": 0.23972776532173157, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.343475341796875, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0017271721735596657, "report/cont_pred": 0.9960575103759766, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08557441085577011, "report/image_loss_std": 0.10100474953651428, "report/model_loss_mean": 0.7144392728805542, "report/model_loss_std": 0.5883521437644958, "report/post_ent_mag": 34.9155387878418, "report/post_ent_max": 34.9155387878418, "report/post_ent_mean": 34.57084655761719, "report/post_ent_min": 34.32353591918945, "report/post_ent_std": 0.13058821856975555, "report/prior_ent_mag": 35.791542053222656, "report/prior_ent_max": 35.791542053222656, "report/prior_ent_mean": 34.86492156982422, "report/prior_ent_min": 33.03203201293945, "report/prior_ent_std": 0.4132552146911621, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0026306151412427425, "report/reward_loss_mean": 0.0157033558934927, "report/reward_loss_std": 0.3259497880935669, "report/reward_max_data": 0.9437500238418579, "report/reward_max_pred": 0.7902810573577881, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0010713405208662152, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 4.995466232299805, "report/reward_pred": 0.001344800926744938, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.04741569608449936, "eval/cont_loss_std": 0.5532652735710144, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.33147668838501, "eval/cont_pos_acc": 0.9990166425704956, "eval/cont_pos_loss": 0.004162575118243694, "eval/cont_pred": 0.997029185295105, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10653403401374817, "eval/image_loss_std": 0.11437572538852692, "eval/model_loss_mean": 0.7669733762741089, "eval/model_loss_std": 0.7182585000991821, "eval/post_ent_mag": 34.91368865966797, "eval/post_ent_max": 34.91368865966797, "eval/post_ent_mean": 34.56422424316406, "eval/post_ent_min": 34.306602478027344, "eval/post_ent_std": 0.13714690506458282, "eval/prior_ent_mag": 35.817691802978516, "eval/prior_ent_max": 35.817691802978516, "eval/prior_ent_mean": 34.83641815185547, "eval/prior_ent_min": 33.130287170410156, "eval/prior_ent_std": 0.4048171043395996, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.001251220703125, "eval/reward_loss_mean": 0.01302359439432621, "eval/reward_loss_std": 0.27282610535621643, "eval/reward_max_data": 0.6468750238418579, "eval/reward_max_pred": 0.04702436923980713, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011316591408103704, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.0898027420043945, "eval/reward_pred": 0.0005882530240342021, "eval/reward_rate": 0.001953125, "replay/size": 804913.0, "replay/inserts": 32464.0, "replay/samples": 32464.0, "replay/insert_wait_avg": 1.3005357472517033e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.765421789817002e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5536.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1248654023760317e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0003418922424, "timer/env.step_count": 4058.0, "timer/env.step_total": 38.30314517021179, "timer/env.step_frac": 0.038303132074668074, "timer/env.step_avg": 0.009438921924645587, "timer/env.step_min": 0.007589101791381836, "timer/env.step_max": 0.04855179786682129, "timer/replay._sample_count": 32464.0, "timer/replay._sample_total": 16.570725679397583, "timer/replay._sample_frac": 0.01657072001399696, "timer/replay._sample_avg": 0.0005104338861322568, "timer/replay._sample_min": 0.0003991127014160156, "timer/replay._sample_max": 0.01139521598815918, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4750.0, "timer/agent.policy_total": 49.31455659866333, "timer/agent.policy_frac": 0.04931453973840475, "timer/agent.policy_avg": 0.010382011915508069, "timer/agent.policy_min": 0.008556365966796875, "timer/agent.policy_max": 0.09067535400390625, "timer/dataset_train_count": 2029.0, "timer/dataset_train_total": 0.21898245811462402, "timer/dataset_train_frac": 0.00021898238324624596, "timer/dataset_train_avg": 0.00010792629774008084, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0005133152008056641, "timer/agent.train_count": 2029.0, "timer/agent.train_total": 899.7028329372406, "timer/agent.train_frac": 0.8997025253359267, "timer/agent.train_avg": 0.4434218003633517, "timer/agent.train_min": 0.4297444820404053, "timer/agent.train_max": 2.3651797771453857, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47605133056640625, "timer/agent.report_frac": 0.00047605116780820495, "timer/agent.report_avg": 0.23802566528320312, "timer/agent.report_min": 0.2309255599975586, "timer/agent.report_max": 0.24512577056884766, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7418127222634688e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 32.46343662914625}
{"step": 805712, "time": 25279.962901830673, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 805784, "time": 25282.049127340317, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 805904, "time": 25285.895412683487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 806128, "time": 25292.624896764755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 806176, "time": 25294.077196121216, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 806208, "time": 25295.05840444565, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 806304, "time": 25297.937760829926, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 806360, "time": 25299.41505074501, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 806720, "time": 25310.5606405735, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 806856, "time": 25314.45741057396, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 806976, "time": 25318.272569179535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 807224, "time": 25325.570241451263, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 807272, "time": 25327.018731594086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 807280, "time": 25327.48962521553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 807768, "time": 25342.06391119957, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 808056, "time": 25350.7854616642, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 808520, "time": 25364.79430246353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808616, "time": 25367.70227742195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808672, "time": 25369.611828565598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809032, "time": 25380.308114528656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809168, "time": 25384.657523870468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809192, "time": 25385.166451215744, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 809400, "time": 25391.43657684326, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 809600, "time": 25397.649809598923, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 809880, "time": 25405.97035050392, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 809936, "time": 25407.877864599228, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 25412.487221717834, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 810056, "time": 25413.820306777954, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 810056, "time": 25414.154502391815, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 810056, "time": 25414.59865951538, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 810056, "time": 25414.67906999588, "eval_episode/length": 179.0, "eval_episode/score": 0.44062501192092896, "eval_episode/reward_rate": 0.005555555555555556}
{"step": 810056, "time": 25414.704131364822, "eval_episode/length": 180.0, "eval_episode/score": 0.4375, "eval_episode/reward_rate": 0.0055248618784530384}
{"step": 810056, "time": 25414.912214756012, "eval_episode/length": 191.0, "eval_episode/score": 0.40312498807907104, "eval_episode/reward_rate": 0.005208333333333333}
{"step": 810056, "time": 25414.992193222046, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 810080, "time": 25415.934418439865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 810288, "time": 25422.181721925735, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 810320, "time": 25423.13754749298, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 810440, "time": 25426.51326775551, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 810528, "time": 25429.38325715065, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 810736, "time": 25435.692814588547, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 811024, "time": 25444.876497745514, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 811128, "time": 25447.77916264534, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 811192, "time": 25449.71778202057, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 811200, "time": 25450.186167240143, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 811344, "time": 25454.539771318436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 811992, "time": 25474.11575436592, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 812008, "time": 25474.61785888672, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 812336, "time": 25484.754316568375, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 812600, "time": 25492.593478918076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812792, "time": 25498.38297700882, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 812840, "time": 25499.82282757759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812952, "time": 25503.211455106735, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 813048, "time": 25506.125518083572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813224, "time": 25511.433665513992, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 813272, "time": 25512.898495674133, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 813336, "time": 25514.832458734512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813504, "time": 25520.109010457993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813576, "time": 25522.147261619568, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 813608, "time": 25523.117060899734, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 814112, "time": 25538.5576710701, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 814240, "time": 25542.42766571045, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 814328, "time": 25544.844618558884, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 814584, "time": 25552.704910755157, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 814712, "time": 25556.56955766678, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 814800, "time": 25559.454877853394, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 814912, "time": 25562.840713500977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 815016, "time": 25565.788334846497, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 815120, "time": 25569.14820933342, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 815152, "time": 25570.135100364685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 815320, "time": 25574.97942352295, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 815328, "time": 25575.445729732513, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 815648, "time": 25585.191769838333, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 815888, "time": 25592.439014673233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 815920, "time": 25593.40853381157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 816320, "time": 25605.46013903618, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 816328, "time": 25605.48682451248, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 816440, "time": 25608.868013620377, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 816496, "time": 25610.849905967712, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 817008, "time": 25626.321353912354, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 817048, "time": 25627.31321144104, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 817224, "time": 25632.630926132202, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 817224, "time": 25632.642741203308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817256, "time": 25633.62804365158, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 817328, "time": 25636.00988292694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817344, "time": 25636.49436855316, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 817632, "time": 25645.230367660522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817656, "time": 25645.740087509155, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 817936, "time": 25654.40162205696, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 818200, "time": 25662.137358665466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 818232, "time": 25663.119226932526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 818472, "time": 25670.43175625801, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 818600, "time": 25674.298634290695, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 818992, "time": 25686.323315143585, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 819176, "time": 25691.652852773666, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 819536, "time": 25703.21891260147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819536, "time": 25703.22615623474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819568, "time": 25704.18949198723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819640, "time": 25706.14725112915, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 819888, "time": 25713.81730747223, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 819952, "time": 25715.760515213013, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 819968, "time": 25716.2472717762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 25719.431713581085, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 820040, "time": 25719.725422143936, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 820040, "time": 25719.732450962067, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 820040, "time": 25719.97077345848, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 820040, "time": 25721.2349691391, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 820040, "time": 25723.414542913437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 25723.422026395798, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 25723.430204868317, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 25723.43798851967, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820152, "time": 25726.828085660934, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 820208, "time": 25728.74308514595, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 820528, "time": 25738.481417417526, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 820544, "time": 25738.96598958969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820576, "time": 25739.929179430008, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 820736, "time": 25744.746749401093, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 820784, "time": 25746.212301015854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 821064, "time": 25754.373450756073, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 821224, "time": 25759.19500875473, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 821304, "time": 25761.73336648941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 821496, "time": 25767.550280570984, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 822136, "time": 25786.84921336174, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 822176, "time": 25788.273233652115, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 822264, "time": 25790.80574655533, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 822280, "time": 25791.288154363632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822520, "time": 25798.526801109314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822792, "time": 25806.6940844059, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 822888, "time": 25809.590052366257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823048, "time": 25814.407263040543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823112, "time": 25816.332267045975, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 823240, "time": 25820.224732637405, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 823616, "time": 25831.824066877365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823688, "time": 25833.786173582077, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 823776, "time": 25836.641592264175, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 823952, "time": 25841.95188307762, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 823976, "time": 25842.452651023865, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 824520, "time": 25858.860387563705, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 824592, "time": 25861.257900714874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825104, "time": 25876.638852119446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825200, "time": 25879.509694099426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825360, "time": 25884.448961496353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825584, "time": 25891.21005010605, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 825648, "time": 25893.138830423355, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 825744, "time": 25896.03125858307, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 825928, "time": 25901.340092420578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 826088, "time": 25906.149868011475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 826096, "time": 25906.61431145668, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 826264, "time": 25911.567361354828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 826568, "time": 25920.723378658295, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 826624, "time": 25922.626125097275, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 826848, "time": 25929.391933441162, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 826904, "time": 25930.856927394867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827032, "time": 25934.69762134552, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 827136, "time": 25938.02523469925, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 827576, "time": 25951.6298289299, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 827896, "time": 25961.258937358856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827960, "time": 25963.209745645523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 828056, "time": 25966.0989010334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 828272, "time": 25972.984332084656, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 828400, "time": 25976.818132400513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 828536, "time": 25980.706753969193, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 829088, "time": 25997.581145763397, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 829160, "time": 25999.528839349747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829344, "time": 26005.434095144272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829448, "time": 26008.377016305923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829856, "time": 26020.868318796158, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 830008, "time": 26025.201858758926, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 26027.03917980194, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 830024, "time": 26027.20741701126, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 830024, "time": 26027.327884435654, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 830024, "time": 26028.252321720123, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 830024, "time": 26028.294709444046, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 830024, "time": 26028.391421318054, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 830024, "time": 26028.83400964737, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 830024, "time": 26028.856982707977, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 830128, "time": 26032.279923915863, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 830424, "time": 26040.95551466942, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 830488, "time": 26042.87460064888, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 830584, "time": 26045.784429311752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 830712, "time": 26049.635976791382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 830872, "time": 26054.441262722015, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 831200, "time": 26064.753643751144, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 831408, "time": 26071.025923490524, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 831472, "time": 26072.960597753525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831656, "time": 26078.281849384308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831760, "time": 26081.63688826561, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 832048, "time": 26090.45954966545, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 832088, "time": 26091.443459272385, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 832256, "time": 26096.697951316833, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 832264, "time": 26096.724450349808, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 832320, "time": 26098.634596586227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832440, "time": 26102.03210568428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832520, "time": 26104.447978258133, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 832736, "time": 26111.15349173546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832752, "time": 26111.655388116837, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 832848, "time": 26114.52742934227, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 833336, "time": 26129.014768123627, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 833392, "time": 26130.951163053513, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 833504, "time": 26134.332750558853, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 833784, "time": 26142.56072831154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 833880, "time": 26145.474986314774, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 833920, "time": 26146.901111364365, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 834232, "time": 26156.12419629097, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 834400, "time": 26161.37922668457, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 834432, "time": 26162.340877771378, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 834752, "time": 26171.963201522827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834832, "time": 26174.379496574402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 835064, "time": 26181.205979585648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 835104, "time": 26182.62438225746, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 835304, "time": 26188.431163311005, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 835696, "time": 26200.92417550087, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 835816, "time": 26204.31575369835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 835912, "time": 26207.1887447834, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 836064, "time": 26212.070011615753, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 836232, "time": 26216.93344116211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 836520, "time": 26225.617521047592, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 836544, "time": 26226.56842803955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 836648, "time": 26229.483411073685, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 836896, "time": 26237.137503385544, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 837224, "time": 26246.862292289734, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 837376, "time": 26251.654352903366, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 837416, "time": 26252.65711593628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 837472, "time": 26254.56026482582, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 837632, "time": 26259.405451774597, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 837993, "time": 26271.1222512722, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.449506787830973, "train/action_min": 0.0, "train/action_std": 1.6137320384603415, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010987397167473812, "train/actor_opt_grad_steps": 51260.0, "train/actor_opt_loss": -11.242282170673896, "train/adv_mag": 0.8131157327168094, "train/adv_max": 0.33766473719639145, "train/adv_mean": 0.001451849522628736, "train/adv_min": -0.7703334060795789, "train/adv_std": 0.030280264144937688, "train/cont_avg": 0.9953288562192119, "train/cont_loss_mean": 0.016606440204493884, "train/cont_loss_std": 0.23702181216898222, "train/cont_neg_acc": 0.32806513998015174, "train/cont_neg_loss": 2.8627021155902757, "train/cont_pos_acc": 0.9998791203123009, "train/cont_pos_loss": 0.0033615175015270123, "train/cont_pred": 0.9951978167289584, "train/cont_rate": 0.9953288562192119, "train/dyn_loss_mean": 1.0000000675323562, "train/dyn_loss_std": 2.163978611242962e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12212312856019278, "train/extr_critic_critic_opt_grad_steps": 51260.0, "train/extr_critic_critic_opt_loss": 13186.897119381158, "train/extr_critic_mag": 1.1988142957828316, "train/extr_critic_max": 1.1988142957828316, "train/extr_critic_mean": 1.0569082445699005, "train/extr_critic_min": 0.88262780487831, "train/extr_critic_std": 0.02167790909779483, "train/extr_return_normed_mag": 0.8166189396322654, "train/extr_return_normed_max": 0.3757851420364944, "train/extr_return_normed_mean": 0.03974919365214303, "train/extr_return_normed_min": -0.7423168532366823, "train/extr_return_normed_std": 0.03820569217755583, "train/extr_return_rate": 0.9991876800072017, "train/extr_return_raw_mag": 1.3943960185121433, "train/extr_return_raw_max": 1.3943960185121433, "train/extr_return_raw_mean": 1.0583601191713305, "train/extr_return_raw_min": 0.2762940232389666, "train/extr_return_raw_std": 0.038205692085799915, "train/extr_reward_mag": 0.397271084080776, "train/extr_reward_max": 0.397271084080776, "train/extr_reward_mean": 0.0017538404260220677, "train/extr_reward_min": -1.5855422748133467e-08, "train/extr_reward_std": 0.010379296309989074, "train/image_loss_mean": 0.07323120626175932, "train/image_loss_std": 0.09245196539046142, "train/model_loss_mean": 0.6989942263499856, "train/model_loss_std": 0.3929896993296487, "train/model_opt_grad_norm": 20.599623038036988, "train/model_opt_grad_steps": 51210.69950738916, "train/model_opt_loss": 3546.735879531635, "train/model_opt_model_opt_grad_overflow": 0.0049261083743842365, "train/model_opt_model_opt_grad_scale": 5049.261083743842, "train/policy_entropy_mag": 1.3224319360526324, "train/policy_entropy_max": 1.3224319360526324, "train/policy_entropy_mean": 0.10673840923849585, "train/policy_entropy_min": 0.06468649219556395, "train/policy_entropy_std": 0.13780857105120062, "train/policy_logprob_mag": 6.551080255085612, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10679070394614647, "train/policy_logprob_min": -6.551080255085612, "train/policy_logprob_std": 0.6437851287461267, "train/policy_randomness_mag": 0.6795956187060314, "train/policy_randomness_max": 0.6795956187060314, "train/policy_randomness_mean": 0.054852693594001196, "train/policy_randomness_min": 0.033242281581380685, "train/policy_randomness_std": 0.07081960059078456, "train/post_ent_mag": 34.831953339976046, "train/post_ent_max": 34.831953339976046, "train/post_ent_mean": 34.47282311951586, "train/post_ent_min": 34.2040124526752, "train/post_ent_std": 0.1363931895403439, "train/prior_ent_mag": 35.8839793651562, "train/prior_ent_max": 35.8839793651562, "train/prior_ent_mean": 34.822462241637886, "train/prior_ent_min": 33.17705190123009, "train/prior_ent_std": 0.41052764800969016, "train/rep_loss_mean": 1.0000000675323562, "train/rep_loss_std": 2.163978611242962e-06, "train/reward_avg": 0.0012468309866423889, "train/reward_loss_mean": 0.009156518096787846, "train/reward_loss_std": 0.1675245053171561, "train/reward_max_data": 0.6593903968927308, "train/reward_max_pred": 0.1992402781406647, "train/reward_neg_acc": 0.9997397288313052, "train/reward_neg_loss": 0.001682588809371692, "train/reward_pos_acc": 0.19363296023580465, "train/reward_pos_loss": 4.1199893288398055, "train/reward_pred": 0.0010273546482817146, "train/reward_rate": 0.0018136160714285715, "train_stats/mean_log_entropy": 0.08278119215863435, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.022858358919620514, "report/cont_loss_std": 0.32997381687164307, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.6147868633270264, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0024494738318026066, "report/cont_pred": 0.9937930107116699, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08230684697628021, "report/image_loss_std": 0.10027345269918442, "report/model_loss_mean": 0.7060902118682861, "report/model_loss_std": 0.34139400720596313, "report/post_ent_mag": 34.72038650512695, "report/post_ent_max": 34.72038650512695, "report/post_ent_mean": 34.387977600097656, "report/post_ent_min": 34.09054946899414, "report/post_ent_std": 0.15530648827552795, "report/prior_ent_mag": 35.81330108642578, "report/prior_ent_max": 35.81330108642578, "report/prior_ent_mean": 34.85486602783203, "report/prior_ent_min": 33.47304153442383, "report/prior_ent_std": 0.4035551846027374, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0009249716531485319, "report/reward_loss_std": 0.005560646764934063, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.051450490951538086, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0009249716531485319, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000454847002401948, "report/reward_rate": 0.0, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.045949965715408325, "eval/cont_loss_std": 0.5710323452949524, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.471031665802002, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0017261982429772615, "eval/cont_pred": 0.9982575178146362, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1213972270488739, "eval/image_loss_std": 0.11916051059961319, "eval/model_loss_mean": 0.7851988077163696, "eval/model_loss_std": 0.7853825688362122, "eval/post_ent_mag": 34.721107482910156, "eval/post_ent_max": 34.721107482910156, "eval/post_ent_mean": 34.347110748291016, "eval/post_ent_min": 34.04148864746094, "eval/post_ent_std": 0.14040932059288025, "eval/prior_ent_mag": 35.67998504638672, "eval/prior_ent_max": 35.67998504638672, "eval/prior_ent_mean": 34.801109313964844, "eval/prior_ent_min": 32.530189514160156, "eval/prior_ent_std": 0.4396654963493347, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0018096923595294356, "eval/reward_loss_mean": 0.017851531505584717, "eval/reward_loss_std": 0.3188851475715637, "eval/reward_max_data": 0.734375, "eval/reward_max_pred": 0.023851990699768066, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0007745885523036122, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.829704284667969, "eval/reward_pred": 0.0004106310661882162, "eval/reward_rate": 0.0029296875, "replay/size": 837489.0, "replay/inserts": 32576.0, "replay/samples": 32576.0, "replay/insert_wait_avg": 1.281207109012866e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.617084239929739e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0729286926777388e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0051336288452, "timer/env.step_count": 4072.0, "timer/env.step_total": 38.9482216835022, "timer/env.step_frac": 0.038948021738814335, "timer/env.step_avg": 0.009564887446832563, "timer/env.step_min": 0.007768154144287109, "timer/env.step_max": 0.05300498008728027, "timer/replay._sample_count": 32576.0, "timer/replay._sample_total": 16.42595410346985, "timer/replay._sample_frac": 0.016425869779150944, "timer/replay._sample_avg": 0.0005042348386379497, "timer/replay._sample_min": 0.00039577484130859375, "timer/replay._sample_max": 0.010981321334838867, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4733.0, "timer/agent.policy_total": 48.672229528427124, "timer/agent.policy_frac": 0.048671979664548365, "timer/agent.policy_avg": 0.010283589589779658, "timer/agent.policy_min": 0.008581876754760742, "timer/agent.policy_max": 0.08308625221252441, "timer/dataset_train_count": 2036.0, "timer/dataset_train_total": 0.21689295768737793, "timer/dataset_train_frac": 0.00021689184424515003, "timer/dataset_train_avg": 0.00010652895760676715, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0004506111145019531, "timer/agent.train_count": 2036.0, "timer/agent.train_total": 900.6236684322357, "timer/agent.train_frac": 0.9006190449883278, "timer/agent.train_avg": 0.44234954245198216, "timer/agent.train_min": 0.43334507942199707, "timer/agent.train_max": 0.6637041568756104, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4753406047821045, "timer/agent.report_frac": 0.00047533816457239164, "timer/agent.report_avg": 0.23767030239105225, "timer/agent.report_min": 0.23022842407226562, "timer/agent.report_max": 0.24511218070983887, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9086917328952806e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 32.57523140763031}
{"step": 838040, "time": 26272.342535972595, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 838128, "time": 26275.215504169464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838376, "time": 26282.504712581635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838720, "time": 26293.12531685829, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 838832, "time": 26296.508449554443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838960, "time": 26300.422845363617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839488, "time": 26316.368514299393, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 839608, "time": 26319.75469136238, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 839632, "time": 26320.720677614212, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 839688, "time": 26322.195523500443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839784, "time": 26325.11397957802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 26332.52767777443, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 840008, "time": 26333.093601942062, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 840008, "time": 26333.68827533722, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 840008, "time": 26333.839864253998, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 840008, "time": 26333.967450380325, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 840008, "time": 26333.99144220352, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 840008, "time": 26334.065301656723, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 840008, "time": 26334.1936917305, "eval_episode/length": 6.0, "eval_episode/score": 0.981249988079071, "eval_episode/reward_rate": 0.14285714285714285}
{"step": 840216, "time": 26340.463329076767, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 840288, "time": 26342.88006424904, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 840440, "time": 26347.275336503983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 840528, "time": 26350.167019605637, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 840624, "time": 26353.07763648033, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 840688, "time": 26355.016310453415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 841032, "time": 26365.225871562958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 841112, "time": 26367.65770483017, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 841120, "time": 26368.132487297058, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 841288, "time": 26373.04014158249, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 841400, "time": 26376.43914246559, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 841712, "time": 26386.053520202637, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 841760, "time": 26387.49634051323, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 841800, "time": 26388.48772239685, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 841944, "time": 26392.910961151123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 841976, "time": 26393.872203826904, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 842352, "time": 26405.427840471268, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 842464, "time": 26408.780462265015, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 842528, "time": 26410.708280563354, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 842728, "time": 26416.490171432495, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 842872, "time": 26420.874519348145, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 842936, "time": 26422.78807592392, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 843000, "time": 26424.728006839752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843024, "time": 26425.666736602783, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 843344, "time": 26435.2630546093, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 843360, "time": 26435.74631214142, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 843424, "time": 26437.669738054276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843912, "time": 26452.709955215454, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 844024, "time": 26456.093834638596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 844616, "time": 26473.902381181717, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 845040, "time": 26486.964592456818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845088, "time": 26488.44048142433, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 845248, "time": 26493.272856473923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845312, "time": 26495.206268310547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845336, "time": 26495.713527202606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845672, "time": 26505.867857456207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845688, "time": 26506.355870962143, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 845896, "time": 26512.727528095245, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 845920, "time": 26513.677884817123, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 845984, "time": 26515.60207438469, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 846128, "time": 26519.953741550446, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 846184, "time": 26521.42088675499, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 846208, "time": 26522.38258075714, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 846224, "time": 26522.86682677269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 846592, "time": 26533.954189538956, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 846672, "time": 26536.386759519577, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 846728, "time": 26537.84401869774, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 846928, "time": 26544.17500948906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 847240, "time": 26553.34589791298, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 847336, "time": 26556.24063849449, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 847360, "time": 26557.19622039795, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 847488, "time": 26561.070606946945, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 847560, "time": 26563.01646733284, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 847968, "time": 26575.653324365616, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 847984, "time": 26576.1452562809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848224, "time": 26583.407123804092, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 848440, "time": 26589.7372610569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848496, "time": 26591.644062757492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848520, "time": 26592.15128993988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848528, "time": 26592.625152349472, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 848904, "time": 26603.780435323715, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 849096, "time": 26609.59507060051, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 849800, "time": 26630.861648082733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 849904, "time": 26634.251105070114, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 26640.788153409958, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 850096, "time": 26641.250010252, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 850096, "time": 26641.653663396835, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 850096, "time": 26641.67924451828, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 850096, "time": 26642.452457666397, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 850096, "time": 26642.742245197296, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 850096, "time": 26642.766451120377, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 850096, "time": 26642.921673059464, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 850216, "time": 26646.33276772499, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 850280, "time": 26648.275468349457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850296, "time": 26648.764340162277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850752, "time": 26662.815385580063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850808, "time": 26664.302468299866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850832, "time": 26665.271736860275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850872, "time": 26666.255829811096, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 850944, "time": 26668.656194210052, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 851216, "time": 26676.824651002884, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 851408, "time": 26682.598853826523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851440, "time": 26683.56004333496, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 851520, "time": 26685.989192724228, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 851584, "time": 26687.921041727066, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 851648, "time": 26689.870748996735, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 851664, "time": 26690.4349694252, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 851936, "time": 26698.60363316536, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 851992, "time": 26700.553980112076, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 852360, "time": 26711.642596960068, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 852568, "time": 26717.95555663109, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 852592, "time": 26718.917165994644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852848, "time": 26726.71361017227, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 852880, "time": 26727.69109916687, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 852944, "time": 26729.65300488472, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 853240, "time": 26738.44075345993, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 853256, "time": 26738.93026638031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 853528, "time": 26747.154387950897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 853608, "time": 26749.594304800034, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 853960, "time": 26760.33355140686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 854248, "time": 26769.12601542473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 854528, "time": 26777.864344596863, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 855192, "time": 26797.795907974243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855256, "time": 26799.73797392845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855552, "time": 26808.98658680916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855568, "time": 26809.473526239395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855840, "time": 26817.854496479034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855888, "time": 26819.30876135826, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 855920, "time": 26820.27844119072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 856232, "time": 26829.496002435684, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 856256, "time": 26830.44398379326, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 856384, "time": 26834.30400276184, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 856560, "time": 26839.630672216415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 856840, "time": 26847.965704202652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 857072, "time": 26855.19763112068, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 857080, "time": 26855.22455883026, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 857120, "time": 26856.652277469635, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 858000, "time": 26883.509664297104, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 858152, "time": 26887.87500977516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858232, "time": 26890.304135084152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858544, "time": 26899.884825468063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858568, "time": 26900.476348638535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 859152, "time": 26918.298819303513, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 859152, "time": 26918.307284355164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 859288, "time": 26922.192688703537, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 859384, "time": 26925.11475777626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 859392, "time": 26925.581899642944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 859776, "time": 26937.247863054276, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 859864, "time": 26939.699858665466, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 26947.564521551132, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 860080, "time": 26947.657035827637, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 860080, "time": 26947.988565683365, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 860080, "time": 26948.04809975624, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 860080, "time": 26948.125570058823, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 860080, "time": 26948.412045955658, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 860080, "time": 26949.08748269081, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 860080, "time": 26949.156512975693, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 860128, "time": 26950.62774205208, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 860208, "time": 26953.517941713333, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 860312, "time": 26956.47388982773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860464, "time": 26961.406108379364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860544, "time": 26963.82054591179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860568, "time": 26964.329960107803, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 860640, "time": 26966.761077404022, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 860776, "time": 26970.707679748535, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 860936, "time": 26975.513740062714, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 860992, "time": 26977.41205763817, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 861336, "time": 26987.493410348892, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 861440, "time": 26990.89403963089, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 861464, "time": 26991.398284196854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 861704, "time": 26998.62051653862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 861904, "time": 27004.929057121277, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 862288, "time": 27016.502426862717, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 862440, "time": 27020.96807527542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862624, "time": 27026.744661092758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862736, "time": 27030.14183807373, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 863008, "time": 27038.321151971817, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 863088, "time": 27040.714690208435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 863304, "time": 27047.02755379677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 863320, "time": 27047.530908823013, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 863472, "time": 27052.41600751877, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 863552, "time": 27054.82103085518, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 863752, "time": 27060.621149778366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 863808, "time": 27062.535385131836, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 863904, "time": 27065.41212439537, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 864312, "time": 27077.470695257187, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 864504, "time": 27083.33697462082, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 864648, "time": 27087.67041873932, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 864680, "time": 27088.640130519867, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 864744, "time": 27090.57517671585, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 864752, "time": 27091.060331344604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 864936, "time": 27096.402316093445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865224, "time": 27105.06526374817, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 865280, "time": 27106.99174976349, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 865392, "time": 27110.44382762909, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 865632, "time": 27117.689241170883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865864, "time": 27124.544459342957, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 865864, "time": 27124.551778316498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865984, "time": 27128.423505067825, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 866472, "time": 27143.037705659866, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 866784, "time": 27152.658292531967, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 866864, "time": 27155.07928419113, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 866992, "time": 27158.956744670868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 867056, "time": 27160.917602062225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 867064, "time": 27160.946367025375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 867248, "time": 27166.713960170746, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 867536, "time": 27175.535760641098, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 867592, "time": 27177.009348630905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 867912, "time": 27186.68036031723, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 868168, "time": 27194.38877749443, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 868176, "time": 27194.856270074844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868784, "time": 27213.95232820511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 869304, "time": 27229.384042024612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 869376, "time": 27231.828731536865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 869640, "time": 27239.586186647415, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 869848, "time": 27245.845029354095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 869904, "time": 27247.771975040436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 27253.259269952774, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 870064, "time": 27254.068878412247, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 870064, "time": 27254.42561507225, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 870064, "time": 27255.776807308197, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 870064, "time": 27257.483164072037, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 870064, "time": 27257.836081027985, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 870064, "time": 27257.951476573944, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 27257.960411310196, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 27257.970398426056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 27257.97958087921, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 27257.98899769783, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 27257.99665427208, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870184, "time": 27261.551340579987, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 870224, "time": 27263.007382154465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870392, "time": 27267.83132815361, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 870432, "time": 27269.25420832634, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 870473, "time": 27271.234736442566, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.460123297028941, "train/action_min": 0.0, "train/action_std": 1.5918731337110397, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008449517713465127, "train/actor_opt_grad_steps": 53290.0, "train/actor_opt_loss": -11.992640687914317, "train/adv_mag": 0.7439963324316616, "train/adv_max": 0.2846029850062478, "train/adv_mean": -0.0005976435954230488, "train/adv_min": -0.7000843042810562, "train/adv_std": 0.023849622089544248, "train/cont_avg": 0.9952470751231527, "train/cont_loss_mean": 0.016291360735544578, "train/cont_loss_std": 0.22690086241747284, "train/cont_neg_acc": 0.3352341329678893, "train/cont_neg_loss": 2.6705898136115866, "train/cont_pos_acc": 0.9998647517758638, "train/cont_pos_loss": 0.003393902147436524, "train/cont_pred": 0.9951702978810654, "train/cont_rate": 0.9952470751231527, "train/dyn_loss_mean": 1.0000708825482523, "train/dyn_loss_std": 0.0022671310847001197, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10203703346070397, "train/extr_critic_critic_opt_grad_steps": 53290.0, "train/extr_critic_critic_opt_loss": 13328.147494612069, "train/extr_critic_mag": 1.1469301214359078, "train/extr_critic_max": 1.1469301214359078, "train/extr_critic_mean": 1.0328959573078624, "train/extr_critic_min": 0.8123280232763056, "train/extr_critic_std": 0.01851453225637598, "train/extr_return_normed_mag": 0.7556677114200122, "train/extr_return_normed_max": 0.28302705493466607, "train/extr_return_normed_mean": 0.030703990364658276, "train/extr_return_normed_min": -0.6977532887693696, "train/extr_return_normed_std": 0.030861009416982457, "train/extr_return_rate": 0.9993342428371824, "train/extr_return_raw_mag": 1.2846213115259932, "train/extr_return_raw_max": 1.2846213115259932, "train/extr_return_raw_mean": 1.0322982953687019, "train/extr_return_raw_min": 0.30384096782195746, "train/extr_return_raw_std": 0.030861009283936376, "train/extr_reward_mag": 0.3052719449762053, "train/extr_reward_max": 0.3052719449762053, "train/extr_reward_mean": 0.0014559914073516876, "train/extr_reward_min": -1.1744757591209976e-09, "train/extr_reward_std": 0.007600477071974445, "train/image_loss_mean": 0.07352115702012489, "train/image_loss_std": 0.09244234573664924, "train/model_loss_mean": 0.6995843155630703, "train/model_loss_std": 0.3936042787296138, "train/model_opt_grad_norm": 20.08687207264266, "train/model_opt_grad_steps": 53238.724137931036, "train/model_opt_loss": 3635.6151008793872, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5221.674876847291, "train/policy_entropy_mag": 1.350867597340363, "train/policy_entropy_max": 1.350867597340363, "train/policy_entropy_mean": 0.11079263988093202, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.14473063425330693, "train/policy_logprob_mag": 6.551080257434563, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11115403293535628, "train/policy_logprob_min": -6.551080257434563, "train/policy_logprob_std": 0.6495337791630788, "train/policy_randomness_mag": 0.694208659855603, "train/policy_randomness_max": 0.694208659855603, "train/policy_randomness_mean": 0.05693615624323267, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0743768372449088, "train/post_ent_mag": 34.62973467822145, "train/post_ent_max": 34.62973467822145, "train/post_ent_mean": 34.26378022743563, "train/post_ent_min": 33.98833897783251, "train/post_ent_std": 0.13979267431744213, "train/prior_ent_mag": 36.139331535752774, "train/prior_ent_max": 36.139331535752774, "train/prior_ent_mean": 34.878432006084275, "train/prior_ent_min": 33.17418636829395, "train/prior_ent_std": 0.42892476740141805, "train/rep_loss_mean": 1.0000708825482523, "train/rep_loss_std": 0.0022671310847001197, "train/reward_avg": 0.0013695928274442813, "train/reward_loss_mean": 0.00972924700403687, "train/reward_loss_std": 0.17177633984528226, "train/reward_max_data": 0.6734144112159466, "train/reward_max_pred": 0.22299982585343234, "train/reward_neg_acc": 0.9996817399715555, "train/reward_neg_loss": 0.0016995945967174149, "train/reward_pos_acc": 0.22199735583530533, "train/reward_pos_loss": 3.9599161066942745, "train/reward_pred": 0.0010672138918998647, "train/reward_rate": 0.001991610221674877, "train_stats/mean_log_entropy": 0.08497681974300317, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.01215931586921215, "report/cont_loss_std": 0.20206229388713837, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 3.0230846405029297, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0033123258035629988, "report/cont_pred": 0.9957485198974609, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05995463579893112, "report/image_loss_std": 0.07390348613262177, "report/model_loss_mean": 0.6794934272766113, "report/model_loss_std": 0.34563297033309937, "report/post_ent_mag": 34.837493896484375, "report/post_ent_max": 34.837493896484375, "report/post_ent_mean": 34.46937561035156, "report/post_ent_min": 34.184913635253906, "report/post_ent_std": 0.13150879740715027, "report/prior_ent_mag": 35.789215087890625, "report/prior_ent_max": 35.789215087890625, "report/prior_ent_mean": 34.792205810546875, "report/prior_ent_min": 32.47663497924805, "report/prior_ent_std": 0.4759213626384735, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0016113281017169356, "report/reward_loss_mean": 0.0073793926276266575, "report/reward_loss_std": 0.16239403188228607, "report/reward_max_data": 0.903124988079071, "report/reward_max_pred": 0.6685999631881714, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0015803661663085222, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.97068190574646, "report/reward_pred": 0.001497840043157339, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.01123836264014244, "eval/cont_loss_std": 0.23879846930503845, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.625487804412842, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0037953024730086327, "eval/cont_pred": 0.9963725805282593, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10338626801967621, "eval/image_loss_std": 0.11420410871505737, "eval/model_loss_mean": 0.7164478302001953, "eval/model_loss_std": 0.26474109292030334, "eval/post_ent_mag": 34.828102111816406, "eval/post_ent_max": 34.828102111816406, "eval/post_ent_mean": 34.47172546386719, "eval/post_ent_min": 34.20509338378906, "eval/post_ent_std": 0.13963757455348969, "eval/prior_ent_mag": 35.71471405029297, "eval/prior_ent_max": 35.71471405029297, "eval/prior_ent_mean": 34.81098175048828, "eval/prior_ent_min": 33.127105712890625, "eval/prior_ent_std": 0.40100014209747314, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0018232283182442188, "eval/reward_loss_std": 0.03039627894759178, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.2699241638183594, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.0018232283182442188, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0007235974771901965, "eval/reward_rate": 0.0, "replay/size": 869969.0, "replay/inserts": 32480.0, "replay/samples": 32480.0, "replay/insert_wait_avg": 1.8800934547273984e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.532793900062298e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5408.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0947944849905883e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.099244594574, "timer/env.step_count": 4060.0, "timer/env.step_total": 38.342371702194214, "timer/env.step_frac": 0.03833856680667494, "timer/env.step_avg": 0.009443933916796604, "timer/env.step_min": 0.0075647830963134766, "timer/env.step_max": 0.06231236457824707, "timer/replay._sample_count": 32480.0, "timer/replay._sample_total": 16.314932107925415, "timer/replay._sample_frac": 0.01631331309978067, "timer/replay._sample_avg": 0.0005023070230272603, "timer/replay._sample_min": 0.00040411949157714844, "timer/replay._sample_max": 0.012985706329345703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4736.0, "timer/agent.policy_total": 48.929118156433105, "timer/agent.policy_frac": 0.04892426268781782, "timer/agent.policy_avg": 0.010331317178300908, "timer/agent.policy_min": 0.008589982986450195, "timer/agent.policy_max": 0.09283208847045898, "timer/dataset_train_count": 2030.0, "timer/dataset_train_total": 0.21347904205322266, "timer/dataset_train_frac": 0.00021345785751469498, "timer/dataset_train_avg": 0.00010516208968139047, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0007369518280029297, "timer/agent.train_count": 2030.0, "timer/agent.train_total": 900.6919391155243, "timer/agent.train_frac": 0.9006025591796663, "timer/agent.train_avg": 0.44369061040173613, "timer/agent.train_min": 0.4299125671386719, "timer/agent.train_max": 0.6928248405456543, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4798734188079834, "timer/agent.report_frac": 0.00047982579869112617, "timer/agent.report_avg": 0.2399367094039917, "timer/agent.report_min": 0.23422574996948242, "timer/agent.report_max": 0.24564766883850098, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003775988149553e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 32.47621615237851}
{"step": 870480, "time": 27271.25884604454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870488, "time": 27271.692665576935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870720, "time": 27278.923114299774, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 870920, "time": 27284.739045381546, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 870944, "time": 27285.683944940567, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 871216, "time": 27293.982891321182, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 871584, "time": 27305.089283704758, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 871688, "time": 27307.999846220016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 872144, "time": 27321.95540523529, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 872160, "time": 27322.443357229233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 872216, "time": 27323.91401553154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 872416, "time": 27330.12813591957, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 872480, "time": 27332.0648291111, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 872784, "time": 27341.17190861702, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 872784, "time": 27341.1913189888, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 873032, "time": 27348.480362653732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 873200, "time": 27353.95549583435, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 873232, "time": 27354.95303082466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 873256, "time": 27355.468027353287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 873720, "time": 27369.52799463272, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 873960, "time": 27376.708324432373, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 874184, "time": 27383.55377817154, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 874456, "time": 27391.740634441376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874472, "time": 27392.23104906082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874664, "time": 27397.967920541763, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 874720, "time": 27399.890148878098, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 874728, "time": 27399.919232845306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 875096, "time": 27411.08031964302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 875096, "time": 27411.098868608475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 875192, "time": 27413.99599957466, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 875320, "time": 27417.834198713303, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 875544, "time": 27424.57325029373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 875968, "time": 27437.592316150665, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 875984, "time": 27438.078448295593, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 876104, "time": 27441.557347774506, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 876272, "time": 27446.855282068253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 877032, "time": 27469.89383149147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 877040, "time": 27470.410145521164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 877088, "time": 27471.863404273987, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 877352, "time": 27479.538970708847, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 877624, "time": 27487.70692372322, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 877688, "time": 27489.62240767479, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 877856, "time": 27494.880783081055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 877888, "time": 27495.85754299164, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 877936, "time": 27497.293065309525, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 878216, "time": 27505.59863448143, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 878280, "time": 27507.51381134987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 878416, "time": 27511.818123817444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 878416, "time": 27511.827508211136, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 878584, "time": 27516.64829492569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 878608, "time": 27517.585075378418, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 879256, "time": 27536.898084163666, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 879264, "time": 27537.360075235367, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 879472, "time": 27543.621619462967, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 879512, "time": 27544.605362176895, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 879576, "time": 27546.52661037445, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 879672, "time": 27549.438318014145, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 880000, "time": 27559.49529480934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 27562.085625886917, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 880048, "time": 27562.645212173462, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 880048, "time": 27562.818347215652, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 880048, "time": 27562.93149447441, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 880048, "time": 27562.991556167603, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 880048, "time": 27563.069318056107, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 880048, "time": 27563.092744112015, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 880048, "time": 27563.602352142334, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 880168, "time": 27566.99764943123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 880576, "time": 27579.430572748184, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 880592, "time": 27579.935699224472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 880800, "time": 27586.16220355034, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 881048, "time": 27593.472338438034, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 881136, "time": 27596.33022236824, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 881568, "time": 27609.328909397125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 881576, "time": 27609.35751438141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 881640, "time": 27611.27955198288, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 881888, "time": 27618.999700307846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 881984, "time": 27621.99499630928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882016, "time": 27622.953088998795, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 882312, "time": 27631.576394557953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882432, "time": 27635.392238378525, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 882448, "time": 27635.87427186966, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 882640, "time": 27641.668103694916, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 883360, "time": 27663.291365623474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 883416, "time": 27664.754595279694, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 883448, "time": 27665.71839952469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 883704, "time": 27673.41193842888, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 883848, "time": 27677.756858587265, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 883880, "time": 27678.723079919815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 883912, "time": 27679.68474292755, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 884120, "time": 27686.072650909424, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 884168, "time": 27687.51697587967, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 884328, "time": 27692.32102751732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 884352, "time": 27693.26682448387, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 884392, "time": 27694.24750804901, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 884560, "time": 27699.509158849716, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 884624, "time": 27701.464395046234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 884760, "time": 27705.85212302208, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 884840, "time": 27708.259421110153, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 884968, "time": 27712.21019244194, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 884984, "time": 27712.69501543045, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 885128, "time": 27717.027785778046, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 885536, "time": 27729.527678251266, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 885552, "time": 27730.03146457672, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 885696, "time": 27734.333708763123, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 885880, "time": 27739.739090442657, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 886128, "time": 27747.57624721527, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 886448, "time": 27757.150546073914, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 886512, "time": 27759.091928958893, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 886584, "time": 27761.037494421005, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 886824, "time": 27768.255575418472, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 886920, "time": 27771.23298883438, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 887152, "time": 27778.398926258087, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 887152, "time": 27778.407137155533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887296, "time": 27782.72714662552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887448, "time": 27787.083060503006, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 887616, "time": 27792.353310108185, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 887848, "time": 27799.101600170135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887856, "time": 27799.56352496147, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 888008, "time": 27803.978308439255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 888152, "time": 27808.29953479767, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 888544, "time": 27820.225955724716, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 888832, "time": 27828.87726998329, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 889136, "time": 27838.10118484497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889232, "time": 27841.04498720169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889248, "time": 27841.53564095497, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 889552, "time": 27850.724583387375, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 889608, "time": 27852.183891773224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889736, "time": 27856.02397608757, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 889760, "time": 27856.96436214447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 27865.598509311676, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 890032, "time": 27866.055492401123, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 890032, "time": 27866.111011743546, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 890032, "time": 27866.539531469345, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 890032, "time": 27866.700164794922, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 890032, "time": 27867.106672286987, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 890032, "time": 27867.367661952972, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 890032, "time": 27867.782458782196, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 890160, "time": 27871.628180980682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890584, "time": 27884.127447605133, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 890856, "time": 27892.364669322968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 891160, "time": 27901.488485097885, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 891544, "time": 27913.048545360565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 891560, "time": 27913.533642053604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 891664, "time": 27916.86777997017, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 891864, "time": 27922.72651028633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 892048, "time": 27928.459244966507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 892072, "time": 27928.966586112976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 892240, "time": 27934.230889558792, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 892472, "time": 27940.965638399124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 892568, "time": 27943.82824778557, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 892656, "time": 27946.700242996216, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 892696, "time": 27947.683001756668, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 893136, "time": 27961.643332481384, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 893296, "time": 27966.465014219284, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 893448, "time": 27970.813044786453, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 893472, "time": 27971.752927541733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 893624, "time": 27976.09348988533, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 893872, "time": 27983.868369579315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 893976, "time": 27986.771023750305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 894552, "time": 28004.058206796646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 894688, "time": 28008.366340875626, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 894784, "time": 28011.309594869614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895056, "time": 28019.457522153854, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 895328, "time": 28027.68156003952, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 895448, "time": 28031.05582499504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895456, "time": 28031.521337032318, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 895608, "time": 28035.854590654373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895936, "time": 28046.11967921257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896184, "time": 28053.359971284866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896264, "time": 28055.760573387146, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 896288, "time": 28056.717910528183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896528, "time": 28063.909272670746, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 896816, "time": 28072.639963388443, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 896864, "time": 28074.086146593094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896968, "time": 28076.993517398834, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 897152, "time": 28082.721578121185, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 897336, "time": 28088.0351190567, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 897400, "time": 28089.97241282463, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 897416, "time": 28090.463949918747, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 897640, "time": 28097.173815488815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 897704, "time": 28099.089123249054, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 897760, "time": 28101.097491264343, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 897768, "time": 28101.12577676773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 897784, "time": 28101.610492944717, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 897920, "time": 28105.92826938629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 898080, "time": 28110.72420191765, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 898208, "time": 28114.573862314224, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 898360, "time": 28118.923352003098, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 898512, "time": 28123.698382616043, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 898656, "time": 28127.993685245514, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 898656, "time": 28128.001010894775, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 898752, "time": 28130.99346470833, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 898872, "time": 28134.38059091568, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 898928, "time": 28136.26393198967, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 898984, "time": 28137.725166797638, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 899136, "time": 28142.48565363884, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 899384, "time": 28149.722666502, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 899464, "time": 28152.113634824753, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 899712, "time": 28159.76399254799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 899728, "time": 28160.2720849514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 28170.341844320297, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 900016, "time": 28170.365894317627, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 900016, "time": 28172.322695493698, "eval_episode/length": 171.0, "eval_episode/score": 0.46562498807907104, "eval_episode/reward_rate": 0.005813953488372093}
{"step": 900016, "time": 28175.069819688797, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 28175.077047348022, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 28175.085290431976, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 28175.09316301346, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 28175.10043144226, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900160, "time": 28179.41875386238, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 900232, "time": 28181.342953681946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 900280, "time": 28182.796673059464, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 900384, "time": 28186.10982942581, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 900408, "time": 28186.610676050186, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 900568, "time": 28191.526815891266, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 900952, "time": 28203.058891773224, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 900968, "time": 28203.54301905632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 901104, "time": 28207.877393245697, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 901288, "time": 28213.687866449356, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 901296, "time": 28214.156923294067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 901776, "time": 28228.657558441162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 902472, "time": 28249.287071466446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 902544, "time": 28251.788176059723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 902688, "time": 28256.129420518875, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 902976, "time": 28264.75328397751, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 903104, "time": 28268.61000394821, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 903177, "time": 28271.561351299286, "train_stats/mean_log_entropy": 0.0882710722177776, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3499240782202744, "train/action_min": 0.0, "train/action_std": 1.6176588261999736, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009807522078158288, "train/actor_opt_grad_steps": 55330.0, "train/actor_opt_loss": -11.842113911814806, "train/adv_mag": 0.7059967221283331, "train/adv_max": 0.2894293197771398, "train/adv_mean": 0.0006928075585874911, "train/adv_min": -0.6605872395561962, "train/adv_std": 0.0241120577040242, "train/cont_avg": 0.9952505716463415, "train/cont_loss_mean": 0.016680352741897834, "train/cont_loss_std": 0.23582347596473083, "train/cont_neg_acc": 0.31822493810479235, "train/cont_neg_loss": 2.8186642768903543, "train/cont_pos_acc": 0.9998563638547572, "train/cont_pos_loss": 0.003462559097764514, "train/cont_pred": 0.9951739968323126, "train/cont_rate": 0.9952505716463415, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11559854767217141, "train/extr_critic_critic_opt_grad_steps": 55330.0, "train/extr_critic_critic_opt_loss": 13392.398175495427, "train/extr_critic_mag": 1.156487596325758, "train/extr_critic_max": 1.156487596325758, "train/extr_critic_mean": 1.033467719613052, "train/extr_critic_min": 0.8195854983678679, "train/extr_critic_std": 0.020548422689118037, "train/extr_return_normed_mag": 0.7305636885689526, "train/extr_return_normed_max": 0.31072803561280415, "train/extr_return_normed_mean": 0.03812670608664431, "train/extr_return_normed_min": -0.655553338295076, "train/extr_return_normed_std": 0.03239620572819216, "train/extr_return_rate": 0.999395995896037, "train/extr_return_raw_mag": 1.3067619608669747, "train/extr_return_raw_max": 1.3067619608669747, "train/extr_return_raw_mean": 1.0341606797241583, "train/extr_return_raw_min": 0.34048058695909456, "train/extr_return_raw_std": 0.03239620575545037, "train/extr_reward_mag": 0.31242652811655186, "train/extr_reward_max": 0.31242652811655186, "train/extr_reward_mean": 0.0013692833000521472, "train/extr_reward_min": -5.815087295160061e-10, "train/extr_reward_std": 0.007418743619786166, "train/image_loss_mean": 0.07261989783586525, "train/image_loss_std": 0.09259186921323218, "train/model_loss_mean": 0.6987773357368097, "train/model_loss_std": 0.3965374849191526, "train/model_opt_grad_norm": 20.038661419473044, "train/model_opt_grad_steps": 55276.785365853655, "train/model_opt_loss": 3646.528310785061, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5219.512195121952, "train/policy_entropy_mag": 1.3133149338931571, "train/policy_entropy_max": 1.3133149338931571, "train/policy_entropy_mean": 0.10872462181056418, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1408646746743016, "train/policy_logprob_mag": 6.551080252484577, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10824092408505882, "train/policy_logprob_min": -6.551080252484577, "train/policy_logprob_std": 0.6440889649274872, "train/policy_randomness_mag": 0.6749104078223066, "train/policy_randomness_max": 0.6749104078223066, "train/policy_randomness_mean": 0.05587340544273214, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07239012678221958, "train/post_ent_mag": 34.52484715159346, "train/post_ent_max": 34.52484715159346, "train/post_ent_mean": 34.16363973850157, "train/post_ent_min": 33.884755260188406, "train/post_ent_std": 0.14104263858824242, "train/prior_ent_mag": 35.73587413880883, "train/prior_ent_max": 35.73587413880883, "train/prior_ent_mean": 34.73474630960604, "train/prior_ent_min": 33.119899898622094, "train/prior_ent_std": 0.4136689078517076, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0013207114604017812, "train/reward_loss_mean": 0.009477059229663232, "train/reward_loss_std": 0.17161835479073045, "train/reward_max_data": 0.6657469525569822, "train/reward_max_pred": 0.23503957783303608, "train/reward_neg_acc": 0.9997088042701163, "train/reward_neg_loss": 0.0017460838212949655, "train/reward_pos_acc": 0.21149471054474514, "train/reward_pos_loss": 4.079299918313821, "train/reward_pred": 0.0011061909052020892, "train/reward_rate": 0.0019388338414634146, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.011869465932250023, "report/cont_loss_std": 0.21864654123783112, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.636255145072937, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0022954836022108793, "report/cont_pred": 0.9938209056854248, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06934516131877899, "report/image_loss_std": 0.08792892098426819, "report/model_loss_mean": 0.6970605850219727, "report/model_loss_std": 0.5383579730987549, "report/post_ent_mag": 34.14234161376953, "report/post_ent_max": 34.14234161376953, "report/post_ent_mean": 33.749183654785156, "report/post_ent_min": 33.48560333251953, "report/post_ent_std": 0.15186326205730438, "report/prior_ent_mag": 35.684242248535156, "report/prior_ent_max": 35.684242248535156, "report/prior_ent_mean": 34.63928985595703, "report/prior_ent_min": 33.149009704589844, "report/prior_ent_std": 0.4294799268245697, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002532958984375, "report/reward_loss_mean": 0.01584593579173088, "report/reward_loss_std": 0.2967521846294403, "report/reward_max_data": 0.8343750238418579, "report/reward_max_pred": 0.6453570127487183, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0010455759475007653, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 3.7899374961853027, "report/reward_pred": 0.0017909068847075105, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.04070139676332474, "eval/cont_loss_std": 0.5515190958976746, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.463024139404297, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0028488088864833117, "eval/cont_pred": 0.997184693813324, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11881358921527863, "eval/image_loss_std": 0.15340259671211243, "eval/model_loss_mean": 0.7824714779853821, "eval/model_loss_std": 0.805538535118103, "eval/post_ent_mag": 34.14240264892578, "eval/post_ent_max": 34.14240264892578, "eval/post_ent_mean": 33.76073455810547, "eval/post_ent_min": 33.49058532714844, "eval/post_ent_std": 0.14660882949829102, "eval/prior_ent_mag": 35.9063835144043, "eval/prior_ent_max": 35.9063835144043, "eval/prior_ent_mean": 34.67790985107422, "eval/prior_ent_min": 33.46770477294922, "eval/prior_ent_std": 0.38859808444976807, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0027404786087572575, "eval/reward_loss_mean": 0.02295646257698536, "eval/reward_loss_std": 0.34644633531570435, "eval/reward_max_data": 0.8374999761581421, "eval/reward_max_pred": 0.2238069772720337, "eval/reward_neg_acc": 0.9990195631980896, "eval/reward_neg_loss": 0.0013669300824403763, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.528287410736084, "eval/reward_pred": 0.0007299521239474416, "eval/reward_rate": 0.00390625, "replay/size": 902673.0, "replay/inserts": 32704.0, "replay/samples": 32704.0, "replay/insert_wait_avg": 1.2850939294363421e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.521732912604823e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1002291060690385e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2998821735382, "timer/env.step_count": 4088.0, "timer/env.step_total": 38.632813453674316, "timer/env.step_frac": 0.03862123163478695, "timer/env.step_avg": 0.009450296833090586, "timer/env.step_min": 0.007660627365112305, "timer/env.step_max": 0.04315900802612305, "timer/replay._sample_count": 32704.0, "timer/replay._sample_total": 16.4422709941864, "timer/replay._sample_frac": 0.016437341728421692, "timer/replay._sample_avg": 0.0005027602432175392, "timer/replay._sample_min": 0.0003724098205566406, "timer/replay._sample_max": 0.01065516471862793, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4646.0, "timer/agent.policy_total": 48.19744896888733, "timer/agent.policy_frac": 0.04818299974619585, "timer/agent.policy_avg": 0.010373966631271487, "timer/agent.policy_min": 0.008963823318481445, "timer/agent.policy_max": 0.08599638938903809, "timer/dataset_train_count": 2044.0, "timer/dataset_train_total": 0.21706819534301758, "timer/dataset_train_frac": 0.00021700311997573468, "timer/dataset_train_avg": 0.00010619774723239608, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0007457733154296875, "timer/agent.train_count": 2044.0, "timer/agent.train_total": 901.8506414890289, "timer/agent.train_frac": 0.9015802736369515, "timer/agent.train_avg": 0.44121851344864427, "timer/agent.train_min": 0.4301576614379883, "timer/agent.train_max": 0.6814253330230713, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4769148826599121, "timer/agent.report_frac": 0.0004767719072640798, "timer/agent.report_avg": 0.23845744132995605, "timer/agent.report_min": 0.22999167442321777, "timer/agent.report_max": 0.24692320823669434, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8839999469563288e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 32.69364256445183}
{"step": 903264, "time": 28274.150542736053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903280, "time": 28274.634430885315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903416, "time": 28278.492986679077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903600, "time": 28284.341933250427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903608, "time": 28284.370037555695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903952, "time": 28294.961851119995, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 904064, "time": 28298.34192442894, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 904280, "time": 28304.673617601395, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 904368, "time": 28307.5546104908, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 904784, "time": 28320.202820062637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905008, "time": 28326.92339158058, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 905016, "time": 28326.951133966446, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 905416, "time": 28338.94972896576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905576, "time": 28343.837559223175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905592, "time": 28344.321578264236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905728, "time": 28348.640266418457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 905760, "time": 28349.606890439987, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 906024, "time": 28357.315606594086, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 906136, "time": 28360.691165208817, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 906392, "time": 28368.3454310894, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 906560, "time": 28373.69703221321, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 906848, "time": 28382.3432970047, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 907096, "time": 28389.57854437828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 907320, "time": 28396.315336704254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 907328, "time": 28396.782366514206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 907568, "time": 28404.085299253464, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 907584, "time": 28404.570689439774, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 907752, "time": 28409.396894931793, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 907904, "time": 28414.166225910187, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 908240, "time": 28424.24035835266, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 908304, "time": 28426.174723148346, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 908416, "time": 28429.537092924118, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 908448, "time": 28430.600977659225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 908600, "time": 28434.947822332382, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 908704, "time": 28438.270703554153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 908856, "time": 28442.614511489868, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 908872, "time": 28443.106414794922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 909016, "time": 28447.436589717865, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 909104, "time": 28450.303063631058, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 909296, "time": 28456.032258749008, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 909384, "time": 28458.904855012894, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 909640, "time": 28466.682646751404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 909656, "time": 28467.168827295303, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 28478.862273216248, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 910000, "time": 28478.923818588257, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 910000, "time": 28479.16717529297, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 910000, "time": 28479.21119904518, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 910000, "time": 28479.539954185486, "eval_episode/length": 16.0, "eval_episode/score": 0.949999988079071, "eval_episode/reward_rate": 0.058823529411764705}
{"step": 910000, "time": 28480.353078603745, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 910000, "time": 28480.662200450897, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 910000, "time": 28481.765837192535, "eval_episode/length": 212.0, "eval_episode/score": 0.3375000059604645, "eval_episode/reward_rate": 0.004694835680751174}
{"step": 910008, "time": 28481.79046869278, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 910216, "time": 28488.050559282303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910288, "time": 28490.546573400497, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 910760, "time": 28504.48368692398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910912, "time": 28509.319251537323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911168, "time": 28517.132601499557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911560, "time": 28528.783281564713, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 911696, "time": 28533.079197883606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911728, "time": 28534.037895202637, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 911776, "time": 28535.476935863495, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 911968, "time": 28541.239109039307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912264, "time": 28549.880526065826, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 912320, "time": 28551.862338781357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912528, "time": 28558.091291189194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912600, "time": 28560.053287506104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912808, "time": 28566.30345916748, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 912856, "time": 28567.751633405685, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 913104, "time": 28575.438403367996, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 913208, "time": 28578.32642531395, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 913232, "time": 28579.288689136505, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 913280, "time": 28580.803971529007, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 913512, "time": 28587.54047679901, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 913656, "time": 28591.873292207718, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 913872, "time": 28598.63649582863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 913984, "time": 28602.035521030426, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 914128, "time": 28606.37590456009, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 914624, "time": 28621.32689332962, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 914912, "time": 28630.030384778976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 914968, "time": 28631.494829893112, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 915120, "time": 28636.289135932922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915168, "time": 28637.74977040291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915264, "time": 28640.72638607025, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 915280, "time": 28641.211206912994, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 915328, "time": 28642.67152786255, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 915592, "time": 28650.384361982346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915760, "time": 28655.652891874313, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 915824, "time": 28657.596666574478, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 915920, "time": 28660.473345041275, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 915936, "time": 28660.9572057724, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 915968, "time": 28661.933772087097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 916432, "time": 28676.043453216553, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 916440, "time": 28676.070394277573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 916696, "time": 28683.81845808029, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 916840, "time": 28688.13991689682, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 916944, "time": 28691.484970331192, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 917016, "time": 28693.40492129326, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 917048, "time": 28694.36120033264, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 917312, "time": 28702.587206840515, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 917496, "time": 28707.885105848312, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 917904, "time": 28720.775846481323, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 917904, "time": 28720.784227371216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 917944, "time": 28721.770795345306, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 918048, "time": 28725.117641687393, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 918232, "time": 28730.51780319214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 918744, "time": 28745.823291301727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 918880, "time": 28750.112004995346, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 918984, "time": 28753.009579896927, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 919008, "time": 28753.97078728676, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 919328, "time": 28763.64674282074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 919416, "time": 28766.061527729034, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 919696, "time": 28774.71805047989, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 919808, "time": 28778.12296438217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 920056, "time": 28785.328526735306, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 28787.280948638916, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 920088, "time": 28787.31991481781, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 920088, "time": 28787.497581243515, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 920088, "time": 28787.781587839127, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 920088, "time": 28788.081491708755, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 920088, "time": 28788.48042368889, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 920088, "time": 28788.973987579346, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 920088, "time": 28789.844576835632, "eval_episode/length": 194.0, "eval_episode/score": 0.39375001192092896, "eval_episode/reward_rate": 0.005128205128205128}
{"step": 920112, "time": 28790.87289428711, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 920216, "time": 28793.78746509552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 920360, "time": 28798.112396001816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 920656, "time": 28807.227529525757, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 920696, "time": 28808.208913326263, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 920960, "time": 28816.318225860596, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 920960, "time": 28816.326863527298, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 920992, "time": 28817.288033246994, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 921056, "time": 28819.210479021072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921296, "time": 28826.51982498169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921312, "time": 28827.004110097885, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 921320, "time": 28827.032804250717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921736, "time": 28839.51330471039, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 921944, "time": 28845.800260782242, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 921976, "time": 28846.7876765728, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 922104, "time": 28850.747138738632, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 922344, "time": 28857.91375041008, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 922368, "time": 28858.879133939743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 922400, "time": 28859.850487709045, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 922656, "time": 28867.559851408005, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 922800, "time": 28871.887753725052, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 922904, "time": 28874.79795742035, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 923200, "time": 28883.99893260002, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 923248, "time": 28885.451328516006, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 923272, "time": 28885.960861206055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923304, "time": 28886.929255247116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923336, "time": 28887.924444437027, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 923400, "time": 28889.844746112823, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 923456, "time": 28891.743027210236, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 923552, "time": 28894.623576164246, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 923584, "time": 28895.578670740128, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 923792, "time": 28901.840331554413, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 924264, "time": 28915.878637313843, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 924360, "time": 28918.78637957573, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 924848, "time": 28933.73515677452, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 925104, "time": 28941.580694437027, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 925512, "time": 28953.72994327545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 925616, "time": 28957.097028017044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 925648, "time": 28958.061036109924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 925712, "time": 28960.483425855637, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 925864, "time": 28964.80806326866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 926104, "time": 28972.16900038719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 926168, "time": 28974.10078883171, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 926288, "time": 28977.926324367523, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 926448, "time": 28982.726541042328, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 926496, "time": 28984.168694496155, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 926528, "time": 28985.148587703705, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 926672, "time": 28991.650604486465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 927128, "time": 29005.158251285553, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 927160, "time": 29006.1425614357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 927208, "time": 29007.586411476135, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 927672, "time": 29021.506494045258, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 927776, "time": 29024.845611333847, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 927808, "time": 29025.823147058487, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 927944, "time": 29029.665035009384, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 928184, "time": 29036.96844267845, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 928352, "time": 29042.230260372162, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 928416, "time": 29044.153458595276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 928432, "time": 29044.658517837524, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 928480, "time": 29046.09960412979, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 928600, "time": 29049.49508523941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 928848, "time": 29057.132440328598, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 928904, "time": 29058.592270851135, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 928912, "time": 29059.072124242783, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 929120, "time": 29065.411904096603, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 929336, "time": 29071.673946857452, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 929696, "time": 29082.716245174408, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 929784, "time": 29085.148730754852, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 929824, "time": 29086.56861972809, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 929936, "time": 29089.934981822968, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 29094.762322187424, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 930072, "time": 29095.12510061264, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 930072, "time": 29095.405025720596, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 930072, "time": 29095.618542432785, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 930072, "time": 29095.898553609848, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 930072, "time": 29096.54481458664, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 930072, "time": 29096.801300048828, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 930072, "time": 29097.477206468582, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 930312, "time": 29104.66973209381, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 930496, "time": 29110.403314113617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 930552, "time": 29111.884080171585, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 930744, "time": 29117.662714719772, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 930872, "time": 29121.59335565567, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 930912, "time": 29123.008281946182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931056, "time": 29127.318723917007, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 931144, "time": 29129.72983956337, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 931280, "time": 29134.02126979828, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 931280, "time": 29134.02909207344, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 931304, "time": 29134.535138845444, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 931384, "time": 29136.94677758217, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 931448, "time": 29138.871159553528, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 931656, "time": 29145.115445137024, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 932008, "time": 29155.803822994232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 932288, "time": 29164.3965344429, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 932776, "time": 29178.81164574623, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 933368, "time": 29196.722178697586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 933592, "time": 29203.477833747864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 933616, "time": 29204.425362586975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 933696, "time": 29206.82372045517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 933968, "time": 29215.599356889725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934288, "time": 29225.177000761032, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 934320, "time": 29226.139548540115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934584, "time": 29233.82383275032, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 934600, "time": 29234.30705165863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934704, "time": 29237.644164323807, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 934704, "time": 29237.650997161865, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 934856, "time": 29242.075104236603, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 935088, "time": 29249.24223446846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 935376, "time": 29257.897518873215, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 935408, "time": 29258.859073400497, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 935512, "time": 29261.777015447617, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 935768, "time": 29269.44060897827, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 935817, "time": 29271.9816634655, "train_stats/mean_log_entropy": 0.0854783073067665, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5033051733877145, "train/action_min": 0.0, "train/action_std": 1.6785374792183148, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008111566926042238, "train/actor_opt_grad_steps": 57375.0, "train/actor_opt_loss": -12.327293212507286, "train/adv_mag": 0.7355877812586579, "train/adv_max": 0.2990989150369869, "train/adv_mean": 0.0016302430657578596, "train/adv_min": -0.676177986404475, "train/adv_std": 0.023573847195389224, "train/cont_avg": 0.9951219745710784, "train/cont_loss_mean": 0.017211326957205494, "train/cont_loss_std": 0.23697267065518626, "train/cont_neg_acc": 0.3027065180826421, "train/cont_neg_loss": 2.8333634229079596, "train/cont_pos_acc": 0.99991341928641, "train/cont_pos_loss": 0.0034655712233335875, "train/cont_pred": 0.9951027456451865, "train/cont_rate": 0.9951219745710784, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10011010296989743, "train/extr_critic_critic_opt_grad_steps": 57375.0, "train/extr_critic_critic_opt_loss": 12301.893502029718, "train/extr_critic_mag": 1.1909949662638646, "train/extr_critic_max": 1.1909949662638646, "train/extr_critic_mean": 1.080713987934823, "train/extr_critic_min": 0.8444408242608986, "train/extr_critic_std": 0.02198882562601391, "train/extr_return_normed_mag": 0.7599875926971436, "train/extr_return_normed_max": 0.31481098310620176, "train/extr_return_normed_mean": 0.04241855218823926, "train/extr_return_normed_min": -0.6713038884541568, "train/extr_return_normed_std": 0.03293594633064726, "train/extr_return_rate": 0.9995398372411728, "train/extr_return_raw_mag": 1.354736682246713, "train/extr_return_raw_max": 1.354736682246713, "train/extr_return_raw_mean": 1.0823442976848752, "train/extr_return_raw_min": 0.3686218106863545, "train/extr_return_raw_std": 0.03293594641282278, "train/extr_reward_mag": 0.3316367046505797, "train/extr_reward_max": 0.3316367046505797, "train/extr_reward_mean": 0.0013862107609348446, "train/extr_reward_min": 1.1687185250076593e-09, "train/extr_reward_std": 0.007665726601593562, "train/image_loss_mean": 0.07155320859130691, "train/image_loss_std": 0.09223861820703629, "train/model_loss_mean": 0.6998545755358303, "train/model_loss_std": 0.4206640236079693, "train/model_opt_grad_norm": 20.01296354742611, "train/model_opt_grad_steps": 57319.78431372549, "train/model_opt_loss": 3516.139290603937, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5024.509803921569, "train/policy_entropy_mag": 1.3160962666950973, "train/policy_entropy_max": 1.3160962666950973, "train/policy_entropy_mean": 0.10152212318544294, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12897191751821369, "train/policy_logprob_mag": 6.551080257284875, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10130677777616416, "train/policy_logprob_min": -6.551080257284875, "train/policy_logprob_std": 0.6376747427617803, "train/policy_randomness_mag": 0.6763397306203842, "train/policy_randomness_max": 0.6763397306203842, "train/policy_randomness_mean": 0.0521720534227058, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06627845862770781, "train/post_ent_mag": 34.12755225686466, "train/post_ent_max": 34.12755225686466, "train/post_ent_mean": 33.76423706727869, "train/post_ent_min": 33.479948829202094, "train/post_ent_std": 0.14299679898163853, "train/prior_ent_mag": 35.56750871620926, "train/prior_ent_max": 35.56750871620926, "train/prior_ent_mean": 34.60896772496841, "train/prior_ent_min": 33.14007762834137, "train/prior_ent_std": 0.38755736017928405, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0016287710119179204, "train/reward_loss_mean": 0.011090016466172813, "train/reward_loss_std": 0.19069513169747285, "train/reward_max_data": 0.7366727969663984, "train/reward_max_pred": 0.2527512510617574, "train/reward_neg_acc": 0.9997504572657978, "train/reward_neg_loss": 0.0018722214416472935, "train/reward_pos_acc": 0.2065071071941815, "train/reward_pos_loss": 3.9968144562856067, "train/reward_pred": 0.0012315179874170937, "train/reward_rate": 0.002326516544117647, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.013438841328024864, "report/cont_loss_std": 0.16400524973869324, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 1.9151147603988647, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004107752814888954, "report/cont_pred": 0.994377851486206, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07195062935352325, "report/image_loss_std": 0.08408215641975403, "report/model_loss_mean": 0.6925782561302185, "report/model_loss_std": 0.28046053647994995, "report/post_ent_mag": 33.92527770996094, "report/post_ent_max": 33.92527770996094, "report/post_ent_mean": 33.609683990478516, "report/post_ent_min": 33.27363204956055, "report/post_ent_std": 0.15304987132549286, "report/prior_ent_mag": 35.35708999633789, "report/prior_ent_max": 35.35708999633789, "report/prior_ent_mean": 34.17168045043945, "report/prior_ent_min": 33.101097106933594, "report/prior_ent_std": 0.34558773040771484, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014129638439044356, "report/reward_loss_mean": 0.007188776973634958, "report/reward_loss_std": 0.12784886360168457, "report/reward_max_data": 0.793749988079071, "report/reward_max_pred": 0.20863008499145508, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0018425113521516323, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.7391302585601807, "report/reward_pred": 0.001171494135633111, "report/reward_rate": 0.001953125, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.007223574444651604, "eval/cont_loss_std": 0.09781011193990707, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.9990234375, "eval/cont_pos_loss": 0.007223574444651604, "eval/cont_pred": 0.9949462413787842, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10851800441741943, "eval/image_loss_std": 0.12969370186328888, "eval/model_loss_mean": 0.7221601009368896, "eval/model_loss_std": 0.28031328320503235, "eval/post_ent_mag": 33.92323684692383, "eval/post_ent_max": 33.92323684692383, "eval/post_ent_mean": 33.57048034667969, "eval/post_ent_min": 33.29112243652344, "eval/post_ent_std": 0.13543269038200378, "eval/prior_ent_mag": 35.15544891357422, "eval/prior_ent_max": 35.15544891357422, "eval/prior_ent_mean": 34.20392608642578, "eval/prior_ent_min": 33.15827178955078, "eval/prior_ent_std": 0.34643077850341797, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0064185066148638725, "eval/reward_loss_std": 0.14441996812820435, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.5065804719924927, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.0064185066148638725, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0014967380557209253, "eval/reward_rate": 0.0, "replay/size": 935313.0, "replay/inserts": 32640.0, "replay/samples": 32640.0, "replay/insert_wait_avg": 1.2726906467886532e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.710912648369285e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4776.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0785245815513522e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4108731746674, "timer/env.step_count": 4080.0, "timer/env.step_total": 38.50917387008667, "timer/env.step_frac": 0.03849335798188904, "timer/env.step_avg": 0.009438523007374184, "timer/env.step_min": 0.007698535919189453, "timer/env.step_max": 0.035370588302612305, "timer/replay._sample_count": 32640.0, "timer/replay._sample_total": 16.520350694656372, "timer/replay._sample_frac": 0.016513565713486594, "timer/replay._sample_avg": 0.0005061381953019721, "timer/replay._sample_min": 0.0003807544708251953, "timer/replay._sample_max": 0.034440040588378906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4677.0, "timer/agent.policy_total": 48.26339650154114, "timer/agent.policy_frac": 0.048243574510924536, "timer/agent.policy_avg": 0.010319306500222608, "timer/agent.policy_min": 0.008808612823486328, "timer/agent.policy_max": 0.07802557945251465, "timer/dataset_train_count": 2040.0, "timer/dataset_train_total": 0.21899652481079102, "timer/dataset_train_frac": 0.00021890658196850203, "timer/dataset_train_avg": 0.00010735123765234853, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.0010802745819091797, "timer/agent.train_count": 2040.0, "timer/agent.train_total": 902.3681745529175, "timer/agent.train_frac": 0.9019975679486322, "timer/agent.train_avg": 0.4423373404671164, "timer/agent.train_min": 0.4305877685546875, "timer/agent.train_max": 2.6266884803771973, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4759974479675293, "timer/agent.report_frac": 0.00047580195370829624, "timer/agent.report_avg": 0.23799872398376465, "timer/agent.report_min": 0.22957658767700195, "timer/agent.report_max": 0.24642086029052734, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9790082441948788e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 32.62602525751533}
{"step": 935824, "time": 29272.003036499023, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 936512, "time": 29293.107557058334, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 936536, "time": 29293.61533498764, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 936632, "time": 29296.51494050026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 936696, "time": 29298.437960624695, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 936896, "time": 29304.70832633972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 936912, "time": 29305.215022325516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 936992, "time": 29307.60774040222, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 937688, "time": 29328.29882454872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 937720, "time": 29329.278757572174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 937744, "time": 29330.24731373787, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 937960, "time": 29336.58283829689, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 938288, "time": 29346.663904428482, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 938344, "time": 29348.114620685577, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 938472, "time": 29351.957663059235, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 938944, "time": 29366.39685845375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939008, "time": 29368.32508778572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939048, "time": 29369.305335998535, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 939104, "time": 29371.227796316147, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 939184, "time": 29373.666242599487, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 939184, "time": 29373.672443151474, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 939224, "time": 29374.66016793251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939224, "time": 29374.667692422867, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 939496, "time": 29382.878450155258, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 939728, "time": 29390.053769350052, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 939960, "time": 29396.880363702774, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 940040, "time": 29399.2718667984, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 29401.424538612366, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 940056, "time": 29401.710901260376, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 940056, "time": 29401.734191179276, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 940056, "time": 29401.82973217964, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 940056, "time": 29401.908625364304, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 940056, "time": 29402.45001244545, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 940056, "time": 29402.525921344757, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 940056, "time": 29402.637208223343, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 940072, "time": 29403.118614673615, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 940136, "time": 29405.04372191429, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 940312, "time": 29410.323788166046, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 940672, "time": 29421.436095952988, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 940800, "time": 29425.291219711304, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 940832, "time": 29426.255313396454, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 941288, "time": 29439.744597673416, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 941360, "time": 29442.136038780212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 941536, "time": 29447.454264640808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 941568, "time": 29448.43686747551, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 942048, "time": 29463.026329040527, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 942176, "time": 29467.37813425064, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 942240, "time": 29469.332746505737, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 942352, "time": 29472.71977686882, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 942384, "time": 29473.69393515587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 942448, "time": 29475.621872901917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 942456, "time": 29475.64805150032, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 942904, "time": 29489.322062015533, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 943048, "time": 29493.66351056099, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 943144, "time": 29496.54725265503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 943240, "time": 29499.448841571808, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 943640, "time": 29511.61485338211, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 943672, "time": 29512.584841251373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 943696, "time": 29513.542271614075, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 943944, "time": 29520.791680574417, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 944000, "time": 29522.711678504944, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 944024, "time": 29523.21921825409, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 944312, "time": 29531.9189119339, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 944344, "time": 29532.89081645012, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 944360, "time": 29533.37947702408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944416, "time": 29535.278089523315, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 944568, "time": 29539.62477350235, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 944792, "time": 29546.5310857296, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 944872, "time": 29548.954081058502, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 945024, "time": 29553.793316602707, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 945088, "time": 29555.7480096817, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 945368, "time": 29563.998497486115, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 945688, "time": 29573.70412659645, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 946336, "time": 29593.490230560303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 946568, "time": 29600.42633485794, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 946624, "time": 29602.36522912979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 946648, "time": 29602.878551721573, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 946672, "time": 29603.857991933823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 946840, "time": 29608.68630361557, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 946880, "time": 29610.109266519547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947104, "time": 29616.861513376236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947296, "time": 29622.63856959343, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 947336, "time": 29623.640580892563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947584, "time": 29631.383396863937, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 948264, "time": 29651.632672309875, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 948280, "time": 29652.13408613205, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 948408, "time": 29655.981837272644, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 948448, "time": 29657.442044734955, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 948864, "time": 29670.121183395386, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 948984, "time": 29673.52836537361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 949152, "time": 29678.819274663925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 949192, "time": 29679.8083319664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 949216, "time": 29680.75097155571, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 949360, "time": 29685.088088035583, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 949864, "time": 29700.142211675644, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 949896, "time": 29701.13036441803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 949944, "time": 29702.57915496826, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 29706.111233711243, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 950040, "time": 29707.196695566177, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 950040, "time": 29707.205399036407, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 950040, "time": 29708.133905887604, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 950040, "time": 29708.58317708969, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 950040, "time": 29708.676512241364, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 950040, "time": 29708.700868844986, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 950040, "time": 29709.400305986404, "eval_episode/length": 205.0, "eval_episode/score": 0.359375, "eval_episode/reward_rate": 0.0048543689320388345}
{"step": 950128, "time": 29712.273720502853, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 950592, "time": 29726.900599241257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 950624, "time": 29727.868728160858, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 951040, "time": 29740.428065299988, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 951040, "time": 29740.433250188828, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 951368, "time": 29750.089072942734, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 951464, "time": 29753.061108112335, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 951528, "time": 29755.01562690735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 951536, "time": 29755.480540513992, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 951672, "time": 29759.36662888527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 951704, "time": 29760.327125549316, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 951840, "time": 29764.660069942474, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 952080, "time": 29771.894273996353, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 952176, "time": 29774.804666757584, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 952240, "time": 29776.71975517273, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 952248, "time": 29776.74576163292, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 952272, "time": 29777.715067863464, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 952328, "time": 29779.173179388046, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 952784, "time": 29793.237093925476, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 952880, "time": 29796.15618777275, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 952904, "time": 29796.666197538376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 952944, "time": 29798.118681907654, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 953016, "time": 29800.066762924194, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 953024, "time": 29800.529084682465, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 953032, "time": 29800.55636358261, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 953056, "time": 29801.507697582245, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 953360, "time": 29810.801840543747, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 953560, "time": 29816.64315009117, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 953632, "time": 29819.039352416992, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 953688, "time": 29820.502126932144, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 953752, "time": 29822.459522008896, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 953848, "time": 29825.386093378067, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 953904, "time": 29827.32004380226, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 954120, "time": 29833.610386371613, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 954152, "time": 29834.5773499012, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 954472, "time": 29844.311814308167, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 954592, "time": 29848.157761335373, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 954608, "time": 29848.648082971573, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 955064, "time": 29862.198578834534, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 955288, "time": 29868.90499472618, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 955328, "time": 29870.406618595123, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 955408, "time": 29872.83524107933, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 955528, "time": 29876.251619577408, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 955872, "time": 29886.82493185997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956064, "time": 29892.595240354538, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 956464, "time": 29904.712403535843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956704, "time": 29911.960076332092, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 956784, "time": 29914.387659311295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957032, "time": 29921.658264160156, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 957048, "time": 29922.14345550537, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 957280, "time": 29929.375620365143, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 957296, "time": 29929.863176107407, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 957520, "time": 29936.683569908142, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 957640, "time": 29940.092389822006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957656, "time": 29940.57924103737, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 957720, "time": 29942.52203464508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957968, "time": 29950.258739709854, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 957976, "time": 29950.285201072693, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 958184, "time": 29956.557060956955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 958400, "time": 29963.390082359314, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 958584, "time": 29969.168590784073, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 958776, "time": 29974.936926603317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 959048, "time": 29983.143088817596, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 959488, "time": 29996.77944803238, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 959592, "time": 29999.678696155548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 959608, "time": 30000.1652674675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 959656, "time": 30001.63747382164, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 959968, "time": 30011.254813194275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 30014.667669296265, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 960024, "time": 30014.818450689316, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 960024, "time": 30015.554218769073, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 960024, "time": 30015.66542696953, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 960024, "time": 30016.08958530426, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 960024, "time": 30016.273468255997, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 960024, "time": 30017.389857769012, "eval_episode/length": 221.0, "eval_episode/score": 0.30937498807907104, "eval_episode/reward_rate": 0.0045045045045045045}
{"step": 960024, "time": 30017.842886924744, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 960112, "time": 30020.82223010063, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 960280, "time": 30025.699878692627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 960408, "time": 30029.530497312546, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 960472, "time": 30031.478835105896, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 960560, "time": 30034.346065998077, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 960568, "time": 30034.372773885727, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 960648, "time": 30036.796975135803, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 960712, "time": 30038.725364923477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 960768, "time": 30040.651419878006, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 960936, "time": 30045.49420952797, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 961008, "time": 30047.86876988411, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 961008, "time": 30047.874687433243, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 961016, "time": 30047.90116596222, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 961144, "time": 30051.849241256714, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 961296, "time": 30056.638622522354, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 961552, "time": 30064.348803281784, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 961664, "time": 30067.70415019989, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 961712, "time": 30069.161779642105, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 961720, "time": 30069.187458753586, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 961776, "time": 30071.080400705338, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 962040, "time": 30078.831512451172, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 962192, "time": 30083.73636341095, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 962400, "time": 30090.015646219254, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 962528, "time": 30093.888716697693, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 962536, "time": 30093.916480779648, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 962592, "time": 30095.83434033394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 962728, "time": 30099.729071378708, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 962776, "time": 30101.173280239105, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 962784, "time": 30101.63716816902, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 962824, "time": 30102.629111766815, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 962888, "time": 30104.578506708145, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 963248, "time": 30115.73422408104, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 963312, "time": 30117.701587438583, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 963328, "time": 30118.190930128098, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 963352, "time": 30118.701807498932, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 963360, "time": 30119.171818494797, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 963888, "time": 30135.11559200287, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 963896, "time": 30135.142969608307, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 964048, "time": 30140.02895474434, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 964088, "time": 30141.13151192665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 964112, "time": 30142.11134505272, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 964320, "time": 30148.405992269516, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 964376, "time": 30149.875237464905, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 964384, "time": 30150.340912103653, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 964536, "time": 30154.712102890015, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 964664, "time": 30158.59970521927, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 964944, "time": 30167.255093574524, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 965024, "time": 30169.655119657516, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 965088, "time": 30171.69296360016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 965296, "time": 30177.95334792137, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 965560, "time": 30185.73969936371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 965920, "time": 30196.809965133667, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 966184, "time": 30204.634808063507, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 966360, "time": 30209.971982240677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 966656, "time": 30219.26388192177, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 966696, "time": 30220.588176250458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 966976, "time": 30229.244975328445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 967120, "time": 30233.715261936188, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 967208, "time": 30236.170097351074, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 967256, "time": 30237.618872880936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 967336, "time": 30240.05026292801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 967472, "time": 30244.397598981857, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 967824, "time": 30255.013489484787, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 967872, "time": 30256.4551217556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 967896, "time": 30256.957869529724, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 968008, "time": 30260.425034999847, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 968024, "time": 30260.915873765945, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 968232, "time": 30267.175088882446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 968328, "time": 30270.083939790726, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 968361, "time": 30272.04595041275, "train_stats/mean_log_entropy": 0.09426436180957651, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.479055019435037, "train/action_min": 0.0, "train/action_std": 1.6509242791847643, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010107232777291697, "train/actor_opt_grad_steps": 59410.0, "train/actor_opt_loss": -12.796251289950217, "train/adv_mag": 0.7510043966946344, "train/adv_max": 0.2924185909073928, "train/adv_mean": 0.0008811408314089609, "train/adv_min": -0.7127595907948875, "train/adv_std": 0.023180015967800994, "train/cont_avg": 0.9951027555418719, "train/cont_loss_mean": 0.017620719900455675, "train/cont_loss_std": 0.23717498384746424, "train/cont_neg_acc": 0.3083120142224387, "train/cont_neg_loss": 2.828296700022826, "train/cont_pos_acc": 0.9998839791185163, "train/cont_pos_loss": 0.0037308729900588544, "train/cont_pred": 0.9949404796943289, "train/cont_rate": 0.9951027555418719, "train/dyn_loss_mean": 1.0000009542615542, "train/dyn_loss_std": 2.4582034554974787e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08960638120953966, "train/extr_critic_critic_opt_grad_steps": 59410.0, "train/extr_critic_critic_opt_loss": 11007.212337399938, "train/extr_critic_mag": 1.2187091681757585, "train/extr_critic_max": 1.2187091681757585, "train/extr_critic_mean": 1.109894588075835, "train/extr_critic_min": 0.8220909622502445, "train/extr_critic_std": 0.02091107140822804, "train/extr_return_normed_mag": 0.7869824852262225, "train/extr_return_normed_max": 0.2863650321960449, "train/extr_return_normed_mean": 0.03820946402480743, "train/extr_return_normed_min": -0.7220781348608984, "train/extr_return_normed_std": 0.03190206561072413, "train/extr_return_rate": 0.9995654756799707, "train/extr_return_raw_mag": 1.3589312266833677, "train/extr_return_raw_max": 1.3589312266833677, "train/extr_return_raw_mean": 1.1107757085649839, "train/extr_return_raw_min": 0.35048805962642426, "train/extr_return_raw_std": 0.03190206556484617, "train/extr_reward_mag": 0.2850647137082856, "train/extr_reward_max": 0.2850647137082856, "train/extr_reward_mean": 0.0015232635523178821, "train/extr_reward_min": 4.051941368967441e-08, "train/extr_reward_std": 0.007538901952788087, "train/image_loss_mean": 0.06997281500124579, "train/image_loss_std": 0.09085757322058889, "train/model_loss_mean": 0.6985411946409441, "train/model_loss_std": 0.4103477265447231, "train/model_opt_grad_norm": 18.684105164933914, "train/model_opt_grad_steps": 59352.75369458128, "train/model_opt_loss": 3509.6119739551264, "train/model_opt_model_opt_grad_overflow": 0.0049261083743842365, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.3219309199619762, "train/policy_entropy_max": 1.3219309199619762, "train/policy_entropy_mean": 0.10763333095558758, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1390217151768102, "train/policy_logprob_mag": 6.551080257434563, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1069866725670293, "train/policy_logprob_min": -6.551080257434563, "train/policy_logprob_std": 0.6414299522127423, "train/policy_randomness_mag": 0.6793381501301169, "train/policy_randomness_max": 0.6793381501301169, "train/policy_randomness_mean": 0.055312593270258364, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07144303313396834, "train/post_ent_mag": 33.87484752485905, "train/post_ent_max": 33.87484752485905, "train/post_ent_mean": 33.508678661778646, "train/post_ent_min": 33.20871050604458, "train/post_ent_std": 0.1493508133835393, "train/prior_ent_mag": 35.1135504586356, "train/prior_ent_max": 35.1135504586356, "train/prior_ent_mean": 34.13062852004479, "train/prior_ent_min": 32.83466120189047, "train/prior_ent_std": 0.3666131117661011, "train/rep_loss_mean": 1.0000009542615542, "train/rep_loss_std": 2.4582034554974787e-05, "train/reward_avg": 0.0015398297974153932, "train/reward_loss_mean": 0.010947064755787257, "train/reward_loss_std": 0.18057491390832833, "train/reward_max_data": 0.7083128093205062, "train/reward_max_pred": 0.2407185397124643, "train/reward_neg_acc": 0.9996190813961875, "train/reward_neg_loss": 0.002044406166676377, "train/reward_pos_acc": 0.2053053843100434, "train/reward_pos_loss": 3.8590757241877527, "train/reward_pred": 0.0012534768383702254, "train/reward_rate": 0.0022273322044334977, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.019236218184232712, "report/cont_loss_std": 0.2951650619506836, "report/cont_neg_acc": 0.5714285969734192, "report/cont_neg_loss": 2.355785846710205, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003153774421662092, "report/cont_pred": 0.9934797286987305, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07017266005277634, "report/image_loss_std": 0.09233443439006805, "report/model_loss_mean": 0.6955504417419434, "report/model_loss_std": 0.3820343315601349, "report/post_ent_mag": 34.206947326660156, "report/post_ent_max": 34.206947326660156, "report/post_ent_mean": 33.84381103515625, "report/post_ent_min": 33.563560485839844, "report/post_ent_std": 0.14871633052825928, "report/prior_ent_mag": 34.945289611816406, "report/prior_ent_max": 34.945289611816406, "report/prior_ent_mean": 33.74019241333008, "report/prior_ent_min": 32.31910705566406, "report/prior_ent_std": 0.33614659309387207, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007049560663290322, "report/reward_loss_mean": 0.0061415256932377815, "report/reward_loss_std": 0.137186199426651, "report/reward_max_data": 0.721875011920929, "report/reward_max_pred": 0.05911433696746826, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.001859480980783701, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.386673927307129, "report/reward_pred": 0.0009876476833596826, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.029437463730573654, "eval/cont_loss_std": 0.34107375144958496, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.3469462394714355, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003990457858890295, "eval/cont_pred": 0.9960170984268188, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08866355568170547, "eval/image_loss_std": 0.10762274265289307, "eval/model_loss_mean": 0.7462320327758789, "eval/model_loss_std": 0.7083312273025513, "eval/post_ent_mag": 34.207130432128906, "eval/post_ent_max": 34.207130432128906, "eval/post_ent_mean": 33.84010314941406, "eval/post_ent_min": 33.531349182128906, "eval/post_ent_std": 0.14973115921020508, "eval/prior_ent_mag": 34.604522705078125, "eval/prior_ent_max": 34.604522705078125, "eval/prior_ent_mean": 33.68427276611328, "eval/prior_ent_min": 32.781314849853516, "eval/prior_ent_std": 0.31256163120269775, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0030609131790697575, "eval/reward_loss_mean": 0.028130948543548584, "eval/reward_loss_std": 0.3671465814113617, "eval/reward_max_data": 0.7437499761581421, "eval/reward_max_pred": 0.11745774745941162, "eval/reward_neg_acc": 0.999018669128418, "eval/reward_neg_loss": 0.0024380336981266737, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.264346599578857, "eval/reward_pred": 0.0013192362384870648, "eval/reward_rate": 0.0048828125, "replay/size": 967857.0, "replay/inserts": 32544.0, "replay/samples": 32544.0, "replay/insert_wait_avg": 1.2927819611165844e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.650361651867892e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0967936391144796e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0492417812347, "timer/env.step_count": 4068.0, "timer/env.step_total": 38.406872510910034, "timer/env.step_frac": 0.038404981381218534, "timer/env.step_avg": 0.009441217431393813, "timer/env.step_min": 0.007617473602294922, "timer/env.step_max": 0.03995871543884277, "timer/replay._sample_count": 32544.0, "timer/replay._sample_total": 16.574597358703613, "timer/replay._sample_frac": 0.016573781236193748, "timer/replay._sample_avg": 0.0005092980997635083, "timer/replay._sample_min": 0.0003948211669921875, "timer/replay._sample_max": 0.010502099990844727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4680.0, "timer/agent.policy_total": 48.24203014373779, "timer/agent.policy_frac": 0.04823965473721238, "timer/agent.policy_avg": 0.010308126099089272, "timer/agent.policy_min": 0.007956266403198242, "timer/agent.policy_max": 0.08428239822387695, "timer/dataset_train_count": 2034.0, "timer/dataset_train_total": 0.21553707122802734, "timer/dataset_train_frac": 0.00021552645832131637, "timer/dataset_train_avg": 0.00010596709499903016, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.00035071372985839844, "timer/agent.train_count": 2034.0, "timer/agent.train_total": 901.4633691310883, "timer/agent.train_frac": 0.9014189816547927, "timer/agent.train_avg": 0.44319732995628724, "timer/agent.train_min": 0.43300771713256836, "timer/agent.train_max": 0.6623854637145996, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47417473793029785, "timer/agent.report_frac": 0.00047415138987128567, "timer/agent.report_avg": 0.23708736896514893, "timer/agent.report_min": 0.23045897483825684, "timer/agent.report_max": 0.24371576309204102, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.894371032714844e-05, "timer/dataset_eval_frac": 9.89388384025122e-08, "timer/dataset_eval_avg": 9.894371032714844e-05, "timer/dataset_eval_min": 9.894371032714844e-05, "timer/dataset_eval_max": 9.894371032714844e-05, "fps": 32.54182350238241}
{"step": 968392, "time": 30272.743195295334, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 968400, "time": 30273.25906419754, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 968432, "time": 30274.23845911026, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 968664, "time": 30280.995715618134, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 968696, "time": 30281.959933519363, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 968744, "time": 30283.400386095047, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 968808, "time": 30285.358364343643, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 969096, "time": 30294.144310951233, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 969136, "time": 30295.574035406113, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 969432, "time": 30304.388076543808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969472, "time": 30305.817552804947, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 969496, "time": 30306.328597068787, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 969624, "time": 30310.195964813232, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 969664, "time": 30311.62267971039, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 969728, "time": 30313.576936244965, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 969752, "time": 30314.085139751434, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 30322.442239761353, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 970008, "time": 30322.58632326126, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 970008, "time": 30323.54112458229, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 970008, "time": 30323.91145658493, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 970008, "time": 30324.355246067047, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 970008, "time": 30324.43036723137, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 970008, "time": 30324.43922686577, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 970008, "time": 30324.958207130432, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 970264, "time": 30332.656564950943, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 970360, "time": 30335.54173207283, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 970544, "time": 30341.302828788757, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 970640, "time": 30344.186316490173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 970664, "time": 30344.690382242203, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 970696, "time": 30345.670034885406, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 970976, "time": 30354.458718538284, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 971232, "time": 30362.207408189774, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 971696, "time": 30376.204921483994, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 971800, "time": 30379.137549638748, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 971808, "time": 30379.602831363678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 971976, "time": 30384.501299381256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972040, "time": 30386.425469636917, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 972040, "time": 30386.431990146637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972504, "time": 30400.40561413765, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 972576, "time": 30402.79751420021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972760, "time": 30408.15955710411, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 973008, "time": 30415.95794081688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 973216, "time": 30422.24445080757, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 973288, "time": 30424.229335546494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 973728, "time": 30437.7729139328, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 973728, "time": 30437.77994298935, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 973800, "time": 30439.74868631363, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 973896, "time": 30442.771632909775, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 974056, "time": 30447.617392539978, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 974064, "time": 30448.08374929428, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 974120, "time": 30449.560784578323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 974288, "time": 30454.893572330475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 974352, "time": 30456.860654354095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 974400, "time": 30458.310725927353, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 974712, "time": 30467.526294231415, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 974736, "time": 30468.46882748604, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 974760, "time": 30468.977120637894, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 974792, "time": 30469.94568347931, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 974896, "time": 30473.889399290085, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 975264, "time": 30484.98626089096, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 975456, "time": 30490.77947330475, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 975472, "time": 30491.28915786743, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 975520, "time": 30492.742643117905, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 975680, "time": 30497.57795548439, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 976000, "time": 30507.498552322388, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 976040, "time": 30508.502390146255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 976048, "time": 30508.971148490906, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 976208, "time": 30513.84094429016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 976304, "time": 30516.743357658386, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 976520, "time": 30523.07629084587, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 976848, "time": 30533.347089529037, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 977008, "time": 30538.19028186798, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 977016, "time": 30538.21654009819, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 977200, "time": 30544.033539295197, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 977544, "time": 30554.22331571579, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 977576, "time": 30555.216987848282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 977680, "time": 30558.57614016533, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 977712, "time": 30559.56921839714, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 977760, "time": 30561.14271712303, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 977784, "time": 30561.658099889755, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 977784, "time": 30561.66623544693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 977872, "time": 30564.574705839157, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 978112, "time": 30571.8077647686, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 978304, "time": 30577.596784353256, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 978352, "time": 30579.070780992508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 978552, "time": 30584.891750574112, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 978984, "time": 30598.04716014862, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 979160, "time": 30603.37220931053, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 979168, "time": 30603.83936214447, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 979376, "time": 30610.142609596252, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 979856, "time": 30624.803627967834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 980024, "time": 30629.71119618416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 980040, "time": 30630.204466342926, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 980072, "time": 30631.17761158943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 30632.1229531765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 30632.583042383194, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 980096, "time": 30632.9026927948, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 980096, "time": 30633.1188249588, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 980096, "time": 30633.401839971542, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 980096, "time": 30633.78068447113, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 980096, "time": 30633.858395814896, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 980096, "time": 30634.15079855919, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 980096, "time": 30634.174218416214, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 980192, "time": 30637.071591854095, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 980336, "time": 30641.424106121063, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 980792, "time": 30655.061363220215, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 981200, "time": 30667.631013154984, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 981296, "time": 30670.573536157608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981336, "time": 30671.56787776947, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 981480, "time": 30675.925723552704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981872, "time": 30688.055124759674, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 981912, "time": 30689.041947603226, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 981952, "time": 30690.471519231796, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 982104, "time": 30694.864279031754, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 982336, "time": 30702.110232114792, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 982352, "time": 30702.6211810112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 982384, "time": 30703.59776043892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 982616, "time": 30710.477499485016, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 982648, "time": 30711.449535369873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 982672, "time": 30712.4165995121, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 982944, "time": 30720.69287633896, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 982984, "time": 30721.698814868927, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 983024, "time": 30723.17923784256, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 983168, "time": 30728.13114953041, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 983256, "time": 30730.574630975723, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 983424, "time": 30735.898169994354, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 983488, "time": 30737.86499428749, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 983592, "time": 30740.880285978317, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 983744, "time": 30745.71163201332, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 984072, "time": 30755.42632842064, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 984352, "time": 30764.119289159775, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 984384, "time": 30765.084431886673, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 984392, "time": 30765.111124038696, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 984640, "time": 30772.946803808212, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 984680, "time": 30773.934272527695, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 984864, "time": 30779.699508190155, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 985296, "time": 30792.74431657791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 985336, "time": 30793.738491773605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 985400, "time": 30795.682075738907, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 985480, "time": 30798.099292993546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 985976, "time": 30813.22608757019, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 986040, "time": 30815.175105810165, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 986232, "time": 30820.983703374863, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 986264, "time": 30821.952116250992, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 986560, "time": 30831.23525261879, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 986640, "time": 30833.65501308441, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 986640, "time": 30833.663944244385, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 986696, "time": 30835.150666952133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986952, "time": 30842.859539031982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 987104, "time": 30847.67633843422, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 987176, "time": 30849.643541574478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 987240, "time": 30851.587368011475, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 987656, "time": 30864.253551483154, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 987696, "time": 30865.679732322693, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 988000, "time": 30874.88849544525, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 988032, "time": 30875.85394001007, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 988184, "time": 30880.221256256104, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 988288, "time": 30883.584009170532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 988384, "time": 30886.45654964447, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 988408, "time": 30886.965960264206, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 988520, "time": 30890.424746990204, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 988952, "time": 30903.533348560333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 989032, "time": 30905.947498321533, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 989040, "time": 30906.41658639908, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 989064, "time": 30906.92754292488, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 989072, "time": 30907.41901063919, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 989456, "time": 30918.99935412407, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 989536, "time": 30921.54657793045, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 989872, "time": 30931.704135894775, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 990008, "time": 30935.60115337372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 30938.902671337128, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 990080, "time": 30939.240760803223, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 990080, "time": 30939.431791067123, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 990080, "time": 30939.600201368332, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 990080, "time": 30939.924624681473, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 990080, "time": 30940.558166742325, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 990080, "time": 30941.41136431694, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 990080, "time": 30941.54035949707, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 990096, "time": 30942.02408027649, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 990184, "time": 30944.46097254753, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 990328, "time": 30948.83003115654, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 990760, "time": 30961.950459480286, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 990832, "time": 30964.377349853516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 991112, "time": 30972.590069770813, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 991192, "time": 30975.02180814743, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 991384, "time": 30981.359949827194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 991504, "time": 30985.232599020004, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 991808, "time": 30994.43577480316, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 992112, "time": 31003.6685898304, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 992224, "time": 31007.048364639282, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 992280, "time": 31008.541545152664, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 992304, "time": 31009.48849439621, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 992400, "time": 31012.514497995377, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 992400, "time": 31012.521176815033, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 992440, "time": 31013.54432964325, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 992904, "time": 31027.604587316513, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 992984, "time": 31030.031789302826, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 992992, "time": 31030.498298883438, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 993072, "time": 31032.928194522858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 993120, "time": 31034.383368492126, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 993232, "time": 31037.77469277382, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 993256, "time": 31038.280748844147, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 993376, "time": 31042.205483675003, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 993392, "time": 31042.70960021019, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 993488, "time": 31045.611040592194, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 993576, "time": 31048.054083108902, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 993776, "time": 31054.30740237236, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 993920, "time": 31058.674738645554, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 993968, "time": 31060.125018835068, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 994088, "time": 31063.53635764122, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 994328, "time": 31070.87838435173, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 994424, "time": 31073.794605493546, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 994728, "time": 31083.010189056396, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 995104, "time": 31094.63799738884, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 995216, "time": 31098.060747146606, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 995304, "time": 31100.641212940216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 995344, "time": 31102.092953443527, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 995536, "time": 31107.89457845688, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 995568, "time": 31108.86918926239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 995688, "time": 31112.28140258789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 995696, "time": 31112.746401309967, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 995704, "time": 31112.77326440811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 995808, "time": 31116.153477668762, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 996040, "time": 31122.98824262619, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 996088, "time": 31124.437453985214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 996192, "time": 31127.819917440414, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 996528, "time": 31138.080620765686, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 996552, "time": 31138.587282657623, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 996568, "time": 31139.073212623596, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 996776, "time": 31145.361966848373, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 996808, "time": 31146.341870069504, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 996984, "time": 31151.6875064373, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 997232, "time": 31159.39471054077, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 997248, "time": 31159.880529880524, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 997696, "time": 31173.47584271431, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 997848, "time": 31177.852743148804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 997896, "time": 31179.329011678696, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 998080, "time": 31185.10218501091, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 998088, "time": 31185.13043642044, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 998336, "time": 31192.922887802124, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 998352, "time": 31193.429250001907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 998560, "time": 31199.692593812943, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 998840, "time": 31207.925122499466, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 998896, "time": 31209.834801197052, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 999088, "time": 31215.652903318405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999136, "time": 31217.09880423546, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 999184, "time": 31218.578255176544, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 999368, "time": 31224.053599834442, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 999520, "time": 31229.32519006729, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 999992, "time": 31243.58292555809, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1000016, "time": 31244.548605442047, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 31247.32387828827, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1000064, "time": 31247.92923784256, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1000064, "time": 31247.99182534218, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1000064, "time": 31248.20308327675, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1000064, "time": 31248.375591039658, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 1000064, "time": 31248.422740221024, "eval_episode/length": 10.0, "eval_episode/score": 0.96875, "eval_episode/reward_rate": 0.09090909090909091}
{"step": 1000064, "time": 31250.453279733658, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1000064, "time": 31250.586713552475, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 1000208, "time": 31254.945005893707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000392, "time": 31260.290519475937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000656, "time": 31268.54356622696, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1000761, "time": 31272.495332479477, "train_stats/mean_log_entropy": 0.08286635755844739, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4025000962130543, "train/action_min": 0.0, "train/action_std": 1.6513352088740307, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010955102294408188, "train/actor_opt_grad_steps": 61440.0, "train/actor_opt_loss": -14.402674999143102, "train/adv_mag": 0.7549707167254293, "train/adv_max": 0.3066969910278696, "train/adv_mean": 0.0022652125718451124, "train/adv_min": -0.7188057165427748, "train/adv_std": 0.027719127161088836, "train/cont_avg": 0.995184536637931, "train/cont_loss_mean": 0.017744449994944293, "train/cont_loss_std": 0.2394463560530191, "train/cont_neg_acc": 0.28579692480158925, "train/cont_neg_loss": 2.9732583623072375, "train/cont_pos_acc": 0.9998115371600748, "train/cont_pos_loss": 0.003757808982564384, "train/cont_pred": 0.9950366014330257, "train/cont_rate": 0.995184536637931, "train/dyn_loss_mean": 1.0000023301599061, "train/dyn_loss_std": 7.453177891570726e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17593390127561362, "train/extr_critic_critic_opt_grad_steps": 61440.0, "train/extr_critic_critic_opt_loss": 5021.987900005773, "train/extr_critic_mag": 1.2802379190040927, "train/extr_critic_max": 1.2802379190040927, "train/extr_critic_mean": 1.1888505102965632, "train/extr_critic_min": 0.9379891074936966, "train/extr_critic_std": 0.024710655964800876, "train/extr_return_normed_mag": 0.7915836989585989, "train/extr_return_normed_max": 0.313697348087292, "train/extr_return_normed_mean": 0.049664606243885794, "train/extr_return_normed_min": -0.714790243526985, "train/extr_return_normed_std": 0.03839259647897312, "train/extr_return_rate": 0.9994227557346739, "train/extr_return_raw_mag": 1.4551483733313424, "train/extr_return_raw_max": 1.4551483733313424, "train/extr_return_raw_mean": 1.1911156835227177, "train/extr_return_raw_min": 0.4266607817170655, "train/extr_return_raw_std": 0.038392596534026664, "train/extr_reward_mag": 0.30392938059539043, "train/extr_reward_max": 0.30392938059539043, "train/extr_reward_mean": 0.002089829579525595, "train/extr_reward_min": 8.221330313846983e-09, "train/extr_reward_std": 0.009681358419615647, "train/image_loss_mean": 0.07194113894709812, "train/image_loss_std": 0.0928402380659956, "train/model_loss_mean": 0.7004582523712384, "train/model_loss_std": 0.41042167274969554, "train/model_opt_grad_norm": 18.697512928802187, "train/model_opt_grad_steps": 61380.7881773399, "train/model_opt_loss": 3675.452216989301, "train/model_opt_model_opt_grad_overflow": 0.0049261083743842365, "train/model_opt_model_opt_grad_scale": 5221.674876847291, "train/policy_entropy_mag": 1.2925970407542338, "train/policy_entropy_max": 1.2925970407542338, "train/policy_entropy_mean": 0.10461615051688819, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13384266832632385, "train/policy_logprob_mag": 6.551080285621981, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10439827898746641, "train/policy_logprob_min": -6.551080285621981, "train/policy_logprob_std": 0.6407572832600824, "train/policy_randomness_mag": 0.6642635182794092, "train/policy_randomness_max": 0.6642635182794092, "train/policy_randomness_mean": 0.05376206899951831, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06878152939266172, "train/post_ent_mag": 33.98960701702851, "train/post_ent_max": 33.98960701702851, "train/post_ent_mean": 33.6029424056631, "train/post_ent_min": 33.28672082083566, "train/post_ent_std": 0.1562149676636522, "train/prior_ent_mag": 34.97142134041622, "train/prior_ent_max": 34.97142134041622, "train/prior_ent_mean": 33.84202870711904, "train/prior_ent_min": 32.603557530295085, "train/prior_ent_std": 0.3633979086218209, "train/rep_loss_mean": 1.0000023301599061, "train/rep_loss_std": 7.453177891570726e-05, "train/reward_avg": 0.0014745402136952914, "train/reward_loss_mean": 0.010771240657103692, "train/reward_loss_std": 0.17974759765620815, "train/reward_max_data": 0.6580972901999657, "train/reward_max_pred": 0.23900566371203644, "train/reward_neg_acc": 0.9996865832159672, "train/reward_neg_loss": 0.002069731618580523, "train/reward_pos_acc": 0.19287720891866791, "train/reward_pos_loss": 4.033897449461262, "train/reward_pred": 0.0012681170514660884, "train/reward_rate": 0.002169604371921182, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.03138596564531326, "report/cont_loss_std": 0.3564595878124237, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 3.938589334487915, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004492726176977158, "report/cont_pred": 0.9949910640716553, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07033848017454147, "report/image_loss_std": 0.08896344900131226, "report/model_loss_mean": 0.7182136178016663, "report/model_loss_std": 0.5745424628257751, "report/post_ent_mag": 33.9795036315918, "report/post_ent_max": 33.9795036315918, "report/post_ent_mean": 33.56108093261719, "report/post_ent_min": 33.18650817871094, "report/post_ent_std": 0.1866869479417801, "report/prior_ent_mag": 34.79433822631836, "report/prior_ent_max": 34.79433822631836, "report/prior_ent_mean": 33.585201263427734, "report/prior_ent_min": 32.34739303588867, "report/prior_ent_std": 0.4233540892601013, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023834228049963713, "report/reward_loss_mean": 0.016489163041114807, "report/reward_loss_std": 0.26481783390045166, "report/reward_max_data": 0.90625, "report/reward_max_pred": 0.05590474605560303, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002159555209800601, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.893332481384277, "report/reward_pred": 0.0011352276196703315, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.01972053200006485, "eval/cont_loss_std": 0.2323695868253708, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.7146317958831787, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00523068243637681, "eval/cont_pred": 0.9947780966758728, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09285128116607666, "eval/image_loss_std": 0.11376386135816574, "eval/model_loss_mean": 0.7333417534828186, "eval/model_loss_std": 0.5590800642967224, "eval/post_ent_mag": 33.96354675292969, "eval/post_ent_max": 33.96354675292969, "eval/post_ent_mean": 33.58167266845703, "eval/post_ent_min": 33.23736572265625, "eval/post_ent_std": 0.17156802117824554, "eval/prior_ent_mag": 34.753662109375, "eval/prior_ent_max": 34.753662109375, "eval/prior_ent_mean": 33.65492630004883, "eval/prior_ent_min": 32.36766815185547, "eval/prior_ent_std": 0.4102383852005005, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0028594969771802425, "eval/reward_loss_mean": 0.020769912749528885, "eval/reward_loss_std": 0.29472091794013977, "eval/reward_max_data": 0.8062499761581421, "eval/reward_max_pred": 0.03960275650024414, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.002333384472876787, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.7220845222473145, "eval/reward_pred": 0.001211395370773971, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32400.0, "replay/samples": 32400.0, "replay/insert_wait_avg": 1.2846787770589193e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.708131531138479e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5640.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.062822680101327e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4305808544159, "timer/env.step_count": 4050.0, "timer/env.step_total": 38.5113844871521, "timer/env.step_frac": 0.038494809359247616, "timer/env.step_avg": 0.009508983823988173, "timer/env.step_min": 0.007546186447143555, "timer/env.step_max": 0.03591275215148926, "timer/replay._sample_count": 32400.0, "timer/replay._sample_total": 16.493045330047607, "timer/replay._sample_frac": 0.016485946796989906, "timer/replay._sample_avg": 0.0005090446089520866, "timer/replay._sample_min": 0.00040030479431152344, "timer/replay._sample_max": 0.013711690902709961, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4755.0, "timer/agent.policy_total": 48.99537992477417, "timer/agent.policy_frac": 0.04897429253205131, "timer/agent.policy_avg": 0.010303970541487732, "timer/agent.policy_min": 0.008429527282714844, "timer/agent.policy_max": 0.08323931694030762, "timer/dataset_train_count": 2025.0, "timer/dataset_train_total": 0.21787285804748535, "timer/dataset_train_frac": 0.00021777908654232805, "timer/dataset_train_avg": 0.00010759153483826437, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0006928443908691406, "timer/agent.train_count": 2025.0, "timer/agent.train_total": 900.5942614078522, "timer/agent.train_frac": 0.9002066496594909, "timer/agent.train_avg": 0.44473790686807513, "timer/agent.train_min": 0.43322181701660156, "timer/agent.train_max": 0.6729967594146729, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47907233238220215, "timer/agent.report_frac": 0.0004788661417897195, "timer/agent.report_avg": 0.23953616619110107, "timer/agent.report_min": 0.2316138744354248, "timer/agent.report_max": 0.24745845794677734, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0266127530846346e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 32.385504954253435}
{"step": 1000872, "time": 31275.656484127045, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1001056, "time": 31281.626560926437, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1001120, "time": 31283.58838248253, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1001208, "time": 31286.02017235756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1001400, "time": 31291.821214199066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1001448, "time": 31293.266333818436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1001696, "time": 31300.973484516144, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1001704, "time": 31301.000343084335, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1001832, "time": 31304.875337600708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1002192, "time": 31316.073115825653, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1002368, "time": 31321.413770914078, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1002416, "time": 31322.85911798477, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1002480, "time": 31324.79530787468, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1002664, "time": 31330.126247882843, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1002856, "time": 31335.93089556694, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1002968, "time": 31339.33636188507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1003112, "time": 31343.74114227295, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1003432, "time": 31353.320862293243, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1003448, "time": 31353.80558204651, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1003480, "time": 31354.786112070084, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1003848, "time": 31365.839082956314, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1003928, "time": 31368.234018564224, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1003968, "time": 31369.679895162582, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1003992, "time": 31370.22896718979, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1004016, "time": 31371.25687122345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1004256, "time": 31378.507066249847, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1004640, "time": 31390.091148376465, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1004728, "time": 31392.513172864914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1004912, "time": 31398.274448633194, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1004936, "time": 31398.778541088104, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1004936, "time": 31398.787148475647, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1005320, "time": 31410.49698328972, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1005424, "time": 31413.8784365654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1005704, "time": 31422.087643384933, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1005744, "time": 31423.54295372963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1005880, "time": 31427.436228513718, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1005888, "time": 31427.90180206299, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1006008, "time": 31431.37331366539, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1006184, "time": 31436.681971788406, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1006224, "time": 31438.118409633636, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1006704, "time": 31452.58890104294, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1007040, "time": 31462.826335430145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1007112, "time": 31464.783714532852, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1007120, "time": 31465.2559902668, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1007224, "time": 31468.20165038109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1007248, "time": 31469.152678728104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1007528, "time": 31477.40445137024, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1007560, "time": 31478.372529745102, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1007824, "time": 31487.065389871597, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1007872, "time": 31488.51827955246, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1008008, "time": 31492.535960674286, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1008040, "time": 31493.505223751068, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1008048, "time": 31493.973667383194, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 1008056, "time": 31494.001319646835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1008360, "time": 31503.201860904694, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1008584, "time": 31509.990899801254, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1008808, "time": 31516.78825712204, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1009024, "time": 31523.657977104187, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1009056, "time": 31524.635367631912, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1009280, "time": 31531.443335294724, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1009432, "time": 31535.82338666916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1009632, "time": 31542.15905022621, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1009840, "time": 31548.497830867767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 31556.066823720932, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1010048, "time": 31556.248529195786, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1010048, "time": 31557.4870762825, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1010048, "time": 31557.813301563263, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 1010048, "time": 31558.080748319626, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 1010048, "time": 31559.612087011337, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1010048, "time": 31560.286994457245, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 1010048, "time": 31560.81747674942, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 31560.823253154755, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 31560.829288244247, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010248, "time": 31566.649883270264, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1010360, "time": 31570.029931783676, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1010360, "time": 31570.03762626648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1010432, "time": 31572.411951065063, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1010488, "time": 31573.87146282196, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1010536, "time": 31575.333308935165, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1010856, "time": 31585.067885637283, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1010896, "time": 31586.497737169266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1010936, "time": 31587.498491048813, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1011232, "time": 31596.760767698288, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1011368, "time": 31600.653037786484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1011512, "time": 31605.005509853363, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1011712, "time": 31611.32046198845, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1011944, "time": 31618.08934736252, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1012056, "time": 31621.469305753708, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1012672, "time": 31640.42382788658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012744, "time": 31642.394402742386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1013008, "time": 31650.6193523407, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1013040, "time": 31651.58984041214, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1013056, "time": 31652.075695991516, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1013168, "time": 31655.459717273712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1013544, "time": 31666.57274746895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1013600, "time": 31668.50039958954, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1013824, "time": 31675.36468243599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1014016, "time": 31681.119433403015, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1014024, "time": 31681.146062612534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1014176, "time": 31685.940351486206, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1014256, "time": 31688.363041877747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1014440, "time": 31693.712565422058, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1014712, "time": 31702.069835424423, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1014728, "time": 31702.55930542946, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1014792, "time": 31704.48656129837, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1015152, "time": 31715.615012168884, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1015248, "time": 31718.505656003952, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1015440, "time": 31724.29558157921, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1015456, "time": 31724.78197312355, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1015520, "time": 31726.738703250885, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1015856, "time": 31737.367566108704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1016200, "time": 31747.542220830917, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1016328, "time": 31751.437093496323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1016336, "time": 31751.90912938118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1016416, "time": 31754.35000896454, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1016440, "time": 31754.88212108612, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1017200, "time": 31778.267386436462, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1017400, "time": 31784.140742778778, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 1017464, "time": 31786.077880382538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1017832, "time": 31797.32851099968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018376, "time": 31813.783541202545, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1018512, "time": 31818.1530649662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018640, "time": 31822.16403245926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018648, "time": 31822.191793441772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018728, "time": 31824.63700556755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018744, "time": 31825.126052618027, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1019128, "time": 31836.724853038788, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1019416, "time": 31845.473445653915, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1019512, "time": 31848.381873607635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1019776, "time": 31856.671893119812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1019880, "time": 31859.61802625656, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1019920, "time": 31861.05571913719, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1020032, "time": 31865.686640024185, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1020032, "time": 31865.800483226776, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1020032, "time": 31866.203530311584, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1020032, "time": 31866.722910642624, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1020032, "time": 31866.85239505768, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1020032, "time": 31867.844128608704, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1020032, "time": 31868.99081015587, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1020032, "time": 31869.87859749794, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1020032, "time": 31869.885118961334, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1020032, "time": 31869.890667438507, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1020032, "time": 31869.896213293076, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1020080, "time": 31871.365409851074, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1020144, "time": 31873.334606170654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1020192, "time": 31874.79877758026, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1020208, "time": 31875.28876399994, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1020504, "time": 31884.13189125061, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1020632, "time": 31888.011021375656, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1020736, "time": 31891.36626982689, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1020904, "time": 31896.26005411148, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1020920, "time": 31896.77046918869, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1020952, "time": 31897.74857401848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1020960, "time": 31898.21790242195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1021024, "time": 31900.1545650959, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1021040, "time": 31900.646160125732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1021336, "time": 31909.42930150032, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1021528, "time": 31915.36806511879, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1021528, "time": 31915.37419652939, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1021584, "time": 31917.31393480301, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1021616, "time": 31918.283585071564, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1021744, "time": 31922.16296362877, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1021880, "time": 31926.11788392067, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1022192, "time": 31935.79025864601, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1022232, "time": 31936.775553941727, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1022304, "time": 31939.16874551773, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1022448, "time": 31943.600884199142, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1022456, "time": 31943.627120256424, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1022888, "time": 31956.694259643555, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1022976, "time": 31959.576321601868, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1023112, "time": 31963.466835021973, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1023192, "time": 31965.882442474365, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1023232, "time": 31967.30709385872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1023392, "time": 31972.22546029091, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1023840, "time": 31985.787719249725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1023968, "time": 31989.70898747444, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1024192, "time": 31996.987104654312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1024504, "time": 32006.253921985626, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1024584, "time": 32008.65904712677, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1024768, "time": 32014.43033695221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1024808, "time": 32015.415117025375, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1025424, "time": 32034.211007356644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1025488, "time": 32036.138871908188, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1025544, "time": 32037.61271095276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1025632, "time": 32040.506810188293, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1026152, "time": 32055.960537433624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1026352, "time": 32062.32069659233, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1026352, "time": 32062.326322078705, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1026736, "time": 32073.91885995865, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1026816, "time": 32076.317579746246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1026896, "time": 32078.739846229553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1027120, "time": 32085.508322954178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1027384, "time": 32093.36156129837, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1027784, "time": 32105.482274532318, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1027904, "time": 32109.324167728424, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1028328, "time": 32122.015640497208, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 1028336, "time": 32122.48043179512, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1028664, "time": 32132.13535451889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1028696, "time": 32133.098123311996, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1028808, "time": 32136.478534936905, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1029080, "time": 32144.69545674324, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1029128, "time": 32146.140248537064, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 1029184, "time": 32148.048310279846, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1029328, "time": 32152.51633310318, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1029336, "time": 32152.542612552643, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1029440, "time": 32155.909731149673, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1029480, "time": 32156.89757514, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1029568, "time": 32159.80981850624, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1029696, "time": 32163.676849126816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1029880, "time": 32169.055893182755, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1030016, "time": 32175.12725162506, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1030016, "time": 32175.168325185776, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1030016, "time": 32175.52230811119, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1030016, "time": 32175.886233091354, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1030016, "time": 32176.50462412834, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 1030016, "time": 32177.176741600037, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1030016, "time": 32177.533672571182, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1030016, "time": 32177.94042801857, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1030080, "time": 32179.881451129913, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1030264, "time": 32185.30193901062, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1030696, "time": 32198.30181121826, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1031152, "time": 32212.31141757965, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1031392, "time": 32219.518498182297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1031752, "time": 32230.158955574036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1031792, "time": 32231.612295627594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1032008, "time": 32237.888848781586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1032064, "time": 32239.790491342545, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1032392, "time": 32250.01241159439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1032576, "time": 32255.808640241623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1032816, "time": 32263.101271867752, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1032968, "time": 32267.466423273087, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1033008, "time": 32268.900421619415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1033088, "time": 32271.401783943176, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1033113, "time": 32272.95879292488, "train_stats/mean_log_entropy": 0.0873917566941065, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.398736632696473, "train/action_min": 0.0, "train/action_std": 1.6143528990226217, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010924269173220537, "train/actor_opt_grad_steps": 63465.0, "train/actor_opt_loss": -14.893664286868407, "train/adv_mag": 0.7620445239071799, "train/adv_max": 0.3558223336049826, "train/adv_mean": 0.0017262779161021423, "train/adv_min": -0.6936315554793518, "train/adv_std": 0.026534030707276397, "train/cont_avg": 0.9949479811262376, "train/cont_loss_mean": 0.018677163801137542, "train/cont_loss_std": 0.24585729976885462, "train/cont_neg_acc": 0.2670645681717018, "train/cont_neg_loss": 2.939451208874329, "train/cont_pos_acc": 0.9999028028237937, "train/cont_pos_loss": 0.0037532007525730325, "train/cont_pred": 0.9949806816507094, "train/cont_rate": 0.9949479811262376, "train/dyn_loss_mean": 1.000002119800832, "train/dyn_loss_std": 5.19952844853725e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1915392336426395, "train/extr_critic_critic_opt_grad_steps": 63465.0, "train/extr_critic_critic_opt_loss": 5362.908676902846, "train/extr_critic_mag": 1.3281695004737024, "train/extr_critic_max": 1.3281695004737024, "train/extr_critic_mean": 1.2177046301341292, "train/extr_critic_min": 0.901929249267767, "train/extr_critic_std": 0.02502460637600115, "train/extr_return_normed_mag": 0.7852151039803382, "train/extr_return_normed_max": 0.33960880324392034, "train/extr_return_normed_mean": 0.04933889832642704, "train/extr_return_normed_min": -0.6924120240872449, "train/extr_return_normed_std": 0.037544214470994354, "train/extr_return_rate": 0.999636158494666, "train/extr_return_raw_mag": 1.5097007633435844, "train/extr_return_raw_max": 1.5097007633435844, "train/extr_return_raw_mean": 1.219430919330899, "train/extr_return_raw_min": 0.47767993601241915, "train/extr_return_raw_std": 0.03754421433267912, "train/extr_reward_mag": 0.3177393704357714, "train/extr_reward_max": 0.3177393704357714, "train/extr_reward_mean": 0.0018885533912061244, "train/extr_reward_min": 2.419594490882194e-08, "train/extr_reward_std": 0.009363522319731737, "train/image_loss_mean": 0.07089214491667134, "train/image_loss_std": 0.09172579428494566, "train/model_loss_mean": 0.7017493681742413, "train/model_loss_std": 0.4339826321321549, "train/model_opt_grad_norm": 18.304813857125765, "train/model_opt_grad_steps": 63403.86138613861, "train/model_opt_loss": 3715.2204033879952, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5297.029702970297, "train/policy_entropy_mag": 1.3142270917939667, "train/policy_entropy_max": 1.3142270917939667, "train/policy_entropy_mean": 0.10642558896895682, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13759300522137397, "train/policy_logprob_mag": 6.551080262306893, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10667217375323323, "train/policy_logprob_min": -6.551080262306893, "train/policy_logprob_std": 0.644391657102226, "train/policy_randomness_mag": 0.6753791629677952, "train/policy_randomness_max": 0.6753791629677952, "train/policy_randomness_mean": 0.05469193669165125, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07070882192416357, "train/post_ent_mag": 33.99354776061407, "train/post_ent_max": 33.99354776061407, "train/post_ent_mean": 33.522310313611925, "train/post_ent_min": 33.120009875533604, "train/post_ent_std": 0.19688583563755055, "train/prior_ent_mag": 34.31293731160683, "train/prior_ent_max": 34.31293731160683, "train/prior_ent_mean": 33.32766994627396, "train/prior_ent_min": 32.19496075469669, "train/prior_ent_std": 0.32528541524811544, "train/rep_loss_mean": 1.000002119800832, "train/rep_loss_std": 5.19952844853725e-05, "train/reward_avg": 0.0016839357815097353, "train/reward_loss_mean": 0.012178764283186802, "train/reward_loss_std": 0.19842653749925593, "train/reward_max_data": 0.71913675831096, "train/reward_max_pred": 0.2368239488932166, "train/reward_neg_acc": 0.9996462266634006, "train/reward_neg_loss": 0.002148855923061803, "train/reward_pos_acc": 0.17927928091706458, "train/reward_pos_loss": 4.051620108372457, "train/reward_pred": 0.0013159755392617887, "train/reward_rate": 0.002465578589108911, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.015217844396829605, "report/cont_loss_std": 0.21769434213638306, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.1170928478240967, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004904425702989101, "report/cont_pred": 0.9929200410842896, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05305005982518196, "report/image_loss_std": 0.08113079518079758, "report/model_loss_mean": 0.6757086515426636, "report/model_loss_std": 0.33827322721481323, "report/post_ent_mag": 33.800315856933594, "report/post_ent_max": 33.800315856933594, "report/post_ent_mean": 33.317962646484375, "report/post_ent_min": 32.85554504394531, "report/post_ent_std": 0.1973840594291687, "report/prior_ent_mag": 34.226341247558594, "report/prior_ent_max": 34.226341247558594, "report/prior_ent_mean": 33.45317840576172, "report/prior_ent_min": 32.51590347290039, "report/prior_ent_std": 0.2923206388950348, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001312255859375, "report/reward_loss_mean": 0.007440679706633091, "report/reward_loss_std": 0.1520785540342331, "report/reward_max_data": 0.768750011920929, "report/reward_max_pred": 0.758643627166748, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0020419200882315636, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.766206979751587, "report/reward_pred": 0.0017615386750549078, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.029018918052315712, "eval/cont_loss_std": 0.41959235072135925, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.120691299438477, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.005130006931722164, "eval/cont_pred": 0.9949386119842529, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09494658559560776, "eval/image_loss_std": 0.11637125164270401, "eval/model_loss_mean": 0.7360377907752991, "eval/model_loss_std": 0.5646408200263977, "eval/post_ent_mag": 33.79981994628906, "eval/post_ent_max": 33.79981994628906, "eval/post_ent_mean": 33.343528747558594, "eval/post_ent_min": 32.86591720581055, "eval/post_ent_std": 0.1995047926902771, "eval/prior_ent_mag": 34.25031280517578, "eval/prior_ent_max": 34.25031280517578, "eval/prior_ent_mean": 33.46253967285156, "eval/prior_ent_min": 32.463863372802734, "eval/prior_ent_std": 0.2736342251300812, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0016418457962572575, "eval/reward_loss_mean": 0.012072273530066013, "eval/reward_loss_std": 0.23126468062400818, "eval/reward_max_data": 0.878125011920929, "eval/reward_max_pred": 0.09804165363311768, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0018580913310870528, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.23151969909668, "eval/reward_pred": 0.0009437225526198745, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32352.0, "replay/samples": 32352.0, "replay/insert_wait_avg": 1.1988286330603232e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.541373033080209e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6616.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0733160459433097e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3872857093811, "timer/env.step_count": 4044.0, "timer/env.step_total": 38.64577078819275, "timer/env.step_frac": 0.038630809627682124, "timer/env.step_avg": 0.009556323142480897, "timer/env.step_min": 0.007690906524658203, "timer/env.step_max": 0.03758096694946289, "timer/replay._sample_count": 32352.0, "timer/replay._sample_total": 16.49614930152893, "timer/replay._sample_frac": 0.01648976305194783, "timer/replay._sample_avg": 0.0005098958117435995, "timer/replay._sample_min": 0.00040221214294433594, "timer/replay._sample_max": 0.014254093170166016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4871.0, "timer/agent.policy_total": 50.386043071746826, "timer/agent.policy_frac": 0.050366536831800854, "timer/agent.policy_avg": 0.01034408603402727, "timer/agent.policy_min": 0.00890207290649414, "timer/agent.policy_max": 0.08279800415039062, "timer/dataset_train_count": 2022.0, "timer/dataset_train_total": 0.22034692764282227, "timer/dataset_train_frac": 0.00022026162346372967, "timer/dataset_train_avg": 0.00010897474166311684, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0003452301025390625, "timer/agent.train_count": 2022.0, "timer/agent.train_total": 897.8821659088135, "timer/agent.train_frac": 0.8975345635986561, "timer/agent.train_avg": 0.444056461873795, "timer/agent.train_min": 0.43329453468322754, "timer/agent.train_max": 0.6660394668579102, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47835707664489746, "timer/agent.report_frac": 0.00047817188750623853, "timer/agent.report_avg": 0.23917853832244873, "timer/agent.report_min": 0.23294854164123535, "timer/agent.report_max": 0.2454085350036621, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074408995741313e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 32.338869635757895}
{"step": 1033168, "time": 32274.605274438858, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1033464, "time": 32283.346759557724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1033584, "time": 32287.21399831772, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1033704, "time": 32290.626406431198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1033712, "time": 32291.111726760864, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1033920, "time": 32297.381641626358, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1034104, "time": 32302.785822868347, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1034320, "time": 32309.512181282043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1034408, "time": 32311.936980485916, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1034888, "time": 32326.40887284279, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1035112, "time": 32333.30709862709, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 1035200, "time": 32336.223588228226, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1035296, "time": 32339.126841783524, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1035336, "time": 32340.13789486885, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1035528, "time": 32345.957962036133, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1035648, "time": 32349.80821967125, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1035648, "time": 32349.81627202034, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1035840, "time": 32355.633199691772, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1035896, "time": 32357.105892896652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1036024, "time": 32361.11118555069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1036056, "time": 32362.07452750206, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1036416, "time": 32373.161597013474, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1036592, "time": 32378.563828229904, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1036832, "time": 32385.871663570404, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1036936, "time": 32388.839656829834, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1036936, "time": 32388.848843336105, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1037352, "time": 32401.546189308167, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1037376, "time": 32402.492304086685, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1037424, "time": 32403.966047525406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1037648, "time": 32410.736822605133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1037720, "time": 32412.703212976456, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1037840, "time": 32416.5287399292, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1037960, "time": 32419.938400030136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1038056, "time": 32422.937203645706, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1038064, "time": 32423.403292179108, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1038096, "time": 32424.375265598297, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1038384, "time": 32433.089881181717, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1038520, "time": 32436.990901708603, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 1038632, "time": 32440.366480588913, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1038720, "time": 32443.25668811798, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1038824, "time": 32446.195937633514, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1038976, "time": 32451.149781942368, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1038984, "time": 32451.17723464966, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1039576, "time": 32469.09354519844, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1039592, "time": 32469.579701423645, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1039616, "time": 32470.529297351837, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1039744, "time": 32474.409491300583, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1040000, "time": 32483.01961016655, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1040000, "time": 32483.316876411438, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1040000, "time": 32484.07830452919, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1040000, "time": 32484.367698431015, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1040000, "time": 32484.431204319, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1040000, "time": 32485.024030923843, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1040000, "time": 32485.70222067833, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1040000, "time": 32486.508543252945, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1040008, "time": 32486.534414052963, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1040152, "time": 32490.951900959015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1040400, "time": 32499.139917612076, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1040408, "time": 32499.168526887894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1040832, "time": 32512.307413578033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1041128, "time": 32521.025964021683, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1041128, "time": 32521.03265452385, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1041136, "time": 32521.50217151642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1041320, "time": 32526.92511153221, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1041560, "time": 32534.209795236588, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1041728, "time": 32539.510215997696, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1041840, "time": 32543.004097223282, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1041888, "time": 32544.47593140602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1041928, "time": 32545.46989440918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1042288, "time": 32556.55774617195, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1042320, "time": 32557.526294469833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1042536, "time": 32563.833971738815, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1042744, "time": 32570.10535645485, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1042784, "time": 32571.629029273987, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1042824, "time": 32572.62568473816, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1042880, "time": 32574.555155992508, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1042920, "time": 32575.550354003906, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1043120, "time": 32581.85280776024, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1043136, "time": 32582.340804815292, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1043280, "time": 32586.719686985016, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1043440, "time": 32591.547699451447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1043592, "time": 32595.928856611252, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1043648, "time": 32597.854234933853, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1043984, "time": 32608.115888118744, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1044128, "time": 32612.477164030075, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1044256, "time": 32616.331076145172, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1044384, "time": 32620.20605635643, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1044552, "time": 32625.062730550766, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1044632, "time": 32627.487377405167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1045056, "time": 32640.674159765244, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1045320, "time": 32648.458359003067, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1045480, "time": 32653.303095579147, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1045592, "time": 32656.703718662262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1045816, "time": 32663.552117347717, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1045888, "time": 32665.969643354416, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1045904, "time": 32666.458116054535, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1045904, "time": 32666.464891433716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1045920, "time": 32666.956805944443, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1045992, "time": 32668.91139268875, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1046048, "time": 32670.85686326027, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1046184, "time": 32674.73388028145, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1046456, "time": 32682.95501446724, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1046520, "time": 32684.91035437584, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1046728, "time": 32691.299449920654, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1046752, "time": 32692.247200250626, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1047120, "time": 32703.432226896286, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1047280, "time": 32708.372136831284, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1047352, "time": 32710.344408273697, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1047360, "time": 32710.81178164482, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1047384, "time": 32711.317924261093, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1047456, "time": 32713.70965909958, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1047672, "time": 32720.049732923508, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1047816, "time": 32724.547564268112, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1048000, "time": 32730.33868956566, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1048056, "time": 32731.82645225525, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1048200, "time": 32736.208335638046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1048232, "time": 32737.17923092842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1048352, "time": 32741.047721862793, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1048368, "time": 32741.53511071205, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1048376, "time": 32741.56166625023, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1048536, "time": 32746.415498256683, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1048568, "time": 32747.37832736969, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1048800, "time": 32755.213703632355, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1048816, "time": 32755.703238010406, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1049136, "time": 32765.401020288467, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1049320, "time": 32770.771936416626, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1049680, "time": 32782.06011509895, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1050064, "time": 32793.72975897789, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1050088, "time": 32794.358580350876, "eval_episode/length": 5.0, "eval_episode/score": 0.984375, "eval_episode/reward_rate": 0.16666666666666666}
{"step": 1050088, "time": 32795.145107746124, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1050088, "time": 32795.16838932037, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1050088, "time": 32796.161969184875, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1050088, "time": 32796.98219656944, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1050088, "time": 32796.9913418293, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1050088, "time": 32797.07509422302, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1050088, "time": 32797.194276571274, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1050312, "time": 32803.98021483421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050512, "time": 32810.31835317612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050544, "time": 32811.3412566185, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1050608, "time": 32813.288162231445, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1050664, "time": 32814.787365436554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050688, "time": 32815.770325660706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050848, "time": 32820.704778671265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050968, "time": 32824.147535562515, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1051040, "time": 32826.59092092514, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1051280, "time": 32833.93780255318, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1051448, "time": 32838.804834127426, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1051512, "time": 32840.86736249924, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1051784, "time": 32849.21829652786, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1051992, "time": 32855.55574440956, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1052032, "time": 32856.99591875076, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1052304, "time": 32865.289737463, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1052456, "time": 32869.668349027634, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1052576, "time": 32873.608661174774, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1052768, "time": 32879.430342674255, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1052808, "time": 32880.42667937279, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1053000, "time": 32886.23265838623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1053096, "time": 32889.14892220497, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1053280, "time": 32894.92976331711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1053416, "time": 32898.88495993614, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1053560, "time": 32903.40897655487, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1053592, "time": 32904.38927316666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1053664, "time": 32906.79086995125, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1053704, "time": 32907.7827603817, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1053744, "time": 32909.23408675194, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1053872, "time": 32913.10591506958, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1053928, "time": 32914.57687449455, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1054208, "time": 32923.30522656441, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1054280, "time": 32925.26090884209, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1054456, "time": 32930.72749686241, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1054536, "time": 32933.162491083145, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1054616, "time": 32935.602365255356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1054824, "time": 32941.9436173439, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1054880, "time": 32943.88548731804, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1054960, "time": 32946.31393313408, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1054968, "time": 32946.3420279026, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1055024, "time": 32948.287685871124, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1055088, "time": 32950.24905824661, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1055624, "time": 32966.42648935318, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1055632, "time": 32966.91059589386, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1055776, "time": 32971.25307703018, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 1056016, "time": 32978.51414823532, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1056184, "time": 32983.37135028839, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1056368, "time": 32989.161957502365, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1056592, "time": 32996.071249723434, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1056744, "time": 33000.422840595245, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1056784, "time": 33002.376163482666, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1056928, "time": 33006.73986983299, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1057272, "time": 33016.99920153618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1057320, "time": 33018.47768139839, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1057400, "time": 33021.064934015274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1057656, "time": 33028.87884712219, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1057712, "time": 33030.81263041496, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1058008, "time": 33039.5208864212, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1058080, "time": 33041.92747569084, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1058088, "time": 33041.955151319504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1058168, "time": 33044.36723160744, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1058264, "time": 33047.30666708946, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1058320, "time": 33049.22249364853, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1058328, "time": 33049.25393533707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1058496, "time": 33054.68178987503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1058704, "time": 33061.003398895264, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1058800, "time": 33063.93081736565, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 1058976, "time": 33069.259212970734, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1059376, "time": 33081.47829627991, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1060072, "time": 33103.95477223396, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1060072, "time": 33104.21943116188, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1060072, "time": 33104.357357263565, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1060072, "time": 33104.518077373505, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1060072, "time": 33105.0382373333, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 1060072, "time": 33105.14985394478, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1060072, "time": 33105.174021959305, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1060072, "time": 33105.623634815216, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1060328, "time": 33113.51001787186, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1060400, "time": 33115.90109825134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1060480, "time": 33118.32670760155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1060576, "time": 33121.22875714302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1060640, "time": 33123.18040275574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1060808, "time": 33128.04019021988, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1061016, "time": 33134.325662612915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1061112, "time": 33137.24021553993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1061288, "time": 33142.65165734291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1061384, "time": 33145.544994831085, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1061472, "time": 33148.43501830101, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1061728, "time": 33156.19288825989, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1061952, "time": 33162.995970249176, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1062024, "time": 33164.94583129883, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1062152, "time": 33168.81769180298, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1062168, "time": 33169.31051445007, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1062368, "time": 33175.72014427185, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1062640, "time": 33183.93082857132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1062928, "time": 33192.65120792389, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1063008, "time": 33195.07745575905, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1063008, "time": 33195.08465886116, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1063096, "time": 33197.54954242706, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1063272, "time": 33203.035751104355, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1063448, "time": 33208.37662029266, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1063472, "time": 33209.35163855553, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1063864, "time": 33221.01294541359, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1064224, "time": 33232.219073057175, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1064336, "time": 33235.61246728897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1064368, "time": 33236.577480793, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1064464, "time": 33239.47539448738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1064464, "time": 33239.48367381096, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1064568, "time": 33242.39521932602, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1064768, "time": 33248.69747042656, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1064864, "time": 33251.60055446625, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 1064952, "time": 33254.05390930176, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1065296, "time": 33265.21792602539, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1065488, "time": 33271.00740289688, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1065529, "time": 33273.17067742348, "train_stats/mean_log_entropy": 0.08762505027440796, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.366943359375, "train/action_min": 0.0, "train/action_std": 1.6365107516250987, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011888821305024742, "train/actor_opt_grad_steps": 65485.0, "train/actor_opt_loss": -16.476166242420085, "train/adv_mag": 0.858489865418708, "train/adv_max": 0.36808591195852447, "train/adv_mean": 0.0021069495978803623, "train/adv_min": -0.7880311782407289, "train/adv_std": 0.028043886028820336, "train/cont_avg": 0.9948464573019802, "train/cont_loss_mean": 0.019430252808690218, "train/cont_loss_std": 0.2473153393245348, "train/cont_neg_acc": 0.24002990049153272, "train/cont_neg_loss": 2.9835878795077377, "train/cont_pos_acc": 0.9998542256284468, "train/cont_pos_loss": 0.0041344228891038, "train/cont_pred": 0.9947006041460699, "train/cont_rate": 0.9948464573019802, "train/dyn_loss_mean": 1.0000000784892846, "train/dyn_loss_std": 2.499997352438951e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15023996676364454, "train/extr_critic_critic_opt_grad_steps": 65485.0, "train/extr_critic_critic_opt_loss": 8998.34320612237, "train/extr_critic_mag": 1.3878024969950762, "train/extr_critic_max": 1.3878024969950762, "train/extr_critic_mean": 1.264986516225456, "train/extr_critic_min": 0.9079557409380922, "train/extr_critic_std": 0.02656065340679471, "train/extr_return_normed_mag": 0.8821358627612048, "train/extr_return_normed_max": 0.3332770100914606, "train/extr_return_normed_mean": 0.05283697857752, "train/extr_return_normed_min": -0.7936826289290249, "train/extr_return_normed_std": 0.03919686515363726, "train/extr_return_rate": 0.9995681572668623, "train/extr_return_raw_mag": 1.5475334554615587, "train/extr_return_raw_max": 1.5475334554615587, "train/extr_return_raw_mean": 1.2670934749121714, "train/extr_return_raw_min": 0.4205738164410733, "train/extr_return_raw_std": 0.0391968651167532, "train/extr_reward_mag": 0.30586052413033965, "train/extr_reward_max": 0.30586052413033965, "train/extr_reward_mean": 0.001965910799704529, "train/extr_reward_min": 4.131014984433013e-08, "train/extr_reward_std": 0.008801358209065356, "train/image_loss_mean": 0.0718058591136838, "train/image_loss_std": 0.09299755255037015, "train/model_loss_mean": 0.7046972221077079, "train/model_loss_std": 0.4494331037201504, "train/model_opt_grad_norm": 18.061089350445435, "train/model_opt_grad_steps": 65421.94554455446, "train/model_opt_loss": 3610.7782526299507, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5123.762376237623, "train/policy_entropy_mag": 1.3146676031669768, "train/policy_entropy_max": 1.3146676031669768, "train/policy_entropy_mean": 0.1067782318459289, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13852583956305342, "train/policy_logprob_mag": 6.5510803000761735, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10687585765182382, "train/policy_logprob_min": -6.5510803000761735, "train/policy_logprob_std": 0.6438624829348951, "train/policy_randomness_mag": 0.6756055437692321, "train/policy_randomness_max": 0.6756055437692321, "train/policy_randomness_mean": 0.05487315917369163, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0711882034925246, "train/post_ent_mag": 34.05468242003186, "train/post_ent_max": 34.05468242003186, "train/post_ent_mean": 33.602720600543634, "train/post_ent_min": 33.19875970217261, "train/post_ent_std": 0.1922984160851724, "train/prior_ent_mag": 34.21972884754143, "train/prior_ent_max": 34.21972884754143, "train/prior_ent_mean": 33.09864809961602, "train/prior_ent_min": 31.993330247331375, "train/prior_ent_std": 0.3430448313160698, "train/rep_loss_mean": 1.0000000784892846, "train/rep_loss_std": 2.499997352438951e-06, "train/reward_avg": 0.0018789159177397931, "train/reward_loss_mean": 0.013461038217842948, "train/reward_loss_std": 0.20970064585124798, "train/reward_max_data": 0.7455136145252993, "train/reward_max_pred": 0.2328780169534211, "train/reward_neg_acc": 0.9995975346848516, "train/reward_neg_loss": 0.002348500463851073, "train/reward_pos_acc": 0.16728966378177385, "train/reward_pos_loss": 4.031674686800013, "train/reward_pred": 0.0014349791033442436, "train/reward_rate": 0.002741143254950495, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.018992630764842033, "report/cont_loss_std": 0.23997406661510468, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.320518970489502, "report/cont_pos_acc": 0.9990177154541016, "report/cont_pos_loss": 0.0054276431910693645, "report/cont_pred": 0.9929755330085754, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07064930349588394, "report/image_loss_std": 0.09926100075244904, "report/model_loss_mean": 0.7007097005844116, "report/model_loss_std": 0.4235370457172394, "report/post_ent_mag": 33.80497741699219, "report/post_ent_max": 33.80497741699219, "report/post_ent_mean": 33.36545944213867, "report/post_ent_min": 32.9608039855957, "report/post_ent_std": 0.1891096979379654, "report/prior_ent_mag": 34.11933135986328, "report/prior_ent_max": 34.11933135986328, "report/prior_ent_mean": 32.803199768066406, "report/prior_ent_min": 31.715599060058594, "report/prior_ent_std": 0.3693549633026123, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0013580322265625, "report/reward_loss_mean": 0.011067798361182213, "report/reward_loss_std": 0.19931942224502563, "report/reward_max_data": 0.7593749761581421, "report/reward_max_pred": 0.07597994804382324, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0023887562565505505, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.44605827331543, "report/reward_pred": 0.0012573398416861892, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.04838436096906662, "eval/cont_loss_std": 0.5827433466911316, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.725193023681641, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036850764881819487, "eval/cont_pred": 0.9959544539451599, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09196200966835022, "eval/image_loss_std": 0.1038818284869194, "eval/model_loss_mean": 0.7745049595832825, "eval/model_loss_std": 1.0502731800079346, "eval/post_ent_mag": 33.80713653564453, "eval/post_ent_max": 33.80713653564453, "eval/post_ent_mean": 33.41276550292969, "eval/post_ent_min": 33.017372131347656, "eval/post_ent_std": 0.18019399046897888, "eval/prior_ent_mag": 33.99687194824219, "eval/prior_ent_max": 33.99687194824219, "eval/prior_ent_mean": 32.892066955566406, "eval/prior_ent_min": 31.9973201751709, "eval/prior_ent_std": 0.3308613896369934, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0036285400856286287, "eval/reward_loss_mean": 0.03415858745574951, "eval/reward_loss_std": 0.5467087626457214, "eval/reward_max_data": 0.8218749761581421, "eval/reward_max_pred": 0.1284034252166748, "eval/reward_neg_acc": 0.999018669128418, "eval/reward_neg_loss": 0.0023141438141465187, "eval/reward_pos_acc": 0.20000000298023224, "eval/reward_pos_loss": 6.524056911468506, "eval/reward_pred": 0.001397800981067121, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 32416.0, "replay/samples": 32416.0, "replay/insert_wait_avg": 1.2243738414504567e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.594223083654255e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1169234750724514e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0743675231934, "timer/env.step_count": 4052.0, "timer/env.step_total": 39.09955382347107, "timer/env.step_frac": 0.03909664630272037, "timer/env.step_avg": 0.009649445662258407, "timer/env.step_min": 0.007731914520263672, "timer/env.step_max": 0.03542971611022949, "timer/replay._sample_count": 32416.0, "timer/replay._sample_total": 16.625698804855347, "timer/replay._sample_frac": 0.016624462484755933, "timer/replay._sample_avg": 0.0005128855751744616, "timer/replay._sample_min": 0.00040078163146972656, "timer/replay._sample_max": 0.0305020809173584, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4546.0, "timer/agent.policy_total": 47.772034883499146, "timer/agent.policy_frac": 0.04776848245977191, "timer/agent.policy_avg": 0.010508586643972535, "timer/agent.policy_min": 0.008587360382080078, "timer/agent.policy_max": 0.09008073806762695, "timer/dataset_train_count": 2026.0, "timer/dataset_train_total": 0.2166130542755127, "timer/dataset_train_frac": 0.00021659694649707047, "timer/dataset_train_avg": 0.000106916611192257, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0010745525360107422, "timer/agent.train_count": 2026.0, "timer/agent.train_total": 902.0935838222504, "timer/agent.train_frac": 0.9020265023454161, "timer/agent.train_avg": 0.44525843229133777, "timer/agent.train_min": 0.43379974365234375, "timer/agent.train_max": 0.6696949005126953, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4806692600250244, "timer/agent.report_frac": 0.0004806335165008385, "timer/agent.report_avg": 0.2403346300125122, "timer/agent.report_min": 0.23394370079040527, "timer/agent.report_max": 0.24672555923461914, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.218411472581261e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 32.41300529093186}
{"step": 1065864, "time": 33283.14707875252, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1065880, "time": 33283.65226006508, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1066344, "time": 33297.729288101196, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1066360, "time": 33298.23893094063, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1066504, "time": 33302.56847310066, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1066536, "time": 33303.56403565407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1066648, "time": 33306.95430612564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1066880, "time": 33314.29337978363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1067000, "time": 33317.7730948925, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1067080, "time": 33320.2777197361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1067176, "time": 33323.271597623825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1067448, "time": 33331.536856651306, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1067456, "time": 33332.01142168045, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1067456, "time": 33332.020637989044, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1067648, "time": 33337.860981702805, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1067848, "time": 33343.69502854347, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1067928, "time": 33346.10620903969, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1067968, "time": 33347.55252075195, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1068256, "time": 33356.38145852089, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1068656, "time": 33368.51569724083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1068696, "time": 33369.502407073975, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1068696, "time": 33369.511108875275, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1068768, "time": 33371.93832588196, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1068784, "time": 33372.42765212059, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1068816, "time": 33373.40443253517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1069056, "time": 33380.737292289734, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1069272, "time": 33387.03877782822, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1069352, "time": 33389.44870209694, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1069480, "time": 33393.32766866684, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1069912, "time": 33406.46083641052, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1069960, "time": 33407.92256641388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1070056, "time": 33411.726885318756, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1070056, "time": 33412.23170042038, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1070056, "time": 33412.29191279411, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1070056, "time": 33413.2087290287, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1070056, "time": 33413.575283288956, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1070056, "time": 33413.601144075394, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 1070056, "time": 33413.95073270798, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1070056, "time": 33414.86282706261, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1070120, "time": 33416.79285097122, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1070208, "time": 33419.68284082413, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1070240, "time": 33420.652109861374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1070256, "time": 33421.138436317444, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1070472, "time": 33427.50876331329, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1070832, "time": 33438.657943964005, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1070848, "time": 33439.14394402504, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1070968, "time": 33442.64500164986, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1071008, "time": 33444.08988928795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1071216, "time": 33450.365837574005, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1071352, "time": 33454.27977371216, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1071384, "time": 33455.245614767075, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1071832, "time": 33468.840096473694, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1072120, "time": 33477.64491510391, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1072272, "time": 33482.47918367386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1072424, "time": 33486.86383605003, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1072472, "time": 33488.33756828308, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1072512, "time": 33489.781854867935, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1072648, "time": 33493.68783926964, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1072664, "time": 33494.18067622185, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1072800, "time": 33498.548040151596, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1073008, "time": 33504.99274659157, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1073144, "time": 33508.91963672638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1073200, "time": 33511.33255004883, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1073528, "time": 33521.05613350868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1073920, "time": 33533.256006240845, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1074064, "time": 33537.61592531204, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1074144, "time": 33540.03206157684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1074184, "time": 33541.0232963562, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1074264, "time": 33543.463888168335, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1074512, "time": 33551.230615377426, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1074584, "time": 33553.193595170975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1074832, "time": 33561.09649467468, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1074920, "time": 33563.52989459038, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1074960, "time": 33564.97492837906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1074992, "time": 33565.96438217163, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1075000, "time": 33565.99063658714, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1075024, "time": 33566.94006347656, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1075320, "time": 33575.68621468544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1075328, "time": 33576.153468608856, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1075424, "time": 33579.05593752861, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1075456, "time": 33580.02626943588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1075512, "time": 33581.52395892143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1075624, "time": 33584.90399289131, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1075704, "time": 33587.343901872635, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1075752, "time": 33588.8006105423, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1075856, "time": 33592.28746056557, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1076176, "time": 33601.96374607086, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1076392, "time": 33608.29264116287, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1076680, "time": 33617.06552219391, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1076816, "time": 33621.59548711777, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1076944, "time": 33625.51350188255, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1077048, "time": 33628.44133877754, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1077232, "time": 33634.264708042145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1077304, "time": 33636.216222047806, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1077632, "time": 33646.365819215775, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1077768, "time": 33650.326916217804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1077936, "time": 33655.66347551346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1078064, "time": 33659.5597987175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1078904, "time": 33684.810968875885, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1078904, "time": 33684.82031869888, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1078992, "time": 33687.745790719986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1079208, "time": 33694.07023406029, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1079360, "time": 33698.95296263695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1079544, "time": 33704.33050656319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1079608, "time": 33706.26412177086, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1079616, "time": 33706.736562013626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1079928, "time": 33716.02968144417, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1080040, "time": 33719.70489025116, "eval_episode/length": 13.0, "eval_episode/score": 0.9593750238418579, "eval_episode/reward_rate": 0.07142857142857142}
{"step": 1080040, "time": 33721.17702460289, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1080040, "time": 33721.23913860321, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1080040, "time": 33721.439027547836, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1080040, "time": 33721.47984910011, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1080040, "time": 33721.7055003643, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 1080040, "time": 33722.09475207329, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1080040, "time": 33722.83309459686, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1080056, "time": 33723.32307624817, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1080296, "time": 33730.596836566925, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1080736, "time": 33744.224596738815, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1080832, "time": 33747.138513326645, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1080904, "time": 33749.08704686165, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1081216, "time": 33758.806933641434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1081304, "time": 33761.28471660614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1081456, "time": 33766.57674431801, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1081520, "time": 33768.507291555405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1081648, "time": 33772.527837991714, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1081672, "time": 33773.037450790405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1081856, "time": 33778.818672180176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1082568, "time": 33800.40862941742, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1082616, "time": 33801.89255452156, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1083048, "time": 33814.99989628792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1083392, "time": 33825.67621421814, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1083400, "time": 33825.70308852196, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1083528, "time": 33829.58203148842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1083616, "time": 33832.54311585426, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1083832, "time": 33838.88950395584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1083960, "time": 33842.761686086655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1083984, "time": 33843.71640467644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1084088, "time": 33846.633477211, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1084240, "time": 33851.47108888626, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1084368, "time": 33855.36178946495, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1084600, "time": 33862.26696252823, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1084712, "time": 33865.661328077316, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1084928, "time": 33872.438165426254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1085032, "time": 33875.36899256706, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1085048, "time": 33875.85909700394, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1085424, "time": 33887.47409820557, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1085488, "time": 33889.406940460205, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1085504, "time": 33889.897735357285, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1085600, "time": 33892.90681052208, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1086912, "time": 33932.710693359375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1086968, "time": 33934.191536188126, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1086984, "time": 33934.680211782455, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1087240, "time": 33942.41400933266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1087344, "time": 33945.79277777672, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1087360, "time": 33946.282655477524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1087456, "time": 33949.18526816368, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1087464, "time": 33949.213124752045, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1087712, "time": 33957.07450342178, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1087736, "time": 33957.58818101883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1087816, "time": 33960.03384900093, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1087912, "time": 33962.94989013672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1088504, "time": 33980.939937114716, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1088880, "time": 33992.539403915405, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1088896, "time": 33993.02668571472, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1089136, "time": 34000.26946210861, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1089512, "time": 34011.45376825333, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1089656, "time": 34016.33687329292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1089704, "time": 34017.8119597435, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 1090024, "time": 34027.51401638985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1090024, "time": 34027.843431949615, "eval_episode/length": 16.0, "eval_episode/score": 0.949999988079071, "eval_episode/reward_rate": 0.058823529411764705}
{"step": 1090024, "time": 34028.620594501495, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1090024, "time": 34028.96201515198, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1090024, "time": 34029.18209075928, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1090024, "time": 34029.576533555984, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1090024, "time": 34029.73600721359, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 1090024, "time": 34030.279020786285, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1090024, "time": 34031.84858870506, "eval_episode/length": 217.0, "eval_episode/score": 0.3218750059604645, "eval_episode/reward_rate": 0.0045871559633027525}
{"step": 1090048, "time": 34032.817882061005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1090072, "time": 34033.32622051239, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1090504, "time": 34046.469520807266, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1090592, "time": 34049.38287329674, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1090664, "time": 34051.3561463356, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1090816, "time": 34056.197493076324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1091144, "time": 34065.939110040665, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1091448, "time": 34075.24272155762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1091520, "time": 34077.654111623764, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1091768, "time": 34084.96960401535, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1091936, "time": 34090.27213668823, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1092024, "time": 34092.72600722313, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1092360, "time": 34103.02890086174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1092384, "time": 34103.97262310982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1092792, "time": 34116.13452339172, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1093128, "time": 34126.259754896164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1093176, "time": 34127.70523357391, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1093176, "time": 34127.712968826294, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1093256, "time": 34130.148636341095, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1093576, "time": 34139.89039707184, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1093744, "time": 34145.19867682457, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1093832, "time": 34147.65072512627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1094000, "time": 34152.92845916748, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 1094248, "time": 34160.276941776276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1094736, "time": 34175.30729341507, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1094928, "time": 34181.13155531883, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1095144, "time": 34187.429980516434, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1095216, "time": 34189.840968608856, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1095440, "time": 34196.68999147415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1095488, "time": 34198.185874700546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1095488, "time": 34198.19354391098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1095840, "time": 34208.88161063194, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1095888, "time": 34210.332162857056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1096048, "time": 34215.17644286156, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1096208, "time": 34220.01503276825, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1096304, "time": 34223.04746007919, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1096712, "time": 34235.12878870964, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1097048, "time": 34245.290600538254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1097080, "time": 34246.27663040161, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1097200, "time": 34250.118633031845, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1097240, "time": 34251.219750881195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1097344, "time": 34254.587673187256, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1097432, "time": 34257.039462566376, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1097528, "time": 34259.93298768997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1097848, "time": 34270.07935357094, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1097913, "time": 34273.068351745605, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3694433954548955, "train/action_min": 0.0, "train/action_std": 1.58161314015318, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012360200790569114, "train/actor_opt_grad_steps": 67510.0, "train/actor_opt_loss": -16.7734188563718, "train/adv_mag": 0.8247029981002432, "train/adv_max": 0.34184020728313275, "train/adv_mean": 0.0010645135245141125, "train/adv_min": -0.749327043594398, "train/adv_std": 0.028431127834239324, "train/cont_avg": 0.9947660098522167, "train/cont_loss_mean": 0.019636206015751792, "train/cont_loss_std": 0.25202212896510007, "train/cont_neg_acc": 0.2577730194468216, "train/cont_neg_loss": 2.971328545930644, "train/cont_pos_acc": 0.9998838778199821, "train/cont_pos_loss": 0.004106412894606334, "train/cont_pred": 0.9946334411945249, "train/cont_rate": 0.9947660098522167, "train/dyn_loss_mean": 1.000000921963471, "train/dyn_loss_std": 2.2191396028977896e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12299432631196647, "train/extr_critic_critic_opt_grad_steps": 67510.0, "train/extr_critic_critic_opt_loss": 12914.811119342672, "train/extr_critic_mag": 1.4593482346370303, "train/extr_critic_max": 1.4593482346370303, "train/extr_critic_mean": 1.3406173801187224, "train/extr_critic_min": 1.0207900907018501, "train/extr_critic_std": 0.025515780889709006, "train/extr_return_normed_mag": 0.8759304138239968, "train/extr_return_normed_max": 0.31857573457539373, "train/extr_return_normed_mean": 0.04744388420923884, "train/extr_return_normed_min": -0.7692073055088814, "train/extr_return_normed_std": 0.03899278926658513, "train/extr_return_rate": 0.9996273661481923, "train/extr_return_raw_mag": 1.6128136195572726, "train/extr_return_raw_max": 1.6128136195572726, "train/extr_return_raw_mean": 1.3416818474313896, "train/extr_return_raw_min": 0.5250305794729975, "train/extr_return_raw_std": 0.03899278921153158, "train/extr_reward_mag": 0.28914175773489065, "train/extr_reward_max": 0.28914175773489065, "train/extr_reward_mean": 0.001675906587676535, "train/extr_reward_min": 6.635788039033636e-08, "train/extr_reward_std": 0.008515039472634276, "train/image_loss_mean": 0.06995563091609279, "train/image_loss_std": 0.09186913502480597, "train/model_loss_mean": 0.7025397129246754, "train/model_loss_std": 0.4424839128781422, "train/model_opt_grad_norm": 17.51358388797403, "train/model_opt_grad_steps": 67444.94581280788, "train/model_opt_loss": 3582.6195230718904, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5098.522167487685, "train/policy_entropy_mag": 1.2903222749973167, "train/policy_entropy_max": 1.2903222749973167, "train/policy_entropy_mean": 0.10563106321055314, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13573417966735773, "train/policy_logprob_mag": 6.551080266830369, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10580087526531642, "train/policy_logprob_min": -6.551080266830369, "train/policy_logprob_std": 0.6433762717129562, "train/policy_randomness_mag": 0.6630945173390393, "train/policy_randomness_max": 0.6630945173390393, "train/policy_randomness_mean": 0.0542836318462353, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06975357351925572, "train/post_ent_mag": 34.00153551900328, "train/post_ent_max": 34.00153551900328, "train/post_ent_mean": 33.512076974502335, "train/post_ent_min": 33.06107247639172, "train/post_ent_std": 0.20778537875619427, "train/prior_ent_mag": 34.3395174524467, "train/prior_ent_max": 34.3395174524467, "train/prior_ent_mean": 33.08521276389437, "train/prior_ent_min": 32.0475801834332, "train/prior_ent_std": 0.3497543041341998, "train/rep_loss_mean": 1.000000921963471, "train/rep_loss_std": 2.2191396028977896e-05, "train/reward_avg": 0.0018076779284420437, "train/reward_loss_mean": 0.012947297999130681, "train/reward_loss_std": 0.20018670778593112, "train/reward_max_data": 0.7304495062146869, "train/reward_max_pred": 0.2710343194125321, "train/reward_neg_acc": 0.9995659046572417, "train/reward_neg_loss": 0.0024732828818105636, "train/reward_pos_acc": 0.19178762681343975, "train/reward_pos_loss": 3.9633343873973836, "train/reward_pred": 0.0015276912502311354, "train/reward_rate": 0.002660290948275862, "train_stats/mean_log_entropy": 0.09388882452339838, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.023338232189416885, "report/cont_loss_std": 0.30229711532592773, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 3.7491207122802734, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005056668538600206, "report/cont_pred": 0.9939998388290405, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08664102852344513, "report/image_loss_std": 0.11811589449644089, "report/model_loss_mean": 0.7218001484870911, "report/model_loss_std": 0.4632285535335541, "report/post_ent_mag": 34.14533996582031, "report/post_ent_max": 34.14533996582031, "report/post_ent_mean": 33.6768798828125, "report/post_ent_min": 33.24441146850586, "report/post_ent_std": 0.19450171291828156, "report/prior_ent_mag": 34.57899475097656, "report/prior_ent_max": 34.57899475097656, "report/prior_ent_mean": 33.63341522216797, "report/prior_ent_min": 31.675979614257812, "report/prior_ent_std": 0.4574854373931885, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0021514892578125, "report/reward_loss_mean": 0.01182086206972599, "report/reward_loss_std": 0.19570167362689972, "report/reward_max_data": 0.824999988079071, "report/reward_max_pred": 0.6944209337234497, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0024026099126785994, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.2171664237976074, "report/reward_pred": 0.0019642957486212254, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01598251238465309, "eval/cont_loss_std": 0.217992901802063, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.522455215454102, "eval/cont_pos_acc": 0.9980430603027344, "eval/cont_pos_loss": 0.007163582369685173, "eval/cont_pred": 0.9946179389953613, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09671947360038757, "eval/image_loss_std": 0.11620291322469711, "eval/model_loss_mean": 0.7276397347450256, "eval/model_loss_std": 0.4905708134174347, "eval/post_ent_mag": 34.15940856933594, "eval/post_ent_max": 34.15940856933594, "eval/post_ent_mean": 33.628623962402344, "eval/post_ent_min": 33.15509796142578, "eval/post_ent_std": 0.22163058817386627, "eval/prior_ent_mag": 34.55728530883789, "eval/prior_ent_max": 34.55728530883789, "eval/prior_ent_mean": 33.64274215698242, "eval/prior_ent_min": 32.11766052246094, "eval/prior_ent_std": 0.435322642326355, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0015533447731286287, "eval/reward_loss_mean": 0.014937717467546463, "eval/reward_loss_std": 0.24552185833454132, "eval/reward_max_data": 0.8218749761581421, "eval/reward_max_pred": 0.5556704998016357, "eval/reward_neg_acc": 0.9970645904541016, "eval/reward_neg_loss": 0.004432258196175098, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.383228302001953, "eval/reward_pred": 0.0019241207046434283, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32384.0, "replay/samples": 32384.0, "replay/insert_wait_avg": 1.2098137922437766e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.606439086288331e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5016.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.061808739742784e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.004293680191, "timer/env.step_count": 4048.0, "timer/env.step_total": 38.78232550621033, "timer/env.step_frac": 0.038782158988022515, "timer/env.step_avg": 0.009580614008451168, "timer/env.step_min": 0.007716178894042969, "timer/env.step_max": 0.035141944885253906, "timer/replay._sample_count": 32384.0, "timer/replay._sample_total": 16.613009929656982, "timer/replay._sample_frac": 0.016612938599011605, "timer/replay._sample_avg": 0.000513000553657886, "timer/replay._sample_min": 0.0003867149353027344, "timer/replay._sample_max": 0.02533578872680664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4675.0, "timer/agent.policy_total": 48.471545934677124, "timer/agent.policy_frac": 0.04847133781425412, "timer/agent.policy_avg": 0.010368245119717031, "timer/agent.policy_min": 0.008383989334106445, "timer/agent.policy_max": 0.07810115814208984, "timer/dataset_train_count": 2024.0, "timer/dataset_train_total": 0.2126905918121338, "timer/dataset_train_frac": 0.00021268967859067398, "timer/dataset_train_avg": 0.00010508428449216096, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0004451274871826172, "timer/agent.train_count": 2024.0, "timer/agent.train_total": 900.9085392951965, "timer/agent.train_frac": 0.9009046710986562, "timer/agent.train_avg": 0.4451129146715398, "timer/agent.train_min": 0.4336659908294678, "timer/agent.train_max": 0.6726772785186768, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47644877433776855, "timer/agent.report_frac": 0.00047644672862788773, "timer/agent.report_avg": 0.23822438716888428, "timer/agent.report_min": 0.23109102249145508, "timer/agent.report_max": 0.24535775184631348, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8610106649539315e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 32.38327221670414}
{"step": 1098216, "time": 34282.137838840485, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1098432, "time": 34289.01282835007, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1098448, "time": 34289.51199197769, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1098504, "time": 34291.01915550232, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1098568, "time": 34292.987498283386, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1098616, "time": 34294.44019269943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1099152, "time": 34311.08680701256, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1099392, "time": 34318.361745119095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1099616, "time": 34325.211716890335, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1099720, "time": 34328.16318273544, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1100008, "time": 34337.295577049255, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1100008, "time": 34338.02843475342, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1100008, "time": 34338.26925563812, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1100008, "time": 34338.436754226685, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1100008, "time": 34339.479046583176, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 1100008, "time": 34339.8654923439, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 1100008, "time": 34341.92009615898, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1100008, "time": 34342.15291547775, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 1100112, "time": 34345.51744771004, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1100160, "time": 34346.965010643005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100672, "time": 34362.5503320694, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1100696, "time": 34363.055263996124, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1100744, "time": 34364.51352405548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100760, "time": 34365.02612876892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100928, "time": 34370.503621816635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100944, "time": 34370.99836087227, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1101584, "time": 34390.40388727188, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1101704, "time": 34393.80128955841, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1101928, "time": 34400.662910461426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1102144, "time": 34407.40188288689, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1102472, "time": 34417.22667002678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1102480, "time": 34417.70049238205, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1103008, "time": 34433.845056295395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1103032, "time": 34434.35213971138, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1103056, "time": 34435.30570244789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1103240, "time": 34440.68160557747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1103400, "time": 34445.52382326126, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1103480, "time": 34447.972712516785, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1103624, "time": 34452.348798274994, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1103976, "time": 34463.05882978439, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1104088, "time": 34466.414739608765, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1104272, "time": 34472.202942848206, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1104448, "time": 34477.503234386444, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1104688, "time": 34484.74431967735, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1104784, "time": 34487.66883444786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1105320, "time": 34503.782608270645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1105368, "time": 34505.236677885056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1105768, "time": 34517.37073254585, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1105792, "time": 34518.32578253746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1106472, "time": 34539.22082710266, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1106584, "time": 34542.59909296036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1106760, "time": 34547.926458120346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107000, "time": 34555.2797870636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107096, "time": 34558.19559621811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107168, "time": 34560.64417099953, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1107592, "time": 34573.3097755909, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1107632, "time": 34574.76983857155, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1107632, "time": 34574.778775691986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107696, "time": 34576.72165393829, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1108104, "time": 34588.94841051102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1108128, "time": 34589.92129588127, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1108272, "time": 34594.304938554764, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1108600, "time": 34604.095838308334, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1109032, "time": 34617.261313438416, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1109072, "time": 34618.74402832985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109392, "time": 34628.492584466934, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1109408, "time": 34628.984919548035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109464, "time": 34630.46517300606, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1109880, "time": 34643.24294400215, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1109944, "time": 34645.17994570732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109944, "time": 34645.1885330677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1110096, "time": 34651.51410531998, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1110096, "time": 34651.82266950607, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1110096, "time": 34653.02812242508, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 1110096, "time": 34653.20981359482, "eval_episode/length": 170.0, "eval_episode/score": 0.46875, "eval_episode/reward_rate": 0.005847953216374269}
{"step": 1110096, "time": 34653.80718922615, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 1110096, "time": 34654.16466712952, "eval_episode/length": 221.0, "eval_episode/score": 0.30937498807907104, "eval_episode/reward_rate": 0.0045045045045045045}
{"step": 1110096, "time": 34654.32931828499, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1110096, "time": 34654.508133888245, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1110232, "time": 34658.43406033516, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 1110448, "time": 34665.21248245239, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1110848, "time": 34677.37638235092, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1111088, "time": 34684.605620622635, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1111280, "time": 34690.41249489784, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1111344, "time": 34692.366876363754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1111456, "time": 34695.742894887924, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1111656, "time": 34701.71505475044, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1111720, "time": 34703.65995836258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1111776, "time": 34705.582126140594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1111776, "time": 34705.59023118019, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1112232, "time": 34719.15202999115, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1112256, "time": 34720.097387075424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112256, "time": 34720.105951070786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112264, "time": 34720.13534450531, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1112552, "time": 34728.87413907051, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1112632, "time": 34731.398970127106, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1112640, "time": 34731.8650598526, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1112736, "time": 34734.75293111801, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1112832, "time": 34737.65644741058, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1112928, "time": 34740.547050476074, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1113072, "time": 34744.90314269066, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1113296, "time": 34751.648077487946, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1113312, "time": 34752.132326602936, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1113344, "time": 34753.09640312195, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 1113904, "time": 34770.115653038025, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1114088, "time": 34775.46759104729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1114392, "time": 34785.15032124519, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1114784, "time": 34797.29561543465, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1115048, "time": 34805.04047036171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1115144, "time": 34807.95834541321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1115240, "time": 34810.872495651245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1115384, "time": 34815.25429368019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1115656, "time": 34823.65513634682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1116216, "time": 34840.59608602524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1116400, "time": 34846.35794019699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1116528, "time": 34850.2646009922, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1116920, "time": 34861.99437904358, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1117096, "time": 34867.32495737076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1117360, "time": 34875.52090382576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1117408, "time": 34876.991904973984, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1117456, "time": 34878.43866467476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1117552, "time": 34881.39033794403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1117592, "time": 34882.37567901611, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1117624, "time": 34883.337213754654, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1117696, "time": 34885.715242147446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1117968, "time": 34893.914569854736, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1118096, "time": 34897.788066864014, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1118160, "time": 34899.73270368576, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1118640, "time": 34914.417785167694, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1118656, "time": 34914.90401625633, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1118712, "time": 34916.387387275696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1119208, "time": 34931.36565947533, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1119672, "time": 34945.46928858757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1119720, "time": 34946.92054104805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1119832, "time": 34950.329629421234, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 1120008, "time": 34955.673293828964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1120080, "time": 34959.56951999664, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1120080, "time": 34959.63539457321, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1120080, "time": 34959.923904657364, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1120080, "time": 34961.753418684006, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1120080, "time": 34961.84176683426, "eval_episode/length": 192.0, "eval_episode/score": 0.4000000059604645, "eval_episode/reward_rate": 0.0051813471502590676}
{"step": 1120080, "time": 34962.54624795914, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 1120080, "time": 34963.64704656601, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1120080, "time": 34963.713025569916, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1120080, "time": 34963.71983504295, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1120080, "time": 34963.7277636528, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1120080, "time": 34963.734790086746, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1120240, "time": 34968.561329603195, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1120304, "time": 34970.61376738548, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1120408, "time": 34973.53260087967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1120544, "time": 34977.85229301453, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1120752, "time": 34984.18086838722, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1120784, "time": 34985.16078042984, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1120816, "time": 34986.14479804039, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 1120952, "time": 34990.05056452751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1120968, "time": 34990.53859233856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121304, "time": 35000.800110816956, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1121520, "time": 35007.57549524307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121640, "time": 35011.01330900192, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1121728, "time": 35013.9184551239, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1122168, "time": 35026.97514748573, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1122184, "time": 35027.46148657799, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1122320, "time": 35032.30080270767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1122744, "time": 35044.84324288368, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1122840, "time": 35047.752361536026, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1122840, "time": 35047.75833821297, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1123096, "time": 35055.45833039284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1123104, "time": 35055.923540353775, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1123128, "time": 35056.432413101196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1123304, "time": 35061.86041235924, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1123344, "time": 35063.31856632233, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1123504, "time": 35068.19666147232, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1123608, "time": 35071.138959646225, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1123624, "time": 35071.62988471985, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1123832, "time": 35077.94189095497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1123856, "time": 35078.89283514023, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1123872, "time": 35079.382506370544, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1124016, "time": 35083.74753022194, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1124224, "time": 35090.03550314903, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1124512, "time": 35098.83661580086, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1124616, "time": 35101.761766433716, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1124688, "time": 35104.16166853905, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1124832, "time": 35108.5274207592, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1125000, "time": 35113.39751338959, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1125056, "time": 35115.31391954422, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1125168, "time": 35118.694262742996, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1125200, "time": 35119.65428352356, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1125472, "time": 35127.97767019272, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1125568, "time": 35130.885194540024, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1125640, "time": 35132.84095907211, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1125656, "time": 35133.328077077866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1125704, "time": 35134.77194595337, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1125720, "time": 35135.27722978592, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1125816, "time": 35138.16362929344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1126008, "time": 35143.96401453018, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1126080, "time": 35146.36685705185, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1126184, "time": 35149.286527872086, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1126232, "time": 35150.83535194397, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1126536, "time": 35159.96832370758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1126904, "time": 35171.12021827698, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1126944, "time": 35172.5632622242, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1127176, "time": 35179.38252091408, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1127240, "time": 35181.38394236565, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1127368, "time": 35185.27648472786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1127576, "time": 35191.632309913635, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1127640, "time": 35193.58565402031, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1127816, "time": 35198.88640379906, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1127856, "time": 35200.3137691021, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1128040, "time": 35205.67728447914, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1128312, "time": 35214.02927994728, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1129088, "time": 35237.78572487831, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1129112, "time": 35238.294171094894, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1129256, "time": 35242.76270985603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129344, "time": 35245.64019727707, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1129488, "time": 35250.00151181221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129552, "time": 35251.959275484085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129680, "time": 35255.82862114906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129952, "time": 35264.0878469944, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 1130000, "time": 35265.537972450256, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1130064, "time": 35268.5142686367, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1130064, "time": 35269.07263302803, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1130064, "time": 35269.39929652214, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1130064, "time": 35269.58261704445, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1130064, "time": 35269.78868460655, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1130064, "time": 35269.886847019196, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1130064, "time": 35270.70087099075, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1130064, "time": 35270.724947690964, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1130121, "time": 35273.39403414726, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4964496365827116, "train/action_min": 0.0, "train/action_std": 1.659948190646385, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009695557699033722, "train/actor_opt_grad_steps": 69530.0, "train/actor_opt_loss": -18.57715913193736, "train/adv_mag": 0.7245837666502046, "train/adv_max": 0.3496318788670782, "train/adv_mean": 0.0007635768621972304, "train/adv_min": -0.6378165290723392, "train/adv_std": 0.025343367695548936, "train/cont_avg": 0.9946361940298507, "train/cont_loss_mean": 0.02075891275032984, "train/cont_loss_std": 0.25688258213783377, "train/cont_neg_acc": 0.2268374974825489, "train/cont_neg_loss": 3.0332721855806475, "train/cont_pos_acc": 0.9997949084239219, "train/cont_pos_loss": 0.004342912947666363, "train/cont_pred": 0.9946310063499716, "train/cont_rate": 0.9946361940298507, "train/dyn_loss_mean": 1.000039399559818, "train/dyn_loss_std": 0.00018297424030244648, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10351452653745737, "train/extr_critic_critic_opt_grad_steps": 69530.0, "train/extr_critic_critic_opt_loss": 12951.09766596704, "train/extr_critic_mag": 1.4760346021225204, "train/extr_critic_max": 1.4760346021225204, "train/extr_critic_mean": 1.3439745778468117, "train/extr_critic_min": 1.019000198117536, "train/extr_critic_std": 0.02743266581265784, "train/extr_return_normed_mag": 0.7478343568631073, "train/extr_return_normed_max": 0.32493004336285947, "train/extr_return_normed_mean": 0.05111771269668987, "train/extr_return_normed_min": -0.6227177867841958, "train/extr_return_normed_std": 0.03799455045764126, "train/extr_return_rate": 0.9997451168980764, "train/extr_return_raw_mag": 1.6185503172044138, "train/extr_return_raw_max": 1.6185503172044138, "train/extr_return_raw_mean": 1.3447380492936318, "train/extr_return_raw_min": 0.6709024870573584, "train/extr_return_raw_std": 0.037994550337171674, "train/extr_reward_mag": 0.3213891306919838, "train/extr_reward_max": 0.3213891306919838, "train/extr_reward_mean": 0.0017063406203984659, "train/extr_reward_min": 1.3047782935906406e-08, "train/extr_reward_std": 0.00842907536538568, "train/image_loss_mean": 0.07040786609720828, "train/image_loss_std": 0.09214345775359306, "train/model_loss_mean": 0.7054777139454932, "train/model_loss_std": 0.46148334906913746, "train/model_opt_grad_norm": 17.28812733455677, "train/model_opt_grad_steps": 69463.01492537314, "train/model_opt_loss": 3700.719527363184, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5248.756218905472, "train/policy_entropy_mag": 1.3176328032764035, "train/policy_entropy_max": 1.3176328032764035, "train/policy_entropy_mean": 0.1009048577120055, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12881668004675292, "train/policy_logprob_mag": 6.551080248249111, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10051954515389543, "train/policy_logprob_min": -6.551080248249111, "train/policy_logprob_std": 0.6360936873587802, "train/policy_randomness_mag": 0.6771293552360724, "train/policy_randomness_max": 0.6771293552360724, "train/policy_randomness_mean": 0.051854842467539346, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0661986819398937, "train/post_ent_mag": 33.94715951568452, "train/post_ent_max": 33.94715951568452, "train/post_ent_mean": 33.463807860417155, "train/post_ent_min": 33.021863130787715, "train/post_ent_std": 0.20493618365543992, "train/prior_ent_mag": 34.27957935238359, "train/prior_ent_max": 34.27957935238359, "train/prior_ent_mean": 32.881560425260176, "train/prior_ent_min": 31.616980500482207, "train/prior_ent_std": 0.46288733636561913, "train/rep_loss_mean": 1.000039399559818, "train/rep_loss_std": 0.00018297424030244648, "train/reward_avg": 0.002043068349744837, "train/reward_loss_mean": 0.014287271452326309, "train/reward_loss_std": 0.21645662626390583, "train/reward_max_data": 0.762842041491276, "train/reward_max_pred": 0.30262474396928624, "train/reward_neg_acc": 0.9994787060799291, "train/reward_neg_loss": 0.0026196219375709175, "train/reward_pos_acc": 0.1838727700524032, "train/reward_pos_loss": 3.9390697882821164, "train/reward_pred": 0.0016151481216532453, "train/reward_rate": 0.0029636971393034828, "train_stats/mean_log_entropy": 0.08827504461320738, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.030863014981150627, "report/cont_loss_std": 0.30528002977371216, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.6666271686553955, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.005838088225573301, "report/cont_pred": 0.9940845370292664, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07056981325149536, "report/image_loss_std": 0.09107886254787445, "report/model_loss_mean": 0.7323036193847656, "report/model_loss_std": 0.7129309773445129, "report/post_ent_mag": 33.848114013671875, "report/post_ent_max": 33.848114013671875, "report/post_ent_mean": 33.465232849121094, "report/post_ent_min": 33.06516647338867, "report/post_ent_std": 0.17289818823337555, "report/prior_ent_mag": 34.18671417236328, "report/prior_ent_max": 34.18671417236328, "report/prior_ent_mean": 32.688907623291016, "report/prior_ent_min": 31.33203125, "report/prior_ent_std": 0.458011656999588, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002401733538135886, "report/reward_loss_mean": 0.03087078034877777, "report/reward_loss_std": 0.4151616096496582, "report/reward_max_data": 0.793749988079071, "report/reward_max_pred": 0.037285685539245605, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002503955038264394, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.812029838562012, "report/reward_pred": 0.0013721471186727285, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03326889127492905, "eval/cont_loss_std": 0.4162856936454773, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.6026740074157715, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005941092502325773, "eval/cont_pred": 0.9941343069076538, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08915428072214127, "eval/image_loss_std": 0.1108216717839241, "eval/model_loss_mean": 0.7405055165290833, "eval/model_loss_std": 0.7380831241607666, "eval/post_ent_mag": 33.828102111816406, "eval/post_ent_max": 33.828102111816406, "eval/post_ent_mean": 33.451011657714844, "eval/post_ent_min": 33.033226013183594, "eval/post_ent_std": 0.16317084431648254, "eval/prior_ent_mag": 34.18671417236328, "eval/prior_ent_max": 34.18671417236328, "eval/prior_ent_mean": 32.70146942138672, "eval/prior_ent_min": 31.4794921875, "eval/prior_ent_std": 0.44227081537246704, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0009735107305459678, "eval/reward_loss_mean": 0.018082350492477417, "eval/reward_loss_std": 0.35406914353370667, "eval/reward_max_data": 0.6343749761581421, "eval/reward_max_pred": 0.05286562442779541, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0026081199757754803, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.925414085388184, "eval/reward_pred": 0.001375557272695005, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32208.0, "replay/samples": 32208.0, "replay/insert_wait_avg": 1.2109321678567158e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.613212743684301e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7496.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0959430336316086e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1881227493286, "timer/env.step_count": 4026.0, "timer/env.step_total": 38.34968590736389, "timer/env.step_frac": 0.038342472815961696, "timer/env.step_avg": 0.009525505689856903, "timer/env.step_min": 0.007684469223022461, "timer/env.step_max": 0.036283254623413086, "timer/replay._sample_count": 32208.0, "timer/replay._sample_total": 16.506890535354614, "timer/replay._sample_frac": 0.016503785797796003, "timer/replay._sample_avg": 0.000512509020595958, "timer/replay._sample_min": 0.0003764629364013672, "timer/replay._sample_max": 0.029426097869873047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4963.0, "timer/agent.policy_total": 51.74828863143921, "timer/agent.policy_frac": 0.05173855543214502, "timer/agent.policy_avg": 0.010426816165915617, "timer/agent.policy_min": 0.008998394012451172, "timer/agent.policy_max": 0.09125089645385742, "timer/dataset_train_count": 2013.0, "timer/dataset_train_total": 0.2087874412536621, "timer/dataset_train_frac": 0.0002087481709738212, "timer/dataset_train_avg": 0.00010371954359347347, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0004112720489501953, "timer/agent.train_count": 2013.0, "timer/agent.train_total": 895.3771319389343, "timer/agent.train_frac": 0.8952087228127759, "timer/agent.train_avg": 0.4447973829800965, "timer/agent.train_min": 0.42945218086242676, "timer/agent.train_max": 0.6656534671783447, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4760558605194092, "timer/agent.report_frac": 0.0004759663204266227, "timer/agent.report_avg": 0.2380279302597046, "timer/agent.report_min": 0.23185467720031738, "timer/agent.report_max": 0.2442011833190918, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00010514259338378906, "timer/dataset_eval_frac": 1.0512281739036442e-07, "timer/dataset_eval_avg": 0.00010514259338378906, "timer/dataset_eval_min": 0.00010514259338378906, "timer/dataset_eval_max": 0.00010514259338378906, "fps": 32.201379196075386}
{"step": 1130136, "time": 35273.446185112, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1130144, "time": 35274.333142757416, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1130288, "time": 35278.7763106823, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1130440, "time": 35283.221975803375, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1130480, "time": 35284.687143564224, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1130496, "time": 35285.33148097992, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1131368, "time": 35311.911059617996, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1131376, "time": 35312.378792762756, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1131416, "time": 35313.37824034691, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1131656, "time": 35320.65257310867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1131992, "time": 35330.87372326851, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1132104, "time": 35334.253153800964, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1132136, "time": 35335.24425029755, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1132312, "time": 35340.58819246292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1132328, "time": 35341.07603573799, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1132352, "time": 35342.03191232681, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1132752, "time": 35354.13742685318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1132800, "time": 35355.586421489716, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1132808, "time": 35355.614844083786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1132832, "time": 35356.56561613083, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1132832, "time": 35356.57396697998, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1133104, "time": 35364.941647052765, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1133240, "time": 35368.83527159691, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1133424, "time": 35374.594680547714, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1133424, "time": 35374.60969996452, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1133488, "time": 35376.54301381111, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1134304, "time": 35401.32214927673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1135064, "time": 35424.286720752716, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1135120, "time": 35426.20780515671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1135416, "time": 35434.952999830246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1135552, "time": 35439.321008205414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1135736, "time": 35444.66805791855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1135736, "time": 35444.6769425869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1135800, "time": 35446.636258363724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1136088, "time": 35455.4318420887, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1136568, "time": 35469.94349312782, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1136584, "time": 35470.42685031891, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1136616, "time": 35471.41940140724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1136816, "time": 35477.719284296036, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1137376, "time": 35494.76929616928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1137432, "time": 35496.265756607056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1137864, "time": 35509.36535573006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138048, "time": 35515.215733766556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138088, "time": 35516.20513319969, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1138200, "time": 35519.591579675674, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1138400, "time": 35525.84801745415, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1138632, "time": 35532.63146734238, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1138728, "time": 35535.99214601517, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1138880, "time": 35540.91866159439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138896, "time": 35541.408614873886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138928, "time": 35542.37764835358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1139128, "time": 35548.206312417984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1139176, "time": 35549.66849899292, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1139208, "time": 35550.63649272919, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1139520, "time": 35560.28558301926, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1139544, "time": 35560.79713010788, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1139752, "time": 35567.09182524681, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1140048, "time": 35577.82713961601, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1140048, "time": 35578.05930233002, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1140048, "time": 35578.140419483185, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1140048, "time": 35578.76640200615, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1140048, "time": 35579.750192165375, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 1140048, "time": 35580.31181693077, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1140048, "time": 35580.34177517891, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1140048, "time": 35580.889788627625, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1140128, "time": 35583.34015369415, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1140352, "time": 35590.131870508194, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1140472, "time": 35593.542140483856, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1140512, "time": 35594.96988487244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1140944, "time": 35608.10418963432, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1141040, "time": 35611.00549030304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1141176, "time": 35614.9161157608, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1141192, "time": 35615.405717372894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1141336, "time": 35619.77446556091, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1141440, "time": 35623.1521525383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1141680, "time": 35630.48402738571, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1141768, "time": 35632.94939541817, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1141824, "time": 35634.859516620636, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1141856, "time": 35635.82474017143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1141936, "time": 35638.25047016144, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1141944, "time": 35638.27646660805, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1142448, "time": 35653.71106386185, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1142520, "time": 35655.67766833305, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1142616, "time": 35658.58080768585, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1142688, "time": 35661.120750665665, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1142688, "time": 35661.1292617321, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1142816, "time": 35665.050798892975, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1142928, "time": 35668.4791970253, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1142936, "time": 35668.50660610199, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1143256, "time": 35678.18974375725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1143328, "time": 35680.61940693855, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1143336, "time": 35680.64719247818, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1143392, "time": 35682.564858675, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1143704, "time": 35691.88320040703, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1144112, "time": 35704.418687820435, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1144184, "time": 35706.40550851822, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1144248, "time": 35708.370119810104, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1144360, "time": 35711.8230843544, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1144440, "time": 35714.278752326965, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1144552, "time": 35717.66428589821, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1144752, "time": 35724.02760910988, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1145000, "time": 35731.295590639114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1145128, "time": 35735.183124780655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1145240, "time": 35738.59608221054, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1145408, "time": 35743.89135694504, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1145440, "time": 35744.86022853851, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1145464, "time": 35745.365693330765, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1145656, "time": 35751.27455329895, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1146016, "time": 35762.42042970657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1146024, "time": 35762.447617292404, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1146128, "time": 35765.8334710598, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1146192, "time": 35767.78638482094, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1146304, "time": 35771.154423475266, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1146384, "time": 35773.57405924797, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1146528, "time": 35777.93777680397, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1146560, "time": 35778.939908504486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1146568, "time": 35778.966445446014, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1146656, "time": 35781.92576122284, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1146864, "time": 35788.22271537781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1146888, "time": 35788.923956394196, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1147480, "time": 35807.1063182354, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1147496, "time": 35807.59524154663, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1147528, "time": 35808.56461262703, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1147776, "time": 35816.38646745682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1147928, "time": 35820.75633120537, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1147992, "time": 35822.71322774887, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1148144, "time": 35827.53702092171, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1148264, "time": 35830.92068576813, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1148280, "time": 35831.42566370964, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1148464, "time": 35837.21634435654, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1148680, "time": 35843.62493467331, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1148816, "time": 35848.04732179642, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1148880, "time": 35849.9812400341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1149048, "time": 35854.85219144821, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1149192, "time": 35859.22225213051, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1149552, "time": 35870.39376449585, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1149592, "time": 35871.42081570625, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1149792, "time": 35877.73755145073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1149904, "time": 35881.146486997604, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1150032, "time": 35886.81544995308, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1150032, "time": 35887.22904276848, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1150032, "time": 35887.3062274456, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1150032, "time": 35887.64662909508, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1150032, "time": 35887.67061448097, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1150032, "time": 35888.597430467606, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 1150032, "time": 35889.60231947899, "eval_episode/length": 210.0, "eval_episode/score": 0.34375, "eval_episode/reward_rate": 0.004739336492890996}
{"step": 1150032, "time": 35889.681386470795, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1150088, "time": 35891.14360046387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1150528, "time": 35904.71880364418, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1150592, "time": 35906.6501352787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1151008, "time": 35919.32647871971, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1151032, "time": 35919.839227199554, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1151032, "time": 35919.84680104256, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1151040, "time": 35920.321976184845, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1151288, "time": 35927.65473031998, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1151360, "time": 35930.09517621994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1151504, "time": 35934.5892496109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1151856, "time": 35945.23314642906, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1151904, "time": 35946.67639923096, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1152104, "time": 35952.482768535614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1152312, "time": 35958.75294852257, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1152376, "time": 35960.791056871414, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1152592, "time": 35967.54792761803, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1152688, "time": 35970.439935445786, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1153216, "time": 35986.38867402077, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1153344, "time": 35990.285262584686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1153344, "time": 35990.29408836365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1153352, "time": 35990.352662563324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1153360, "time": 35990.86782479286, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1153424, "time": 35992.82202076912, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1153744, "time": 36002.46419453621, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1153960, "time": 36008.770884513855, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1154120, "time": 36013.60786700249, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1154184, "time": 36015.578221559525, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1154664, "time": 36030.395550727844, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1154856, "time": 36036.2151556015, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1154904, "time": 36037.67116975784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1155000, "time": 36040.60356283188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1155136, "time": 36045.43289446831, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1155368, "time": 36052.327383995056, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1155488, "time": 36056.197066783905, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1155528, "time": 36057.18407845497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1155624, "time": 36060.082334280014, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1155672, "time": 36061.54594254494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1155864, "time": 36067.35693836212, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1156144, "time": 36076.05683970451, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1156432, "time": 36084.920645713806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1156496, "time": 36086.857191085815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1156976, "time": 36101.34213280678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1157200, "time": 36108.1281542778, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1157448, "time": 36115.505460977554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1157520, "time": 36117.898470401764, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1157800, "time": 36126.22858810425, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1157840, "time": 36127.67308926582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1157936, "time": 36130.59604930878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1157984, "time": 36132.04503917694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1158088, "time": 36134.986354112625, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1158184, "time": 36137.88105916977, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1158256, "time": 36140.334253549576, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1158384, "time": 36144.25889253616, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1158424, "time": 36145.25000858307, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1158544, "time": 36149.11433196068, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1158616, "time": 36151.08096718788, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1158664, "time": 36152.52775645256, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1158976, "time": 36162.208758592606, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1159760, "time": 36185.999087810516, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1159784, "time": 36186.504640340805, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 1159832, "time": 36187.968264102936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1160016, "time": 36194.14671802521, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 1160016, "time": 36195.00316905975, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1160016, "time": 36195.027220487595, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1160016, "time": 36195.5536775589, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 1160016, "time": 36195.577072143555, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1160016, "time": 36196.692831516266, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1160016, "time": 36196.80822825432, "eval_episode/length": 166.0, "eval_episode/score": 0.48124998807907104, "eval_episode/reward_rate": 0.005988023952095809}
{"step": 1160016, "time": 36197.09774184227, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1160248, "time": 36204.014191150665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1160640, "time": 36216.11929798126, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1160696, "time": 36217.599286317825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1160696, "time": 36217.60834646225, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1160736, "time": 36219.039521455765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1160752, "time": 36219.54805064201, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1160928, "time": 36224.89636325836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1161072, "time": 36229.30132436752, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1161168, "time": 36232.27501535416, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1161256, "time": 36234.72162389755, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1161312, "time": 36236.63239431381, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1161616, "time": 36245.85562586784, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1161624, "time": 36245.884299993515, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1161832, "time": 36252.22949194908, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1162072, "time": 36259.50565266609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1162376, "time": 36268.87176847458, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1162384, "time": 36269.33801865578, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1162424, "time": 36270.32740020752, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1162489, "time": 36273.309285879135, "train_stats/mean_log_entropy": 0.0823533896356821, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.38443657903388, "train/action_min": 0.0, "train/action_std": 1.670724140535487, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009783290810698625, "train/actor_opt_grad_steps": 71545.0, "train/actor_opt_loss": -19.18198239921343, "train/adv_mag": 0.6655540507618743, "train/adv_max": 0.27949473881485437, "train/adv_mean": 0.0007040646776271622, "train/adv_min": -0.5942651694363886, "train/adv_std": 0.024181716632798757, "train/cont_avg": 0.9945225479579208, "train/cont_loss_mean": 0.021875832896071052, "train/cont_loss_std": 0.26543361292967554, "train/cont_neg_acc": 0.19096481427550316, "train/cont_neg_loss": 3.158181994987449, "train/cont_pos_acc": 0.9998686493623374, "train/cont_pos_loss": 0.004439921102182257, "train/cont_pred": 0.9946187613624158, "train/cont_rate": 0.9945225479579208, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11028384070124218, "train/extr_critic_critic_opt_grad_steps": 71545.0, "train/extr_critic_critic_opt_loss": 13287.804895382116, "train/extr_critic_mag": 1.4955113772118445, "train/extr_critic_max": 1.4955113772118445, "train/extr_critic_mean": 1.368731976145565, "train/extr_critic_min": 1.1018022564378116, "train/extr_critic_std": 0.026937199295452324, "train/extr_return_normed_mag": 0.7139748252264344, "train/extr_return_normed_max": 0.2986686684117459, "train/extr_return_normed_mean": 0.05349088164212385, "train/extr_return_normed_min": -0.5854801736255684, "train/extr_return_normed_std": 0.03707057005255529, "train/extr_return_rate": 0.9997650694729078, "train/extr_return_raw_mag": 1.6146137667174387, "train/extr_return_raw_max": 1.6146137667174387, "train/extr_return_raw_mean": 1.3694360545366118, "train/extr_return_raw_min": 0.7304649246801244, "train/extr_return_raw_std": 0.03707057004333428, "train/extr_reward_mag": 0.2669991650203667, "train/extr_reward_max": 0.2669991650203667, "train/extr_reward_mean": 0.00196247410442966, "train/extr_reward_min": 2.950724988880724e-09, "train/extr_reward_std": 0.008109455229714513, "train/image_loss_mean": 0.07055217136472168, "train/image_loss_std": 0.09231924097800609, "train/model_loss_mean": 0.7076997016326035, "train/model_loss_std": 0.4786283684396508, "train/model_opt_grad_norm": 17.012810990361885, "train/model_opt_grad_steps": 71476.13366336633, "train/model_opt_loss": 3837.748350237856, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5445.544554455446, "train/policy_entropy_mag": 1.310640307936338, "train/policy_entropy_max": 1.310640307936338, "train/policy_entropy_mean": 0.09892568914311947, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1251283532174507, "train/policy_logprob_mag": 6.551080257585733, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0985881254298262, "train/policy_logprob_min": -6.551080257585733, "train/policy_logprob_std": 0.6342508816482997, "train/policy_randomness_mag": 0.6735359194255112, "train/policy_randomness_max": 0.6735359194255112, "train/policy_randomness_mean": 0.050837750592739275, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06430325688480741, "train/post_ent_mag": 33.975626690552964, "train/post_ent_max": 33.975626690552964, "train/post_ent_mean": 33.533965403490726, "train/post_ent_min": 33.117456983811785, "train/post_ent_std": 0.1869202188336023, "train/prior_ent_mag": 34.15528684559435, "train/prior_ent_max": 34.15528684559435, "train/prior_ent_mean": 32.614701469345846, "train/prior_ent_min": 31.397266765632253, "train/prior_ent_std": 0.4877493589526356, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0021650408672561896, "train/reward_loss_mean": 0.01527167436214957, "train/reward_loss_std": 0.22578708844554454, "train/reward_max_data": 0.7666151010901621, "train/reward_max_pred": 0.28802727826751107, "train/reward_neg_acc": 0.9994858600715599, "train/reward_neg_loss": 0.002683778349333212, "train/reward_pos_acc": 0.19746768301756112, "train/reward_pos_loss": 3.9668888084052765, "train/reward_pred": 0.0016747427952134668, "train/reward_rate": 0.0031617419554455448, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.03288206830620766, "report/cont_loss_std": 0.3740816116333008, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.442023992538452, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006038432940840721, "report/cont_pred": 0.9919787049293518, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.059077806770801544, "report/image_loss_std": 0.08325474709272385, "report/model_loss_mean": 0.7034381628036499, "report/model_loss_std": 0.4849356412887573, "report/post_ent_mag": 33.703834533691406, "report/post_ent_max": 33.703834533691406, "report/post_ent_mean": 33.258766174316406, "report/post_ent_min": 32.750972747802734, "report/post_ent_std": 0.21485105156898499, "report/prior_ent_mag": 34.055423736572266, "report/prior_ent_max": 34.055423736572266, "report/prior_ent_mean": 32.73228454589844, "report/prior_ent_min": 31.573467254638672, "report/prior_ent_std": 0.4615555703639984, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0012939453590661287, "report/reward_loss_mean": 0.01147829182446003, "report/reward_loss_std": 0.1804649978876114, "report/reward_max_data": 0.7281249761581421, "report/reward_max_pred": 0.1139211654663086, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.0037355280946940184, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.9680304527282715, "report/reward_pred": 0.0019315427634865046, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01597217470407486, "eval/cont_loss_std": 0.21303044259548187, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.721240997314453, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.006764211691915989, "eval/cont_pred": 0.9935605525970459, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.07813382148742676, "eval/image_loss_std": 0.0970955640077591, "eval/model_loss_mean": 0.7045196294784546, "eval/model_loss_std": 0.4294191598892212, "eval/post_ent_mag": 33.73883056640625, "eval/post_ent_max": 33.73883056640625, "eval/post_ent_mean": 33.24530029296875, "eval/post_ent_min": 32.8067512512207, "eval/post_ent_std": 0.19849538803100586, "eval/prior_ent_mag": 34.055423736572266, "eval/prior_ent_max": 34.055423736572266, "eval/prior_ent_mean": 32.69034194946289, "eval/prior_ent_min": 31.652679443359375, "eval/prior_ent_std": 0.4485745429992676, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006988525274209678, "eval/reward_loss_mean": 0.010413595475256443, "eval/reward_loss_std": 0.21710070967674255, "eval/reward_max_data": 0.715624988079071, "eval/reward_max_pred": 0.08422350883483887, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0036396596115082502, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.940150737762451, "eval/reward_pred": 0.0017664481420069933, "eval/reward_rate": 0.0009765625, "replay/size": 1000000.0, "replay/inserts": 32368.0, "replay/samples": 32368.0, "replay/insert_wait_avg": 1.2260863996648104e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.541475470444382e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5128.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0855763267243336e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0202813148499, "timer/env.step_count": 4046.0, "timer/env.step_total": 38.64189076423645, "timer/env.step_frac": 0.03864110707177778, "timer/env.step_avg": 0.009550640327295218, "timer/env.step_min": 0.007717132568359375, "timer/env.step_max": 0.03857612609863281, "timer/replay._sample_count": 32368.0, "timer/replay._sample_total": 16.521870851516724, "timer/replay._sample_frac": 0.016521535773047907, "timer/replay._sample_avg": 0.0005104384222539769, "timer/replay._sample_min": 0.00041174888610839844, "timer/replay._sample_max": 0.028086423873901367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4687.0, "timer/agent.policy_total": 48.78810167312622, "timer/agent.policy_frac": 0.04878711220634295, "timer/agent.policy_avg": 0.010409238675725671, "timer/agent.policy_min": 0.008898735046386719, "timer/agent.policy_max": 0.09470725059509277, "timer/dataset_train_count": 2023.0, "timer/dataset_train_total": 0.21431374549865723, "timer/dataset_train_frac": 0.00021430939902226037, "timer/dataset_train_avg": 0.00010593857908979596, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0010614395141601562, "timer/agent.train_count": 2023.0, "timer/agent.train_total": 900.0296745300293, "timer/agent.train_frac": 0.9000114211150292, "timer/agent.train_avg": 0.4448985044636823, "timer/agent.train_min": 0.4337046146392822, "timer/agent.train_max": 0.6855628490447998, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754905700683594, "timer/agent.report_frac": 0.0004754809266899801, "timer/agent.report_avg": 0.2377452850341797, "timer/agent.report_min": 0.22975611686706543, "timer/agent.report_max": 0.24573445320129395, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.6940753044581773e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 32.36676517470766}
{"step": 1162584, "time": 36275.99295926094, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1162848, "time": 36284.215943813324, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1162920, "time": 36286.17176580429, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1163016, "time": 36289.08235287666, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1163064, "time": 36290.62976503372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1163072, "time": 36291.09688091278, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1163216, "time": 36295.47203326225, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1163384, "time": 36300.8287050724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1163480, "time": 36303.75448799133, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1163568, "time": 36306.62857961655, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1163680, "time": 36310.02430820465, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1163832, "time": 36314.415056467056, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1164120, "time": 36323.20184350014, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1164168, "time": 36324.64505767822, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1164384, "time": 36331.368206977844, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1164424, "time": 36332.35899353027, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1164488, "time": 36334.302778720856, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1164624, "time": 36338.63116502762, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1164696, "time": 36340.58517241478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1164736, "time": 36342.0096886158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1164864, "time": 36345.87465214729, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1165160, "time": 36354.74634361267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1165328, "time": 36360.05494642258, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1165424, "time": 36362.97362232208, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1165680, "time": 36370.74352288246, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1165688, "time": 36370.77076077461, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1165880, "time": 36376.614295482635, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1166128, "time": 36384.560468673706, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1166240, "time": 36387.97351813316, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1166392, "time": 36392.38646245003, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 1166456, "time": 36394.34145903587, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1166544, "time": 36397.25035881996, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1166624, "time": 36399.69700908661, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1166744, "time": 36403.14548707008, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1167048, "time": 36412.53863596916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1167168, "time": 36416.40080976486, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1167280, "time": 36419.79048490524, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1167320, "time": 36420.800590753555, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1167544, "time": 36427.579783439636, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1167640, "time": 36430.50947356224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1167704, "time": 36432.45645022392, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1167728, "time": 36433.4081864357, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1168000, "time": 36441.7987909317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1168280, "time": 36450.107731580734, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1168392, "time": 36453.50023937225, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1168704, "time": 36463.23403382301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1168872, "time": 36468.16306948662, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1169592, "time": 36490.107639312744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1169672, "time": 36492.531658411026, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1169704, "time": 36493.50278162956, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1169752, "time": 36494.97059345245, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1169952, "time": 36501.33652091026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1170000, "time": 36503.31228995323, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 1170000, "time": 36503.774483680725, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1170000, "time": 36503.81656932831, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1170000, "time": 36503.82413649559, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1170000, "time": 36504.11597084999, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1170000, "time": 36505.3713991642, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1170000, "time": 36505.70724272728, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 1170000, "time": 36505.834408283234, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1170016, "time": 36506.33278799057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1170168, "time": 36510.78442573547, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1170256, "time": 36513.727098464966, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1170440, "time": 36519.07629156113, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1170480, "time": 36520.514729976654, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1170704, "time": 36527.290023326874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1170840, "time": 36531.30663943291, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1170840, "time": 36531.316363573074, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1170992, "time": 36536.14418411255, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1171312, "time": 36545.89315319061, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1171336, "time": 36546.412247896194, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1171392, "time": 36548.35514545441, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1171728, "time": 36559.179919958115, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1171864, "time": 36563.16118144989, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1171872, "time": 36563.62747311592, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1172064, "time": 36569.43407154083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1172136, "time": 36571.398463726044, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1172264, "time": 36575.23562049866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1172352, "time": 36578.12586236, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1172376, "time": 36578.63170814514, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1172400, "time": 36579.57347846031, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1172600, "time": 36585.3974571228, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1172640, "time": 36586.82297873497, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1172640, "time": 36586.82987785339, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1172936, "time": 36595.630664110184, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1173008, "time": 36598.00655412674, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1173024, "time": 36598.49081683159, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1173152, "time": 36602.356357097626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1173480, "time": 36612.019323825836, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1173560, "time": 36614.46964788437, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1173800, "time": 36621.78371715546, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1173968, "time": 36627.083213329315, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1174040, "time": 36629.04349279404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1174240, "time": 36635.29626774788, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1174352, "time": 36638.6746339798, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1174472, "time": 36642.07302045822, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1174520, "time": 36643.55027222633, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1174528, "time": 36644.019313812256, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1174664, "time": 36647.90404701233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1174752, "time": 36650.89176440239, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1174936, "time": 36656.24054646492, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1175128, "time": 36662.09190368652, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1175224, "time": 36665.02463364601, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1175416, "time": 36670.8455016613, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1175472, "time": 36672.777052402496, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1175552, "time": 36675.19131541252, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1175792, "time": 36682.55180287361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1176088, "time": 36691.268584251404, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1176288, "time": 36697.565465688705, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1176328, "time": 36698.55001926422, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1176384, "time": 36700.45823264122, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1176784, "time": 36712.66360998154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1176792, "time": 36712.690640211105, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1176904, "time": 36716.07750034332, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1177248, "time": 36726.69363498688, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1177352, "time": 36729.60513615608, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1177440, "time": 36732.487693309784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1177528, "time": 36734.90501141548, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1177536, "time": 36735.368562698364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1177696, "time": 36740.1899497509, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 1178104, "time": 36752.33748745918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1178312, "time": 36758.63070344925, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 1178464, "time": 36763.46527981758, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1178696, "time": 36770.35581970215, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1178712, "time": 36770.876777648926, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1178944, "time": 36778.16128826141, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1179320, "time": 36789.33116531372, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 1179472, "time": 36794.15702486038, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 1179560, "time": 36796.587854385376, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1179656, "time": 36799.70330786705, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1179704, "time": 36801.56046795845, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1179840, "time": 36805.906499147415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1179848, "time": 36805.933438539505, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1179848, "time": 36805.941580057144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1180088, "time": 36814.38202047348, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1180088, "time": 36814.66046023369, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1180088, "time": 36815.175532102585, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1180088, "time": 36815.1985270977, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1180088, "time": 36815.20664477348, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1180088, "time": 36815.39221763611, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 1180088, "time": 36815.752675294876, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 1180088, "time": 36815.797966480255, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1180168, "time": 36818.246418476105, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1180320, "time": 36823.079612493515, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1180528, "time": 36829.38040161133, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1180528, "time": 36829.39017248154, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1181008, "time": 36843.989818573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1181632, "time": 36863.0174305439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182152, "time": 36878.588208436966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182160, "time": 36879.06279420853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182368, "time": 36885.42979168892, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1182480, "time": 36888.81929540634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182632, "time": 36893.328999996185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182840, "time": 36899.67206811905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182840, "time": 36899.68139386177, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 1182840, "time": 36899.6900408268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182872, "time": 36900.662872076035, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1182960, "time": 36903.52634859085, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1183088, "time": 36907.39557623863, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1183144, "time": 36908.86155414581, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1183152, "time": 36909.3470351696, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1183520, "time": 36920.58042550087, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1183696, "time": 36925.90720152855, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1183888, "time": 36931.71938705444, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1184008, "time": 36935.12958431244, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1184264, "time": 36942.84920811653, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1184352, "time": 36945.74426436424, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1184816, "time": 36959.833246707916, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1184944, "time": 36963.71756696701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1185344, "time": 36975.862352371216, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1185456, "time": 36979.308210134506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1185824, "time": 36990.61328434944, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1185832, "time": 36990.642879247665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1185960, "time": 36994.5578789711, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1186200, "time": 37001.89813160896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1186216, "time": 37002.38896012306, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1186320, "time": 37005.76783823967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1186600, "time": 37014.195263147354, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1186616, "time": 37014.68525648117, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1186664, "time": 37016.147534132004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1187128, "time": 37030.30968093872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1187152, "time": 37031.280165433884, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1187240, "time": 37033.71110320091, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1187240, "time": 37033.71766448021, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1187256, "time": 37034.206573963165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1187264, "time": 37034.67228293419, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1187768, "time": 37049.88100814819, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1187792, "time": 37050.85209727287, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1188040, "time": 37058.6444170475, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1188248, "time": 37064.98490834236, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1188272, "time": 37065.95119476318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1188640, "time": 37077.1547665596, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1188688, "time": 37078.630061388016, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1188904, "time": 37084.95829510689, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1188976, "time": 37087.38967347145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1189096, "time": 37090.807265758514, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1189192, "time": 37093.720072984695, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1189552, "time": 37104.99699640274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1189568, "time": 37105.48673796654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1189920, "time": 37116.220968961716, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1189928, "time": 37116.24902296066, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1190072, "time": 37121.61088705063, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1190072, "time": 37122.07126903534, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1190072, "time": 37122.867599487305, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 1190072, "time": 37122.89150381088, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 1190072, "time": 37122.98836040497, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1190072, "time": 37124.34512400627, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 1190072, "time": 37124.8460483551, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 1190072, "time": 37125.46027159691, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 1190248, "time": 37130.87787461281, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1190592, "time": 37141.49696612358, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1190768, "time": 37146.84005331993, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1191216, "time": 37160.592848062515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1191288, "time": 37162.54581785202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1191488, "time": 37168.85500264168, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1191768, "time": 37177.137140750885, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1191864, "time": 37180.069761276245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1191880, "time": 37180.56090950966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1191928, "time": 37182.02852129936, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1192192, "time": 37190.29330039024, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1192208, "time": 37190.86345887184, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1192240, "time": 37191.834871053696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1192560, "time": 37201.53583455086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1192704, "time": 37205.93396782875, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1192776, "time": 37207.92108082771, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1193128, "time": 37218.63143801689, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1193272, "time": 37223.10096168518, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1193512, "time": 37230.372643470764, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1193536, "time": 37231.329192876816, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1193688, "time": 37235.71881365776, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1194024, "time": 37245.919628858566, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1194024, "time": 37245.92597937584, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1194048, "time": 37246.89670777321, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1194176, "time": 37250.83720374107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1194240, "time": 37252.791194200516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1194320, "time": 37255.20345664024, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1194520, "time": 37261.08683657646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1194712, "time": 37266.92500448227, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1194889, "time": 37275.87453818321, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.312815999749846, "train/action_min": 0.0, "train/action_std": 1.6374618361148927, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00978926512793514, "train/actor_opt_grad_steps": 73570.0, "train/actor_opt_loss": -18.94245298977556, "train/adv_mag": 0.6762041032607919, "train/adv_max": 0.2901849764321238, "train/adv_mean": -0.0002733987115735442, "train/adv_min": -0.6095246144116219, "train/adv_std": 0.02314446088880888, "train/cont_avg": 0.9945880157019704, "train/cont_loss_mean": 0.02187752516554861, "train/cont_loss_std": 0.2679349154766117, "train/cont_neg_acc": 0.19802813852215048, "train/cont_neg_loss": 3.1833937715399516, "train/cont_pos_acc": 0.9998645030806217, "train/cont_pos_loss": 0.004500261450580923, "train/cont_pred": 0.9945469451655308, "train/cont_rate": 0.9945880157019704, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10304584321588865, "train/extr_critic_critic_opt_grad_steps": 73570.0, "train/extr_critic_critic_opt_loss": 13207.578432881774, "train/extr_critic_mag": 1.4824336526429125, "train/extr_critic_max": 1.4824336526429125, "train/extr_critic_mean": 1.359009637621236, "train/extr_critic_min": 1.0651177015210607, "train/extr_critic_std": 0.02622393579245201, "train/extr_return_normed_mag": 0.7178271709404556, "train/extr_return_normed_max": 0.27180741338307046, "train/extr_return_normed_mean": 0.04992429336780691, "train/extr_return_normed_min": -0.6135935049338881, "train/extr_return_normed_std": 0.035674637321180896, "train/extr_return_rate": 0.9997768114353048, "train/extr_return_raw_mag": 1.580619201284324, "train/extr_return_raw_max": 1.580619201284324, "train/extr_return_raw_mean": 1.358736149195967, "train/extr_return_raw_min": 0.6952182829673654, "train/extr_return_raw_std": 0.03567463738541004, "train/extr_reward_mag": 0.24314500369461886, "train/extr_reward_max": 0.24314500369461886, "train/extr_reward_mean": 0.002097438128545807, "train/extr_reward_min": 1.526818486857297e-08, "train/extr_reward_std": 0.008065823846372772, "train/image_loss_mean": 0.07070163740166302, "train/image_loss_std": 0.09225436779005187, "train/model_loss_mean": 0.7070807165700227, "train/model_loss_std": 0.4720063920825573, "train/model_opt_grad_norm": 16.890920299114565, "train/model_opt_grad_steps": 73499.25615763546, "train/model_opt_loss": 3777.277710562269, "train/model_opt_model_opt_grad_overflow": 0.0049261083743842365, "train/model_opt_model_opt_grad_scale": 5320.1970443349755, "train/policy_entropy_mag": 1.3073925067638528, "train/policy_entropy_max": 1.3073925067638528, "train/policy_entropy_mean": 0.10038986398375092, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12703951976716224, "train/policy_logprob_mag": 6.551080285621981, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09956268400981508, "train/policy_logprob_min": -6.551080285621981, "train/policy_logprob_std": 0.6334660173636939, "train/policy_randomness_mag": 0.6718668820235529, "train/policy_randomness_max": 0.6718668820235529, "train/policy_randomness_mean": 0.051590188144903466, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06528540254740292, "train/post_ent_mag": 34.30687565169311, "train/post_ent_max": 34.30687565169311, "train/post_ent_mean": 33.80510651536763, "train/post_ent_min": 33.31622727868592, "train/post_ent_std": 0.21842724987732365, "train/prior_ent_mag": 34.209388732910156, "train/prior_ent_max": 34.209388732910156, "train/prior_ent_mean": 32.916113191050265, "train/prior_ent_min": 31.81570887448165, "train/prior_ent_std": 0.42977495146502415, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0020708506885317285, "train/reward_loss_mean": 0.01450152773859686, "train/reward_loss_std": 0.2197785345204358, "train/reward_max_data": 0.7738454462272193, "train/reward_max_pred": 0.30441798306451057, "train/reward_neg_acc": 0.9994838305294808, "train/reward_neg_loss": 0.0027905464707988457, "train/reward_pos_acc": 0.20825477632774314, "train/reward_pos_loss": 3.9362214626697116, "train/reward_pred": 0.0017377875264724854, "train/reward_rate": 0.003016279248768473, "train_stats/mean_log_entropy": 0.08245534223513068, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.017885485664010048, "report/cont_loss_std": 0.22234566509723663, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.904184103012085, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037230791058391333, "report/cont_pred": 0.9957345724105835, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07968553155660629, "report/image_loss_std": 0.09858065098524094, "report/model_loss_mean": 0.7136539220809937, "report/model_loss_std": 0.4747484028339386, "report/post_ent_mag": 34.546146392822266, "report/post_ent_max": 34.546146392822266, "report/post_ent_mean": 34.07569885253906, "report/post_ent_min": 33.56846237182617, "report/post_ent_std": 0.21277420222759247, "report/prior_ent_mag": 34.304378509521484, "report/prior_ent_max": 34.304378509521484, "report/prior_ent_mean": 33.27519989013672, "report/prior_ent_min": 32.33289337158203, "report/prior_ent_std": 0.34081214666366577, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0018951415549963713, "report/reward_loss_mean": 0.016082828864455223, "report/reward_loss_std": 0.2475225031375885, "report/reward_max_data": 0.84375, "report/reward_max_pred": 0.23395442962646484, "report/reward_neg_acc": 0.9980410933494568, "report/reward_neg_loss": 0.0029707560315728188, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.478558540344238, "report/reward_pred": 0.001645364798605442, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.012091298587620258, "eval/cont_loss_std": 0.19230325520038605, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.3310933113098145, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036392398178577423, "eval/cont_pred": 0.9963781833648682, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08755186945199966, "eval/image_loss_std": 0.1126997321844101, "eval/model_loss_mean": 0.7117452025413513, "eval/model_loss_std": 0.44810935854911804, "eval/post_ent_mag": 34.553138732910156, "eval/post_ent_max": 34.553138732910156, "eval/post_ent_mean": 34.055267333984375, "eval/post_ent_min": 33.618568420410156, "eval/post_ent_std": 0.23344607651233673, "eval/prior_ent_mag": 34.304378509521484, "eval/prior_ent_max": 34.304378509521484, "eval/prior_ent_mean": 33.218406677246094, "eval/prior_ent_min": 32.367286682128906, "eval/prior_ent_std": 0.37888312339782715, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0015411376953125, "eval/reward_loss_mean": 0.012101991102099419, "eval/reward_loss_std": 0.22859933972358704, "eval/reward_max_data": 0.8031250238418579, "eval/reward_max_pred": 0.04863452911376953, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0021053904201835394, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.120364665985107, "eval/reward_pred": 0.0011127815814688802, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32400.0, "replay/samples": 32400.0, "replay/insert_wait_avg": 1.2127484804318275e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.536013921101888e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4504.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0777536124573296e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0270907878876, "timer/env.step_count": 4050.0, "timer/env.step_total": 38.78045129776001, "timer/env.step_frac": 0.038779400733240335, "timer/env.step_avg": 0.00957542007352099, "timer/env.step_min": 0.0076563358306884766, "timer/env.step_max": 0.038916587829589844, "timer/replay._sample_count": 32400.0, "timer/replay._sample_total": 16.47581124305725, "timer/replay._sample_frac": 0.01647536491244104, "timer/replay._sample_avg": 0.0005085126926869522, "timer/replay._sample_min": 0.00041365623474121094, "timer/replay._sample_max": 0.010682344436645508, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4613.0, "timer/agent.policy_total": 47.89394402503967, "timer/agent.policy_frac": 0.04789264657550992, "timer/agent.policy_avg": 0.010382385437901511, "timer/agent.policy_min": 0.009051084518432617, "timer/agent.policy_max": 0.08366990089416504, "timer/dataset_train_count": 2025.0, "timer/dataset_train_total": 0.21362566947937012, "timer/dataset_train_frac": 0.00021361988234844885, "timer/dataset_train_avg": 0.00010549415776759019, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0010678768157958984, "timer/agent.train_count": 2025.0, "timer/agent.train_total": 902.3349089622498, "timer/agent.train_frac": 0.9023104646608429, "timer/agent.train_avg": 0.4455974859072838, "timer/agent.train_min": 0.4342215061187744, "timer/agent.train_max": 0.7719221115112305, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47766995429992676, "timer/agent.report_frac": 0.0004776570141950722, "timer/agent.report_avg": 0.23883497714996338, "timer/agent.report_min": 0.2316293716430664, "timer/agent.report_max": 0.24604058265686035, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0516751402160746e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 32.39842430244125}
{"step": 1195000, "time": 37279.05340361595, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1195008, "time": 37279.523839235306, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1195288, "time": 37287.96492910385, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1195488, "time": 37294.31634092331, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1195600, "time": 37297.71697688103, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1195808, "time": 37304.07208895683, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1195992, "time": 37309.44919466972, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1196000, "time": 37309.92246198654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1196128, "time": 37314.43666243553, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1196192, "time": 37316.38402700424, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 1196336, "time": 37320.76364612579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1196360, "time": 37321.27348327637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1196424, "time": 37323.21338534355, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1196552, "time": 37327.10748386383, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1196760, "time": 37333.436346530914, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1196848, "time": 37336.32062005997, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1196928, "time": 37338.77105998993, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1197296, "time": 37350.08407044411, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1197296, "time": 37350.09108710289, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1197312, "time": 37350.58442187309, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1197384, "time": 37352.550481557846, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1197536, "time": 37357.41155195236, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1197856, "time": 37367.17373776436, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1197952, "time": 37370.1292424202, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1198032, "time": 37372.67906165123, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1198184, "time": 37377.078976631165, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1198312, "time": 37380.99187660217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1198336, "time": 37381.95863747597, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1198352, "time": 37382.469670534134, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1198536, "time": 37387.88488149643, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1198536, "time": 37387.89370441437, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1198696, "time": 37392.79680562019, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1199072, "time": 37404.527221918106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1199264, "time": 37410.37210726738, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1200024, "time": 37433.305478811264, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1200056, "time": 37434.68106460571, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 1200056, "time": 37435.08841109276, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1200056, "time": 37436.153083086014, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1200056, "time": 37436.70206737518, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1200056, "time": 37437.69698834419, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1200056, "time": 37438.04228305817, "eval_episode/length": 170.0, "eval_episode/score": 0.46875, "eval_episode/reward_rate": 0.005847953216374269}
{"step": 1200056, "time": 37438.239884376526, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1200056, "time": 37439.225892305374, "eval_episode/length": 233.0, "eval_episode/score": 0.2718749940395355, "eval_episode/reward_rate": 0.004273504273504274}
{"step": 1200096, "time": 37440.65881681442, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1200344, "time": 37447.97591662407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1200400, "time": 37449.89325642586, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1200432, "time": 37450.882475852966, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1200496, "time": 37452.819857120514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1200552, "time": 37454.290212869644, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1200664, "time": 37457.69197559357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1200832, "time": 37463.084298849106, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1200848, "time": 37463.576196193695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1200848, "time": 37463.58397293091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1201064, "time": 37469.94593310356, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1201472, "time": 37482.64413142204, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1201480, "time": 37482.669949531555, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1201848, "time": 37494.01364040375, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1201872, "time": 37494.978162527084, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1202144, "time": 37503.21937775612, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1202712, "time": 37520.338908195496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1202744, "time": 37521.35050058365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1202776, "time": 37522.32339501381, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1202808, "time": 37523.30384969711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1203144, "time": 37533.48560976982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1203208, "time": 37535.441039800644, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1203272, "time": 37537.3805603981, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1203424, "time": 37542.23354911804, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1203752, "time": 37552.097182273865, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1203792, "time": 37553.55954623222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1204160, "time": 37564.75834822655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1204240, "time": 37567.700427770615, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1205024, "time": 37591.68905735016, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 1205024, "time": 37591.69605922699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1205040, "time": 37592.186743974686, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1205368, "time": 37601.9590613842, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1205424, "time": 37603.89861321449, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1205448, "time": 37604.4076499939, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1205456, "time": 37604.87791323662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1205584, "time": 37608.77159309387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1205616, "time": 37609.740329265594, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1205808, "time": 37615.69817328453, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1206016, "time": 37622.03552746773, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1206064, "time": 37623.50821137428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1206280, "time": 37629.89012384415, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1206472, "time": 37635.72043943405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1206528, "time": 37637.67176032066, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1206744, "time": 37644.083052158356, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1206808, "time": 37646.037110090256, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1207000, "time": 37651.929148197174, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1207040, "time": 37653.395844221115, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1207480, "time": 37666.65298938751, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1207568, "time": 37669.5392537117, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1207568, "time": 37669.544775009155, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1207656, "time": 37672.12229371071, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1207768, "time": 37675.51130604744, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1207800, "time": 37676.49953174591, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1207968, "time": 37681.81640315056, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1208088, "time": 37685.24219059944, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1208376, "time": 37693.97776222229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1208400, "time": 37694.93580365181, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1208400, "time": 37694.945190668106, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1208432, "time": 37695.93765068054, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1208752, "time": 37705.76709961891, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1209216, "time": 37719.83231639862, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1209304, "time": 37722.286274433136, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1209488, "time": 37728.105597257614, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1209872, "time": 37739.88602948189, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1209880, "time": 37739.9132668972, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1209880, "time": 37739.92125058174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1210008, "time": 37743.81565642357, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 1210040, "time": 37745.69493317604, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1210040, "time": 37746.23491334915, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1210040, "time": 37746.52453494072, "eval_episode/length": 15.0, "eval_episode/score": 0.953125, "eval_episode/reward_rate": 0.0625}
{"step": 1210040, "time": 37746.56567311287, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1210040, "time": 37747.10659599304, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1210040, "time": 37747.52646160126, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1210040, "time": 37747.62555861473, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 1210040, "time": 37747.956040382385, "eval_episode/length": 162.0, "eval_episode/score": 0.4937500059604645, "eval_episode/reward_rate": 0.006134969325153374}
{"step": 1210088, "time": 37749.40407013893, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1210400, "time": 37759.07601261139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1210544, "time": 37763.56071996689, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 1210576, "time": 37764.532474279404, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1210592, "time": 37765.02056646347, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1210688, "time": 37767.944417238235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1211112, "time": 37780.610886096954, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1211152, "time": 37782.07644200325, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1211496, "time": 37792.33905887604, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1211560, "time": 37794.27524781227, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1211800, "time": 37801.60102200508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1211920, "time": 37805.51807332039, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1211960, "time": 37806.53561592102, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1212144, "time": 37812.366850852966, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1212176, "time": 37813.35803246498, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1212320, "time": 37817.80097723007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1212664, "time": 37828.60645508766, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1212672, "time": 37829.073040008545, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1212856, "time": 37834.40952515602, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1213000, "time": 37838.78476977348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1213296, "time": 37847.97289276123, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1213464, "time": 37852.923587322235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1213512, "time": 37854.37564444542, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1213808, "time": 37863.58159947395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1213864, "time": 37865.06461620331, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1214224, "time": 37876.2509663105, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1214272, "time": 37877.7048034668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1214632, "time": 37888.471635103226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1214984, "time": 37899.16971492767, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1214984, "time": 37899.178552150726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1215312, "time": 37909.387942790985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1215400, "time": 37911.90056991577, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1215464, "time": 37913.843584775925, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1215736, "time": 37922.14517235756, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1215776, "time": 37923.61042189598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1216024, "time": 37931.030217170715, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1216120, "time": 37933.95935201645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1216176, "time": 37935.888147592545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1216400, "time": 37942.80967116356, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1216536, "time": 37946.771622657776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1216808, "time": 37955.03839159012, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1217008, "time": 37961.364448308945, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1217040, "time": 37962.34544610977, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1217176, "time": 37966.25708627701, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1217320, "time": 37970.7365500927, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1217624, "time": 37980.03360295296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1217656, "time": 37981.00860667229, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1217672, "time": 37981.49428009987, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1217776, "time": 37984.87353491783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1218024, "time": 37992.1623146534, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1218048, "time": 37993.13689208031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1218088, "time": 37994.13651061058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1218464, "time": 38005.93203306198, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1218480, "time": 38006.41928267479, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1218488, "time": 38006.44615125656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1218584, "time": 38009.3679857254, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1218968, "time": 38021.05208325386, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1219304, "time": 38031.41862106323, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1219320, "time": 38031.92843461037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1219560, "time": 38039.19802880287, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1219928, "time": 38050.34522771835, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1220024, "time": 38053.86703968048, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 1220024, "time": 38054.21515870094, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1220024, "time": 38054.54843521118, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1220024, "time": 38055.17441868782, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1220024, "time": 38055.21712875366, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1220024, "time": 38055.65291810036, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1220024, "time": 38055.81989765167, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1220024, "time": 38056.07048559189, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 1220040, "time": 38056.56599879265, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1220144, "time": 38059.95401215553, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1220336, "time": 38065.9114177227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1220360, "time": 38066.41847038269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1220400, "time": 38067.849266052246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1220432, "time": 38068.84011220932, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1220440, "time": 38068.866200208664, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1220664, "time": 38076.12268161774, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1220792, "time": 38080.01438212395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1220816, "time": 38080.96589803696, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1220888, "time": 38082.92489385605, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1220928, "time": 38084.37348270416, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1221064, "time": 38088.270141363144, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1221192, "time": 38092.239025592804, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1221336, "time": 38096.61139726639, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1221400, "time": 38098.568690776825, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1221656, "time": 38106.32955765724, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1221680, "time": 38107.28039765358, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1221808, "time": 38111.176855802536, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1222104, "time": 38119.946791648865, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1222152, "time": 38121.51608419418, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1222528, "time": 38133.24279475212, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1222712, "time": 38138.67368507385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1222912, "time": 38145.00974392891, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1222952, "time": 38146.00848150253, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1223024, "time": 38148.432681798935, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1223128, "time": 38151.47774100304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1223168, "time": 38152.942645549774, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1223312, "time": 38157.33478856087, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1223504, "time": 38163.1602973938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1223648, "time": 38167.54897379875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1223744, "time": 38170.46859455109, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1223800, "time": 38171.966089725494, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1224176, "time": 38183.698313713074, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1224528, "time": 38194.3627409935, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1224896, "time": 38205.521040439606, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1225016, "time": 38208.95381450653, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1225024, "time": 38209.422365903854, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1225200, "time": 38214.85291647911, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1225224, "time": 38215.361006975174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1225264, "time": 38216.80290865898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1225344, "time": 38219.23348879814, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1225896, "time": 38235.78523397446, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1225960, "time": 38237.71513700485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1225968, "time": 38238.18176436424, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1226112, "time": 38242.680830955505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1226216, "time": 38245.67943692207, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1226496, "time": 38254.47175192833, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1226824, "time": 38264.23642206192, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1227097, "time": 38273.59647870064, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.401628332944652, "train/action_min": 0.0, "train/action_std": 1.705571118278883, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010659087569781798, "train/actor_opt_grad_steps": 75590.0, "train/actor_opt_loss": -22.8122545735753, "train/adv_mag": 0.769675675019696, "train/adv_max": 0.31228710703588836, "train/adv_mean": 0.00021828293054441651, "train/adv_min": -0.7010810425625512, "train/adv_std": 0.02734716155042696, "train/cont_avg": 0.9942912391169154, "train/cont_loss_mean": 0.022923035706991134, "train/cont_loss_std": 0.27013312931177186, "train/cont_neg_acc": 0.18086237743496894, "train/cont_neg_loss": 3.1485357838869095, "train/cont_pos_acc": 0.999829009990787, "train/cont_pos_loss": 0.004818424287099225, "train/cont_pred": 0.9942604045369732, "train/cont_rate": 0.9942912391169154, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09802968992355895, "train/extr_critic_critic_opt_grad_steps": 75590.0, "train/extr_critic_critic_opt_loss": 12772.901440065298, "train/extr_critic_mag": 1.463969377735954, "train/extr_critic_max": 1.463969377735954, "train/extr_critic_mean": 1.3350858842555564, "train/extr_critic_min": 1.016017827821608, "train/extr_critic_std": 0.0277099483808623, "train/extr_return_normed_mag": 0.7939450580682328, "train/extr_return_normed_max": 0.2957987097365346, "train/extr_return_normed_mean": 0.055392148260453446, "train/extr_return_normed_min": -0.6946649646284568, "train/extr_return_normed_std": 0.03954402868872258, "train/extr_return_rate": 0.9996362900852565, "train/extr_return_raw_mag": 1.5757106732373214, "train/extr_return_raw_max": 1.5757106732373214, "train/extr_return_raw_mean": 1.3353041754433173, "train/extr_return_raw_min": 0.5852469988723299, "train/extr_return_raw_std": 0.0395440285589861, "train/extr_reward_mag": 0.2746872996809471, "train/extr_reward_max": 0.2746872996809471, "train/extr_reward_mean": 0.0021472728309633944, "train/extr_reward_min": 8.896215638118004e-08, "train/extr_reward_std": 0.008620665571999862, "train/image_loss_mean": 0.07089191760441557, "train/image_loss_std": 0.09257457101374716, "train/model_loss_mean": 0.7103009647990933, "train/model_loss_std": 0.4961161381792073, "train/model_opt_grad_norm": 16.322324112280093, "train/model_opt_grad_steps": 75517.38308457712, "train/model_opt_loss": 3711.168033125389, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5223.880597014925, "train/policy_entropy_mag": 1.2577382160063406, "train/policy_entropy_max": 1.2577382160063406, "train/policy_entropy_mean": 0.0970857763171789, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12102881748581407, "train/policy_logprob_mag": 6.551080267227705, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09737854206295156, "train/policy_logprob_min": -6.551080267227705, "train/policy_logprob_std": 0.6356147738238472, "train/policy_randomness_mag": 0.6463496240217295, "train/policy_randomness_max": 0.6463496240217295, "train/policy_randomness_mean": 0.049892223537413044, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0621965122015322, "train/post_ent_mag": 34.53403563997639, "train/post_ent_max": 34.53403563997639, "train/post_ent_mean": 34.062617059963856, "train/post_ent_min": 33.577758086854544, "train/post_ent_std": 0.20915512288387736, "train/prior_ent_mag": 34.01765586131841, "train/prior_ent_max": 34.01765586131841, "train/prior_ent_mean": 33.09354599909996, "train/prior_ent_min": 32.12111866889308, "train/prior_ent_std": 0.3441287500051717, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0023457237715666084, "train/reward_loss_mean": 0.016485991480005024, "train/reward_loss_std": 0.23961642496658497, "train/reward_max_data": 0.8108830840433415, "train/reward_max_pred": 0.2984442046625697, "train/reward_neg_acc": 0.999429632182145, "train/reward_neg_loss": 0.003016286914176609, "train/reward_pos_acc": 0.1815515898168087, "train/reward_pos_loss": 4.009711390137673, "train/reward_pred": 0.0018336327326025313, "train/reward_rate": 0.0033961054104477612, "train_stats/mean_log_entropy": 0.08351167974958443, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.028170285746455193, "report/cont_loss_std": 0.31657543778419495, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 3.503662109375, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004248515702784061, "report/cont_pred": 0.9947574138641357, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07308313250541687, "report/image_loss_std": 0.09333205968141556, "report/model_loss_mean": 0.7270708084106445, "report/model_loss_std": 0.6563189029693604, "report/post_ent_mag": 34.58608627319336, "report/post_ent_max": 34.58608627319336, "report/post_ent_mean": 33.99419403076172, "report/post_ent_min": 33.413673400878906, "report/post_ent_std": 0.2632368206977844, "report/prior_ent_mag": 33.923362731933594, "report/prior_ent_max": 33.923362731933594, "report/prior_ent_mean": 32.89988708496094, "report/prior_ent_min": 31.803478240966797, "report/prior_ent_std": 0.3929264545440674, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003662109375, "report/reward_loss_mean": 0.02581736259162426, "report/reward_loss_std": 0.3363129496574402, "report/reward_max_data": 0.903124988079071, "report/reward_max_pred": 0.02868950366973877, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0024500375147908926, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.788078308105469, "report/reward_pred": 0.0013315498363226652, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03980384021997452, "eval/cont_loss_std": 0.49317699670791626, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.928166389465332, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.006004223134368658, "eval/cont_pred": 0.9945523738861084, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.0906732976436615, "eval/image_loss_std": 0.11293479055166245, "eval/model_loss_mean": 0.7657451629638672, "eval/model_loss_std": 1.007429599761963, "eval/post_ent_mag": 34.58729553222656, "eval/post_ent_max": 34.58729553222656, "eval/post_ent_mean": 34.05109786987305, "eval/post_ent_min": 33.38328170776367, "eval/post_ent_std": 0.24504023790359497, "eval/prior_ent_mag": 33.923362731933594, "eval/prior_ent_max": 33.923362731933594, "eval/prior_ent_mean": 32.93975830078125, "eval/prior_ent_min": 31.794662475585938, "eval/prior_ent_std": 0.3745785355567932, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002923583844676614, "eval/reward_loss_mean": 0.035268016159534454, "eval/reward_loss_std": 0.513185977935791, "eval/reward_max_data": 0.925000011920929, "eval/reward_max_pred": 0.3959418535232544, "eval/reward_neg_acc": 0.9980391263961792, "eval/reward_neg_loss": 0.003587893443182111, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.11369800567627, "eval/reward_pred": 0.0017087075393646955, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32208.0, "replay/samples": 32208.0, "replay/insert_wait_avg": 1.2137525068606183e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.561765614872955e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4368.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0922059908018008e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2399349212646, "timer/env.step_count": 4026.0, "timer/env.step_total": 38.704572439193726, "timer/env.step_frac": 0.03869528808829295, "timer/env.step_avg": 0.009613654356481302, "timer/env.step_min": 0.007747650146484375, "timer/env.step_max": 0.03579854965209961, "timer/replay._sample_count": 32208.0, "timer/replay._sample_total": 16.57036566734314, "timer/replay._sample_frac": 0.0165663908116681, "timer/replay._sample_avg": 0.0005144798083501969, "timer/replay._sample_min": 0.0003681182861328125, "timer/replay._sample_max": 0.011687517166137695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4572.0, "timer/agent.policy_total": 47.91673803329468, "timer/agent.policy_frac": 0.047905243892373196, "timer/agent.policy_avg": 0.010480476385235056, "timer/agent.policy_min": 0.008533239364624023, "timer/agent.policy_max": 0.09085583686828613, "timer/dataset_train_count": 2013.0, "timer/dataset_train_total": 0.21057391166687012, "timer/dataset_train_frac": 0.00021052339975152637, "timer/dataset_train_avg": 0.0001046070102667015, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0003542900085449219, "timer/agent.train_count": 2013.0, "timer/agent.train_total": 899.9044215679169, "timer/agent.train_frac": 0.8996885548653425, "timer/agent.train_avg": 0.4470464091246482, "timer/agent.train_min": 0.4364163875579834, "timer/agent.train_max": 0.6789929866790771, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47646474838256836, "timer/agent.report_frac": 0.00047635045527358793, "timer/agent.report_avg": 0.23823237419128418, "timer/agent.report_min": 0.23092198371887207, "timer/agent.report_max": 0.2455427646636963, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9318450709329642e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 32.199739676452445}
{"step": 1227128, "time": 38274.27832984924, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1227336, "time": 38280.63586139679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1227488, "time": 38285.45290160179, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1227536, "time": 38286.90097761154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1227544, "time": 38286.92827296257, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1227576, "time": 38287.89644622803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1228000, "time": 38301.04956817627, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1228176, "time": 38306.381539583206, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1228336, "time": 38311.22373199463, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1228424, "time": 38313.66519880295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1228664, "time": 38320.967284440994, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1228672, "time": 38321.435747385025, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1228896, "time": 38328.68641090393, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1228904, "time": 38328.71331071854, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1229040, "time": 38333.15078020096, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1229264, "time": 38339.92162489891, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1229440, "time": 38345.2239317894, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1229464, "time": 38345.734327316284, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1229464, "time": 38345.74143075943, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1229752, "time": 38354.426590681076, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1229768, "time": 38354.91350674629, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1230008, "time": 38362.79281377792, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 1230008, "time": 38363.18785881996, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1230008, "time": 38363.38899040222, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1230008, "time": 38363.432072639465, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1230008, "time": 38364.15885567665, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1230008, "time": 38364.33034491539, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1230008, "time": 38364.68728303909, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1230008, "time": 38364.76568245888, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1230016, "time": 38365.23411178589, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1230048, "time": 38366.23114347458, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1230272, "time": 38372.9862537384, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1230344, "time": 38374.95030283928, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1230360, "time": 38375.455763578415, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1230648, "time": 38384.13501787186, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1230736, "time": 38387.03574967384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1230960, "time": 38393.966443777084, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1231328, "time": 38405.08478689194, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1231352, "time": 38405.59493684769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1231544, "time": 38411.4005715847, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1231696, "time": 38416.21446752548, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1231712, "time": 38416.69746375084, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1231776, "time": 38418.61510038376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1231992, "time": 38424.996559381485, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 1232232, "time": 38432.21731686592, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1232456, "time": 38438.97175693512, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1232584, "time": 38442.83693122864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1232624, "time": 38444.302706718445, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1232680, "time": 38445.76901388168, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1232752, "time": 38448.19014978409, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1232872, "time": 38451.67900276184, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1233048, "time": 38457.02723836899, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1233264, "time": 38463.827390909195, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1233472, "time": 38470.12301468849, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1233496, "time": 38470.63493561745, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1233728, "time": 38477.86028575897, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1234352, "time": 38496.809561014175, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1234544, "time": 38502.593781232834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1234768, "time": 38509.386145591736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1234936, "time": 38514.28738451004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1234992, "time": 38516.209995508194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1235576, "time": 38533.61008667946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1235648, "time": 38536.01703262329, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1235760, "time": 38539.369837999344, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1235784, "time": 38539.878652095795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1235808, "time": 38540.9052901268, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1235936, "time": 38544.73847913742, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1235952, "time": 38545.24797463417, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1236040, "time": 38547.67538714409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1236360, "time": 38557.29198336601, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1236408, "time": 38558.73661661148, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1236432, "time": 38559.6971886158, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1236504, "time": 38561.65145659447, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1236728, "time": 38568.402824640274, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1236760, "time": 38569.38533329964, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1236920, "time": 38574.2671148777, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1236960, "time": 38575.685598134995, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1237000, "time": 38576.887888908386, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1237184, "time": 38582.95231485367, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1237472, "time": 38591.67970967293, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1237656, "time": 38597.02287864685, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1237984, "time": 38607.30390572548, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1238016, "time": 38608.26795625687, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1238096, "time": 38610.690626621246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1238224, "time": 38614.55823493004, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1238352, "time": 38618.40034508705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1238376, "time": 38618.90249609947, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1238432, "time": 38620.81202721596, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1238440, "time": 38620.83789730072, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1238568, "time": 38624.69804024696, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1238976, "time": 38637.34716629982, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1239056, "time": 38639.800787210464, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1239544, "time": 38654.43366241455, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1239912, "time": 38665.57388615608, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1240024, "time": 38668.95466709137, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1240096, "time": 38671.99258875847, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1240096, "time": 38672.28982138634, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1240096, "time": 38672.58352279663, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1240096, "time": 38672.73981523514, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1240096, "time": 38673.50618863106, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1240096, "time": 38673.94122648239, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1240096, "time": 38674.0531539917, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1240096, "time": 38674.06122350693, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1240296, "time": 38679.895741701126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1240408, "time": 38683.27907729149, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1240408, "time": 38683.28695368767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1240656, "time": 38691.10623764992, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1240664, "time": 38691.13751935959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1240688, "time": 38692.08203458786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1240688, "time": 38692.089534044266, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1240728, "time": 38693.08332943916, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 1241120, "time": 38705.17448782921, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1241536, "time": 38717.74599838257, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1241656, "time": 38721.30505490303, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1241656, "time": 38721.314247369766, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1241856, "time": 38727.59409213066, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1241872, "time": 38728.10118603706, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1242008, "time": 38731.98841547966, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1242328, "time": 38741.72192454338, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1242424, "time": 38744.658035993576, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1242608, "time": 38750.55895233154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1242720, "time": 38753.958300590515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1242816, "time": 38756.83577656746, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1242952, "time": 38760.72898864746, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1243040, "time": 38763.60987305641, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1243256, "time": 38769.96956515312, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1243328, "time": 38772.38880228996, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1243432, "time": 38775.30968332291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1243664, "time": 38782.63017678261, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1244040, "time": 38793.76500034332, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1244144, "time": 38797.12792301178, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1244152, "time": 38797.15473127365, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1244168, "time": 38797.644342660904, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1244256, "time": 38800.51296544075, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1244416, "time": 38805.34039187431, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1244456, "time": 38806.349267721176, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1244648, "time": 38812.2534365654, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1244920, "time": 38820.43220663071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1244936, "time": 38820.91743373871, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1245272, "time": 38831.68948984146, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1245440, "time": 38836.994906425476, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1245640, "time": 38842.90813446045, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1245744, "time": 38846.28551912308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1245848, "time": 38849.18699216843, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1245872, "time": 38850.14779663086, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1246192, "time": 38859.82171750069, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1246232, "time": 38860.80859184265, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1246456, "time": 38867.582634687424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1246512, "time": 38869.500965833664, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1246568, "time": 38871.093719244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1246584, "time": 38871.57896375656, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1246728, "time": 38875.93089771271, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 1247144, "time": 38888.43427181244, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1247232, "time": 38891.321403980255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1247272, "time": 38892.33042526245, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1247680, "time": 38905.01957345009, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1247688, "time": 38905.04721426964, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1247904, "time": 38911.79778075218, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1248056, "time": 38916.191009521484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1248072, "time": 38916.68379831314, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1248312, "time": 38923.9600083828, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1248528, "time": 38930.81483459473, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1248544, "time": 38931.30645632744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1248640, "time": 38934.22826361656, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1248640, "time": 38934.23760390282, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1249040, "time": 38946.30522823334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1249072, "time": 38947.2927377224, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1249192, "time": 38950.69358539581, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1249296, "time": 38954.046813964844, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1249344, "time": 38955.497621536255, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1249640, "time": 38964.25766038895, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1249840, "time": 38970.50009417534, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1249864, "time": 38971.011590480804, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1250000, "time": 38975.39948129654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1250080, "time": 38979.11644625664, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1250080, "time": 38979.23298239708, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1250080, "time": 38979.57432746887, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1250080, "time": 38979.62220740318, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1250080, "time": 38980.22598576546, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1250080, "time": 38980.61462831497, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 1250080, "time": 38981.00779771805, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1250080, "time": 38981.160957574844, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1250200, "time": 38984.6051902771, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1250952, "time": 39007.32431387901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1251032, "time": 39009.76462650299, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1251352, "time": 39019.44115233421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1251384, "time": 39020.50007271767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1251832, "time": 39033.995764255524, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1251952, "time": 39037.81909418106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1251984, "time": 39038.78187704086, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1252024, "time": 39039.76764202118, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1252088, "time": 39041.69359087944, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1252152, "time": 39043.63572692871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1252176, "time": 39044.5824174881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1252320, "time": 39048.942153692245, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1252376, "time": 39050.53921222687, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1252520, "time": 39054.908823251724, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1252544, "time": 39055.854632377625, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1252680, "time": 39059.74408531189, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1253016, "time": 39069.86706781387, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1253464, "time": 39083.97448849678, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1253472, "time": 39084.439433813095, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1253480, "time": 39084.46606302261, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1254144, "time": 39104.709320783615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1254208, "time": 39106.66107058525, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1254336, "time": 39110.63000917435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1254400, "time": 39112.58304166794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1254464, "time": 39114.540142059326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1254600, "time": 39118.44032120705, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1254960, "time": 39129.50647568703, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1255328, "time": 39140.69024634361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1255384, "time": 39142.15880036354, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1255488, "time": 39145.52607560158, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1255536, "time": 39146.97355103493, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1255720, "time": 39152.34565639496, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1255784, "time": 39154.28627252579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1256040, "time": 39162.057904958725, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1256168, "time": 39165.942041397095, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1256472, "time": 39175.209517240524, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1256696, "time": 39181.96013689041, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1256776, "time": 39184.38722085953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1256848, "time": 39186.77002000809, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1256856, "time": 39186.79621171951, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1256952, "time": 39189.701857089996, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1257008, "time": 39191.60889172554, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1257272, "time": 39199.35187911987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1257776, "time": 39214.8749935627, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1257800, "time": 39215.39293575287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1257848, "time": 39216.84573149681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1258032, "time": 39222.64088845253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1258152, "time": 39226.02195930481, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1258656, "time": 39241.515099048615, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1258728, "time": 39243.489246845245, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1258768, "time": 39244.92117500305, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1258888, "time": 39248.34986758232, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1259048, "time": 39253.20927286148, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1259160, "time": 39256.608335494995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1259464, "time": 39265.945152044296, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1259689, "time": 39273.89860677719, "train_stats/mean_log_entropy": 0.08159904671119195, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.474265304266238, "train/action_min": 0.0, "train/action_std": 1.7522195758772832, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01210653321023154, "train/actor_opt_grad_steps": 77615.0, "train/actor_opt_loss": -28.072617465374517, "train/adv_mag": 0.7668635503334158, "train/adv_max": 0.33825262270721734, "train/adv_mean": 0.0013108787521686923, "train/adv_min": -0.6947077562411627, "train/adv_std": 0.02964011400791944, "train/cont_avg": 0.9943081724877451, "train/cont_loss_mean": 0.023158761624739888, "train/cont_loss_std": 0.27382682053847057, "train/cont_neg_acc": 0.1743965020467495, "train/cont_neg_loss": 3.224894828397065, "train/cont_pos_acc": 0.9998603565435783, "train/cont_pos_loss": 0.004790466257106221, "train/cont_pred": 0.9943460231902552, "train/cont_rate": 0.9943081724877451, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12219703473223775, "train/extr_critic_critic_opt_grad_steps": 77615.0, "train/extr_critic_critic_opt_loss": 13068.742173138788, "train/extr_critic_mag": 1.5102359687580782, "train/extr_critic_max": 1.5102359687580782, "train/extr_critic_mean": 1.3795281940815496, "train/extr_critic_min": 1.057125587089389, "train/extr_critic_std": 0.03472052409551015, "train/extr_return_normed_mag": 0.7873034541513405, "train/extr_return_normed_max": 0.3294403938686146, "train/extr_return_normed_mean": 0.07347663250916145, "train/extr_return_normed_min": -0.6670995775391074, "train/extr_return_normed_std": 0.04619546775140014, "train/extr_return_rate": 0.9996607844151703, "train/extr_return_raw_mag": 1.6368027265165366, "train/extr_return_raw_max": 1.6368027265165366, "train/extr_return_raw_mean": 1.3808390404663833, "train/extr_return_raw_min": 0.6402627551088146, "train/extr_return_raw_std": 0.04619546779705321, "train/extr_reward_mag": 0.2770618398984273, "train/extr_reward_max": 0.2770618398984273, "train/extr_reward_mean": 0.0022826382357344103, "train/extr_reward_min": 7.830414117551317e-08, "train/extr_reward_std": 0.009007733922415212, "train/image_loss_mean": 0.07218806314117768, "train/image_loss_std": 0.09391864863973037, "train/model_loss_mean": 0.7122742013604033, "train/model_loss_std": 0.5029674509503678, "train/model_opt_grad_norm": 16.642264398874023, "train/model_opt_grad_steps": 77540.4705882353, "train/model_opt_loss": 3772.335177552466, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5294.117647058823, "train/policy_entropy_mag": 1.2351656082798452, "train/policy_entropy_max": 1.2351656082798452, "train/policy_entropy_mean": 0.09521886954704921, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11783754285059723, "train/policy_logprob_mag": 6.551080273646934, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09528604843745045, "train/policy_logprob_min": -6.551080273646934, "train/policy_logprob_std": 0.6326166213143105, "train/policy_randomness_mag": 0.6347495960254296, "train/policy_randomness_max": 0.6347495960254296, "train/policy_randomness_mean": 0.04893282358991165, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06055652131052578, "train/post_ent_mag": 34.70629701427385, "train/post_ent_max": 34.70629701427385, "train/post_ent_mean": 34.091337297476976, "train/post_ent_min": 33.455382664998375, "train/post_ent_std": 0.26867389467124847, "train/prior_ent_mag": 34.676749322928636, "train/prior_ent_max": 34.676749322928636, "train/prior_ent_mean": 33.64885661181282, "train/prior_ent_min": 32.46283034717335, "train/prior_ent_std": 0.39650087394550737, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0023901097834002974, "train/reward_loss_mean": 0.016927353778680532, "train/reward_loss_std": 0.24178013521219222, "train/reward_max_data": 0.7889705877385887, "train/reward_max_pred": 0.32541873875786276, "train/reward_neg_acc": 0.9995580131516737, "train/reward_neg_loss": 0.0029516350460813984, "train/reward_pos_acc": 0.18797222536057234, "train/reward_pos_loss": 3.958379545211792, "train/reward_pred": 0.0018472151851336308, "train/reward_rate": 0.0035137101715686275, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.02346225269138813, "report/cont_loss_std": 0.27380895614624023, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.8125665187835693, "report/cont_pos_acc": 0.999018669128418, "report/cont_pos_loss": 0.004869985394179821, "report/cont_pred": 0.9955172538757324, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.058750592172145844, "report/image_loss_std": 0.07438501715660095, "report/model_loss_mean": 0.6900742650032043, "report/model_loss_std": 0.3428284823894501, "report/post_ent_mag": 35.050537109375, "report/post_ent_max": 35.050537109375, "report/post_ent_mean": 34.41310119628906, "report/post_ent_min": 33.832923889160156, "report/post_ent_std": 0.26369509100914, "report/prior_ent_mag": 35.08375930786133, "report/prior_ent_max": 35.08375930786133, "report/prior_ent_mean": 33.895896911621094, "report/prior_ent_min": 32.658531188964844, "report/prior_ent_std": 0.39853018522262573, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007263183360919356, "report/reward_loss_mean": 0.007861394435167313, "report/reward_loss_std": 0.11875191330909729, "report/reward_max_data": 0.7437499761581421, "report/reward_max_pred": 0.20221173763275146, "report/reward_neg_acc": 0.9990224838256836, "report/reward_neg_loss": 0.0044794934801757336, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.467545509338379, "report/reward_pred": 0.0016741228755563498, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02282489463686943, "eval/cont_loss_std": 0.3587993383407593, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.3270697593688965, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004301157314330339, "eval/cont_pred": 0.995764970779419, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.06561017036437988, "eval/image_loss_std": 0.08907364308834076, "eval/model_loss_mean": 0.7135251760482788, "eval/model_loss_std": 0.800763726234436, "eval/post_ent_mag": 35.030250549316406, "eval/post_ent_max": 35.030250549316406, "eval/post_ent_mean": 34.404293060302734, "eval/post_ent_min": 33.6961555480957, "eval/post_ent_std": 0.27399125695228577, "eval/prior_ent_mag": 34.83148956298828, "eval/prior_ent_max": 34.83148956298828, "eval/prior_ent_mean": 33.91295623779297, "eval/prior_ent_min": 32.33607482910156, "eval/prior_ent_std": 0.3804379105567932, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0021270751021802425, "eval/reward_loss_mean": 0.025090046226978302, "eval/reward_loss_std": 0.4165269732475281, "eval/reward_max_data": 0.871874988079071, "eval/reward_max_pred": 0.08880531787872314, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00363102275878191, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.328311920166016, "eval/reward_pred": 0.0017738102469593287, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 32592.0, "replay/samples": 32592.0, "replay/insert_wait_avg": 1.2174182858137038e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.543337947899767e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3632.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1100380431187835e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1614012718201, "timer/env.step_count": 4074.0, "timer/env.step_total": 38.77721190452576, "timer/env.step_frac": 0.03877095422320445, "timer/env.step_avg": 0.009518215980492331, "timer/env.step_min": 0.007714033126831055, "timer/env.step_max": 0.03535294532775879, "timer/replay._sample_count": 32592.0, "timer/replay._sample_total": 16.671915531158447, "timer/replay._sample_frac": 0.01666922509702753, "timer/replay._sample_avg": 0.000511533981687483, "timer/replay._sample_min": 0.00040602684020996094, "timer/replay._sample_max": 0.01498556137084961, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4528.0, "timer/agent.policy_total": 46.85561919212341, "timer/agent.policy_frac": 0.046848057856003156, "timer/agent.policy_avg": 0.010347972436423014, "timer/agent.policy_min": 0.008129596710205078, "timer/agent.policy_max": 0.08180594444274902, "timer/dataset_train_count": 2037.0, "timer/dataset_train_total": 0.2108762264251709, "timer/dataset_train_frac": 0.0002108421962265466, "timer/dataset_train_avg": 0.00010352293884397197, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0005280971527099609, "timer/agent.train_count": 2037.0, "timer/agent.train_total": 904.306741476059, "timer/agent.train_frac": 0.9041608087715933, "timer/agent.train_avg": 0.44394047200591996, "timer/agent.train_min": 0.43227052688598633, "timer/agent.train_max": 0.7084763050079346, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48134303092956543, "timer/agent.report_frac": 0.0004812653540893325, "timer/agent.report_avg": 0.24067151546478271, "timer/agent.report_min": 0.23373723030090332, "timer/agent.report_max": 0.2476058006286621, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.4565115116186205e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 32.58611135352972}
{"step": 1259704, "time": 39273.957441568375, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1259736, "time": 39275.29814863205, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1259968, "time": 39282.52622413635, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1260064, "time": 39286.43319749832, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1260064, "time": 39286.907259225845, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1260064, "time": 39287.11012649536, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1260064, "time": 39288.32068538666, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1260064, "time": 39289.00685667992, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 1260064, "time": 39289.07048559189, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1260064, "time": 39289.55138731003, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1260064, "time": 39291.494462013245, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1260200, "time": 39295.3798725605, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1260264, "time": 39297.31445860863, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1260344, "time": 39299.746059179306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1260368, "time": 39300.69797325134, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1260464, "time": 39303.605341911316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1260552, "time": 39306.02858567238, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1260640, "time": 39308.913408994675, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1260648, "time": 39308.940281391144, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1260960, "time": 39318.65879225731, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1260968, "time": 39318.687764167786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1261040, "time": 39321.158400774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1261640, "time": 39339.58716773987, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1261760, "time": 39343.503504276276, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1261816, "time": 39344.979672670364, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1261848, "time": 39345.948285102844, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1262016, "time": 39351.32439184189, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1262496, "time": 39365.89078569412, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1262504, "time": 39365.91909623146, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1262776, "time": 39374.164595127106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1262992, "time": 39381.09432220459, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1263280, "time": 39389.82908439636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1263320, "time": 39390.83893632889, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1263408, "time": 39393.72235226631, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1263528, "time": 39397.15049242973, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1263824, "time": 39406.30901098251, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1263936, "time": 39409.68198990822, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1263952, "time": 39410.254613637924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1264072, "time": 39413.80657243729, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1264072, "time": 39413.81475973129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1264224, "time": 39418.70724225044, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 1264776, "time": 39435.23481655121, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1265144, "time": 39446.42490649223, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1265200, "time": 39448.339617967606, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1265248, "time": 39449.810089826584, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1265432, "time": 39455.16858768463, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1265720, "time": 39463.95222687721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1265840, "time": 39467.809087753296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1266064, "time": 39474.687504291534, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1266136, "time": 39476.64527797699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1266312, "time": 39481.98055100441, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1266384, "time": 39484.391489982605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1266592, "time": 39490.68959617615, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1266728, "time": 39494.57842350006, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1266792, "time": 39496.52848434448, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1267512, "time": 39518.45863723755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1267560, "time": 39519.918912649155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1267760, "time": 39526.154237508774, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1267888, "time": 39530.043555021286, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1267928, "time": 39531.13611674309, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1268688, "time": 39554.35807681084, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1268696, "time": 39554.387892484665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1268712, "time": 39554.878103256226, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1268904, "time": 39560.79754447937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1268984, "time": 39563.25862455368, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1269040, "time": 39565.17791366577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1269152, "time": 39568.60967159271, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1269272, "time": 39572.032625198364, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1269320, "time": 39573.47774362564, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1269376, "time": 39575.38526034355, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1269824, "time": 39589.39973306656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1270032, "time": 39595.806982278824, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1270048, "time": 39597.54928731918, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1270048, "time": 39597.71250104904, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1270048, "time": 39597.80905556679, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1270048, "time": 39598.16661334038, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1270048, "time": 39599.04732680321, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1270048, "time": 39599.662752866745, "eval_episode/length": 184.0, "eval_episode/score": 0.42500001192092896, "eval_episode/reward_rate": 0.005405405405405406}
{"step": 1270048, "time": 39599.6861948967, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1270048, "time": 39600.048901081085, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1270072, "time": 39600.55093359947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1270280, "time": 39606.81183075905, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1270544, "time": 39615.000561475754, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1270560, "time": 39615.49096632004, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1270648, "time": 39617.914145469666, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1271008, "time": 39629.099363565445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1271040, "time": 39630.070476293564, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1271080, "time": 39631.0562608242, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1271192, "time": 39634.442638635635, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 1271320, "time": 39638.37322115898, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1271584, "time": 39646.690475702286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1271624, "time": 39647.685527801514, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1271656, "time": 39648.67311835289, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1271776, "time": 39652.61980652809, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1272496, "time": 39674.41646504402, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1272576, "time": 39676.82859873772, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1272704, "time": 39680.828226327896, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1272960, "time": 39688.67644429207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1273288, "time": 39698.38331580162, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1273320, "time": 39699.35939478874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1273352, "time": 39700.33460402489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1273392, "time": 39701.78051996231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1273688, "time": 39710.61407375336, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1273800, "time": 39714.01745223999, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1274072, "time": 39722.27845907211, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1274088, "time": 39722.7779071331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1274192, "time": 39726.258073329926, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1274728, "time": 39742.43911957741, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1274808, "time": 39744.87790632248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1274888, "time": 39747.31863617897, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1275024, "time": 39751.67819714546, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1275256, "time": 39758.49639391899, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1275288, "time": 39759.47771024704, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1275600, "time": 39769.13326239586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1275664, "time": 39771.192793130875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1275856, "time": 39777.01226592064, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1275896, "time": 39778.01194667816, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1276088, "time": 39783.837990283966, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1276112, "time": 39784.81042766571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1276152, "time": 39785.803726911545, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1276424, "time": 39793.981728076935, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1276664, "time": 39801.308624982834, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1276736, "time": 39803.69777941704, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1276784, "time": 39805.1669485569, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1276808, "time": 39805.67094993591, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1277040, "time": 39812.88391518593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1277048, "time": 39812.91084456444, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1277264, "time": 39819.671311855316, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1277376, "time": 39823.049611091614, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1277736, "time": 39833.78977894783, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1278032, "time": 39843.475199222565, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1278304, "time": 39851.690011024475, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1278400, "time": 39854.6068379879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1278736, "time": 39864.926070690155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1278976, "time": 39872.225142240524, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1279096, "time": 39875.647052288055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1279120, "time": 39876.58979177475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1279256, "time": 39880.47023630142, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1279472, "time": 39887.2133667469, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1279576, "time": 39890.122309207916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1279688, "time": 39893.58813500404, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1279696, "time": 39894.0510263443, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1279712, "time": 39894.53180408478, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1280032, "time": 39905.202363967896, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1280032, "time": 39905.34979701042, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1280032, "time": 39905.35792183876, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1280032, "time": 39905.78654670715, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1280032, "time": 39906.975157260895, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1280032, "time": 39906.99902367592, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1280032, "time": 39907.38697743416, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1280032, "time": 39907.56774520874, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 1280048, "time": 39908.054639577866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1280344, "time": 39916.76544427872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1280392, "time": 39918.208815574646, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1280480, "time": 39921.179240465164, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1280560, "time": 39923.596267938614, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1281328, "time": 39946.79762625694, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1281360, "time": 39947.769610881805, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1281432, "time": 39949.74646663666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1281560, "time": 39953.702688694, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1281696, "time": 39958.00608205795, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1281888, "time": 39963.83828616142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1281944, "time": 39965.307666778564, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1281976, "time": 39966.27634739876, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1282008, "time": 39967.24381136894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1282176, "time": 39972.5745279789, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1282496, "time": 39982.27608036995, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1282712, "time": 39988.561717033386, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1282720, "time": 39989.0298948288, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 1282792, "time": 39990.979941129684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1283128, "time": 40001.12031388283, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1283136, "time": 40001.58571767807, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1283368, "time": 40008.38554644585, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1283472, "time": 40011.82826757431, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1283904, "time": 40024.90003633499, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1283984, "time": 40027.329786777496, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1283984, "time": 40027.33967471123, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1284112, "time": 40031.21220159531, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1284256, "time": 40035.548023700714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1284320, "time": 40037.507736206055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1284480, "time": 40042.42719602585, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1284648, "time": 40047.274799346924, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1284680, "time": 40048.241975069046, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1284936, "time": 40056.00304841995, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1285008, "time": 40058.40253043175, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1285248, "time": 40065.66858291626, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1285424, "time": 40071.0881793499, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1285600, "time": 40076.40751886368, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1285632, "time": 40077.3826611042, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1285712, "time": 40079.82717251778, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1285784, "time": 40081.76770377159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1286176, "time": 40094.27660727501, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1286576, "time": 40106.4104950428, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1286632, "time": 40107.87912654877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1286792, "time": 40112.711186409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1286816, "time": 40113.66493964195, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1286960, "time": 40118.03527331352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1287040, "time": 40120.46140766144, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1287096, "time": 40121.92274594307, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1287168, "time": 40124.327528715134, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1287576, "time": 40136.464233636856, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1287712, "time": 40140.79197072983, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1287872, "time": 40145.62719988823, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1287912, "time": 40146.61858463287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1288016, "time": 40149.99670267105, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1288024, "time": 40150.02376008034, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1288096, "time": 40152.41809415817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1288512, "time": 40165.0616543293, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1288560, "time": 40166.50482106209, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1288680, "time": 40169.898482084274, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1288720, "time": 40171.32142114639, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1288728, "time": 40171.3487739563, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1288912, "time": 40177.12323665619, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1288944, "time": 40178.09736657143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1289128, "time": 40183.42360877991, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1289176, "time": 40184.86474728584, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1289408, "time": 40192.17770218849, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1289696, "time": 40200.843574762344, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1289712, "time": 40201.349578619, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1289744, "time": 40202.31765985489, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1289992, "time": 40209.605224609375, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1290016, "time": 40211.77206277847, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1290016, "time": 40212.13958859444, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1290016, "time": 40212.4426176548, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1290016, "time": 40212.580978393555, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1290016, "time": 40213.17922639847, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1290016, "time": 40213.598269462585, "eval_episode/length": 162.0, "eval_episode/score": 0.4937500059604645, "eval_episode/reward_rate": 0.006134969325153374}
{"step": 1290016, "time": 40214.11174964905, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 1290016, "time": 40214.15317440033, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1290256, "time": 40221.54027032852, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1290264, "time": 40221.5680501461, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1290472, "time": 40227.85102367401, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1290768, "time": 40237.01183605194, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1290824, "time": 40238.480682849884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1290824, "time": 40238.489501953125, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1291200, "time": 40250.07957267761, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1291368, "time": 40255.017359018326, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1291488, "time": 40258.86756014824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1291776, "time": 40267.526527643204, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1291824, "time": 40268.993001937866, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1291961, "time": 40273.90366148949, "train_stats/mean_log_entropy": 0.08624219178007199, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.397935621809251, "train/action_min": 0.0, "train/action_std": 1.6805552291398, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012584910880184114, "train/actor_opt_grad_steps": 79645.0, "train/actor_opt_loss": -26.541229564364595, "train/adv_mag": 0.7115613971606339, "train/adv_max": 0.32824033852851037, "train/adv_mean": -0.00010500074855408096, "train/adv_min": -0.6273350385156008, "train/adv_std": 0.02872609711335142, "train/cont_avg": 0.9941261215965347, "train/cont_loss_mean": 0.02450285038200788, "train/cont_loss_std": 0.28374676181390734, "train/cont_neg_acc": 0.15651297606158965, "train/cont_neg_loss": 3.30786011782982, "train/cont_pos_acc": 0.9998638494179981, "train/cont_pos_loss": 0.004936115393221452, "train/cont_pred": 0.9942593713208, "train/cont_rate": 0.9941261215965347, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10980799956948008, "train/extr_critic_critic_opt_grad_steps": 79645.0, "train/extr_critic_critic_opt_loss": 13248.457954633353, "train/extr_critic_mag": 1.515462599178352, "train/extr_critic_max": 1.515462599178352, "train/extr_critic_mean": 1.3711848725186717, "train/extr_critic_min": 1.0838276578648256, "train/extr_critic_std": 0.030696715680089328, "train/extr_return_normed_mag": 0.7209326247177502, "train/extr_return_normed_max": 0.3424187131447367, "train/extr_return_normed_mean": 0.061269985456572904, "train/extr_return_normed_min": -0.5881251374093612, "train/extr_return_normed_std": 0.04257061190460578, "train/extr_return_rate": 0.9996967424850652, "train/extr_return_raw_mag": 1.6522286138912239, "train/extr_return_raw_max": 1.6522286138912239, "train/extr_return_raw_mean": 1.371079947098647, "train/extr_return_raw_min": 0.7216847633371258, "train/extr_return_raw_std": 0.04257061196915289, "train/extr_reward_mag": 0.3072786514121707, "train/extr_reward_max": 0.3072786514121707, "train/extr_reward_mean": 0.0021745662624477456, "train/extr_reward_min": 7.199768972868966e-08, "train/extr_reward_std": 0.009368918513381246, "train/image_loss_mean": 0.07420068556940791, "train/image_loss_std": 0.09499394493454164, "train/model_loss_mean": 0.7165366995452654, "train/model_loss_std": 0.5173962203287842, "train/model_opt_grad_norm": 16.469324919256835, "train/model_opt_grad_steps": 79568.5396039604, "train/model_opt_loss": 3792.1606264019956, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5297.029702970297, "train/policy_entropy_mag": 1.2506614575291624, "train/policy_entropy_max": 1.2506614575291624, "train/policy_entropy_mean": 0.09677559886090827, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12020482576572068, "train/policy_logprob_mag": 6.551080285912693, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09636060388223959, "train/policy_logprob_min": -6.551080285912693, "train/policy_logprob_std": 0.6310473152316443, "train/policy_randomness_mag": 0.6427128869708222, "train/policy_randomness_max": 0.6427128869708222, "train/policy_randomness_mean": 0.049732824363330805, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.061773064407971826, "train/post_ent_mag": 34.77915826174292, "train/post_ent_max": 34.77915826174292, "train/post_ent_mean": 34.21714926238107, "train/post_ent_min": 33.62975313167761, "train/post_ent_std": 0.24232670273816231, "train/prior_ent_mag": 34.89988785923117, "train/prior_ent_max": 34.89988785923117, "train/prior_ent_mean": 33.90023839591753, "train/prior_ent_min": 32.64011987365118, "train/prior_ent_std": 0.4109834271787417, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0024477363799498093, "train/reward_loss_mean": 0.017833138408028696, "train/reward_loss_std": 0.24791617527382798, "train/reward_max_data": 0.8037283433841007, "train/reward_max_pred": 0.33068801152824173, "train/reward_neg_acc": 0.999461423937637, "train/reward_neg_loss": 0.0032236141614883328, "train/reward_pos_acc": 0.1836906758632826, "train/reward_pos_loss": 3.9675286254331246, "train/reward_pred": 0.0019657587111549506, "train/reward_rate": 0.0036403542698019804, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.029759928584098816, "report/cont_loss_std": 0.3491966724395752, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.299741268157959, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004593045450747013, "report/cont_pred": 0.9953152537345886, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07841096818447113, "report/image_loss_std": 0.09536265581846237, "report/model_loss_mean": 0.7227337956428528, "report/model_loss_std": 0.5144123435020447, "report/post_ent_mag": 35.157127380371094, "report/post_ent_max": 35.157127380371094, "report/post_ent_mean": 34.70977783203125, "report/post_ent_min": 34.184974670410156, "report/post_ent_std": 0.2087860405445099, "report/prior_ent_mag": 35.31868362426758, "report/prior_ent_max": 35.31868362426758, "report/prior_ent_mean": 34.41072082519531, "report/prior_ent_min": 32.96244812011719, "report/prior_ent_std": 0.36339908838272095, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0020050047896802425, "report/reward_loss_mean": 0.014562864787876606, "report/reward_loss_std": 0.2145688682794571, "report/reward_max_data": 0.800000011920929, "report/reward_max_pred": 0.03152656555175781, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002966900821775198, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.9610557556152344, "report/reward_pred": 0.0015772838378325105, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.027523797005414963, "eval/cont_loss_std": 0.39666199684143066, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.888545036315918, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004539398942142725, "eval/cont_pred": 0.9954898357391357, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08153125643730164, "eval/image_loss_std": 0.10483288019895554, "eval/model_loss_mean": 0.7387670278549194, "eval/model_loss_std": 0.8878026604652405, "eval/post_ent_mag": 35.18858337402344, "eval/post_ent_max": 35.18858337402344, "eval/post_ent_mean": 34.69243621826172, "eval/post_ent_min": 34.127769470214844, "eval/post_ent_std": 0.20350289344787598, "eval/prior_ent_mag": 35.392459869384766, "eval/prior_ent_max": 35.392459869384766, "eval/prior_ent_mean": 34.32777404785156, "eval/prior_ent_min": 33.23957824707031, "eval/prior_ent_std": 0.3436049818992615, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0029998780228197575, "eval/reward_loss_mean": 0.02971201203763485, "eval/reward_loss_std": 0.4620888829231262, "eval/reward_max_data": 0.8500000238418579, "eval/reward_max_pred": 0.0862431526184082, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.002946555381640792, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.854903221130371, "eval/reward_pred": 0.0015593315474689007, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32272.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.2243036356194515e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.552384266359238e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6800.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1000913732192096e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0871739387512, "timer/env.step_count": 4034.0, "timer/env.step_total": 38.84891939163208, "timer/env.step_frac": 0.03884553307351117, "timer/env.step_avg": 0.0096303716885553, "timer/env.step_min": 0.0077593326568603516, "timer/env.step_max": 0.03526592254638672, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 16.495815992355347, "timer/replay._sample_frac": 0.016494378112448034, "timer/replay._sample_avg": 0.0005111494791880066, "timer/replay._sample_min": 0.00039076805114746094, "timer/replay._sample_max": 0.025321483612060547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4884.0, "timer/agent.policy_total": 51.13322734832764, "timer/agent.policy_frac": 0.05112877025204126, "timer/agent.policy_avg": 0.010469538769108853, "timer/agent.policy_min": 0.008583307266235352, "timer/agent.policy_max": 0.08856749534606934, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.21643757820129395, "timer/dataset_train_frac": 0.00021641871212973814, "timer/dataset_train_avg": 0.00010730668230108773, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0004584789276123047, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 895.5457954406738, "timer/agent.train_frac": 0.8954677339912772, "timer/agent.train_avg": 0.44399890701074557, "timer/agent.train_min": 0.43489646911621094, "timer/agent.train_max": 0.6547541618347168, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47735166549682617, "timer/agent.report_frac": 0.00047731005649919556, "timer/agent.report_avg": 0.23867583274841309, "timer/agent.report_min": 0.2326066493988037, "timer/agent.report_max": 0.24474501609802246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027652022237897e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 32.2686547969986}
{"step": 1292016, "time": 40275.545367479324, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1292024, "time": 40275.57253575325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1292136, "time": 40278.94639420509, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1292384, "time": 40286.69496297836, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1292752, "time": 40297.84585261345, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1292792, "time": 40298.844494104385, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1292792, "time": 40298.8519077301, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1293072, "time": 40307.588973522186, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1293080, "time": 40307.61621308327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1293200, "time": 40311.548845767975, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1293504, "time": 40320.76418757439, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1293608, "time": 40323.69693160057, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1293640, "time": 40324.66831827164, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1293712, "time": 40327.08519768715, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1293864, "time": 40331.43888783455, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1293968, "time": 40334.80542874336, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1294088, "time": 40338.208631038666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1294400, "time": 40348.33769321442, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1294560, "time": 40353.163227558136, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1294568, "time": 40353.190469026566, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1294968, "time": 40365.27026319504, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1295064, "time": 40368.22063279152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1295080, "time": 40368.712960481644, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1295144, "time": 40370.76371407509, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1295624, "time": 40385.36934924126, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1295808, "time": 40391.218541145325, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1295904, "time": 40394.1137509346, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1295976, "time": 40396.07143473625, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1296024, "time": 40397.52223229408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1296136, "time": 40401.02944922447, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1296168, "time": 40401.9958319664, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1296232, "time": 40403.96183228493, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1296280, "time": 40405.43724656105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1296320, "time": 40406.866324424744, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 1296416, "time": 40409.75529670715, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1296568, "time": 40414.13019156456, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1296624, "time": 40416.05500006676, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1296912, "time": 40424.74473810196, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1297040, "time": 40428.62630581856, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1297312, "time": 40436.972365140915, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1297336, "time": 40437.48266363144, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1297456, "time": 40441.35588526726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1297600, "time": 40445.73499584198, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1298032, "time": 40458.75744724274, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1298248, "time": 40465.14909243584, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1298304, "time": 40467.06002354622, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1298312, "time": 40467.08707857132, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1298424, "time": 40470.48775887489, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1298512, "time": 40473.38083052635, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1298544, "time": 40474.34581017494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1298688, "time": 40478.6824760437, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1298752, "time": 40480.61039328575, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1298864, "time": 40484.005526304245, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1298928, "time": 40485.934188604355, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1299000, "time": 40487.90663957596, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1299272, "time": 40496.17053318024, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1299624, "time": 40506.80020594597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1299640, "time": 40507.3063583374, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1299672, "time": 40508.277540922165, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1299808, "time": 40512.62381362915, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1299872, "time": 40514.55335044861, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1300000, "time": 40519.80808377266, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1300000, "time": 40520.41841673851, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1300000, "time": 40520.53245830536, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1300000, "time": 40521.14340758324, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1300000, "time": 40522.12928152084, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1300000, "time": 40522.17496871948, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1300000, "time": 40523.0241317749, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1300000, "time": 40523.21328854561, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1300096, "time": 40526.12303209305, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1300344, "time": 40533.40534710884, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1300560, "time": 40540.15580844879, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1300792, "time": 40546.95891666412, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1300920, "time": 40550.91660237312, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1301152, "time": 40558.12904763222, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1301176, "time": 40558.638835668564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1301240, "time": 40560.5936126709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1301408, "time": 40565.906469106674, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1301488, "time": 40568.3268532753, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1301816, "time": 40578.025066137314, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1301840, "time": 40578.97298526764, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1301904, "time": 40581.05250406265, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1301984, "time": 40583.471187114716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1302184, "time": 40589.29013609886, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1302280, "time": 40592.1973900795, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1302296, "time": 40592.680240154266, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1302352, "time": 40594.60556387901, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1302392, "time": 40595.60153722763, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1302488, "time": 40598.499416828156, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1302872, "time": 40610.65721011162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1303024, "time": 40615.461198329926, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1303104, "time": 40617.877429008484, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1303136, "time": 40618.850976228714, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1303256, "time": 40622.263489723206, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1303720, "time": 40636.39208292961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1303728, "time": 40636.86136960983, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1303784, "time": 40638.328999996185, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1303880, "time": 40641.314152002335, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1303920, "time": 40642.73967766762, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1304280, "time": 40653.40371417999, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1304544, "time": 40661.68163561821, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1304800, "time": 40669.45843029022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1305336, "time": 40685.61215567589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1305544, "time": 40691.90581226349, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1305624, "time": 40694.35730934143, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1305712, "time": 40697.273322582245, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1305848, "time": 40701.29068827629, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1305976, "time": 40705.18630862236, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1306032, "time": 40707.13415694237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1306040, "time": 40707.16280627251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1306096, "time": 40709.08658075333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1306360, "time": 40716.85327076912, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1306376, "time": 40717.340349674225, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1306424, "time": 40718.78587818146, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1306816, "time": 40730.87845110893, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1306840, "time": 40731.40606093407, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1306864, "time": 40732.35772275925, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1306936, "time": 40734.31887316704, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1306992, "time": 40736.25810170174, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1307232, "time": 40743.52963471413, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1307240, "time": 40743.557312726974, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1307600, "time": 40754.687809705734, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1307864, "time": 40762.56760549545, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1307952, "time": 40765.46405696869, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1307992, "time": 40766.461478710175, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1308160, "time": 40771.7540743351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1308400, "time": 40778.991993665695, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1308416, "time": 40779.4854183197, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1308424, "time": 40779.51340198517, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1308560, "time": 40783.87414574623, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1308680, "time": 40787.284665346146, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1308784, "time": 40790.75877380371, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1308872, "time": 40793.19639635086, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1309176, "time": 40802.38973236084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1309480, "time": 40811.56831121445, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1309504, "time": 40812.516642570496, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1309520, "time": 40813.00197529793, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1310088, "time": 40831.526028871536, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1310088, "time": 40832.00787448883, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1310088, "time": 40832.05159544945, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1310088, "time": 40833.03914427757, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 1310088, "time": 40833.13687586784, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1310088, "time": 40833.35465550423, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1310088, "time": 40833.984535217285, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1310088, "time": 40834.68364548683, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1310120, "time": 40835.65252327919, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1310552, "time": 40848.73187947273, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1310712, "time": 40853.70018076897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1310736, "time": 40855.119206905365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1310872, "time": 40859.02165555954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1311096, "time": 40865.77338504791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1311368, "time": 40873.99651432037, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1311488, "time": 40877.85762453079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1311792, "time": 40887.11090183258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1312128, "time": 40897.266835689545, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1312432, "time": 40906.51523947716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1312472, "time": 40907.50343155861, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1312568, "time": 40910.45294189453, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1312864, "time": 40919.638246297836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1312936, "time": 40921.61239981651, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1313048, "time": 40924.98345327377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1313104, "time": 40926.926176548004, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1313112, "time": 40926.95255732536, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1313248, "time": 40931.27731704712, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1313408, "time": 40936.11597657204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1313680, "time": 40944.45788526535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1313712, "time": 40945.45503234863, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1313808, "time": 40948.350682497025, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1314064, "time": 40956.038506269455, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1314512, "time": 40969.56224536896, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1314584, "time": 40971.59661388397, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1314784, "time": 40977.82276582718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1315184, "time": 40989.87415933609, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1315416, "time": 40996.63760256767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1315424, "time": 40997.10595369339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1315752, "time": 41006.850338220596, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1315776, "time": 41007.79222083092, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1315944, "time": 41012.63570737839, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1316072, "time": 41016.53241300583, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1316120, "time": 41018.00602769852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1316152, "time": 41018.96966457367, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1316352, "time": 41025.22400212288, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1316368, "time": 41025.712008953094, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1316376, "time": 41025.739998817444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1316648, "time": 41034.070422410965, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1316760, "time": 41037.45752477646, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1317096, "time": 41047.60442972183, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1317312, "time": 41054.32959318161, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1317496, "time": 41059.67348027229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1317584, "time": 41062.64034795761, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1317744, "time": 41067.475625514984, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1317864, "time": 41070.86631464958, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1318064, "time": 41077.173347234726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1318376, "time": 41086.46863436699, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1318384, "time": 41086.93415427208, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1318664, "time": 41095.223804712296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1318672, "time": 41095.70670032501, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1318688, "time": 41096.19031095505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1318960, "time": 41104.797535419464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1318960, "time": 41104.803473472595, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1318984, "time": 41105.31339287758, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1319392, "time": 41117.845390319824, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1319520, "time": 41121.81272792816, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1319648, "time": 41125.68663740158, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1319736, "time": 41128.11633992195, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1319808, "time": 41130.53181242943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1320048, "time": 41137.80319261551, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1320056, "time": 41137.83242368698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1320072, "time": 41139.16465115547, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1320072, "time": 41139.78507852554, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1320072, "time": 41139.81199622154, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1320072, "time": 41140.73792910576, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1320072, "time": 41141.21775698662, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1320072, "time": 41141.6463034153, "eval_episode/length": 172.0, "eval_episode/score": 0.4625000059604645, "eval_episode/reward_rate": 0.005780346820809248}
{"step": 1320072, "time": 41142.21943736076, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1320072, "time": 41142.46628141403, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1320104, "time": 41143.43473339081, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1320480, "time": 41155.12789726257, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1320616, "time": 41159.02116727829, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1320680, "time": 41160.96009516716, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1321272, "time": 41178.874675512314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1321296, "time": 41179.828154563904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1321432, "time": 41183.80329155922, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1321440, "time": 41184.26917076111, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1321552, "time": 41187.734691143036, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1321552, "time": 41187.742451667786, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1321768, "time": 41194.05320954323, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1321936, "time": 41199.34693455696, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1322048, "time": 41202.73488998413, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1322360, "time": 41212.09077143669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1322576, "time": 41218.85626220703, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1322880, "time": 41228.0164835453, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1323064, "time": 41233.357592105865, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1323256, "time": 41239.146582365036, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1323400, "time": 41243.59259366989, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1323416, "time": 41244.08063292503, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1323440, "time": 41245.0235042572, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1323568, "time": 41248.88263320923, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1323752, "time": 41254.22675228119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1323800, "time": 41255.70268702507, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 1324120, "time": 41265.42056584358, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1324136, "time": 41265.90813398361, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1324360, "time": 41272.770704984665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1324377, "time": 41274.41211295128, "train_stats/mean_log_entropy": 0.08248742508221435, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3955773079749383, "train/action_min": 0.0, "train/action_std": 1.656134066605332, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01279715378768742, "train/actor_opt_grad_steps": 81665.0, "train/actor_opt_loss": -29.41664389808579, "train/adv_mag": 0.8204824290063122, "train/adv_max": 0.3375108543008861, "train/adv_mean": 0.0010025786566912568, "train/adv_min": -0.7529145853944345, "train/adv_std": 0.031215261059379815, "train/cont_avg": 0.994072942450495, "train/cont_loss_mean": 0.025757540211007738, "train/cont_loss_std": 0.29429708402788285, "train/cont_neg_acc": 0.1332751159546989, "train/cont_neg_loss": 3.479561193744735, "train/cont_pos_acc": 0.9998346593710455, "train/cont_pos_loss": 0.005269655671966548, "train/cont_pred": 0.9940899489539685, "train/cont_rate": 0.994072942450495, "train/dyn_loss_mean": 1.0000008881682216, "train/dyn_loss_std": 2.380219371159478e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11643022837320177, "train/extr_critic_critic_opt_grad_steps": 81665.0, "train/extr_critic_critic_opt_loss": 13132.094567025062, "train/extr_critic_mag": 1.5398692116879, "train/extr_critic_max": 1.5398692116879, "train/extr_critic_mean": 1.3914995771823544, "train/extr_critic_min": 1.093369197137285, "train/extr_critic_std": 0.03243298216326402, "train/extr_return_normed_mag": 0.834403127136797, "train/extr_return_normed_max": 0.35544838468627177, "train/extr_return_normed_mean": 0.06977973310369076, "train/extr_return_normed_min": -0.7131645947989851, "train/extr_return_normed_std": 0.04570738976765977, "train/extr_return_rate": 0.9996361561340861, "train/extr_return_raw_mag": 1.6781706928026559, "train/extr_return_raw_max": 1.6781706928026559, "train/extr_return_raw_mean": 1.3925021078326913, "train/extr_return_raw_min": 0.6095577133173989, "train/extr_return_raw_std": 0.04570738964778657, "train/extr_reward_mag": 0.3124980649145523, "train/extr_reward_max": 0.3124980649145523, "train/extr_reward_mean": 0.002329329225248519, "train/extr_reward_min": 3.363826487324025e-08, "train/extr_reward_std": 0.00959324885832865, "train/image_loss_mean": 0.07366082359953682, "train/image_loss_std": 0.09493753417293624, "train/model_loss_mean": 0.7180798558315428, "train/model_loss_std": 0.5350350719867366, "train/model_opt_grad_norm": 16.040894012451172, "train/model_opt_grad_steps": 81586.70792079208, "train/model_opt_loss": 3891.861875628481, "train/model_opt_model_opt_grad_overflow": 0.009900990099009901, "train/model_opt_model_opt_grad_scale": 5371.287128712871, "train/policy_entropy_mag": 1.2286190924668077, "train/policy_entropy_max": 1.2286190924668077, "train/policy_entropy_mean": 0.09236187635376902, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11216953098036275, "train/policy_logprob_mag": 6.551080262306893, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09270918203314932, "train/policy_logprob_min": -6.551080262306893, "train/policy_logprob_std": 0.6316977585896407, "train/policy_randomness_mag": 0.6313853517617329, "train/policy_randomness_max": 0.6313853517617329, "train/policy_randomness_mean": 0.047464620063800624, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05764373935906604, "train/post_ent_mag": 34.91303921690081, "train/post_ent_max": 34.91303921690081, "train/post_ent_mean": 34.36482299200379, "train/post_ent_min": 33.792505528667185, "train/post_ent_std": 0.23464299465465074, "train/prior_ent_mag": 34.975671371611035, "train/prior_ent_max": 34.975671371611035, "train/prior_ent_mean": 34.06968258395053, "train/prior_ent_min": 33.07047554998115, "train/prior_ent_std": 0.3256555819275356, "train/rep_loss_mean": 1.0000008881682216, "train/rep_loss_std": 2.380219371159478e-05, "train/reward_avg": 0.002507139902344633, "train/reward_loss_mean": 0.018660934335358516, "train/reward_loss_std": 0.25715440645408216, "train/reward_max_data": 0.7988397298325406, "train/reward_max_pred": 0.27604178390880624, "train/reward_neg_acc": 0.9994030724657644, "train/reward_neg_loss": 0.0033390656653053984, "train/reward_pos_acc": 0.13347745605220843, "train/reward_pos_loss": 4.192195559615519, "train/reward_pred": 0.0019442942010764364, "train/reward_rate": 0.0036790300123762374, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.0313529297709465, "report/cont_loss_std": 0.3307691216468811, "report/cont_neg_acc": 0.2222222238779068, "report/cont_neg_loss": 3.0039451122283936, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004994971677660942, "report/cont_pred": 0.9929959177970886, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06767521798610687, "report/image_loss_std": 0.09406771510839462, "report/model_loss_mean": 0.7253943681716919, "report/model_loss_std": 0.635985791683197, "report/post_ent_mag": 35.18070602416992, "report/post_ent_max": 35.18070602416992, "report/post_ent_mean": 34.627044677734375, "report/post_ent_min": 33.94143295288086, "report/post_ent_std": 0.2435683012008667, "report/prior_ent_mag": 35.02582550048828, "report/prior_ent_max": 35.02582550048828, "report/prior_ent_mean": 34.12110900878906, "report/prior_ent_min": 32.814353942871094, "report/prior_ent_std": 0.3563455045223236, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003274535993114114, "report/reward_loss_mean": 0.026366151869297028, "report/reward_loss_std": 0.31913742423057556, "report/reward_max_data": 0.856249988079071, "report/reward_max_pred": 0.4332761764526367, "report/reward_neg_acc": 0.9990177154541016, "report/reward_neg_loss": 0.0036292013246566057, "report/reward_pos_acc": 0.1666666716337204, "report/reward_pos_loss": 3.8840689659118652, "report/reward_pred": 0.002359607722610235, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02732454240322113, "eval/cont_loss_std": 0.38255828619003296, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.402887344360352, "eval/cont_pos_acc": 0.9980391263961792, "eval/cont_pos_loss": 0.006243904121220112, "eval/cont_pred": 0.9947719573974609, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.06521102041006088, "eval/image_loss_std": 0.0777042955160141, "eval/model_loss_mean": 0.7142301201820374, "eval/model_loss_std": 0.6339768767356873, "eval/post_ent_mag": 35.149810791015625, "eval/post_ent_max": 35.149810791015625, "eval/post_ent_mean": 34.52434539794922, "eval/post_ent_min": 34.06848907470703, "eval/post_ent_std": 0.24241159856319427, "eval/prior_ent_mag": 35.04505920410156, "eval/prior_ent_max": 35.04505920410156, "eval/prior_ent_mean": 34.085121154785156, "eval/prior_ent_min": 33.186180114746094, "eval/prior_ent_std": 0.3236967921257019, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0020202635787427425, "eval/reward_loss_mean": 0.02169451117515564, "eval/reward_loss_std": 0.30156370997428894, "eval/reward_max_data": 0.784375011920929, "eval/reward_max_pred": 0.5136698484420776, "eval/reward_neg_acc": 0.9970616698265076, "eval/reward_neg_loss": 0.00631240289658308, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.256738662719727, "eval/reward_pred": 0.002495002932846546, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 32416.0, "replay/samples": 32416.0, "replay/insert_wait_avg": 1.2035004478334087e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.544871261536428e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5272.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1264735179895334e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3833010196686, "timer/env.step_count": 4052.0, "timer/env.step_total": 38.82193040847778, "timer/env.step_frac": 0.03880705562448658, "timer/env.step_avg": 0.009580930505547331, "timer/env.step_min": 0.0076715946197509766, "timer/env.step_max": 0.049254655838012695, "timer/replay._sample_count": 32416.0, "timer/replay._sample_total": 16.553191900253296, "timer/replay._sample_frac": 0.01654684947597685, "timer/replay._sample_avg": 0.0005106488123227201, "timer/replay._sample_min": 0.0004177093505859375, "timer/replay._sample_max": 0.028082609176635742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4711.0, "timer/agent.policy_total": 49.3645281791687, "timer/agent.policy_frac": 0.04934561395502357, "timer/agent.policy_avg": 0.010478566796681958, "timer/agent.policy_min": 0.008598566055297852, "timer/agent.policy_max": 0.09891510009765625, "timer/dataset_train_count": 2026.0, "timer/dataset_train_total": 0.2140202522277832, "timer/dataset_train_frac": 0.00021393824947861195, "timer/dataset_train_avg": 0.00010563684710157117, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0018296241760253906, "timer/agent.train_count": 2026.0, "timer/agent.train_total": 899.6792316436768, "timer/agent.train_frac": 0.8993345158067448, "timer/agent.train_avg": 0.4440667480965828, "timer/agent.train_min": 0.4338419437408447, "timer/agent.train_max": 0.677288293838501, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4774935245513916, "timer/agent.report_frac": 0.0004773105709228583, "timer/agent.report_avg": 0.2387467622756958, "timer/agent.report_min": 0.2314317226409912, "timer/agent.report_max": 0.2460618019104004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.145919410022968e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 32.403015506107884}
{"step": 1324544, "time": 41279.45351266861, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1324648, "time": 41282.38976788521, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1324776, "time": 41286.273239851, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1324816, "time": 41287.70629477501, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1324912, "time": 41290.60848617554, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1324984, "time": 41292.5586874485, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1325032, "time": 41294.00580739975, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1325296, "time": 41302.26783657074, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1325320, "time": 41302.771287202835, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1325560, "time": 41310.02212667465, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1325800, "time": 41317.29095649719, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1325888, "time": 41320.241893053055, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1326008, "time": 41323.69621968269, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1326064, "time": 41325.630907297134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1326216, "time": 41330.02323460579, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1326216, "time": 41330.02896666527, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1326536, "time": 41339.82723546028, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1326960, "time": 41352.87325882912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1326968, "time": 41352.90058326721, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1327088, "time": 41356.759217739105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1327184, "time": 41360.23056411743, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1327608, "time": 41372.89286804199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1327640, "time": 41373.87264752388, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1327656, "time": 41374.35758686066, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1327664, "time": 41374.81919527054, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1327952, "time": 41383.487522125244, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1328016, "time": 41385.407683849335, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1328200, "time": 41390.81632447243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1328384, "time": 41396.560735702515, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1328384, "time": 41396.566620111465, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1328528, "time": 41400.91731452942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1328528, "time": 41400.925285339355, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1328784, "time": 41408.673642873764, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1329256, "time": 41422.91654276848, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1329376, "time": 41426.78498625755, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1329496, "time": 41430.19616365433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1329712, "time": 41437.00999832153, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1330056, "time": 41447.95105743408, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1330056, "time": 41448.66934752464, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1330056, "time": 41448.98223018646, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1330056, "time": 41449.107954740524, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1330056, "time": 41449.44174695015, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1330056, "time": 41449.48642063141, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1330056, "time": 41449.67254114151, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1330056, "time": 41449.917345523834, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 1330208, "time": 41454.808406353, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1330264, "time": 41456.2791390419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1330328, "time": 41458.20228242874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1330512, "time": 41464.00072979927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1330624, "time": 41467.37140083313, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1330696, "time": 41469.34978199005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1331096, "time": 41481.46416091919, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1331200, "time": 41484.83236837387, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1331224, "time": 41485.337265491486, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1331568, "time": 41495.9527592659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1331648, "time": 41498.38621664047, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1331688, "time": 41499.37407398224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1331792, "time": 41502.767954826355, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1331808, "time": 41503.255489349365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1332040, "time": 41510.06027030945, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1332248, "time": 41516.43851399422, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1332400, "time": 41521.271703243256, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1332536, "time": 41525.222049713135, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1333000, "time": 41539.39602923393, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1333008, "time": 41539.868787527084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1333072, "time": 41541.90342068672, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1333096, "time": 41542.410351514816, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1333576, "time": 41556.90947127342, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1333944, "time": 41568.07143473625, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1334008, "time": 41570.00921177864, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1334048, "time": 41571.57747077942, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1334120, "time": 41573.53587126732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1334352, "time": 41580.82247591019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1334440, "time": 41583.26169228554, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1334560, "time": 41587.128554582596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1334744, "time": 41592.50822734833, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1335224, "time": 41607.13147187233, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1335264, "time": 41608.55815792084, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1335408, "time": 41613.38433098793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1335448, "time": 41614.38356614113, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1335528, "time": 41616.82899880409, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1335536, "time": 41617.299429893494, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1335632, "time": 41620.242198228836, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1335816, "time": 41625.6373591423, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1335976, "time": 41630.63925409317, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1336040, "time": 41632.592549324036, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1336264, "time": 41639.42665362358, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1336360, "time": 41642.362889289856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1336520, "time": 41647.20939826965, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1336632, "time": 41650.60263514519, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1336752, "time": 41654.467499256134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1336856, "time": 41657.38457775116, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1337208, "time": 41668.10024905205, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1337248, "time": 41669.53841662407, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1337304, "time": 41671.00554561615, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1337344, "time": 41672.43812966347, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1337368, "time": 41672.945115566254, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1337376, "time": 41673.41323161125, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1337536, "time": 41678.291269779205, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1337840, "time": 41687.544828891754, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1337944, "time": 41690.62479710579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1338016, "time": 41693.0176115036, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1338016, "time": 41693.02508354187, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1338072, "time": 41694.52622151375, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1338144, "time": 41696.92161297798, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1338240, "time": 41699.88561844826, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1338352, "time": 41703.329740047455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1338376, "time": 41703.84858202934, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1338776, "time": 41715.99762964249, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1338848, "time": 41718.41160988808, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1339104, "time": 41726.23191976547, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1339104, "time": 41726.240141153336, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1339248, "time": 41730.6046397686, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1339672, "time": 41743.22297358513, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1339856, "time": 41749.0045030117, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1339880, "time": 41749.51532268524, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1340040, "time": 41755.515689611435, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1340040, "time": 41756.51477718353, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1340040, "time": 41757.19773507118, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 1340040, "time": 41757.69696378708, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1340040, "time": 41757.89736366272, "eval_episode/length": 172.0, "eval_episode/score": 0.4625000059604645, "eval_episode/reward_rate": 0.005780346820809248}
{"step": 1340040, "time": 41759.73453426361, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1340040, "time": 41760.10475111008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1340040, "time": 41760.11074113846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1340040, "time": 41760.116117954254, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1340040, "time": 41760.121500492096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1340184, "time": 41764.493577480316, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1340256, "time": 41766.87764835358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1340288, "time": 41767.86598157883, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1340328, "time": 41768.85940027237, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1340336, "time": 41769.33845424652, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1340664, "time": 41779.0882499218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1340752, "time": 41782.090680360794, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1340984, "time": 41788.87924718857, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1341008, "time": 41789.82819080353, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1341032, "time": 41790.339871644974, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1341160, "time": 41794.251591444016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1341264, "time": 41797.63733077049, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1341480, "time": 41803.96052646637, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1341568, "time": 41806.85310435295, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1341608, "time": 41807.841715335846, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1341808, "time": 41814.177521944046, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 1341864, "time": 41815.641473054886, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1342512, "time": 41835.51689219475, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1342568, "time": 41836.98854017258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1342576, "time": 41837.45640015602, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1342632, "time": 41838.91768336296, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1342760, "time": 41842.820115327835, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1342792, "time": 41843.78881192207, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1342816, "time": 41844.73650121689, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1343000, "time": 41850.0962536335, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1343120, "time": 41853.97193956375, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1343160, "time": 41854.99959731102, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1343184, "time": 41855.95625400543, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1343320, "time": 41859.88346362114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1343360, "time": 41861.318029880524, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1343704, "time": 41872.12779855728, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1343784, "time": 41874.55379676819, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1343840, "time": 41876.48993110657, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1344136, "time": 41885.253141880035, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1344400, "time": 41893.45774936676, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1344560, "time": 41898.29960608482, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1344584, "time": 41898.805661439896, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1344688, "time": 41902.24907660484, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1344712, "time": 41902.75672030449, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1344824, "time": 41906.15788078308, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1345016, "time": 41911.96866393089, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1345072, "time": 41913.89695119858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1345328, "time": 41921.63485002518, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1345416, "time": 41924.08655309677, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1345504, "time": 41926.978931427, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1345632, "time": 41930.932715415955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1345688, "time": 41932.40251350403, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1345968, "time": 41941.101855516434, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1346016, "time": 41942.55475783348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1346056, "time": 41943.56314730644, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1346312, "time": 41951.27861690521, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1346720, "time": 41963.987454891205, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1346848, "time": 41967.872826337814, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1346896, "time": 41969.3261551857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1346944, "time": 41970.777981996536, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1347136, "time": 41976.593935251236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1347320, "time": 41981.95791172981, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1347408, "time": 41984.82541966438, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1347864, "time": 41998.49142932892, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1347944, "time": 42000.899898290634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1348088, "time": 42005.27425765991, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1348280, "time": 42011.106615543365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1348288, "time": 42011.57409071922, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1348312, "time": 42012.08257436752, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1348328, "time": 42012.57182955742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1348352, "time": 42013.51978492737, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1348624, "time": 42021.82692837715, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1348640, "time": 42022.3123922348, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1348896, "time": 42030.04175567627, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1348944, "time": 42031.510786771774, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1349024, "time": 42033.92042374611, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1349032, "time": 42033.94757461548, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1349208, "time": 42039.2776799202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1349320, "time": 42042.667095422745, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1349448, "time": 42046.546800374985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1349464, "time": 42047.03304982185, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1349544, "time": 42049.45465326309, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1349864, "time": 42059.243639945984, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1349864, "time": 42059.25790667534, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1350024, "time": 42065.18882703781, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1350024, "time": 42065.48533344269, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1350024, "time": 42065.806399822235, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 1350024, "time": 42065.99517774582, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 1350024, "time": 42066.181505441666, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1350024, "time": 42066.83715963364, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1350024, "time": 42066.900285959244, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 1350024, "time": 42067.70933508873, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 1350104, "time": 42070.15110087395, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1350160, "time": 42072.067533016205, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1350544, "time": 42083.80138325691, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1350608, "time": 42085.738605737686, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1350952, "time": 42095.922978401184, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1351136, "time": 42101.723821401596, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1351264, "time": 42105.59568166733, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1351344, "time": 42108.036088228226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1351624, "time": 42116.400279045105, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1351760, "time": 42121.19121861458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1351776, "time": 42121.68009877205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1351848, "time": 42123.66087985039, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1351856, "time": 42124.12973666191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1352024, "time": 42129.00214266777, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1352328, "time": 42138.22247052193, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1352376, "time": 42139.66590023041, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1352696, "time": 42149.360607624054, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1352712, "time": 42149.849125385284, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1353080, "time": 42160.991604566574, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1353104, "time": 42161.943855047226, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1353272, "time": 42166.81357359886, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1353288, "time": 42167.30391550064, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1353656, "time": 42178.55054926872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1353664, "time": 42179.02017664909, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1353672, "time": 42179.0461435318, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1353784, "time": 42182.43601846695, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1353832, "time": 42183.88877296448, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1353832, "time": 42183.89703583717, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1353936, "time": 42187.281388282776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1354168, "time": 42194.07054018974, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1354608, "time": 42207.77218866348, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1354856, "time": 42215.135103702545, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1355024, "time": 42220.42675232887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1355080, "time": 42221.89897894859, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1355232, "time": 42226.72861742973, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1355368, "time": 42230.74608230591, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1355400, "time": 42231.71724152565, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1355472, "time": 42234.12567305565, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1355608, "time": 42238.00954127312, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1355904, "time": 42247.15147566795, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1355976, "time": 42249.10802745819, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1355984, "time": 42249.57764816284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1356448, "time": 42263.650192976, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1356528, "time": 42266.05069231987, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1356648, "time": 42269.44119620323, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1356777, "time": 42274.327644348145, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4209212881003697, "train/action_min": 0.0, "train/action_std": 1.722994493146248, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012225450339997784, "train/actor_opt_grad_steps": 83690.0, "train/actor_opt_loss": -28.997798318346145, "train/adv_mag": 0.7723894609606324, "train/adv_max": 0.3205141915476381, "train/adv_mean": 0.0005621943714977713, "train/adv_min": -0.7131833310784965, "train/adv_std": 0.0315568716967194, "train/cont_avg": 0.9939145243226601, "train/cont_loss_mean": 0.02569873622742486, "train/cont_loss_std": 0.2875242047562388, "train/cont_neg_acc": 0.11822127213178597, "train/cont_neg_loss": 3.369463860401379, "train/cont_pos_acc": 0.999801609022864, "train/cont_pos_loss": 0.005310126636498447, "train/cont_pred": 0.9940208355194242, "train/cont_rate": 0.9939145243226601, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11019636376811366, "train/extr_critic_critic_opt_grad_steps": 83690.0, "train/extr_critic_critic_opt_loss": 13111.907231373152, "train/extr_critic_mag": 1.5342983048537682, "train/extr_critic_max": 1.5342983048537682, "train/extr_critic_mean": 1.401537508212874, "train/extr_critic_min": 1.1226138264087622, "train/extr_critic_std": 0.031187790799243695, "train/extr_return_normed_mag": 0.7811830936394302, "train/extr_return_normed_max": 0.3262260236176364, "train/extr_return_normed_mean": 0.06837392301101403, "train/extr_return_normed_min": -0.6683558983168578, "train/extr_return_normed_std": 0.0451528020845405, "train/extr_return_rate": 0.9995305083068133, "train/extr_return_raw_mag": 1.6599519475927493, "train/extr_return_raw_max": 1.6599519475927493, "train/extr_return_raw_mean": 1.402099907104605, "train/extr_return_raw_min": 0.6653700256582551, "train/extr_return_raw_std": 0.045152801983608985, "train/extr_reward_mag": 0.2955914776900719, "train/extr_reward_max": 0.2955914776900719, "train/extr_reward_mean": 0.0025645174341863528, "train/extr_reward_min": 6.224721523341287e-08, "train/extr_reward_std": 0.00969831082336788, "train/image_loss_mean": 0.07462850829650616, "train/image_loss_std": 0.09509201902033661, "train/model_loss_mean": 0.7198900923940349, "train/model_loss_std": 0.5342083000784437, "train/model_opt_grad_norm": 15.550364287615997, "train/model_opt_grad_steps": 83609.85221674877, "train/model_opt_loss": 3897.85831906173, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5418.71921182266, "train/policy_entropy_mag": 1.2143040801503975, "train/policy_entropy_max": 1.2143040801503975, "train/policy_entropy_mean": 0.08896162614152936, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10507178629560424, "train/policy_logprob_mag": 6.551080273877224, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08903363956312828, "train/policy_logprob_min": -6.551080273877224, "train/policy_logprob_std": 0.6265323217866456, "train/policy_randomness_mag": 0.6240288917654253, "train/policy_randomness_max": 0.6240288917654253, "train/policy_randomness_mean": 0.045717236829068274, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.053996220286109765, "train/post_ent_mag": 35.108545425490206, "train/post_ent_max": 35.108545425490206, "train/post_ent_mean": 34.565356700878425, "train/post_ent_min": 34.00459357200585, "train/post_ent_std": 0.22839901042102007, "train/prior_ent_mag": 35.14027696055145, "train/prior_ent_max": 35.14027696055145, "train/prior_ent_mean": 34.061664224258195, "train/prior_ent_min": 32.98056084769113, "train/prior_ent_std": 0.35563796553118476, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0027678841977320577, "train/reward_loss_mean": 0.01956282372545139, "train/reward_loss_std": 0.25921783679775123, "train/reward_max_data": 0.8075431045053041, "train/reward_max_pred": 0.3035357415382498, "train/reward_neg_acc": 0.9994155611897925, "train/reward_neg_loss": 0.003542308857907619, "train/reward_pos_acc": 0.1705759883590854, "train/reward_pos_loss": 4.004272101539196, "train/reward_pred": 0.0021123587356861955, "train/reward_rate": 0.00402651631773399, "train_stats/mean_log_entropy": 0.07939274949503355, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.016772408038377762, "report/cont_loss_std": 0.21065452694892883, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.1424012184143066, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004244143608957529, "report/cont_pred": 0.9937800765037537, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06817063689231873, "report/image_loss_std": 0.09786202758550644, "report/model_loss_mean": 0.6942766904830933, "report/model_loss_std": 0.34151706099510193, "report/post_ent_mag": 35.23810577392578, "report/post_ent_max": 35.23810577392578, "report/post_ent_mean": 34.74831771850586, "report/post_ent_min": 34.22539520263672, "report/post_ent_std": 0.22611179947853088, "report/prior_ent_mag": 34.95885467529297, "report/prior_ent_max": 34.95885467529297, "report/prior_ent_mean": 34.02098083496094, "report/prior_ent_min": 33.07304382324219, "report/prior_ent_std": 0.34451693296432495, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0027709961868822575, "report/reward_loss_mean": 0.009333609603345394, "report/reward_loss_std": 0.15054138004779816, "report/reward_max_data": 0.871874988079071, "report/reward_max_pred": 0.5054929256439209, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.002355764387175441, "report/reward_pos_acc": 0.75, "report/reward_pos_loss": 1.7886842489242554, "report/reward_pred": 0.0024524317122995853, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.038549959659576416, "eval/cont_loss_std": 0.4985792934894562, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.773840427398682, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005501430481672287, "eval/cont_pred": 0.994674801826477, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.07824616134166718, "eval/image_loss_std": 0.10328660905361176, "eval/model_loss_mean": 0.7423650026321411, "eval/model_loss_std": 0.8813788890838623, "eval/post_ent_mag": 35.342552185058594, "eval/post_ent_max": 35.342552185058594, "eval/post_ent_mean": 34.77726745605469, "eval/post_ent_min": 34.25879669189453, "eval/post_ent_std": 0.23297691345214844, "eval/prior_ent_mag": 34.98492431640625, "eval/prior_ent_max": 34.98492431640625, "eval/prior_ent_mean": 34.04779815673828, "eval/prior_ent_min": 32.953460693359375, "eval/prior_ent_std": 0.35756534337997437, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002270507626235485, "eval/reward_loss_mean": 0.02556881308555603, "eval/reward_loss_std": 0.4180137813091278, "eval/reward_max_data": 0.9156249761581421, "eval/reward_max_pred": 0.263225793838501, "eval/reward_neg_acc": 0.9980410933494568, "eval/reward_neg_loss": 0.003932960331439972, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.388971328735352, "eval/reward_pred": 0.0019444175995886326, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 32400.0, "replay/samples": 32400.0, "replay/insert_wait_avg": 1.2200629269635236e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.554704760327752e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4928.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.126247179972661e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0110816955566, "timer/env.step_count": 4050.0, "timer/env.step_total": 38.912546157836914, "timer/env.step_frac": 0.038912114945625624, "timer/env.step_avg": 0.009608036088354794, "timer/env.step_min": 0.007582664489746094, "timer/env.step_max": 0.03536248207092285, "timer/replay._sample_count": 32400.0, "timer/replay._sample_total": 16.576679468154907, "timer/replay._sample_frac": 0.01657649577247536, "timer/replay._sample_avg": 0.0005116259095109539, "timer/replay._sample_min": 0.0004010200500488281, "timer/replay._sample_max": 0.010040760040283203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4666.0, "timer/agent.policy_total": 48.69186449050903, "timer/agent.policy_frac": 0.048691324908070155, "timer/agent.policy_avg": 0.010435461742500865, "timer/agent.policy_min": 0.008728504180908203, "timer/agent.policy_max": 0.07678389549255371, "timer/dataset_train_count": 2025.0, "timer/dataset_train_total": 0.2126023769378662, "timer/dataset_train_frac": 0.0002126000209691585, "timer/dataset_train_avg": 0.0001049888281174648, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0004181861877441406, "timer/agent.train_count": 2025.0, "timer/agent.train_total": 900.2687094211578, "timer/agent.train_frac": 0.9002587330279562, "timer/agent.train_avg": 0.44457714045489277, "timer/agent.train_min": 0.4332315921783447, "timer/agent.train_max": 0.6616561412811279, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47276759147644043, "timer/agent.report_frac": 0.0004727623524679797, "timer/agent.report_avg": 0.23638379573822021, "timer/agent.report_min": 0.22864818572998047, "timer/agent.report_max": 0.24411940574645996, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.218615150157886e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 32.39911677479457}
{"step": 1357184, "time": 42286.61322712898, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1357336, "time": 42291.1280734539, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1357336, "time": 42291.13558673859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1357640, "time": 42300.33361387253, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1357736, "time": 42303.23799657822, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1357784, "time": 42304.68644952774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1357896, "time": 42308.092123270035, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1358272, "time": 42319.676585674286, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1358288, "time": 42320.18675208092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1358392, "time": 42323.23972058296, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1358840, "time": 42336.775059223175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1358880, "time": 42338.20261096954, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1359496, "time": 42356.69783425331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1359640, "time": 42361.04893755913, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1359648, "time": 42361.51275372505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1359704, "time": 42362.978437423706, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1359744, "time": 42364.41588020325, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1360008, "time": 42373.04154229164, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1360008, "time": 42374.32085466385, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1360008, "time": 42374.6847653389, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1360008, "time": 42374.74555206299, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1360008, "time": 42374.973094940186, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 1360008, "time": 42375.39319109917, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1360008, "time": 42375.52148461342, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1360008, "time": 42375.827682971954, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1360048, "time": 42377.24917602539, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1360248, "time": 42383.19634246826, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1360472, "time": 42389.98513221741, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1360504, "time": 42390.95891022682, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1360600, "time": 42393.86450076103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1360704, "time": 42397.219789266586, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1360704, "time": 42397.23232913017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1360928, "time": 42404.024287223816, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1361152, "time": 42410.86733055115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1361168, "time": 42411.35345721245, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1361272, "time": 42414.283490896225, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1361504, "time": 42421.51220083237, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1361680, "time": 42426.91151762009, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1361744, "time": 42428.86464333534, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1361832, "time": 42431.31339144707, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1361920, "time": 42434.20427727699, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1362016, "time": 42437.09769511223, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1362416, "time": 42449.3417096138, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1362464, "time": 42450.79200363159, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1362560, "time": 42453.70933198929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1362624, "time": 42455.63119697571, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1362696, "time": 42457.60343337059, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1362848, "time": 42462.44457411766, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1363056, "time": 42468.741096735, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1363200, "time": 42473.17777967453, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1363360, "time": 42478.00018930435, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1363392, "time": 42478.967541217804, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1363416, "time": 42479.477672576904, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1363480, "time": 42481.43817830086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1363600, "time": 42485.2791326046, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1363760, "time": 42490.120559453964, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1363912, "time": 42494.52658319473, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1364152, "time": 42501.895656347275, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1364232, "time": 42504.30435872078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1364328, "time": 42507.21731710434, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1364416, "time": 42510.0933303833, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1364784, "time": 42521.209949970245, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 1364808, "time": 42521.71665763855, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1364872, "time": 42523.652668476105, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 1365024, "time": 42528.467679739, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1365128, "time": 42531.50714159012, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1365264, "time": 42535.84280347824, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1365296, "time": 42536.80686569214, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1365496, "time": 42542.62451887131, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1365536, "time": 42544.048147678375, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1365624, "time": 42546.492500305176, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1365968, "time": 42557.101814985275, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1366152, "time": 42562.53104996681, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1366304, "time": 42567.339383125305, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1366400, "time": 42570.253455638885, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1366464, "time": 42572.180916786194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1366544, "time": 42574.62014293671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1366624, "time": 42577.0276992321, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1367080, "time": 42590.70357942581, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1367176, "time": 42593.605422496796, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1367184, "time": 42594.07486701012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1367184, "time": 42594.083178043365, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1367424, "time": 42601.324202775955, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1367464, "time": 42602.31364130974, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1367704, "time": 42609.56638598442, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1367848, "time": 42613.93673491478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1368168, "time": 42624.246220350266, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1368216, "time": 42625.694486141205, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1368216, "time": 42625.70012021065, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1368464, "time": 42633.428270578384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1368520, "time": 42634.90298748016, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1368568, "time": 42636.35170841217, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1368712, "time": 42640.730228185654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1368744, "time": 42641.71267557144, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1368792, "time": 42643.1799223423, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1368992, "time": 42649.45031142235, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1369024, "time": 42650.518813848495, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1369224, "time": 42656.33451604843, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1369392, "time": 42661.70415210724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1369488, "time": 42664.61135983467, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1369656, "time": 42669.5073158741, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1369680, "time": 42670.47442030907, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1370024, "time": 42680.80631017685, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1370096, "time": 42683.89018344879, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 1370096, "time": 42684.35210108757, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1370096, "time": 42684.67614030838, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1370096, "time": 42684.71789479256, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1370096, "time": 42684.93780040741, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1370096, "time": 42685.32731437683, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1370096, "time": 42686.4126932621, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 1370096, "time": 42686.66891670227, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1370312, "time": 42692.98411822319, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1370544, "time": 42700.2333176136, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1370568, "time": 42700.7418320179, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1370664, "time": 42703.65313029289, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1370880, "time": 42710.53236222267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1371024, "time": 42714.88897395134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1371056, "time": 42715.86308145523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1371280, "time": 42722.63324403763, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1371392, "time": 42726.04215145111, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1371472, "time": 42728.496076107025, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1371512, "time": 42729.48653244972, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1371624, "time": 42732.87629008293, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1371704, "time": 42735.310698747635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1371904, "time": 42741.63180279732, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1372016, "time": 42745.046607255936, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1372120, "time": 42747.99884700775, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1372232, "time": 42751.393327236176, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1372536, "time": 42760.66211628914, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1373192, "time": 42780.878388404846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1373368, "time": 42786.29456090927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1373616, "time": 42794.10670924187, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1373704, "time": 42796.55485248566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1373776, "time": 42798.98020505905, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1373784, "time": 42799.008584976196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1374144, "time": 42810.245322704315, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1374216, "time": 42812.226571798325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1374536, "time": 42821.9538602829, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1374544, "time": 42822.42556023598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1375224, "time": 42842.91948032379, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1375504, "time": 42851.6579144001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1376016, "time": 42867.249791145325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1376088, "time": 42869.21595072746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1376096, "time": 42869.688447237015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1376280, "time": 42875.55930638313, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1376456, "time": 42880.89608478546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1376768, "time": 42890.6773891449, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1376848, "time": 42893.1016702652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1376856, "time": 42893.12999176979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1377336, "time": 42907.59843635559, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1377344, "time": 42908.06551003456, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1377464, "time": 42911.46863865852, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1377592, "time": 42915.35251045227, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1377672, "time": 42917.76727080345, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1377824, "time": 42922.67039847374, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1377880, "time": 42924.16325545311, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1378000, "time": 42928.00731229782, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1378120, "time": 42931.41965699196, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1378208, "time": 42934.32023739815, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1378328, "time": 42937.72314953804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1378672, "time": 42948.45882296562, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1378688, "time": 42948.957808971405, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1378696, "time": 42948.98520040512, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1379376, "time": 42969.97474050522, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1379496, "time": 42973.46051263809, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1379648, "time": 42978.31226372719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1379672, "time": 42978.824113845825, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1379704, "time": 42979.79441022873, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1379776, "time": 42982.304074048996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1379800, "time": 42982.837874650955, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1379936, "time": 42987.17201948166, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1380056, "time": 42990.62704920769, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1380080, "time": 42992.671387672424, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1380080, "time": 42992.83735227585, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1380080, "time": 42993.925266742706, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1380080, "time": 42994.02134633064, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1380080, "time": 42994.53158783913, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 1380080, "time": 42994.67854619026, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1380080, "time": 42994.96401643753, "eval_episode/length": 185.0, "eval_episode/score": 0.421875, "eval_episode/reward_rate": 0.005376344086021506}
{"step": 1380080, "time": 42995.689234256744, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1380112, "time": 42996.68165445328, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1380344, "time": 43003.49704360962, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1380368, "time": 43004.45429134369, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1380496, "time": 43008.34705734253, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1380872, "time": 43019.66018629074, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1381000, "time": 43023.576576948166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1381064, "time": 43025.52242541313, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1381168, "time": 43028.923244953156, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1381344, "time": 43034.33780360222, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1381680, "time": 43044.68961071968, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1381704, "time": 43045.20275759697, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1381848, "time": 43049.58651447296, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1382016, "time": 43054.90925574303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1382024, "time": 43054.93750214577, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1382208, "time": 43060.77436423302, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1382656, "time": 43074.45535039902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1382664, "time": 43074.481434583664, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1382680, "time": 43074.993122816086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1382800, "time": 43078.902154922485, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1382816, "time": 43079.39838933945, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1383120, "time": 43088.639201402664, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1383280, "time": 43093.500854730606, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1383480, "time": 43099.40350699425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1383624, "time": 43103.83533167839, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1383696, "time": 43106.25669813156, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1383992, "time": 43115.10058760643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1384040, "time": 43116.55018758774, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1384376, "time": 43126.66735768318, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1384520, "time": 43131.63850879669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1384632, "time": 43135.11267852783, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1384968, "time": 43145.38584089279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1384976, "time": 43145.85232281685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1385128, "time": 43150.30093741417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1385488, "time": 43161.583324193954, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1385544, "time": 43163.06802535057, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1385704, "time": 43167.933967113495, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1385896, "time": 43173.80619287491, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1385968, "time": 43176.207412958145, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1386008, "time": 43177.20127630234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1386128, "time": 43181.0888774395, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1386320, "time": 43186.936506032944, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1386336, "time": 43187.42827773094, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1386352, "time": 43187.943445920944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1386496, "time": 43192.368094205856, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1386784, "time": 43201.061700344086, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1386808, "time": 43201.57124042511, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1386848, "time": 43203.02426314354, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1387000, "time": 43207.413298130035, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1387232, "time": 43214.67903590202, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1387328, "time": 43217.57592582703, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1387376, "time": 43219.02089881897, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1387392, "time": 43219.502794742584, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1387456, "time": 43221.54682016373, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1387512, "time": 43223.026684999466, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1387736, "time": 43229.739439964294, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1387816, "time": 43232.15872383118, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1387976, "time": 43236.96962881088, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1388000, "time": 43237.92035317421, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1388096, "time": 43240.81291747093, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1388096, "time": 43240.82195305824, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1388104, "time": 43240.850814819336, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1388272, "time": 43246.24341726303, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1388344, "time": 43248.1893119812, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1388400, "time": 43250.10887527466, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1388472, "time": 43252.18412733078, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1388552, "time": 43254.607796669006, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1388568, "time": 43255.09710621834, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1389177, "time": 43274.75280165672, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4098284126508354, "train/action_min": 0.0, "train/action_std": 1.717366899594222, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013234730150624372, "train/actor_opt_grad_steps": 85715.0, "train/actor_opt_loss": -26.34107769125759, "train/adv_mag": 0.7542372413791052, "train/adv_max": 0.31989349410085394, "train/adv_mean": 0.00014198449505531947, "train/adv_min": -0.6818959208408205, "train/adv_std": 0.03073282415821853, "train/cont_avg": 0.9939569152227723, "train/cont_loss_mean": 0.025879948169435604, "train/cont_loss_std": 0.2906787745507047, "train/cont_neg_acc": 0.13668878184686792, "train/cont_neg_loss": 3.3893188940416468, "train/cont_pos_acc": 0.9998395410504671, "train/cont_pos_loss": 0.005275978798987252, "train/cont_pred": 0.9940289716319283, "train/cont_rate": 0.9939569152227723, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11774258848998954, "train/extr_critic_critic_opt_grad_steps": 85715.0, "train/extr_critic_critic_opt_loss": 13284.16133102568, "train/extr_critic_mag": 1.5359705096424217, "train/extr_critic_max": 1.5359705096424217, "train/extr_critic_mean": 1.3874855578535854, "train/extr_critic_min": 1.115477755518243, "train/extr_critic_std": 0.028713225737435392, "train/extr_return_normed_mag": 0.7575824567587068, "train/extr_return_normed_max": 0.33218493615046585, "train/extr_return_normed_mean": 0.05858768318032864, "train/extr_return_normed_min": -0.6365411789110391, "train/extr_return_normed_std": 0.04278749153755679, "train/extr_return_rate": 0.9996519445782841, "train/extr_return_raw_mag": 1.661224609554404, "train/extr_return_raw_max": 1.661224609554404, "train/extr_return_raw_mean": 1.3876274304814857, "train/extr_return_raw_min": 0.692498494492899, "train/extr_return_raw_std": 0.04278749171275609, "train/extr_reward_mag": 0.31498222303862616, "train/extr_reward_max": 0.31498222303862616, "train/extr_reward_mean": 0.002428817295925784, "train/extr_reward_min": 5.5473629790957614e-08, "train/extr_reward_std": 0.010135361569758394, "train/image_loss_mean": 0.07502552457522638, "train/image_loss_std": 0.09649065230963844, "train/model_loss_mean": 0.7196040318744017, "train/model_loss_std": 0.526739733570283, "train/model_opt_grad_norm": 15.662186707600508, "train/model_opt_grad_steps": 85633.21287128713, "train/model_opt_loss": 4632.162528765083, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6435.6435643564355, "train/policy_entropy_mag": 1.1933526355441253, "train/policy_entropy_max": 1.1933526355441253, "train/policy_entropy_mean": 0.09037048041377918, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10769188459409346, "train/policy_logprob_mag": 6.551080271749213, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.090112802342023, "train/policy_logprob_min": -6.551080271749213, "train/policy_logprob_std": 0.6266779085197071, "train/policy_randomness_mag": 0.6132619782249527, "train/policy_randomness_max": 0.6132619782249527, "train/policy_randomness_mean": 0.046441245012649214, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.055342683771459185, "train/post_ent_mag": 35.181679414050414, "train/post_ent_max": 35.181679414050414, "train/post_ent_mean": 34.61146131836542, "train/post_ent_min": 34.00605868348981, "train/post_ent_std": 0.2398155285875396, "train/prior_ent_mag": 35.02294304347274, "train/prior_ent_max": 35.02294304347274, "train/prior_ent_mean": 34.06274546254979, "train/prior_ent_min": 32.980395137673554, "train/prior_ent_std": 0.34648762215482126, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0026149032244142975, "train/reward_loss_mean": 0.0186985359275898, "train/reward_loss_std": 0.2512820105962824, "train/reward_max_data": 0.8049195554881993, "train/reward_max_pred": 0.31350186260619967, "train/reward_neg_acc": 0.9995002669863181, "train/reward_neg_loss": 0.0034461496968403236, "train/reward_pos_acc": 0.2054485957697034, "train/reward_pos_loss": 3.9045781229436396, "train/reward_pred": 0.002049653933816912, "train/reward_rate": 0.0038627397896039604, "train_stats/mean_log_entropy": 0.08336244186077417, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.023649295791983604, "report/cont_loss_std": 0.28359922766685486, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.8604400157928467, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004823042079806328, "report/cont_pred": 0.9951560497283936, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07635270804166794, "report/image_loss_std": 0.09367833286523819, "report/model_loss_mean": 0.7187408208847046, "report/model_loss_std": 0.5258813500404358, "report/post_ent_mag": 35.08433151245117, "report/post_ent_max": 35.08433151245117, "report/post_ent_mean": 34.470970153808594, "report/post_ent_min": 33.92499542236328, "report/post_ent_std": 0.2329598367214203, "report/prior_ent_mag": 35.02203369140625, "report/prior_ent_max": 35.02203369140625, "report/prior_ent_mean": 34.02629089355469, "report/prior_ent_min": 33.12541580200195, "report/prior_ent_std": 0.35364407300949097, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002655029296875, "report/reward_loss_mean": 0.018738748505711555, "report/reward_loss_std": 0.257651686668396, "report/reward_max_data": 0.746874988079071, "report/reward_max_pred": 0.07075607776641846, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0026933385524898767, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.110318660736084, "report/reward_pred": 0.0015052406815811992, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.022771306335926056, "eval/cont_loss_std": 0.24186447262763977, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.2784154415130615, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.006796608678996563, "eval/cont_pred": 0.9935673475265503, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08860787749290466, "eval/image_loss_std": 0.10424701869487762, "eval/model_loss_mean": 0.7365208864212036, "eval/model_loss_std": 0.5806965827941895, "eval/post_ent_mag": 35.02741241455078, "eval/post_ent_max": 35.02741241455078, "eval/post_ent_mean": 34.46807098388672, "eval/post_ent_min": 33.81126403808594, "eval/post_ent_std": 0.2508588433265686, "eval/prior_ent_mag": 35.02159881591797, "eval/prior_ent_max": 35.02159881591797, "eval/prior_ent_mean": 34.045074462890625, "eval/prior_ent_min": 32.8116569519043, "eval/prior_ent_std": 0.34886348247528076, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0032928469590842724, "eval/reward_loss_mean": 0.025141650810837746, "eval/reward_loss_std": 0.31183984875679016, "eval/reward_max_data": 0.824999988079071, "eval/reward_max_pred": 0.29398584365844727, "eval/reward_neg_acc": 0.999018669128418, "eval/reward_neg_loss": 0.004143565893173218, "eval/reward_pos_acc": 0.20000000298023224, "eval/reward_pos_loss": 4.304551601409912, "eval/reward_pred": 0.002147418214008212, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 32400.0, "replay/samples": 32400.0, "replay/insert_wait_avg": 1.2185838487413194e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.50142850993592e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4416.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0862190654312356e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2907891273499, "timer/env.step_count": 4050.0, "timer/env.step_total": 39.16847062110901, "timer/env.step_frac": 0.03915708416677459, "timer/env.step_avg": 0.009671227313854076, "timer/env.step_min": 0.007616758346557617, "timer/env.step_max": 0.0564417839050293, "timer/replay._sample_count": 32400.0, "timer/replay._sample_total": 16.53933072090149, "timer/replay._sample_frac": 0.01653452266148561, "timer/replay._sample_avg": 0.0005104731703981941, "timer/replay._sample_min": 0.0003993511199951172, "timer/replay._sample_max": 0.011057376861572266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4602.0, "timer/agent.policy_total": 48.15901041030884, "timer/agent.policy_frac": 0.04814501036475862, "timer/agent.policy_avg": 0.01046480017607754, "timer/agent.policy_min": 0.008707046508789062, "timer/agent.policy_max": 0.08853292465209961, "timer/dataset_train_count": 2025.0, "timer/dataset_train_total": 0.2147059440612793, "timer/dataset_train_frac": 0.0002146435280570643, "timer/dataset_train_avg": 0.00010602762669692804, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.00034880638122558594, "timer/agent.train_count": 2025.0, "timer/agent.train_total": 901.7206752300262, "timer/agent.train_frac": 0.9014585408875795, "timer/agent.train_avg": 0.4452941606074204, "timer/agent.train_min": 0.43221282958984375, "timer/agent.train_max": 0.6683847904205322, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4789421558380127, "timer/agent.report_frac": 0.00047880292515323485, "timer/agent.report_avg": 0.23947107791900635, "timer/agent.report_min": 0.2321486473083496, "timer/agent.report_max": 0.24679350852966309, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.649162292480469e-05, "timer/dataset_eval_frac": 4.6478107596455844e-08, "timer/dataset_eval_avg": 4.649162292480469e-05, "timer/dataset_eval_min": 4.649162292480469e-05, "timer/dataset_eval_max": 4.649162292480469e-05, "fps": 32.39003717910157}
{"step": 1389376, "time": 43280.86535644531, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1389416, "time": 43281.869642972946, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1389520, "time": 43285.232219696045, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1389600, "time": 43287.70687055588, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1389728, "time": 43291.66191935539, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1390048, "time": 43301.42901110649, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1390064, "time": 43302.68114066124, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1390064, "time": 43302.94180011749, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1390064, "time": 43303.05430340767, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1390064, "time": 43303.14266848564, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1390064, "time": 43303.300750017166, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1390064, "time": 43303.81915354729, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1390064, "time": 43303.999772548676, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1390064, "time": 43304.10961318016, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1390080, "time": 43304.6112370491, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1390192, "time": 43308.068689107895, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1390312, "time": 43311.61673641205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1390344, "time": 43312.587280511856, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1390352, "time": 43313.07273077965, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 1390424, "time": 43315.028029203415, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1390472, "time": 43316.49165511131, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1390552, "time": 43318.940232515335, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1390600, "time": 43320.41795015335, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1390672, "time": 43322.84302973747, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1390864, "time": 43328.7890958786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1391024, "time": 43333.635269880295, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1391112, "time": 43336.092544555664, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1391144, "time": 43337.070992946625, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1391208, "time": 43339.05061340332, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1391376, "time": 43344.50498151779, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1391512, "time": 43348.43440937996, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1391560, "time": 43349.89747548103, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1391608, "time": 43351.358256578445, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1392040, "time": 43364.49475002289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1392256, "time": 43371.34653878212, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1392280, "time": 43371.87386274338, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1392280, "time": 43371.88060116768, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1392520, "time": 43379.16011977196, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1392600, "time": 43381.6120326519, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1392664, "time": 43384.05304336548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1392760, "time": 43386.96978712082, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1392784, "time": 43387.92238688469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1393672, "time": 43414.76618933678, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1393680, "time": 43415.2360970974, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1393688, "time": 43415.264599084854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1393824, "time": 43419.63150429726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1393832, "time": 43419.65944862366, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1393968, "time": 43424.031713962555, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1394024, "time": 43425.520385980606, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1394384, "time": 43436.79523277283, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1394472, "time": 43439.250834703445, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1394608, "time": 43443.58493089676, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1394816, "time": 43449.89911174774, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1395016, "time": 43455.739382743835, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1395072, "time": 43457.65271258354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1395160, "time": 43460.10521507263, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1395184, "time": 43461.13426375389, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1395184, "time": 43461.14166808128, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1395512, "time": 43470.825162410736, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1395640, "time": 43474.71981072426, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1395880, "time": 43482.05117869377, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1396088, "time": 43488.35818743706, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1396280, "time": 43494.28333616257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1396848, "time": 43511.66915893555, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1396888, "time": 43512.66060638428, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1396920, "time": 43513.65271663666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1397008, "time": 43516.538206100464, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1397072, "time": 43518.490495443344, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1397312, "time": 43525.89123392105, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1397328, "time": 43526.38146829605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1397384, "time": 43527.853749752045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1397472, "time": 43530.745265483856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1398048, "time": 43548.26773953438, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1398072, "time": 43548.78501415253, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1398400, "time": 43559.07445549965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1398688, "time": 43567.88770914078, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1398960, "time": 43576.135539770126, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1399208, "time": 43583.59193229675, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1399320, "time": 43587.00401711464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1399384, "time": 43588.97313928604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1399392, "time": 43589.44719648361, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1399472, "time": 43591.92738080025, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1399536, "time": 43593.898878097534, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 1399696, "time": 43598.770327568054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1399968, "time": 43607.03439426422, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1399984, "time": 43607.52333164215, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1400048, "time": 43610.18527960777, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 1400048, "time": 43611.01582813263, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1400048, "time": 43611.24918937683, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1400048, "time": 43611.8387362957, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1400048, "time": 43612.027420043945, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1400048, "time": 43613.18659687042, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1400048, "time": 43614.52161550522, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 1400048, "time": 43614.564648389816, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 1400376, "time": 43624.27026295662, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1400384, "time": 43624.73914885521, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1400384, "time": 43624.753269433975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1400608, "time": 43631.56588292122, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1400824, "time": 43637.88072490692, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1400984, "time": 43643.327378988266, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1400992, "time": 43643.79287481308, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1401080, "time": 43646.248493433, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1401200, "time": 43650.09135341644, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1401280, "time": 43652.572429180145, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1401656, "time": 43663.81359267235, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1401696, "time": 43665.27072072029, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1401704, "time": 43665.29988026619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1401728, "time": 43666.27160835266, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1401736, "time": 43666.299822330475, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1401848, "time": 43669.69173622131, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1401944, "time": 43672.73210835457, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1402184, "time": 43680.04322576523, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1402248, "time": 43682.01029229164, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1402320, "time": 43684.421180963516, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1402512, "time": 43690.28446125984, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1402536, "time": 43690.7937002182, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1402696, "time": 43695.69116950035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1402816, "time": 43699.53963279724, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1402968, "time": 43704.04423713684, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1403152, "time": 43709.85585927963, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1403176, "time": 43710.36228346825, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1403512, "time": 43720.52603697777, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1403552, "time": 43721.960733652115, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1403792, "time": 43729.22968173027, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1403808, "time": 43729.71619915962, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1403856, "time": 43731.2837574482, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1403896, "time": 43732.27760887146, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1404008, "time": 43735.68320560455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1404048, "time": 43737.11739039421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1404256, "time": 43743.40259552002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1404272, "time": 43743.91181755066, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1404448, "time": 43749.26390004158, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1404448, "time": 43749.27096414566, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1404520, "time": 43751.23348379135, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1404600, "time": 43753.68351602554, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1404688, "time": 43756.57020711899, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1405112, "time": 43769.34501838684, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1405336, "time": 43776.10051822662, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1405408, "time": 43778.517709970474, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1405736, "time": 43788.277329444885, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1405952, "time": 43795.183665275574, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1406096, "time": 43799.57300376892, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1406320, "time": 43806.42935347557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1406320, "time": 43806.435123205185, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1406760, "time": 43819.59339976311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1406760, "time": 43819.59976530075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1406792, "time": 43820.65608167648, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1407000, "time": 43826.97374463081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1407072, "time": 43829.36804652214, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1407104, "time": 43830.341291189194, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1407456, "time": 43840.99342107773, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1407552, "time": 43843.9013903141, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1407720, "time": 43848.77674245834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1407720, "time": 43848.78406953812, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1407920, "time": 43855.20661878586, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1407952, "time": 43856.19829368591, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1408064, "time": 43859.58146262169, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1408336, "time": 43867.8368499279, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1408408, "time": 43869.78835105896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1408416, "time": 43870.25966978073, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1408552, "time": 43874.18125796318, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1408768, "time": 43881.16706752777, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1408920, "time": 43885.58346700668, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1409104, "time": 43891.852222919464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1409464, "time": 43902.579748392105, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1409488, "time": 43903.53879237175, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1409544, "time": 43905.01758861542, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1409696, "time": 43909.8946852684, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1409960, "time": 43917.78002643585, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1410032, "time": 43920.856630802155, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 1410032, "time": 43921.345519304276, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1410032, "time": 43921.93141388893, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1410032, "time": 43922.03071975708, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1410032, "time": 43922.074548482895, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1410032, "time": 43922.639629125595, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1410032, "time": 43922.86175894737, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1410032, "time": 43924.31634640694, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1410088, "time": 43925.79174208641, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1410232, "time": 43930.15458655357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1410264, "time": 43931.12297606468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1410720, "time": 43945.223246097565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1410744, "time": 43945.73311686516, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1411080, "time": 43955.95398712158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1411160, "time": 43958.39935183525, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1411168, "time": 43958.869295835495, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1411248, "time": 43961.30187821388, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1411480, "time": 43968.158249378204, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1411672, "time": 43974.05106258392, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1411744, "time": 43976.44070935249, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1411912, "time": 43981.32018375397, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1411968, "time": 43983.260170936584, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1412296, "time": 43992.97442793846, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1412400, "time": 43996.342680454254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1412496, "time": 43999.258021354675, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1412600, "time": 44002.29564833641, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1412984, "time": 44013.928569316864, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1413056, "time": 44016.31472611427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1413096, "time": 44017.32683944702, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1413256, "time": 44022.16188120842, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1413472, "time": 44028.92138171196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1413696, "time": 44035.775275707245, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1413984, "time": 44044.544791936874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1414224, "time": 44051.90026831627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1414280, "time": 44053.393547058105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1414760, "time": 44068.14074754715, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1415296, "time": 44084.60036444664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1415368, "time": 44086.590264081955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1415520, "time": 44091.537437438965, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1415568, "time": 44092.98434686661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1415736, "time": 44097.858458042145, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1415784, "time": 44099.318694114685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1415920, "time": 44103.67795419693, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1416008, "time": 44106.147725343704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1416040, "time": 44107.11678004265, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1416296, "time": 44114.874812603, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1416296, "time": 44114.88465642929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1416320, "time": 44115.83949685097, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1416368, "time": 44117.298352479935, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1416640, "time": 44125.61950016022, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1416656, "time": 44126.1061193943, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1417016, "time": 44136.78563427925, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1417072, "time": 44138.71518588066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1417280, "time": 44145.43684411049, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1417560, "time": 44153.79691338539, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1417744, "time": 44159.61726641655, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 1418352, "time": 44178.17791938782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1418400, "time": 44179.629856824875, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1418608, "time": 44186.04266166687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1418784, "time": 44191.40070581436, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1418952, "time": 44196.28167772293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1418968, "time": 44196.768715143204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1419384, "time": 44209.40014624596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1419584, "time": 44215.72429203987, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1419616, "time": 44216.69555783272, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1419960, "time": 44227.001140117645, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1419984, "time": 44227.94959807396, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1420016, "time": 44229.977110147476, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1420016, "time": 44230.15336346626, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1420016, "time": 44230.21866822243, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1420016, "time": 44230.425045490265, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1420016, "time": 44231.06535100937, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1420016, "time": 44231.09095597267, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1420016, "time": 44231.79467868805, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1420016, "time": 44232.040691137314, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1420056, "time": 44233.03927755356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1420200, "time": 44237.42430472374, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1420408, "time": 44243.78259563446, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1420440, "time": 44244.76748943329, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1420600, "time": 44249.61563515663, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1420784, "time": 44255.4189119339, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1420808, "time": 44255.93072938919, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1420960, "time": 44260.776091337204, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1420992, "time": 44261.74446606636, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1421096, "time": 44264.68233656883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1421112, "time": 44265.17043828964, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1421224, "time": 44268.55995130539, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1421401, "time": 44275.080018758774, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4189368521813117, "train/action_min": 0.0, "train/action_std": 1.7061419546014012, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012001648927937345, "train/actor_opt_grad_steps": 87735.0, "train/actor_opt_loss": -25.13531785908312, "train/adv_mag": 0.7416871092697181, "train/adv_max": 0.3064348857001503, "train/adv_mean": 0.0013690256244147593, "train/adv_min": -0.6855101759480958, "train/adv_std": 0.03208798214811647, "train/cont_avg": 0.9939907564975248, "train/cont_loss_mean": 0.025558520412754894, "train/cont_loss_std": 0.2847739393306472, "train/cont_neg_acc": 0.1324589204284089, "train/cont_neg_loss": 3.3580026017937494, "train/cont_pos_acc": 0.9998687207698822, "train/cont_pos_loss": 0.005290183866866818, "train/cont_pred": 0.9940402982848706, "train/cont_rate": 0.9939907564975248, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12477557065592397, "train/extr_critic_critic_opt_grad_steps": 87735.0, "train/extr_critic_critic_opt_loss": 13068.831064356436, "train/extr_critic_mag": 1.5478694391722727, "train/extr_critic_max": 1.5478694391722727, "train/extr_critic_mean": 1.4012150133010184, "train/extr_critic_min": 1.151927922621812, "train/extr_critic_std": 0.03074484320339, "train/extr_return_normed_mag": 0.7495085381635345, "train/extr_return_normed_max": 0.3458615252287081, "train/extr_return_normed_mean": 0.06385511999009269, "train/extr_return_normed_min": -0.6342520185626379, "train/extr_return_normed_std": 0.04551131032997429, "train/extr_return_rate": 0.9996103676829008, "train/extr_return_raw_mag": 1.6845902859574498, "train/extr_return_raw_max": 1.6845902859574498, "train/extr_return_raw_mean": 1.4025839396042399, "train/extr_return_raw_min": 0.7044767421661037, "train/extr_return_raw_std": 0.045511310403742414, "train/extr_reward_mag": 0.3091571885760468, "train/extr_reward_max": 0.3091571885760468, "train/extr_reward_mean": 0.0024633946659107977, "train/extr_reward_min": 1.593391493995591e-08, "train/extr_reward_std": 0.010005563105650173, "train/image_loss_mean": 0.07412289199188794, "train/image_loss_std": 0.09577591283855462, "train/model_loss_mean": 0.7201004057827562, "train/model_loss_std": 0.5443430599378477, "train/model_opt_grad_norm": 15.357404904790444, "train/model_opt_grad_steps": 87651.4900990099, "train/model_opt_loss": 3776.873994430693, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5247.524752475248, "train/policy_entropy_mag": 1.236609439448555, "train/policy_entropy_max": 1.236609439448555, "train/policy_entropy_mean": 0.09264002360477305, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11279914273631454, "train/policy_logprob_mag": 6.5510802764703735, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0919607012800061, "train/policy_logprob_min": -6.5510802764703735, "train/policy_logprob_std": 0.6263792193172002, "train/policy_randomness_mag": 0.6354915806562593, "train/policy_randomness_max": 0.6354915806562593, "train/policy_randomness_mean": 0.0476075595078787, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0579672961099313, "train/post_ent_mag": 35.223082721823516, "train/post_ent_max": 35.223082721823516, "train/post_ent_mean": 34.62518261446811, "train/post_ent_min": 33.99095867647983, "train/post_ent_std": 0.2517554830796648, "train/prior_ent_mag": 35.26265099025009, "train/prior_ent_max": 35.26265099025009, "train/prior_ent_mean": 34.090715502748395, "train/prior_ent_min": 32.953555494251816, "train/prior_ent_std": 0.36863786085407335, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0028467310566165816, "train/reward_loss_mean": 0.02041896991777501, "train/reward_loss_std": 0.26612381762041165, "train/reward_max_data": 0.8019183181447558, "train/reward_max_pred": 0.3179477618472411, "train/reward_neg_acc": 0.9994611079149908, "train/reward_neg_loss": 0.003605813623087868, "train/reward_pos_acc": 0.16590708968314258, "train/reward_pos_loss": 4.007401205373533, "train/reward_pred": 0.0021599075194485115, "train/reward_rate": 0.004152807858910891, "train_stats/mean_log_entropy": 0.08091925473750702, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.017667336389422417, "report/cont_loss_std": 0.24050042033195496, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.14219331741333, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0054142954759299755, "report/cont_pred": 0.9935981631278992, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.065549336373806, "report/image_loss_std": 0.09519325941801071, "report/model_loss_mean": 0.6959257125854492, "report/model_loss_std": 0.41752979159355164, "report/post_ent_mag": 35.51720428466797, "report/post_ent_max": 35.51720428466797, "report/post_ent_mean": 34.940887451171875, "report/post_ent_min": 34.204402923583984, "report/post_ent_std": 0.21558521687984467, "report/prior_ent_mag": 35.21211242675781, "report/prior_ent_max": 35.21211242675781, "report/prior_ent_mean": 34.38215255737305, "report/prior_ent_min": 33.169532775878906, "report/prior_ent_std": 0.33485591411590576, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0016723633743822575, "report/reward_loss_mean": 0.012708991765975952, "report/reward_loss_std": 0.19516798853874207, "report/reward_max_data": 0.862500011920929, "report/reward_max_pred": 0.030114293098449707, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004090371076017618, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.416824817657471, "report/reward_pred": 0.0021226750686764717, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.02501368336379528, "eval/cont_loss_std": 0.3028152883052826, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.253925323486328, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004263381473720074, "eval/cont_pred": 0.9957170486450195, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.07730717957019806, "eval/image_loss_std": 0.10263459384441376, "eval/model_loss_mean": 0.7259711027145386, "eval/model_loss_std": 0.6274240612983704, "eval/post_ent_mag": 35.4407958984375, "eval/post_ent_max": 35.4407958984375, "eval/post_ent_mean": 34.8788948059082, "eval/post_ent_min": 34.21678161621094, "eval/post_ent_std": 0.24941328167915344, "eval/prior_ent_mag": 35.21211242675781, "eval/prior_ent_max": 35.21211242675781, "eval/prior_ent_mean": 34.31863021850586, "eval/prior_ent_min": 33.00404357910156, "eval/prior_ent_std": 0.35433483123779297, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0024078369606286287, "eval/reward_loss_mean": 0.023650215938687325, "eval/reward_loss_std": 0.3290945589542389, "eval/reward_max_data": 0.862500011920929, "eval/reward_max_pred": 0.05170607566833496, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.003386222757399082, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.1909685134887695, "eval/reward_pred": 0.0017804981907829642, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32224.0, "replay/samples": 32224.0, "replay/insert_wait_avg": 1.2202452879321374e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.646500531587723e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5696.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1080017920290485e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.428884267807, "timer/env.step_count": 4028.0, "timer/env.step_total": 39.13087606430054, "timer/env.step_frac": 0.039114100641885814, "timer/env.step_avg": 0.009714716004046806, "timer/env.step_min": 0.0076160430908203125, "timer/env.step_max": 0.03609490394592285, "timer/replay._sample_count": 32224.0, "timer/replay._sample_total": 16.540157318115234, "timer/replay._sample_frac": 0.01653306654597506, "timer/replay._sample_avg": 0.0005132869078362473, "timer/replay._sample_min": 0.00037169456481933594, "timer/replay._sample_max": 0.01095271110534668, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4740.0, "timer/agent.policy_total": 50.20663094520569, "timer/agent.policy_frac": 0.050185107342188416, "timer/agent.policy_avg": 0.010592116233165758, "timer/agent.policy_min": 0.008972406387329102, "timer/agent.policy_max": 0.09168314933776855, "timer/dataset_train_count": 2014.0, "timer/dataset_train_total": 0.21434998512268066, "timer/dataset_train_frac": 0.00021425809319725804, "timer/dataset_train_avg": 0.00010642998268256239, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0010695457458496094, "timer/agent.train_count": 2014.0, "timer/agent.train_total": 897.7772309780121, "timer/agent.train_frac": 0.8973923535155389, "timer/agent.train_avg": 0.4457682378242364, "timer/agent.train_min": 0.4361302852630615, "timer/agent.train_max": 0.6830244064331055, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47423720359802246, "timer/agent.report_frac": 0.0004740338979167987, "timer/agent.report_avg": 0.23711860179901123, "timer/agent.report_min": 0.2283766269683838, "timer/agent.report_max": 0.24586057662963867, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.859796427521855e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 32.20964788668399}
{"step": 1421672, "time": 44283.04532122612, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1421736, "time": 44284.99942064285, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1421784, "time": 44286.45655322075, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1421864, "time": 44288.889362335205, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1421984, "time": 44292.77470564842, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1422272, "time": 44301.67559289932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1422424, "time": 44306.08833742142, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1422528, "time": 44309.49733877182, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1422536, "time": 44309.5246386528, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1422872, "time": 44319.70776486397, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1422912, "time": 44321.14383506775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1422968, "time": 44322.616559267044, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1423096, "time": 44326.52904009819, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1423112, "time": 44327.02238082886, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1423288, "time": 44332.46009731293, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1423624, "time": 44342.62648463249, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1424176, "time": 44359.59818315506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1424336, "time": 44364.53270149231, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1424360, "time": 44365.04446864128, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1424592, "time": 44372.304788827896, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1424848, "time": 44380.01984214783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1425128, "time": 44388.29163527489, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1425224, "time": 44391.2884209156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1425264, "time": 44392.73700451851, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1425304, "time": 44393.73193001747, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1425424, "time": 44398.096962213516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1425600, "time": 44403.42943930626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1425816, "time": 44409.76940727234, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1425872, "time": 44411.71440792084, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1426040, "time": 44416.62033867836, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1426096, "time": 44418.538843393326, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1426784, "time": 44439.596255779266, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1426904, "time": 44443.040264844894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1427440, "time": 44459.57527089119, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1427440, "time": 44459.5828397274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1427536, "time": 44462.510299921036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1427616, "time": 44464.94188737869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1427712, "time": 44467.85525894165, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1427736, "time": 44468.36369514465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1427760, "time": 44469.31212472916, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1428304, "time": 44485.940190792084, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1428352, "time": 44487.39826464653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1428408, "time": 44488.876111269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1428896, "time": 44503.89789533615, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1428952, "time": 44505.38024520874, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1428976, "time": 44506.331067085266, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1429000, "time": 44506.83930492401, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1429096, "time": 44509.74960565567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1429128, "time": 44510.81140780449, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1429176, "time": 44512.26261758804, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1429344, "time": 44517.55806326866, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1429368, "time": 44518.06533432007, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1429424, "time": 44520.006675481796, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1429736, "time": 44529.250913619995, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1429776, "time": 44530.67826247215, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1429960, "time": 44536.04564857483, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1430000, "time": 44538.764477968216, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1430000, "time": 44538.77177429199, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1430000, "time": 44539.126070261, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1430000, "time": 44539.25500154495, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1430000, "time": 44539.83888697624, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1430000, "time": 44540.075087070465, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 1430000, "time": 44540.83745551109, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1430000, "time": 44541.12259864807, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1430072, "time": 44543.11163878441, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1430136, "time": 44545.08361172676, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1430200, "time": 44547.061541080475, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1430376, "time": 44552.421946525574, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1430584, "time": 44558.783321380615, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1430584, "time": 44558.792553424835, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1430720, "time": 44563.161469459534, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1430720, "time": 44563.16883087158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1430752, "time": 44564.1453101635, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1431144, "time": 44575.953264951706, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1431248, "time": 44579.3308236599, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1431408, "time": 44584.19909954071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1431752, "time": 44594.5098862648, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1431872, "time": 44598.387263059616, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1431984, "time": 44601.86087322235, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1432360, "time": 44613.09828400612, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 1432448, "time": 44615.9925327301, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1432552, "time": 44618.907876729965, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1432688, "time": 44623.26385474205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1433032, "time": 44633.54866838455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1433096, "time": 44635.50912809372, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1433544, "time": 44649.096566200256, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1433560, "time": 44649.60930299759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1433624, "time": 44652.00789499283, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1433680, "time": 44653.92516732216, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1433840, "time": 44658.795754909515, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1434064, "time": 44665.72496700287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1434224, "time": 44670.61339426041, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1434272, "time": 44672.07416296005, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 1434336, "time": 44674.03264260292, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1434616, "time": 44682.37243580818, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1434752, "time": 44686.739780426025, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1434976, "time": 44693.670278549194, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1435040, "time": 44695.63521027565, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1435408, "time": 44706.794207811356, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1435432, "time": 44707.30879330635, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1435528, "time": 44710.234394311905, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1435856, "time": 44720.490981817245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1435872, "time": 44720.98242974281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1435888, "time": 44721.471061229706, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1435984, "time": 44724.3909406662, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1435992, "time": 44724.418739795685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1436152, "time": 44729.294226408005, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1436160, "time": 44729.76270699501, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1436248, "time": 44732.217814683914, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1436456, "time": 44738.51195240021, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1436736, "time": 44747.18365597725, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1436896, "time": 44752.113126039505, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1436904, "time": 44752.13919091225, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1437352, "time": 44765.71870160103, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1437520, "time": 44771.07090830803, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1437600, "time": 44773.53425836563, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1437704, "time": 44776.45480084419, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1437720, "time": 44776.963644742966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1437776, "time": 44778.884842157364, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1437928, "time": 44783.34198331833, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 1438016, "time": 44786.22473526001, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 1438112, "time": 44789.15243291855, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1438336, "time": 44795.96433520317, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1438512, "time": 44801.348903656006, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1438520, "time": 44801.37512969971, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1438600, "time": 44803.799545288086, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 1438704, "time": 44807.20007777214, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1438736, "time": 44808.17356848717, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1438888, "time": 44812.658282756805, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1439056, "time": 44817.945140600204, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1439328, "time": 44826.205350875854, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1439360, "time": 44827.178617239, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1439632, "time": 44835.447838783264, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1439992, "time": 44846.25776863098, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1440016, "time": 44847.20598435402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1440088, "time": 44849.51388525963, "eval_episode/length": 17.0, "eval_episode/score": 0.9468749761581421, "eval_episode/reward_rate": 0.05555555555555555}
{"step": 1440088, "time": 44849.7153403759, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 1440088, "time": 44850.29058456421, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1440088, "time": 44850.33348274231, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1440088, "time": 44850.6503970623, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1440088, "time": 44851.3973300457, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1440088, "time": 44851.92820453644, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1440088, "time": 44852.149941682816, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 1440136, "time": 44853.62310242653, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1440416, "time": 44862.35555243492, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1440528, "time": 44865.75954771042, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1440600, "time": 44867.74430012703, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1440824, "time": 44874.61895489693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1440872, "time": 44876.070086956024, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1440880, "time": 44876.53739571571, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1440952, "time": 44878.514233350754, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1440968, "time": 44879.00283718109, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1441392, "time": 44892.06835460663, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1441584, "time": 44897.88304543495, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1441592, "time": 44897.91003513336, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1441664, "time": 44900.358053684235, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1441816, "time": 44905.2598528862, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1442088, "time": 44913.535657167435, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1442216, "time": 44917.412558317184, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 1442224, "time": 44917.87974476814, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1442248, "time": 44918.38780546188, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1442448, "time": 44924.71034550667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1442632, "time": 44930.08703804016, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1443264, "time": 44949.64404916763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1443504, "time": 44956.958261966705, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1443896, "time": 44968.743161439896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1443976, "time": 44971.18608999252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1444096, "time": 44975.02834439278, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1444104, "time": 44975.0568985939, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1444528, "time": 44988.101932525635, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1444536, "time": 44988.131202459335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1444544, "time": 44988.597207307816, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1444560, "time": 44989.086906671524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1444760, "time": 44995.025176525116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1444888, "time": 44998.88915634155, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1445208, "time": 45008.56813287735, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1445392, "time": 45014.38152003288, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1445576, "time": 45019.7486205101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1445888, "time": 45029.571528196335, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1446104, "time": 45035.90952849388, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1446272, "time": 45041.236122608185, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1446288, "time": 45041.7286798954, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1446528, "time": 45049.07470178604, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1446776, "time": 45056.442648887634, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1446848, "time": 45058.85638213158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1446856, "time": 45058.88583087921, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1446856, "time": 45058.89502835274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1447072, "time": 45065.691016197205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1447080, "time": 45065.71749305725, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1447152, "time": 45068.129068374634, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 1447416, "time": 45075.898891448975, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1447512, "time": 45078.83334851265, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1447544, "time": 45079.802663087845, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1447744, "time": 45086.15370178223, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1447760, "time": 45086.64184832573, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1447824, "time": 45088.601697683334, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1447960, "time": 45092.518045425415, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1448168, "time": 45098.825797080994, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1448408, "time": 45106.11216020584, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1448464, "time": 45108.04396343231, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1448528, "time": 45110.0035610199, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1448768, "time": 45117.415678977966, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1448976, "time": 45123.727991104126, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1449088, "time": 45127.18232750893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1449168, "time": 45129.61515665054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1449512, "time": 45139.80993151665, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1449648, "time": 45144.2670879364, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1449712, "time": 45146.214059352875, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1449712, "time": 45146.22204852104, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1450008, "time": 45155.431128025055, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1450072, "time": 45158.50268983841, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1450072, "time": 45158.67444109917, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1450072, "time": 45159.49779462814, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1450072, "time": 45160.634615421295, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1450072, "time": 45160.7397005558, "eval_episode/length": 170.0, "eval_episode/score": 0.46875, "eval_episode/reward_rate": 0.005847953216374269}
{"step": 1450072, "time": 45160.8608982563, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1450072, "time": 45161.4019203186, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 1450072, "time": 45161.83371734619, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1450088, "time": 45162.32535600662, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1450160, "time": 45164.720133543015, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1450160, "time": 45164.729211330414, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1450392, "time": 45171.66342186928, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1450472, "time": 45174.132570028305, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1450480, "time": 45174.60687851906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1450600, "time": 45178.031878232956, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1450776, "time": 45183.36547398567, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1450776, "time": 45183.3726913929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1450792, "time": 45183.86573386192, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1450896, "time": 45187.25607442856, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1451104, "time": 45193.60982275009, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1451128, "time": 45194.12277197838, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1451464, "time": 45204.52551198006, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1451592, "time": 45208.46403288841, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1451744, "time": 45213.31382751465, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1451872, "time": 45217.196120262146, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1451880, "time": 45217.22354102135, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1452400, "time": 45233.269582271576, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1452632, "time": 45240.11504602432, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1452720, "time": 45242.991169691086, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1452768, "time": 45244.469918489456, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1452920, "time": 45248.85363340378, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1452928, "time": 45249.32259392738, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1453088, "time": 45254.16679286957, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1453120, "time": 45255.135135650635, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1453176, "time": 45256.60220837593, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1453272, "time": 45259.508887290955, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1453328, "time": 45261.55339503288, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1453753, "time": 45275.32360291481, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3843063505569306, "train/action_min": 0.0, "train/action_std": 1.6450250048448545, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012744110617048965, "train/actor_opt_grad_steps": 89755.0, "train/actor_opt_loss": -26.95492751055425, "train/adv_mag": 0.7298181334344467, "train/adv_max": 0.2961694627705187, "train/adv_mean": -0.00019909563147561498, "train/adv_min": -0.6572725601715617, "train/adv_std": 0.03063722521914999, "train/cont_avg": 0.9941599628712872, "train/cont_loss_mean": 0.02435137700326372, "train/cont_loss_std": 0.2731342865246357, "train/cont_neg_acc": 0.1571992806868978, "train/cont_neg_loss": 3.22802532702168, "train/cont_pos_acc": 0.9998394926585773, "train/cont_pos_loss": 0.005475407546976268, "train/cont_pred": 0.9937980765163308, "train/cont_rate": 0.9941599628712872, "train/dyn_loss_mean": 1.000000032457975, "train/dyn_loss_std": 1.0444337472153624e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11303941628868037, "train/extr_critic_critic_opt_grad_steps": 89755.0, "train/extr_critic_critic_opt_loss": 12820.066889696782, "train/extr_critic_mag": 1.5550546303834065, "train/extr_critic_max": 1.5550546303834065, "train/extr_critic_mean": 1.4183384652184967, "train/extr_critic_min": 1.1795359289292062, "train/extr_critic_std": 0.02916227062555528, "train/extr_return_normed_mag": 0.7437028589815197, "train/extr_return_normed_max": 0.3212130040225416, "train/extr_return_normed_mean": 0.06070484685720784, "train/extr_return_normed_min": -0.6074468670505109, "train/extr_return_normed_std": 0.04295875381051314, "train/extr_return_rate": 0.9995984390820607, "train/extr_return_raw_mag": 1.6786476833985584, "train/extr_return_raw_max": 1.6786476833985584, "train/extr_return_raw_mean": 1.4181395975670013, "train/extr_return_raw_min": 0.7499878123255059, "train/extr_return_raw_std": 0.04295875400415446, "train/extr_reward_mag": 0.28731955632124795, "train/extr_reward_max": 0.28731955632124795, "train/extr_reward_mean": 0.0023842096999564235, "train/extr_reward_min": 9.442319964418317e-09, "train/extr_reward_std": 0.009331827881828984, "train/image_loss_mean": 0.07352622155800904, "train/image_loss_std": 0.09469659165433138, "train/model_loss_mean": 0.7176936823542756, "train/model_loss_std": 0.5251121155106195, "train/model_opt_grad_norm": 15.88363567513613, "train/model_opt_grad_steps": 89669.65841584158, "train/model_opt_loss": 3905.859782303914, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5420.792079207921, "train/policy_entropy_mag": 1.2474566349888792, "train/policy_entropy_max": 1.2474566349888792, "train/policy_entropy_mean": 0.09551201465696392, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11844117943160605, "train/policy_logprob_mag": 6.551080295355013, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09552519738969237, "train/policy_logprob_min": -6.551080295355013, "train/policy_logprob_std": 0.6325008895727667, "train/policy_randomness_mag": 0.641065933031611, "train/policy_randomness_max": 0.641065933031611, "train/policy_randomness_mean": 0.04908347116912355, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.060866729015170935, "train/post_ent_mag": 35.28463125700998, "train/post_ent_max": 35.28463125700998, "train/post_ent_mean": 34.726250978979735, "train/post_ent_min": 34.12449151218527, "train/post_ent_std": 0.2385750031559774, "train/prior_ent_mag": 35.27523584649114, "train/prior_ent_max": 35.27523584649114, "train/prior_ent_mean": 33.94712663405012, "train/prior_ent_min": 32.74703723605317, "train/prior_ent_std": 0.4103941623822297, "train/rep_loss_mean": 1.000000032457975, "train/rep_loss_std": 1.0444337472153624e-06, "train/reward_avg": 0.002749120130018956, "train/reward_loss_mean": 0.019816042886502894, "train/reward_loss_std": 0.25986693744169603, "train/reward_max_data": 0.8090191847543315, "train/reward_max_pred": 0.3686510407098449, "train/reward_neg_acc": 0.9993640184402466, "train/reward_neg_loss": 0.003814063160588024, "train/reward_pos_acc": 0.2037400823459029, "train/reward_pos_loss": 3.917366371750832, "train/reward_pred": 0.0022999454764557063, "train/reward_rate": 0.004056118502475247, "train_stats/mean_log_entropy": 0.08218967757551125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.02970406413078308, "report/cont_loss_std": 0.2959643304347992, "report/cont_neg_acc": 0.2222222238779068, "report/cont_neg_loss": 2.7161710262298584, "report/cont_pos_acc": 0.9990147948265076, "report/cont_pos_loss": 0.005883175879716873, "report/cont_pred": 0.9929943084716797, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06747289001941681, "report/image_loss_std": 0.09322245419025421, "report/model_loss_mean": 0.7320398688316345, "report/model_loss_std": 0.6994369626045227, "report/post_ent_mag": 35.45854949951172, "report/post_ent_max": 35.45854949951172, "report/post_ent_mean": 35.017555236816406, "report/post_ent_min": 34.597843170166016, "report/post_ent_std": 0.19904716312885284, "report/prior_ent_mag": 34.92711639404297, "report/prior_ent_max": 34.92711639404297, "report/prior_ent_mean": 33.31785583496094, "report/prior_ent_min": 32.125694274902344, "report/prior_ent_std": 0.495287150144577, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00583496131002903, "report/reward_loss_mean": 0.03486292064189911, "report/reward_loss_std": 0.36635202169418335, "report/reward_max_data": 0.862500011920929, "report/reward_max_pred": 0.783561110496521, "report/reward_neg_acc": 0.9970472455024719, "report/reward_neg_loss": 0.005092516541481018, "report/reward_pos_acc": 0.125, "report/reward_pos_loss": 3.815703868865967, "report/reward_pred": 0.003172018565237522, "report/reward_rate": 0.0078125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.037637799978256226, "eval/cont_loss_std": 0.45360568165779114, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.671411514282227, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004432846792042255, "eval/cont_pred": 0.9955854415893555, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10748039186000824, "eval/image_loss_std": 0.11475256830453873, "eval/model_loss_mean": 0.789095401763916, "eval/model_loss_std": 1.0392669439315796, "eval/post_ent_mag": 35.489219665527344, "eval/post_ent_max": 35.489219665527344, "eval/post_ent_mean": 35.082794189453125, "eval/post_ent_min": 34.62452697753906, "eval/post_ent_std": 0.20571434497833252, "eval/prior_ent_mag": 34.92711639404297, "eval/prior_ent_max": 34.92711639404297, "eval/prior_ent_mean": 33.366580963134766, "eval/prior_ent_min": 32.05685806274414, "eval/prior_ent_std": 0.4960392117500305, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.003720092587172985, "eval/reward_loss_mean": 0.04397720843553543, "eval/reward_loss_std": 0.556608259677887, "eval/reward_max_data": 0.949999988079071, "eval/reward_max_pred": 0.04787945747375488, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0032062637619674206, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.961447715759277, "eval/reward_pred": 0.0017133757937699556, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32352.0, "replay/samples": 32352.0, "replay/insert_wait_avg": 1.2451828882083459e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.668128706934898e-07, "replay/sample_wait_frac": 0.9999690900098912, "eval_replay/size": 100000.0, "eval_replay/inserts": 4392.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1318911185898632e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1130366325378, "timer/env.step_count": 4044.0, "timer/env.step_total": 39.19548726081848, "timer/env.step_frac": 0.03919105723568296, "timer/env.step_avg": 0.009692256988332959, "timer/env.step_min": 0.007687568664550781, "timer/env.step_max": 0.03739666938781738, "timer/replay._sample_count": 32352.0, "timer/replay._sample_total": 16.629106998443604, "timer/replay._sample_frac": 0.016627227512637135, "timer/replay._sample_avg": 0.0005140055328401213, "timer/replay._sample_min": 0.0003447532653808594, "timer/replay._sample_max": 0.011243581771850586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4593.0, "timer/agent.policy_total": 48.43758010864258, "timer/agent.policy_frac": 0.048432105506529405, "timer/agent.policy_avg": 0.010545956914574913, "timer/agent.policy_min": 0.009083032608032227, "timer/agent.policy_max": 0.07850003242492676, "timer/dataset_train_count": 2022.0, "timer/dataset_train_total": 0.2158527374267578, "timer/dataset_train_frac": 0.00021582834091789422, "timer/dataset_train_avg": 0.00010675209566110673, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.00029587745666503906, "timer/agent.train_count": 2022.0, "timer/agent.train_total": 900.8966257572174, "timer/agent.train_frac": 0.9007948029460848, "timer/agent.train_avg": 0.4455472926593558, "timer/agent.train_min": 0.43352770805358887, "timer/agent.train_max": 0.6934347152709961, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4726145267486572, "timer/agent.report_frac": 0.00047256111003211084, "timer/agent.report_avg": 0.2363072633743286, "timer/agent.report_min": 0.22936058044433594, "timer/agent.report_max": 0.2432539463043213, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8845387485823415e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 32.34778499732332}
{"step": 1453856, "time": 45278.401824474335, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1453864, "time": 45278.42927789688, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1454064, "time": 45284.72810912132, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1454088, "time": 45285.238765478134, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1454184, "time": 45288.15608596802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1454208, "time": 45289.136292696, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1454288, "time": 45291.6364300251, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1454320, "time": 45292.609050273895, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1454416, "time": 45295.52771496773, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1454472, "time": 45297.00348854065, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1454600, "time": 45300.89148426056, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1454760, "time": 45305.743416547775, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1454864, "time": 45309.132004499435, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1454912, "time": 45310.61424231529, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1455032, "time": 45314.079103946686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1455208, "time": 45319.43467259407, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1455648, "time": 45333.21804738045, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1455944, "time": 45341.9815993309, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1456000, "time": 45343.92325472832, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1456048, "time": 45345.37423300743, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1456256, "time": 45351.792590379715, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1456632, "time": 45362.96412944794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1456648, "time": 45363.46101522446, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1456736, "time": 45366.37904882431, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1456784, "time": 45367.856852293015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1457144, "time": 45378.54077124596, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1457456, "time": 45388.324945926666, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1457632, "time": 45393.65999364853, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1457672, "time": 45394.65131306648, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1457872, "time": 45400.963389873505, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1458256, "time": 45413.209641456604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1458312, "time": 45414.6840171814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1458544, "time": 45421.933941841125, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1458568, "time": 45422.445826768875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1458576, "time": 45422.9117474556, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1458576, "time": 45422.91908597946, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1458760, "time": 45428.28239417076, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1459048, "time": 45437.04528045654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1459456, "time": 45449.7601416111, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1459656, "time": 45455.66689968109, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1459760, "time": 45459.066618442535, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1459768, "time": 45459.09406876564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1459944, "time": 45464.50381946564, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1459952, "time": 45464.99155712128, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1460056, "time": 45469.19053077698, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1460056, "time": 45469.93318605423, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1460056, "time": 45470.64560890198, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1460056, "time": 45470.673288583755, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1460056, "time": 45470.925827264786, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 1460056, "time": 45471.34821867943, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1460056, "time": 45471.43750214577, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1460056, "time": 45471.888316869736, "eval_episode/length": 184.0, "eval_episode/score": 0.42500001192092896, "eval_episode/reward_rate": 0.005405405405405406}
{"step": 1460184, "time": 45475.79213953018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1460328, "time": 45480.170590400696, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1460392, "time": 45482.116694927216, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1460672, "time": 45490.87284612656, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1460696, "time": 45491.38321971893, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1461088, "time": 45503.64321398735, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1461184, "time": 45506.55593967438, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1461584, "time": 45518.76482081413, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 1461608, "time": 45519.27803683281, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1462000, "time": 45531.592408418655, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1462040, "time": 45532.616874694824, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1462536, "time": 45547.66929578781, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1462640, "time": 45551.04034805298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1462696, "time": 45552.52737736702, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1462704, "time": 45552.99629116058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1463008, "time": 45562.26916098595, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1463024, "time": 45562.75841093063, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1463040, "time": 45563.25018501282, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1463208, "time": 45568.12853264809, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1463352, "time": 45572.50716876984, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 1463400, "time": 45573.9687898159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1463464, "time": 45575.899908065796, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1463616, "time": 45580.736862659454, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1463920, "time": 45590.03881263733, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1464016, "time": 45593.08797287941, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1464304, "time": 45601.87028717995, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1464448, "time": 45606.28437995911, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1464528, "time": 45608.71617293358, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1464576, "time": 45610.19148898125, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1464712, "time": 45614.11291003227, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1464744, "time": 45615.08870959282, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1464760, "time": 45615.595700502396, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1464880, "time": 45619.44877433777, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1465000, "time": 45623.010117292404, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1465256, "time": 45630.81580233574, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1465256, "time": 45630.822956323624, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1465264, "time": 45631.294213056564, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1465616, "time": 45642.01396155357, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1465792, "time": 45647.36628937721, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1466176, "time": 45659.09859585762, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1466376, "time": 45665.18015742302, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1466400, "time": 45666.39473462105, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1466496, "time": 45669.297727108, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1466720, "time": 45676.11141324043, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1466744, "time": 45676.618884563446, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 1466888, "time": 45681.095799684525, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1467032, "time": 45685.4592730999, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1467416, "time": 45697.06280374527, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1467464, "time": 45698.52014422417, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 1467520, "time": 45700.47478699684, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1468120, "time": 45718.64668512344, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1468280, "time": 45723.53827381134, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1468352, "time": 45725.96426177025, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 1468392, "time": 45726.96962785721, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1468472, "time": 45729.43147802353, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1468560, "time": 45732.329454422, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1468960, "time": 45744.592014074326, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1469000, "time": 45745.587379693985, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 1469056, "time": 45747.510049819946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1469568, "time": 45763.043310403824, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1469744, "time": 45768.36282157898, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1470016, "time": 45776.68806266785, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1470040, "time": 45777.55331802368, "eval_episode/length": 17.0, "eval_episode/score": 0.9468749761581421, "eval_episode/reward_rate": 0.05555555555555555}
{"step": 1470040, "time": 45777.70508646965, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 1470040, "time": 45778.06697964668, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 1470040, "time": 45778.29801154137, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1470040, "time": 45778.73705172539, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1470040, "time": 45779.80478811264, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1470040, "time": 45780.400054216385, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 1470040, "time": 45780.64815545082, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1470144, "time": 45784.01383471489, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1470264, "time": 45787.45258331299, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1470336, "time": 45789.89623713493, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1470432, "time": 45792.82808470726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1470472, "time": 45793.82116866112, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1470592, "time": 45797.69160819054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1470696, "time": 45800.71047210693, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1470744, "time": 45802.15674138069, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1471024, "time": 45810.832961797714, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1471088, "time": 45812.76006555557, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1471144, "time": 45814.22923374176, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1471648, "time": 45829.68976187706, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1471688, "time": 45830.81021261215, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1471960, "time": 45839.08452296257, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1472032, "time": 45841.48449635506, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1472320, "time": 45850.24163937569, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1472344, "time": 45850.750329732895, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1472416, "time": 45853.14765763283, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 1472648, "time": 45859.96350502968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1472744, "time": 45863.0225815773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1472880, "time": 45867.387776851654, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 1472968, "time": 45869.86525654793, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1473072, "time": 45873.250133275986, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1473296, "time": 45880.11767625809, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1473400, "time": 45883.09031581879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1473672, "time": 45891.39981889725, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1473864, "time": 45897.21561551094, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1473912, "time": 45898.70462346077, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1474088, "time": 45904.07411623001, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1474296, "time": 45910.39596056938, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1474528, "time": 45917.66335058212, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1474592, "time": 45920.11240530014, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1474616, "time": 45920.71347737312, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1474728, "time": 45924.11890411377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1475024, "time": 45933.34203624725, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1475056, "time": 45934.31247138977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1475056, "time": 45934.32031059265, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1475064, "time": 45934.34874129295, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1475192, "time": 45938.22352170944, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1475232, "time": 45939.65542984009, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1475240, "time": 45939.682010650635, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1475592, "time": 45950.43461370468, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1475984, "time": 45962.546325683594, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1475984, "time": 45962.55315685272, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1475984, "time": 45962.56082224846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1476024, "time": 45963.5593650341, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1476128, "time": 45966.94196391106, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1476312, "time": 45972.319883823395, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1476376, "time": 45974.26713013649, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1476600, "time": 45981.241580724716, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1476824, "time": 45988.069727897644, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1476840, "time": 45988.567420482635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1477024, "time": 45994.41261458397, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1477200, "time": 45999.78146100044, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1477504, "time": 46009.07688784599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1477720, "time": 46015.53328704834, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1477832, "time": 46018.91424894333, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1478120, "time": 46027.71743893623, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1478272, "time": 46032.56687307358, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1478288, "time": 46033.05778694153, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1478296, "time": 46033.08529424667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1478296, "time": 46033.09333848953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1478440, "time": 46037.46525669098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1478608, "time": 46042.90013504028, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1478832, "time": 46049.719285964966, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1478912, "time": 46052.15265369415, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1479144, "time": 46058.97148060799, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1479152, "time": 46059.45630764961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1479312, "time": 46064.30635857582, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1479456, "time": 46068.658484220505, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1479544, "time": 46071.19203090668, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1479648, "time": 46074.580340623856, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1479792, "time": 46078.9486181736, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1479808, "time": 46079.43599104881, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1479872, "time": 46081.369460344315, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1479920, "time": 46082.8109292984, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1480024, "time": 46087.107768297195, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1480024, "time": 46087.399321079254, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1480024, "time": 46087.972782850266, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1480024, "time": 46088.19182229042, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1480024, "time": 46088.200124025345, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1480024, "time": 46088.22752547264, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1480024, "time": 46088.23527646065, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1480024, "time": 46089.125829935074, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 1480432, "time": 46102.0923845768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1480448, "time": 46102.57766580582, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1480464, "time": 46103.06369280815, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1480592, "time": 46106.96763801575, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1480608, "time": 46107.459223508835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1480848, "time": 46114.79778122902, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1480928, "time": 46117.25299477577, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1481224, "time": 46126.01933002472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1481272, "time": 46127.49540925026, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1481312, "time": 46128.93512797356, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1481416, "time": 46131.985734939575, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1481736, "time": 46141.76012420654, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1481872, "time": 46146.107254743576, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1482232, "time": 46156.769396305084, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1482376, "time": 46161.19667816162, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1482512, "time": 46165.53108739853, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1482528, "time": 46166.01933097839, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1482744, "time": 46172.332912921906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1482920, "time": 46178.21569228172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1483152, "time": 46185.45377659798, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1483168, "time": 46185.94091439247, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1483624, "time": 46199.60224151611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1483736, "time": 46202.99341249466, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1483784, "time": 46204.445063352585, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1483800, "time": 46204.9506547451, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1483960, "time": 46209.81377029419, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1484168, "time": 46216.116725444794, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1484368, "time": 46222.54235005379, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1484560, "time": 46228.40110087395, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1484824, "time": 46236.25435256958, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1484920, "time": 46239.19074296951, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1485072, "time": 46244.04162359238, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1485456, "time": 46255.773522138596, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1485464, "time": 46255.801161527634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1485480, "time": 46256.28765320778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1485888, "time": 46268.870779037476, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1485984, "time": 46271.79133796692, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1485992, "time": 46271.81828403473, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1486040, "time": 46273.29885649681, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 1486073, "time": 46275.34240603447, "train_stats/mean_log_entropy": 0.08284800189517742, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.344114095857828, "train/action_min": 0.0, "train/action_std": 1.606042752171507, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011720958135856113, "train/actor_opt_grad_steps": 91775.0, "train/actor_opt_loss": -22.39426086916782, "train/adv_mag": 0.715833442340983, "train/adv_max": 0.30480401350720093, "train/adv_mean": 0.0008029379523059736, "train/adv_min": -0.6487626713691371, "train/adv_std": 0.028580553488492377, "train/cont_avg": 0.9938892326732673, "train/cont_loss_mean": 0.026097894696942944, "train/cont_loss_std": 0.29243819389750464, "train/cont_neg_acc": 0.1445049889164396, "train/cont_neg_loss": 3.366659114266386, "train/cont_pos_acc": 0.9998297856585814, "train/cont_pos_loss": 0.005514596557788698, "train/cont_pred": 0.9937416495072959, "train/cont_rate": 0.9938892326732673, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11366232382686864, "train/extr_critic_critic_opt_grad_steps": 91775.0, "train/extr_critic_critic_opt_loss": 12472.074344446164, "train/extr_critic_mag": 1.5617090404623806, "train/extr_critic_max": 1.5617090404623806, "train/extr_critic_mean": 1.4333688894120773, "train/extr_critic_min": 1.14354939980082, "train/extr_critic_std": 0.026473535234016358, "train/extr_return_normed_mag": 0.752423371418868, "train/extr_return_normed_max": 0.2855568994389902, "train/extr_return_normed_mean": 0.050899168651661664, "train/extr_return_normed_min": -0.6358985175000559, "train/extr_return_normed_std": 0.0396722253264472, "train/extr_return_rate": 0.9996384051766726, "train/extr_return_raw_mag": 1.668829618114056, "train/extr_return_raw_max": 1.668829618114056, "train/extr_return_raw_mean": 1.4341719522334562, "train/extr_return_raw_min": 0.7473742011750099, "train/extr_return_raw_std": 0.03967222539099431, "train/extr_reward_mag": 0.2551328929344026, "train/extr_reward_max": 0.2551328929344026, "train/extr_reward_mean": 0.002072740449065269, "train/extr_reward_min": 9.383305464640703e-08, "train/extr_reward_std": 0.008660220785416884, "train/image_loss_mean": 0.07476631717959253, "train/image_loss_std": 0.09634572625307754, "train/model_loss_mean": 0.7213060076874082, "train/model_loss_std": 0.5478804006729976, "train/model_opt_grad_norm": 14.894131069752708, "train/model_opt_grad_steps": 91687.80693069307, "train/model_opt_loss": 4031.648709438815, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5569.306930693069, "train/policy_entropy_mag": 1.197950516006734, "train/policy_entropy_max": 1.197950516006734, "train/policy_entropy_mean": 0.09323853671108143, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11339793855896091, "train/policy_logprob_mag": 6.551080283552113, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09353328437203227, "train/policy_logprob_min": -6.551080283552113, "train/policy_logprob_std": 0.6314805188391468, "train/policy_randomness_mag": 0.6156248202418336, "train/policy_randomness_max": 0.6156248202418336, "train/policy_randomness_mean": 0.04791513376749388, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05827501619068703, "train/post_ent_mag": 35.2337964312865, "train/post_ent_max": 35.2337964312865, "train/post_ent_mean": 34.623969219698765, "train/post_ent_min": 33.917665424913466, "train/post_ent_std": 0.2741784962392089, "train/prior_ent_mag": 35.07624614828884, "train/prior_ent_max": 35.07624614828884, "train/prior_ent_mean": 33.371374073595106, "train/prior_ent_min": 32.16905421077615, "train/prior_ent_std": 0.46030015800849045, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.002831638437675054, "train/reward_loss_mean": 0.02044177727686186, "train/reward_loss_std": 0.26706714419611166, "train/reward_max_data": 0.8087716587994358, "train/reward_max_pred": 0.35650489885028047, "train/reward_neg_acc": 0.9994272813938632, "train/reward_neg_loss": 0.003820442210763029, "train/reward_pos_acc": 0.17311757484722376, "train/reward_pos_loss": 4.04495969789112, "train/reward_pred": 0.002309784252256487, "train/reward_rate": 0.00412863551980198, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0322566032409668, "report/cont_loss_std": 0.36289915442466736, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.566035270690918, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005534923169761896, "report/cont_pred": 0.9945156574249268, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05872827768325806, "report/image_loss_std": 0.07912923395633698, "report/model_loss_mean": 0.7074699997901917, "report/model_loss_std": 0.5639965534210205, "report/post_ent_mag": 34.78944396972656, "report/post_ent_max": 34.78944396972656, "report/post_ent_mean": 33.84785461425781, "report/post_ent_min": 32.889644622802734, "report/post_ent_std": 0.4116568863391876, "report/prior_ent_mag": 34.62882995605469, "report/prior_ent_max": 34.62882995605469, "report/prior_ent_mean": 33.27326583862305, "report/prior_ent_min": 32.095497131347656, "report/prior_ent_std": 0.41306546330451965, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0020416260231286287, "report/reward_loss_mean": 0.016485121101140976, "report/reward_loss_std": 0.25213325023651123, "report/reward_max_data": 0.800000011920929, "report/reward_max_pred": 0.05203890800476074, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0031387750059366226, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.558691501617432, "report/reward_pred": 0.0016502385260537267, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.025834232568740845, "eval/cont_loss_std": 0.2658431828022003, "eval/cont_neg_acc": 0.1666666716337204, "eval/cont_neg_loss": 3.074951171875, "eval/cont_pos_acc": 0.9990177154541016, "eval/cont_pos_loss": 0.007863014005124569, "eval/cont_pred": 0.9930258393287659, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11379080265760422, "eval/image_loss_std": 0.13143779337406158, "eval/model_loss_mean": 0.7686790227890015, "eval/model_loss_std": 0.6443201303482056, "eval/post_ent_mag": 34.85773468017578, "eval/post_ent_max": 34.85773468017578, "eval/post_ent_mean": 33.915565490722656, "eval/post_ent_min": 32.74269104003906, "eval/post_ent_std": 0.44505149126052856, "eval/prior_ent_mag": 34.6502685546875, "eval/prior_ent_max": 34.6502685546875, "eval/prior_ent_mean": 33.273155212402344, "eval/prior_ent_min": 31.901641845703125, "eval/prior_ent_std": 0.44211849570274353, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.003811645321547985, "eval/reward_loss_mean": 0.02905397303402424, "eval/reward_loss_std": 0.34449103474617004, "eval/reward_max_data": 0.875, "eval/reward_max_pred": 0.6737768650054932, "eval/reward_neg_acc": 0.9990177154541016, "eval/reward_neg_loss": 0.004893873818218708, "eval/reward_pos_acc": 0.1666666716337204, "eval/reward_pos_loss": 4.1282172203063965, "eval/reward_pred": 0.003000323660671711, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32320.0, "replay/samples": 32320.0, "replay/insert_wait_avg": 1.242410133380701e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.482301589285974e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4040.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1193280172820138e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1106526851654, "timer/env.step_count": 4040.0, "timer/env.step_total": 39.250812292099, "timer/env.step_frac": 0.03924646956485839, "timer/env.step_avg": 0.009715547597054208, "timer/env.step_min": 0.007728099822998047, "timer/env.step_max": 0.0438539981842041, "timer/replay._sample_count": 32320.0, "timer/replay._sample_total": 16.458815813064575, "timer/replay._sample_frac": 0.016456994802399937, "timer/replay._sample_avg": 0.0005092455387705623, "timer/replay._sample_min": 0.00040340423583984375, "timer/replay._sample_max": 0.011356592178344727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4545.0, "timer/agent.policy_total": 48.291011095047, "timer/agent.policy_frac": 0.04828566815621051, "timer/agent.policy_avg": 0.01062508494940528, "timer/agent.policy_min": 0.009064674377441406, "timer/agent.policy_max": 0.08762955665588379, "timer/dataset_train_count": 2020.0, "timer/dataset_train_total": 0.21895766258239746, "timer/dataset_train_frac": 0.00021893343700971985, "timer/dataset_train_avg": 0.00010839488246653339, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0003535747528076172, "timer/agent.train_count": 2020.0, "timer/agent.train_total": 900.966225862503, "timer/agent.train_frac": 0.9008665425605931, "timer/agent.train_avg": 0.44602288409034807, "timer/agent.train_min": 0.43610095977783203, "timer/agent.train_max": 0.6956784725189209, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4840073585510254, "timer/agent.report_frac": 0.00048395380776270044, "timer/agent.report_avg": 0.2420036792755127, "timer/agent.report_min": 0.2361905574798584, "timer/agent.report_max": 0.247816801071167, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.432847685248363e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 32.31585685114605}
{"step": 1486152, "time": 46277.52060461044, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1486208, "time": 46279.4770321846, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1486616, "time": 46291.76596403122, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1486704, "time": 46294.70640921593, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1486728, "time": 46295.21845960617, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1486840, "time": 46298.63659334183, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1487008, "time": 46303.979135751724, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1487256, "time": 46311.349709033966, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1487416, "time": 46316.20486021042, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1487544, "time": 46320.13338446617, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1487608, "time": 46322.07772183418, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1488008, "time": 46334.23925471306, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1488296, "time": 46343.07419371605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1488304, "time": 46343.54412007332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1488416, "time": 46346.947358846664, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1488464, "time": 46348.43024921417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1488520, "time": 46349.92063045502, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1488760, "time": 46357.281569719315, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 1488768, "time": 46357.75270152092, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1488824, "time": 46359.24405169487, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1488848, "time": 46360.20394945145, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1488960, "time": 46363.64081907272, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1489032, "time": 46365.608927965164, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1489368, "time": 46375.95393753052, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1489440, "time": 46378.396555662155, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1489560, "time": 46381.82604455948, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1489632, "time": 46384.23301625252, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1489696, "time": 46386.169358730316, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1489872, "time": 46391.536007881165, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1489920, "time": 46393.00389480591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1490008, "time": 46396.15067958832, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1490008, "time": 46396.53153848648, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1490008, "time": 46396.70057797432, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1490008, "time": 46396.99946856499, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1490008, "time": 46397.00898718834, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1490008, "time": 46397.199838876724, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1490008, "time": 46398.11847400665, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1490008, "time": 46398.17822766304, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1490112, "time": 46401.64865708351, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1490344, "time": 46408.42147684097, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1490408, "time": 46410.40425348282, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1490536, "time": 46414.30590438843, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1490560, "time": 46415.254630327225, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1490640, "time": 46417.68659877777, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1490728, "time": 46420.14804816246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1490992, "time": 46428.849004268646, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1491000, "time": 46428.876525878906, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1491264, "time": 46437.104627370834, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1491344, "time": 46439.53600168228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1491536, "time": 46445.36101484299, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1491904, "time": 46456.49074316025, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1491952, "time": 46457.96356058121, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1491960, "time": 46457.99078321457, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1492104, "time": 46462.42325782776, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1492104, "time": 46462.43100595474, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 1492184, "time": 46464.87541294098, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1492464, "time": 46473.63914465904, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1492680, "time": 46480.026794433594, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1492856, "time": 46485.43389964104, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1493008, "time": 46490.34936571121, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1493312, "time": 46499.65287446976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1493336, "time": 46500.16518688202, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1493448, "time": 46503.57801389694, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1493784, "time": 46513.762318611145, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1494216, "time": 46526.976403951645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1494264, "time": 46528.42165637016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1494272, "time": 46528.88863325119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1494624, "time": 46539.489149570465, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1494944, "time": 46549.212953567505, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1495168, "time": 46556.1249063015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1495208, "time": 46557.116347551346, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1495344, "time": 46561.45954632759, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1495744, "time": 46573.5368411541, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1496064, "time": 46583.25727534294, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1496096, "time": 46584.22294139862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1496472, "time": 46595.40878558159, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1496488, "time": 46595.90265059471, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1496528, "time": 46597.34954786301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1496584, "time": 46598.84572458267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1496672, "time": 46601.77208137512, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1496936, "time": 46609.624720811844, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1497480, "time": 46626.28084254265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1497864, "time": 46637.974037885666, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1498000, "time": 46642.47408437729, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1498040, "time": 46643.489730119705, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1498056, "time": 46643.97925853729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1498408, "time": 46654.64640903473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1498456, "time": 46656.10659956932, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1498648, "time": 46661.96184301376, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1498896, "time": 46669.757113695145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1499176, "time": 46678.70707845688, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1499232, "time": 46680.63511323929, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1499248, "time": 46681.12709784508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1499360, "time": 46684.53222036362, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1499616, "time": 46692.303139448166, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1499736, "time": 46695.738502025604, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1499792, "time": 46697.67807221413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1500096, "time": 46707.713764190674, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1500096, "time": 46708.247302532196, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1500096, "time": 46708.65517258644, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 1500096, "time": 46708.71522641182, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1500096, "time": 46708.90453696251, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1500096, "time": 46709.0328502655, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1500096, "time": 46709.12721347809, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 1500096, "time": 46710.0447974205, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1500368, "time": 46718.2616443634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1500456, "time": 46720.70627069473, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1500584, "time": 46724.56350803375, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1500664, "time": 46727.00692534447, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1501080, "time": 46739.75317144394, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1501280, "time": 46746.10761475563, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1501488, "time": 46752.49319219589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1501688, "time": 46758.358503341675, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1501688, "time": 46758.36721253395, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1501928, "time": 46765.788424015045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1502008, "time": 46768.24322295189, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1502048, "time": 46769.69529700279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1502104, "time": 46771.18022632599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1502296, "time": 46777.01841664314, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1502432, "time": 46781.40498113632, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1502488, "time": 46782.90547013283, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1502904, "time": 46795.647408246994, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1502904, "time": 46795.656413793564, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1502976, "time": 46798.0601580143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1503360, "time": 46809.71548295021, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1503528, "time": 46814.5834710598, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1503544, "time": 46815.07606482506, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1503880, "time": 46825.329740047455, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1503880, "time": 46825.33781337738, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1503968, "time": 46828.23877954483, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1504192, "time": 46835.03523564339, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1504240, "time": 46836.480704545975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1504360, "time": 46839.90116214752, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1504776, "time": 46852.60647559166, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1504784, "time": 46853.076825618744, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1505288, "time": 46868.146230220795, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1505288, "time": 46868.15425205231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1505672, "time": 46879.83936691284, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1506192, "time": 46896.10695552826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1506304, "time": 46899.54252243042, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1506552, "time": 46906.8561668396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1506672, "time": 46910.81302571297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1506784, "time": 46914.18055033684, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1506872, "time": 46916.61896967888, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1507088, "time": 46923.36854672432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1507096, "time": 46923.397265434265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1507320, "time": 46930.272055625916, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1507320, "time": 46930.277396678925, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1507448, "time": 46934.643433094025, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1507600, "time": 46939.466936826706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1507752, "time": 46943.96928715706, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1507896, "time": 46948.3371257782, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1508032, "time": 46952.686430215836, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1508096, "time": 46954.63071894646, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1508392, "time": 46963.43383932114, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1508424, "time": 46964.41669988632, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1508640, "time": 46971.30970621109, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1508648, "time": 46971.33704137802, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1508864, "time": 46978.14075422287, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1509040, "time": 46983.54157328606, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 1509048, "time": 46983.56808042526, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1509192, "time": 46987.99123668671, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1509224, "time": 46988.973568201065, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1509296, "time": 46991.41701436043, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1509536, "time": 46998.74559903145, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1509560, "time": 46999.279881477356, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1509736, "time": 47004.74008178711, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1509800, "time": 47006.685143470764, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1509848, "time": 47008.153932094574, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1510080, "time": 47016.151888132095, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1510080, "time": 47016.34264755249, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1510080, "time": 47016.47805094719, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1510080, "time": 47017.1073384285, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1510080, "time": 47017.33607053757, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1510080, "time": 47017.89918375015, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1510080, "time": 47018.08508133888, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1510080, "time": 47018.32264852524, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 1510288, "time": 47024.647258758545, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1510352, "time": 47026.59949040413, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1510408, "time": 47028.07666349411, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1510656, "time": 47035.94677758217, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1510664, "time": 47035.97345542908, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1510816, "time": 47040.8110268116, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1511056, "time": 47048.107306957245, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1511352, "time": 47056.88036751747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1511384, "time": 47057.858041763306, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1511448, "time": 47059.82873463631, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1511464, "time": 47060.35083937645, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1511504, "time": 47061.86927127838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1511608, "time": 47064.847563028336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1512112, "time": 47080.574907541275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1512136, "time": 47081.083565711975, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1512184, "time": 47082.55771803856, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1512512, "time": 47092.89969921112, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1512648, "time": 47096.80922961235, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1512928, "time": 47105.52781176567, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1513024, "time": 47108.45843362808, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1513384, "time": 47119.27379512787, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1513384, "time": 47119.279537677765, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1513640, "time": 47127.20148420334, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1513664, "time": 47128.15801334381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1513696, "time": 47129.136573791504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1513728, "time": 47130.12896871567, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1513760, "time": 47131.101283073425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1513880, "time": 47134.52887868881, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1514256, "time": 47146.19431042671, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1514456, "time": 47152.157828330994, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1514728, "time": 47160.47611165047, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1514896, "time": 47165.81973671913, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1515128, "time": 47172.60444140434, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1515176, "time": 47174.071326971054, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1515456, "time": 47182.84585118294, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1515496, "time": 47183.855622291565, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1515600, "time": 47187.66901373863, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1515696, "time": 47190.5924077034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1515952, "time": 47198.410809993744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1516088, "time": 47202.30510854721, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1516192, "time": 47205.71043634415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1516512, "time": 47215.46703386307, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1516592, "time": 47217.90987920761, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1516768, "time": 47223.246731996536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1516848, "time": 47225.67056441307, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1516904, "time": 47227.17366719246, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1517224, "time": 47236.97253537178, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1517288, "time": 47238.94900250435, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1517520, "time": 47246.31540846825, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1517768, "time": 47253.617809057236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1518008, "time": 47260.898522138596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1518056, "time": 47262.37155222893, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1518232, "time": 47267.68974471092, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1518360, "time": 47271.672498226166, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1518457, "time": 47275.72888946533, "train_stats/mean_log_entropy": 0.08012049184473241, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4298144047803216, "train/action_min": 0.0, "train/action_std": 1.6959683741673384, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012005774405701915, "train/actor_opt_grad_steps": 93795.0, "train/actor_opt_loss": -25.398456922852166, "train/adv_mag": 0.7710107081007249, "train/adv_max": 0.3196397046051403, "train/adv_mean": 0.0002828885767079969, "train/adv_min": -0.7006703030945051, "train/adv_std": 0.029837229021705023, "train/cont_avg": 0.9937973777846535, "train/cont_loss_mean": 0.026160605053537258, "train/cont_loss_std": 0.2887727317059099, "train/cont_neg_acc": 0.14158719719046414, "train/cont_neg_loss": 3.304169850418169, "train/cont_pos_acc": 0.9998444454504711, "train/cont_pos_loss": 0.005512401288707215, "train/cont_pred": 0.993736737435407, "train/cont_rate": 0.9937973777846535, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11809835235339285, "train/extr_critic_critic_opt_grad_steps": 93795.0, "train/extr_critic_critic_opt_loss": 12341.386704246597, "train/extr_critic_mag": 1.5841437129691096, "train/extr_critic_max": 1.5841437129691096, "train/extr_critic_mean": 1.4373048325576405, "train/extr_critic_min": 1.1639415462418359, "train/extr_critic_std": 0.027781435076405507, "train/extr_return_normed_mag": 0.788050651550293, "train/extr_return_normed_max": 0.3219110422795362, "train/extr_return_normed_mean": 0.0530938554167895, "train/extr_return_normed_min": -0.6627900960421799, "train/extr_return_normed_std": 0.04149432702561711, "train/extr_return_rate": 0.9997270393489611, "train/extr_return_raw_mag": 1.7064048417724005, "train/extr_return_raw_max": 1.7064048417724005, "train/extr_return_raw_mean": 1.4375877185623245, "train/extr_return_raw_min": 0.7217037034506845, "train/extr_return_raw_std": 0.04149432691496493, "train/extr_reward_mag": 0.29991904756810406, "train/extr_reward_max": 0.29991904756810406, "train/extr_reward_mean": 0.0026571428228059028, "train/extr_reward_min": 1.1448812956857209e-07, "train/extr_reward_std": 0.010708485391120067, "train/image_loss_mean": 0.07415925200549092, "train/image_loss_std": 0.09749204694929689, "train/model_loss_mean": 0.7208369229689683, "train/model_loss_std": 0.5429906947630467, "train/model_opt_grad_norm": 14.985851431837176, "train/model_opt_grad_steps": 93706.07920792079, "train/model_opt_loss": 4109.977883518332, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5693.069306930693, "train/policy_entropy_mag": 1.218485952603935, "train/policy_entropy_max": 1.218485952603935, "train/policy_entropy_mean": 0.09035516213072409, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10854845877626154, "train/policy_logprob_mag": 6.5510802764703735, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09083570705929606, "train/policy_logprob_min": -6.5510802764703735, "train/policy_logprob_std": 0.630137311940146, "train/policy_randomness_mag": 0.6261779477100561, "train/policy_randomness_max": 0.6261779477100561, "train/policy_randomness_mean": 0.046433372515262944, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.055782876632148676, "train/post_ent_mag": 35.39069283362662, "train/post_ent_max": 35.39069283362662, "train/post_ent_mean": 34.6923244967319, "train/post_ent_min": 33.88291221089882, "train/post_ent_std": 0.3131547965625725, "train/prior_ent_mag": 34.649158685514244, "train/prior_ent_max": 34.649158685514244, "train/prior_ent_mean": 33.332436249987914, "train/prior_ent_min": 32.18156836292531, "train/prior_ent_std": 0.404320085697835, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.002870012055690594, "train/reward_loss_mean": 0.020517041577063133, "train/reward_loss_std": 0.2640720344434428, "train/reward_max_data": 0.8126701730312688, "train/reward_max_pred": 0.34401898868013137, "train/reward_neg_acc": 0.9993739148767868, "train/reward_neg_loss": 0.003885501532326683, "train/reward_pos_acc": 0.17995436809957027, "train/reward_pos_loss": 3.9609302619099616, "train/reward_pred": 0.0023188231954360287, "train/reward_rate": 0.004191483601485148, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.035128213465213776, "report/cont_loss_std": 0.3381112217903137, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.7766976356506348, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005667035933583975, "report/cont_pred": 0.9942731261253357, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07774968445301056, "report/image_loss_std": 0.10276316106319427, "report/model_loss_mean": 0.7393723726272583, "report/model_loss_std": 0.6288019418716431, "report/post_ent_mag": 35.696006774902344, "report/post_ent_max": 35.696006774902344, "report/post_ent_mean": 35.124385833740234, "report/post_ent_min": 34.46586227416992, "report/post_ent_std": 0.2339688092470169, "report/prior_ent_mag": 34.708587646484375, "report/prior_ent_max": 34.708587646484375, "report/prior_ent_mean": 33.51839828491211, "report/prior_ent_min": 32.74776077270508, "report/prior_ent_std": 0.3252737522125244, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0031829834915697575, "report/reward_loss_mean": 0.026494469493627548, "report/reward_loss_std": 0.3129561245441437, "report/reward_max_data": 0.75, "report/reward_max_pred": 0.053041696548461914, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004713357891887426, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.465484619140625, "report/reward_pred": 0.0024320585653185844, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03694630786776543, "eval/cont_loss_std": 0.450983464717865, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.2352705001831055, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.006307857111096382, "eval/cont_pred": 0.9938665628433228, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1031026616692543, "eval/image_loss_std": 0.11955410242080688, "eval/model_loss_mean": 0.7684007883071899, "eval/model_loss_std": 0.7456048727035522, "eval/post_ent_mag": 35.69716262817383, "eval/post_ent_max": 35.69716262817383, "eval/post_ent_mean": 35.140296936035156, "eval/post_ent_min": 34.569305419921875, "eval/post_ent_std": 0.240289568901062, "eval/prior_ent_mag": 34.659481048583984, "eval/prior_ent_max": 34.659481048583984, "eval/prior_ent_mean": 33.54528045654297, "eval/prior_ent_min": 32.6329460144043, "eval/prior_ent_std": 0.3347166180610657, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.003671264508739114, "eval/reward_loss_mean": 0.028351783752441406, "eval/reward_loss_std": 0.3351345658302307, "eval/reward_max_data": 0.8843749761581421, "eval/reward_max_pred": 0.23338556289672852, "eval/reward_neg_acc": 0.9980372786521912, "eval/reward_neg_loss": 0.005392883438616991, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.707376003265381, "eval/reward_pred": 0.0026729698292911053, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 32384.0, "replay/samples": 32384.0, "replay/insert_wait_avg": 1.2284255192685034e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.601285522634332e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0934369317416487e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2514133453369, "timer/env.step_count": 4048.0, "timer/env.step_total": 39.27976322174072, "timer/env.step_frac": 0.03926989024726264, "timer/env.step_avg": 0.009703498819599981, "timer/env.step_min": 0.0077593326568603516, "timer/env.step_max": 0.0348052978515625, "timer/replay._sample_count": 32384.0, "timer/replay._sample_total": 16.4576735496521, "timer/replay._sample_frac": 0.016453536910894708, "timer/replay._sample_avg": 0.0005082038522002254, "timer/replay._sample_min": 0.0004105567932128906, "timer/replay._sample_max": 0.03401684761047363, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4512.0, "timer/agent.policy_total": 47.60189151763916, "timer/agent.policy_frac": 0.047589926774944336, "timer/agent.policy_avg": 0.010550064609405841, "timer/agent.policy_min": 0.008875608444213867, "timer/agent.policy_max": 0.08514046669006348, "timer/dataset_train_count": 2024.0, "timer/dataset_train_total": 0.21852421760559082, "timer/dataset_train_frac": 0.00021846929151015886, "timer/dataset_train_avg": 0.00010796651067469902, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0007135868072509766, "timer/agent.train_count": 2024.0, "timer/agent.train_total": 902.9525291919708, "timer/agent.train_frac": 0.9027255719360092, "timer/agent.train_avg": 0.4461227911027524, "timer/agent.train_min": 0.4331388473510742, "timer/agent.train_max": 0.6858398914337158, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4737720489501953, "timer/agent.report_frac": 0.00047365296627341574, "timer/agent.report_avg": 0.23688602447509766, "timer/agent.report_min": 0.2299511432647705, "timer/agent.report_max": 0.2438209056854248, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.12249834847487e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 32.375269785223416}
{"step": 1518504, "time": 47276.927683115005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1518744, "time": 47284.2675549984, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1518904, "time": 47289.15094256401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1519032, "time": 47293.078154563904, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1519072, "time": 47294.5059132576, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1519160, "time": 47296.958451747894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1519192, "time": 47297.926730155945, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1519464, "time": 47306.19075202942, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1519808, "time": 47316.83777451515, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1519928, "time": 47320.238909482956, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1520000, "time": 47322.64313817024, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1520064, "time": 47325.72752547264, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1520064, "time": 47326.577328681946, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1520064, "time": 47326.89646649361, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1520064, "time": 47327.15727210045, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 1520064, "time": 47329.39495873451, "eval_episode/length": 255.0, "eval_episode/score": 0.203125, "eval_episode/reward_rate": 0.00390625}
{"step": 1520064, "time": 47330.02658700943, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1520064, "time": 47330.03642606735, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1520064, "time": 47330.04622173309, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1520064, "time": 47330.05679488182, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1520368, "time": 47339.33742547035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1520640, "time": 47347.58677124977, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1520728, "time": 47350.02105641365, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1520920, "time": 47355.88443350792, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1521056, "time": 47360.27062892914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1521080, "time": 47360.89204001427, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1521368, "time": 47369.662497758865, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1521472, "time": 47373.05103468895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1521768, "time": 47381.86395597458, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1521912, "time": 47386.239229917526, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1521944, "time": 47387.21372294426, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1521968, "time": 47388.16325712204, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1522040, "time": 47390.17779612541, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1522240, "time": 47396.48390889168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1522312, "time": 47398.42870426178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1522320, "time": 47398.89494562149, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1522888, "time": 47415.88796877861, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1523040, "time": 47420.81865501404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1523264, "time": 47427.597141742706, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1523320, "time": 47429.088867902756, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1523344, "time": 47430.04267501831, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1523416, "time": 47432.006133556366, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1523480, "time": 47433.97951054573, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1523664, "time": 47439.780572891235, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1523680, "time": 47440.26918840408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1523944, "time": 47448.546016931534, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1524080, "time": 47453.0068666935, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1524104, "time": 47453.51596736908, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1524208, "time": 47456.88675427437, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1524208, "time": 47456.89324474335, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1524224, "time": 47457.38387751579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1524280, "time": 47458.87902998924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1524528, "time": 47466.59022164345, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1524672, "time": 47470.96935725212, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1525136, "time": 47485.159494161606, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1525200, "time": 47487.11347603798, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1525320, "time": 47490.554126262665, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1525360, "time": 47492.02267575264, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1525728, "time": 47503.286405563354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1525792, "time": 47505.23197507858, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1525880, "time": 47507.704045295715, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1526080, "time": 47514.11303091049, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1526136, "time": 47515.59547686577, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1526256, "time": 47519.475987672806, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1526280, "time": 47519.9852309227, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1526344, "time": 47521.92151045799, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1526432, "time": 47524.8260614872, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1526664, "time": 47531.66995429993, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1526672, "time": 47532.15832400322, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1526712, "time": 47533.153232097626, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1526752, "time": 47534.58990693092, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1527136, "time": 47546.32506275177, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1527488, "time": 47556.96208882332, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 1527624, "time": 47560.86092209816, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1527704, "time": 47563.29995179176, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1527776, "time": 47565.698705911636, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1527840, "time": 47567.655831575394, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1528120, "time": 47576.029975652695, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1528120, "time": 47576.03663110733, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1528392, "time": 47584.25626325607, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1528568, "time": 47589.62167406082, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1528656, "time": 47592.53373622894, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 1528680, "time": 47593.04695510864, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1528768, "time": 47595.96487379074, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1528912, "time": 47600.38287305832, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1528976, "time": 47602.3704020977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1529152, "time": 47607.73802804947, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1529176, "time": 47608.25123810768, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1529408, "time": 47615.539965867996, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1529424, "time": 47616.03284955025, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1529640, "time": 47622.39346122742, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1529808, "time": 47627.713911533356, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1530048, "time": 47637.08190655708, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1530048, "time": 47637.355162382126, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1530048, "time": 47637.88242864609, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1530048, "time": 47638.39894986153, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 1530048, "time": 47638.61043739319, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1530048, "time": 47638.921593904495, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 1530048, "time": 47639.463306427, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1530048, "time": 47639.53068494797, "eval_episode/length": 197.0, "eval_episode/score": 0.3843750059604645, "eval_episode/reward_rate": 0.005050505050505051}
{"step": 1530072, "time": 47640.04177570343, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1530088, "time": 47640.52982711792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1530288, "time": 47646.83698487282, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1530296, "time": 47646.866465091705, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1530328, "time": 47647.84021306038, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1530464, "time": 47652.20834326744, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1530504, "time": 47653.202050209045, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1530920, "time": 47665.926357746124, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1530936, "time": 47666.413704156876, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1531176, "time": 47673.699073553085, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1531376, "time": 47680.01226902008, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1531408, "time": 47680.984493255615, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1531488, "time": 47683.41328167915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1531744, "time": 47691.3459277153, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1531992, "time": 47699.092010974884, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1532056, "time": 47701.03125452995, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1532272, "time": 47707.82116436958, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1532384, "time": 47711.22079539299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1532384, "time": 47711.22906637192, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1532576, "time": 47717.1039249897, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1532752, "time": 47722.593620061874, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1532912, "time": 47727.46512413025, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1533248, "time": 47737.74789595604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1533296, "time": 47739.21622776985, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1533336, "time": 47740.22151660919, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1533488, "time": 47745.11485123634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1533592, "time": 47748.08147549629, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1533760, "time": 47753.58445620537, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1533952, "time": 47759.43554353714, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1534352, "time": 47771.65400481224, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1534368, "time": 47772.15068936348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1534520, "time": 47776.53754878044, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1534752, "time": 47783.82770681381, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1534888, "time": 47787.723925590515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1534944, "time": 47789.64700961113, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1534984, "time": 47790.64053893089, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1535008, "time": 47791.61254429817, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1535184, "time": 47796.96107959747, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1535488, "time": 47806.191076517105, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1535600, "time": 47809.57925486565, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1535648, "time": 47811.137496471405, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1535800, "time": 47815.52544784546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1536048, "time": 47823.25626158714, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1536272, "time": 47830.098061323166, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1536440, "time": 47834.961112976074, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1536448, "time": 47835.42452263832, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1536680, "time": 47842.28068423271, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1537200, "time": 47858.352722883224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1537328, "time": 47862.31011533737, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1537528, "time": 47868.21167302132, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 1537672, "time": 47872.731246471405, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1537832, "time": 47877.629356861115, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1537912, "time": 47880.07035732269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1537952, "time": 47881.50576400757, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1538008, "time": 47882.98318481445, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1538112, "time": 47886.388882637024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1538184, "time": 47888.367090940475, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1538584, "time": 47900.740805864334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1538744, "time": 47905.60243153572, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1538888, "time": 47910.00074124336, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1539088, "time": 47916.285655260086, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1539176, "time": 47918.742389917374, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1539440, "time": 47927.014369010925, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1540032, "time": 47946.20775556564, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1540032, "time": 47946.41102147102, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1540032, "time": 47946.49394273758, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1540032, "time": 47946.72901439667, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1540032, "time": 47946.97413897514, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1540032, "time": 47947.409687280655, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1540032, "time": 47947.61330080032, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 1540032, "time": 47948.527888059616, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1540144, "time": 47952.52354335785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1540224, "time": 47954.95950818062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1540264, "time": 47955.961176633835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1540552, "time": 47964.85982489586, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1540632, "time": 47967.32735705376, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1540816, "time": 47973.14249706268, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1540864, "time": 47974.59924674034, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1540936, "time": 47976.5834877491, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1541056, "time": 47980.471024513245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1541200, "time": 47984.92218089104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1541352, "time": 47989.3511633873, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 1541512, "time": 47994.26599574089, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1541656, "time": 47998.620112895966, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1541832, "time": 48003.92519259453, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1541848, "time": 48004.41905498505, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1541992, "time": 48008.77685499191, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1542144, "time": 48013.62577033043, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1542144, "time": 48013.63221311569, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1542520, "time": 48024.97931599617, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1542864, "time": 48035.5481133461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1542928, "time": 48037.465482234955, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1543080, "time": 48041.82344031334, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1543128, "time": 48043.274183511734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1543368, "time": 48050.63963508606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1543592, "time": 48057.39978146553, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1543664, "time": 48059.812938928604, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1543832, "time": 48064.70448112488, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1544032, "time": 48071.026492357254, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1544160, "time": 48074.91700005531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1544168, "time": 48074.94393205643, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1544480, "time": 48084.70505285263, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 1544656, "time": 48090.02924871445, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1544696, "time": 48091.02468585968, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1544784, "time": 48093.919078826904, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1544864, "time": 48096.36707639694, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1545184, "time": 48106.14668464661, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1545200, "time": 48106.63587284088, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1545280, "time": 48109.101289987564, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1545632, "time": 48119.945883989334, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1545752, "time": 48123.38849401474, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1545976, "time": 48130.20867872238, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1545976, "time": 48130.21625041962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1546192, "time": 48137.03847002983, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1546304, "time": 48140.58425092697, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1546344, "time": 48141.576986312866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1546392, "time": 48143.05200767517, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1546832, "time": 48156.7661383152, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1547008, "time": 48162.22317528725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1547296, "time": 48171.096981048584, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1547496, "time": 48176.97325229645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1547536, "time": 48178.40905928612, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1547592, "time": 48179.88572001457, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1547696, "time": 48183.28100013733, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1547832, "time": 48187.17749834061, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1547968, "time": 48191.53110933304, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1548288, "time": 48201.46610927582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1548288, "time": 48201.50269031525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1548440, "time": 48206.24006342888, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1548704, "time": 48214.45041823387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1548832, "time": 48218.358483076096, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1548928, "time": 48221.32340455055, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1549488, "time": 48238.6092748642, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1549608, "time": 48242.0355360508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1549808, "time": 48248.36004257202, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1549808, "time": 48248.36982035637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1550016, "time": 48255.586399793625, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1550016, "time": 48256.15126943588, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1550016, "time": 48256.349445819855, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1550016, "time": 48256.40795135498, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1550016, "time": 48256.92770433426, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1550016, "time": 48256.95071840286, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1550016, "time": 48257.7988550663, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1550016, "time": 48257.84465074539, "eval_episode/length": 170.0, "eval_episode/score": 0.46875, "eval_episode/reward_rate": 0.005847953216374269}
{"step": 1550112, "time": 48260.841452121735, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1550280, "time": 48265.71276855469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1550368, "time": 48268.60803580284, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1550456, "time": 48271.05448555946, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1550488, "time": 48272.03336763382, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1550585, "time": 48275.994815588, "train_stats/mean_log_entropy": 0.08024905835864721, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.413912189540578, "train/action_min": 0.0, "train/action_std": 1.6908876296892688, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012461567207225669, "train/actor_opt_grad_steps": 95810.0, "train/actor_opt_loss": -25.159300007037263, "train/adv_mag": 0.7435235452296128, "train/adv_max": 0.31624505235188044, "train/adv_mean": 0.0009546469155155598, "train/adv_min": -0.6709451334393439, "train/adv_std": 0.033017767982474015, "train/cont_avg": 0.9936450559701493, "train/cont_loss_mean": 0.026926978843388568, "train/cont_loss_std": 0.29450884535538024, "train/cont_neg_acc": 0.11668497564929042, "train/cont_neg_loss": 3.3617823284063766, "train/cont_pos_acc": 0.9998582574858594, "train/cont_pos_loss": 0.005593657554984463, "train/cont_pred": 0.9937152654970464, "train/cont_rate": 0.9936450559701493, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13221844160623514, "train/extr_critic_critic_opt_grad_steps": 95810.0, "train/extr_critic_critic_opt_loss": 11776.35986571051, "train/extr_critic_mag": 1.6073761520101064, "train/extr_critic_max": 1.6073761520101064, "train/extr_critic_mean": 1.4531875570022053, "train/extr_critic_min": 1.2421828941326236, "train/extr_critic_std": 0.027872718954041822, "train/extr_return_normed_mag": 0.7605791868855111, "train/extr_return_normed_max": 0.36131107214078384, "train/extr_return_normed_mean": 0.05538962878731649, "train/extr_return_normed_min": -0.6041211488828138, "train/extr_return_normed_std": 0.04450477284393204, "train/extr_return_rate": 0.9996145806502347, "train/extr_return_raw_mag": 1.7600634619964295, "train/extr_return_raw_max": 1.7600634619964295, "train/extr_return_raw_mean": 1.4541420871345558, "train/extr_return_raw_min": 0.7946312409728321, "train/extr_return_raw_std": 0.044504772769796905, "train/extr_reward_mag": 0.3431775368268217, "train/extr_reward_max": 0.3431775368268217, "train/extr_reward_mean": 0.002590001892618168, "train/extr_reward_min": 1.7317966442203048e-07, "train/extr_reward_std": 0.011337643271469655, "train/image_loss_mean": 0.07474276951667089, "train/image_loss_std": 0.09658143409893881, "train/model_loss_mean": 0.7240645114462174, "train/model_loss_std": 0.568622424605474, "train/model_opt_grad_norm": 15.002033112654045, "train/model_opt_grad_steps": 95719.23383084577, "train/model_opt_loss": 3783.690800149642, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5248.756218905472, "train/policy_entropy_mag": 1.2064770560952562, "train/policy_entropy_max": 1.2064770560952562, "train/policy_entropy_mean": 0.0899799465762442, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10741992747012656, "train/policy_logprob_mag": 6.551080269600028, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08967281503612129, "train/policy_logprob_min": -6.551080269600028, "train/policy_logprob_std": 0.6257302162066027, "train/policy_randomness_mag": 0.6200065959745379, "train/policy_randomness_max": 0.6200065959745379, "train/policy_randomness_mean": 0.04624055010910651, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05520292575383068, "train/post_ent_mag": 35.32581800014818, "train/post_ent_max": 35.32581800014818, "train/post_ent_mean": 34.76011957576619, "train/post_ent_min": 34.13278760008551, "train/post_ent_std": 0.24236488090225713, "train/prior_ent_mag": 34.71683701472496, "train/prior_ent_max": 34.71683701472496, "train/prior_ent_mean": 33.52732052020173, "train/prior_ent_min": 32.691079381686535, "train/prior_ent_std": 0.33021515355774417, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0031435079174695433, "train/reward_loss_mean": 0.022394739536207114, "train/reward_loss_std": 0.2820776635919934, "train/reward_max_data": 0.8345771153174822, "train/reward_max_pred": 0.3533076089413012, "train/reward_neg_acc": 0.9994874931686554, "train/reward_neg_loss": 0.003917645884270024, "train/reward_pos_acc": 0.16861890456569728, "train/reward_pos_loss": 3.9907142143344405, "train/reward_pred": 0.002375584775095444, "train/reward_rate": 0.00461073538557214, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.013483568094670773, "report/cont_loss_std": 0.16831661760807037, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 1.8679656982421875, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0043840487487614155, "report/cont_pred": 0.9936281442642212, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06800106912851334, "report/image_loss_std": 0.08666503429412842, "report/model_loss_mean": 0.6974027752876282, "report/model_loss_std": 0.4245227575302124, "report/post_ent_mag": 35.53577423095703, "report/post_ent_max": 35.53577423095703, "report/post_ent_mean": 34.927001953125, "report/post_ent_min": 34.2898063659668, "report/post_ent_std": 0.26562759280204773, "report/prior_ent_mag": 34.7368278503418, "report/prior_ent_max": 34.7368278503418, "report/prior_ent_mean": 33.5290412902832, "report/prior_ent_min": 32.70185852050781, "report/prior_ent_std": 0.3419993221759796, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002648925641551614, "report/reward_loss_mean": 0.015918098390102386, "report/reward_loss_std": 0.22641658782958984, "report/reward_max_data": 0.8187500238418579, "report/reward_max_pred": 0.7051354646682739, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.00320299225859344, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.258270025253296, "report/reward_pred": 0.002340552629902959, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.030405312776565552, "eval/cont_loss_std": 0.3646591305732727, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.899585723876953, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.006513355765491724, "eval/cont_pred": 0.9942009449005127, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08915605396032333, "eval/image_loss_std": 0.1193200871348381, "eval/model_loss_mean": 0.745299220085144, "eval/model_loss_std": 0.7327806949615479, "eval/post_ent_mag": 35.52174758911133, "eval/post_ent_max": 35.52174758911133, "eval/post_ent_mean": 34.971275329589844, "eval/post_ent_min": 34.201995849609375, "eval/post_ent_std": 0.2549065053462982, "eval/prior_ent_mag": 34.7368278503418, "eval/prior_ent_max": 34.7368278503418, "eval/prior_ent_mean": 33.56824493408203, "eval/prior_ent_min": 32.64803695678711, "eval/prior_ent_std": 0.34344980120658875, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0029663085006177425, "eval/reward_loss_mean": 0.025737840682268143, "eval/reward_loss_std": 0.3723827600479126, "eval/reward_max_data": 0.887499988079071, "eval/reward_max_pred": 0.08429384231567383, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.0037679278757423162, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.628066062927246, "eval/reward_pred": 0.0018954642582684755, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32128.0, "replay/samples": 32128.0, "replay/insert_wait_avg": 1.2418500099524085e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.667938670314166e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6632.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1318052059491091e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3623859882355, "timer/env.step_count": 4016.0, "timer/env.step_total": 39.20520210266113, "timer/env.step_frac": 0.03919099983345655, "timer/env.step_avg": 0.009762251519586936, "timer/env.step_min": 0.0077970027923583984, "timer/env.step_max": 0.055605173110961914, "timer/replay._sample_count": 32128.0, "timer/replay._sample_total": 16.21807336807251, "timer/replay._sample_frac": 0.016212198294572062, "timer/replay._sample_avg": 0.0005047956103110218, "timer/replay._sample_min": 0.00037860870361328125, "timer/replay._sample_max": 0.011277914047241211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4845.0, "timer/agent.policy_total": 51.359219789505005, "timer/agent.policy_frac": 0.05134061467012116, "timer/agent.policy_avg": 0.010600458160888546, "timer/agent.policy_min": 0.009023427963256836, "timer/agent.policy_max": 0.08884310722351074, "timer/dataset_train_count": 2008.0, "timer/dataset_train_total": 0.22022700309753418, "timer/dataset_train_frac": 0.0002201472248279076, "timer/dataset_train_avg": 0.00010967480233940945, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0004246234893798828, "timer/agent.train_count": 2008.0, "timer/agent.train_total": 895.4578702449799, "timer/agent.train_frac": 0.8951334864119038, "timer/agent.train_avg": 0.44594515450447203, "timer/agent.train_min": 0.43438720703125, "timer/agent.train_max": 0.7516477108001709, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4744725227355957, "timer/agent.report_frac": 0.0004743006428284236, "timer/agent.report_avg": 0.23723626136779785, "timer/agent.report_min": 0.22895407676696777, "timer/agent.report_max": 0.24551844596862793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.0744855199366984e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 32.11576404569086}
{"step": 1550600, "time": 48276.067509651184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1550600, "time": 48276.442910432816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1550920, "time": 48286.15794301033, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1550984, "time": 48288.09291911125, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1551072, "time": 48291.101189136505, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1551360, "time": 48299.898403167725, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1551552, "time": 48305.716995716095, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1551624, "time": 48307.67051935196, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1551640, "time": 48308.17652606964, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1551776, "time": 48312.505669116974, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1551920, "time": 48316.88174724579, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1551976, "time": 48318.3760304451, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1552144, "time": 48323.77834939957, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1552216, "time": 48325.73927474022, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1552440, "time": 48332.52851486206, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1552536, "time": 48335.45244693756, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1553032, "time": 48350.726174116135, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1553168, "time": 48355.11664390564, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1553232, "time": 48357.09852933884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1553440, "time": 48363.48799753189, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1553480, "time": 48364.51656460762, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1553672, "time": 48370.38867473602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1553952, "time": 48379.18266439438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1554080, "time": 48383.1993227005, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1554136, "time": 48384.68120384216, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1554200, "time": 48386.64073801041, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1554256, "time": 48388.55738377571, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1554336, "time": 48390.97908902168, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1554528, "time": 48396.8379714489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1554824, "time": 48405.61434650421, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1555264, "time": 48419.39130759239, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1555304, "time": 48420.40336203575, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1555552, "time": 48428.18775033951, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1555712, "time": 48433.04351258278, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1555744, "time": 48434.02464056015, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1555872, "time": 48437.94107794762, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1556208, "time": 48448.27902460098, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1556392, "time": 48453.62876582146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1556512, "time": 48458.01016616821, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1556528, "time": 48458.5009765625, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1556568, "time": 48459.496039152145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1556848, "time": 48468.259635448456, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1556944, "time": 48471.33194184303, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1557152, "time": 48477.716259241104, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1557384, "time": 48484.59297251701, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1557448, "time": 48486.57214188576, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1557496, "time": 48488.03635787964, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1557576, "time": 48490.49562382698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1557640, "time": 48492.454880476, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1557656, "time": 48492.94927215576, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1557968, "time": 48502.784801244736, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1558088, "time": 48506.21792840958, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1558224, "time": 48510.584814310074, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1558272, "time": 48512.054918050766, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1558368, "time": 48514.97520375252, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1558464, "time": 48517.88803792, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1558472, "time": 48517.915675640106, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1558512, "time": 48519.37498855591, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1558544, "time": 48520.35701560974, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1558840, "time": 48529.163942337036, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1559160, "time": 48538.97871541977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1559240, "time": 48541.40964102745, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1559528, "time": 48550.20340466499, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1559720, "time": 48556.074634075165, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1559808, "time": 48559.024242162704, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1559872, "time": 48561.10587763786, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1559992, "time": 48564.553357601166, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1560000, "time": 48566.16864871979, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1560000, "time": 48566.41125059128, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1560000, "time": 48566.65345907211, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1560000, "time": 48567.1260573864, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1560000, "time": 48567.37196087837, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1560000, "time": 48567.831599235535, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1560000, "time": 48568.25465965271, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 1560000, "time": 48568.84665060043, "eval_episode/length": 189.0, "eval_episode/score": 0.40937501192092896, "eval_episode/reward_rate": 0.005263157894736842}
{"step": 1560064, "time": 48570.81173491478, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 1560136, "time": 48572.82992911339, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 1560232, "time": 48575.783200740814, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1560504, "time": 48584.06173110008, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1560544, "time": 48585.50123119354, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1560672, "time": 48589.39587640762, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1560728, "time": 48590.93347597122, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1560824, "time": 48593.85617303848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1560920, "time": 48596.776664972305, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1560960, "time": 48598.21690440178, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1561040, "time": 48600.6474442482, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1561448, "time": 48612.851944208145, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1561480, "time": 48613.848105192184, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1561848, "time": 48625.15922689438, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1561848, "time": 48625.167365312576, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1562048, "time": 48631.50823330879, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1562256, "time": 48637.880650520325, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1562256, "time": 48637.889756679535, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1562640, "time": 48649.59604907036, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 1562712, "time": 48651.68323636055, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1563248, "time": 48668.193247795105, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1563272, "time": 48668.70564341545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1563496, "time": 48675.52923941612, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1563760, "time": 48683.833337306976, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1563760, "time": 48683.84177684784, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1564000, "time": 48691.1426987648, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 1564016, "time": 48691.63296198845, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1564208, "time": 48697.45114803314, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1564440, "time": 48704.25305199623, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1564528, "time": 48707.121748924255, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1564568, "time": 48708.11802196503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1564720, "time": 48713.54590034485, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1564792, "time": 48715.516899347305, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1564984, "time": 48721.36410474777, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1565232, "time": 48729.24730491638, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1565256, "time": 48729.760957956314, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1565304, "time": 48731.23773312569, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1565720, "time": 48744.1211707592, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1565736, "time": 48744.6163983345, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1565904, "time": 48750.01100945473, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1565976, "time": 48751.96950960159, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1566088, "time": 48755.38620996475, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1566168, "time": 48757.826595783234, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1566368, "time": 48764.186014175415, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1566464, "time": 48767.109233140945, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1566576, "time": 48770.63483309746, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1567208, "time": 48789.63917541504, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1567224, "time": 48790.1279695034, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1567240, "time": 48790.6203186512, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1567568, "time": 48800.899465084076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1567616, "time": 48802.356208086014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1567688, "time": 48804.33847117424, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1567792, "time": 48807.71976304054, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1568008, "time": 48814.04200530052, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1568104, "time": 48816.93832373619, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1568144, "time": 48818.390793561935, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1568400, "time": 48826.163112163544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1568480, "time": 48828.601157426834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1568960, "time": 48843.306966781616, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1568984, "time": 48843.82111573219, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1568992, "time": 48844.29439210892, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1568992, "time": 48844.30333662033, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1569232, "time": 48851.6292860508, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1569232, "time": 48851.63835644722, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 1569352, "time": 48855.08508181572, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1569400, "time": 48856.61277341843, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1569488, "time": 48859.50878548622, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1569504, "time": 48860.00172972679, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1569816, "time": 48869.44815945625, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1569880, "time": 48871.43609023094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1569992, "time": 48874.874059438705, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1570048, "time": 48876.825976610184, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1570088, "time": 48879.35219216347, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1570088, "time": 48879.58306646347, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1570088, "time": 48879.68634772301, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1570088, "time": 48880.112778902054, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1570088, "time": 48880.3894507885, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1570088, "time": 48881.28967785835, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 1570088, "time": 48882.08188581467, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1570088, "time": 48882.1066133976, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1570192, "time": 48885.497718811035, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1570536, "time": 48895.78547644615, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1570608, "time": 48898.18302464485, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1570680, "time": 48900.15706896782, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1570848, "time": 48905.48607778549, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1570944, "time": 48908.40570354462, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1571120, "time": 48913.76666688919, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1571128, "time": 48913.79539847374, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1571304, "time": 48919.14368438721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1571768, "time": 48933.349102020264, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1571800, "time": 48934.34471011162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1571952, "time": 48939.17991232872, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1571960, "time": 48939.20897769928, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1572024, "time": 48941.16979122162, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1572360, "time": 48951.47289991379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1572560, "time": 48957.77083277702, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 1572576, "time": 48958.26023554802, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1572872, "time": 48967.21743106842, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1573256, "time": 48979.13997006416, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1573424, "time": 48984.5197327137, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1573456, "time": 48985.48341679573, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1573472, "time": 48985.96845674515, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1573776, "time": 48995.25585460663, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1573816, "time": 48996.25567126274, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 1574056, "time": 49003.595338106155, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1574080, "time": 49004.55125761032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1574112, "time": 49005.52582406998, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1574264, "time": 49009.93276524544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1574296, "time": 49011.01850318909, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1574464, "time": 49016.323835372925, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1574512, "time": 49017.79436159134, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1574552, "time": 49018.789855241776, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1574576, "time": 49019.74269032478, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1574888, "time": 49029.02398610115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1575048, "time": 49033.90079522133, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1575136, "time": 49036.77507519722, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1575192, "time": 49038.27312231064, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1575472, "time": 49047.096980810165, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1575544, "time": 49049.0635163784, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1575632, "time": 49051.96753311157, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1575736, "time": 49054.89506173134, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1575808, "time": 49057.32018947601, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1575920, "time": 49060.73854446411, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1576144, "time": 49067.53992772102, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1576544, "time": 49079.82554483414, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1576656, "time": 49083.24213933945, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1576776, "time": 49086.66675519943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1576784, "time": 49087.138088941574, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1576920, "time": 49091.06946969032, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1576960, "time": 49092.51583433151, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1577360, "time": 49104.78217673302, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1577464, "time": 49107.74136042595, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1577784, "time": 49117.50600671768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1578040, "time": 49125.32092380524, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1578048, "time": 49125.788080215454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1578080, "time": 49126.764214515686, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1578088, "time": 49126.79135918617, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 1578152, "time": 49128.73082232475, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1578784, "time": 49148.25000166893, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1578872, "time": 49150.71428179741, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1579024, "time": 49155.56006169319, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1579272, "time": 49162.95876288414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1580048, "time": 49186.67645096779, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1580072, "time": 49187.18813538551, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 1580072, "time": 49188.668737888336, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1580072, "time": 49189.19606280327, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1580072, "time": 49189.97396707535, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1580072, "time": 49190.73259329796, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1580072, "time": 49190.88635468483, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1580072, "time": 49192.21382331848, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1580072, "time": 49193.497519254684, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1580072, "time": 49193.50546312332, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1580072, "time": 49193.514379024506, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1580072, "time": 49193.52164888382, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1580072, "time": 49193.528891325, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1580160, "time": 49196.41903972626, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1580328, "time": 49201.28712153435, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1580352, "time": 49202.23610949516, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1580360, "time": 49202.26408576965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1580368, "time": 49202.72940540314, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1580400, "time": 49203.695412158966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1580608, "time": 49209.998379945755, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1580744, "time": 49213.903777599335, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1580984, "time": 49221.31260704994, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1581040, "time": 49223.237092256546, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1581184, "time": 49228.11055088043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1581192, "time": 49228.13810992241, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1581744, "time": 49245.19160199165, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1581808, "time": 49247.15159320831, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1582296, "time": 49261.897788763046, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1582384, "time": 49264.83456301689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1582464, "time": 49267.265604019165, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1582672, "time": 49273.59405088425, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1582729, "time": 49276.25919866562, "train_stats/mean_log_entropy": 0.0813621016075978, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4102224473336444, "train/action_min": 0.0, "train/action_std": 1.6969626424324453, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012468630969246377, "train/actor_opt_grad_steps": 97820.0, "train/actor_opt_loss": -31.005794126596022, "train/adv_mag": 0.6653298969885603, "train/adv_max": 0.2660950677311836, "train/adv_mean": 0.0003774498507310405, "train/adv_min": -0.6089178652905706, "train/adv_std": 0.029755308955388877, "train/cont_avg": 0.9938053871268657, "train/cont_loss_mean": 0.02575298395258055, "train/cont_loss_std": 0.2819433498441877, "train/cont_neg_acc": 0.1437001527838446, "train/cont_neg_loss": 3.2444174279370785, "train/cont_pos_acc": 0.9998728766370175, "train/cont_pos_loss": 0.0055706903317581805, "train/cont_pred": 0.9936550096492862, "train/cont_rate": 0.9938053871268657, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11551921812826721, "train/extr_critic_critic_opt_grad_steps": 97820.0, "train/extr_critic_critic_opt_loss": 11700.13424090485, "train/extr_critic_mag": 1.5998070856825035, "train/extr_critic_max": 1.5998070856825035, "train/extr_critic_mean": 1.4528216431983074, "train/extr_critic_min": 1.2363307339635061, "train/extr_critic_std": 0.03100994557364663, "train/extr_return_normed_mag": 0.6778150856198363, "train/extr_return_normed_max": 0.30445504010613283, "train/extr_return_normed_mean": 0.06314478970285672, "train/extr_return_normed_min": -0.5399130642117552, "train/extr_return_normed_std": 0.043838542918512476, "train/extr_return_rate": 0.9997308583401922, "train/extr_return_raw_mag": 1.694509143853069, "train/extr_return_raw_max": 1.694509143853069, "train/extr_return_raw_mean": 1.4531989755915171, "train/extr_return_raw_min": 0.8501410395351808, "train/extr_return_raw_std": 0.04383854285364424, "train/extr_reward_mag": 0.2867937586200771, "train/extr_reward_max": 0.2867937586200771, "train/extr_reward_mean": 0.0025860124229411803, "train/extr_reward_min": 1.927513388258901e-07, "train/extr_reward_std": 0.010430714507026607, "train/image_loss_mean": 0.07509706035923602, "train/image_loss_std": 0.09684412983890196, "train/model_loss_mean": 0.7225109424757127, "train/model_loss_std": 0.5472894382862309, "train/model_opt_grad_norm": 14.88932204839602, "train/model_opt_grad_steps": 97727.39800995025, "train/model_opt_loss": 3936.124321021844, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5447.761194029851, "train/policy_entropy_mag": 1.1687925612155479, "train/policy_entropy_max": 1.1687925612155479, "train/policy_entropy_mean": 0.08827515469113392, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10320822082793535, "train/policy_logprob_mag": 6.55108026485538, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08800551295280457, "train/policy_logprob_min": -6.55108026485538, "train/policy_logprob_std": 0.6245173109111501, "train/policy_randomness_mag": 0.6006405964419617, "train/policy_randomness_max": 0.6006405964419617, "train/policy_randomness_mean": 0.04536446072717211, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05303853700187669, "train/post_ent_mag": 35.33651494268161, "train/post_ent_max": 35.33651494268161, "train/post_ent_mean": 34.76180496974964, "train/post_ent_min": 34.11489957363451, "train/post_ent_std": 0.25001488299808694, "train/prior_ent_mag": 34.844621231306846, "train/prior_ent_max": 34.844621231306846, "train/prior_ent_mean": 33.53036237118849, "train/prior_ent_min": 32.669675494900986, "train/prior_ent_std": 0.3428533001622157, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0030669406834243802, "train/reward_loss_mean": 0.021660872236987698, "train/reward_loss_std": 0.2719148411299681, "train/reward_max_data": 0.8094527349246675, "train/reward_max_pred": 0.3495019348106574, "train/reward_neg_acc": 0.9994044600434564, "train/reward_neg_loss": 0.004031504751113591, "train/reward_pos_acc": 0.18141334330794787, "train/reward_pos_loss": 3.9210907037209983, "train/reward_pred": 0.002447952939758068, "train/reward_rate": 0.004508706467661692, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.023172840476036072, "report/cont_loss_std": 0.31789782643318176, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 3.8527629375457764, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004381914623081684, "report/cont_pred": 0.9948452115058899, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06740286946296692, "report/image_loss_std": 0.09867846220731735, "report/model_loss_mean": 0.7104882597923279, "report/model_loss_std": 0.5877333283424377, "report/post_ent_mag": 35.8101806640625, "report/post_ent_max": 35.8101806640625, "report/post_ent_mean": 35.242820739746094, "report/post_ent_min": 34.64130783081055, "report/post_ent_std": 0.21434637904167175, "report/prior_ent_mag": 34.83531188964844, "report/prior_ent_max": 34.83531188964844, "report/prior_ent_mean": 33.536109924316406, "report/prior_ent_min": 32.714942932128906, "report/prior_ent_std": 0.319518119096756, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023345947265625, "report/reward_loss_mean": 0.01991249993443489, "report/reward_loss_std": 0.2951984405517578, "report/reward_max_data": 0.784375011920929, "report/reward_max_pred": 0.5867360830307007, "report/reward_neg_acc": 0.9990195631980896, "report/reward_neg_loss": 0.0035193462390452623, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 4.200166702270508, "report/reward_pred": 0.0023386278189718723, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.022771432995796204, "eval/cont_loss_std": 0.3253031075000763, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.682306289672852, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004498748108744621, "eval/cont_pred": 0.9955750703811646, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09765677899122238, "eval/image_loss_std": 0.11110712587833405, "eval/model_loss_mean": 0.746428370475769, "eval/model_loss_std": 0.7475869655609131, "eval/post_ent_mag": 35.80030059814453, "eval/post_ent_max": 35.80030059814453, "eval/post_ent_mean": 35.25962829589844, "eval/post_ent_min": 34.70121765136719, "eval/post_ent_std": 0.2400992214679718, "eval/prior_ent_mag": 34.83531188964844, "eval/prior_ent_max": 34.83531188964844, "eval/prior_ent_mean": 33.55581283569336, "eval/prior_ent_min": 32.6503791809082, "eval/prior_ent_std": 0.34681209921836853, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0025756836403161287, "eval/reward_loss_mean": 0.02600017376244068, "eval/reward_loss_std": 0.39381101727485657, "eval/reward_max_data": 0.8656250238418579, "eval/reward_max_pred": 0.22049963474273682, "eval/reward_neg_acc": 0.9990195631980896, "eval/reward_neg_loss": 0.003253732807934284, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.826342582702637, "eval/reward_pred": 0.0017211036756634712, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32144.0, "replay/samples": 32144.0, "replay/insert_wait_avg": 1.2253293829690525e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.552344624589129e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5552.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1273780542423128e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1224842071533, "timer/env.step_count": 4018.0, "timer/env.step_total": 39.22200870513916, "timer/env.step_frac": 0.0392172052168514, "timer/env.step_avg": 0.00976157508838705, "timer/env.step_min": 0.0077135562896728516, "timer/env.step_max": 0.0550382137298584, "timer/replay._sample_count": 32144.0, "timer/replay._sample_total": 16.287592887878418, "timer/replay._sample_frac": 0.01628559815929986, "timer/replay._sample_avg": 0.0005067070958150329, "timer/replay._sample_min": 0.0003802776336669922, "timer/replay._sample_max": 0.032422780990600586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4712.0, "timer/agent.policy_total": 50.33885622024536, "timer/agent.policy_frac": 0.05033269126046243, "timer/agent.policy_avg": 0.010683118892242225, "timer/agent.policy_min": 0.008182048797607422, "timer/agent.policy_max": 0.18193674087524414, "timer/dataset_train_count": 2009.0, "timer/dataset_train_total": 0.21925616264343262, "timer/dataset_train_frac": 0.0002192293105151494, "timer/dataset_train_avg": 0.00010913696497930941, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0010595321655273438, "timer/agent.train_count": 2009.0, "timer/agent.train_total": 896.9659621715546, "timer/agent.train_frac": 0.8968561114618115, "timer/agent.train_avg": 0.4464738487663288, "timer/agent.train_min": 0.436861515045166, "timer/agent.train_max": 0.702124834060669, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4783813953399658, "timer/agent.report_frac": 0.00047832280835002173, "timer/agent.report_avg": 0.2391906976699829, "timer/agent.report_min": 0.23216605186462402, "timer/agent.report_max": 0.2462153434753418, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.932189376058269e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 32.13949743257716}
{"step": 1582920, "time": 49281.84739279747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1582984, "time": 49283.79600429535, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1583056, "time": 49286.2160513401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1583296, "time": 49293.49269914627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1583352, "time": 49294.995092868805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1583496, "time": 49299.376034498215, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1583504, "time": 49299.84656000137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1583544, "time": 49300.84079170227, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1583584, "time": 49302.29073166847, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1583776, "time": 49308.12806606293, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1583848, "time": 49310.1015355587, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1583856, "time": 49310.6390247345, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1584104, "time": 49317.93704390526, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1584384, "time": 49326.67366862297, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1584416, "time": 49327.64741563797, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1584680, "time": 49335.43672156334, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1584696, "time": 49335.92661690712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1584760, "time": 49337.88068461418, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1584928, "time": 49343.28333044052, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1585016, "time": 49345.73203778267, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1585032, "time": 49346.220871686935, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1585144, "time": 49349.627393484116, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1585224, "time": 49352.04511618614, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1585512, "time": 49360.823093891144, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1585704, "time": 49366.7120051384, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1585752, "time": 49368.21044254303, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1585784, "time": 49369.19028353691, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1585896, "time": 49372.71698617935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1586128, "time": 49379.97441148758, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1586152, "time": 49380.482958078384, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1586160, "time": 49380.9490749836, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1586432, "time": 49389.234788656235, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1586504, "time": 49391.19715547562, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1586512, "time": 49391.688600063324, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1586664, "time": 49396.08207798004, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1587240, "time": 49413.69938850403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1587336, "time": 49416.61378645897, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1587360, "time": 49417.57051515579, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1587584, "time": 49424.38065814972, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1587680, "time": 49427.301971912384, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1587752, "time": 49429.2616417408, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1587888, "time": 49433.6852850914, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1588016, "time": 49437.57739567757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1588216, "time": 49443.4360499382, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1588384, "time": 49448.73202729225, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1588440, "time": 49450.218633413315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1588616, "time": 49455.56099534035, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1588840, "time": 49462.43601703644, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1588848, "time": 49462.90688562393, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1589152, "time": 49472.166247844696, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1589200, "time": 49473.6235666275, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1589312, "time": 49477.52874994278, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1589400, "time": 49479.991315603256, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1589408, "time": 49480.46146225929, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1589432, "time": 49480.97724318504, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1589640, "time": 49487.32379961014, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1589896, "time": 49495.28575468063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1589992, "time": 49498.21412587166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1590024, "time": 49499.19183635712, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1590056, "time": 49500.98183917999, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1590056, "time": 49501.04590129852, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1590056, "time": 49501.43651556969, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1590056, "time": 49501.52541422844, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1590056, "time": 49501.7937579155, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1590056, "time": 49502.070296764374, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1590056, "time": 49502.8952589035, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1590056, "time": 49503.16947507858, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 1590424, "time": 49514.388904094696, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1590728, "time": 49523.72522878647, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1590792, "time": 49525.661861658096, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1591072, "time": 49534.40003538132, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1591096, "time": 49534.90600895882, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1591176, "time": 49537.3315179348, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1591192, "time": 49537.81679201126, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1591464, "time": 49546.02398085594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1591592, "time": 49549.92333984375, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1591712, "time": 49553.89996743202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1591808, "time": 49556.839700222015, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1591944, "time": 49560.74158835411, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1592016, "time": 49563.15694665909, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1592080, "time": 49565.107832193375, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1592104, "time": 49565.61940574646, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1592288, "time": 49571.43082141876, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1592304, "time": 49571.92653799057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1592384, "time": 49574.35004901886, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1592416, "time": 49575.31458592415, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1592480, "time": 49577.26538538933, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1592608, "time": 49581.24565792084, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 1592680, "time": 49583.20421886444, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1592864, "time": 49589.02758169174, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1592976, "time": 49592.427148103714, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1593072, "time": 49595.35570478439, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1593136, "time": 49597.29084897041, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1593320, "time": 49602.642709732056, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1593352, "time": 49603.61591720581, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1593488, "time": 49607.97985744476, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1593784, "time": 49616.922182798386, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1594008, "time": 49623.69758105278, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1594064, "time": 49625.66193151474, "episode/length": 6.0, "episode/score": 0.981249988079071, "episode/reward_rate": 0.14285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1594280, "time": 49631.99029922485, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1594312, "time": 49632.96397614479, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1594504, "time": 49638.81098818779, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1594504, "time": 49638.83250236511, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1594712, "time": 49645.23499107361, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 1594800, "time": 49648.132885694504, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1594888, "time": 49650.626775979996, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1594904, "time": 49651.12492823601, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1595144, "time": 49658.521792173386, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1595392, "time": 49666.28058862686, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1595448, "time": 49667.75667691231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1595576, "time": 49671.78234887123, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1595816, "time": 49679.15147995949, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1595904, "time": 49682.08683514595, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1596024, "time": 49685.55660009384, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1596096, "time": 49687.963782548904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1596104, "time": 49687.99144268036, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1596136, "time": 49688.9796230793, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 1596608, "time": 49703.69648337364, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1596640, "time": 49704.67196846008, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1596744, "time": 49707.62043905258, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1596760, "time": 49708.14247107506, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1596792, "time": 49709.12424993515, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1596960, "time": 49714.43836951256, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1597224, "time": 49722.18990254402, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1597424, "time": 49728.50798082352, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1597456, "time": 49729.95406150818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1597712, "time": 49737.9217543602, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1597720, "time": 49737.94936084747, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 1597816, "time": 49740.88215351105, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1597944, "time": 49744.817915678024, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1598280, "time": 49755.09203147888, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1598384, "time": 49758.49372577667, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1598544, "time": 49763.522738695145, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1598560, "time": 49764.012597322464, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1598696, "time": 49767.91909837723, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1598912, "time": 49774.72244596481, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1598936, "time": 49775.24368286133, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1599056, "time": 49779.16857671738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1599104, "time": 49780.63915371895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1599152, "time": 49782.1218252182, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1599208, "time": 49783.60953807831, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1599304, "time": 49786.51880002022, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1599328, "time": 49787.48333120346, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1599432, "time": 49790.527029275894, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1599496, "time": 49792.49247789383, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1599584, "time": 49795.37704014778, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1599912, "time": 49805.117515563965, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1600032, "time": 49808.99627041817, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1600040, "time": 49809.3127925396, "eval_episode/length": 14.0, "eval_episode/score": 0.956250011920929, "eval_episode/reward_rate": 0.06666666666666667}
{"step": 1600040, "time": 49810.31331849098, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1600040, "time": 49810.51286029816, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1600040, "time": 49811.448063373566, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1600040, "time": 49811.91919088364, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1600040, "time": 49812.68902683258, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 1600040, "time": 49812.993966817856, "eval_episode/length": 205.0, "eval_episode/score": 0.359375, "eval_episode/reward_rate": 0.0048543689320388345}
{"step": 1600040, "time": 49813.20920372009, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 1600104, "time": 49815.14228153229, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1600112, "time": 49815.629460811615, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1600320, "time": 49822.07367396355, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1600440, "time": 49825.5041012764, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1600496, "time": 49827.42286109924, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1600496, "time": 49827.43196582794, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1600504, "time": 49827.46410560608, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1600696, "time": 49833.2839949131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1600752, "time": 49835.220910310745, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1600904, "time": 49839.60228347778, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1600944, "time": 49841.0515229702, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1601024, "time": 49843.474231004715, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1601096, "time": 49845.46522498131, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1601104, "time": 49845.93336892128, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1601520, "time": 49858.60916304588, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1601576, "time": 49860.11075472832, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1601808, "time": 49867.398535490036, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1601816, "time": 49867.42693018913, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1601880, "time": 49869.39650297165, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1602144, "time": 49877.67659187317, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1602248, "time": 49880.790689468384, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1602320, "time": 49883.20605611801, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1602344, "time": 49883.72459125519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1602512, "time": 49889.08895611763, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1602568, "time": 49890.57936835289, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1602592, "time": 49891.5307571888, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1602632, "time": 49892.53411102295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1602688, "time": 49894.46676325798, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1602712, "time": 49894.9760093689, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1602800, "time": 49897.863752126694, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1602848, "time": 49899.34945821762, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1603008, "time": 49904.24866294861, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1603008, "time": 49904.25875401497, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1603168, "time": 49909.142235040665, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1603408, "time": 49916.5140953064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1603536, "time": 49920.41002416611, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1603568, "time": 49921.37514615059, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1603696, "time": 49925.266780138016, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1603832, "time": 49929.1865735054, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1604392, "time": 49946.323095321655, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1604552, "time": 49951.19717359543, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1604632, "time": 49953.6422727108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1604824, "time": 49959.49782824516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1604840, "time": 49959.99129652977, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1605208, "time": 49971.25761914253, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1605232, "time": 49972.236686468124, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1605264, "time": 49973.20602226257, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1605320, "time": 49974.68092751503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1605352, "time": 49975.64683055878, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1605408, "time": 49977.57825613022, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1605792, "time": 49989.77783703804, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1605848, "time": 49991.26534199715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1605880, "time": 49992.27485394478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1605904, "time": 49993.232555150986, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1606112, "time": 49999.599241256714, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1606176, "time": 50001.63539195061, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1606352, "time": 50007.022288799286, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1606392, "time": 50008.02280449867, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1606760, "time": 50019.21183204651, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1607048, "time": 50027.9704144001, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1607096, "time": 50029.435970783234, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1607536, "time": 50043.13755297661, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1607544, "time": 50043.165390729904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1607632, "time": 50046.07348489761, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1607664, "time": 50047.04317307472, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1608008, "time": 50057.276933670044, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1608040, "time": 50058.24901127815, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1608160, "time": 50062.199885606766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1608192, "time": 50063.17093753815, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1608320, "time": 50067.11821722984, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1608488, "time": 50072.060311079025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1608848, "time": 50083.308080911636, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1609208, "time": 50094.07265305519, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1609240, "time": 50095.05941271782, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1609328, "time": 50097.92625761032, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 1609360, "time": 50098.89393949509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1609376, "time": 50099.38015604019, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1609408, "time": 50100.37027478218, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1609856, "time": 50113.96319961548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1609944, "time": 50116.47789359093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1609944, "time": 50116.487396240234, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1610024, "time": 50119.431935310364, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 1610024, "time": 50119.515644073486, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 1610024, "time": 50119.97288489342, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1610024, "time": 50120.33411383629, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1610024, "time": 50120.431329488754, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1610024, "time": 50120.9999768734, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1610024, "time": 50121.13484978676, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1610024, "time": 50121.49672317505, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 1610280, "time": 50129.397903203964, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1610320, "time": 50130.85879087448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1610344, "time": 50131.37602233887, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 1610512, "time": 50136.744597435, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1610808, "time": 50145.51213884354, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1610896, "time": 50148.420794487, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1610936, "time": 50149.42387127876, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1610984, "time": 50150.96740412712, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1611200, "time": 50157.77879214287, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1611200, "time": 50157.78757405281, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1611312, "time": 50161.231169462204, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1611392, "time": 50163.675946474075, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1611672, "time": 50171.96382856369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1611744, "time": 50174.35770893097, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1611744, "time": 50174.364590883255, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1611760, "time": 50174.85237836838, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1611864, "time": 50177.78604412079, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1612128, "time": 50186.10166597366, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1612136, "time": 50186.12895464897, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1612168, "time": 50187.09797382355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1612192, "time": 50188.05085396767, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1612368, "time": 50193.35857510567, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1612608, "time": 50200.636583805084, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1612680, "time": 50202.60248374939, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1612856, "time": 50207.93269777298, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1612984, "time": 50211.9090487957, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1613000, "time": 50212.40566301346, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1613472, "time": 50226.97666525841, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1613520, "time": 50228.42857503891, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1613616, "time": 50231.34195637703, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1613744, "time": 50235.25096940994, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1613760, "time": 50235.745401382446, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1614032, "time": 50244.51028871536, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1614056, "time": 50245.023336172104, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1614120, "time": 50246.95538687706, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1614128, "time": 50247.424121141434, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1614336, "time": 50253.70540833473, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1614624, "time": 50262.51730513573, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1614680, "time": 50264.02260136604, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1614816, "time": 50268.37584543228, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1614848, "time": 50269.37638545036, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1614992, "time": 50273.86688399315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1615049, "time": 50276.396214962006, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3253119440362005, "train/action_min": 0.0, "train/action_std": 1.6604316635887222, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009941610307109976, "train/actor_opt_grad_steps": 99835.0, "train/actor_opt_loss": -27.840075365387566, "train/adv_mag": 0.6700428573801966, "train/adv_max": 0.2632705634183223, "train/adv_mean": 0.0005241315412986454, "train/adv_min": -0.6065718062443308, "train/adv_std": 0.027886624263581072, "train/cont_avg": 0.9934444616336634, "train/cont_loss_mean": 0.02748983517510466, "train/cont_loss_std": 0.2962689187267039, "train/cont_neg_acc": 0.11531581973085309, "train/cont_neg_loss": 3.3563125440389805, "train/cont_pos_acc": 0.9998296649739293, "train/cont_pos_loss": 0.005785690121454104, "train/cont_pred": 0.9935073380423064, "train/cont_rate": 0.9934444616336634, "train/dyn_loss_mean": 1.0000007211571873, "train/dyn_loss_std": 2.3071285300325638e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10182423786361619, "train/extr_critic_critic_opt_grad_steps": 99835.0, "train/extr_critic_critic_opt_loss": 10458.60509166151, "train/extr_critic_mag": 1.612819826248849, "train/extr_critic_max": 1.612819826248849, "train/extr_critic_mean": 1.4782294383143435, "train/extr_critic_min": 1.251246978150736, "train/extr_critic_std": 0.02786528980267225, "train/extr_return_normed_mag": 0.6861193286310329, "train/extr_return_normed_max": 0.28693808659468545, "train/extr_return_normed_mean": 0.05731026935252813, "train/extr_return_normed_min": -0.5490331124551225, "train/extr_return_normed_std": 0.04039920610145177, "train/extr_return_rate": 0.9997073739472002, "train/extr_return_raw_mag": 1.7083812733687977, "train/extr_return_raw_max": 1.7083812733687977, "train/extr_return_raw_mean": 1.4787535213007785, "train/extr_return_raw_min": 0.8724100743189896, "train/extr_return_raw_std": 0.0403992060000206, "train/extr_reward_mag": 0.2445765243898524, "train/extr_reward_max": 0.2445765243898524, "train/extr_reward_mean": 0.0025017600158450774, "train/extr_reward_min": 8.43907346819887e-08, "train/extr_reward_std": 0.009075606101201755, "train/image_loss_mean": 0.07765049730787182, "train/image_loss_std": 0.0995976224467896, "train/model_loss_mean": 0.7280961640990606, "train/model_loss_std": 0.5692417174577713, "train/model_opt_grad_norm": 14.81888490620226, "train/model_opt_grad_steps": 99740.49504950496, "train/model_opt_loss": 3856.8001938621596, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5297.029702970297, "train/policy_entropy_mag": 1.174450293921008, "train/policy_entropy_max": 1.174450293921008, "train/policy_entropy_mean": 0.08642798510961014, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09910352413754651, "train/policy_logprob_mag": 6.551080271749213, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08666043311800106, "train/policy_logprob_min": -6.551080271749213, "train/policy_logprob_std": 0.6250051985872854, "train/policy_randomness_mag": 0.6035480944827052, "train/policy_randomness_max": 0.6035480944827052, "train/policy_randomness_mean": 0.04441520328273867, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05092913985694989, "train/post_ent_mag": 35.444559626059956, "train/post_ent_max": 35.444559626059956, "train/post_ent_mean": 34.91541987126416, "train/post_ent_min": 34.31025299223343, "train/post_ent_std": 0.23290397071897392, "train/prior_ent_mag": 35.01084998102471, "train/prior_ent_max": 35.01084998102471, "train/prior_ent_mean": 33.80660640603245, "train/prior_ent_min": 32.88231866666586, "train/prior_ent_std": 0.35308134098454275, "train/rep_loss_mean": 1.0000007211571873, "train/rep_loss_std": 2.3071285300325638e-05, "train/reward_avg": 0.0032283518693034105, "train/reward_loss_mean": 0.022955375803072043, "train/reward_loss_std": 0.28095034977863775, "train/reward_max_data": 0.8247215355386829, "train/reward_max_pred": 0.34840919121657266, "train/reward_neg_acc": 0.99936376733355, "train/reward_neg_loss": 0.004234746330196389, "train/reward_pos_acc": 0.16043849475681782, "train/reward_pos_loss": 3.979964917898178, "train/reward_pred": 0.0025311919484785434, "train/reward_rate": 0.004766785272277228, "train_stats/mean_log_entropy": 0.07787141080648273, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.01946837082505226, "report/cont_loss_std": 0.21681202948093414, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.9613630771636963, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00503316568210721, "report/cont_pred": 0.9946213960647583, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.059451136738061905, "report/image_loss_std": 0.08477254956960678, "report/model_loss_mean": 0.7026007175445557, "report/model_loss_std": 0.5469816327095032, "report/post_ent_mag": 35.2790641784668, "report/post_ent_max": 35.2790641784668, "report/post_ent_mean": 34.77960968017578, "report/post_ent_min": 34.21051788330078, "report/post_ent_std": 0.2355148047208786, "report/prior_ent_mag": 35.86543655395508, "report/prior_ent_max": 35.86543655395508, "report/prior_ent_mean": 34.99122619628906, "report/prior_ent_min": 33.77439880371094, "report/prior_ent_std": 0.35072818398475647, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0034118653275072575, "report/reward_loss_mean": 0.02368125319480896, "report/reward_loss_std": 0.2997509241104126, "report/reward_max_data": 0.90625, "report/reward_max_pred": 0.21468138694763184, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.003649407299235463, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 4.106171607971191, "report/reward_pred": 0.0020656988490372896, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.030835788697004318, "eval/cont_loss_std": 0.38967740535736084, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.190762519836426, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005517208017408848, "eval/cont_pred": 0.994529664516449, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09560687094926834, "eval/image_loss_std": 0.117205411195755, "eval/model_loss_mean": 0.7651411294937134, "eval/model_loss_std": 0.936365008354187, "eval/post_ent_mag": 35.369140625, "eval/post_ent_max": 35.369140625, "eval/post_ent_mean": 34.85517120361328, "eval/post_ent_min": 34.146507263183594, "eval/post_ent_std": 0.2291819304227829, "eval/prior_ent_mag": 35.861846923828125, "eval/prior_ent_max": 35.861846923828125, "eval/prior_ent_mean": 35.03624725341797, "eval/prior_ent_min": 33.95562744140625, "eval/prior_ent_std": 0.34258314967155457, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.003408813616260886, "eval/reward_loss_mean": 0.03869849815964699, "eval/reward_loss_std": 0.5186417102813721, "eval/reward_max_data": 0.9156249761581421, "eval/reward_max_pred": 0.10204219818115234, "eval/reward_neg_acc": 0.999018669128418, "eval/reward_neg_loss": 0.0043543982319533825, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.038025856018066, "eval/reward_pred": 0.002200867049396038, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 32320.0, "replay/samples": 32320.0, "replay/insert_wait_avg": 1.2224337252059785e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.596420179499258e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1525193198782498e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2499272823334, "timer/env.step_count": 4040.0, "timer/env.step_total": 39.49625086784363, "timer/env.step_frac": 0.03948638214366528, "timer/env.step_avg": 0.009776299719763274, "timer/env.step_min": 0.0076787471771240234, "timer/env.step_max": 0.03691673278808594, "timer/replay._sample_count": 32320.0, "timer/replay._sample_total": 16.42107605934143, "timer/replay._sample_frac": 0.016416973009892928, "timer/replay._sample_avg": 0.0005080778483707126, "timer/replay._sample_min": 0.00041675567626953125, "timer/replay._sample_max": 0.010263919830322266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4528.0, "timer/agent.policy_total": 47.977699279785156, "timer/agent.policy_frac": 0.047965711339904786, "timer/agent.policy_avg": 0.010595781643062093, "timer/agent.policy_min": 0.008674383163452148, "timer/agent.policy_max": 0.07524514198303223, "timer/dataset_train_count": 2020.0, "timer/dataset_train_total": 0.2188093662261963, "timer/dataset_train_frac": 0.0002187546934601621, "timer/dataset_train_avg": 0.00010832146842881005, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.000993967056274414, "timer/agent.train_count": 2020.0, "timer/agent.train_total": 901.5776278972626, "timer/agent.train_frac": 0.9013523553526644, "timer/agent.train_avg": 0.44632555836498145, "timer/agent.train_min": 0.43276238441467285, "timer/agent.train_max": 0.6623053550720215, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47609806060791016, "timer/agent.report_frac": 0.0004759791004448885, "timer/agent.report_avg": 0.23804903030395508, "timer/agent.report_min": 0.23227214813232422, "timer/agent.report_max": 0.24382591247558594, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098667086876434e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 32.31137918773387}
{"step": 1615072, "time": 50277.037051439285, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1615152, "time": 50279.57710003853, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1615280, "time": 50283.470651865005, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1615296, "time": 50283.96696519852, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1615584, "time": 50292.77708220482, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1615632, "time": 50294.26775074005, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1615816, "time": 50299.655797719955, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1616072, "time": 50307.537356853485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1616112, "time": 50309.007028102875, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1616496, "time": 50320.750381946564, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1616560, "time": 50322.710988759995, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1616616, "time": 50324.21925854683, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1616696, "time": 50326.68410253525, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1617000, "time": 50336.10107421875, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1617136, "time": 50340.46283578873, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1617312, "time": 50345.82716965675, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1617464, "time": 50350.249774456024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1617592, "time": 50354.195298433304, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1617592, "time": 50354.20340704918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1617712, "time": 50358.11760354042, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1617880, "time": 50363.10834646225, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1618032, "time": 50367.98182964325, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1618104, "time": 50369.962538957596, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1618144, "time": 50371.42197084427, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1618352, "time": 50377.84974837303, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1618584, "time": 50384.74860930443, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1618664, "time": 50387.20498466492, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1618920, "time": 50395.14690756798, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1618976, "time": 50397.088181972504, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1619008, "time": 50398.08491587639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1619072, "time": 50400.040477991104, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1619232, "time": 50404.93632721901, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1619352, "time": 50408.40034079552, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1619400, "time": 50409.86584496498, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1619568, "time": 50415.24526977539, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1619776, "time": 50421.65482521057, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1620008, "time": 50429.29768013954, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1620008, "time": 50429.557530879974, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1620008, "time": 50429.86784887314, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1620008, "time": 50429.876792669296, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1620008, "time": 50430.197395801544, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1620008, "time": 50430.684438705444, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1620008, "time": 50430.83968806267, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1620008, "time": 50430.90102982521, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1620184, "time": 50436.27105641365, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1620360, "time": 50441.63914394379, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1620416, "time": 50443.57987332344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1620528, "time": 50447.01435112953, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1620664, "time": 50451.11963558197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1620768, "time": 50454.51206636429, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1620784, "time": 50455.00372982025, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1620960, "time": 50460.39561486244, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1621664, "time": 50482.1502225399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1621712, "time": 50483.641986608505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1621728, "time": 50484.133722782135, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1621824, "time": 50487.057126522064, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1621960, "time": 50490.97830891609, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1621992, "time": 50491.955682992935, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1622408, "time": 50505.21544408798, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1622416, "time": 50505.68660020828, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1622480, "time": 50507.63413262367, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1622816, "time": 50517.92335295677, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1622856, "time": 50518.94140291214, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1622936, "time": 50521.35896348953, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1623064, "time": 50525.34037947655, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1623096, "time": 50526.32686328888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1623184, "time": 50529.25036239624, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1623272, "time": 50531.721416950226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1623488, "time": 50538.574098587036, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1623624, "time": 50542.5841486454, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1624304, "time": 50563.66680455208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1624456, "time": 50568.097714185715, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1624640, "time": 50574.06169080734, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1624792, "time": 50578.48242664337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1624800, "time": 50578.95369076729, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1625128, "time": 50588.76649975777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1625128, "time": 50588.78445649147, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1625376, "time": 50596.57226228714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1625504, "time": 50600.59213209152, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1625752, "time": 50607.96378850937, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1625800, "time": 50609.439969301224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1625936, "time": 50613.81787252426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1626216, "time": 50622.1752705574, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1626304, "time": 50625.099660634995, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1626328, "time": 50625.610983133316, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1626360, "time": 50626.6055996418, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 1626416, "time": 50628.56425452232, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1626528, "time": 50632.1395509243, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1626552, "time": 50632.654307603836, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1626608, "time": 50634.59062004089, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1626848, "time": 50641.96351480484, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1626856, "time": 50641.98992609978, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1626976, "time": 50645.870685338974, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1627024, "time": 50647.352734327316, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1627240, "time": 50653.74235415459, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1627528, "time": 50662.64135885239, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1627544, "time": 50663.13143110275, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1627688, "time": 50667.51970362663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1628128, "time": 50681.17401766777, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1628440, "time": 50690.64830851555, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1628512, "time": 50693.06197619438, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1628544, "time": 50694.041707754135, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1628728, "time": 50699.430720329285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1628800, "time": 50701.872420310974, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1629136, "time": 50712.12001180649, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1629288, "time": 50716.56938076019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1629344, "time": 50718.51128602028, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1629752, "time": 50730.96019124985, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1629856, "time": 50734.372776031494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1630024, "time": 50739.33001279831, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1630080, "time": 50741.314143419266, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1630096, "time": 50743.78691124916, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1630096, "time": 50744.110703229904, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1630096, "time": 50744.31412911415, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 1630096, "time": 50744.56063556671, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1630096, "time": 50744.93401861191, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1630096, "time": 50745.06210875511, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 1630096, "time": 50745.30664253235, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 1630096, "time": 50745.670843839645, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 1630104, "time": 50745.698713064194, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1630320, "time": 50753.23111796379, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1630600, "time": 50761.592832803726, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1630680, "time": 50764.05327916145, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1630840, "time": 50768.970044374466, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1630872, "time": 50769.964478969574, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1630880, "time": 50770.443417310715, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1630928, "time": 50771.92073345184, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1631040, "time": 50775.37731337547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1631112, "time": 50777.34892249107, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1631536, "time": 50790.59406018257, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1631560, "time": 50791.10320043564, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1631648, "time": 50794.01281261444, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1631656, "time": 50794.03979277611, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1631840, "time": 50799.87148022652, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1631848, "time": 50799.89884471893, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1632240, "time": 50812.24201965332, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1632240, "time": 50812.25124979019, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1632296, "time": 50813.76565670967, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1632328, "time": 50814.74155282974, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1632360, "time": 50815.72070121765, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1632664, "time": 50825.010535001755, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1632712, "time": 50826.48882198334, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1632728, "time": 50826.982050180435, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1633000, "time": 50835.296677351, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1633080, "time": 50837.76093387604, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1633216, "time": 50842.21413016319, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1633272, "time": 50843.72219967842, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1633504, "time": 50851.07087349892, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1633688, "time": 50856.51005887985, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1633736, "time": 50858.01896429062, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1633808, "time": 50860.45765399933, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1633816, "time": 50860.485614061356, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1633848, "time": 50861.498794317245, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1634168, "time": 50871.424333810806, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1634376, "time": 50877.821806669235, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1634640, "time": 50886.11689782143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1634760, "time": 50889.58138823509, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1634888, "time": 50893.535163640976, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1635144, "time": 50901.41907978058, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1635360, "time": 50908.24765777588, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1635472, "time": 50911.6689555645, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1635496, "time": 50912.18131685257, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1635704, "time": 50918.51627230644, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1635872, "time": 50923.883093595505, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 1636024, "time": 50928.303470134735, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1636032, "time": 50928.776555776596, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1636128, "time": 50931.80306982994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1636272, "time": 50936.218089818954, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1636312, "time": 50937.21430397034, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1636360, "time": 50938.67619585991, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1636368, "time": 50939.14955472946, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1636424, "time": 50940.63846683502, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1636576, "time": 50945.50724220276, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1636632, "time": 50947.027265787125, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1636680, "time": 50948.503870248795, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1636864, "time": 50954.33407640457, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1636880, "time": 50954.83354949951, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1636896, "time": 50955.332528829575, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1636984, "time": 50957.82499074936, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1637192, "time": 50964.25324463844, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1637200, "time": 50964.72832489014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1637256, "time": 50966.22864818573, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1637320, "time": 50968.189610004425, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1637416, "time": 50971.135182380676, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1637528, "time": 50974.55725765228, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1637800, "time": 50982.95174074173, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1637944, "time": 50987.364802122116, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1637992, "time": 50988.845381975174, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1637992, "time": 50988.85232257843, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1638152, "time": 50993.886910676956, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1638280, "time": 50997.80903196335, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1638288, "time": 50998.28521156311, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1638312, "time": 50998.804403066635, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 1638352, "time": 51000.271682024, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1638384, "time": 51001.2557220459, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1638408, "time": 51001.97534751892, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1638744, "time": 51012.570080280304, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1638888, "time": 51016.982159137726, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1638912, "time": 51017.94209122658, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1638920, "time": 51017.96840929985, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1639152, "time": 51025.40644907951, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1639296, "time": 51029.78458857536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1639544, "time": 51037.13568544388, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1639760, "time": 51043.95843076706, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1639784, "time": 51044.471620082855, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1639888, "time": 51047.87024998665, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1640080, "time": 51054.76466870308, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1640080, "time": 51055.617414951324, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1640080, "time": 51055.841908454895, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1640080, "time": 51055.97966694832, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1640080, "time": 51056.13410758972, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1640080, "time": 51056.35832810402, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1640080, "time": 51056.811121702194, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1640080, "time": 51057.09331154823, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1640112, "time": 51058.094820261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1640480, "time": 51069.330820798874, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1640512, "time": 51070.32255101204, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1640592, "time": 51072.83414030075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1640688, "time": 51075.8318939209, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1640720, "time": 51076.82183432579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1640840, "time": 51080.35145378113, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1640904, "time": 51082.3586564064, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1641048, "time": 51086.78672480583, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1641160, "time": 51090.229090452194, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1641464, "time": 51099.54374456406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1641608, "time": 51103.95165133476, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1641616, "time": 51104.42558026314, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1641640, "time": 51104.94102716446, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1641728, "time": 51107.858293533325, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1641736, "time": 51107.884340047836, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1641824, "time": 51110.88396000862, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1641968, "time": 51115.28736591339, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1642104, "time": 51119.225229263306, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1642192, "time": 51122.13743472099, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1642248, "time": 51123.619925022125, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1642392, "time": 51128.01573061943, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1642504, "time": 51131.442549705505, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1642592, "time": 51134.37719154358, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1642712, "time": 51137.84527540207, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1642728, "time": 51138.33744263649, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1642760, "time": 51139.323048353195, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1642840, "time": 51141.868509054184, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1642968, "time": 51145.758238554, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1643104, "time": 51150.195088624954, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1643216, "time": 51153.644214868546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1643576, "time": 51164.3965177536, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1643600, "time": 51165.35462260246, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1643880, "time": 51173.764548778534, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1644120, "time": 51181.11957907677, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1644208, "time": 51184.015226364136, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1644456, "time": 51191.35723543167, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1644728, "time": 51199.634135723114, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1644736, "time": 51200.10454273224, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1644904, "time": 51205.11056518555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1645040, "time": 51209.48060488701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1645048, "time": 51209.50836062431, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1645280, "time": 51216.79874277115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1645528, "time": 51224.245210886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1645616, "time": 51227.18285822868, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1646136, "time": 51243.05836439133, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1646584, "time": 51256.82635474205, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1646720, "time": 51261.85433983803, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1646768, "time": 51263.31749391556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1646800, "time": 51264.29782676697, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1647040, "time": 51271.64163303375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1647177, "time": 51276.72842359543, "train_stats/mean_log_entropy": 0.07474716253485918, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3292992435284514, "train/action_min": 0.0, "train/action_std": 1.6646856953255573, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010799133107622169, "train/actor_opt_grad_steps": 101850.0, "train/actor_opt_loss": -31.653089855440815, "train/adv_mag": 0.7086065811897392, "train/adv_max": 0.30652575172595126, "train/adv_mean": 0.0019886539625963563, "train/adv_min": -0.6496870737170699, "train/adv_std": 0.030539368700921832, "train/cont_avg": 0.9935138759328358, "train/cont_loss_mean": 0.027008578375871502, "train/cont_loss_std": 0.2910445910410501, "train/cont_neg_acc": 0.13881835678768395, "train/cont_neg_loss": 3.287379982163064, "train/cont_pos_acc": 0.9998777956511844, "train/cont_pos_loss": 0.005876401501860636, "train/cont_pred": 0.9933018592459646, "train/cont_rate": 0.9935138759328358, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10124987517645703, "train/extr_critic_critic_opt_grad_steps": 101850.0, "train/extr_critic_critic_opt_loss": 9820.970848880597, "train/extr_critic_mag": 1.6370204930281758, "train/extr_critic_max": 1.6370204930281758, "train/extr_critic_mean": 1.4869715005011108, "train/extr_critic_min": 1.2216565484431252, "train/extr_critic_std": 0.03194664781032806, "train/extr_return_normed_mag": 0.7515513917699975, "train/extr_return_normed_max": 0.33849372377443077, "train/extr_return_normed_mean": 0.06961553054514216, "train/extr_return_normed_min": -0.6030764855555634, "train/extr_return_normed_std": 0.045178124050966544, "train/extr_return_rate": 0.9997331265786394, "train/extr_return_raw_mag": 1.757838304956161, "train/extr_return_raw_max": 1.757838304956161, "train/extr_return_raw_mean": 1.4889601872335025, "train/extr_return_raw_min": 0.8162680956261668, "train/extr_return_raw_std": 0.045178123865628715, "train/extr_reward_mag": 0.27723368068239584, "train/extr_reward_max": 0.27723368068239584, "train/extr_reward_mean": 0.002642486864163434, "train/extr_reward_min": 3.5584862552472014e-09, "train/extr_reward_std": 0.009902322678757248, "train/image_loss_mean": 0.07707024254460833, "train/image_loss_std": 0.09857355795837754, "train/model_loss_mean": 0.7267183673322497, "train/model_loss_std": 0.563554972410202, "train/model_opt_grad_norm": 14.290853748321533, "train/model_opt_grad_steps": 101753.70149253731, "train/model_opt_loss": 4143.226393666433, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 5671.641791044776, "train/policy_entropy_mag": 1.1726152458001131, "train/policy_entropy_max": 1.1726152458001131, "train/policy_entropy_mean": 0.08400970923515101, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.0938576659308144, "train/policy_logprob_mag": 6.551080290950946, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08441637267372501, "train/policy_logprob_min": -6.551080290950946, "train/policy_logprob_std": 0.6235183596017941, "train/policy_randomness_mag": 0.602605066785765, "train/policy_randomness_max": 0.602605066785765, "train/policy_randomness_mean": 0.043172455471546495, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04823330167069364, "train/post_ent_mag": 35.54143801257385, "train/post_ent_max": 35.54143801257385, "train/post_ent_mean": 34.88924834977335, "train/post_ent_min": 34.179560779932125, "train/post_ent_std": 0.2701793165497519, "train/prior_ent_mag": 35.77196804445181, "train/prior_ent_max": 35.77196804445181, "train/prior_ent_mean": 34.84693532915258, "train/prior_ent_min": 33.81774164076468, "train/prior_ent_std": 0.33926796364547007, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0031358557624397198, "train/reward_loss_mean": 0.02263952580984886, "train/reward_loss_std": 0.27926962918124687, "train/reward_max_data": 0.8109452743731921, "train/reward_max_pred": 0.35345220506487796, "train/reward_neg_acc": 0.9993850262603949, "train/reward_neg_loss": 0.004342279834811812, "train/reward_pos_acc": 0.16679483584722682, "train/reward_pos_loss": 3.9676986121053073, "train/reward_pred": 0.002594266637038458, "train/reward_rate": 0.004630169465174129, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.029779773205518723, "report/cont_loss_std": 0.3137103319168091, "report/cont_neg_acc": 0.125, "report/cont_neg_loss": 3.1947124004364014, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004859040025621653, "report/cont_pred": 0.9940340518951416, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08775118738412857, "report/image_loss_std": 0.10637728124856949, "report/model_loss_mean": 0.7454849481582642, "report/model_loss_std": 0.6752217411994934, "report/post_ent_mag": 35.79206085205078, "report/post_ent_max": 35.79206085205078, "report/post_ent_mean": 35.12740707397461, "report/post_ent_min": 34.479278564453125, "report/post_ent_std": 0.27861636877059937, "report/prior_ent_mag": 35.697357177734375, "report/prior_ent_max": 35.697357177734375, "report/prior_ent_mean": 34.87146759033203, "report/prior_ent_min": 33.84241485595703, "report/prior_ent_std": 0.30060386657714844, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.004092407412827015, "report/reward_loss_mean": 0.027953920885920525, "report/reward_loss_std": 0.3564106822013855, "report/reward_max_data": 0.90625, "report/reward_max_pred": 0.7806063890457153, "report/reward_neg_acc": 0.9980353713035583, "report/reward_neg_loss": 0.003616263158619404, "report/reward_pos_acc": 0.1666666716337204, "report/reward_pos_loss": 4.157243251800537, "report/reward_pred": 0.002804277464747429, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.021203674376010895, "eval/cont_loss_std": 0.3140037953853607, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.915056228637695, "eval/cont_pos_acc": 0.9980430603027344, "eval/cont_pos_loss": 0.0077127693220973015, "eval/cont_pred": 0.9940085411071777, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09145361185073853, "eval/image_loss_std": 0.1078307181596756, "eval/model_loss_mean": 0.7342830300331116, "eval/model_loss_std": 0.6941492557525635, "eval/post_ent_mag": 35.79137420654297, "eval/post_ent_max": 35.79137420654297, "eval/post_ent_mean": 35.08832550048828, "eval/post_ent_min": 34.473106384277344, "eval/post_ent_std": 0.298890084028244, "eval/prior_ent_mag": 35.6448860168457, "eval/prior_ent_max": 35.6448860168457, "eval/prior_ent_mean": 34.837501525878906, "eval/prior_ent_min": 33.49370193481445, "eval/prior_ent_std": 0.32348376512527466, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0012908935314044356, "eval/reward_loss_mean": 0.02162572368979454, "eval/reward_loss_std": 0.3498663306236267, "eval/reward_max_data": 0.7124999761581421, "eval/reward_max_pred": 0.5041933059692383, "eval/reward_neg_acc": 0.9970645904541016, "eval/reward_neg_loss": 0.006525982636958361, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.7375922203063965, "eval/reward_pred": 0.0025460245087742805, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 32128.0, "replay/samples": 32128.0, "replay/insert_wait_avg": 1.231111971980547e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.570279665677196e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.124487627272638e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2008697986603, "timer/env.step_count": 4016.0, "timer/env.step_total": 39.208237171173096, "timer/env.step_frac": 0.03920036300214944, "timer/env.step_avg": 0.00976300726373832, "timer/env.step_min": 0.007702827453613281, "timer/env.step_max": 0.05088019371032715, "timer/replay._sample_count": 32128.0, "timer/replay._sample_total": 16.3939950466156, "timer/replay._sample_frac": 0.0163907026494745, "timer/replay._sample_avg": 0.0005102712601660732, "timer/replay._sample_min": 0.0003979206085205078, "timer/replay._sample_max": 0.02795124053955078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4463.0, "timer/agent.policy_total": 47.92191457748413, "timer/agent.policy_frac": 0.04791229044534902, "timer/agent.policy_avg": 0.01073760129452927, "timer/agent.policy_min": 0.009088754653930664, "timer/agent.policy_max": 0.08550548553466797, "timer/dataset_train_count": 2008.0, "timer/dataset_train_total": 0.21673130989074707, "timer/dataset_train_frac": 0.00021668778385923113, "timer/dataset_train_avg": 0.00010793391926830033, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0004909038543701172, "timer/agent.train_count": 2008.0, "timer/agent.train_total": 902.1864199638367, "timer/agent.train_frac": 0.9020052343540215, "timer/agent.train_avg": 0.4492960258784047, "timer/agent.train_min": 0.4394419193267822, "timer/agent.train_max": 0.705364465713501, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47581982612609863, "timer/agent.report_frac": 0.0004757242674882705, "timer/agent.report_avg": 0.23790991306304932, "timer/agent.report_min": 0.23108482360839844, "timer/agent.report_max": 0.2447350025177002, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1941673482088154e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 32.12100455380137}
{"step": 1647216, "time": 51277.88342881203, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 1647352, "time": 51281.78017807007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1647360, "time": 51282.24844241142, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1647544, "time": 51287.6071062088, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1647632, "time": 51290.6331307888, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1647744, "time": 51294.025398015976, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1647784, "time": 51295.01838827133, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1648072, "time": 51303.756821632385, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1648232, "time": 51308.57906246185, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1648448, "time": 51315.338416576385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1648528, "time": 51317.74752640724, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1648712, "time": 51323.17356753349, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1648880, "time": 51328.46665263176, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1649296, "time": 51341.04887223244, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1649352, "time": 51342.52450680733, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1649424, "time": 51344.93333530426, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1649720, "time": 51353.72325634956, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1649944, "time": 51360.49278712273, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1649944, "time": 51360.49984169006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1650064, "time": 51365.10873126984, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 1650064, "time": 51365.25459265709, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1650064, "time": 51365.79810023308, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1650064, "time": 51365.82480120659, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1650064, "time": 51366.04383826256, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1650064, "time": 51366.698602199554, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 1650064, "time": 51366.87426447868, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1650064, "time": 51367.85562825203, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1650216, "time": 51372.24409222603, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1650544, "time": 51382.472980976105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1650576, "time": 51383.453256845474, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1650712, "time": 51387.38248133659, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 1650936, "time": 51394.17334628105, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1650992, "time": 51396.12210249901, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1651112, "time": 51399.52514028549, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1652256, "time": 51434.6894364357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1652256, "time": 51434.69961190224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1652280, "time": 51435.23525953293, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1652320, "time": 51436.68093061447, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1652544, "time": 51443.59508109093, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1652632, "time": 51446.0617723465, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1652672, "time": 51447.49891328812, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 1652808, "time": 51451.41115808487, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 1653024, "time": 51458.17555999756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1653056, "time": 51459.1440281868, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1653112, "time": 51460.634093761444, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1653120, "time": 51461.10271406174, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1653464, "time": 51471.383949279785, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1653536, "time": 51473.79656243324, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1653616, "time": 51476.25556087494, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1653992, "time": 51487.50929117203, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1653992, "time": 51487.51819849014, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1654064, "time": 51489.964446783066, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1654088, "time": 51490.48086190224, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1654384, "time": 51499.76465678215, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1654568, "time": 51505.227772951126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1654592, "time": 51506.178609609604, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1654624, "time": 51507.161687374115, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1654800, "time": 51513.018218278885, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1654984, "time": 51518.35761260986, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1655096, "time": 51521.760283231735, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1655232, "time": 51526.13134384155, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1655392, "time": 51531.07422924042, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1655880, "time": 51545.64034700394, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1656008, "time": 51549.543336868286, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1656040, "time": 51550.51960730553, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1656144, "time": 51553.904870033264, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1656288, "time": 51558.282965898514, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1656448, "time": 51563.247337818146, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1657080, "time": 51582.22450590134, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1657240, "time": 51587.079944610596, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1657296, "time": 51588.99630355835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1657408, "time": 51592.53161239624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1657544, "time": 51596.418971300125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1657664, "time": 51600.31463766098, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1657672, "time": 51600.341579675674, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1657680, "time": 51600.809688806534, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1657704, "time": 51601.32931017876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1657976, "time": 51609.65846443176, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1658344, "time": 51621.01874613762, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1658464, "time": 51624.915897369385, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1658600, "time": 51628.81777191162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1658888, "time": 51637.675231695175, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1659024, "time": 51642.0331492424, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1659128, "time": 51644.977607011795, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1659168, "time": 51646.43663024902, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1659648, "time": 51661.12552523613, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1659840, "time": 51666.95734643936, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1659984, "time": 51671.320502996445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1660000, "time": 51671.809268951416, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1660048, "time": 51674.304028749466, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1660048, "time": 51674.61298561096, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1660048, "time": 51674.733441114426, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1660048, "time": 51675.35895180702, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1660048, "time": 51675.438534498215, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1660048, "time": 51675.93660092354, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 1660048, "time": 51678.48690700531, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 1660048, "time": 51678.81704926491, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1660048, "time": 51678.82508230209, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1660048, "time": 51678.834116220474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1660152, "time": 51681.867117643356, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1660288, "time": 51686.22444367409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1660512, "time": 51693.000180482864, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1660520, "time": 51693.0275220871, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1660552, "time": 51693.99653553963, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1660720, "time": 51699.315726041794, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1660776, "time": 51700.802533864975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1661040, "time": 51708.97704553604, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1661224, "time": 51714.46296429634, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1661320, "time": 51717.38491368294, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 1661432, "time": 51720.78216838837, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1661456, "time": 51721.729691028595, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1661480, "time": 51722.23674964905, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1661768, "time": 51730.99411892891, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1661904, "time": 51735.31776833534, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1661960, "time": 51736.78589653969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1662056, "time": 51739.718799591064, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1662152, "time": 51742.73998045921, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1662256, "time": 51746.13671708107, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1662304, "time": 51747.59361791611, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1662312, "time": 51747.62251615524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1662432, "time": 51751.492552280426, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1662720, "time": 51760.26273083687, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1662984, "time": 51768.24387526512, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1663000, "time": 51769.04479885101, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1663112, "time": 51772.54450893402, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1663152, "time": 51773.9965133667, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1663432, "time": 51782.25540852547, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1663456, "time": 51783.20813250542, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1663656, "time": 51789.08816695213, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1663832, "time": 51794.430648088455, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1664272, "time": 51808.14242005348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1664352, "time": 51810.57938456535, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1664368, "time": 51811.069232702255, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1664928, "time": 51828.08660817146, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1664952, "time": 51828.60445833206, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1664968, "time": 51829.10045719147, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1665456, "time": 51844.228430747986, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1665464, "time": 51844.25746893883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1665656, "time": 51850.07388424873, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1665768, "time": 51853.48652458191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1665968, "time": 51859.79892897606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1666112, "time": 51864.26853656769, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1666216, "time": 51867.22647404671, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1666440, "time": 51874.067549705505, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1666472, "time": 51875.05134701729, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1666512, "time": 51876.518729925156, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1666560, "time": 51877.98234963417, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 1666848, "time": 51886.765300512314, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1666904, "time": 51888.23840379715, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1666960, "time": 51890.19927597046, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1667200, "time": 51897.610830783844, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1667232, "time": 51898.594464063644, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1667240, "time": 51898.62420248985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1667360, "time": 51902.50022816658, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1667416, "time": 51903.987256765366, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1667800, "time": 51915.657794713974, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1667992, "time": 51921.63526010513, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1667992, "time": 51921.64325404167, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1668080, "time": 51924.53553271294, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1668472, "time": 51936.2577252388, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1668632, "time": 51941.10942029953, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1668752, "time": 51945.013734579086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1668872, "time": 51948.4319152832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1668920, "time": 51949.921305179596, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1669056, "time": 51954.34973216057, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1669216, "time": 51959.223098516464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1669296, "time": 51961.681144714355, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1669328, "time": 51962.65134596825, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1669552, "time": 51969.465671777725, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1669648, "time": 51972.36666369438, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1669728, "time": 51974.810319662094, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1669856, "time": 51978.714681863785, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1670032, "time": 51985.3531806469, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1670032, "time": 51986.0687482357, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1670032, "time": 51986.09548854828, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1670032, "time": 51986.754127025604, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1670032, "time": 51986.97235250473, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 1670032, "time": 51987.03742456436, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 1670032, "time": 51987.16072511673, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1670032, "time": 51987.43924856186, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 1670232, "time": 51993.32623195648, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1670272, "time": 51994.768105745316, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1670344, "time": 51996.744433641434, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1670448, "time": 52000.13602352142, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1670600, "time": 52004.571219205856, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1670832, "time": 52011.96354150772, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1670968, "time": 52015.86381840706, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1670976, "time": 52016.33108448982, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1671184, "time": 52023.13115501404, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1671184, "time": 52023.1401219368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1671288, "time": 52026.07961845398, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1671600, "time": 52035.76643872261, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1671656, "time": 52037.2566986084, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1671864, "time": 52043.61783647537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1671928, "time": 52045.55177092552, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1672216, "time": 52054.28011250496, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1672248, "time": 52055.25498127937, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1672368, "time": 52059.13336753845, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1672376, "time": 52059.163543224335, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1672488, "time": 52062.59482860565, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1672504, "time": 52063.09272623062, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1672840, "time": 52073.35439157486, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1672864, "time": 52074.30460500717, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1673376, "time": 52089.87304329872, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1673408, "time": 52090.88343811035, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1673544, "time": 52094.808811187744, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1673872, "time": 52105.07929062843, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1673912, "time": 52106.06922459602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1673912, "time": 52106.07629084587, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1673944, "time": 52107.04875302315, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1674096, "time": 52111.87783765793, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1674176, "time": 52114.28556251526, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1674560, "time": 52125.883427619934, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1674560, "time": 52125.89913678169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1674608, "time": 52127.36951708794, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1674760, "time": 52131.940351724625, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1674920, "time": 52136.82730770111, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1674960, "time": 52138.2677924633, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1675080, "time": 52141.70176720619, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1675456, "time": 52153.39217329025, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1675488, "time": 52154.39559030533, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1675632, "time": 52158.789071798325, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1676224, "time": 52176.94974207878, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1676224, "time": 52176.96438455582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1676776, "time": 52193.62202548981, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1676872, "time": 52196.526030540466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1677072, "time": 52202.82080769539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1677112, "time": 52203.81188249588, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1677224, "time": 52207.20922636986, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1677232, "time": 52207.69941735268, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1677272, "time": 52208.692041397095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1677616, "time": 52219.3401966095, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1677664, "time": 52220.88162279129, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1677696, "time": 52221.85091924667, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1677944, "time": 52229.13065171242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1678192, "time": 52236.87961101532, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1678376, "time": 52242.29106068611, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1678424, "time": 52243.76381492615, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1678600, "time": 52249.123760700226, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1678608, "time": 52249.60201859474, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1678656, "time": 52251.17111945152, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1678752, "time": 52254.12631750107, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1679088, "time": 52264.31890106201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1679272, "time": 52269.67367148399, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1679465, "time": 52277.06607103348, "train_stats/mean_log_entropy": 0.07677120594051454, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.327829795308632, "train/action_min": 0.0, "train/action_std": 1.6597415415367278, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01182786142568814, "train/actor_opt_grad_steps": 103865.0, "train/actor_opt_loss": -29.685054892360576, "train/adv_mag": 0.765485528967168, "train/adv_max": 0.32679054937740365, "train/adv_mean": -0.00010094399173191626, "train/adv_min": -0.6888451354928536, "train/adv_std": 0.03154876586603056, "train/cont_avg": 0.9934589650371287, "train/cont_loss_mean": 0.02676057363721994, "train/cont_loss_std": 0.2846902163311987, "train/cont_neg_acc": 0.1454161519903948, "train/cont_neg_loss": 3.173833772318788, "train/cont_pos_acc": 0.9997859225414767, "train/cont_pos_loss": 0.005917559361712324, "train/cont_pred": 0.993303509927032, "train/cont_rate": 0.9934589650371287, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11837723200200218, "train/extr_critic_critic_opt_grad_steps": 103865.0, "train/extr_critic_critic_opt_loss": 6626.445467202971, "train/extr_critic_mag": 1.663220723076622, "train/extr_critic_max": 1.663220723076622, "train/extr_critic_mean": 1.5313538714210586, "train/extr_critic_min": 1.2302792939809288, "train/extr_critic_std": 0.030251891444446427, "train/extr_return_normed_mag": 0.7831997228140878, "train/extr_return_normed_max": 0.3099845004553842, "train/extr_return_normed_mean": 0.05952949951043223, "train/extr_return_normed_min": -0.6606384014139081, "train/extr_return_normed_std": 0.044659426242186884, "train/extr_return_rate": 0.999621968753267, "train/extr_return_raw_mag": 1.7817078693078297, "train/extr_return_raw_max": 1.7817078693078297, "train/extr_return_raw_mean": 1.5312529395122338, "train/extr_return_raw_min": 0.8110849674385373, "train/extr_return_raw_std": 0.044659426232965864, "train/extr_reward_mag": 0.27227869128236676, "train/extr_reward_max": 0.27227869128236676, "train/extr_reward_mean": 0.002707602648124431, "train/extr_reward_min": 2.3605799911045792e-09, "train/extr_reward_std": 0.010206903865800636, "train/image_loss_mean": 0.07504168499519329, "train/image_loss_std": 0.09686407015317737, "train/model_loss_mean": 0.7243403936966811, "train/model_loss_std": 0.5528705627980208, "train/model_opt_grad_norm": 14.105047485615948, "train/model_opt_grad_steps": 103767.38613861386, "train/model_opt_loss": 4770.32209883586, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6584.158415841584, "train/policy_entropy_mag": 1.1664151891623393, "train/policy_entropy_max": 1.1664151891623393, "train/policy_entropy_mean": 0.08538334031063731, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.0964613598540868, "train/policy_logprob_mag": 6.551080271749213, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08552682019843913, "train/policy_logprob_min": -6.551080271749213, "train/policy_logprob_std": 0.623168143305448, "train/policy_randomness_mag": 0.5994188680802242, "train/policy_randomness_max": 0.5994188680802242, "train/policy_randomness_mean": 0.04387836185938651, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.04957133612715372, "train/post_ent_mag": 35.56430274661225, "train/post_ent_max": 35.56430274661225, "train/post_ent_mean": 34.94566951411785, "train/post_ent_min": 34.28502934521968, "train/post_ent_std": 0.2554792967615741, "train/prior_ent_mag": 35.28553082683299, "train/prior_ent_max": 35.28553082683299, "train/prior_ent_mean": 34.34520222881053, "train/prior_ent_min": 33.47880973438225, "train/prior_ent_std": 0.30845092974676946, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.003179402852495487, "train/reward_loss_mean": 0.02253811021270876, "train/reward_loss_std": 0.2757433782156446, "train/reward_max_data": 0.8267481436233709, "train/reward_max_pred": 0.3768256672538153, "train/reward_neg_acc": 0.9993540278755793, "train/reward_neg_loss": 0.004375326095637635, "train/reward_pos_acc": 0.16906933909031882, "train/reward_pos_loss": 3.8854768311799464, "train/reward_pred": 0.0026197490515187383, "train/reward_rate": 0.004699102722772277, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0198000930249691, "report/cont_loss_std": 0.2184314727783203, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 2.7819294929504395, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0062469555996358395, "report/cont_pred": 0.992805540561676, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.061204761266708374, "report/image_loss_std": 0.08753345906734467, "report/model_loss_mean": 0.7012372612953186, "report/model_loss_std": 0.5270230174064636, "report/post_ent_mag": 35.737545013427734, "report/post_ent_max": 35.737545013427734, "report/post_ent_mean": 35.06865692138672, "report/post_ent_min": 34.378944396972656, "report/post_ent_std": 0.2799132466316223, "report/prior_ent_mag": 35.09986114501953, "report/prior_ent_max": 35.09986114501953, "report/prior_ent_mean": 34.266170501708984, "report/prior_ent_min": 33.56462478637695, "report/prior_ent_std": 0.26361900568008423, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023834228049963713, "report/reward_loss_mean": 0.020232388749718666, "report/reward_loss_std": 0.2892584204673767, "report/reward_max_data": 0.7593749761581421, "report/reward_max_pred": 0.7227919101715088, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.004017886705696583, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 4.154930114746094, "report/reward_pred": 0.0027614696882665157, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.027886077761650085, "eval/cont_loss_std": 0.30526459217071533, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.124229907989502, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.007786257192492485, "eval/cont_pred": 0.992626965045929, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1050071120262146, "eval/image_loss_std": 0.11789444833993912, "eval/model_loss_mean": 0.765586256980896, "eval/model_loss_std": 0.7546402812004089, "eval/post_ent_mag": 35.619686126708984, "eval/post_ent_max": 35.619686126708984, "eval/post_ent_mean": 35.10737228393555, "eval/post_ent_min": 34.4555549621582, "eval/post_ent_std": 0.24156808853149414, "eval/prior_ent_mag": 35.09986114501953, "eval/prior_ent_max": 35.09986114501953, "eval/prior_ent_mean": 34.268638610839844, "eval/prior_ent_min": 33.66794967651367, "eval/prior_ent_std": 0.25031283497810364, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.003359985537827015, "eval/reward_loss_mean": 0.032693035900592804, "eval/reward_loss_std": 0.41544923186302185, "eval/reward_max_data": 0.8125, "eval/reward_max_pred": 0.398002028465271, "eval/reward_neg_acc": 0.9970559477806091, "eval/reward_neg_loss": 0.005537342745810747, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.567022800445557, "eval/reward_pred": 0.002911995630711317, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 32288.0, "replay/samples": 32288.0, "replay/insert_wait_avg": 1.2363385634332512e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.638875745805451e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1078209500765838e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4290120601654, "timer/env.step_count": 4036.0, "timer/env.step_total": 39.529268741607666, "timer/env.step_frac": 0.03951231748088328, "timer/env.step_avg": 0.009794169658475635, "timer/env.step_min": 0.007728099822998047, "timer/env.step_max": 0.04396367073059082, "timer/replay._sample_count": 32288.0, "timer/replay._sample_total": 16.540550470352173, "timer/replay._sample_frac": 0.01653345741772374, "timer/replay._sample_avg": 0.0005122816671937616, "timer/replay._sample_min": 0.00040435791015625, "timer/replay._sample_max": 0.03077864646911621, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4657.0, "timer/agent.policy_total": 49.40183663368225, "timer/agent.policy_frac": 0.04938065173854759, "timer/agent.policy_avg": 0.010608081733665934, "timer/agent.policy_min": 0.009100198745727539, "timer/agent.policy_max": 0.08622431755065918, "timer/dataset_train_count": 2018.0, "timer/dataset_train_total": 0.22142672538757324, "timer/dataset_train_frac": 0.00022133177138834986, "timer/dataset_train_avg": 0.00010972583022179051, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.00043511390686035156, "timer/agent.train_count": 2018.0, "timer/agent.train_total": 899.0208148956299, "timer/agent.train_frac": 0.8986352895187362, "timer/agent.train_avg": 0.44550089935363224, "timer/agent.train_min": 0.4331061840057373, "timer/agent.train_max": 0.6876716613769531, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47475171089172363, "timer/agent.report_frac": 0.0004745481240233887, "timer/agent.report_avg": 0.23737585544586182, "timer/agent.report_min": 0.2299957275390625, "timer/agent.report_max": 0.24475598335266113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.883627696070265e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 32.27356467455319}
{"step": 1679528, "time": 52278.737973451614, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1679536, "time": 52279.204094171524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1679592, "time": 52280.772981882095, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1679664, "time": 52283.191784620285, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1679672, "time": 52283.21925854683, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1679912, "time": 52290.482249736786, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1679952, "time": 52291.93341898918, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1680016, "time": 52294.95599746704, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1680016, "time": 52295.16366195679, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1680016, "time": 52296.26274681091, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1680016, "time": 52296.79025006294, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 1680016, "time": 52296.873217105865, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 1680016, "time": 52297.53797197342, "eval_episode/length": 185.0, "eval_episode/score": 0.421875, "eval_episode/reward_rate": 0.005376344086021506}
{"step": 1680016, "time": 52297.79091334343, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1680016, "time": 52298.630546331406, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1680144, "time": 52302.520694971085, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1680208, "time": 52304.465819358826, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1680296, "time": 52306.92249941826, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1680424, "time": 52310.86569523811, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1680632, "time": 52317.17377257347, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1680944, "time": 52326.96945524216, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1680960, "time": 52327.457480192184, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1681152, "time": 52333.27102017403, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1681296, "time": 52337.61206459999, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1681528, "time": 52344.57200336456, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1681976, "time": 52358.15897798538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1682152, "time": 52363.52590703964, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 1682296, "time": 52367.92503905296, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1682344, "time": 52369.40145897865, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1682368, "time": 52370.459753751755, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1682544, "time": 52375.84789609909, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1682680, "time": 52379.80869650841, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1682712, "time": 52380.7877266407, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1683128, "time": 52393.445801734924, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 1683360, "time": 52400.88288617134, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1683720, "time": 52411.60195374489, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1683816, "time": 52414.52013540268, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1684088, "time": 52422.76959109306, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1684240, "time": 52427.618312597275, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1684288, "time": 52429.10465288162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1684656, "time": 52440.44824409485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1684776, "time": 52443.89170432091, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1684840, "time": 52445.84319353104, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1684944, "time": 52449.23963856697, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1684992, "time": 52450.69371986389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1685184, "time": 52456.51153087616, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1685312, "time": 52460.51727056503, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1685440, "time": 52464.39810872078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1685632, "time": 52470.207290410995, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1685728, "time": 52473.1209628582, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1685816, "time": 52475.545625925064, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1685832, "time": 52476.03517460823, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1685872, "time": 52477.477982997894, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1686064, "time": 52483.29123234749, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1686248, "time": 52488.685933589935, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1686600, "time": 52499.4630856514, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1686600, "time": 52499.47299981117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1686616, "time": 52499.96786785126, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1686688, "time": 52502.39609360695, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1686904, "time": 52508.76901316643, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1687104, "time": 52515.06011533737, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 1687352, "time": 52522.46562218666, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1687432, "time": 52524.89414167404, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1687448, "time": 52525.38308262825, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1687496, "time": 52526.856852054596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1687576, "time": 52529.75609135628, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1688048, "time": 52544.32811021805, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1688176, "time": 52548.22374677658, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1688544, "time": 52559.52315115929, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1688760, "time": 52565.87005853653, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1688896, "time": 52570.198528289795, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1689064, "time": 52575.10646748543, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1689216, "time": 52579.970875263214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1689416, "time": 52585.98449420929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1689760, "time": 52596.65298914909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1689808, "time": 52598.12171912193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1689920, "time": 52601.54127073288, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1690000, "time": 52604.98017787933, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1690000, "time": 52605.437782526016, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1690000, "time": 52605.44741439819, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1690000, "time": 52606.33329868317, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1690000, "time": 52606.34199476242, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1690000, "time": 52606.721324920654, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1690000, "time": 52607.42043209076, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 1690000, "time": 52607.54032731056, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1690160, "time": 52612.53159070015, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1690312, "time": 52616.94774580002, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1690392, "time": 52619.398359537125, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1690856, "time": 52633.664680957794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1691024, "time": 52638.994410037994, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1691072, "time": 52640.59729909897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1691080, "time": 52640.62493920326, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1691592, "time": 52656.1646463871, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1691744, "time": 52661.008407354355, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1691832, "time": 52663.48167014122, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1692008, "time": 52668.81718707085, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1692072, "time": 52670.854966163635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1692488, "time": 52683.495113134384, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1692624, "time": 52687.848115205765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1692632, "time": 52687.874430179596, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1692640, "time": 52688.33885669708, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1692704, "time": 52690.2812435627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1692760, "time": 52691.7785551548, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1692976, "time": 52698.53087568283, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1693304, "time": 52708.34267568588, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1693392, "time": 52711.23965597153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1693640, "time": 52718.49384713173, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1693640, "time": 52718.50208854675, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1693736, "time": 52721.40956950188, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1693976, "time": 52728.6743285656, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1694016, "time": 52730.11019515991, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1694752, "time": 52752.63236093521, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 1694776, "time": 52753.141389131546, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1694800, "time": 52754.0958712101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1694936, "time": 52758.045226335526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1694952, "time": 52758.53587126732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1695064, "time": 52762.08871912956, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1695184, "time": 52765.959819316864, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1695384, "time": 52771.85510778427, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1695384, "time": 52771.86386013031, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1695400, "time": 52772.357139110565, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1695496, "time": 52775.295826911926, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1695680, "time": 52781.10182595253, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1695704, "time": 52781.61291074753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1696040, "time": 52792.361525774, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1696296, "time": 52800.12794804573, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1696328, "time": 52801.102570295334, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1696864, "time": 52817.57974290848, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1697024, "time": 52822.56584906578, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1697248, "time": 52829.38225030899, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1697352, "time": 52832.31508588791, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1697376, "time": 52833.27141618729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1697640, "time": 52841.09649467468, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1697696, "time": 52843.01115512848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1698000, "time": 52852.30880379677, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1698184, "time": 52857.65017199516, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1698280, "time": 52860.57054924965, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1698352, "time": 52863.00366234779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1698624, "time": 52871.35893154144, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1698640, "time": 52871.852162361145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1698848, "time": 52878.21192860603, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1699176, "time": 52888.07301735878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1699288, "time": 52891.48285269737, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1699560, "time": 52899.72206068039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1699888, "time": 52909.92452406883, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1699912, "time": 52910.54652953148, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1700008, "time": 52913.45673418045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1700056, "time": 52914.90365791321, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1700088, "time": 52916.265089035034, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 1700088, "time": 52917.210700035095, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1700088, "time": 52917.3794939518, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1700088, "time": 52917.72396183014, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 1700088, "time": 52917.84635591507, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 1700088, "time": 52917.928614616394, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1700088, "time": 52918.34462237358, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1700088, "time": 52918.46447086334, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1700128, "time": 52919.91378569603, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1700496, "time": 52931.06957364082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1700592, "time": 52933.99062919617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1700832, "time": 52941.334637880325, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1700952, "time": 52944.77388048172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1700968, "time": 52945.259737730026, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1701176, "time": 52951.560425043106, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1701248, "time": 52953.97847890854, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1701304, "time": 52955.44770884514, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1701448, "time": 52959.816057920456, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1701712, "time": 52968.09585881233, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1701992, "time": 52976.60725784302, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1702440, "time": 52990.25926756859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1702512, "time": 52992.70088672638, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1702552, "time": 52993.695296764374, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1702568, "time": 52994.18781256676, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1702744, "time": 52999.60728287697, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1702744, "time": 52999.617264032364, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1702896, "time": 53004.625178575516, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1702992, "time": 53007.575305223465, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1703256, "time": 53015.402680158615, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1703576, "time": 53025.12028717995, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1703904, "time": 53035.45959734917, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1704752, "time": 53061.79667329788, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 1704752, "time": 53061.8052482605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1704824, "time": 53063.76591682434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1704840, "time": 53064.25590252876, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1704880, "time": 53065.69136071205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1705056, "time": 53071.020711660385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1705080, "time": 53071.55068778992, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1705120, "time": 53072.9791560173, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1705416, "time": 53081.73778939247, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1705624, "time": 53088.064992427826, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1705672, "time": 53089.51902246475, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1705736, "time": 53091.62363624573, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1705784, "time": 53093.09395098686, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 1705824, "time": 53094.53347039223, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1706040, "time": 53100.88250541687, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1706368, "time": 53111.18052268028, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1706384, "time": 53111.674723386765, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1706656, "time": 53120.039984464645, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1706880, "time": 53126.99061393738, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1707056, "time": 53132.37764620781, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1707584, "time": 53148.47839951515, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1707624, "time": 53149.492631196976, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1707728, "time": 53153.036494255066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1707792, "time": 53155.00977778435, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 1707848, "time": 53156.49465966225, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1707912, "time": 53158.44083881378, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1707960, "time": 53159.930643081665, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 1708152, "time": 53165.7735786438, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1708192, "time": 53167.20500946045, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1708352, "time": 53172.05258202553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1708752, "time": 53184.28328323364, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1708776, "time": 53184.79356217384, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1708808, "time": 53185.76726055145, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1708880, "time": 53188.165135622025, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1708968, "time": 53190.625148296356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1709192, "time": 53197.425364494324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1709312, "time": 53201.28851175308, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1709336, "time": 53201.80343079567, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1709688, "time": 53212.57158327103, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1709736, "time": 53214.06898069382, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1710072, "time": 53225.44883918762, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 1710072, "time": 53226.15510749817, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1710072, "time": 53226.41725683212, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1710072, "time": 53226.95619750023, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1710072, "time": 53227.037083148956, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1710072, "time": 53227.204403162, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1710072, "time": 53227.69635772705, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 1710072, "time": 53228.15443921089, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1710136, "time": 53230.08473086357, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1710240, "time": 53233.48248338699, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1710256, "time": 53233.96834850311, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1710368, "time": 53237.37872171402, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 1710824, "time": 53251.167587041855, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1710848, "time": 53252.13672709465, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1710848, "time": 53252.14545083046, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1710960, "time": 53255.586462020874, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1711088, "time": 53259.516620635986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1711120, "time": 53260.49111676216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1711192, "time": 53262.47697377205, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1711344, "time": 53267.35545992851, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1711352, "time": 53267.3835504055, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1711641, "time": 53279.75536417961, "train_stats/mean_log_entropy": 0.07440201187721239, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3669315167327425, "train/action_min": 0.0, "train/action_std": 1.678653137007756, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011957730270866582, "train/actor_opt_grad_steps": 105880.0, "train/actor_opt_loss": -33.67617668797128, "train/adv_mag": 0.7526457686329362, "train/adv_max": 0.31634615962185075, "train/adv_mean": 0.0006719415322283082, "train/adv_min": -0.6829446325847759, "train/adv_std": 0.03160057588485046, "train/cont_avg": 0.9933146766169154, "train/cont_loss_mean": 0.027454413821114534, "train/cont_loss_std": 0.28899278914305704, "train/cont_neg_acc": 0.12923650717853907, "train/cont_neg_loss": 3.2187924758711857, "train/cont_pos_acc": 0.999833660042701, "train/cont_pos_loss": 0.0058688186375489134, "train/cont_pred": 0.993363450415692, "train/cont_rate": 0.9933146766169154, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11719226736149088, "train/extr_critic_critic_opt_grad_steps": 105880.0, "train/extr_critic_critic_opt_loss": 6149.270352339863, "train/extr_critic_mag": 1.668731408332711, "train/extr_critic_max": 1.668731408332711, "train/extr_critic_mean": 1.5367931228371996, "train/extr_critic_min": 1.2063815593719482, "train/extr_critic_std": 0.03210660745737268, "train/extr_return_normed_mag": 0.7805007808837131, "train/extr_return_normed_max": 0.315606477841809, "train/extr_return_normed_mean": 0.06826135301174809, "train/extr_return_normed_min": -0.6441434829389278, "train/extr_return_normed_std": 0.046176341987812695, "train/extr_return_rate": 0.9996660793598612, "train/extr_return_raw_mag": 1.7848101391721127, "train/extr_return_raw_max": 1.7848101391721127, "train/extr_return_raw_mean": 1.5374650967061816, "train/extr_return_raw_min": 0.8250601783913759, "train/extr_return_raw_std": 0.04617634193221135, "train/extr_reward_mag": 0.2755341215513239, "train/extr_reward_max": 0.2755341215513239, "train/extr_reward_mean": 0.002760415752557343, "train/extr_reward_min": -1.7792431276236007e-09, "train/extr_reward_std": 0.009885097221374067, "train/image_loss_mean": 0.07724254999068839, "train/image_loss_std": 0.09851690735760613, "train/model_loss_mean": 0.7288249686582765, "train/model_loss_std": 0.5727212545438786, "train/model_opt_grad_norm": 13.72672935267586, "train/model_opt_grad_steps": 105780.52736318408, "train/model_opt_loss": 3949.9824643870493, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5422.885572139304, "train/policy_entropy_mag": 1.1567203120805731, "train/policy_entropy_max": 1.1567203120805731, "train/policy_entropy_mean": 0.08362134371823933, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09235535524970856, "train/policy_logprob_mag": 6.551080286206298, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08363213679238932, "train/policy_logprob_min": -6.551080286206298, "train/policy_logprob_std": 0.6211151753492024, "train/policy_randomness_mag": 0.5944366843546208, "train/policy_randomness_max": 0.5944366843546208, "train/policy_randomness_mean": 0.04297287511959005, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.047461267190044794, "train/post_ent_mag": 35.6506642204019, "train/post_ent_max": 35.6506642204019, "train/post_ent_mean": 35.00912815302759, "train/post_ent_min": 34.28593776949602, "train/post_ent_std": 0.2710359423463024, "train/prior_ent_mag": 35.107925054445786, "train/prior_ent_max": 35.107925054445786, "train/prior_ent_mean": 34.32802853180994, "train/prior_ent_min": 33.564195509573715, "train/prior_ent_std": 0.2579293063475718, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.003417300722684563, "train/reward_loss_mean": 0.02412798191045425, "train/reward_loss_std": 0.28736829212333875, "train/reward_max_data": 0.8277985094791621, "train/reward_max_pred": 0.34678525058784293, "train/reward_neg_acc": 0.9994092067675804, "train/reward_neg_loss": 0.004399349938485011, "train/reward_pos_acc": 0.15934343771501022, "train/reward_pos_loss": 3.9270990933432723, "train/reward_pred": 0.00264650721228056, "train/reward_rate": 0.00501885105721393, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.029697809368371964, "report/cont_loss_std": 0.30103304982185364, "report/cont_neg_acc": 0.125, "report/cont_neg_loss": 3.0414791107177734, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005982997361570597, "report/cont_pred": 0.9931600093841553, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06857676804065704, "report/image_loss_std": 0.0927886962890625, "report/model_loss_mean": 0.7192760705947876, "report/model_loss_std": 0.5368915796279907, "report/post_ent_mag": 35.79350280761719, "report/post_ent_max": 35.79350280761719, "report/post_ent_mean": 35.14529800415039, "report/post_ent_min": 34.50748825073242, "report/post_ent_std": 0.2533230185508728, "report/prior_ent_mag": 35.008628845214844, "report/prior_ent_max": 35.008628845214844, "report/prior_ent_mean": 34.33916091918945, "report/prior_ent_min": 33.58993911743164, "report/prior_ent_std": 0.2563060224056244, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0035736083518713713, "report/reward_loss_mean": 0.021001514047384262, "report/reward_loss_std": 0.25942760705947876, "report/reward_max_data": 0.9437500238418579, "report/reward_max_pred": 0.4600318670272827, "report/reward_neg_acc": 0.999018669128418, "report/reward_neg_loss": 0.00423868652433157, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 3.4372661113739014, "report/reward_pred": 0.0025885836221277714, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.018361054360866547, "eval/cont_loss_std": 0.20035585761070251, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.544093608856201, "eval/cont_pos_acc": 0.9980410933494568, "eval/cont_pos_loss": 0.008001409471035004, "eval/cont_pred": 0.9930237531661987, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.100165456533432, "eval/image_loss_std": 0.12086234986782074, "eval/model_loss_mean": 0.7361632585525513, "eval/model_loss_std": 0.479749858379364, "eval/post_ent_mag": 35.737247467041016, "eval/post_ent_max": 35.737247467041016, "eval/post_ent_mean": 35.170921325683594, "eval/post_ent_min": 34.4318962097168, "eval/post_ent_std": 0.2532936632633209, "eval/prior_ent_mag": 35.15857696533203, "eval/prior_ent_max": 35.15857696533203, "eval/prior_ent_mean": 34.36397933959961, "eval/prior_ent_min": 33.57209014892578, "eval/prior_ent_std": 0.24225600063800812, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0022521973587572575, "eval/reward_loss_mean": 0.017636742442846298, "eval/reward_loss_std": 0.24447540938854218, "eval/reward_max_data": 0.8500000238418579, "eval/reward_max_pred": 0.36879658699035645, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.004568443633615971, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.46521520614624, "eval/reward_pred": 0.002280976390466094, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 32176.0, "replay/samples": 32176.0, "replay/insert_wait_avg": 1.2477777420377803e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.577510925740641e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1327804303636737e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1990592479706, "timer/env.step_count": 4022.0, "timer/env.step_total": 39.380199670791626, "timer/env.step_frac": 0.03937236223797371, "timer/env.step_avg": 0.009791198326899956, "timer/env.step_min": 0.007752180099487305, "timer/env.step_max": 0.03594565391540527, "timer/replay._sample_count": 32176.0, "timer/replay._sample_total": 16.40367817878723, "timer/replay._sample_frac": 0.016400413524804577, "timer/replay._sample_avg": 0.0005098109826823481, "timer/replay._sample_min": 0.00040268898010253906, "timer/replay._sample_max": 0.009900569915771484, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4736.0, "timer/agent.policy_total": 50.52271056175232, "timer/agent.policy_frac": 0.050512655550525434, "timer/agent.policy_avg": 0.010667802061180811, "timer/agent.policy_min": 0.008643627166748047, "timer/agent.policy_max": 0.08917808532714844, "timer/dataset_train_count": 2011.0, "timer/dataset_train_total": 0.21994638442993164, "timer/dataset_train_frac": 0.00021990261078160269, "timer/dataset_train_avg": 0.00010937164815014005, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0009062290191650391, "timer/agent.train_count": 2011.0, "timer/agent.train_total": 897.1408514976501, "timer/agent.train_frac": 0.8969623028561856, "timer/agent.train_avg": 0.4461167834399056, "timer/agent.train_min": 0.43480563163757324, "timer/agent.train_max": 0.7278354167938232, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47460174560546875, "timer/agent.report_frac": 0.0004745072905410571, "timer/agent.report_avg": 0.23730087280273438, "timer/agent.report_min": 0.23124980926513672, "timer/agent.report_max": 0.24335193634033203, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.908127775311107e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 32.16902546465311}
{"step": 1711744, "time": 53282.87120056152, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1711912, "time": 53287.777396678925, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1711992, "time": 53290.22065806389, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1712000, "time": 53290.68836474419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1712112, "time": 53294.10494542122, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1712360, "time": 53302.05681729317, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1712456, "time": 53304.97801232338, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1712696, "time": 53312.27372908592, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1712792, "time": 53315.19723725319, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1713056, "time": 53323.42652583122, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1713160, "time": 53326.42163872719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1713184, "time": 53327.372012615204, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1713304, "time": 53330.868794202805, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1713376, "time": 53333.29626226425, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1713568, "time": 53339.19129896164, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1713768, "time": 53345.0543551445, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1714064, "time": 53354.267075777054, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1714192, "time": 53358.1536462307, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 1714304, "time": 53361.61964225769, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1714760, "time": 53375.3074297905, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1714800, "time": 53376.751200675964, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1714816, "time": 53377.24685406685, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1714872, "time": 53378.75024700165, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1714984, "time": 53382.174439668655, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1715008, "time": 53383.15357923508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1715368, "time": 53394.04688358307, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1715368, "time": 53394.055156469345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1715552, "time": 53399.840591192245, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1715592, "time": 53400.82877159119, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1715696, "time": 53404.217809677124, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1715840, "time": 53408.62968873978, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1715880, "time": 53409.62545824051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1715928, "time": 53411.0763399601, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1716024, "time": 53414.00732779503, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1716168, "time": 53418.38594484329, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1716320, "time": 53423.28029155731, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1716688, "time": 53434.4109146595, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1717112, "time": 53447.08762049675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1717240, "time": 53451.11622214317, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1717320, "time": 53453.52313423157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1717408, "time": 53456.40632176399, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1717688, "time": 53464.65745139122, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1717840, "time": 53469.48894691467, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1718192, "time": 53480.215565919876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1718200, "time": 53480.290962696075, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1718240, "time": 53481.764348745346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1719000, "time": 53504.78867530823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1719104, "time": 53508.2299580574, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1719368, "time": 53516.19052696228, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 1719392, "time": 53517.14155006409, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1719424, "time": 53518.11475610733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1719552, "time": 53522.022008895874, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1719688, "time": 53526.04864549637, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 1719792, "time": 53529.44071650505, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1720000, "time": 53535.77958226204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1720056, "time": 53538.120515584946, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1720056, "time": 53538.655692100525, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/re