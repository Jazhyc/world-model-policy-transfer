{"step": 1560, "time": 140.7982337474823, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 140.8844118118286, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 141.81783151626587, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 141.82675552368164, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 141.84067749977112, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 141.8574595451355, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 141.86889219284058, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 141.87759041786194, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 264.5795695781708, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8341064453125, "train/action_min": 0.0, "train/action_std": 2.1183128356933594, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0003878468123730272, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.108890414237976, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.7654223442077637, "train/cont_loss_std": 0.2678714394569397, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.439453125, "train/cont_pos_loss": 0.7654223442077637, "train/cont_pred": 0.48137331008911133, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.569034576416016, "train/dyn_loss_std": 0.37620946764945984, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 5.771844387054443, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 23706.830078125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 4692.9794921875, "train/image_loss_std": 37.983734130859375, "train/model_loss_mean": 4705.6279296875, "train/model_loss_std": 37.9739875793457, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 47056280.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9414448738098145, "train/policy_entropy_max": 1.9414448738098145, "train/policy_entropy_mean": 1.738539218902588, "train/policy_entropy_min": 0.9487718343734741, "train/policy_entropy_std": 0.11627081036567688, "train/policy_logprob_mag": 4.2568840980529785, "train/policy_logprob_max": -0.27151036262512207, "train/policy_logprob_mean": -1.736271858215332, "train/policy_logprob_min": -4.2568840980529785, "train/policy_logprob_std": 0.6171562671661377, "train/policy_randomness_mag": 0.997705340385437, "train/policy_randomness_max": 0.997705340385437, "train/policy_randomness_mean": 0.8934324979782104, "train/policy_randomness_min": 0.4875723123550415, "train/policy_randomness_std": 0.05975137650966644, "train/post_ent_mag": 105.81227111816406, "train/post_ent_max": 105.81227111816406, "train/post_ent_mean": 105.53813171386719, "train/post_ent_min": 105.23424530029297, "train/post_ent_std": 0.09986532479524612, "train/prior_ent_mag": 106.71485137939453, "train/prior_ent_max": 106.71485137939453, "train/prior_ent_mean": 105.6263656616211, "train/prior_ent_min": 104.57807922363281, "train/prior_ent_std": 0.3137233257293701, "train/rep_loss_mean": 10.569034576416016, "train/rep_loss_std": 0.37620946764945984, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.7781051397323608, "report/cont_loss_std": 0.2763713002204895, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.42578125, "report/cont_pos_loss": 0.7781051397323608, "report/cont_pred": 0.47621455788612366, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.54682445526123, "report/dyn_loss_std": 0.40304142236709595, "report/image_loss_mean": 4694.8447265625, "report/image_loss_std": 41.274864196777344, "report/model_loss_mean": 4707.49267578125, "report/model_loss_std": 41.25685119628906, "report/post_ent_mag": 105.82859802246094, "report/post_ent_max": 105.82859802246094, "report/post_ent_mean": 105.56645202636719, "report/post_ent_min": 105.2554931640625, "report/post_ent_std": 0.09145837277173996, "report/prior_ent_mag": 106.70166015625, "report/prior_ent_max": 106.70166015625, "report/prior_ent_mean": 105.63301086425781, "report/prior_ent_min": 104.45909881591797, "report/prior_ent_std": 0.30229589343070984, "report/rep_loss_mean": 10.54682445526123, "report/rep_loss_std": 0.40304142236709595, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.784313976764679, "eval/cont_loss_std": 0.28394782543182373, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.40625, "eval/cont_pos_loss": 0.784313976764679, "eval/cont_pred": 0.47415071725845337, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 10.582987785339355, "eval/dyn_loss_std": 0.411357045173645, "eval/image_loss_mean": 4695.79052734375, "eval/image_loss_std": 38.00345993041992, "eval/model_loss_mean": 4708.4658203125, "eval/model_loss_std": 37.99173355102539, "eval/post_ent_mag": 105.85134887695312, "eval/post_ent_max": 105.85134887695312, "eval/post_ent_mean": 105.5584945678711, "eval/post_ent_min": 105.29205322265625, "eval/post_ent_std": 0.0982842966914177, "eval/prior_ent_mag": 106.67900085449219, "eval/prior_ent_max": 106.67900085449219, "eval/prior_ent_mean": 105.57860565185547, "eval/prior_ent_min": 104.60459899902344, "eval/prior_ent_std": 0.3128471076488495, "eval/rep_loss_mean": 10.582987785339355, "eval/rep_loss_std": 0.411357045173645, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.8976494853183022e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.98377799987793e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.4742593017723101e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2240239552089146e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 151.896954536438, "timer/env.step_count": 196.0, "timer/env.step_total": 1.8026118278503418, "timer/env.step_frac": 0.011867333570653782, "timer/env.step_avg": 0.009196999121685418, "timer/env.step_min": 0.007193565368652344, "timer/env.step_max": 0.017021894454956055, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.13007760047912598, "timer/replay._sample_frac": 0.000856354236173459, "timer/replay._sample_avg": 0.0011614071471350534, "timer/replay._sample_min": 0.00038504600524902344, "timer/replay._sample_max": 0.018754959106445312, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.340938091278076, "timer/agent.save_frac": 0.01541135632654516, "timer/agent.save_avg": 2.340938091278076, "timer/agent.save_min": 2.340938091278076, "timer/agent.save_max": 2.340938091278076, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 23.116187572479248, "timer/agent.policy_frac": 0.15218335116082918, "timer/agent.policy_avg": 0.07971099162923878, "timer/agent.policy_min": 0.009514331817626953, "timer/agent.policy_max": 17.885738134384155, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.457069396972656e-05, "timer/dataset_train_frac": 2.275930684405758e-07, "timer/dataset_train_avg": 3.457069396972656e-05, "timer/dataset_train_min": 3.457069396972656e-05, "timer/dataset_train_max": 3.457069396972656e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 94.56863522529602, "timer/agent.train_frac": 0.6225841427427059, "timer/agent.train_avg": 94.56863522529602, "timer/agent.train_min": 94.56863522529602, "timer/agent.train_max": 94.56863522529602, "timer/agent.report_count": 2.0, "timer/agent.report_total": 25.911975145339966, "timer/agent.report_frac": 0.17058916832413543, "timer/agent.report_avg": 12.955987572669983, "timer/agent.report_min": 0.24618148803710938, "timer/agent.report_max": 25.665793657302856, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.506111145019531e-05, "timer/dataset_eval_frac": 2.966557926570264e-07, "timer/dataset_eval_avg": 4.506111145019531e-05, "timer/dataset_eval_min": 4.506111145019531e-05, "timer/dataset_eval_max": 4.506111145019531e-05}
{"step": 2312, "time": 287.5900049209595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 287.5984694957733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 287.60721731185913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 287.6145782470703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 287.62170934677124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 287.6289527416229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 287.6368134021759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 287.6443190574646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 359.4686508178711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 359.4794557094574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 359.4876515865326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 359.4959034919739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 359.50417971611023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 359.5121192932129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 359.51966190338135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 359.5297682285309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 430.51265263557434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 430.5208423137665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 430.52963399887085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 430.53906178474426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 430.5485212802887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 430.5562994480133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 430.5649402141571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 430.5737888813019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8952, "time": 493.4264106750488, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 502.89127230644226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 502.90048813819885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 502.9092445373535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 502.9189145565033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 502.9276406764984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 502.9357180595398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 502.94981265068054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 534.8164772987366, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 534.8330640792847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 534.8418803215027, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 534.849606513977, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 534.8570072650909, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 534.8648462295532, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 534.8745708465576, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 534.8799164295197, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11264, "time": 571.6764888763428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 580.5507771968842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 580.5592930316925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 580.5666737556458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 580.5740854740143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 580.5814592838287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 580.5887384414673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 580.5960295200348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13576, "time": 642.5687594413757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 651.8538537025452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 651.8622152805328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 651.8705673217773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 651.8785650730133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 651.8860936164856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 651.8935356140137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 651.9012989997864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 15720, "time": 708.6894381046295, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 15888, "time": 714.0673780441284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 723.0821583271027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 723.0905792713165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 723.0986204147339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 723.1062979698181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 723.1232628822327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 723.1314404010773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18032, "time": 781.0122382640839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18200, "time": 785.9887807369232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 795.3042397499084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 795.3128292560577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 795.320241689682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 795.3303961753845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 795.3381652832031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 795.3459870815277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 850.5375108718872, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 850.5453817844391, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 850.5524303913116, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 850.5596284866333, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 850.5665080547333, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 850.573326587677, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 850.5801787376404, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 850.5871951580048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20344, "time": 858.9694316387177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20512, "time": 864.3629477024078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 873.3247213363647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 873.3529689311981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 873.3819131851196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 873.4035866260529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 873.4314889907837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 873.4499523639679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22656, "time": 930.6731460094452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 22824, "time": 935.6133046150208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 944.9654183387756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 944.974746465683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 944.9825983047485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 944.989963054657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 944.9978530406952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 945.0056114196777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24560, "time": 989.6037859916687, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 25136, "time": 1008.0072946548462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1016.9381954669952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1016.9465126991272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1016.953920841217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1016.9611399173737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1016.9685039520264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1016.9757394790649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25720, "time": 1026.0024211406708, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 26872, "time": 1061.4391696453094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27448, "time": 1079.1174802780151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1088.4160702228546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1088.427553653717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1088.437471151352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1088.4463999271393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1088.4550137519836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28032, "time": 1097.3229761123657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29184, "time": 1132.9805083274841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29760, "time": 1150.929185628891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1159.913550376892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1159.922700881958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1159.931062221527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1159.9393603801727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1159.9473061561584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1161.7453796863556, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 30056, "time": 1166.1814467906952, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1166.1913015842438, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1166.1984167099, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1166.205638408661, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1166.2131342887878, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1166.2204284667969, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1166.2273993492126, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30344, "time": 1175.1874332427979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31496, "time": 1210.6482837200165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32072, "time": 1228.2544958591461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32248, "time": 1233.7645134925842, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1237.6657071113586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1237.6742663383484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1237.6895089149475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1237.7013297080994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32393, "time": 1239.2112016677856, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9984207153320312, "train/action_min": 0.0, "train/action_std": 2.000930452098449, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 7.482131865306958e-05, "train/actor_opt_grad_steps": 965.0, "train/actor_opt_loss": -4.528218669816852, "train/adv_mag": 9.950453072826715e-05, "train/adv_max": 9.945174524433192e-05, "train/adv_mean": 5.953525232878997e-05, "train/adv_min": 9.149576125448236e-06, "train/adv_std": 2.7661041604246674e-05, "train/cont_avg": 0.9970245361328125, "train/cont_loss_mean": 0.02441406306529596, "train/cont_loss_std": 0.29581347378629413, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.785696261421928, "train/cont_pos_acc": 0.9970906476179758, "train/cont_pos_loss": 0.007201766198901301, "train/cont_pred": 0.9941889575372139, "train/cont_rate": 0.9970245361328125, "train/dyn_loss_mean": 1.0634403036286433, "train/dyn_loss_std": 0.004597248084621697, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.4047159253774835, "train/extr_critic_critic_opt_grad_steps": 965.0, "train/extr_critic_critic_opt_loss": 5111.620389143626, "train/extr_critic_mag": 7.630822559197743e-05, "train/extr_critic_max": 7.630450030167897e-05, "train/extr_critic_mean": 7.586988119012079e-05, "train/extr_critic_min": 7.564450303713481e-05, "train/extr_critic_std": 9.657876778116266e-08, "train/extr_return_normed_mag": 0.00011688013835670201, "train/extr_return_normed_max": 0.00011687312968169129, "train/extr_return_normed_mean": 7.702252842704121e-05, "train/extr_return_normed_min": 2.678061218237826e-05, "train/extr_return_normed_std": 2.7655989540364165e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.00017526475104711475, "train/extr_return_raw_max": 0.00017525237718714107, "train/extr_return_raw_mean": 0.00013540177941913386, "train/extr_return_raw_min": 8.515985969451134e-05, "train/extr_return_raw_std": 2.7655989554517702e-05, "train/extr_reward_mag": 9.675820668538412e-06, "train/extr_reward_max": 9.67271625995636e-06, "train/extr_reward_mean": 9.637548148046614e-06, "train/extr_reward_min": 9.569029013315836e-06, "train/extr_reward_std": 1.3770085953435096e-08, "train/image_loss_mean": 25.519004712967824, "train/image_loss_std": 0.36371431526883197, "train/model_loss_mean": 26.29011629956464, "train/model_loss_std": 0.6024057422764599, "train/model_opt_grad_norm": 109.27147045934387, "train/model_opt_grad_steps": 955.0, "train/model_opt_loss": 500.4714958469073, "train/model_opt_model_opt_grad_overflow": 0.005208333333333333, "train/model_opt_model_opt_grad_scale": 14.394124348958334, "train/policy_entropy_mag": 1.945808820426464, "train/policy_entropy_max": 1.945808820426464, "train/policy_entropy_mean": 1.9412197365115087, "train/policy_entropy_min": 1.8418819413830836, "train/policy_entropy_std": 0.0035450927486332753, "train/policy_logprob_mag": 2.5080037203927836, "train/policy_logprob_max": -1.4180961089829605, "train/policy_logprob_mean": -1.941168478379647, "train/policy_logprob_min": -2.5080037203927836, "train/policy_logprob_std": 0.08405521822472413, "train/policy_randomness_mag": 0.999947987186412, "train/policy_randomness_max": 0.999947987186412, "train/policy_randomness_mean": 0.9975896558413903, "train/policy_randomness_min": 0.9465401329410573, "train/policy_randomness_std": 0.0018218173921316823, "train/post_ent_mag": 79.77374676863353, "train/post_ent_max": 79.77374676863353, "train/post_ent_mean": 79.6774316628774, "train/post_ent_min": 79.63085820277531, "train/post_ent_std": 0.018844717128862005, "train/prior_ent_mag": 85.33500552177429, "train/prior_ent_max": 85.33500552177429, "train/prior_ent_mean": 85.20039959748586, "train/prior_ent_min": 85.02095313866933, "train/prior_ent_std": 0.04672657275417199, "train/rep_loss_mean": 1.0634403036286433, "train/rep_loss_std": 0.004597248084621697, "train/reward_avg": 1.726150526337733e-05, "train/reward_loss_mean": 0.10863169131092339, "train/reward_loss_std": 0.019359519542037407, "train/reward_max_data": 0.016552734499176342, "train/reward_max_pred": 9.628633658091227e-06, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.10799701866956941, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.411651698025791, "train/reward_pred": 9.590017725713551e-06, "train/reward_rate": 6.103515625e-05, "train_stats/mean_log_entropy": 1.9286947080067225, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014702882617712021, "report/cont_loss_std": 0.24541747570037842, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.562440395355225, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038462562952190638, "report/cont_pred": 0.9961610436439514, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.3386373817920685, "report/image_loss_std": 0.08345441520214081, "report/model_loss_mean": 0.9539161920547485, "report/model_loss_std": 0.2646697461605072, "report/post_ent_mag": 63.814754486083984, "report/post_ent_max": 63.814754486083984, "report/post_ent_mean": 63.632080078125, "report/post_ent_min": 63.60773849487305, "report/post_ent_std": 0.02730189636349678, "report/prior_ent_mag": 71.41598510742188, "report/prior_ent_max": 71.41598510742188, "report/prior_ent_mean": 71.32688903808594, "report/prior_ent_min": 71.1247329711914, "report/prior_ent_std": 0.03477787598967552, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0005758795887231827, "report/reward_loss_std": 1.2485101024140022e-06, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.1828880310058594e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005758795887231827, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.162992652505636e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0038462569937109947, "eval/cont_loss_std": 2.7567655251914402e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038462569937109947, "eval/cont_pred": 0.9961610436439514, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3456965982913971, "eval/image_loss_std": 0.08582992851734161, "eval/model_loss_mean": 0.9501186609268188, "eval/model_loss_std": 0.08582974225282669, "eval/post_ent_mag": 63.818092346191406, "eval/post_ent_max": 63.818092346191406, "eval/post_ent_mean": 63.63136672973633, "eval/post_ent_min": 63.60758972167969, "eval/post_ent_std": 0.025842638686299324, "eval/prior_ent_mag": 71.42440795898438, "eval/prior_ent_max": 71.42440795898438, "eval/prior_ent_mean": 71.32621765136719, "eval/prior_ent_min": 71.1247329711914, "eval/prior_ent_std": 0.03334182873368263, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0005758400075137615, "eval/reward_loss_std": 1.2454953548513004e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.1948089599609375e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005758400075137615, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.16305086016655e-05, "eval/reward_rate": 0.0, "replay/size": 31889.0, "replay/inserts": 30832.0, "replay/samples": 30832.0, "replay/insert_wait_avg": 1.4044131772408042e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.665804077568114e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.310683451721825e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 974.6189334392548, "timer/env.step_count": 3854.0, "timer/env.step_total": 40.14989995956421, "timer/env.step_frac": 0.04119548531432941, "timer/env.step_avg": 0.010417721836939339, "timer/env.step_min": 0.008649826049804688, "timer/env.step_max": 0.03687858581542969, "timer/replay._sample_count": 30832.0, "timer/replay._sample_total": 16.775274515151978, "timer/replay._sample_frac": 0.017212136907657903, "timer/replay._sample_avg": 0.000544086485312402, "timer/replay._sample_min": 0.0003647804260253906, "timer/replay._sample_max": 0.025841712951660156, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4721.0, "timer/agent.policy_total": 52.910991191864014, "timer/agent.policy_frac": 0.054288901412114635, "timer/agent.policy_avg": 0.011207581273430208, "timer/agent.policy_min": 0.00961756706237793, "timer/agent.policy_max": 0.10108089447021484, "timer/dataset_train_count": 1927.0, "timer/dataset_train_total": 0.2191295623779297, "timer/dataset_train_frac": 0.00022483614350139999, "timer/dataset_train_avg": 0.00011371539303473259, "timer/dataset_train_min": 8.106231689453125e-05, "timer/dataset_train_max": 0.0005936622619628906, "timer/agent.train_count": 1927.0, "timer/agent.train_total": 865.6124227046967, "timer/agent.train_frac": 0.8881547372059624, "timer/agent.train_avg": 0.44920208754784463, "timer/agent.train_min": 0.43689846992492676, "timer/agent.train_max": 0.738217830657959, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4770355224609375, "timer/agent.report_frac": 0.0004894585012601439, "timer/agent.report_avg": 0.23851776123046875, "timer/agent.report_min": 0.23143410682678223, "timer/agent.report_max": 0.24560141563415527, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 3.6694122839409595e-08, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05, "fps": 31.634469517388393}
{"step": 32656, "time": 1247.3434143066406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33472, "time": 1273.0537729263306, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 33808, "time": 1283.338633775711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34384, "time": 1301.1008760929108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34560, "time": 1306.4912023544312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1309.9635789394379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1309.9728453159332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1309.9814193248749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34968, "time": 1318.9119141101837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35784, "time": 1343.9652140140533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36120, "time": 1354.429770231247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36696, "time": 1372.147715330124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36872, "time": 1377.5715234279633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1381.6602940559387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1381.6798095703125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1381.6919934749603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37280, "time": 1390.598307609558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38096, "time": 1416.2136628627777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38432, "time": 1426.4972641468048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38712, "time": 1435.0442850589752, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 39008, "time": 1444.5566263198853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39184, "time": 1449.9840097427368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1453.4735915660858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1453.4826996326447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39592, "time": 1462.3533086776733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 1482.5193197727203, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1482.5282521247864, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1482.5352942943573, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1482.5420229434967, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1482.5486290454865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1482.5553169250488, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1482.5623235702515, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1482.5694391727448, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40408, "time": 1493.8767535686493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40744, "time": 1504.3283700942993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40744, "time": 1504.33753490448, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 40984, "time": 1512.249225139618, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 41024, "time": 1513.6929132938385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41496, "time": 1528.0074639320374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1532.0327503681183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1532.0411064624786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42720, "time": 1566.114025592804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43056, "time": 1576.4194073677063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43056, "time": 1576.4284245967865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43296, "time": 1583.7326922416687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43336, "time": 1584.7477955818176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43808, "time": 1599.532885313034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1602.9982960224152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1603.0070612430573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45032, "time": 1636.955708026886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45368, "time": 1647.313279390335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45368, "time": 1647.3245947360992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45608, "time": 1654.800880432129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45648, "time": 1656.2554860115051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45936, "time": 1665.0778269767761, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 46120, "time": 1670.514088153839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1674.5065984725952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47176, "time": 1703.0011818408966, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 47344, "time": 1708.376387834549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47680, "time": 1718.7110764980316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47920, "time": 1726.0474610328674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47960, "time": 1727.0723643302917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48248, "time": 1735.8862483501434, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 48432, "time": 1741.8524706363678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1745.3694212436676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49488, "time": 1775.0688562393188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49656, "time": 1779.972987651825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49992, "time": 1790.347938299179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 1795.3497686386108, "eval_episode/length": 198.0, "eval_episode/score": 0.3812499940395355, "eval_episode/reward_rate": 0.005025125628140704}
{"step": 50024, "time": 1797.1857862472534, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1797.1946139335632, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1797.2039177417755, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1797.2125253677368, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1797.2195501327515, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1797.22665143013, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1797.233166694641, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50232, "time": 1803.6273212432861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50272, "time": 1805.0723524093628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50560, "time": 1813.8577444553375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50744, "time": 1819.2568199634552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1823.1632461547852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51800, "time": 1851.727246761322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51968, "time": 1857.101580619812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52304, "time": 1867.5216150283813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52544, "time": 1874.8214094638824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52584, "time": 1875.8306896686554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52872, "time": 1884.6699681282043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53056, "time": 1890.6752939224243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1894.14675116539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54112, "time": 1923.2429876327515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54280, "time": 1928.163138628006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54616, "time": 1938.5219700336456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54856, "time": 1945.9574625492096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54896, "time": 1947.42822599411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55184, "time": 1956.5161230564117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55368, "time": 1962.632576227188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1966.608643770218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56424, "time": 1995.267270565033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56592, "time": 2000.6771085262299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56928, "time": 2011.1454215049744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57168, "time": 2018.4908578395844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57208, "time": 2019.4946763515472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57496, "time": 2028.8296358585358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57680, "time": 2034.7047350406647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2038.1628522872925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58736, "time": 2067.1657259464264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58904, "time": 2072.1810200214386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59240, "time": 2082.4769711494446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59480, "time": 2089.786430120468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59520, "time": 2091.2254338264465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59808, "time": 2100.0435190200806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59992, "time": 2105.7210144996643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 2108.609926700592, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 60008, "time": 2112.812230825424, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2112.820289373398, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2112.8278682231903, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2112.835719347, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2112.842832803726, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2112.849748849869, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2112.8564834594727, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60112, "time": 2116.267812013626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61048, "time": 2144.886866092682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61216, "time": 2150.2056562900543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61552, "time": 2160.53525185585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61792, "time": 2167.830973148346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61832, "time": 2168.821398973465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62120, "time": 2177.5387465953827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62304, "time": 2183.361242055893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2186.826000213623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63360, "time": 2215.827332496643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63528, "time": 2220.8092029094696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63864, "time": 2231.0817959308624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64104, "time": 2238.40189409256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64105, "time": 2239.433153629303, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.997652446804334, "train/action_min": 0.0, "train/action_std": 1.9994539166215677, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00010843271507408315, "train/actor_opt_grad_steps": 2920.0, "train/actor_opt_loss": -1.3721781193358291, "train/adv_mag": 0.0003885673944038063, "train/adv_max": 0.0003885673944038063, "train/adv_mean": 0.0002263409989984266, "train/adv_min": 2.2642470044481695e-05, "train/adv_std": 0.00010526792767683474, "train/cont_avg": 0.9964078203517588, "train/cont_loss_mean": 0.023925145583732717, "train/cont_loss_std": 0.32579697455119816, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.693913114567597, "train/cont_pos_acc": 0.9999999838258753, "train/cont_pos_loss": 0.003464106706687104, "train/cont_pred": 0.9965422288257273, "train/cont_rate": 0.9964078203517588, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08464791988907149, "train/extr_critic_critic_opt_grad_steps": 2920.0, "train/extr_critic_critic_opt_loss": 2650.73139501217, "train/extr_critic_mag": 0.004948188911131279, "train/extr_critic_max": 0.004948188911131279, "train/extr_critic_mean": 0.004927061695310675, "train/extr_critic_min": 0.004912696292052916, "train/extr_critic_std": 5.847377093945324e-06, "train/extr_return_normed_mag": 0.0007562030103272903, "train/extr_return_normed_max": 0.0007562030103272903, "train/extr_return_normed_mean": 0.0006005138822190052, "train/extr_return_normed_min": 0.0004023635600829244, "train/extr_return_normed_std": 0.00010522003342990118, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.005309103909720802, "train/extr_return_raw_max": 0.005309103909720802, "train/extr_return_raw_mean": 0.005153415003913132, "train/extr_return_raw_min": 0.004955264459476436, "train/extr_return_raw_std": 0.00010522003300943126, "train/extr_reward_mag": 5.06387883095286e-05, "train/extr_reward_max": 5.06387883095286e-05, "train/extr_reward_mean": 5.058349189088193e-05, "train/extr_reward_min": 5.049741447870456e-05, "train/extr_reward_std": 2.2768802277420022e-08, "train/image_loss_mean": 0.2704276462745427, "train/image_loss_std": 0.08694309280745348, "train/model_loss_mean": 0.8961906855429836, "train/model_loss_std": 0.37104662211995626, "train/model_opt_grad_norm": 85.21647078547646, "train/model_opt_grad_steps": 2910.0, "train/model_opt_loss": 50.01226046576572, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 55.84563442211055, "train/policy_entropy_mag": 1.9458894651738843, "train/policy_entropy_max": 1.9458894651738843, "train/policy_entropy_mean": 1.9448717521063645, "train/policy_entropy_min": 1.9202196568100895, "train/policy_entropy_std": 0.0008219844739458257, "train/policy_logprob_mag": 2.2371939211035494, "train/policy_logprob_max": -1.661894801274017, "train/policy_logprob_mean": -1.9448488435553546, "train/policy_logprob_min": -2.2371939211035494, "train/policy_logprob_std": 0.045344750392227316, "train/policy_randomness_mag": 0.9999894299099793, "train/policy_randomness_max": 0.9999894299099793, "train/policy_randomness_mean": 0.9994664297031997, "train/policy_randomness_min": 0.986797757484206, "train/policy_randomness_std": 0.0004224164761549058, "train/post_ent_mag": 54.28468907418563, "train/post_ent_max": 54.28468907418563, "train/post_ent_mean": 54.12110918131306, "train/post_ent_min": 54.09874644830598, "train/post_ent_std": 0.024027542028594855, "train/prior_ent_mag": 63.0868822797459, "train/prior_ent_max": 63.0868822797459, "train/prior_ent_mean": 62.97218224990308, "train/prior_ent_min": 62.91021028834971, "train/prior_ent_std": 0.028072454662403868, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 6.10504909339548e-05, "train/reward_loss_mean": 0.001837868938437808, "train/reward_loss_std": 0.0429850405259277, "train/reward_max_data": 0.057616205109124206, "train/reward_max_pred": 5.0641184476152736e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00040712830977369306, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.043810997009277, "train/reward_pred": 5.057275449697995e-05, "train/reward_rate": 0.0001423131281407035, "train_stats/mean_log_entropy": 1.9380580722738843, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02011190727353096, "report/cont_loss_std": 0.30162307620048523, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.584491729736328, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037621110677719116, "report/cont_pred": 0.9962450265884399, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2739168703556061, "report/image_loss_std": 0.07914561033248901, "report/model_loss_mean": 0.8943090438842773, "report/model_loss_std": 0.3130094110965729, "report/post_ent_mag": 46.67637634277344, "report/post_ent_max": 46.67637634277344, "report/post_ent_mean": 46.53498840332031, "report/post_ent_min": 46.50810241699219, "report/post_ent_std": 0.02008821815252304, "report/prior_ent_mag": 57.15519714355469, "report/prior_ent_max": 57.15519714355469, "report/prior_ent_mean": 57.05713653564453, "report/prior_ent_min": 57.0147819519043, "report/prior_ent_std": 0.026984447613358498, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0002802656963467598, "report/reward_loss_std": 4.770471946358157e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 5.316734313964844e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002802656963467598, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.295046139508486e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003762098727747798, "eval/cont_loss_std": 6.661584848188795e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003762098727747798, "eval/cont_pred": 0.9962450265884399, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2610520124435425, "eval/image_loss_std": 0.07415539026260376, "eval/model_loss_mean": 0.8650944232940674, "eval/model_loss_std": 0.07415517419576645, "eval/post_ent_mag": 46.68042755126953, "eval/post_ent_max": 46.68042755126953, "eval/post_ent_mean": 46.533573150634766, "eval/post_ent_min": 46.50449752807617, "eval/post_ent_std": 0.018669605255126953, "eval/prior_ent_mag": 57.155826568603516, "eval/prior_ent_max": 57.155826568603516, "eval/prior_ent_mean": 57.05424118041992, "eval/prior_ent_min": 57.01116943359375, "eval/prior_ent_std": 0.024205103516578674, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00028027454391121864, "eval/reward_loss_std": 4.839274083678902e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 5.316734313964844e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00028027454391121864, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.2949413657188416e-05, "eval/reward_rate": 0.0, "replay/size": 63601.0, "replay/inserts": 31712.0, "replay/samples": 31712.0, "replay/insert_wait_avg": 1.4218654930892313e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.836644208274864e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2750375367090914e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.203488111496, "timer/env.step_count": 3964.0, "timer/env.step_total": 40.88920831680298, "timer/env.step_frac": 0.04088088954179384, "timer/env.step_avg": 0.010315138324117805, "timer/env.step_min": 0.008546590805053711, "timer/env.step_max": 0.039762258529663086, "timer/replay._sample_count": 31712.0, "timer/replay._sample_total": 17.521583080291748, "timer/replay._sample_frac": 0.017518018371816116, "timer/replay._sample_avg": 0.0005525221707962836, "timer/replay._sample_min": 0.00034499168395996094, "timer/replay._sample_max": 0.026484251022338867, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4831.0, "timer/agent.policy_total": 53.76492261886597, "timer/agent.policy_frac": 0.05375398432211088, "timer/agent.policy_avg": 0.011129149786558884, "timer/agent.policy_min": 0.009142875671386719, "timer/agent.policy_max": 0.08924269676208496, "timer/dataset_train_count": 1982.0, "timer/dataset_train_total": 0.23320293426513672, "timer/dataset_train_frac": 0.0002331554898948131, "timer/dataset_train_avg": 0.00011766041083003871, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0010976791381835938, "timer/agent.train_count": 1982.0, "timer/agent.train_total": 888.8638036251068, "timer/agent.train_frac": 0.8886829672063914, "timer/agent.train_avg": 0.44846811484616894, "timer/agent.train_min": 0.4364438056945801, "timer/agent.train_max": 0.8671841621398926, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.476870059967041, "timer/agent.report_frac": 0.0004767730423210469, "timer/agent.report_avg": 0.2384350299835205, "timer/agent.report_min": 0.23073816299438477, "timer/agent.report_max": 0.24613189697265625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.527877089656561e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 31.705015658470884}
{"step": 64144, "time": 2240.707672595978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64432, "time": 2249.725373983383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64616, "time": 2255.1885392665863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2259.0892271995544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65672, "time": 2288.2010023593903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65840, "time": 2293.6019191741943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66176, "time": 2303.888659477234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66416, "time": 2311.3905823230743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66456, "time": 2312.403083086014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66744, "time": 2321.2768399715424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66928, "time": 2327.137199163437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2330.620355129242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67984, "time": 2359.5267379283905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68152, "time": 2364.4885430336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68488, "time": 2375.011684656143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68728, "time": 2382.3813993930817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68768, "time": 2383.8593294620514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69056, "time": 2392.6759362220764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69240, "time": 2398.116046190262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69360, "time": 2402.114589691162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 2425.35645198822, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 70096, "time": 2429.3893897533417, "eval_episode/length": 216.0, "eval_episode/score": 0.32499998807907104, "eval_episode/reward_rate": 0.004608294930875576}
{"step": 70096, "time": 2430.916579246521, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2430.9240906238556, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2430.9309916496277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2430.9382972717285, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2430.946015357971, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2430.95365190506, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70296, "time": 2436.861970424652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70464, "time": 2442.3433969020844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70800, "time": 2452.6234817504883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71040, "time": 2460.0251939296722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71080, "time": 2461.0288619995117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71368, "time": 2469.845526456833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71552, "time": 2477.2661304473877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 2480.7147126197815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72608, "time": 2509.6941344738007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72776, "time": 2514.6260006427765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73112, "time": 2524.983143568039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73192, "time": 2527.431207895279, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 73352, "time": 2532.37659406662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73392, "time": 2533.837133169174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73680, "time": 2542.6259837150574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73864, "time": 2548.707707643509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74920, "time": 2581.2343928813934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75088, "time": 2586.646986246109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75424, "time": 2597.0171864032745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75504, "time": 2599.5001130104065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75664, "time": 2604.4213383197784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75704, "time": 2605.4291529655457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75992, "time": 2614.423250436783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76176, "time": 2620.2741193771362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77232, "time": 2652.7228157520294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77400, "time": 2657.6807160377502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77736, "time": 2668.0158157348633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77816, "time": 2670.557635784149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77976, "time": 2675.484831571579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78016, "time": 2676.9384446144104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78152, "time": 2680.912102460861, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 78304, "time": 2685.8125483989716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78488, "time": 2691.2225902080536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79544, "time": 2723.6705260276794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79712, "time": 2729.215684890747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80064, "time": 2740.057518720627, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 2746.4007663726807, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2746.4084239006042, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2746.4157059192657, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2746.422078847885, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2746.428291797638, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2746.434711933136, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2746.441084623337, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2746.4472517967224, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80128, "time": 2747.931914806366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80288, "time": 2755.844957590103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80328, "time": 2756.905702829361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80616, "time": 2765.8601458072662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80800, "time": 2771.733462333679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81856, "time": 2804.1525616645813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82024, "time": 2809.5826404094696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82376, "time": 2820.460132598877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82440, "time": 2822.4129388332367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82600, "time": 2827.31379365921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82640, "time": 2828.7690863609314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82928, "time": 2837.5805530548096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83112, "time": 2843.0172984600067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84168, "time": 2875.518031835556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84336, "time": 2880.9633798599243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84688, "time": 2891.7997777462006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84752, "time": 2893.780074596405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84912, "time": 2898.6887447834015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84952, "time": 2899.684725522995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85240, "time": 2908.561499595642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85424, "time": 2915.010479927063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86480, "time": 2947.434948205948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86648, "time": 2952.4031522274017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87000, "time": 2963.245062828064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87064, "time": 2965.2043619155884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87224, "time": 2970.2193574905396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87264, "time": 2971.6595809459686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87552, "time": 2980.4334588050842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87736, "time": 2985.816714525223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88792, "time": 3018.2782213687897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88960, "time": 3023.6546535491943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89312, "time": 3034.6383945941925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89376, "time": 3036.600184202194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89536, "time": 3041.5355484485626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89576, "time": 3042.56023979187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89864, "time": 3051.307592153549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90048, "time": 3057.197395801544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 3064.589952468872, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3064.606282234192, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3064.621399641037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3064.6438295841217, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3064.672648191452, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3064.7020993232727, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3064.728029489517, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3064.747010231018, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 91104, "time": 3097.264167070389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91272, "time": 3102.1754145622253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91624, "time": 3112.8919632434845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91688, "time": 3114.8676397800446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91848, "time": 3119.887220144272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91888, "time": 3121.3429157733917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92176, "time": 3130.1877825260162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92360, "time": 3135.609381914139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93416, "time": 3168.1373665332794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93584, "time": 3173.504639148712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93936, "time": 3184.405625104904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94000, "time": 3186.3977661132812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94160, "time": 3191.2815492153168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94200, "time": 3192.308451652527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94488, "time": 3201.074147462845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94672, "time": 3206.9444143772125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95705, "time": 3239.4345581531525, "train_stats/mean_log_entropy": 1.9383204289532583, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0000749771970177, "train/action_min": 0.0, "train/action_std": 1.999306494209367, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 5.140471586375571e-05, "train/actor_opt_grad_steps": 4900.0, "train/actor_opt_loss": -3.726210140268588, "train/adv_mag": 0.0002092742384765959, "train/adv_max": 0.00020263707123432064, "train/adv_mean": 0.00010315794577366844, "train/adv_min": -1.99700237682023e-05, "train/adv_std": 5.178775693377875e-05, "train/cont_avg": 0.9967133962563451, "train/cont_loss_mean": 0.022157442224150534, "train/cont_loss_std": 0.3083445995810941, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.665506781724395, "train/cont_pos_acc": 0.9999999842667943, "train/cont_pos_loss": 0.003541623316657952, "train/cont_pred": 0.9964648246160014, "train/cont_rate": 0.9967133962563451, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.023055505333704693, "train/extr_critic_critic_opt_grad_steps": 4900.0, "train/extr_critic_critic_opt_loss": 5066.320468650857, "train/extr_critic_mag": 0.01149463048441156, "train/extr_critic_max": 0.01149463048441156, "train/extr_critic_mean": 0.011451634384578255, "train/extr_critic_min": 0.01141967991281887, "train/extr_critic_std": 1.3153705313339133e-05, "train/extr_return_normed_mag": 0.00038597318651107363, "train/extr_return_normed_max": 0.0003851824652800705, "train/extr_return_normed_mean": 0.00030285412394224863, "train/extr_return_normed_min": 0.00019648722207485722, "train/extr_return_normed_std": 5.064572926666035e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.011637320382719113, "train/extr_return_raw_max": 0.011637320382719113, "train/extr_return_raw_mean": 0.011554992559181555, "train/extr_return_raw_min": 0.0114486251395139, "train/extr_return_raw_std": 5.0645729354378115e-05, "train/extr_reward_mag": 5.076681901960808e-05, "train/extr_reward_max": 5.076681901960808e-05, "train/extr_reward_mean": 5.071623901837165e-05, "train/extr_reward_min": 5.0673630031837425e-05, "train/extr_reward_std": 2.0866110376492588e-08, "train/image_loss_mean": 0.26221832277508555, "train/image_loss_std": 0.08637877330562185, "train/model_loss_mean": 0.8863059019074222, "train/model_loss_std": 0.36394248762862935, "train/model_opt_grad_norm": 72.30610831013792, "train/model_opt_grad_steps": 4890.0, "train/model_opt_loss": 196.00626229997818, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 221.28807106598984, "train/policy_entropy_mag": 1.9458994036398563, "train/policy_entropy_max": 1.9458994036398563, "train/policy_entropy_mean": 1.9453583108592154, "train/policy_entropy_min": 1.93227509919762, "train/policy_entropy_std": 0.00044231399448191376, "train/policy_logprob_mag": 2.150670525991372, "train/policy_logprob_max": -1.7388327866036275, "train/policy_logprob_mean": -1.9453196047526327, "train/policy_logprob_min": -2.150670525991372, "train/policy_logprob_std": 0.03309302517038009, "train/policy_randomness_mag": 0.9999945396699276, "train/policy_randomness_max": 0.9999945396699276, "train/policy_randomness_mean": 0.9997164658483515, "train/policy_randomness_min": 0.9929930298461527, "train/policy_randomness_std": 0.00022730443691350237, "train/post_ent_mag": 43.39830323040183, "train/post_ent_max": 43.39830323040183, "train/post_ent_mean": 43.21402748224094, "train/post_ent_min": 43.18913501410315, "train/post_ent_std": 0.027263869408536985, "train/prior_ent_mag": 47.01282869135668, "train/prior_ent_max": 47.01282869135668, "train/prior_ent_mean": 46.91310867077203, "train/prior_ent_min": 46.07877822333786, "train/prior_ent_std": 0.14733880485034534, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 7.406321799927415e-05, "train/reward_loss_mean": 0.0019301151818959846, "train/reward_loss_std": 0.05268708501603212, "train/reward_max_data": 0.07085977112732562, "train/reward_max_pred": 5.142458804367762e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00024979608753923003, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.919533342123032, "train/reward_pred": 5.1330783886617514e-05, "train/reward_rate": 0.00016854378172588832, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020013852044939995, "report/cont_loss_std": 0.31520527601242065, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.834959030151367, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002927824854850769, "report/cont_pred": 0.9970762729644775, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2618755102157593, "report/image_loss_std": 0.08378855139017105, "report/model_loss_mean": 0.8820397853851318, "report/model_loss_std": 0.3222070336341858, "report/post_ent_mag": 39.5748291015625, "report/post_ent_max": 39.5748291015625, "report/post_ent_mean": 39.46405792236328, "report/post_ent_min": 39.42974853515625, "report/post_ent_std": 0.016037212684750557, "report/prior_ent_mag": 43.67481231689453, "report/prior_ent_max": 43.67481231689453, "report/prior_ent_mean": 43.58727264404297, "report/prior_ent_min": 42.486515045166016, "report/prior_ent_std": 0.18821363151073456, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001503857783973217, "report/reward_loss_std": 2.3166496987414575e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.910064697265625e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001503857783973217, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.90269560739398e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.002927824854850769, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002927824854850769, "eval/cont_pred": 0.9970762729644775, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25884777307510376, "eval/image_loss_std": 0.08105725795030594, "eval/model_loss_mean": 0.8619259595870972, "eval/model_loss_std": 0.08105725049972534, "eval/post_ent_mag": 39.57649230957031, "eval/post_ent_max": 39.57649230957031, "eval/post_ent_mean": 39.46405792236328, "eval/post_ent_min": 39.43194580078125, "eval/post_ent_std": 0.015147087164223194, "eval/prior_ent_mag": 43.674983978271484, "eval/prior_ent_max": 43.674983978271484, "eval/prior_ent_mean": 43.59623718261719, "eval/prior_ent_min": 42.486515045166016, "eval/prior_ent_std": 0.17344540357589722, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001503676176071167, "eval/reward_loss_std": 2.2647803632480645e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.910064697265625e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001503676176071167, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.902241587638855e-05, "eval/reward_rate": 0.0, "replay/size": 95201.0, "replay/inserts": 31600.0, "replay/samples": 31600.0, "replay/insert_wait_avg": 1.4226044280619561e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.867737613146818e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.298686899803364e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9862415790558, "timer/env.step_count": 3950.0, "timer/env.step_total": 40.505019426345825, "timer/env.step_frac": 0.04050557671912092, "timer/env.step_avg": 0.01025443529780907, "timer/env.step_min": 0.008393049240112305, "timer/env.step_max": 0.0706944465637207, "timer/replay._sample_count": 31600.0, "timer/replay._sample_total": 17.611005544662476, "timer/replay._sample_frac": 0.017611247847623718, "timer/replay._sample_avg": 0.0005573103020462809, "timer/replay._sample_min": 0.00038886070251464844, "timer/replay._sample_max": 0.012352228164672852, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4817.0, "timer/agent.policy_total": 53.855844497680664, "timer/agent.policy_frac": 0.05385658547925431, "timer/agent.policy_avg": 0.01118037045831029, "timer/agent.policy_min": 0.009256839752197266, "timer/agent.policy_max": 0.09912276268005371, "timer/dataset_train_count": 1975.0, "timer/dataset_train_total": 0.2311108112335205, "timer/dataset_train_frac": 0.00023111399099709474, "timer/dataset_train_avg": 0.00011701813227013697, "timer/dataset_train_min": 0.00010013580322265625, "timer/dataset_train_max": 0.0005195140838623047, "timer/agent.train_count": 1975.0, "timer/agent.train_total": 885.1780123710632, "timer/agent.train_frac": 0.8851901911903293, "timer/agent.train_avg": 0.4481913986688928, "timer/agent.train_min": 0.4371051788330078, "timer/agent.train_max": 0.9982221126556396, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4790630340576172, "timer/agent.report_frac": 0.0004790696252991836, "timer/agent.report_avg": 0.2395315170288086, "timer/agent.report_min": 0.22969532012939453, "timer/agent.report_max": 0.24936771392822266, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 3.576327891147998e-08, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05, "fps": 31.5998927911581}
{"step": 95728, "time": 3240.1192865371704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95896, "time": 3245.1653299331665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96248, "time": 3255.9381833076477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96312, "time": 3257.9164624214172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96472, "time": 3262.8102321624756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96512, "time": 3264.2589526176453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96800, "time": 3273.171377658844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96984, "time": 3281.806845664978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97856, "time": 3308.7314977645874, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 98040, "time": 3314.144599676132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98208, "time": 3319.5100152492523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98368, "time": 3324.909206390381, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 98560, "time": 3333.0899996757507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98624, "time": 3335.084148168564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99112, "time": 3349.9144628047943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99296, "time": 3355.768532514572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 3384.553318977356, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3384.560892343521, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3384.567638874054, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3384.5742206573486, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3384.580545902252, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3384.5869541168213, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3384.593839406967, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3384.600730895996, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100168, "time": 3388.053696870804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100352, "time": 3394.016284942627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100520, "time": 3398.931843519211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100680, "time": 3403.824488401413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100872, "time": 3409.703832387924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100936, "time": 3411.678304672241, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101424, "time": 3427.043746948242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101608, "time": 3432.500372171402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102480, "time": 3459.4436416625977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102664, "time": 3464.865439891815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102832, "time": 3470.216461658478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102992, "time": 3475.1971633434296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103184, "time": 3481.2209000587463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103248, "time": 3483.1946489810944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103736, "time": 3497.9111833572388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103920, "time": 3503.7524960041046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104792, "time": 3530.284183740616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104976, "time": 3536.1409571170807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105144, "time": 3541.188727617264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105304, "time": 3546.1227810382843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105496, "time": 3552.030366897583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105560, "time": 3554.0057425498962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106048, "time": 3569.2707595825195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106232, "time": 3574.7113358974457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107104, "time": 3602.291499376297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107288, "time": 3607.701342821121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107456, "time": 3613.0648806095123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107616, "time": 3617.9733498096466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107808, "time": 3623.8905699253082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107872, "time": 3625.8444108963013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108360, "time": 3640.7563152313232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108544, "time": 3646.627679347992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109416, "time": 3673.325080394745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109600, "time": 3679.29439163208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109768, "time": 3684.243554353714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109928, "time": 3689.2690465450287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 3698.7832341194153, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.805327653885, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.8282186985016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.8369166851044, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.8443541526794, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.8514518737793, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.8584883213043, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3698.8657484054565, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110120, "time": 3701.3389427661896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110184, "time": 3703.290850877762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110672, "time": 3718.4772095680237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110856, "time": 3723.9377353191376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111728, "time": 3750.936705827713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111912, "time": 3756.3642535209656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112080, "time": 3761.711492061615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112240, "time": 3766.5982711315155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112432, "time": 3772.471575975418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112496, "time": 3774.4243865013123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112984, "time": 3789.263683795929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113168, "time": 3795.136432170868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113800, "time": 3814.387680053711, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 114040, "time": 3821.790801048279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114176, "time": 3826.1559031009674, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 114224, "time": 3827.645306825638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114744, "time": 3843.936854839325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114808, "time": 3845.8882551193237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115296, "time": 3861.019054174423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115480, "time": 3866.470249414444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115936, "time": 3880.6804523468018, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 116112, "time": 3886.0540025234222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116352, "time": 3893.3312277793884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116488, "time": 3897.2638807296753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116536, "time": 3898.8183157444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117056, "time": 3914.947461128235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117120, "time": 3916.9327533245087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117608, "time": 3931.670647382736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118136, "time": 3947.819201231003, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 118248, "time": 3951.2877418994904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118424, "time": 3956.702488422394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118664, "time": 3964.2069623470306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118848, "time": 3970.1022641658783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119368, "time": 3985.8072044849396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119432, "time": 3987.7580320835114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119920, "time": 4002.980933904648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 4010.621370792389, "eval_episode/length": 235.0, "eval_episode/score": 0.265625, "eval_episode/reward_rate": 0.00423728813559322}
{"step": 120016, "time": 4011.705897092819, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4011.713833808899, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4011.7208251953125, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4011.7279975414276, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4011.7349026203156, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4011.74161028862, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4011.7481639385223, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120448, "time": 4025.108762741089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120560, "time": 4028.530961751938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120736, "time": 4033.9388201236725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120976, "time": 4041.3070056438446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121160, "time": 4046.7571103572845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121680, "time": 4063.0966606140137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121744, "time": 4065.0703172683716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122232, "time": 4079.9122397899628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122760, "time": 4096.053498268127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122872, "time": 4099.502068042755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123048, "time": 4105.42596912384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123288, "time": 4112.892306804657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123472, "time": 4118.772141456604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123992, "time": 4134.47385597229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124056, "time": 4136.427279472351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124544, "time": 4151.724479913712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125072, "time": 4167.964683055878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125184, "time": 4171.4885511398315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125360, "time": 4176.904802560806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125600, "time": 4184.294755220413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125784, "time": 4189.853249788284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126304, "time": 4206.07133936882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126368, "time": 4208.0562472343445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126856, "time": 4222.804273843765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127369, "time": 4239.619149684906, "train_stats/mean_log_entropy": 1.9384344603334154, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0002330433238638, "train/action_min": 0.0, "train/action_std": 1.999860254201022, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 3.436799440093793e-05, "train/actor_opt_grad_steps": 6875.0, "train/actor_opt_loss": -4.751504912370383, "train/adv_mag": 0.0001580945376043368, "train/adv_max": 0.0001355273404506722, "train/adv_mean": 4.942561468189037e-05, "train/adv_min": -5.191984125460037e-05, "train/adv_std": 3.728638081337972e-05, "train/cont_avg": 0.9964932528409091, "train/cont_loss_mean": 0.023389515773901207, "train/cont_loss_std": 0.3247470304108764, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.695436657089548, "train/cont_pos_acc": 0.9999999837441877, "train/cont_pos_loss": 0.0034117537404815055, "train/cont_pred": 0.9965941842758295, "train/cont_rate": 0.9964932528409091, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.009728049724174645, "train/extr_critic_critic_opt_grad_steps": 6875.0, "train/extr_critic_critic_opt_loss": 5899.377924755366, "train/extr_critic_mag": 0.014304383836611353, "train/extr_critic_max": 0.014304383836611353, "train/extr_critic_mean": 0.014252141611932806, "train/extr_critic_min": 0.01420845648255011, "train/extr_critic_std": 1.8477289010186062e-05, "train/extr_return_normed_mag": 0.00023976285857233134, "train/extr_return_normed_max": 0.00022386076549688974, "train/extr_return_normed_mean": 0.0001590174525684881, "train/extr_return_normed_min": 8.482377355297406e-05, "train/extr_return_normed_std": 3.46154205690576e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.014366407958658957, "train/extr_return_raw_max": 0.014366407958658957, "train/extr_return_raw_mean": 0.01430156541461445, "train/extr_return_raw_min": 0.014227370966715043, "train/extr_return_raw_std": 3.461542029862073e-05, "train/extr_reward_mag": 5.0679601804174555e-05, "train/extr_reward_max": 5.0679601804174555e-05, "train/extr_reward_mean": 5.064699781551191e-05, "train/extr_reward_min": 5.060855788413924e-05, "train/extr_reward_std": 1.1607663017084455e-08, "train/image_loss_mean": 0.25700638006732923, "train/image_loss_std": 0.08532808341010652, "train/model_loss_mean": 0.8817698762874411, "train/model_loss_std": 0.3650220970463271, "train/model_opt_grad_norm": 61.23805380349207, "train/model_opt_grad_steps": 6865.0, "train/model_opt_loss": 769.449419734454, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 872.790404040404, "train/policy_entropy_mag": 1.9459025257765645, "train/policy_entropy_max": 1.9459025257765645, "train/policy_entropy_mean": 1.945489541448728, "train/policy_entropy_min": 1.9370306146265281, "train/policy_entropy_std": 0.00031984813518427086, "train/policy_logprob_mag": 2.115561174623894, "train/policy_logprob_max": -1.7789926727612813, "train/policy_logprob_mean": -1.9454859790175851, "train/policy_logprob_min": -2.115561174623894, "train/policy_logprob_std": 0.029014028975683632, "train/policy_randomness_mag": 0.9999961422549354, "train/policy_randomness_max": 0.9999961422549354, "train/policy_randomness_mean": 0.9997838970386621, "train/policy_randomness_min": 0.9954368818287898, "train/policy_randomness_std": 0.00016436942597566586, "train/post_ent_mag": 39.095276996342825, "train/post_ent_max": 39.095276996342825, "train/post_ent_mean": 39.0545377442331, "train/post_ent_min": 38.938551450016526, "train/post_ent_std": 0.02914666940429897, "train/prior_ent_mag": 43.77459462483724, "train/prior_ent_max": 43.77459462483724, "train/prior_ent_mean": 43.685297359119765, "train/prior_ent_min": 42.6131389887646, "train/prior_ent_std": 0.1888548457863355, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 4.361855852296529e-05, "train/reward_loss_mean": 0.0013739623463326933, "train/reward_loss_std": 0.03851610870840545, "train/reward_max_data": 0.04466540392751646, "train/reward_max_pred": 5.071090929435961e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001999913563280404, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.917871594429016, "train/reward_pred": 5.0656654462782725e-05, "train/reward_rate": 0.00011837121212121212, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.003435499034821987, "report/cont_loss_std": 6.984919309616089e-10, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003435499034821987, "report/cont_pred": 0.9965705275535583, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2741625905036926, "report/image_loss_std": 0.08842823654413223, "report/model_loss_mean": 0.8778116703033447, "report/model_loss_std": 0.08842823654413223, "report/post_ent_mag": 42.075706481933594, "report/post_ent_max": 42.075706481933594, "report/post_ent_mean": 42.0358772277832, "report/post_ent_min": 41.662147521972656, "report/post_ent_std": 0.07519710063934326, "report/prior_ent_mag": 43.87879943847656, "report/prior_ent_max": 43.87879943847656, "report/prior_ent_mean": 43.79835510253906, "report/prior_ent_min": 42.75615310668945, "report/prior_ent_std": 0.17017346620559692, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.000213623046875, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 6.687641143798828e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000213623046875, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.687641143798828e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003435499034821987, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003435499034821987, "eval/cont_pred": 0.9965705275535583, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.28945624828338623, "eval/image_loss_std": 0.08890269696712494, "eval/model_loss_mean": 0.8931053876876831, "eval/model_loss_std": 0.08890269696712494, "eval/post_ent_mag": 42.078529357910156, "eval/post_ent_max": 42.078529357910156, "eval/post_ent_mean": 42.036399841308594, "eval/post_ent_min": 41.66381072998047, "eval/post_ent_std": 0.07539334893226624, "eval/prior_ent_mag": 43.87797546386719, "eval/prior_ent_max": 43.87797546386719, "eval/prior_ent_mean": 43.79767608642578, "eval/prior_ent_min": 42.75615310668945, "eval/prior_ent_std": 0.1692018359899521, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.000213623046875, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 6.687641143798828e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000213623046875, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.687641143798828e-05, "eval/reward_rate": 0.0, "replay/size": 126865.0, "replay/inserts": 31664.0, "replay/samples": 31664.0, "replay/insert_wait_avg": 1.4297434511420822e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.886182109414477e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2970369442386473e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1700601577759, "timer/env.step_count": 3958.0, "timer/env.step_total": 39.69456672668457, "timer/env.step_frac": 0.03968781741019401, "timer/env.step_avg": 0.010028945610582256, "timer/env.step_min": 0.00797724723815918, "timer/env.step_max": 0.03997540473937988, "timer/replay._sample_count": 31664.0, "timer/replay._sample_total": 17.877084016799927, "timer/replay._sample_frac": 0.017874044353996994, "timer/replay._sample_avg": 0.0005645870394391083, "timer/replay._sample_min": 0.00035500526428222656, "timer/replay._sample_max": 0.0345001220703125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4825.0, "timer/agent.policy_total": 53.12725830078125, "timer/agent.policy_frac": 0.05311822500705578, "timer/agent.policy_avg": 0.011010830735913213, "timer/agent.policy_min": 0.009232044219970703, "timer/agent.policy_max": 0.08543682098388672, "timer/dataset_train_count": 1979.0, "timer/dataset_train_total": 0.2320563793182373, "timer/dataset_train_frac": 0.00023201692248379303, "timer/dataset_train_avg": 0.00011725941350087788, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.00035858154296875, "timer/agent.train_count": 1979.0, "timer/agent.train_total": 886.6348614692688, "timer/agent.train_frac": 0.8864841058423635, "timer/agent.train_avg": 0.44802165814515854, "timer/agent.train_min": 0.4366428852081299, "timer/agent.train_max": 0.7135388851165771, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47975873947143555, "timer/agent.report_frac": 0.0004796771654969896, "timer/agent.report_avg": 0.23987936973571777, "timer/agent.report_min": 0.23387598991394043, "timer/agent.report_max": 0.24588274955749512, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.719329833984375e-05, "timer/dataset_eval_frac": 3.718697431712417e-08, "timer/dataset_eval_avg": 3.719329833984375e-05, "timer/dataset_eval_min": 3.719329833984375e-05, "timer/dataset_eval_max": 3.719329833984375e-05, "fps": 31.65808469972336}
{"step": 127384, "time": 4239.67897439003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127496, "time": 4243.53294301033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127672, "time": 4248.96003651619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127912, "time": 4256.317748785019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128096, "time": 4262.281343698502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128616, "time": 4278.1057760715485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128680, "time": 4280.082814455032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129168, "time": 4295.4219081401825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129696, "time": 4311.654834747314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129808, "time": 4315.102634429932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129984, "time": 4320.610109090805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 4327.558691740036, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4327.567646026611, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4327.575103521347, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4327.58219909668, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4327.589402675629, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4327.596622467041, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4327.603699207306, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4327.61075925827, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130224, "time": 4334.4903473854065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130408, "time": 4339.927119970322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130928, "time": 4356.138599395752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130992, "time": 4358.109055519104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131480, "time": 4373.412477254868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132008, "time": 4389.755496025085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132120, "time": 4393.187740802765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132296, "time": 4398.58208155632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132536, "time": 4405.91343832016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132720, "time": 4411.847151756287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133240, "time": 4427.5872457027435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133304, "time": 4429.545592069626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133792, "time": 4444.880504846573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134320, "time": 4461.078413248062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134432, "time": 4464.514385700226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134608, "time": 4469.990598917007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134848, "time": 4477.386312484741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135032, "time": 4482.886667966843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135552, "time": 4499.065792322159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135616, "time": 4501.0095455646515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136104, "time": 4515.791973829269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136632, "time": 4532.26789188385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136744, "time": 4535.700607061386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136920, "time": 4541.138218402863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137160, "time": 4548.5134065151215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137344, "time": 4554.381319761276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137864, "time": 4570.228622436523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137928, "time": 4572.208985567093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138416, "time": 4587.371408700943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138944, "time": 4603.731286287308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139056, "time": 4607.183666706085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139232, "time": 4612.591880083084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139472, "time": 4620.716520547867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139656, "time": 4626.159642934799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 4646.130375862122, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4646.142936706543, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4646.153965473175, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4646.165633201599, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4646.175385951996, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4646.185822248459, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4646.199897766113, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4646.212166786194, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140176, "time": 4649.241692304611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140240, "time": 4651.22153878212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140728, "time": 4665.927107810974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141016, "time": 4674.676060199738, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 141256, "time": 4682.174064397812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141368, "time": 4685.597095251083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141544, "time": 4690.985755205154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141784, "time": 4698.333592891693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141968, "time": 4704.207973003387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142488, "time": 4720.034281253815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142552, "time": 4722.022701501846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143328, "time": 4746.089854717255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143568, "time": 4753.416985273361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143680, "time": 4756.862339496613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143856, "time": 4762.245258331299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144096, "time": 4769.731293439865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144280, "time": 4775.15708065033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144800, "time": 4791.301980495453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144864, "time": 4793.256830215454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145640, "time": 4816.93555021286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145880, "time": 4824.29610824585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145992, "time": 4827.720459222794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146168, "time": 4833.2202026844025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146408, "time": 4840.556449890137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146592, "time": 4846.364997625351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147112, "time": 4862.164453983307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147176, "time": 4864.142631292343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147952, "time": 4888.750421762466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148192, "time": 4896.067903757095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148304, "time": 4899.523439645767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148480, "time": 4904.911283493042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148720, "time": 4912.21341252327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148904, "time": 4917.595432281494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149424, "time": 4933.851555347443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149488, "time": 4935.811307430267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 4959.689722061157, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4959.698723554611, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4959.706446886063, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4959.715273618698, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4959.72442317009, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4959.732057571411, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4959.739716529846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4959.748111248016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150264, "time": 4965.661225795746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150504, "time": 4973.142933368683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150616, "time": 4976.578956604004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150792, "time": 4982.031659126282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151032, "time": 4989.358779430389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151216, "time": 4995.207525730133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151736, "time": 5010.950197219849, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151800, "time": 5012.922034025192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152576, "time": 5036.804793596268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152816, "time": 5044.274530172348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152928, "time": 5047.700234889984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153104, "time": 5053.049822330475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153344, "time": 5060.318037509918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153528, "time": 5065.679291725159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154048, "time": 5081.974409580231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154112, "time": 5083.9347012043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154888, "time": 5107.599495172501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155128, "time": 5114.920408248901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155240, "time": 5118.378780841827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155416, "time": 5123.760952949524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155656, "time": 5131.463297843933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155840, "time": 5137.555191993713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156360, "time": 5153.187668561935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156424, "time": 5155.149842977524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157200, "time": 5179.176890134811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157440, "time": 5186.491421222687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157552, "time": 5189.988598108292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157728, "time": 5195.352300643921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157968, "time": 5202.640025377274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158152, "time": 5208.044513940811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158672, "time": 5224.160592556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158736, "time": 5226.1032371521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159161, "time": 5239.848169565201, "train_stats/mean_log_entropy": 1.9379924610257149, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9977150155072234, "train/action_min": 0.0, "train/action_std": 1.9995515304594185, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.450092626884451e-05, "train/actor_opt_grad_steps": 8860.0, "train/actor_opt_loss": -5.249180362976376, "train/adv_mag": 0.0001597637965825934, "train/adv_max": 0.00011598246275030788, "train/adv_mean": 2.3292006166236694e-05, "train/adv_min": -8.956094426875138e-05, "train/adv_std": 3.540564067228861e-05, "train/cont_avg": 0.9964961526381909, "train/cont_loss_mean": 0.023347066755139798, "train/cont_loss_std": 0.3226273613279901, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6597773225940005, "train/cont_pos_acc": 0.9999999853234794, "train/cont_pos_loss": 0.0035244622700683886, "train/cont_pred": 0.9964818505186531, "train/cont_rate": 0.9964961526381909, "train/dyn_loss_mean": 1.001848607806105, "train/dyn_loss_std": 5.869943901297435e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.007140113853372109, "train/extr_critic_critic_opt_grad_steps": 8860.0, "train/extr_critic_critic_opt_loss": 6251.35891861652, "train/extr_critic_mag": 0.015602234619945737, "train/extr_critic_max": 0.015602234619945737, "train/extr_critic_mean": 0.015523906422769605, "train/extr_critic_min": 0.015474699250417738, "train/extr_critic_std": 2.2095893886006563e-05, "train/extr_return_normed_mag": 0.00020324432726331692, "train/extr_return_normed_max": 0.00016579091380439212, "train/extr_return_normed_mean": 0.0001004346246339656, "train/extr_return_normed_min": 2.9728584103847867e-05, "train/extr_return_normed_std": 3.118310793388903e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.01561374404004321, "train/extr_return_raw_max": 0.01561374404004321, "train/extr_return_raw_mean": 0.01554838871705023, "train/extr_return_raw_min": 0.015477681710342667, "train/extr_return_raw_std": 3.1183108151265114e-05, "train/extr_reward_mag": 5.038958698061842e-05, "train/extr_reward_max": 5.038958698061842e-05, "train/extr_reward_mean": 5.0366825445194786e-05, "train/extr_reward_min": 5.033687131488743e-05, "train/extr_reward_std": 1.117882068599294e-08, "train/image_loss_mean": 0.2539688802544196, "train/image_loss_std": 0.08537682434122766, "train/model_loss_mean": 0.8804766356046475, "train/model_loss_std": 0.37815288255861657, "train/model_opt_grad_norm": 53.54242220356237, "train/model_opt_grad_steps": 8849.61809045226, "train/model_opt_loss": 2206.3349995828753, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2506.281407035176, "train/policy_entropy_mag": 1.9458819274327264, "train/policy_entropy_max": 1.9458819274327264, "train/policy_entropy_mean": 1.9450953653709373, "train/policy_entropy_min": 1.9283535186968856, "train/policy_entropy_std": 0.0006065899671474238, "train/policy_logprob_mag": 2.162911186266185, "train/policy_logprob_max": -1.6970927032394025, "train/policy_logprob_mean": -1.945138302879717, "train/policy_logprob_min": -2.162911186266185, "train/policy_logprob_std": 0.03904045664298175, "train/policy_randomness_mag": 0.999985557105673, "train/policy_randomness_max": 0.999985557105673, "train/policy_randomness_mean": 0.9995813426659934, "train/policy_randomness_min": 0.99097773567516, "train/policy_randomness_std": 0.00031172557906235975, "train/post_ent_mag": 39.7886212219545, "train/post_ent_max": 39.7886212219545, "train/post_ent_mean": 39.77568861228138, "train/post_ent_min": 39.73350823943939, "train/post_ent_std": 0.01006288734737353, "train/prior_ent_mag": 41.30847622281942, "train/prior_ent_max": 41.30847622281942, "train/prior_ent_mean": 41.282627642454216, "train/prior_ent_min": 41.08664680365941, "train/prior_ent_std": 0.03613062160810334, "train/rep_loss_mean": 1.001848607806105, "train/rep_loss_std": 5.869943901297435e-05, "train/reward_avg": 7.295081302425333e-05, "train/reward_loss_mean": 0.0020515052578294994, "train/reward_loss_std": 0.05767191958106234, "train/reward_max_data": 0.07145100442608397, "train/reward_max_pred": 5.0418940021764094e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00022598607091223774, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.095433712005615, "train/reward_pred": 5.036712057851068e-05, "train/reward_rate": 0.00018157192211055276, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014346146024763584, "report/cont_loss_std": 0.2562827169895172, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.807696342468262, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030088648200035095, "report/cont_pred": 0.9969958662986755, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25676295161247253, "report/image_loss_std": 0.08277758955955505, "report/model_loss_mean": 0.8712216019630432, "report/model_loss_std": 0.26559126377105713, "report/post_ent_mag": 39.51002883911133, "report/post_ent_max": 39.51002883911133, "report/post_ent_mean": 39.503631591796875, "report/post_ent_min": 39.49031448364258, "report/post_ent_std": 0.0025567077100276947, "report/prior_ent_mag": 41.05946350097656, "report/prior_ent_max": 41.05946350097656, "report/prior_ent_mean": 41.03730392456055, "report/prior_ent_min": 40.89552307128906, "report/prior_ent_std": 0.025080930441617966, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001125335693359375, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.3736228942871094e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001125335693359375, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.3736228942871094e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003008865052834153, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003008865052834153, "eval/cont_pred": 0.9969958662986755, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25074195861816406, "eval/image_loss_std": 0.081410713493824, "eval/model_loss_mean": 0.8538633584976196, "eval/model_loss_std": 0.081410713493824, "eval/post_ent_mag": 39.510406494140625, "eval/post_ent_max": 39.510406494140625, "eval/post_ent_mean": 39.50361633300781, "eval/post_ent_min": 39.48986053466797, "eval/post_ent_std": 0.0025387259665876627, "eval/prior_ent_mag": 41.055885314941406, "eval/prior_ent_max": 41.055885314941406, "eval/prior_ent_mean": 41.03828430175781, "eval/prior_ent_min": 40.89552307128906, "eval/prior_ent_std": 0.02368093468248844, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001125335693359375, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.3736228942871094e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001125335693359375, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.3736228942871094e-05, "eval/reward_rate": 0.0, "replay/size": 158657.0, "replay/inserts": 31792.0, "replay/samples": 31792.0, "replay/insert_wait_avg": 1.4386782408600545e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.863378663007854e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3217862777093978e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2142980098724, "timer/env.step_count": 3974.0, "timer/env.step_total": 39.2211549282074, "timer/env.step_frac": 0.03921275171355356, "timer/env.step_avg": 0.009869440092654102, "timer/env.step_min": 0.00787806510925293, "timer/env.step_max": 0.035434722900390625, "timer/replay._sample_count": 31792.0, "timer/replay._sample_total": 17.793979167938232, "timer/replay._sample_frac": 0.017790166770603993, "timer/replay._sample_avg": 0.000559699898337262, "timer/replay._sample_min": 0.0004057884216308594, "timer/replay._sample_max": 0.026599645614624023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4841.0, "timer/agent.policy_total": 53.40650725364685, "timer/agent.policy_frac": 0.053395064797523734, "timer/agent.policy_avg": 0.01103212296088553, "timer/agent.policy_min": 0.007986068725585938, "timer/agent.policy_max": 0.08999752998352051, "timer/dataset_train_count": 1987.0, "timer/dataset_train_total": 0.23253893852233887, "timer/dataset_train_frac": 0.00023248911656734148, "timer/dataset_train_avg": 0.00011703016533585248, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.001085042953491211, "timer/agent.train_count": 1987.0, "timer/agent.train_total": 891.8231682777405, "timer/agent.train_frac": 0.891632093294609, "timer/agent.train_avg": 0.4488289724598593, "timer/agent.train_min": 0.4338967800140381, "timer/agent.train_max": 1.1516578197479248, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4714925289154053, "timer/agent.report_frac": 0.0004713915106528016, "timer/agent.report_avg": 0.23574626445770264, "timer/agent.report_min": 0.22919416427612305, "timer/agent.report_max": 0.24229836463928223, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2417979649289575e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 31.784685361405955}
{"step": 159512, "time": 5250.3994472026825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159752, "time": 5257.706295251846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159864, "time": 5261.137676000595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160040, "time": 5266.514866352081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 5272.8611924648285, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5272.869152069092, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5272.87669968605, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5272.883965015411, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5272.89102435112, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5272.898320674896, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5272.905961275101, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5272.913822889328, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160280, "time": 5279.847828388214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160464, "time": 5285.660396337509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160984, "time": 5301.296061038971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161048, "time": 5303.240365743637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161824, "time": 5327.150648117065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162064, "time": 5334.574100017548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162176, "time": 5337.982089519501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162352, "time": 5343.454704284668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162592, "time": 5350.772470235825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162776, "time": 5356.157927036285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163296, "time": 5372.29932308197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163360, "time": 5374.270924568176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164136, "time": 5398.164855718613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164376, "time": 5405.592987298965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164488, "time": 5409.01374745369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164664, "time": 5414.361498594284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164904, "time": 5421.616264104843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165088, "time": 5427.410523414612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165608, "time": 5443.083389759064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165672, "time": 5445.0497324466705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166448, "time": 5469.058474063873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166688, "time": 5476.3645632267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166800, "time": 5479.768236875534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166976, "time": 5485.145037651062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167216, "time": 5492.608937501907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167400, "time": 5497.973145008087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167920, "time": 5514.03803062439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167984, "time": 5516.00900387764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168760, "time": 5539.499140024185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169000, "time": 5546.766086578369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169112, "time": 5550.265897035599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169288, "time": 5555.628039598465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169528, "time": 5562.962834358215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169712, "time": 5568.811973571777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 5582.665943145752, "eval_episode/length": 176.0, "eval_episode/score": 0.44999998807907104, "eval_episode/reward_rate": 0.005649717514124294}
{"step": 170040, "time": 5584.926558256149, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5584.934550523758, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5584.941255569458, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5584.9479784965515, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5584.954575061798, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5584.961458206177, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5584.967643022537, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170232, "time": 5590.802539348602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170296, "time": 5592.751260757446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171072, "time": 5616.666415214539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171312, "time": 5623.988505601883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171424, "time": 5627.388904094696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171600, "time": 5632.742089748383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171840, "time": 5640.166785240173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172024, "time": 5645.525455713272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172544, "time": 5662.003475666046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172608, "time": 5663.963252067566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173384, "time": 5687.363019227982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173624, "time": 5694.6705441474915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173736, "time": 5698.091890335083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173912, "time": 5703.590879201889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174152, "time": 5710.888611078262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174336, "time": 5716.683658838272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174856, "time": 5732.411481142044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174920, "time": 5734.362769365311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175696, "time": 5758.1830542087555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175936, "time": 5765.572825431824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176048, "time": 5768.982569217682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176224, "time": 5774.291457891464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176464, "time": 5781.596876144409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176648, "time": 5786.966462850571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177168, "time": 5803.050458192825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177232, "time": 5805.028775930405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178008, "time": 5828.496006727219, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178248, "time": 5835.809093475342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178360, "time": 5839.235007047653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178536, "time": 5844.605328083038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178776, "time": 5852.0004868507385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178960, "time": 5857.878956317902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179480, "time": 5873.540325880051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179544, "time": 5875.49493598938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 5896.35586977005, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5896.363962888718, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5896.371456861496, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5896.378689527512, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5896.386113882065, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5896.39434671402, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5896.401850938797, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5896.409587144852, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180320, "time": 5906.17774438858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180560, "time": 5913.647267580032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180672, "time": 5917.093425273895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180848, "time": 5922.448262691498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181088, "time": 5929.751836538315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181272, "time": 5935.157709598541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181544, "time": 5943.517682313919, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 181856, "time": 5953.270271778107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182632, "time": 5976.921768188477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182872, "time": 5984.259876489639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182984, "time": 5987.6597402095795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183160, "time": 5993.055410385132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183400, "time": 6000.440561532974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183584, "time": 6006.2708241939545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183856, "time": 6014.585804224014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184168, "time": 6023.866750240326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184944, "time": 6047.868912935257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185184, "time": 6055.191928386688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185296, "time": 6058.743210077286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185472, "time": 6064.083236694336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185712, "time": 6071.392114877701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185896, "time": 6076.769905328751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186168, "time": 6085.052340507507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186480, "time": 6094.865581989288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187256, "time": 6118.375960111618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187496, "time": 6125.74564409256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187608, "time": 6129.143436670303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187784, "time": 6134.535431623459, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188024, "time": 6141.834872484207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188208, "time": 6147.6783583164215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188480, "time": 6156.6190712451935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188792, "time": 6165.962711811066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189568, "time": 6190.076143741608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189808, "time": 6197.397816896439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189920, "time": 6200.822416543961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 6209.394619703293, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6209.43819975853, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6209.48411989212, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6209.531473398209, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6209.580895185471, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6209.631052970886, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6209.682302236557, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6209.734071969986, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190096, "time": 6212.662912368774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190272, "time": 6218.044240236282, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 190336, "time": 6219.996631622314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190520, "time": 6225.38453745842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190792, "time": 6233.626799106598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190969, "time": 6240.112094640732, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000735504458649, "train/action_min": 0.0, "train/action_std": 1.9995412314781036, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.440587915015136e-05, "train/actor_opt_grad_steps": 10845.0, "train/actor_opt_loss": -6.151411901218722, "train/adv_mag": 0.00021680261977393217, "train/adv_max": 0.00012077870449483996, "train/adv_mean": -2.4112607532761287e-05, "train/adv_min": -0.00017202490319808325, "train/adv_std": 4.5686377490602636e-05, "train/cont_avg": 0.9965425741792929, "train/cont_loss_mean": 0.02303121735299514, "train/cont_loss_std": 0.3210656960514465, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.663116885454227, "train/cont_pos_acc": 0.9999999828410872, "train/cont_pos_loss": 0.003500429757005262, "train/cont_pred": 0.9965057948020973, "train/cont_rate": 0.9965425741792929, "train/dyn_loss_mean": 1.0000000517777723, "train/dyn_loss_std": 1.645341252136712e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.005859670333618373, "train/extr_critic_critic_opt_grad_steps": 10845.0, "train/extr_critic_critic_opt_loss": 6366.08815449416, "train/extr_critic_mag": 0.016056869969223484, "train/extr_critic_max": 0.016056869969223484, "train/extr_critic_mean": 0.015953782710688886, "train/extr_critic_min": 0.015877364861844767, "train/extr_critic_std": 3.077106261015514e-05, "train/extr_return_normed_mag": 0.0002195848048561149, "train/extr_return_normed_max": 0.00012294241612908815, "train/extr_return_normed_mean": 1.900588603408011e-05, "train/extr_return_normed_min": -7.269238451063031e-05, "train/extr_return_normed_std": 3.9987068895688845e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.016036154622343753, "train/extr_return_raw_max": 0.016036154622343753, "train/extr_return_raw_mean": 0.01593221898538747, "train/extr_return_raw_min": 0.015840519821704035, "train/extr_return_raw_std": 3.9987068851764386e-05, "train/extr_reward_mag": 4.417065418127811e-05, "train/extr_reward_max": 4.417065418127811e-05, "train/extr_reward_mean": 4.4146675004366896e-05, "train/extr_reward_min": 4.411345780497849e-05, "train/extr_reward_std": 1.263821145379471e-08, "train/image_loss_mean": 0.24639535499642592, "train/image_loss_std": 0.08397190400747338, "train/model_loss_mean": 0.8709144179869179, "train/model_loss_std": 0.36411979241353093, "train/model_opt_grad_norm": 48.509542445943815, "train/model_opt_grad_steps": 10832.914141414141, "train/model_opt_loss": 2375.94586489899, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2727.2727272727275, "train/policy_entropy_mag": 1.9458802535076334, "train/policy_entropy_max": 1.9458802535076334, "train/policy_entropy_mean": 1.9442672049156342, "train/policy_entropy_min": 1.923134051188074, "train/policy_entropy_std": 0.0013074639530833623, "train/policy_logprob_mag": 2.2115201456378206, "train/policy_logprob_max": -1.6651767949865321, "train/policy_logprob_mean": -1.9442921166468148, "train/policy_logprob_min": -2.2115201456378206, "train/policy_logprob_std": 0.05351792514850997, "train/policy_randomness_mag": 0.99998469575487, "train/policy_randomness_max": 0.99998469575487, "train/policy_randomness_mean": 0.9991557568010657, "train/policy_randomness_min": 0.98829545818194, "train/policy_randomness_std": 0.0006719035861691497, "train/post_ent_mag": 41.08533560627639, "train/post_ent_max": 41.08533560627639, "train/post_ent_mean": 41.05258883851947, "train/post_ent_min": 41.03279115696146, "train/post_ent_std": 0.010336584109352018, "train/prior_ent_mag": 41.11692297579062, "train/prior_ent_max": 41.11692297579062, "train/prior_ent_mean": 40.988550976069284, "train/prior_ent_min": 40.88666482405229, "train/prior_ent_std": 0.03307694032543687, "train/rep_loss_mean": 1.0000000517777723, "train/rep_loss_std": 1.645341252136712e-06, "train/reward_avg": 5.907771533156388e-05, "train/reward_loss_mean": 0.0014877943227989505, "train/reward_loss_std": 0.03935150202260168, "train/reward_max_data": 0.04990530258627853, "train/reward_max_pred": 4.42079823426526e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001661590627698002, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.258031715046275, "train/reward_pred": 4.414664499104174e-05, "train/reward_rate": 0.0001282354797979798, "train_stats/mean_log_entropy": 1.936866670846939, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014342058449983597, "report/cont_loss_std": 0.2564552128314972, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.811590671539307, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029971525073051453, "report/cont_pred": 0.9970073103904724, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2426552176475525, "report/image_loss_std": 0.0835268422961235, "report/model_loss_mean": 0.8570945262908936, "report/model_loss_std": 0.2729424238204956, "report/post_ent_mag": 42.90179443359375, "report/post_ent_max": 42.90179443359375, "report/post_ent_mean": 42.82014465332031, "report/post_ent_min": 42.77351379394531, "report/post_ent_std": 0.028172845020890236, "report/prior_ent_mag": 41.66581344604492, "report/prior_ent_max": 41.66581344604492, "report/prior_ent_mean": 41.14588165283203, "report/prior_ent_min": 41.01863098144531, "report/prior_ent_std": 0.08613795042037964, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 9.72747802734375e-05, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.0994415283203125e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 9.72747802734375e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.0994415283203125e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0029971522744745016, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0029971522744745016, "eval/cont_pred": 0.9970073103904724, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2486293911933899, "eval/image_loss_std": 0.09664646536111832, "eval/model_loss_mean": 0.8517237901687622, "eval/model_loss_std": 0.09664646536111832, "eval/post_ent_mag": 42.899208068847656, "eval/post_ent_max": 42.899208068847656, "eval/post_ent_mean": 42.82160949707031, "eval/post_ent_min": 42.75556182861328, "eval/post_ent_std": 0.03265826776623726, "eval/prior_ent_mag": 41.76145553588867, "eval/prior_ent_max": 41.76145553588867, "eval/prior_ent_mean": 41.17888641357422, "eval/prior_ent_min": 41.01167297363281, "eval/prior_ent_std": 0.10899313539266586, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 9.72747802734375e-05, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.0994415283203125e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 9.72747802734375e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.0994415283203125e-05, "eval/reward_rate": 0.0, "replay/size": 190465.0, "replay/inserts": 31808.0, "replay/samples": 31808.0, "replay/insert_wait_avg": 1.4235181228015984e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.97405193125458e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47296.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.301789160005774e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2403047084808, "timer/env.step_count": 3976.0, "timer/env.step_total": 39.31058669090271, "timer/env.step_frac": 0.03930114244132538, "timer/env.step_avg": 0.009886968483627441, "timer/env.step_min": 0.008202075958251953, "timer/env.step_max": 0.03555178642272949, "timer/replay._sample_count": 31808.0, "timer/replay._sample_total": 17.256762981414795, "timer/replay._sample_frac": 0.01725261709629294, "timer/replay._sample_avg": 0.0005425290172728494, "timer/replay._sample_min": 0.00038886070251464844, "timer/replay._sample_max": 0.02619338035583496, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5132.0, "timer/agent.policy_total": 55.88418793678284, "timer/agent.policy_frac": 0.055870761929624736, "timer/agent.policy_avg": 0.010889358522366102, "timer/agent.policy_min": 0.009154796600341797, "timer/agent.policy_max": 0.08869528770446777, "timer/dataset_train_count": 1988.0, "timer/dataset_train_total": 0.2278432846069336, "timer/dataset_train_frac": 0.00022778854594680456, "timer/dataset_train_avg": 0.00011460929809201891, "timer/dataset_train_min": 0.00010037422180175781, "timer/dataset_train_max": 0.00045800209045410156, "timer/agent.train_count": 1988.0, "timer/agent.train_total": 886.6843957901001, "timer/agent.train_frac": 0.886471372545344, "timer/agent.train_avg": 0.44601830774149903, "timer/agent.train_min": 0.43410682678222656, "timer/agent.train_max": 0.6997215747833252, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4789714813232422, "timer/agent.report_frac": 0.0004788564098732634, "timer/agent.report_avg": 0.2394857406616211, "timer/agent.report_min": 0.23249340057373047, "timer/agent.report_max": 0.24647808074951172, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265549806697078e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 31.799725536285514}
{"step": 191104, "time": 6244.282099246979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191880, "time": 6267.774203538895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192112, "time": 6275.232582092285, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 192120, "time": 6275.262134552002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192232, "time": 6278.682489156723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192648, "time": 6291.381921291351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192832, "time": 6297.268750429153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193104, "time": 6305.680980920792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193416, "time": 6315.00785279274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194192, "time": 6339.155354976654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194424, "time": 6346.022136688232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194432, "time": 6346.497744560242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194544, "time": 6349.935212850571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194960, "time": 6362.837970495224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195144, "time": 6368.234863758087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195416, "time": 6376.539477348328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195728, "time": 6386.306079864502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196504, "time": 6409.91956782341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196736, "time": 6417.790195226669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196744, "time": 6417.822562217712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196856, "time": 6421.396794319153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197272, "time": 6434.134482145309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197456, "time": 6439.945290327072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197728, "time": 6448.314973831177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198040, "time": 6457.757216453552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198696, "time": 6477.797412872314, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 198816, "time": 6481.76948595047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199048, "time": 6488.6813352108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199056, "time": 6489.155134677887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199584, "time": 6505.311567544937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199768, "time": 6510.8063135147095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200040, "time": 6519.134345769882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 6527.477897882462, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6527.485805511475, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6527.493306159973, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6527.500817298889, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6527.507532835007, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6527.515217065811, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6527.5240213871, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6527.531494617462, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200352, "time": 6536.132289648056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201008, "time": 6556.337895393372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201128, "time": 6559.790084123611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201360, "time": 6567.14272403717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201368, "time": 6567.17719912529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201896, "time": 6583.464477777481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202080, "time": 6589.2530727386475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202352, "time": 6597.513339042664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202664, "time": 6606.930416584015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203320, "time": 6627.009457826614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203440, "time": 6630.9735062122345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203672, "time": 6637.870603561401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203680, "time": 6638.344042301178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204208, "time": 6654.629727363586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204392, "time": 6660.1745772361755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204664, "time": 6668.473061800003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204816, "time": 6673.875765800476, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 205632, "time": 6698.983133792877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205752, "time": 6702.433098554611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205984, "time": 6709.703715324402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205992, "time": 6709.742644309998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206520, "time": 6725.941583156586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206704, "time": 6731.787920951843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206976, "time": 6740.112108945847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207112, "time": 6744.042432785034, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 207128, "time": 6744.548565864563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208064, "time": 6773.402497291565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208296, "time": 6780.386765003204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208304, "time": 6780.858075141907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208832, "time": 6796.942679643631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209016, "time": 6802.324593067169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209288, "time": 6810.822225809097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209424, "time": 6815.224027395248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209440, "time": 6815.719014406204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 6841.322595834732, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6841.330848693848, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6841.338196754456, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6841.346401691437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6841.353313922882, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6841.361205339432, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6841.3675191402435, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6841.374924898148, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210376, "time": 6850.200518608093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210464, "time": 6853.108026742935, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 210608, "time": 6857.50720334053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210616, "time": 6857.543011665344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211144, "time": 6873.7588992118835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211328, "time": 6879.642314195633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211600, "time": 6887.9624943733215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211736, "time": 6891.918310165405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212688, "time": 6921.237569093704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212776, "time": 6923.7423276901245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212920, "time": 6928.167715072632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212928, "time": 6928.757025241852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213456, "time": 6945.3037531375885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213640, "time": 6950.698054552078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213912, "time": 6959.163049697876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214048, "time": 6963.558283090591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215000, "time": 6992.476326942444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215072, "time": 6994.907715797424, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 215232, "time": 6999.803776502609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215240, "time": 6999.835387468338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215768, "time": 7015.911923646927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215952, "time": 7021.921568155289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216224, "time": 7030.2237637043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216360, "time": 7034.165485620499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217312, "time": 7063.666436910629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217384, "time": 7065.647137403488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217544, "time": 7070.503405570984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217552, "time": 7070.999064922333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217760, "time": 7077.377126693726, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 218080, "time": 7087.28094625473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218264, "time": 7092.679557561874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218536, "time": 7100.9998116493225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219624, "time": 7134.287053108215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219696, "time": 7136.72007727623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219856, "time": 7141.697505950928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219864, "time": 7141.727463006973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 7151.739762067795, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 220064, "time": 7153.9280569553375, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7153.941784620285, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7153.951506614685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7153.961798191071, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7153.969608545303, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7153.976848125458, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7153.984163284302, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220072, "time": 7154.012992620468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220392, "time": 7163.783785820007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220576, "time": 7169.831255674362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220848, "time": 7178.184757947922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221936, "time": 7211.987723350525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222008, "time": 7213.975915193558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222168, "time": 7218.891617298126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222176, "time": 7219.368776321411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222384, "time": 7225.7593767642975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222704, "time": 7235.671037912369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222825, "time": 7240.131561040878, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.08789794921875, "train/action_min": 0.0, "train/action_std": 1.9470448857545852, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00046914515813114123, "train/actor_opt_grad_steps": 12835.0, "train/actor_opt_loss": -4.178224023929797, "train/adv_mag": 0.0014865522133186459, "train/adv_max": 0.0013135364186018705, "train/adv_mean": 8.524874401501848e-05, "train/adv_min": -0.0005853822315111756, "train/adv_std": 0.00020089296756850672, "train/cont_avg": 0.9964501953125, "train/cont_loss_mean": 0.02363812904339284, "train/cont_loss_std": 0.3272978862375021, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.661642801761627, "train/cont_pos_acc": 0.9999999853968621, "train/cont_pos_loss": 0.003509688318008557, "train/cont_pred": 0.9964965459704399, "train/cont_rate": 0.9964501953125, "train/dyn_loss_mean": 1.0000006121397018, "train/dyn_loss_std": 1.7609839705983176e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.017736574067530455, "train/extr_critic_critic_opt_grad_steps": 12835.0, "train/extr_critic_critic_opt_loss": 6231.456281738281, "train/extr_critic_mag": 0.015963608026504518, "train/extr_critic_max": 0.015963608026504518, "train/extr_critic_mean": 0.015452221045270562, "train/extr_critic_min": 0.015138460397720337, "train/extr_critic_std": 7.737991600151873e-05, "train/extr_return_normed_mag": 0.0015120526077225804, "train/extr_return_normed_max": 0.0014756555808708072, "train/extr_return_normed_mean": 0.0003077945685885197, "train/extr_return_normed_min": -7.529637310653925e-05, "train/extr_return_normed_std": 0.00018883907334384274, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.016705325287766755, "train/extr_return_raw_max": 0.016705325287766755, "train/extr_return_raw_mean": 0.015537465107627213, "train/extr_return_raw_min": 0.015154373343102634, "train/extr_return_raw_std": 0.00018883907354393158, "train/extr_reward_mag": 0.00019192636013031005, "train/extr_reward_max": 0.00019192636013031005, "train/extr_reward_mean": 5.7958345469160125e-05, "train/extr_reward_min": 3.797829151153564e-05, "train/extr_reward_std": 2.3628971877877046e-05, "train/image_loss_mean": 0.21070233330130578, "train/image_loss_std": 0.09406207770109176, "train/model_loss_mean": 0.8361263406276703, "train/model_loss_std": 0.37923621326684953, "train/model_opt_grad_norm": 44.43177797317505, "train/model_opt_grad_steps": 12821.305, "train/model_opt_loss": 2669.082720336914, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3200.0, "train/policy_entropy_mag": 1.939260504245758, "train/policy_entropy_max": 1.939260504245758, "train/policy_entropy_mean": 1.904897740483284, "train/policy_entropy_min": 1.7518510308861732, "train/policy_entropy_std": 0.01787166389869526, "train/policy_logprob_mag": 3.1329080617427825, "train/policy_logprob_max": -1.080182325989008, "train/policy_logprob_mean": -1.9046959096193314, "train/policy_logprob_min": -3.1329080617427825, "train/policy_logprob_std": 0.22514733169227838, "train/policy_randomness_mag": 0.9965828168392181, "train/policy_randomness_max": 0.9965828168392181, "train/policy_randomness_mean": 0.9789238429069519, "train/policy_randomness_min": 0.900273394137621, "train/policy_randomness_std": 0.00918421901355032, "train/post_ent_mag": 45.99350782394409, "train/post_ent_max": 45.99350782394409, "train/post_ent_mean": 45.56991230010986, "train/post_ent_min": 45.20756956100464, "train/post_ent_std": 0.15706494343467056, "train/prior_ent_mag": 46.44509088516235, "train/prior_ent_max": 46.44509088516235, "train/prior_ent_mean": 43.12350814819336, "train/prior_ent_min": 41.36152570724487, "train/prior_ent_std": 0.8025538354367018, "train/rep_loss_mean": 1.0000006121397018, "train/rep_loss_std": 1.7609839705983176e-05, "train/reward_avg": 6.59942626953125e-05, "train/reward_loss_mean": 0.001785487588495016, "train/reward_loss_std": 0.04982853894313338, "train/reward_max_data": 0.06401562467217445, "train/reward_max_pred": 8.547902107238769e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001380792656891572, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.192135890324911, "train/reward_pred": 4.577149113174528e-05, "train/reward_rate": 0.0001611328125, "train_stats/mean_log_entropy": 1.8938407195465905, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02006056159734726, "report/cont_loss_std": 0.3057047128677368, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6597394943237305, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034895187709480524, "report/cont_pred": 0.9965164661407471, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.19778963923454285, "report/image_loss_std": 0.09821352362632751, "report/model_loss_mean": 0.8180049657821655, "report/model_loss_std": 0.3262963593006134, "report/post_ent_mag": 43.50067901611328, "report/post_ent_max": 43.50067901611328, "report/post_ent_mean": 42.93376159667969, "report/post_ent_min": 42.512229919433594, "report/post_ent_std": 0.18691137433052063, "report/prior_ent_mag": 44.95750427246094, "report/prior_ent_max": 44.95750427246094, "report/prior_ent_mean": 41.712646484375, "report/prior_ent_min": 39.37090301513672, "report/prior_ent_std": 1.0221483707427979, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00015476299449801445, "report/reward_loss_std": 0.00011747689131880179, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.00014650821685791016, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00015476299449801445, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.7662993893027306e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.025584230199456215, "eval/cont_loss_std": 0.35282447934150696, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.6597394943237305, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0034895052667707205, "eval/cont_pred": 0.9965164661407471, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2009558081626892, "eval/image_loss_std": 0.10027045756578445, "eval/model_loss_mean": 0.8362986445426941, "eval/model_loss_std": 0.5910792946815491, "eval/post_ent_mag": 43.455448150634766, "eval/post_ent_max": 43.455448150634766, "eval/post_ent_mean": 42.94886016845703, "eval/post_ent_min": 42.52973937988281, "eval/post_ent_std": 0.1798962950706482, "eval/prior_ent_mag": 45.70866394042969, "eval/prior_ent_max": 45.70866394042969, "eval/prior_ent_mean": 41.634422302246094, "eval/prior_ent_min": 39.3016357421875, "eval/prior_ent_std": 0.9900941252708435, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007263183360919356, "eval/reward_loss_mean": 0.009758584201335907, "eval/reward_loss_std": 0.3076912462711334, "eval/reward_max_data": 0.7437499761581421, "eval/reward_max_pred": 0.00014519691467285156, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000138534014695324, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.851069450378418, "eval/reward_pred": 4.257191903889179e-05, "eval/reward_rate": 0.0009765625, "replay/size": 222321.0, "replay/inserts": 31856.0, "replay/samples": 31856.0, "replay/insert_wait_avg": 1.421687532345414e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.112834690923609e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54232.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2545162143729274e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9969482421875, "timer/env.step_count": 3982.0, "timer/env.step_total": 39.82134675979614, "timer/env.step_frac": 0.03982146828527309, "timer/env.step_avg": 0.010000338211902597, "timer/env.step_min": 0.008157014846801758, "timer/env.step_max": 0.04939866065979004, "timer/replay._sample_count": 31856.0, "timer/replay._sample_total": 17.420267343521118, "timer/replay._sample_frac": 0.01742032050612032, "timer/replay._sample_avg": 0.0005468441531743194, "timer/replay._sample_min": 0.00037670135498046875, "timer/replay._sample_max": 0.013840675354003906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4849.0, "timer/agent.policy_total": 53.557974100112915, "timer/agent.policy_frac": 0.053558137546577594, "timer/agent.policy_avg": 0.011045158610045971, "timer/agent.policy_min": 0.009264945983886719, "timer/agent.policy_max": 0.09108829498291016, "timer/dataset_train_count": 1991.0, "timer/dataset_train_total": 0.23239684104919434, "timer/dataset_train_frac": 0.000232397550270234, "timer/dataset_train_avg": 0.00011672367707141856, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0007436275482177734, "timer/agent.train_count": 1991.0, "timer/agent.train_total": 891.6362709999084, "timer/agent.train_frac": 0.8916389920661684, "timer/agent.train_avg": 0.44783338573576514, "timer/agent.train_min": 0.4361398220062256, "timer/agent.train_max": 1.2521450519561768, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47354698181152344, "timer/agent.report_frac": 0.000473548426966635, "timer/agent.report_avg": 0.23677349090576172, "timer/agent.report_min": 0.22547149658203125, "timer/agent.report_max": 0.2480754852294922, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1471348484339854e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 31.855430410895565}
{"step": 222888, "time": 7241.8570239543915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222952, "time": 7243.803314208984, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 223160, "time": 7250.190931081772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224248, "time": 7283.797241687775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224320, "time": 7286.265931367874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224480, "time": 7291.332811594009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224696, "time": 7297.824858188629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225016, "time": 7307.6051342487335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225200, "time": 7313.467888832092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225264, "time": 7315.474352836609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225472, "time": 7321.945984840393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226560, "time": 7355.278337478638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226632, "time": 7357.266736030579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226792, "time": 7362.197558879852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227008, "time": 7369.066858530045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227328, "time": 7379.010406970978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227512, "time": 7384.40811252594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227576, "time": 7386.37878704071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227784, "time": 7392.7430284023285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228872, "time": 7426.028881072998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228944, "time": 7428.46107506752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229104, "time": 7433.378694534302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229320, "time": 7439.840473890305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229640, "time": 7450.139124631882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229824, "time": 7455.986301183701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229888, "time": 7457.9707288742065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 7463.5257833004, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 230048, "time": 7468.906744718552, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7468.915160417557, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7468.922527074814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7468.929600954056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7468.936922311783, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7468.944339513779, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7468.95167350769, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230096, "time": 7470.416709661484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231184, "time": 7503.785411834717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231256, "time": 7505.762145280838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231416, "time": 7510.671733140945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231632, "time": 7517.490483522415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231952, "time": 7527.303497076035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232136, "time": 7532.852121591568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232200, "time": 7534.808562517166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232408, "time": 7541.167671918869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233480, "time": 7574.03537774086, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 233496, "time": 7574.527789115906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233568, "time": 7576.951246500015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233728, "time": 7581.832154035568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233944, "time": 7588.199398517609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234448, "time": 7603.929221153259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234512, "time": 7605.906615972519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234720, "time": 7612.2422597408295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235792, "time": 7645.15841627121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235808, "time": 7645.653711795807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235880, "time": 7647.641927242279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236040, "time": 7652.680713176727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236256, "time": 7659.54975271225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236760, "time": 7674.775944471359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236776, "time": 7675.273793935776, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 236824, "time": 7676.738738298416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237032, "time": 7683.189789056778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238104, "time": 7716.594678878784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238120, "time": 7717.095369577408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238352, "time": 7724.452115535736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238568, "time": 7730.808527231216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239072, "time": 7746.565049171448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239088, "time": 7747.065721273422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239136, "time": 7748.55312037468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239344, "time": 7754.915660381317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 7778.983342409134, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 240032, "time": 7782.6067633628845, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7782.614897251129, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7782.622329235077, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7782.6299386024475, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7782.6372220516205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7782.645950555801, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7782.65682721138, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240336, "time": 7791.949541807175, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 240416, "time": 7794.390958547592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240432, "time": 7794.899374008179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240664, "time": 7801.853828668594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241384, "time": 7823.847419261932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241400, "time": 7824.359897136688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241448, "time": 7825.819832086563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241656, "time": 7832.2437381744385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242648, "time": 7862.630548238754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242728, "time": 7865.084744930267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242744, "time": 7865.581305027008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242896, "time": 7870.462433576584, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 243696, "time": 7895.0907735824585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243712, "time": 7895.587491750717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243760, "time": 7897.058296442032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243968, "time": 7903.450206756592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244960, "time": 7933.833377838135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245040, "time": 7936.269891738892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245056, "time": 7936.765736103058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245208, "time": 7941.145776748657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246008, "time": 7966.159551858902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246024, "time": 7966.662224769592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246072, "time": 7968.1376004219055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246280, "time": 7974.448619365692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247272, "time": 8004.9397258758545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247352, "time": 8007.423693418503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247368, "time": 8007.921761751175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247520, "time": 8012.922046422958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248320, "time": 8037.258976697922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248336, "time": 8037.748157978058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248384, "time": 8039.300940036774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248592, "time": 8045.6407997608185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249576, "time": 8075.656235933304, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 249584, "time": 8076.127462863922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249664, "time": 8078.575917005539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249680, "time": 8079.067492246628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249832, "time": 8083.473703622818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 8095.086840867996, "eval_episode/length": 278.0, "eval_episode/score": 0.13124999403953552, "eval_episode/reward_rate": 0.0035842293906810036}
{"step": 250016, "time": 8095.304263353348, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8095.313669919968, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8095.32141661644, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8095.328697443008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8095.336091518402, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8095.343320608139, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8095.350482225418, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250368, "time": 8106.182133674622, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 250648, "time": 8114.453652381897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250696, "time": 8115.9450051784515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250904, "time": 8122.293229103088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251896, "time": 8152.894864559174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251976, "time": 8155.357550144196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251992, "time": 8155.85883641243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252144, "time": 8160.93322634697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252680, "time": 8177.21865606308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252960, "time": 8186.054258584976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253008, "time": 8187.51834321022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253216, "time": 8193.969387054443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254208, "time": 8225.128151416779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254288, "time": 8227.576637983322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254304, "time": 8228.074669599533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254456, "time": 8232.534621715546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254681, "time": 8240.442505836487, "train_stats/mean_log_entropy": 1.7417811535101022, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.365418093887406, "train/action_min": 0.0, "train/action_std": 1.843134611695256, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007902318654884936, "train/actor_opt_grad_steps": 14830.0, "train/actor_opt_loss": -0.6737823481460912, "train/adv_mag": 0.003031076479647028, "train/adv_max": 0.0029379216832431717, "train/adv_mean": 0.00031682380060846156, "train/adv_min": -0.001491862840613528, "train/adv_std": 0.0005614410062968712, "train/cont_avg": 0.9965255967336684, "train/cont_loss_mean": 0.023180500018040662, "train/cont_loss_std": 0.320095724370733, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.686392433941364, "train/cont_pos_acc": 0.9999999853234794, "train/cont_pos_loss": 0.003418624670193273, "train/cont_pred": 0.9965872950290315, "train/cont_rate": 0.9965255967336684, "train/dyn_loss_mean": 1.000004689897125, "train/dyn_loss_std": 9.571357870628898e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02210965381666723, "train/extr_critic_critic_opt_grad_steps": 14830.0, "train/extr_critic_critic_opt_loss": 8604.436008165829, "train/extr_critic_mag": 0.026842370704190814, "train/extr_critic_max": 0.026842370704190814, "train/extr_critic_mean": 0.025815401918924036, "train/extr_critic_min": 0.024748275028401285, "train/extr_critic_std": 0.00029115663580602295, "train/extr_return_normed_mag": 0.004294512718541538, "train/extr_return_normed_max": 0.004294512718541538, "train/extr_return_normed_mean": 0.0014726291326588128, "train/extr_return_normed_min": -1.7842390204793844e-05, "train/extr_return_normed_std": 0.0006290127210413812, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.028953904679148042, "train/extr_return_raw_max": 0.028953904679148042, "train/extr_return_raw_mean": 0.02613202249397285, "train/extr_return_raw_min": 0.02464154957040171, "train/extr_return_raw_std": 0.0006290127230157617, "train/extr_reward_mag": 0.0006012527187864985, "train/extr_reward_max": 0.0006012527187864985, "train/extr_reward_mean": 0.00011310457983510522, "train/extr_reward_min": 1.5228836979698296e-05, "train/extr_reward_std": 0.00013899904207453654, "train/image_loss_mean": 0.18532619464337527, "train/image_loss_std": 0.10073559547788534, "train/model_loss_mean": 0.8099786115052113, "train/model_loss_std": 0.366712463224054, "train/model_opt_grad_norm": 40.25085720464812, "train/model_opt_grad_steps": 14815.150753768845, "train/model_opt_loss": 3032.904196887759, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3743.718592964824, "train/policy_entropy_mag": 1.9337162845697835, "train/policy_entropy_max": 1.9337162845697835, "train/policy_entropy_mean": 1.7670336386666226, "train/policy_entropy_min": 1.3280320131599004, "train/policy_entropy_std": 0.07833386243475442, "train/policy_logprob_mag": 4.688563862038617, "train/policy_logprob_max": -0.53622196876823, "train/policy_logprob_mean": -1.7674143607891983, "train/policy_logprob_min": -4.688563862038617, "train/policy_logprob_std": 0.5134447935837597, "train/policy_randomness_mag": 0.9937336504758902, "train/policy_randomness_max": 0.9937336504758902, "train/policy_randomness_mean": 0.908075711535449, "train/policy_randomness_min": 0.682473490286113, "train/policy_randomness_std": 0.04025564447335487, "train/post_ent_mag": 40.010992059755566, "train/post_ent_max": 40.010992059755566, "train/post_ent_mean": 39.43366022924682, "train/post_ent_min": 39.12139944335324, "train/post_ent_std": 0.16330673725311481, "train/prior_ent_mag": 42.73045111421364, "train/prior_ent_max": 42.73045111421364, "train/prior_ent_mean": 40.154855239331425, "train/prior_ent_min": 37.570821905854956, "train/prior_ent_std": 1.0046974791953311, "train/rep_loss_mean": 1.000004689897125, "train/rep_loss_std": 9.571357870628898e-05, "train/reward_avg": 6.111183314322115e-05, "train/reward_loss_mean": 0.0014690811296541187, "train/reward_loss_std": 0.038839551952937035, "train/reward_max_data": 0.057993089883171735, "train/reward_max_pred": 0.0005268888856897402, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00015807453825284176, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.874323037954477, "train/reward_pred": 5.1763272568134206e-05, "train/reward_rate": 0.00014722047738693466, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020117972046136856, "report/cont_loss_std": 0.3012711703777313, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.578005790710449, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037872574757784605, "report/cont_pred": 0.9962196946144104, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18044413626194, "report/image_loss_std": 0.11296617984771729, "report/model_loss_mean": 0.8006560802459717, "report/model_loss_std": 0.32015299797058105, "report/post_ent_mag": 37.57185363769531, "report/post_ent_max": 37.57185363769531, "report/post_ent_mean": 37.11617660522461, "report/post_ent_min": 36.82155990600586, "report/post_ent_std": 0.12243491411209106, "report/prior_ent_mag": 39.867462158203125, "report/prior_ent_max": 39.867462158203125, "report/prior_ent_mean": 37.6004524230957, "report/prior_ent_min": 35.64299011230469, "report/prior_ent_std": 0.811674177646637, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 9.38992016017437e-05, "report/reward_loss_std": 0.0002579691063147038, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0005495548248291016, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 9.38992016017437e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.341271076351404e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020117968320846558, "eval/cont_loss_std": 0.3012711703777313, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.578005790710449, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0037872574757784605, "eval/cont_pred": 0.9962196946144104, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18179607391357422, "eval/image_loss_std": 0.1093888059258461, "eval/model_loss_mean": 0.8020305633544922, "eval/model_loss_std": 0.32414236664772034, "eval/post_ent_mag": 37.589210510253906, "eval/post_ent_max": 37.589210510253906, "eval/post_ent_mean": 37.113033294677734, "eval/post_ent_min": 36.84034729003906, "eval/post_ent_std": 0.12364023923873901, "eval/prior_ent_mag": 39.96628189086914, "eval/prior_ent_max": 39.96628189086914, "eval/prior_ent_mean": 37.65903091430664, "eval/prior_ent_min": 35.39812088012695, "eval/prior_ent_std": 0.8328022956848145, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00011649122461676598, "eval/reward_loss_std": 0.0002900147810578346, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0005249977111816406, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00011649122461676598, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.1672843508422375e-05, "eval/reward_rate": 0.0, "replay/size": 254177.0, "replay/inserts": 31856.0, "replay/samples": 31856.0, "replay/insert_wait_avg": 1.4274279595858365e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.149881776764667e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61168.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3390420629903932e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2367963790893555e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.29354429245, "timer/env.step_count": 3982.0, "timer/env.step_total": 39.27835297584534, "timer/env.step_frac": 0.039266826423066226, "timer/env.step_avg": 0.009863976136575926, "timer/env.step_min": 0.008323192596435547, "timer/env.step_max": 0.03592944145202637, "timer/replay._sample_count": 31856.0, "timer/replay._sample_total": 17.492135286331177, "timer/replay._sample_frac": 0.017487002076679508, "timer/replay._sample_avg": 0.0005491001785011043, "timer/replay._sample_min": 0.00038123130798339844, "timer/replay._sample_max": 0.02849102020263672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4849.0, "timer/agent.policy_total": 53.48312997817993, "timer/agent.policy_frac": 0.053467434917827864, "timer/agent.policy_avg": 0.011029723649861814, "timer/agent.policy_min": 0.009484052658081055, "timer/agent.policy_max": 0.10005569458007812, "timer/dataset_train_count": 1991.0, "timer/dataset_train_total": 0.23023486137390137, "timer/dataset_train_frac": 0.00023016729707753562, "timer/dataset_train_avg": 0.00011563780079050796, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.0005345344543457031, "timer/agent.train_count": 1991.0, "timer/agent.train_total": 892.4329793453217, "timer/agent.train_frac": 0.8921710876146635, "timer/agent.train_avg": 0.44823354060538506, "timer/agent.train_min": 0.43506431579589844, "timer/agent.train_max": 0.7206583023071289, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47321438789367676, "timer/agent.report_frac": 0.00047307551927509573, "timer/agent.report_avg": 0.23660719394683838, "timer/agent.report_min": 0.2242574691772461, "timer/agent.report_max": 0.24895691871643066, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.647804260253906e-05, "timer/dataset_eval_frac": 3.646733782366008e-08, "timer/dataset_eval_avg": 3.647804260253906e-05, "timer/dataset_eval_min": 3.647804260253906e-05, "timer/dataset_eval_max": 3.647804260253906e-05, "fps": 31.846064641685878}
{"step": 254992, "time": 8250.179396152496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255272, "time": 8258.53639125824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255320, "time": 8260.038300037384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255520, "time": 8266.41458272934, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 255528, "time": 8266.447028636932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255936, "time": 8279.336929559708, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 256520, "time": 8297.015374422073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256600, "time": 8299.50746679306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256616, "time": 8300.011085510254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256768, "time": 8304.940190553665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257584, "time": 8330.12639284134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257696, "time": 8333.561037063599, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 257832, "time": 8337.520362854004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257840, "time": 8338.003032684326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258248, "time": 8350.41465306282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258912, "time": 8371.222321748734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258928, "time": 8371.718909025192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259080, "time": 8376.174668550491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259896, "time": 8401.30533027649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 8406.922258138657, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 260000, "time": 8409.996201992035, "eval_episode/length": 261.0, "eval_episode/score": 0.18437500298023224, "eval_episode/reward_rate": 0.003816793893129771}
{"step": 260000, "time": 8410.55485534668, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8410.563924312592, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8410.571121931076, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8410.577853918076, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8410.584669351578, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8410.59196472168, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260008, "time": 8410.619770288467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260144, "time": 8415.006404876709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260152, "time": 8415.037547111511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260560, "time": 8427.695308685303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261224, "time": 8447.895216941833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261240, "time": 8448.41745686531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261392, "time": 8453.331594944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261528, "time": 8457.27897977829, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 262208, "time": 8479.004222393036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262320, "time": 8482.473086833954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262456, "time": 8486.47525858879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262464, "time": 8486.948522806168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262872, "time": 8499.42615556717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263536, "time": 8520.199465036392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263704, "time": 8525.139815092087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263840, "time": 8529.546999454498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264520, "time": 8550.302779912949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264632, "time": 8553.740273475647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264768, "time": 8558.172496080399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264768, "time": 8558.182894706726, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 265184, "time": 8570.90795302391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265848, "time": 8591.17078447342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266016, "time": 8596.550573587418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266088, "time": 8598.550355196, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 266152, "time": 8600.514084100723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266832, "time": 8621.75405049324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266944, "time": 8625.177910327911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267080, "time": 8629.113742113113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267408, "time": 8639.494623184204, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 267416, "time": 8639.5247964859, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 267688, "time": 8647.887744426727, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 267856, "time": 8653.27392745018, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 268328, "time": 8667.51028752327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269144, "time": 8692.72404551506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269168, "time": 8693.69454073906, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 269224, "time": 8695.181574106216, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 269720, "time": 8710.566236495972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269728, "time": 8711.041404008865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270000, "time": 8719.380043029785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 8722.677487134933, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 270088, "time": 8723.007881879807, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 270088, "time": 8724.74363040924, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 270088, "time": 8725.646883964539, "eval_episode/length": 183.0, "eval_episode/score": 0.4281249940395355, "eval_episode/reward_rate": 0.005434782608695652}
{"step": 270088, "time": 8726.587953329086, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 270088, "time": 8726.724469900131, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 270088, "time": 8727.038695335388, "eval_episode/length": 219.0, "eval_episode/score": 0.31562501192092896, "eval_episode/reward_rate": 0.004545454545454545}
{"step": 270088, "time": 8728.882630109787, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 270168, "time": 8731.32177734375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270472, "time": 8741.173475980759, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 270640, "time": 8746.53682923317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271480, "time": 8772.149040699005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271536, "time": 8774.073850870132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272032, "time": 8789.370707273483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272040, "time": 8789.402152299881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272312, "time": 8797.76658463478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272480, "time": 8803.165331840515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272584, "time": 8806.115483522415, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 272952, "time": 8817.446863889694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272968, "time": 8817.951608896255, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 273256, "time": 8826.848436832428, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 273848, "time": 8844.983047246933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274344, "time": 8860.256434679031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274352, "time": 8860.756725549698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274624, "time": 8869.055931329727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274896, "time": 8877.395984888077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275264, "time": 8888.741201162338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275280, "time": 8889.231593370438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275568, "time": 8898.025347709656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275816, "time": 8905.407093286514, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 276160, "time": 8916.283795595169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276656, "time": 8931.511055231094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276656, "time": 8931.519095897675, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 276664, "time": 8931.548418045044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276936, "time": 8939.984952688217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277208, "time": 8948.314219713211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277576, "time": 8959.694058895111, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277880, "time": 8969.138214111328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278128, "time": 8976.980855464935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278696, "time": 8994.711076259613, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 278856, "time": 8999.769748926163, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 278968, "time": 9003.193449020386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278976, "time": 9003.668345928192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279248, "time": 9012.012553215027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279376, "time": 9015.921578407288, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 279520, "time": 9020.329451560974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279712, "time": 9026.197565317154, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 279888, "time": 9031.697875499725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279992, "time": 9034.693041563034, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 9039.043528795242, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 280072, "time": 9039.393678426743, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 280072, "time": 9039.420068740845, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 280072, "time": 9039.708799362183, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 280072, "time": 9039.915882825851, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 280072, "time": 9040.14547920227, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 280072, "time": 9041.061358451843, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 280072, "time": 9041.902963399887, "eval_episode/length": 232.0, "eval_episode/score": 0.2750000059604645, "eval_episode/reward_rate": 0.004291845493562232}
{"step": 280432, "time": 9053.157237291336, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 280440, "time": 9053.187222480774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280984, "time": 9069.942136526108, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 281168, "time": 9075.817481040955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281832, "time": 9096.144874095917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282024, "time": 9102.049107789993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282072, "time": 9103.544666051865, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 282168, "time": 9106.50031876564, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 282200, "time": 9107.504285812378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282304, "time": 9110.90827035904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282752, "time": 9124.775881528854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283296, "time": 9141.464567661285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283480, "time": 9146.901284217834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284144, "time": 9167.502063274384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284384, "time": 9174.837257862091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284480, "time": 9177.78742647171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284512, "time": 9178.90411233902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284616, "time": 9181.866759061813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285064, "time": 9195.57739186287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285608, "time": 9212.365120649338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285792, "time": 9218.234030485153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286456, "time": 9238.435059070587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286489, "time": 9240.482474088669, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.130999324297664, "train/action_min": 0.0, "train/action_std": 1.796057737234867, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0013802578050856045, "train/actor_opt_grad_steps": 16815.0, "train/actor_opt_loss": 8.217139296676972, "train/adv_mag": 0.008106486354437139, "train/adv_max": 0.008020192798640993, "train/adv_mean": 0.0013977103786288868, "train/adv_min": -0.0025232772747374546, "train/adv_std": 0.0013165853094754063, "train/cont_avg": 0.9964735243055556, "train/cont_loss_mean": 0.02346591095115538, "train/cont_loss_std": 0.32152598587405273, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.66593711078167, "train/cont_pos_acc": 0.9999999864534899, "train/cont_pos_loss": 0.0034869347082808464, "train/cont_pred": 0.9965192181895478, "train/cont_rate": 0.9964735243055556, "train/dyn_loss_mean": 1.0000011511523315, "train/dyn_loss_std": 3.264350343302758e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0615331173993205, "train/extr_critic_critic_opt_grad_steps": 16815.0, "train/extr_critic_critic_opt_loss": 11509.173985953283, "train/extr_critic_mag": 0.051398008760779795, "train/extr_critic_max": 0.051398008760779795, "train/extr_critic_mean": 0.04890927659215951, "train/extr_critic_min": 0.04651182709318219, "train/extr_critic_std": 0.0007451168044512583, "train/extr_return_normed_mag": 0.01252534431452402, "train/extr_return_normed_max": 0.01252534431452402, "train/extr_return_normed_mean": 0.004995168509218145, "train/extr_return_normed_min": 0.0012105435904378843, "train/extr_return_normed_std": 0.0015564587798011912, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.05783653774797314, "train/extr_return_raw_max": 0.05783653774797314, "train/extr_return_raw_mean": 0.05030636432947534, "train/extr_return_raw_min": 0.04652173702388701, "train/extr_return_raw_std": 0.001556458782153016, "train/extr_reward_mag": 0.004048549165629378, "train/extr_reward_max": 0.004048549165629378, "train/extr_reward_mean": 0.0003536339408670719, "train/extr_reward_min": 1.2402582650232798e-06, "train/extr_reward_std": 0.0006688603166137431, "train/image_loss_mean": 0.1753497113182087, "train/image_loss_std": 0.1031288586255878, "train/model_loss_mean": 0.8004310657881727, "train/model_loss_std": 0.37168910595202687, "train/model_opt_grad_norm": 38.70260188301203, "train/model_opt_grad_steps": 16798.939393939392, "train/model_opt_loss": 2647.6134853170374, "train/model_opt_model_opt_grad_overflow": 0.005050505050505051, "train/model_opt_model_opt_grad_scale": 3295.4545454545455, "train/policy_entropy_mag": 1.848476919260892, "train/policy_entropy_max": 1.848476919260892, "train/policy_entropy_mean": 1.3607516923938134, "train/policy_entropy_min": 0.5483262339851471, "train/policy_entropy_std": 0.24079529877112368, "train/policy_logprob_mag": 5.716869688997365, "train/policy_logprob_max": -0.15700424299340207, "train/policy_logprob_mean": -1.3607233443645517, "train/policy_logprob_min": -5.716869688997365, "train/policy_logprob_std": 0.8311602832994076, "train/policy_randomness_mag": 0.9499292795104209, "train/policy_randomness_max": 0.9499292795104209, "train/policy_randomness_mean": 0.699288080286498, "train/policy_randomness_min": 0.2817839582572983, "train/policy_randomness_std": 0.12374431216581301, "train/post_ent_mag": 34.71489994935315, "train/post_ent_max": 34.71489994935315, "train/post_ent_mean": 34.42038611209754, "train/post_ent_min": 34.19293767755682, "train/post_ent_std": 0.08094028688289902, "train/prior_ent_mag": 38.140081097381284, "train/prior_ent_max": 38.140081097381284, "train/prior_ent_mean": 35.62010917278251, "train/prior_ent_min": 33.956431937940195, "train/prior_ent_std": 0.8303883361695993, "train/rep_loss_mean": 1.0000011511523315, "train/rep_loss_std": 3.264350343302758e-05, "train/reward_avg": 7.880625075859376e-05, "train/reward_loss_mean": 0.0016147279570989236, "train/reward_loss_std": 0.044997210348553536, "train/reward_max_data": 0.0755839647744039, "train/reward_max_pred": 0.00237202945381704, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.000204628359778776, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.472528338432312, "train/reward_pred": 6.230222061276436e-05, "train/reward_rate": 0.00018742108585858585, "train_stats/mean_log_entropy": 1.3678207648687126, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014363061636686325, "report/cont_loss_std": 0.2555929124355316, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.792118549346924, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030562945175915956, "report/cont_pred": 0.9969483017921448, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12762735784053802, "report/image_loss_std": 0.10652071982622147, "report/model_loss_mean": 0.742431104183197, "report/model_loss_std": 0.2773534059524536, "report/post_ent_mag": 32.982608795166016, "report/post_ent_max": 32.982608795166016, "report/post_ent_mean": 32.77886199951172, "report/post_ent_min": 32.58839797973633, "report/post_ent_std": 0.058864008635282516, "report/prior_ent_mag": 35.107818603515625, "report/prior_ent_max": 35.107818603515625, "report/prior_ent_mean": 33.07057571411133, "report/prior_ent_min": 32.01462173461914, "report/prior_ent_std": 0.6263392567634583, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0004406832158565521, "report/reward_loss_std": 0.0015242245281115174, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.004618644714355469, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0004406832158565521, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00015206390526145697, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014362357556819916, "eval/cont_loss_std": 0.255592942237854, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.792118549346924, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0030555962584912777, "eval/cont_pred": 0.9969490766525269, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.000142216682434, "eval/dyn_loss_std": 0.004548868164420128, "eval/image_loss_mean": 0.2170090675354004, "eval/image_loss_std": 0.11034724116325378, "eval/model_loss_mean": 0.8317098617553711, "eval/model_loss_std": 0.28018614649772644, "eval/post_ent_mag": 33.017425537109375, "eval/post_ent_max": 33.017425537109375, "eval/post_ent_mean": 32.77260971069336, "eval/post_ent_min": 32.600181579589844, "eval/post_ent_std": 0.0632697120308876, "eval/prior_ent_mag": 35.5093994140625, "eval/prior_ent_max": 35.5093994140625, "eval/prior_ent_mean": 33.21931457519531, "eval/prior_ent_min": 31.998851776123047, "eval/prior_ent_std": 0.6664258241653442, "eval/rep_loss_mean": 1.000142216682434, "eval/rep_loss_std": 0.004548868164420128, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00025309622287750244, "eval/reward_loss_std": 0.0010494220769032836, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.004369020462036133, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00025309622287750244, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.704990614205599e-05, "eval/reward_rate": 0.0, "replay/size": 285985.0, "replay/inserts": 31808.0, "replay/samples": 31808.0, "replay/insert_wait_avg": 1.4297844058790918e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.166687667010056e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 67376.0, "eval_replay/inserts": 6208.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3004719596548178e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0223703384399, "timer/env.step_count": 3976.0, "timer/env.step_total": 39.674668312072754, "timer/env.step_frac": 0.03967378079616915, "timer/env.step_avg": 0.009978538307865381, "timer/env.step_min": 0.008167266845703125, "timer/env.step_max": 0.050638437271118164, "timer/replay._sample_count": 31808.0, "timer/replay._sample_total": 17.39507293701172, "timer/replay._sample_frac": 0.017394683812047788, "timer/replay._sample_avg": 0.0005468772930398554, "timer/replay._sample_min": 0.00040268898010253906, "timer/replay._sample_max": 0.030199050903320312, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4752.0, "timer/agent.policy_total": 53.382704734802246, "timer/agent.policy_frac": 0.05338151057234431, "timer/agent.policy_avg": 0.011233734161364108, "timer/agent.policy_min": 0.009080648422241211, "timer/agent.policy_max": 1.1450035572052002, "timer/dataset_train_count": 1988.0, "timer/dataset_train_total": 0.2311384677886963, "timer/dataset_train_frac": 0.00023113329725861186, "timer/dataset_train_avg": 0.00011626683490377077, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0006604194641113281, "timer/agent.train_count": 1988.0, "timer/agent.train_total": 892.9517533779144, "timer/agent.train_frac": 0.8929317781918324, "timer/agent.train_avg": 0.4491709021015666, "timer/agent.train_min": 0.4377884864807129, "timer/agent.train_max": 0.7206697463989258, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47643351554870605, "timer/agent.report_frac": 0.00047642285780813637, "timer/agent.report_avg": 0.23821675777435303, "timer/agent.report_min": 0.23103117942810059, "timer/agent.report_max": 0.24540233612060547, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313944115460285e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 31.806723538699234}
{"step": 286696, "time": 9246.666217327118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286792, "time": 9250.10068655014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286824, "time": 9251.091670274734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286928, "time": 9254.51737332344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287376, "time": 9268.276062250137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287920, "time": 9285.12734746933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288104, "time": 9290.524977207184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288768, "time": 9311.304465532303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289008, "time": 9318.608145236969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289104, "time": 9321.557816505432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289136, "time": 9322.543250322342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289240, "time": 9325.53266954422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289688, "time": 9339.359471321106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 9356.529412269592, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9356.537649869919, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9356.545292377472, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9356.553315162659, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9356.560735940933, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9356.56850194931, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9356.57766366005, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9356.585469722748, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290232, "time": 9362.109376907349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290416, "time": 9367.994949817657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291032, "time": 9386.644608020782, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 291080, "time": 9388.129570960999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291248, "time": 9393.643260478973, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 291320, "time": 9395.654415607452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291448, "time": 9399.567108392715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291552, "time": 9402.986745357513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291856, "time": 9412.33692574501, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 291992, "time": 9416.301256656647, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 292728, "time": 9439.01299905777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292976, "time": 9446.859936475754, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 293344, "time": 9458.249401569366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293392, "time": 9459.748503446579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293560, "time": 9464.683946609497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293632, "time": 9467.121286392212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293760, "time": 9471.042727947235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293904, "time": 9475.492492675781, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 293904, "time": 9475.500891685486, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 294168, "time": 9483.447918176651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294592, "time": 9496.708758592606, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 295232, "time": 9516.915776729584, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 295288, "time": 9518.420433282852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295656, "time": 9529.733029603958, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 295656, "time": 9529.741949558258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295704, "time": 9531.218349695206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295840, "time": 9535.619209051132, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 295912, "time": 9537.607339382172, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 295944, "time": 9538.762699842453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296072, "time": 9542.715469360352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296216, "time": 9547.151315927505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296416, "time": 9553.555227994919, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 296848, "time": 9566.849192857742, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 296904, "time": 9568.381830692291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296912, "time": 9568.956055402756, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 297584, "time": 9589.595475912094, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 297936, "time": 9600.686577796936, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 298152, "time": 9607.175407886505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298224, "time": 9609.625975608826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298256, "time": 9610.609768390656, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 298384, "time": 9614.5712621212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298528, "time": 9618.993470668793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299152, "time": 9638.174715995789, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 299160, "time": 9638.205417871475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299392, "time": 9645.559739589691, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 299744, "time": 9656.373193979263, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 299768, "time": 9656.894265413284, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 299808, "time": 9658.38796210289, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 299896, "time": 9660.93652510643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 9666.158030986786, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 300040, "time": 9666.960253953934, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 300040, "time": 9667.568255186081, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 300040, "time": 9668.402380228043, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 300040, "time": 9668.646264076233, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 300040, "time": 9670.243287086487, "eval_episode/length": 236.0, "eval_episode/score": 0.26249998807907104, "eval_episode/reward_rate": 0.004219409282700422}
{"step": 300040, "time": 9670.453160524368, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 300040, "time": 9671.022326469421, "eval_episode/length": 274.0, "eval_episode/score": 0.14374999701976776, "eval_episode/reward_rate": 0.0036363636363636364}
{"step": 300064, "time": 9671.982050657272, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 300248, "time": 9677.394832849503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300592, "time": 9688.22090125084, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 300696, "time": 9691.290642023087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300840, "time": 9695.747457027435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301144, "time": 9705.111474990845, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 301448, "time": 9714.46486234665, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 301472, "time": 9715.427371263504, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 301632, "time": 9720.45123052597, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 301640, "time": 9720.481234073639, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 301664, "time": 9721.445453882217, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 301872, "time": 9727.80157995224, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 302056, "time": 9733.215448379517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302072, "time": 9733.709134101868, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 302120, "time": 9735.197417974472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303008, "time": 9762.919558525085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303760, "time": 9786.568242788315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303944, "time": 9791.988461971283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303952, "time": 9792.483063697815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304184, "time": 9799.358560562134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304240, "time": 9801.296112298965, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 304368, "time": 9805.236585378647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304384, "time": 9805.73132944107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304440, "time": 9807.26593875885, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 305040, "time": 9826.093425750732, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 305320, "time": 9834.42215681076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305560, "time": 9841.901876449585, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 305792, "time": 9849.257495880127, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 306224, "time": 9862.527757883072, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 306256, "time": 9863.513513088226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306264, "time": 9863.54476094246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306496, "time": 9870.98377108574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306752, "time": 9878.867805480957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307352, "time": 9897.028344154358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307632, "time": 9905.955614805222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308104, "time": 9920.215733766556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308232, "time": 9924.146946668625, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 308288, "time": 9926.105688333511, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 308536, "time": 9933.607607126236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308568, "time": 9934.602888584137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308576, "time": 9935.07442522049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308808, "time": 9942.003113269806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309064, "time": 9949.866136312485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309664, "time": 9968.636260509491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 9984.878193378448, "eval_episode/length": 233.0, "eval_episode/score": 0.2718749940395355, "eval_episode/reward_rate": 0.004273504273504274}
{"step": 310024, "time": 9986.02398610115, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9986.031724691391, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9986.039037942886, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9986.046247720718, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9986.053703546524, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9986.060646533966, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 9986.067465782166, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310400, "time": 9997.898587226868, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 310544, "time": 10002.321899652481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310832, "time": 10011.197067975998, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 310848, "time": 10011.692817211151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310880, "time": 10012.677290439606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311120, "time": 10020.194278240204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311304, "time": 10025.855030536652, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 311336, "time": 10027.155642271042, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 311408, "time": 10029.56632900238, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 311600, "time": 10035.492913484573, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 311672, "time": 10037.483275413513, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 311720, "time": 10038.96498298645, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 312368, "time": 10059.139450788498, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 313144, "time": 10082.780795097351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313160, "time": 10083.278661727905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313432, "time": 10091.641764640808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313480, "time": 10093.113349676132, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 313624, "time": 10097.54224562645, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 313720, "time": 10100.507440805435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313912, "time": 10106.39892578125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313984, "time": 10108.935211658478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314032, "time": 10110.428233861923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314360, "time": 10120.248411417007, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 314680, "time": 10129.99242568016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314832, "time": 10134.870007753372, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 314840, "time": 10134.899391889572, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 314888, "time": 10136.364824056625, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 315144, "time": 10144.314716815948, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 315144, "time": 10144.324235200882, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 315456, "time": 10154.134008407593, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 315744, "time": 10162.93833899498, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 315792, "time": 10164.433132648468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315904, "time": 10167.883250236511, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 315952, "time": 10169.495199203491, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 316568, "time": 10188.157260417938, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 316672, "time": 10191.56909942627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316992, "time": 10201.579783201218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317200, "time": 10207.958401441574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317256, "time": 10209.470656633377, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 318056, "time": 10234.041290283203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318104, "time": 10235.523767709732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318216, "time": 10238.972759008408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318241, "time": 10240.494693279266, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.533045476405465, "train/action_min": 0.0, "train/action_std": 1.6527719725316494, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0046926988870836794, "train/actor_opt_grad_steps": 18800.0, "train/actor_opt_loss": 15.859576526448954, "train/adv_mag": 0.06430550155477907, "train/adv_max": 0.06345675136875267, "train/adv_mean": 0.006478030727078078, "train/adv_min": -0.010183502943372008, "train/adv_std": 0.007496699824199155, "train/cont_avg": 0.9962753219221105, "train/cont_loss_mean": 0.024267823245825628, "train/cont_loss_std": 0.3285449508202599, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.570803299242137, "train/cont_pos_acc": 0.9999999805311461, "train/cont_pos_loss": 0.003580538888260647, "train/cont_pred": 0.9964237755267464, "train/cont_rate": 0.9962753219221105, "train/dyn_loss_mean": 1.00000357747677, "train/dyn_loss_std": 9.824193763399226e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9796806085414848, "train/extr_critic_critic_opt_grad_steps": 18800.0, "train/extr_critic_critic_opt_loss": 8726.21352489989, "train/extr_critic_mag": 0.1797751601616941, "train/extr_critic_max": 0.1797751601616941, "train/extr_critic_mean": 0.17572207767609974, "train/extr_critic_min": 0.16406457448125483, "train/extr_critic_std": 0.0029680488919827564, "train/extr_return_normed_mag": 0.0797282653912228, "train/extr_return_normed_max": 0.07898659401353281, "train/extr_return_normed_mean": 0.01979855249165534, "train/extr_return_normed_min": 0.002037479013354335, "train/extr_return_normed_std": 0.008370902389287949, "train/extr_return_rate": 0.0001295540309522825, "train/extr_return_raw_mag": 0.24138767609194894, "train/extr_return_raw_max": 0.24138767609194894, "train/extr_return_raw_mean": 0.18219964198730698, "train/extr_return_raw_min": 0.16443856112921057, "train/extr_return_raw_std": 0.00837090236091537, "train/extr_reward_mag": 0.04142332975588851, "train/extr_reward_max": 0.04142332975588851, "train/extr_reward_mean": 0.0014226841096442787, "train/extr_reward_min": 4.4568699208935304e-07, "train/extr_reward_std": 0.003920803219050722, "train/image_loss_mean": 0.15790371506956954, "train/image_loss_std": 0.10516583432803801, "train/model_loss_mean": 0.784461069945714, "train/model_loss_std": 0.38518872048387576, "train/model_opt_grad_norm": 35.62906753118314, "train/model_opt_grad_steps": 18782.4824120603, "train/model_opt_loss": 2286.3135452653896, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2914.572864321608, "train/policy_entropy_mag": 1.6308252308236895, "train/policy_entropy_max": 1.6308252308236895, "train/policy_entropy_mean": 0.44439660214898574, "train/policy_entropy_min": 0.0659827006297495, "train/policy_entropy_std": 0.3313192055003727, "train/policy_logprob_mag": 6.54547004843477, "train/policy_logprob_max": -0.008812852274046172, "train/policy_logprob_mean": -0.4444019661926145, "train/policy_logprob_min": -6.54547004843477, "train/policy_logprob_std": 0.8799097109679601, "train/policy_randomness_mag": 0.8380784320471873, "train/policy_randomness_max": 0.8380784320471873, "train/policy_randomness_mean": 0.2283746901169494, "train/policy_randomness_min": 0.033908402556600284, "train/policy_randomness_std": 0.17026440050434227, "train/post_ent_mag": 31.998578172233238, "train/post_ent_max": 31.998578172233238, "train/post_ent_mean": 31.822946903094575, "train/post_ent_min": 31.654527731277234, "train/post_ent_std": 0.05527662474605905, "train/prior_ent_mag": 33.33529641041205, "train/prior_ent_max": 33.33529641041205, "train/prior_ent_mean": 31.525409871010325, "train/prior_ent_min": 30.418372887462827, "train/prior_ent_std": 0.4720034937762735, "train/rep_loss_mean": 1.00000357747677, "train/rep_loss_std": 9.824193763399226e-05, "train/reward_avg": 0.00015609971057926655, "train/reward_loss_mean": 0.0022873615813277775, "train/reward_loss_std": 0.05854962088881223, "train/reward_max_data": 0.13842650630216502, "train/reward_max_pred": 0.012034704337767021, "train/reward_neg_acc": 0.999990175716841, "train/reward_neg_loss": 0.00029379335820298153, "train/reward_pos_acc": 0.017857142857142856, "train/reward_pos_loss": 5.996695054428918, "train/reward_pred": 0.00011835425528206269, "train/reward_rate": 0.0003336997487437186, "train_stats/mean_log_entropy": 0.4330083761062171, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.01841059699654579, "report/cont_loss_std": 0.2877506911754608, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.2392191886901855, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030703169759362936, "report/cont_pred": 0.9969195127487183, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.14410749077796936, "report/image_loss_std": 0.10376980900764465, "report/model_loss_mean": 0.7628021240234375, "report/model_loss_std": 0.31277796626091003, "report/post_ent_mag": 30.699817657470703, "report/post_ent_max": 30.699817657470703, "report/post_ent_mean": 30.55987548828125, "report/post_ent_min": 30.38616180419922, "report/post_ent_std": 0.05444887652993202, "report/prior_ent_mag": 31.273096084594727, "report/prior_ent_max": 31.273096084594727, "report/prior_ent_mean": 29.7393856048584, "report/prior_ent_min": 28.450061798095703, "report/prior_ent_std": 0.3937844932079315, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00028399890288710594, "report/reward_loss_std": 0.0016909668920561671, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.00957345962524414, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00028399890288710594, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0001186886802315712, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.036785781383514404, "eval/cont_loss_std": 0.44240450859069824, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.79480504989624, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0028485418297350407, "eval/cont_pred": 0.9971541166305542, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2013581097126007, "eval/image_loss_std": 0.12559258937835693, "eval/model_loss_mean": 0.8381853103637695, "eval/model_loss_std": 0.464790940284729, "eval/post_ent_mag": 30.715744018554688, "eval/post_ent_max": 30.715744018554688, "eval/post_ent_mean": 30.550861358642578, "eval/post_ent_min": 30.39348030090332, "eval/post_ent_std": 0.0537695549428463, "eval/prior_ent_mag": 31.376361846923828, "eval/prior_ent_max": 31.376361846923828, "eval/prior_ent_mean": 29.809024810791016, "eval/prior_ent_min": 28.80280303955078, "eval/prior_ent_std": 0.3782389760017395, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 4.135631024837494e-05, "eval/reward_loss_std": 0.0004433437716215849, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.004893302917480469, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 4.135631024837494e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 1.7037848010659218e-05, "eval/reward_rate": 0.0, "replay/size": 317737.0, "replay/inserts": 31752.0, "replay/samples": 31744.0, "replay/insert_wait_avg": 1.419646279221369e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.183741865619537e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 74200.0, "eval_replay/inserts": 6824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2681883915926898e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.430511474609375e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9987649917603, "timer/env.step_count": 3969.0, "timer/env.step_total": 39.768264293670654, "timer/env.step_frac": 0.039768313407865394, "timer/env.step_avg": 0.010019718894852772, "timer/env.step_min": 0.00816035270690918, "timer/env.step_max": 0.0686335563659668, "timer/replay._sample_count": 31744.0, "timer/replay._sample_total": 17.350138902664185, "timer/replay._sample_frac": 0.017350160330255153, "timer/replay._sample_avg": 0.0005465643555526772, "timer/replay._sample_min": 0.0004048347473144531, "timer/replay._sample_max": 0.0354304313659668, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4822.0, "timer/agent.policy_total": 53.365395307540894, "timer/agent.policy_frac": 0.05336546121432521, "timer/agent.policy_avg": 0.011067066633666713, "timer/agent.policy_min": 0.009229421615600586, "timer/agent.policy_max": 0.10187935829162598, "timer/dataset_train_count": 1984.0, "timer/dataset_train_total": 0.2326056957244873, "timer/dataset_train_frac": 0.00023260598299479292, "timer/dataset_train_avg": 0.0001172407740546811, "timer/dataset_train_min": 0.00010180473327636719, "timer/dataset_train_max": 0.0003674030303955078, "timer/agent.train_count": 1984.0, "timer/agent.train_total": 891.8561148643494, "timer/agent.train_frac": 0.8918572163153602, "timer/agent.train_avg": 0.4495242514437245, "timer/agent.train_min": 0.4356355667114258, "timer/agent.train_max": 0.7075066566467285, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4841606616973877, "timer/agent.report_frac": 0.0004841612596405327, "timer/agent.report_avg": 0.24208033084869385, "timer/agent.report_min": 0.23316621780395508, "timer/agent.report_max": 0.2509944438934326, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.506111145019531e-05, "timer/dataset_eval_frac": 4.506116710110797e-08, "timer/dataset_eval_avg": 4.506111145019531e-05, "timer/dataset_eval_min": 4.506111145019531e-05, "timer/dataset_eval_max": 4.506111145019531e-05, "fps": 31.751483928164877}
{"step": 318264, "time": 10241.168153762817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318880, "time": 10260.404908180237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319040, "time": 10265.308572530746, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 319512, "time": 10279.980296134949, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 319512, "time": 10279.989454746246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319568, "time": 10281.938691139221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319640, "time": 10283.946588516235, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 319920, "time": 10292.887534856796, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 10296.799968719482, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 320008, "time": 10296.827880382538, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 320008, "time": 10297.19686126709, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 320008, "time": 10297.940281391144, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 320008, "time": 10298.070469141006, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 320008, "time": 10298.457607746124, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 320008, "time": 10298.62801861763, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 320008, "time": 10299.426439762115, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 320040, "time": 10300.412247419357, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 320208, "time": 10305.763859510422, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 320336, "time": 10309.684933662415, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 320416, "time": 10312.12082028389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321136, "time": 10334.066457986832, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 321192, "time": 10335.555220365524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321880, "time": 10356.667355537415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321952, "time": 10359.100117444992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322024, "time": 10361.077039003372, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 322232, "time": 10367.46424293518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322352, "time": 10371.362223863602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322520, "time": 10376.283438205719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322648, "time": 10380.277111768723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 322656, "time": 10380.758003234863, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 323152, "time": 10395.918322086334, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 323504, "time": 10406.702816009521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324192, "time": 10427.889393568039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324336, "time": 10432.266535282135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324544, "time": 10438.734262228012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324664, "time": 10442.173579216003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324960, "time": 10451.438888311386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324968, "time": 10451.469136714935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325048, "time": 10453.909311532974, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 325408, "time": 10465.217641353607, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 325440, "time": 10466.19879412651, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 325464, "time": 10466.717969417572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326056, "time": 10484.97414469719, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 326056, "time": 10484.982459545135, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 326640, "time": 10503.212557792664, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 326752, "time": 10506.629974126816, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 326856, "time": 10509.600373506546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327272, "time": 10522.359853982925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327280, "time": 10522.837894678116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327360, "time": 10525.30631017685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327704, "time": 10536.207007169724, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 327720, "time": 10536.707032680511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327728, "time": 10537.181443452835, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 327752, "time": 10537.70013141632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328080, "time": 10547.95512843132, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 328952, "time": 10574.475723743439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329584, "time": 10594.195799350739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329592, "time": 10594.225818157196, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 329592, "time": 10594.234403133392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329672, "time": 10596.684654712677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329904, "time": 10604.036002159119, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 330016, "time": 10607.445958852768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330040, "time": 10607.994246006012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 10614.186388015747, "eval_episode/length": 196.0, "eval_episode/score": 0.38749998807907104, "eval_episode/reward_rate": 0.005076142131979695}
{"step": 330096, "time": 10616.176001548767, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10616.184262752533, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10616.19173526764, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10616.199211597443, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10616.20976471901, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10616.218298912048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10616.22568154335, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330392, "time": 10625.167099952698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331264, "time": 10652.19685459137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331896, "time": 10671.27983880043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331904, "time": 10671.747722148895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331984, "time": 10674.206801891327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332216, "time": 10681.171098947525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332328, "time": 10684.589580535889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332352, "time": 10685.543652057648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332704, "time": 10696.252479314804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333576, "time": 10722.895699977875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334208, "time": 10742.428148269653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334216, "time": 10742.460833311081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334296, "time": 10744.903002500534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334528, "time": 10752.222616195679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334640, "time": 10755.61415719986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334664, "time": 10756.125810861588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335016, "time": 10766.943394422531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335152, "time": 10771.416305303574, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 335888, "time": 10794.37808251381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336112, "time": 10801.368121147156, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 336520, "time": 10813.540714502335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336528, "time": 10814.011566638947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336776, "time": 10821.333714962006, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 336952, "time": 10826.707145929337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336976, "time": 10827.66361284256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337328, "time": 10838.56395983696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337376, "time": 10840.041609287262, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 337784, "time": 10852.25948882103, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 337952, "time": 10857.60433769226, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 338024, "time": 10859.732362508774, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 338056, "time": 10860.731923103333, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 338120, "time": 10862.68148946762, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 338344, "time": 10869.518795728683, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 338488, "time": 10873.932939052582, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 338840, "time": 10884.6212079525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338928, "time": 10887.54451918602, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 338944, "time": 10888.034673690796, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 339208, "time": 10895.971616983414, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 339232, "time": 10896.929551362991, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 339408, "time": 10902.301703453064, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 339560, "time": 10906.718241930008, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 339688, "time": 10910.639136075974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339752, "time": 10912.582924127579, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 339912, "time": 10917.484674215317, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 10924.444255828857, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 340080, "time": 10924.612726211548, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 340080, "time": 10925.429863929749, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 340080, "time": 10926.98012638092, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 340080, "time": 10927.331551790237, "eval_episode/length": 216.0, "eval_episode/score": 0.32499998807907104, "eval_episode/reward_rate": 0.004608294930875576}
{"step": 340080, "time": 10927.670936584473, "eval_episode/length": 232.0, "eval_episode/score": 0.2750000059604645, "eval_episode/reward_rate": 0.004291845493562232}
{"step": 340080, "time": 10928.811068296432, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10928.81908082962, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10928.826200008392, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340096, "time": 10929.320119380951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340336, "time": 10936.667400360107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340368, "time": 10937.645487070084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340600, "time": 10944.546653747559, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 340608, "time": 10945.026913404465, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 340736, "time": 10949.025964736938, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 340776, "time": 10950.068097352982, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 341120, "time": 10960.815837144852, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 341376, "time": 10968.63846373558, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 341400, "time": 10969.172867298126, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 341456, "time": 10971.102551221848, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 341688, "time": 10977.991985797882, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 341872, "time": 10983.954775333405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341936, "time": 10985.897671937943, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 342568, "time": 11005.06357383728, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 342608, "time": 11006.52383685112, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 343024, "time": 11019.381885528564, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 343144, "time": 11022.836324214935, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 343272, "time": 11026.808895349503, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 343368, "time": 11029.76176404953, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 343712, "time": 11040.611658334732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343912, "time": 11046.491704702377, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 344000, "time": 11049.449674129486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344640, "time": 11069.73230624199, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 344920, "time": 11078.118649482727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345456, "time": 11094.586929559708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345584, "time": 11098.644666433334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345680, "time": 11101.599200963974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346024, "time": 11111.914149045944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346136, "time": 11115.33228135109, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 346224, "time": 11118.265191793442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346312, "time": 11120.721721887589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346952, "time": 11140.348251342773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347232, "time": 11149.094749689102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347768, "time": 11165.339968919754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347896, "time": 11169.273790597916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348336, "time": 11182.858301639557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348448, "time": 11186.265675067902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348536, "time": 11188.800619602203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348544, "time": 11189.266884565353, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 348624, "time": 11191.715011358261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349264, "time": 11211.296434879303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349544, "time": 11219.737080097198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 11243.41523551941, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11243.423341274261, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11243.43072772026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11243.437860250473, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11243.444851398468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11243.453028678894, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11243.45995759964, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11243.467647314072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350065, "time": 11244.028739213943, "train_stats/mean_log_entropy": 0.2259457303394734, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.579281600875471, "train/action_min": 0.0, "train/action_std": 1.5088935772977283, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010177899136245437, "train/actor_opt_grad_steps": 20790.0, "train/actor_opt_loss": 13.607679213729487, "train/adv_mag": 0.26582631873126006, "train/adv_max": 0.19387504608187844, "train/adv_mean": 0.013092802599505064, "train/adv_min": -0.15586813280929873, "train/adv_std": 0.027525476650358295, "train/cont_avg": 0.996368561557789, "train/cont_loss_mean": 0.022249942486310126, "train/cont_loss_std": 0.30615891117471544, "train/cont_neg_acc": 0.015325115038658762, "train/cont_neg_loss": 5.126896456413463, "train/cont_pos_acc": 0.9999507087558958, "train/cont_pos_loss": 0.0035738053067058476, "train/cont_pred": 0.9963864684104919, "train/cont_rate": 0.996368561557789, "train/dyn_loss_mean": 1.000029298528355, "train/dyn_loss_std": 0.0003786580861226103, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.5164246544073425, "train/extr_critic_critic_opt_grad_steps": 20790.0, "train/extr_critic_critic_opt_loss": 10766.40808902913, "train/extr_critic_mag": 0.4501829614591359, "train/extr_critic_max": 0.4501829614591359, "train/extr_critic_mean": 0.44155985641120066, "train/extr_critic_min": 0.41823690440786543, "train/extr_critic_std": 0.006507414453382131, "train/extr_return_normed_mag": 0.28145685432544304, "train/extr_return_normed_max": 0.23135056327934841, "train/extr_return_normed_mean": 0.04572983500933808, "train/extr_return_normed_min": -0.12159970252957177, "train/extr_return_normed_std": 0.02872327922249035, "train/extr_return_rate": 0.3463626861743452, "train/extr_return_raw_mag": 0.6402733517651582, "train/extr_return_raw_max": 0.6402733517651582, "train/extr_return_raw_mean": 0.45465264503081243, "train/extr_return_raw_min": 0.2873230862042787, "train/extr_return_raw_std": 0.028723279314920604, "train/extr_reward_mag": 0.16986218409322615, "train/extr_reward_max": 0.16986218409322615, "train/extr_reward_mean": 0.0030054134621784203, "train/extr_reward_min": 3.8817899311008164e-07, "train/extr_reward_std": 0.012432059738346277, "train/image_loss_mean": 0.13607397495801724, "train/image_loss_std": 0.10477273746501262, "train/model_loss_mean": 0.7614436817528615, "train/model_loss_std": 0.3733694469509412, "train/model_opt_grad_norm": 33.831401614088506, "train/model_opt_grad_steps": 20771.206030150755, "train/model_opt_loss": 2841.701284130614, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3731.1557788944724, "train/policy_entropy_mag": 1.535759253717547, "train/policy_entropy_max": 1.535759253717547, "train/policy_entropy_mean": 0.23254483092070824, "train/policy_entropy_min": 0.06470265999511259, "train/policy_entropy_std": 0.25390594493803664, "train/policy_logprob_mag": 6.5510009736871, "train/policy_logprob_max": -0.008610819265171512, "train/policy_logprob_mean": -0.2328126371730512, "train/policy_logprob_min": -6.5510009736871, "train/policy_logprob_std": 0.7593783128201662, "train/policy_randomness_mag": 0.7892241819420053, "train/policy_randomness_max": 0.7892241819420053, "train/policy_randomness_mean": 0.11950441101687638, "train/policy_randomness_min": 0.03325059165682026, "train/policy_randomness_std": 0.13048185172242735, "train/post_ent_mag": 31.591278018663875, "train/post_ent_max": 31.591278018663875, "train/post_ent_mean": 31.439071674442772, "train/post_ent_min": 31.29534020735391, "train/post_ent_std": 0.05034814101068219, "train/prior_ent_mag": 33.50945684538415, "train/prior_ent_max": 33.50945684538415, "train/prior_ent_mean": 31.30050767486419, "train/prior_ent_min": 30.145896739097097, "train/prior_ent_std": 0.4858425625005559, "train/rep_loss_mean": 1.000029298528355, "train/rep_loss_std": 0.0003786580861226103, "train/reward_avg": 0.0002855463825466331, "train/reward_loss_mean": 0.0031021667642041517, "train/reward_loss_std": 0.07391389222460537, "train/reward_max_data": 0.230150752967626, "train/reward_max_pred": 0.044523571603861285, "train/reward_neg_acc": 0.9999214246045405, "train/reward_neg_loss": 0.00046867380375653883, "train/reward_pos_acc": 0.08666666666666667, "train/reward_pos_loss": 5.156747179031372, "train/reward_pred": 0.00021508513205689402, "train/reward_rate": 0.0005005496231155779, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.018943626433610916, "report/cont_loss_std": 0.2763504385948181, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.983626365661621, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004355920013040304, "report/cont_pred": 0.9957168102264404, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09802311658859253, "report/image_loss_std": 0.08137398213148117, "report/model_loss_mean": 0.7174088358879089, "report/model_loss_std": 0.28514835238456726, "report/post_ent_mag": 32.380592346191406, "report/post_ent_max": 32.380592346191406, "report/post_ent_mean": 32.237701416015625, "report/post_ent_min": 32.11689376831055, "report/post_ent_std": 0.046052366495132446, "report/prior_ent_mag": 35.90506362915039, "report/prior_ent_max": 35.90506362915039, "report/prior_ent_mean": 33.69498062133789, "report/prior_ent_min": 32.46868133544922, "report/prior_ent_std": 0.6124643087387085, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00044204387813806534, "report/reward_loss_std": 0.0036757648922502995, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0252000093460083, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00044204387813806534, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00020355894230306149, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0029518650844693184, "eval/cont_loss_std": 0.010327738709747791, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0029518650844693184, "eval/cont_pred": 0.9971011877059937, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0000178813934326, "eval/dyn_loss_std": 0.0005743491346947849, "eval/image_loss_mean": 0.1877758502960205, "eval/image_loss_std": 0.12361884117126465, "eval/model_loss_mean": 0.7907976508140564, "eval/model_loss_std": 0.12381095439195633, "eval/post_ent_mag": 32.38273239135742, "eval/post_ent_max": 32.38273239135742, "eval/post_ent_mean": 32.22552490234375, "eval/post_ent_min": 32.110069274902344, "eval/post_ent_std": 0.04623313620686531, "eval/prior_ent_mag": 35.94044494628906, "eval/prior_ent_max": 35.94044494628906, "eval/prior_ent_mean": 33.726470947265625, "eval/prior_ent_min": 32.400882720947266, "eval/prior_ent_std": 0.6320686936378479, "eval/rep_loss_mean": 1.0000178813934326, "eval/rep_loss_std": 0.0005743491346947849, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.9120822697877884e-05, "eval/reward_loss_std": 0.0007752767414785922, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0097275972366333, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.9120822697877884e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.739299088716507e-05, "eval/reward_rate": 0.0, "replay/size": 349561.0, "replay/inserts": 31824.0, "replay/samples": 31824.0, "replay/insert_wait_avg": 1.4299196235614545e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.89387305745412e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 82656.0, "eval_replay/inserts": 8456.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3010109384441106e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1003.511458158493, "timer/env.step_count": 3978.0, "timer/env.step_total": 39.380326986312866, "timer/env.step_frac": 0.03924252848948855, "timer/env.step_avg": 0.009899529156941395, "timer/env.step_min": 0.008164167404174805, "timer/env.step_max": 0.0351407527923584, "timer/replay._sample_count": 31824.0, "timer/replay._sample_total": 17.134012460708618, "timer/replay._sample_frac": 0.01707405762177406, "timer/replay._sample_avg": 0.0005383990843611306, "timer/replay._sample_min": 0.0003781318664550781, "timer/replay._sample_max": 0.010097980499267578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5035.0, "timer/agent.policy_total": 56.30435276031494, "timer/agent.policy_frac": 0.056107334203873455, "timer/agent.policy_avg": 0.011182592405226403, "timer/agent.policy_min": 0.008630514144897461, "timer/agent.policy_max": 1.1183619499206543, "timer/dataset_train_count": 1989.0, "timer/dataset_train_total": 0.22987604141235352, "timer/dataset_train_frac": 0.00022907166584245145, "timer/dataset_train_avg": 0.00011557367592375742, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0010752677917480469, "timer/agent.train_count": 1989.0, "timer/agent.train_total": 890.512166261673, "timer/agent.train_frac": 0.8873961119445702, "timer/agent.train_avg": 0.44771853507374204, "timer/agent.train_min": 0.43506622314453125, "timer/agent.train_max": 0.6849441528320312, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4730978012084961, "timer/agent.report_frac": 0.00047144235111840223, "timer/agent.report_avg": 0.23654890060424805, "timer/agent.report_min": 0.22595882415771484, "timer/agent.report_max": 0.24713897705078125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.62396240234375e-05, "timer/dataset_eval_frac": 3.611281538323389e-08, "timer/dataset_eval_avg": 3.62396240234375e-05, "timer/dataset_eval_min": 3.62396240234375e-05, "timer/dataset_eval_max": 3.62396240234375e-05, "fps": 31.712051393789913}
{"step": 350080, "time": 11244.660889863968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350648, "time": 11262.11996459961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350760, "time": 11265.544355392456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350848, "time": 11268.465550422668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350856, "time": 11268.495990276337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350936, "time": 11270.946360349655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351576, "time": 11290.770028591156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351856, "time": 11299.56769990921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351944, "time": 11302.048259496689, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 352072, "time": 11305.973613023758, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 352104, "time": 11306.965581655502, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 352112, "time": 11307.46022939682, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 352168, "time": 11309.037316322327, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 352592, "time": 11322.781531333923, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 352656, "time": 11324.755422830582, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 352712, "time": 11326.243922710419, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 352856, "time": 11330.646008491516, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 352944, "time": 11333.578916549683, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 353104, "time": 11338.579137563705, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 353168, "time": 11340.546061754227, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 353248, "time": 11343.003342628479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353280, "time": 11343.98324751854, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 353416, "time": 11347.945727586746, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 353656, "time": 11355.29840350151, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 354024, "time": 11366.599972009659, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 355064, "time": 11398.758934020996, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 355168, "time": 11402.171484231949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355256, "time": 11404.635748624802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355504, "time": 11412.441974639893, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 355592, "time": 11414.906865358353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355600, "time": 11415.380558729172, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 355728, "time": 11419.27464222908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355968, "time": 11426.617669582367, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 355968, "time": 11426.626987218857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356112, "time": 11431.178679704666, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 356208, "time": 11434.095067977905, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 356336, "time": 11438.011287927628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356424, "time": 11440.47741484642, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 356472, "time": 11441.974067211151, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 356480, "time": 11442.448213338852, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 356656, "time": 11447.814675569534, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 356680, "time": 11448.328758478165, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 356840, "time": 11453.21246433258, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 356872, "time": 11454.197810649872, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 357184, "time": 11464.103429555893, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 357912, "time": 11486.179547309875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358000, "time": 11489.245284318924, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 358104, "time": 11492.230851650238, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 358400, "time": 11501.493272066116, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 358624, "time": 11508.342554569244, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 358648, "time": 11508.860695362091, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 358648, "time": 11508.86969089508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358784, "time": 11513.261816263199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358968, "time": 11518.76800274849, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358992, "time": 11519.750643014908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359184, "time": 11525.62990951538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359376, "time": 11531.472363710403, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 359496, "time": 11534.919926166534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359648, "time": 11539.786134719849, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 360000, "time": 11550.638774394989, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 11553.006286382675, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 360048, "time": 11553.700561285019, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 360048, "time": 11553.747968673706, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 360048, "time": 11553.774907827377, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 360048, "time": 11554.561589241028, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 360048, "time": 11555.234466552734, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 360048, "time": 11558.06914806366, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11558.078734874725, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11558.086338043213, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11558.093677520752, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360208, "time": 11562.954837560654, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 360936, "time": 11585.64204120636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360960, "time": 11586.606639623642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361096, "time": 11590.534794092178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361304, "time": 11596.856786966324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361656, "time": 11607.561107635498, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 361688, "time": 11608.672345399857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361808, "time": 11612.536857366562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362208, "time": 11624.715284824371, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 362312, "time": 11627.641843557358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362392, "time": 11630.082852602005, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 362456, "time": 11632.021636724472, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 362720, "time": 11640.400599479675, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 363176, "time": 11654.054701089859, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 363176, "time": 11654.065329551697, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 363232, "time": 11656.005549192429, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 363248, "time": 11656.498759269714, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 363272, "time": 11657.013508796692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363504, "time": 11664.339225530624, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 363608, "time": 11667.283957242966, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 363872, "time": 11675.686148881912, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 363944, "time": 11677.669497728348, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 364456, "time": 11693.344886302948, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 364520, "time": 11695.325493812561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364632, "time": 11698.92535996437, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 364800, "time": 11704.297499656677, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 364896, "time": 11707.239096403122, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 365288, "time": 11719.051435947418, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 365488, "time": 11725.386705160141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365560, "time": 11727.392129421234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365696, "time": 11731.865586996078, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 366032, "time": 11742.183824062347, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 366088, "time": 11743.670508623123, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 366544, "time": 11757.75926041603, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 366576, "time": 11758.859949350357, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 366808, "time": 11765.711023569107, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 366832, "time": 11766.69673371315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366944, "time": 11770.132940769196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367232, "time": 11778.93407535553, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 367448, "time": 11785.29263830185, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 367648, "time": 11791.783994436264, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 367872, "time": 11798.640323162079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368312, "time": 11811.936823606491, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 368344, "time": 11812.923897743225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368448, "time": 11816.376824378967, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 368808, "time": 11827.835687875748, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 368856, "time": 11829.321232318878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368888, "time": 11830.308205842972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368984, "time": 11833.259183645248, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 369456, "time": 11847.92056131363, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 369528, "time": 11850.012530565262, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 369960, "time": 11863.3691842556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 11866.07944226265, "eval_episode/length": 11.0, "eval_episode/score": 0.965624988079071, "eval_episode/reward_rate": 0.08333333333333333}
{"step": 370032, "time": 11867.627581834793, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 370032, "time": 11867.92021894455, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 370032, "time": 11868.248699188232, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 370032, "time": 11868.565890550613, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 370032, "time": 11870.222072601318, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 370032, "time": 11870.289808511734, "eval_episode/length": 214.0, "eval_episode/score": 0.33125001192092896, "eval_episode/reward_rate": 0.004651162790697674}
{"step": 370032, "time": 11871.001294136047, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 370368, "time": 11881.333250045776, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 370656, "time": 11890.134721279144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370760, "time": 11893.117954969406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370832, "time": 11896.118363142014, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 370864, "time": 11897.09786105156, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 371120, "time": 11904.921005010605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371200, "time": 11907.374977827072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371536, "time": 11917.727056741714, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 371768, "time": 11924.613057851791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371840, "time": 11927.051557540894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 372096, "time": 11934.857588291168, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 372144, "time": 11936.36063337326, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 372376, "time": 11943.32018828392, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 372528, "time": 11948.22375369072, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 372680, "time": 11952.657543420792, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 372696, "time": 11953.155402183533, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 372776, "time": 11955.618222236633, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 372936, "time": 11960.486799955368, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 372968, "time": 11961.458284139633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373080, "time": 11964.974365234375, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 373144, "time": 11966.951206922531, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 373144, "time": 11966.959917783737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373224, "time": 11969.496453046799, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 373328, "time": 11972.901884794235, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 373792, "time": 11987.071078777313, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 373808, "time": 11987.563652038574, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 374016, "time": 11993.861365795135, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 374688, "time": 12014.374790430069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374728, "time": 12015.373812675476, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 375008, "time": 12024.143670797348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375216, "time": 12030.568553209305, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 375248, "time": 12031.53789305687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375336, "time": 12033.996611595154, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 375456, "time": 12037.864265441895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375536, "time": 12040.30908203125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375832, "time": 12049.042265176773, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 376328, "time": 12064.218586683273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376384, "time": 12066.150161981583, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 376416, "time": 12067.130955934525, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 376552, "time": 12071.076229810715, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 376736, "time": 12076.92052936554, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 376896, "time": 12082.301827669144, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 376936, "time": 12083.325889110565, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 377000, "time": 12085.28969836235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377528, "time": 12101.510353803635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377560, "time": 12102.51151418686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377584, "time": 12103.47880911827, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 377616, "time": 12104.453241348267, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 377720, "time": 12107.398402690887, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 378088, "time": 12118.77576470375, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 378120, "time": 12119.758723258972, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 378136, "time": 12120.255161046982, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 378592, "time": 12134.364501476288, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 378632, "time": 12135.375625610352, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 378720, "time": 12138.298390865326, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 378864, "time": 12142.69788813591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378920, "time": 12144.188698530197, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 378928, "time": 12144.659251213074, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 379192, "time": 12152.661325454712, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 379336, "time": 12157.08492064476, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 379872, "time": 12173.629890918732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 12178.947231769562, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 380016, "time": 12178.99491930008, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 380016, "time": 12179.97850227356, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 380016, "time": 12181.08955001831, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 380016, "time": 12181.47046303749, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 380016, "time": 12184.410565853119, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 380016, "time": 12184.579221963882, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12184.588861942291, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12184.59637260437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12184.603513240814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380200, "time": 12189.965788841248, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 380224, "time": 12190.93350315094, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 380496, "time": 12199.236391305923, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 380664, "time": 12204.136457681656, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 380864, "time": 12210.623725891113, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 380904, "time": 12211.622815608978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381176, "time": 12219.970421791077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381232, "time": 12221.910778522491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381240, "time": 12221.952788591385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381728, "time": 12237.027498960495, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 381945, "time": 12244.502233982086, "train_stats/mean_log_entropy": 0.14901117186565868, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.522069269688285, "train/action_min": 0.0, "train/action_std": 1.5960346430390324, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011206701215375309, "train/actor_opt_grad_steps": 22780.0, "train/actor_opt_loss": 1.7069423782203965, "train/adv_mag": 0.4784477799382042, "train/adv_max": 0.24402249787920086, "train/adv_mean": 0.0066372492159205276, "train/adv_min": -0.4283226803319538, "train/adv_std": 0.033419567686809815, "train/cont_avg": 0.9962655072236181, "train/cont_loss_mean": 0.01891652969690274, "train/cont_loss_std": 0.2709645747263265, "train/cont_neg_acc": 0.1248971976224005, "train/cont_neg_loss": 4.205527752338682, "train/cont_pos_acc": 0.9998817276115992, "train/cont_pos_loss": 0.0034654320547609922, "train/cont_pred": 0.9961373826966213, "train/cont_rate": 0.9962655072236181, "train/dyn_loss_mean": 1.00001436082562, "train/dyn_loss_std": 0.0004216716310723647, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1700632032287779, "train/extr_critic_critic_opt_grad_steps": 22780.0, "train/extr_critic_critic_opt_loss": 9727.439661687344, "train/extr_critic_mag": 0.680160042628571, "train/extr_critic_max": 0.680160042628571, "train/extr_critic_mean": 0.662867739272477, "train/extr_critic_min": 0.6370796528293858, "train/extr_critic_std": 0.008905751600243787, "train/extr_return_normed_mag": 0.47026356500596855, "train/extr_return_normed_max": 0.2884857441911745, "train/extr_return_normed_mean": 0.038154628201523544, "train/extr_return_normed_min": -0.39254146814346313, "train/extr_return_normed_std": 0.03531354474109696, "train/extr_return_rate": 0.9933489429291769, "train/extr_return_raw_mag": 0.9198370054738605, "train/extr_return_raw_max": 0.9198370054738605, "train/extr_return_raw_mean": 0.6695059217400288, "train/extr_return_raw_min": 0.23880979313922288, "train/extr_return_raw_std": 0.03531354489085737, "train/extr_reward_mag": 0.24870287832902305, "train/extr_reward_max": 0.24870287832902305, "train/extr_reward_mean": 0.002955811670788297, "train/extr_reward_min": 2.2164541273260835e-08, "train/extr_reward_std": 0.012805831627382068, "train/image_loss_mean": 0.11906315419991412, "train/image_loss_std": 0.10337841615604995, "train/model_loss_mean": 0.7417223174967359, "train/model_loss_std": 0.3511596461711217, "train/model_opt_grad_norm": 32.524461664746156, "train/model_opt_grad_steps": 22759.628140703517, "train/model_opt_loss": 2095.9799332355137, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2826.6331658291456, "train/policy_entropy_mag": 1.4747029123593813, "train/policy_entropy_max": 1.4747029123593813, "train/policy_entropy_mean": 0.16542532998862577, "train/policy_entropy_min": 0.06468690242899124, "train/policy_entropy_std": 0.20678830775783288, "train/policy_logprob_mag": 6.55107930677021, "train/policy_logprob_max": -0.008608213415247711, "train/policy_logprob_mean": -0.16568572235167325, "train/policy_logprob_min": -6.55107930677021, "train/policy_logprob_std": 0.6998137145785231, "train/policy_randomness_mag": 0.7578474283218384, "train/policy_randomness_max": 0.7578474283218384, "train/policy_randomness_mean": 0.08501180768686922, "train/policy_randomness_min": 0.033242493774273886, "train/policy_randomness_std": 0.10626817386054513, "train/post_ent_mag": 31.607956316003847, "train/post_ent_max": 31.607956316003847, "train/post_ent_mean": 31.45705844169885, "train/post_ent_min": 31.337586608963395, "train/post_ent_std": 0.04550532723341755, "train/prior_ent_mag": 35.92312863603908, "train/prior_ent_max": 35.92312863603908, "train/prior_ent_mean": 33.14093632913714, "train/prior_ent_min": 31.826006434071605, "train/prior_ent_std": 0.6103329670489134, "train/rep_loss_mean": 1.00001436082562, "train/rep_loss_std": 0.0004216716310723647, "train/reward_avg": 0.00039596174084277234, "train/reward_loss_mean": 0.0037339975964979983, "train/reward_loss_std": 0.08570583143704992, "train/reward_max_data": 0.3055904503893014, "train/reward_max_pred": 0.0794846017157013, "train/reward_neg_acc": 0.9998821562259042, "train/reward_neg_loss": 0.0005593272738466414, "train/reward_pos_acc": 0.19587628896703424, "train/reward_pos_loss": 4.479821045374133, "train/reward_pred": 0.00030137337077334146, "train/reward_rate": 0.0007115656407035176, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.016837315633893013, "report/cont_loss_std": 0.23570802807807922, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.152669906616211, "report/cont_pos_acc": 0.9990177154541016, "report/cont_pos_loss": 0.004248910583555698, "report/cont_pred": 0.994270920753479, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10159028321504593, "report/image_loss_std": 0.0947832390666008, "report/model_loss_mean": 0.7185708284378052, "report/model_loss_std": 0.2555101811885834, "report/post_ent_mag": 31.112655639648438, "report/post_ent_max": 31.112655639648438, "report/post_ent_mean": 30.955913543701172, "report/post_ent_min": 30.847103118896484, "report/post_ent_std": 0.046622127294540405, "report/prior_ent_mag": 34.18217468261719, "report/prior_ent_max": 34.18217468261719, "report/prior_ent_mean": 32.27898025512695, "report/prior_ent_min": 31.151811599731445, "report/prior_ent_std": 0.6196600794792175, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001431899145245552, "report/reward_loss_std": 0.001122353714890778, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.00932168960571289, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001431899145245552, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.376253440976143e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.021996142342686653, "eval/cont_loss_std": 0.3200940787792206, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.548336029052734, "eval/cont_pos_acc": 0.9980430603027344, "eval/cont_pos_loss": 0.009224440902471542, "eval/cont_pred": 0.9950501322746277, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21988674998283386, "eval/image_loss_std": 0.13588827848434448, "eval/model_loss_mean": 0.8419032096862793, "eval/model_loss_std": 0.35386061668395996, "eval/post_ent_mag": 31.115129470825195, "eval/post_ent_max": 31.115129470825195, "eval/post_ent_mean": 30.944324493408203, "eval/post_ent_min": 30.8265380859375, "eval/post_ent_std": 0.045468058437108994, "eval/prior_ent_mag": 35.5676155090332, "eval/prior_ent_max": 35.5676155090332, "eval/prior_ent_mean": 32.26903533935547, "eval/prior_ent_min": 31.022228240966797, "eval/prior_ent_std": 0.6068758368492126, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 2.0326580852270126e-05, "eval/reward_loss_std": 0.00022576941410079598, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0025904178619384766, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 2.0326580852270126e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.829520083963871e-06, "eval/reward_rate": 0.0, "replay/size": 381441.0, "replay/inserts": 31880.0, "replay/samples": 31888.0, "replay/insert_wait_avg": 1.4173864869580814e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.946902418160522e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 89280.0, "eval_replay/inserts": 6624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2938815038561245e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.8030405044555664e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.452755689621, "timer/env.step_count": 3985.0, "timer/env.step_total": 39.702903747558594, "timer/env.step_frac": 0.039684936166916776, "timer/env.step_avg": 0.009963087515071165, "timer/env.step_min": 0.008059024810791016, "timer/env.step_max": 0.03612852096557617, "timer/replay._sample_count": 31888.0, "timer/replay._sample_total": 17.322139024734497, "timer/replay._sample_frac": 0.017314299876953404, "timer/replay._sample_avg": 0.0005432181079006052, "timer/replay._sample_min": 0.00041413307189941406, "timer/replay._sample_max": 0.0256655216217041, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4813.0, "timer/agent.policy_total": 52.51609396934509, "timer/agent.policy_frac": 0.0524923277692861, "timer/agent.policy_avg": 0.010911301468802221, "timer/agent.policy_min": 0.009211540222167969, "timer/agent.policy_max": 0.07916092872619629, "timer/dataset_train_count": 1993.0, "timer/dataset_train_total": 0.22973084449768066, "timer/dataset_train_frac": 0.00022962687962144215, "timer/dataset_train_avg": 0.00011526886327028633, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0003921985626220703, "timer/agent.train_count": 1993.0, "timer/agent.train_total": 892.3262491226196, "timer/agent.train_frac": 0.8919224261694708, "timer/agent.train_avg": 0.44773018019198174, "timer/agent.train_min": 0.4359605312347412, "timer/agent.train_max": 0.7063524723052979, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48711466789245605, "timer/agent.report_frac": 0.00048689422376240404, "timer/agent.report_avg": 0.24355733394622803, "timer/agent.report_min": 0.23425626754760742, "timer/agent.report_max": 0.25285840034484863, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.1484832763671875e-05, "timer/dataset_eval_frac": 4.146605876963776e-08, "timer/dataset_eval_avg": 4.1484832763671875e-05, "timer/dataset_eval_min": 4.1484832763671875e-05, "timer/dataset_eval_max": 4.1484832763671875e-05, "fps": 31.864949506520166}
{"step": 382048, "time": 12247.653796434402, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 382272, "time": 12254.515218496323, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 382536, "time": 12262.387227535248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382800, "time": 12270.839612483978, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 382808, "time": 12270.873726844788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382976, "time": 12276.3155002594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383096, "time": 12279.78587436676, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 383200, "time": 12283.197531700134, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 383264, "time": 12285.149447441101, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 383488, "time": 12292.015595197678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383544, "time": 12293.499338388443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383648, "time": 12296.89688873291, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 383656, "time": 12296.925891637802, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 383672, "time": 12297.41932964325, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 383816, "time": 12301.886293172836, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 384008, "time": 12307.706698656082, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 384216, "time": 12314.051394462585, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 384320, "time": 12317.471579551697, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 384448, "time": 12321.415692090988, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 384760, "time": 12330.90241265297, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 385120, "time": 12342.7247569561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385288, "time": 12347.668380737305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385328, "time": 12349.111859321594, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 385408, "time": 12351.579014539719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385632, "time": 12358.45626616478, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 385960, "time": 12368.333430051804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386016, "time": 12370.261484384537, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 386536, "time": 12386.007849216461, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 386632, "time": 12389.05460858345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386840, "time": 12395.501008749008, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 387072, "time": 12402.829032182693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387432, "time": 12413.614541769028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387600, "time": 12419.032874822617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387688, "time": 12421.497542142868, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 387720, "time": 12422.47595334053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388272, "time": 12439.589787006378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388328, "time": 12441.073334693909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388848, "time": 12457.203990221024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389152, "time": 12466.434480428696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389744, "time": 12484.587269067764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389912, "time": 12489.484461307526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 12492.391988039017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 12498.855496883392, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12498.863673686981, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12498.876694440842, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12498.886221647263, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12498.893487930298, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12498.900448083878, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12498.907439470291, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12498.914492845535, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390032, "time": 12499.91044163704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390128, "time": 12502.831624984741, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 390376, "time": 12510.323263645172, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 390584, "time": 12516.673628807068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390640, "time": 12518.60103559494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391160, "time": 12534.25127530098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391376, "time": 12541.156937599182, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 391464, "time": 12543.611126184464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392224, "time": 12567.119613409042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392312, "time": 12569.747031927109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392440, "time": 12573.685667276382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392688, "time": 12581.496616363525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392896, "time": 12587.814028024673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393376, "time": 12603.13948559761, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 393472, "time": 12606.078346252441, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393584, "time": 12609.520642518997, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 393776, "time": 12615.416380167007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394000, "time": 12622.26355600357, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 394040, "time": 12623.276644945145, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 394536, "time": 12638.607526540756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394624, "time": 12641.49138879776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394824, "time": 12647.338451862335, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 395000, "time": 12653.218492746353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395208, "time": 12659.719736099243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395688, "time": 12674.382514953613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396088, "time": 12686.633826971054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396352, "time": 12695.097601413727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396768, "time": 12707.851935625076, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 396848, "time": 12710.30591249466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396936, "time": 12712.791098833084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397136, "time": 12719.258513212204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397312, "time": 12724.65087389946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397520, "time": 12730.991747617722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398000, "time": 12745.631624221802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398000, "time": 12745.66245007515, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 398664, "time": 12765.978343725204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399080, "time": 12778.873602628708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399160, "time": 12781.346375465393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399248, "time": 12785.044819116592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399312, "time": 12787.006435871124, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 399336, "time": 12787.516564130783, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 399448, "time": 12790.917892217636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400000, "time": 12807.990401983261, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 12811.247988939285, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 400088, "time": 12811.539084911346, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 400088, "time": 12812.129122257233, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 400088, "time": 12812.391422986984, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 400088, "time": 12813.12392282486, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 400088, "time": 12813.725360393524, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 400088, "time": 12816.40042757988, "eval_episode/length": 189.0, "eval_episode/score": 0.40937501192092896, "eval_episode/reward_rate": 0.005263157894736842}
{"step": 400088, "time": 12816.656073093414, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12816.667514562607, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12816.679266929626, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12816.68947148323, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400224, "time": 12821.046962499619, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 400288, "time": 12823.00832271576, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 400312, "time": 12823.524526119232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400752, "time": 12837.156420469284, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 400976, "time": 12844.13200378418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401112, "time": 12848.0888671875, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 401192, "time": 12850.5407102108, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 401264, "time": 12852.995824098587, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 401480, "time": 12859.845231056213, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 401760, "time": 12868.774689912796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402312, "time": 12885.309066534042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402600, "time": 12894.11139512062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402616, "time": 12894.602890491486, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 403064, "time": 12908.42039346695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403424, "time": 12919.708874702454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403504, "time": 12922.160492897034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403576, "time": 12924.147880077362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403792, "time": 12931.14739704132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404072, "time": 12939.511871814728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404912, "time": 12965.689641475677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404928, "time": 12966.184272289276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405152, "time": 12973.07282280922, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 405376, "time": 12979.92827963829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405736, "time": 12990.832541704178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405816, "time": 12993.258682727814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405888, "time": 12995.682544469833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406384, "time": 13010.833363771439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407136, "time": 13033.96521282196, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 407224, "time": 13036.449755907059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407240, "time": 13036.944005012512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407464, "time": 13043.785109519958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407936, "time": 13058.625705718994, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 408048, "time": 13062.084665060043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408200, "time": 13066.562313318253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408632, "time": 13079.953169107437, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 408696, "time": 13081.909266710281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409136, "time": 13095.647849082947, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 409256, "time": 13099.090141057968, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 409448, "time": 13104.991121292114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409552, "time": 13108.46029829979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409600, "time": 13110.158118486404, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 409768, "time": 13115.46231341362, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 13126.051318645477, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 410072, "time": 13126.932338953018, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 410072, "time": 13127.298305034637, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 410072, "time": 13127.43563580513, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 410072, "time": 13128.428077936172, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 410072, "time": 13130.993254423141, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13131.001664161682, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13131.009038448334, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13131.01628446579, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410136, "time": 13132.96761894226, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 410160, "time": 13133.920249462128, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 410248, "time": 13136.386231899261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410512, "time": 13144.824698925018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410728, "time": 13151.313817977905, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 410880, "time": 13156.215353250504, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 410880, "time": 13156.224421024323, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 411288, "time": 13168.594602108002, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 411344, "time": 13170.574366092682, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 411504, "time": 13175.486649990082, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 411568, "time": 13177.446265220642, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 411568, "time": 13177.459320783615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411568, "time": 13177.466155290604, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 411616, "time": 13178.942616224289, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 411720, "time": 13181.961960077286, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 411768, "time": 13183.4428896904, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 411856, "time": 13186.37228012085, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 412112, "time": 13194.20257282257, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 412144, "time": 13195.184586048126, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 412472, "time": 13205.103083610535, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 412472, "time": 13205.111240625381, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 412584, "time": 13208.502895832062, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 412784, "time": 13214.839557647705, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 413344, "time": 13232.085804700851, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 413729, "time": 13244.5028424263, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.582588847558103, "train/action_min": 0.0, "train/action_std": 1.6404942154285296, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012137274782000175, "train/actor_opt_grad_steps": 24770.0, "train/actor_opt_loss": -5.412786596833761, "train/adv_mag": 0.6826811411871982, "train/adv_max": 0.2911476151428031, "train/adv_mean": 0.0035482462545492217, "train/adv_min": -0.6595011266631696, "train/adv_std": 0.042243144907824805, "train/cont_avg": 0.9961281014447236, "train/cont_loss_mean": 0.01524424266617689, "train/cont_loss_std": 0.23303089115824832, "train/cont_neg_acc": 0.2820132860571754, "train/cont_neg_loss": 3.1873763380809783, "train/cont_pos_acc": 0.9997684826802968, "train/cont_pos_loss": 0.0030289513314021143, "train/cont_pred": 0.9961202860477582, "train/cont_rate": 0.9961281014447236, "train/dyn_loss_mean": 1.0000054386991952, "train/dyn_loss_std": 0.0001739342519179093, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.706746806601184, "train/extr_critic_critic_opt_grad_steps": 24770.0, "train/extr_critic_critic_opt_loss": 11255.300724815485, "train/extr_critic_mag": 0.8441361787930206, "train/extr_critic_max": 0.8441361787930206, "train/extr_critic_mean": 0.8119788885715619, "train/extr_critic_min": 0.7756113676569569, "train/extr_critic_std": 0.010493141503059236, "train/extr_return_normed_mag": 0.659020122870728, "train/extr_return_normed_max": 0.34137666824475005, "train/extr_return_normed_mean": 0.03688992583485386, "train/extr_return_normed_min": -0.6208373167406973, "train/extr_return_normed_std": 0.04434675158904725, "train/extr_return_rate": 0.9953563848332544, "train/extr_return_raw_mag": 1.1200138974429374, "train/extr_return_raw_max": 1.1200138974429374, "train/extr_return_raw_mean": 0.8155271923122693, "train/extr_return_raw_min": 0.1577999127570109, "train/extr_return_raw_std": 0.044346751537567106, "train/extr_reward_mag": 0.317041803844011, "train/extr_reward_max": 0.317041803844011, "train/extr_reward_mean": 0.0025679561207579897, "train/extr_reward_min": 2.330272041972558e-07, "train/extr_reward_std": 0.014562681194479067, "train/image_loss_mean": 0.10372974502680889, "train/image_loss_std": 0.09892518241800854, "train/model_loss_mean": 0.7234159857783485, "train/model_loss_std": 0.32637277979347573, "train/model_opt_grad_norm": 30.594865846873528, "train/model_opt_grad_steps": 24748.618090452263, "train/model_opt_loss": 3344.9130761228016, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4635.678391959799, "train/policy_entropy_mag": 1.4145017191393292, "train/policy_entropy_max": 1.4145017191393292, "train/policy_entropy_mean": 0.15807455104200085, "train/policy_entropy_min": 0.06468693829661039, "train/policy_entropy_std": 0.19841523880335554, "train/policy_logprob_mag": 6.5510798387192, "train/policy_logprob_max": -0.00860824967130794, "train/policy_logprob_mean": -0.1578424090341707, "train/policy_logprob_min": -6.5510798387192, "train/policy_logprob_std": 0.6922649070246136, "train/policy_randomness_mag": 0.7269101298634132, "train/policy_randomness_max": 0.7269101298634132, "train/policy_randomness_mean": 0.08123425411144693, "train/policy_randomness_min": 0.0332425121199246, "train/policy_randomness_std": 0.10196526831568185, "train/post_ent_mag": 30.65507963554344, "train/post_ent_max": 30.65507963554344, "train/post_ent_mean": 30.495601404851406, "train/post_ent_min": 30.373097932518426, "train/post_ent_std": 0.04766136452780297, "train/prior_ent_mag": 33.993977168097565, "train/prior_ent_max": 33.993977168097565, "train/prior_ent_mean": 31.44184285072825, "train/prior_ent_min": 29.746851782103878, "train/prior_ent_std": 0.6826002594813629, "train/rep_loss_mean": 1.0000054386991952, "train/rep_loss_std": 0.0001739342519179093, "train/reward_avg": 0.0005108703920648704, "train/reward_loss_mean": 0.004438713195279765, "train/reward_loss_std": 0.09739153630591008, "train/reward_max_data": 0.37300565228540095, "train/reward_max_pred": 0.10393692800148048, "train/reward_neg_acc": 0.999798688157719, "train/reward_neg_loss": 0.0008294356180638386, "train/reward_pos_acc": 0.26060606078668075, "train/reward_pos_loss": 4.327024425159801, "train/reward_pred": 0.0004099985951997677, "train/reward_rate": 0.0008146199748743718, "train_stats/mean_log_entropy": 0.16008651014787473, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.007778482511639595, "report/cont_loss_std": 0.17601841688156128, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.9275097846984863, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0021377443335950375, "report/cont_pred": 0.9961237907409668, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10873864591121674, "report/image_loss_std": 0.08919554203748703, "report/model_loss_mean": 0.7166038751602173, "report/model_loss_std": 0.1988794505596161, "report/post_ent_mag": 30.270526885986328, "report/post_ent_max": 30.270526885986328, "report/post_ent_mean": 30.118452072143555, "report/post_ent_min": 30.00859260559082, "report/post_ent_std": 0.04261353984475136, "report/prior_ent_mag": 33.05911636352539, "report/prior_ent_max": 33.05911636352539, "report/prior_ent_mean": 30.180500030517578, "report/prior_ent_min": 28.01065444946289, "report/prior_ent_std": 0.8166871070861816, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 8.671684190630913e-05, "report/reward_loss_std": 0.000574268342461437, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.006512045860290527, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 8.671684190630913e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.135654307901859e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.018128948286175728, "eval/cont_loss_std": 0.35837262868881226, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.961691856384277, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.0025838161818683147, "eval/cont_pred": 0.997826337814331, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0001318454742432, "eval/dyn_loss_std": 0.004219228867441416, "eval/image_loss_mean": 0.25034868717193604, "eval/image_loss_std": 0.15578418970108032, "eval/model_loss_mean": 0.8686020374298096, "eval/model_loss_std": 0.3936159014701843, "eval/post_ent_mag": 30.269943237304688, "eval/post_ent_max": 30.269943237304688, "eval/post_ent_mean": 30.109149932861328, "eval/post_ent_min": 30.023914337158203, "eval/post_ent_std": 0.0422501415014267, "eval/prior_ent_mag": 33.456790924072266, "eval/prior_ent_max": 33.456790924072266, "eval/prior_ent_mean": 30.109989166259766, "eval/prior_ent_min": 28.09612274169922, "eval/prior_ent_std": 0.884318470954895, "eval/rep_loss_mean": 1.0001318454742432, "eval/rep_loss_std": 0.004219228867441416, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 4.5219436287879944e-05, "eval/reward_loss_std": 0.00030952694942243397, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0024989843368530273, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 4.5219436287879944e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.1277694031596184e-05, "eval/reward_rate": 0.0, "replay/size": 413225.0, "replay/inserts": 31784.0, "replay/samples": 31776.0, "replay/insert_wait_avg": 1.4226727061988184e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.047165738131704e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 96216.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2963150886790838e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9862177371979, "timer/env.step_count": 3973.0, "timer/env.step_total": 39.485955476760864, "timer/env.step_frac": 0.039486499690076726, "timer/env.step_avg": 0.009938574245346304, "timer/env.step_min": 0.008165836334228516, "timer/env.step_max": 0.03611564636230469, "timer/replay._sample_count": 31776.0, "timer/replay._sample_total": 17.283488035202026, "timer/replay._sample_frac": 0.01728372624405932, "timer/replay._sample_avg": 0.0005439164160121483, "timer/replay._sample_min": 0.0004391670227050781, "timer/replay._sample_max": 0.026368141174316406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4840.0, "timer/agent.policy_total": 53.3302047252655, "timer/agent.policy_frac": 0.05333093974629257, "timer/agent.policy_avg": 0.011018637339930889, "timer/agent.policy_min": 0.009088754653930664, "timer/agent.policy_max": 0.10144758224487305, "timer/dataset_train_count": 1986.0, "timer/dataset_train_total": 0.23003530502319336, "timer/dataset_train_frac": 0.00023003847547391695, "timer/dataset_train_avg": 0.00011582845167330985, "timer/dataset_train_min": 0.00010085105895996094, "timer/dataset_train_max": 0.0007960796356201172, "timer/agent.train_count": 1986.0, "timer/agent.train_total": 890.5373742580414, "timer/agent.train_frac": 0.8905496480473291, "timer/agent.train_avg": 0.44840753990837934, "timer/agent.train_min": 0.4349863529205322, "timer/agent.train_max": 0.824662446975708, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4763948917388916, "timer/agent.report_frac": 0.00047640145762897995, "timer/agent.report_avg": 0.2381974458694458, "timer/agent.report_min": 0.23054742813110352, "timer/agent.report_max": 0.24584746360778809, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.4094326708494196e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 31.783922781426156}
{"step": 413880, "time": 13249.12138581276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414080, "time": 13255.46077823639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414120, "time": 13256.46459555626, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 414176, "time": 13258.447696208954, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 414208, "time": 13259.54567027092, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 414408, "time": 13265.456492424011, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 414424, "time": 13265.963615179062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414456, "time": 13266.957874298096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414456, "time": 13266.96593093872, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 414672, "time": 13273.870788097382, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 414856, "time": 13279.28814792633, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 415040, "time": 13285.153671503067, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 415120, "time": 13287.62537240982, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 415168, "time": 13289.265291929245, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 415392, "time": 13296.118352413177, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 415472, "time": 13298.591075658798, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 415568, "time": 13301.563537836075, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 415672, "time": 13304.549731016159, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 415864, "time": 13310.411808252335, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 415880, "time": 13310.903464317322, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 416296, "time": 13323.820443153381, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 416344, "time": 13325.292813777924, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 416576, "time": 13332.629748344421, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 416704, "time": 13336.556519508362, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 416928, "time": 13343.426525831223, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 417168, "time": 13350.844943761826, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 417224, "time": 13352.344334602356, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 417288, "time": 13354.329156637192, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 417352, "time": 13356.288982391357, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 417424, "time": 13358.730702638626, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 417432, "time": 13358.761563062668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418016, "time": 13377.426154613495, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 418192, "time": 13382.954497814178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418328, "time": 13386.905655384064, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 418368, "time": 13388.37314748764, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 418656, "time": 13397.219004631042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418672, "time": 13397.736057281494, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 419016, "time": 13408.091393709183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419080, "time": 13410.19648385048, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 419112, "time": 13411.18653678894, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 419320, "time": 13417.638540744781, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 419432, "time": 13421.056865930557, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 419536, "time": 13424.499816417694, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 419536, "time": 13424.509585142136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419584, "time": 13425.980161190033, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 419592, "time": 13426.008698701859, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 419712, "time": 13429.920980930328, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 419800, "time": 13432.44441318512, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 420032, "time": 13439.96299290657, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 13441.602900505066, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 420056, "time": 13441.629405021667, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 420056, "time": 13442.319592475891, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 420056, "time": 13442.388167858124, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 420056, "time": 13443.718014478683, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 420056, "time": 13444.368705272675, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 420056, "time": 13445.51351261139, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 420056, "time": 13447.101646900177, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13447.111528396606, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13447.119225025177, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13447.126227617264, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420224, "time": 13452.5179874897, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 420312, "time": 13455.004889726639, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 420560, "time": 13462.80591249466, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 420680, "time": 13466.266454458237, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 421096, "time": 13479.22240614891, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 421424, "time": 13489.488540410995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421840, "time": 13502.394982099533, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 421848, "time": 13502.425307035446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421848, "time": 13502.433678388596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421896, "time": 13503.926642894745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422032, "time": 13508.329798221588, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 422112, "time": 13510.774965763092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422272, "time": 13515.686195135117, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 422872, "time": 13534.015184164047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422928, "time": 13535.971049785614, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 422960, "time": 13536.957133054733, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 423408, "time": 13550.640219211578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423896, "time": 13565.519439220428, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 423912, "time": 13566.013941764832, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 424136, "time": 13572.903442621231, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 424160, "time": 13573.863012313843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424192, "time": 13574.847699642181, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 424192, "time": 13574.855309963226, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 424208, "time": 13575.356143712997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424344, "time": 13579.321527957916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424584, "time": 13586.69027543068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424624, "time": 13588.17107796669, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 424952, "time": 13598.130363464355, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 425016, "time": 13600.083275556564, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 425040, "time": 13601.045706510544, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 425272, "time": 13607.929465532303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425352, "time": 13610.374491930008, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 425376, "time": 13611.34026145935, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 425728, "time": 13622.26796579361, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 425864, "time": 13626.208995342255, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 425968, "time": 13629.659082174301, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 426072, "time": 13633.13494181633, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 426400, "time": 13643.381712198257, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 426504, "time": 13646.3425989151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426936, "time": 13659.697257757187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427328, "time": 13671.938491821289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427584, "time": 13679.87179684639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427800, "time": 13686.323192834854, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 427808, "time": 13686.795257806778, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 427880, "time": 13688.780721187592, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 428224, "time": 13699.549840688705, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 428280, "time": 13701.064831972122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428384, "time": 13704.493996858597, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 428384, "time": 13704.503891706467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428480, "time": 13707.48220872879, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 428816, "time": 13717.943498849869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429056, "time": 13725.293894052505, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 429120, "time": 13727.272862911224, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 429352, "time": 13734.129954099655, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 429464, "time": 13737.591917276382, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 429568, "time": 13741.152768850327, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 13756.186351299286, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 430040, "time": 13756.778733253479, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 430040, "time": 13757.505271673203, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 430040, "time": 13757.59552359581, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 430040, "time": 13758.117948293686, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 430040, "time": 13758.71676826477, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 430040, "time": 13760.159146785736, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 430040, "time": 13761.54345369339, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13761.55167555809, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430088, "time": 13763.02464723587, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 430256, "time": 13768.461596488953, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 430536, "time": 13776.90258193016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430696, "time": 13781.818543434143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430712, "time": 13782.319268465042, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 430792, "time": 13784.779343128204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431088, "time": 13794.089812517166, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 431344, "time": 13802.063931703568, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 431352, "time": 13802.093535661697, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 431432, "time": 13804.53491306305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431520, "time": 13807.447365522385, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 431776, "time": 13815.2893075943, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 432128, "time": 13826.100275278091, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 432568, "time": 13839.442396640778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432648, "time": 13841.946342229843, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 433008, "time": 13853.185107469559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433024, "time": 13853.680196523666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433272, "time": 13861.195093154907, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 433272, "time": 13861.204734802246, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 433328, "time": 13863.14428448677, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 433464, "time": 13867.105095863342, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 433504, "time": 13868.56271481514, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 433696, "time": 13874.49422955513, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 434000, "time": 13883.900790214539, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 434256, "time": 13892.402511358261, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 434392, "time": 13896.367531776428, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 434552, "time": 13901.245923280716, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 434584, "time": 13902.235933542252, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 434736, "time": 13907.118326425552, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 434736, "time": 13907.126372098923, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 434928, "time": 13913.017478704453, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 435080, "time": 13917.455580949783, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 435288, "time": 13923.93892788887, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 435368, "time": 13926.397503137589, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 435584, "time": 13933.24100613594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435776, "time": 13939.174996614456, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 436120, "time": 13949.658472299576, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 436312, "time": 13955.600327730179, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 436312, "time": 13955.608568668365, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 436384, "time": 13958.053852558136, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 436704, "time": 13967.887731552124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436896, "time": 13973.808806419373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436936, "time": 13974.857232570648, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 437048, "time": 13978.297192811966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437168, "time": 13982.317615032196, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 437456, "time": 13991.185110330582, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 438440, "time": 14021.287638664246, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 438440, "time": 14021.308970928192, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 438496, "time": 14023.24177122116, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 438504, "time": 14023.270939588547, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 438624, "time": 14027.190765857697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438624, "time": 14027.20314002037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438696, "time": 14029.21221780777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439328, "time": 14048.904385089874, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 439360, "time": 14049.886332273483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439576, "time": 14057.654852628708, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 14072.357098340988, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 440024, "time": 14072.883719682693, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 440024, "time": 14072.978528022766, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 440024, "time": 14073.137690782547, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 440024, "time": 14073.29560661316, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 440024, "time": 14073.365295886993, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 440024, "time": 14073.39166879654, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 440024, "time": 14074.30249428749, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 440048, "time": 14075.26445031166, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 440424, "time": 14086.535985946655, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 440448, "time": 14087.517033100128, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 440512, "time": 14089.469635009766, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 440584, "time": 14091.453548669815, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 440752, "time": 14096.830999612808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440808, "time": 14098.368550539017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441000, "time": 14104.296441793442, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 441208, "time": 14110.665822267532, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 441408, "time": 14117.024787664413, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 441520, "time": 14120.471870422363, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 441672, "time": 14124.925658226013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441848, "time": 14130.40424323082, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 441856, "time": 14130.877435922623, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 441984, "time": 14134.824142456055, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 442200, "time": 14141.268575429916, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 442232, "time": 14142.251126527786, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 442568, "time": 14153.00885105133, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 442648, "time": 14155.452400445938, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 442848, "time": 14161.938056707382, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 442896, "time": 14163.421721935272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443096, "time": 14169.330398082733, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 443136, "time": 14170.78569483757, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 443184, "time": 14172.284005641937, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 443232, "time": 14173.75082731247, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 443336, "time": 14176.732311964035, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 443520, "time": 14182.602718353271, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 443672, "time": 14187.050779819489, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 443984, "time": 14196.93163394928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444024, "time": 14197.925533533096, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 444128, "time": 14201.354951620102, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 444320, "time": 14207.244889974594, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 444448, "time": 14211.189369440079, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 444712, "time": 14219.190456151962, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 444744, "time": 14220.170885324478, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 444824, "time": 14222.637208223343, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 445072, "time": 14230.460317850113, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 445176, "time": 14233.404589653015, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 445272, "time": 14236.376323699951, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 445296, "time": 14237.342883348465, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 445320, "time": 14237.85625052452, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 445400, "time": 14240.312191963196, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 445513, "time": 14244.772902011871, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.698659569326073, "train/action_min": 0.0, "train/action_std": 1.8820479734979494, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013259286294935854, "train/actor_opt_grad_steps": 26755.0, "train/actor_opt_loss": -5.262344615804408, "train/adv_mag": 0.784504487658992, "train/adv_max": 0.2906801137659285, "train/adv_mean": 0.004271623901405117, "train/adv_min": -0.7656839080531188, "train/adv_std": 0.04402420960714796, "train/cont_avg": 0.9961085464015151, "train/cont_loss_mean": 0.012630944036775164, "train/cont_loss_std": 0.20106506012050868, "train/cont_neg_acc": 0.395580262287843, "train/cont_neg_loss": 2.572721593312406, "train/cont_pos_acc": 0.999816773515759, "train/cont_pos_loss": 0.002613835015294208, "train/cont_pred": 0.996075013370225, "train/cont_rate": 0.9961085464015151, "train/dyn_loss_mean": 1.0000079563169768, "train/dyn_loss_std": 0.0002544564293459942, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7549892555395461, "train/extr_critic_critic_opt_grad_steps": 26755.0, "train/extr_critic_critic_opt_loss": 6848.178342260496, "train/extr_critic_mag": 0.9301010267903106, "train/extr_critic_max": 0.9301010267903106, "train/extr_critic_mean": 0.8988087132121577, "train/extr_critic_min": 0.8497799604830115, "train/extr_critic_std": 0.011300004985785544, "train/extr_return_normed_mag": 0.7591792474491428, "train/extr_return_normed_max": 0.32666458505572693, "train/extr_return_normed_mean": 0.0402699890193727, "train/extr_return_normed_min": -0.7311464433718209, "train/extr_return_normed_std": 0.046367851546918505, "train/extr_return_rate": 0.9952227822457901, "train/extr_return_raw_mag": 1.1894749710054109, "train/extr_return_raw_max": 1.1894749710054109, "train/extr_return_raw_mean": 0.9030804200605913, "train/extr_return_raw_min": 0.13166394257786299, "train/extr_return_raw_std": 0.04636785149988201, "train/extr_reward_mag": 0.3359746613887825, "train/extr_reward_max": 0.3359746613887825, "train/extr_reward_mean": 0.002967614443141337, "train/extr_reward_min": 1.426899071895715e-07, "train/extr_reward_std": 0.014221120501675576, "train/image_loss_mean": 0.09769212842138127, "train/image_loss_std": 0.09850111261311204, "train/model_loss_mean": 0.7154847293189077, "train/model_loss_std": 0.3143228438090194, "train/model_opt_grad_norm": 29.511770932361333, "train/model_opt_grad_steps": 26731.989898989897, "train/model_opt_loss": 2732.9884994969225, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3825.757575757576, "train/policy_entropy_mag": 1.4011340129255043, "train/policy_entropy_max": 1.4011340129255043, "train/policy_entropy_mean": 0.1312809857831459, "train/policy_entropy_min": 0.06468672768184633, "train/policy_entropy_std": 0.16878121639742996, "train/policy_logprob_mag": 6.551080082402085, "train/policy_logprob_max": -0.008608207219477856, "train/policy_logprob_mean": -0.13203796240115406, "train/policy_logprob_min": -6.551080082402085, "train/policy_logprob_std": 0.6711460568688132, "train/policy_randomness_mag": 0.7200404884237231, "train/policy_randomness_max": 0.7200404884237231, "train/policy_randomness_mean": 0.06746508499061821, "train/policy_randomness_min": 0.03324240421631722, "train/policy_randomness_std": 0.08673639275660419, "train/post_ent_mag": 29.996184397225427, "train/post_ent_max": 29.996184397225427, "train/post_ent_mean": 29.846410905471956, "train/post_ent_min": 29.734837609108048, "train/post_ent_std": 0.04536248056801281, "train/prior_ent_mag": 32.588056930387864, "train/prior_ent_max": 32.588056930387864, "train/prior_ent_mean": 29.94602406627, "train/prior_ent_min": 28.072346369425457, "train/prior_ent_std": 0.7142938673496246, "train/rep_loss_mean": 1.0000079563169768, "train/rep_loss_std": 0.0002544564293459942, "train/reward_avg": 0.0006145592868216971, "train/reward_loss_mean": 0.005156864135201569, "train/reward_loss_std": 0.1097423117325613, "train/reward_max_data": 0.4221275242214853, "train/reward_max_pred": 0.12162411212921143, "train/reward_neg_acc": 0.9998716242385634, "train/reward_neg_loss": 0.0008336832618835909, "train/reward_pos_acc": 0.24043715903993512, "train/reward_pos_loss": 4.314577508168142, "train/reward_pred": 0.000490998050828248, "train/reward_rate": 0.001006155303030303, "train_stats/mean_log_entropy": 0.11831124205821253, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.009198160842061043, "report/cont_loss_std": 0.17829027771949768, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.513235330581665, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0018405589507892728, "report/cont_pred": 0.9971290826797485, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07745194435119629, "report/image_loss_std": 0.07922367751598358, "report/model_loss_mean": 0.6914865970611572, "report/model_loss_std": 0.27083155512809753, "report/post_ent_mag": 29.96440315246582, "report/post_ent_max": 29.96440315246582, "report/post_ent_mean": 29.82342529296875, "report/post_ent_min": 29.718318939208984, "report/post_ent_std": 0.040739260613918304, "report/prior_ent_mag": 32.16789245605469, "report/prior_ent_max": 32.16789245605469, "report/prior_ent_mean": 29.690044403076172, "report/prior_ent_min": 27.977052688598633, "report/prior_ent_std": 0.5997716188430786, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007720947032794356, "report/reward_loss_mean": 0.004836463835090399, "report/reward_loss_std": 0.12058219313621521, "report/reward_max_data": 0.7906249761581421, "report/reward_max_pred": 0.03755784034729004, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0010709390044212341, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.856968641281128, "report/reward_pred": 0.0005444932030513883, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03675471246242523, "eval/cont_loss_std": 0.5901592969894409, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.20654582977295, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0007947473786771297, "eval/cont_pred": 0.9992197751998901, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0001107454299927, "eval/dyn_loss_std": 0.003540998324751854, "eval/image_loss_mean": 0.24405533075332642, "eval/image_loss_std": 0.13768687844276428, "eval/model_loss_mean": 0.880946934223175, "eval/model_loss_std": 0.6055986881256104, "eval/post_ent_mag": 29.944095611572266, "eval/post_ent_max": 29.944095611572266, "eval/post_ent_mean": 29.805461883544922, "eval/post_ent_min": 29.71685791015625, "eval/post_ent_std": 0.04280135780572891, "eval/prior_ent_mag": 32.16789245605469, "eval/prior_ent_max": 32.16789245605469, "eval/prior_ent_mean": 29.637184143066406, "eval/prior_ent_min": 27.949806213378906, "eval/prior_ent_std": 0.658556342124939, "eval/rep_loss_mean": 1.0001107454299927, "eval/rep_loss_std": 0.003540998324751854, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 7.042009383440018e-05, "eval/reward_loss_std": 0.0007117694476619363, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0064896345138549805, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 7.042009383440018e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.384239971637726e-05, "eval/reward_rate": 0.0, "replay/size": 445009.0, "replay/inserts": 31784.0, "replay/samples": 31792.0, "replay/insert_wait_avg": 1.4258832257009412e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.076884480415424e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5704.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2762750515931117e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2520062923431, "timer/env.step_count": 3973.0, "timer/env.step_total": 40.10532569885254, "timer/env.step_frac": 0.04009522145075406, "timer/env.step_avg": 0.01009446909107791, "timer/env.step_min": 0.008339643478393555, "timer/env.step_max": 0.038230180740356445, "timer/replay._sample_count": 31792.0, "timer/replay._sample_total": 17.341538190841675, "timer/replay._sample_frac": 0.017337169115133243, "timer/replay._sample_avg": 0.0005454686144577779, "timer/replay._sample_min": 0.0004162788391113281, "timer/replay._sample_max": 0.027551651000976562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4686.0, "timer/agent.policy_total": 51.91048073768616, "timer/agent.policy_frac": 0.051897402265758924, "timer/agent.policy_avg": 0.011077780780556159, "timer/agent.policy_min": 0.009107589721679688, "timer/agent.policy_max": 0.09013915061950684, "timer/dataset_train_count": 1987.0, "timer/dataset_train_total": 0.23067855834960938, "timer/dataset_train_frac": 0.00023062044054744847, "timer/dataset_train_avg": 0.00011609388945627045, "timer/dataset_train_min": 9.942054748535156e-05, "timer/dataset_train_max": 0.0005185604095458984, "timer/agent.train_count": 1987.0, "timer/agent.train_total": 894.317093372345, "timer/agent.train_frac": 0.8940917766187048, "timer/agent.train_avg": 0.4500840932925742, "timer/agent.train_min": 0.43750905990600586, "timer/agent.train_max": 1.8119139671325684, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4821922779083252, "timer/agent.report_frac": 0.0004820707930351255, "timer/agent.report_avg": 0.2410961389541626, "timer/agent.report_min": 0.2329263687133789, "timer/agent.report_max": 0.2492659091949463, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313183306470802e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 31.775451985046836}
{"step": 445528, "time": 14244.825806379318, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 445664, "time": 14249.748716592789, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 445736, "time": 14251.768473863602, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 445768, "time": 14252.757270097733, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 445920, "time": 14257.6715528965, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 446200, "time": 14266.05650305748, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 446232, "time": 14267.039311647415, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 446272, "time": 14268.487441778183, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 446296, "time": 14269.002352952957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446824, "time": 14285.336731433868, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 446864, "time": 14286.810065984726, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 447104, "time": 14294.204266548157, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 447168, "time": 14296.184012889862, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 447208, "time": 14297.200288534164, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 447272, "time": 14299.173734903336, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 447472, "time": 14305.603809833527, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 447496, "time": 14306.123915195465, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 447592, "time": 14309.21468448639, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 447608, "time": 14309.715159893036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448032, "time": 14323.026556968689, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 448256, "time": 14329.916502952576, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 448296, "time": 14330.947060108185, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 448376, "time": 14333.417281866074, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 448496, "time": 14337.348138570786, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 448824, "time": 14347.312569856644, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 449080, "time": 14355.23185133934, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 449128, "time": 14356.700006008148, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 449480, "time": 14367.532143831253, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 449520, "time": 14369.09362244606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449840, "time": 14378.90050983429, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 449920, "time": 14381.39179635048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449960, "time": 14382.40481543541, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 14385.24465084076, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 450008, "time": 14385.334781646729, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 450008, "time": 14385.684393882751, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 450008, "time": 14385.712162733078, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 450008, "time": 14386.162685871124, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 450008, "time": 14386.24039530754, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 450008, "time": 14386.679484128952, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 450008, "time": 14386.848608016968, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 450008, "time": 14386.855483293533, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 450152, "time": 14391.274470329285, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 450200, "time": 14392.761523485184, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 450208, "time": 14393.232318878174, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 450384, "time": 14398.749359369278, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 450568, "time": 14404.407622098923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450632, "time": 14406.665382623672, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 450840, "time": 14413.06155705452, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 451112, "time": 14421.402268886566, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 451344, "time": 14428.871201992035, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 451368, "time": 14429.38541150093, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 451416, "time": 14430.860584259033, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 451696, "time": 14439.70360159874, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 451872, "time": 14445.098901033401, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 452080, "time": 14451.499331712723, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 452088, "time": 14451.52962231636, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 452152, "time": 14453.518186092377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452208, "time": 14455.462242603302, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 452424, "time": 14461.941132545471, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 452464, "time": 14463.415202856064, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 452592, "time": 14467.340462207794, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 452696, "time": 14470.298039197922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452712, "time": 14470.79689502716, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 453176, "time": 14485.020698070526, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 453232, "time": 14486.983654499054, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 453384, "time": 14491.545273542404, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 453440, "time": 14493.494164943695, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 453664, "time": 14500.324970006943, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 453872, "time": 14506.678584098816, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 453912, "time": 14507.682915687561, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 454128, "time": 14514.523880720139, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 454392, "time": 14522.47676539421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454424, "time": 14523.45405459404, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 454424, "time": 14523.461707353592, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 454984, "time": 14540.605699539185, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 455008, "time": 14541.587512731552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455016, "time": 14541.617501735687, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 455296, "time": 14550.500909090042, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 455504, "time": 14556.914446592331, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 455560, "time": 14558.413101196289, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 455696, "time": 14562.84367966652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455976, "time": 14571.211913108826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456072, "time": 14574.146278858185, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 456104, "time": 14575.132202386856, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 456344, "time": 14582.699595451355, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 456384, "time": 14584.156212568283, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 456736, "time": 14594.99265050888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456848, "time": 14598.426443576813, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 456880, "time": 14599.412207126617, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 456944, "time": 14601.406595230103, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 457016, "time": 14603.402975320816, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 457024, "time": 14603.88170337677, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 457224, "time": 14609.950483322144, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 457328, "time": 14613.363120794296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457360, "time": 14614.35567164421, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 457384, "time": 14614.87420296669, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 457480, "time": 14617.833645105362, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 457800, "time": 14627.685773849487, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 457992, "time": 14633.591243743896, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 458288, "time": 14642.985342025757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458304, "time": 14643.483964443207, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 458376, "time": 14645.50227355957, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 458384, "time": 14645.978330135345, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 458856, "time": 14660.71537733078, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 458968, "time": 14664.147202253342, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 459256, "time": 14673.167558908463, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 459336, "time": 14675.651687383652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459488, "time": 14680.55479669571, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 459672, "time": 14685.966952562332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459736, "time": 14687.917742967606, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 459904, "time": 14693.270241975784, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 14699.607113838196, "eval_episode/length": 15.0, "eval_episode/score": 0.953125, "eval_episode/reward_rate": 0.0625}
{"step": 460096, "time": 14700.275145292282, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 460096, "time": 14701.225792884827, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 460096, "time": 14701.37802696228, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 460096, "time": 14701.465154886246, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 460096, "time": 14701.848796606064, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 460096, "time": 14702.060741901398, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 460096, "time": 14702.129917621613, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 460200, "time": 14705.102969646454, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 460304, "time": 14708.530577659607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460600, "time": 14717.4087100029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460688, "time": 14720.329074382782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460744, "time": 14721.828451156616, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 460936, "time": 14727.739030361176, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 461280, "time": 14738.690306425095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461528, "time": 14746.040643453598, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 461528, "time": 14746.053719997406, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 461568, "time": 14747.512733459473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461744, "time": 14752.911936283112, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 461784, "time": 14753.910496473312, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 461792, "time": 14754.387603521347, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 462248, "time": 14768.302922964096, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 462280, "time": 14769.284416913986, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 462320, "time": 14770.739825725555, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 462512, "time": 14776.654664993286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462976, "time": 14790.908926010132, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 463168, "time": 14796.807214260101, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 463552, "time": 14808.59243631363, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 463840, "time": 14817.418055057526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463840, "time": 14817.426871061325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463880, "time": 14818.488707780838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463920, "time": 14819.98871922493, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 464072, "time": 14824.450631380081, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 464104, "time": 14825.429356098175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464224, "time": 14829.346074581146, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 464376, "time": 14833.790122032166, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 464656, "time": 14842.573090553284, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 464848, "time": 14848.54158949852, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 465864, "time": 14879.741298913956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465912, "time": 14881.237237930298, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 466384, "time": 14895.916945457458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466416, "time": 14896.899911165237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466536, "time": 14900.344456195831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466688, "time": 14905.257368087769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466968, "time": 14914.259784460068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466992, "time": 14915.244723320007, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 467048, "time": 14916.74034166336, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 467136, "time": 14919.645926952362, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 467160, "time": 14920.183079481125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467360, "time": 14926.527302503586, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 467488, "time": 14930.475675821304, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 467816, "time": 14940.51049041748, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 467832, "time": 14941.006102323532, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 467960, "time": 14944.937111854553, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 468072, "time": 14948.35576748848, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 468176, "time": 14951.798974275589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468216, "time": 14952.814655542374, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 468224, "time": 14953.292551755905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468696, "time": 14967.545555830002, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 468728, "time": 14968.632816076279, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 468808, "time": 14971.08956360817, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 468808, "time": 14971.096953392029, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 469000, "time": 14976.967428922653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469272, "time": 14985.35442829132, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 469416, "time": 14989.775025367737, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 469464, "time": 14991.248708963394, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 469600, "time": 14995.638086795807, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 469704, "time": 14998.744582176208, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 469800, "time": 15001.709699630737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469976, "time": 15007.11254811287, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 15011.898449659348, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 470080, "time": 15012.032057762146, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 470080, "time": 15012.387567996979, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 470080, "time": 15012.578491926193, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 470080, "time": 15013.269028425217, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 470080, "time": 15013.316611528397, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 470080, "time": 15013.448611021042, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 470080, "time": 15014.25268292427, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 470144, "time": 15016.209477424622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470536, "time": 15028.06782245636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470552, "time": 15028.697907924652, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 470568, "time": 15029.20008802414, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 471312, "time": 15052.244230747223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471400, "time": 15054.710079908371, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 471416, "time": 15055.20448422432, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 471584, "time": 15060.71284198761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471760, "time": 15066.112583875656, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 471912, "time": 15070.5739569664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472016, "time": 15073.986930847168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472200, "time": 15079.362983465195, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 472200, "time": 15079.370488166809, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 472272, "time": 15081.819057941437, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 472456, "time": 15087.236218214035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472640, "time": 15093.256114244461, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 472720, "time": 15095.720134019852, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 472824, "time": 15098.692303180695, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 473016, "time": 15104.55240893364, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 473160, "time": 15108.950109958649, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 473192, "time": 15109.936232089996, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 473256, "time": 15111.919363737106, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 473544, "time": 15120.837473154068, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 473632, "time": 15123.758981704712, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 473952, "time": 15133.543024301529, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 474224, "time": 15141.838533878326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474280, "time": 15143.32100534439, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 474312, "time": 15144.301764011383, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 474328, "time": 15144.799335956573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474512, "time": 15150.82444524765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475056, "time": 15167.499804973602, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 475056, "time": 15167.507426261902, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 475336, "time": 15176.674747467041, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 475544, "time": 15183.134266614914, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 475568, "time": 15184.09799194336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475640, "time": 15186.119962215424, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 475856, "time": 15192.975297927856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475992, "time": 15196.917429208755, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 476264, "time": 15205.235330343246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476432, "time": 15210.741784095764, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 476504, "time": 15212.720412015915, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 476536, "time": 15213.714127779007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476896, "time": 15225.007558345795, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 477256, "time": 15235.846863508224, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 477264, "time": 15236.319087028503, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 477513, "time": 15244.810396671295, "train_stats/mean_log_entropy": 0.10515343847029517, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5610693359375, "train/action_min": 0.0, "train/action_std": 1.8763290125131606, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011228569902013987, "train/actor_opt_grad_steps": 28745.0, "train/actor_opt_loss": -3.2528743924573065, "train/adv_mag": 0.9006911718845367, "train/adv_max": 0.32331576585769656, "train/adv_mean": 0.005483411996283394, "train/adv_min": -0.8734709823131561, "train/adv_std": 0.03847336287610233, "train/cont_avg": 0.995791015625, "train/cont_loss_mean": 0.01209476805641316, "train/cont_loss_std": 0.18792468548752367, "train/cont_neg_acc": 0.44328723290953975, "train/cont_neg_loss": 2.19160899290735, "train/cont_pos_acc": 0.9998529046773911, "train/cont_pos_loss": 0.0025753317202907057, "train/cont_pred": 0.9957850056886673, "train/cont_rate": 0.995791015625, "train/dyn_loss_mean": 1.0000375282764435, "train/dyn_loss_std": 0.0011601762982900255, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5054866329673677, "train/extr_critic_critic_opt_grad_steps": 28745.0, "train/extr_critic_critic_opt_loss": 12242.319113769532, "train/extr_critic_mag": 1.0564559936523437, "train/extr_critic_max": 1.0564559936523437, "train/extr_critic_mean": 1.0032428607344628, "train/extr_critic_min": 0.9105128920078278, "train/extr_critic_std": 0.015608484437689186, "train/extr_return_normed_mag": 0.8795908841490746, "train/extr_return_normed_max": 0.32826351910829543, "train/extr_return_normed_mean": 0.039002063995576465, "train/extr_return_normed_min": -0.8487577098608017, "train/extr_return_normed_std": 0.042019348186440764, "train/extr_return_rate": 0.9976442542672157, "train/extr_return_raw_mag": 1.2979876220226287, "train/extr_return_raw_max": 1.2979876220226287, "train/extr_return_raw_mean": 1.008726215362549, "train/extr_return_raw_min": 0.12096639305353164, "train/extr_return_raw_std": 0.04201934820506722, "train/extr_reward_mag": 0.33392818927764895, "train/extr_reward_max": 0.33392818927764895, "train/extr_reward_mean": 0.0027770530828274786, "train/extr_reward_min": 1.2040138244628906e-07, "train/extr_reward_std": 0.01191984913079068, "train/image_loss_mean": 0.09423967771232128, "train/image_loss_std": 0.12839235547930003, "train/model_loss_mean": 0.7131058898568153, "train/model_loss_std": 0.3558114094659686, "train/model_opt_grad_norm": 28.369437826338725, "train/model_opt_grad_steps": 28720.09, "train/model_opt_loss": 2878.4579656982423, "train/model_opt_model_opt_grad_overflow": 0.005, "train/model_opt_model_opt_grad_scale": 4012.5, "train/policy_entropy_mag": 1.407812289595604, "train/policy_entropy_max": 1.407812289595604, "train/policy_entropy_mean": 0.12744683220982553, "train/policy_entropy_min": 0.06468663234263658, "train/policy_entropy_std": 0.16648765824735165, "train/policy_logprob_mag": 6.55108021736145, "train/policy_logprob_max": -0.008608199441805481, "train/policy_logprob_mean": -0.1280735594034195, "train/policy_logprob_min": -6.55108021736145, "train/policy_logprob_std": 0.6671263167262077, "train/policy_randomness_mag": 0.7234724456071854, "train/policy_randomness_max": 0.7234724456071854, "train/policy_randomness_mean": 0.065494719799608, "train/policy_randomness_min": 0.0332423553802073, "train/policy_randomness_std": 0.08555773712694645, "train/post_ent_mag": 29.577310428619384, "train/post_ent_max": 29.577310428619384, "train/post_ent_mean": 29.42503258705139, "train/post_ent_min": 29.313896045684814, "train/post_ent_std": 0.04716954294592142, "train/prior_ent_mag": 32.26583197593689, "train/prior_ent_max": 32.26583197593689, "train/prior_ent_mean": 29.412721643447878, "train/prior_ent_min": 27.71004014015198, "train/prior_ent_std": 0.6653241062164307, "train/rep_loss_mean": 1.0000375282764435, "train/rep_loss_std": 0.0011601762982900255, "train/reward_avg": 0.00086474609648576, "train/reward_loss_mean": 0.0067489036347251384, "train/reward_loss_std": 0.1318431943374162, "train/reward_max_data": 0.5127968741953373, "train/reward_max_pred": 0.15827632069587708, "train/reward_neg_acc": 0.9997310546040535, "train/reward_neg_loss": 0.0011493112401512917, "train/reward_pos_acc": 0.2443185560662171, "train/reward_pos_loss": 4.127668656974003, "train/reward_pred": 0.000671254793414846, "train/reward_rate": 0.001376953125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.011312605813145638, "report/cont_loss_std": 0.20322169363498688, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 1.8377742767333984, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0023505757562816143, "report/cont_pred": 0.994870662689209, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10482344031333923, "report/image_loss_std": 0.11189458519220352, "report/model_loss_mean": 0.7232547998428345, "report/model_loss_std": 0.39853888750076294, "report/post_ent_mag": 29.611560821533203, "report/post_ent_max": 29.611560821533203, "report/post_ent_mean": 29.48011016845703, "report/post_ent_min": 29.358951568603516, "report/post_ent_std": 0.03869687020778656, "report/prior_ent_mag": 30.113622665405273, "report/prior_ent_max": 30.113622665405273, "report/prior_ent_mean": 29.105485916137695, "report/prior_ent_min": 27.886899948120117, "report/prior_ent_std": 0.32065245509147644, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006286621210165322, "report/reward_loss_mean": 0.007118741050362587, "report/reward_loss_std": 0.18025189638137817, "report/reward_max_data": 0.643750011920929, "report/reward_max_pred": 0.09212136268615723, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0014905703719705343, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.764737129211426, "report/reward_pred": 0.0007167091825976968, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.032495930790901184, "eval/cont_loss_std": 0.5791277289390564, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.69533920288086, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0011653477558866143, "eval/cont_pred": 0.9988718032836914, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2170669287443161, "eval/image_loss_std": 0.1400095671415329, "eval/model_loss_mean": 0.8508286476135254, "eval/model_loss_std": 0.6003204584121704, "eval/post_ent_mag": 29.609695434570312, "eval/post_ent_max": 29.609695434570312, "eval/post_ent_mean": 29.464950561523438, "eval/post_ent_min": 29.369577407836914, "eval/post_ent_std": 0.043918758630752563, "eval/prior_ent_mag": 29.956113815307617, "eval/prior_ent_max": 29.956113815307617, "eval/prior_ent_mean": 29.060558319091797, "eval/prior_ent_min": 27.89260482788086, "eval/prior_ent_std": 0.32209041714668274, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012657912448048592, "eval/reward_loss_std": 0.026887541636824608, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.2504764795303345, "eval/reward_neg_acc": 0.998046875, "eval/reward_neg_loss": 0.0012657912448048592, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004930400755256414, "eval/reward_rate": 0.0, "replay/size": 477009.0, "replay/inserts": 32000.0, "replay/samples": 32000.0, "replay/insert_wait_avg": 1.4496669173240661e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.120330214500427e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2669605398283362e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.341104507446289e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0179688930511, "timer/env.step_count": 4000.0, "timer/env.step_total": 40.25327920913696, "timer/env.step_frac": 0.040252555915264686, "timer/env.step_avg": 0.01006331980228424, "timer/env.step_min": 0.008097171783447266, "timer/env.step_max": 0.03778338432312012, "timer/replay._sample_count": 32000.0, "timer/replay._sample_total": 17.48192310333252, "timer/replay._sample_frac": 0.01748160897817043, "timer/replay._sample_avg": 0.0005463100969791412, "timer/replay._sample_min": 0.0004038810729980469, "timer/replay._sample_max": 0.025855541229248047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4453.0, "timer/agent.policy_total": 48.83588099479675, "timer/agent.policy_frac": 0.048835003483841996, "timer/agent.policy_avg": 0.0109669618223213, "timer/agent.policy_min": 0.008836984634399414, "timer/agent.policy_max": 0.09154939651489258, "timer/dataset_train_count": 2000.0, "timer/dataset_train_total": 0.23526501655578613, "timer/dataset_train_frac": 0.00023526078917982622, "timer/dataset_train_avg": 0.00011763250827789307, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0010747909545898438, "timer/agent.train_count": 2000.0, "timer/agent.train_total": 899.2188744544983, "timer/agent.train_frac": 0.8992027167770492, "timer/agent.train_avg": 0.44960943722724916, "timer/agent.train_min": 0.4342505931854248, "timer/agent.train_max": 0.7937684059143066, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47591686248779297, "timer/agent.report_frac": 0.0004759083109422515, "timer/agent.report_avg": 0.23795843124389648, "timer/agent.report_min": 0.232391357421875, "timer/agent.report_max": 0.24352550506591797, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.4808487078846535e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 31.998811315824437}
{"step": 477648, "time": 15248.949692487717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477672, "time": 15249.46845960617, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 477880, "time": 15255.857454299927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478024, "time": 15260.222203731537, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 478488, "time": 15274.492362976074, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 478544, "time": 15276.449078798294, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 478576, "time": 15277.430564165115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478624, "time": 15278.911466360092, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 478744, "time": 15282.357949733734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478816, "time": 15284.76606965065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478904, "time": 15287.235988616943, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 479000, "time": 15290.180412054062, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 479576, "time": 15307.831742286682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479688, "time": 15311.282029151917, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 479696, "time": 15311.760651350021, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 479944, "time": 15319.096805334091, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 480048, "time": 15322.516750335693, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 15323.984417438507, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 480064, "time": 15324.050208806992, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 480064, "time": 15324.136491060257, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 480064, "time": 15324.163537740707, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 480064, "time": 15325.34821486473, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 480064, "time": 15326.107235431671, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 480064, "time": 15326.235970258713, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 480064, "time": 15326.284550189972, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 480144, "time": 15328.86982369423, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 480648, "time": 15344.057282686234, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 480792, "time": 15348.449025630951, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 480888, "time": 15351.368001937866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480928, "time": 15352.834577560425, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 481008, "time": 15355.264417886734, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 481200, "time": 15361.261909246445, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 481312, "time": 15364.685622215271, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481464, "time": 15369.124912023544, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 481760, "time": 15378.398581266403, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 481936, "time": 15383.776980876923, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 482000, "time": 15385.742416381836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482008, "time": 15385.772852420807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482120, "time": 15389.335654973984, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 482256, "time": 15393.699505329132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482360, "time": 15396.673609733582, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 482576, "time": 15403.49696278572, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 482792, "time": 15409.843305110931, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 482984, "time": 15415.693309545517, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 483096, "time": 15419.25061416626, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 483112, "time": 15419.742547035217, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 483360, "time": 15428.00654244423, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 483496, "time": 15431.970042467117, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 483768, "time": 15440.242261886597, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 484072, "time": 15449.648441553116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484088, "time": 15450.137959003448, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 484120, "time": 15451.128812074661, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 484248, "time": 15455.023419857025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484432, "time": 15460.869822263718, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 484816, "time": 15472.528760671616, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 484848, "time": 15473.507325649261, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 484872, "time": 15474.020945072174, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 485032, "time": 15479.01416349411, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 485080, "time": 15480.495751619339, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 485152, "time": 15482.89855670929, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 485192, "time": 15483.888120889664, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 485408, "time": 15490.699575185776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485440, "time": 15491.682028055191, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 485672, "time": 15498.478714704514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485696, "time": 15499.434141635895, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 486088, "time": 15511.30833697319, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 486104, "time": 15511.803137540817, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 486192, "time": 15514.714948892593, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 486568, "time": 15525.939182758331, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 486712, "time": 15530.326866865158, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 486792, "time": 15532.779374361038, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 487000, "time": 15539.301866531372, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 487024, "time": 15540.266822814941, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 487176, "time": 15544.708247184753, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 487184, "time": 15545.184459209442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487392, "time": 15551.535799741745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487496, "time": 15554.518286705017, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 487504, "time": 15554.993247270584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487528, "time": 15555.51539683342, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 488024, "time": 15570.833379983902, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 488088, "time": 15572.784927845001, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 488200, "time": 15576.236455202103, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 488560, "time": 15587.446325063705, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 488592, "time": 15588.448417425156, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 488632, "time": 15589.453090429306, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 488808, "time": 15594.825776576996, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 488936, "time": 15598.865098953247, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 488944, "time": 15599.337600708008, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 489816, "time": 15625.78114247322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 15634.339116573334, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 490048, "time": 15634.61278629303, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 490048, "time": 15634.953879356384, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 490048, "time": 15634.980501890182, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 490048, "time": 15635.19457745552, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 490048, "time": 15635.342396736145, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 490048, "time": 15635.391118049622, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 490048, "time": 15635.478379964828, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 490280, "time": 15642.33477807045, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 490336, "time": 15644.258640289307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490456, "time": 15647.71548986435, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 490512, "time": 15649.669168233871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490824, "time": 15659.01114821434, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 490872, "time": 15660.4969124794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490904, "time": 15661.478755235672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490944, "time": 15662.92439699173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491136, "time": 15668.78381729126, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 491168, "time": 15669.774866819382, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 491248, "time": 15672.219955205917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491592, "time": 15683.032878875732, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 491688, "time": 15686.002765417099, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 491936, "time": 15693.914639472961, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 491944, "time": 15693.94480395317, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 491952, "time": 15694.441708803177, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 492752, "time": 15718.938638210297, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 492768, "time": 15719.435348272324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492904, "time": 15723.374789953232, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 493256, "time": 15734.316131830215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493480, "time": 15741.157461643219, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493560, "time": 15743.612610340118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493608, "time": 15745.085389375687, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 493744, "time": 15749.579575300217, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 494000, "time": 15757.443197488785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494240, "time": 15764.833058357239, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 494264, "time": 15765.353553533554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494408, "time": 15769.772989273071, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 494488, "time": 15772.227594852448, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 494680, "time": 15778.147502422333, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 494952, "time": 15786.560391902924, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 495040, "time": 15789.499960422516, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 495064, "time": 15790.01349401474, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 495064, "time": 15790.022372484207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495160, "time": 15792.967346191406, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 495568, "time": 15805.627252578735, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 495728, "time": 15810.701608657837, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 496312, "time": 15828.376057863235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496720, "time": 15841.194588422775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496800, "time": 15843.672990322113, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 496888, "time": 15846.12933397293, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 496992, "time": 15849.5352602005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497248, "time": 15857.352940797806, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 497376, "time": 15861.254829645157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497472, "time": 15864.206538438797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497544, "time": 15866.20219373703, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 497720, "time": 15871.737578868866, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 497880, "time": 15876.658727645874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498040, "time": 15881.571037769318, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 498232, "time": 15887.43037223816, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 498304, "time": 15889.863539457321, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 498512, "time": 15896.249213218689, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 498520, "time": 15896.277553796768, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 498712, "time": 15902.225691318512, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 498944, "time": 15909.523447036743, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 499040, "time": 15912.469094276428, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 499112, "time": 15914.44478058815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499120, "time": 15914.914892673492, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 499160, "time": 15915.940267562866, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 499440, "time": 15924.74426484108, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 499608, "time": 15929.808649301529, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 499784, "time": 15935.782289981842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499784, "time": 15935.79215168953, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 499968, "time": 15941.663002967834, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 499984, "time": 15942.168865919113, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 15944.799438714981, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 500032, "time": 15945.927604675293, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 500032, "time": 15946.32396888733, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 500032, "time": 15946.475357532501, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 500032, "time": 15946.725594997406, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 500032, "time": 15946.93289232254, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 500032, "time": 15947.316321611404, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 500032, "time": 15948.305293560028, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 500056, "time": 15948.821459531784, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 500192, "time": 15953.206412553787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500344, "time": 15957.63599729538, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 500624, "time": 15966.53427195549, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 500688, "time": 15968.47750711441, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 500720, "time": 15969.449010848999, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 501416, "time": 15990.43330025673, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 501584, "time": 15995.751397371292, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 501616, "time": 15996.730147600174, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 501736, "time": 16000.161781787872, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 501752, "time": 16000.656802892685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501800, "time": 16002.121520280838, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 501920, "time": 16005.995862007141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502240, "time": 16015.695594787598, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 502280, "time": 16016.701450109482, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 502280, "time": 16016.708904981613, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 502504, "time": 16023.64603471756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502792, "time": 16032.476780414581, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 502800, "time": 16032.946522474289, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 502888, "time": 16035.427080869675, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 503256, "time": 16046.728219985962, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 503408, "time": 16051.72136092186, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 503424, "time": 16052.21225142479, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 503560, "time": 16056.156918048859, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 503712, "time": 16061.03299856186, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 503800, "time": 16063.516930818558, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 503800, "time": 16063.524780511856, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 503896, "time": 16066.442513942719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504016, "time": 16070.355266809464, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 504048, "time": 16071.334330558777, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 504080, "time": 16072.31805562973, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 504384, "time": 16081.738015651703, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 504432, "time": 16083.23044872284, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 504504, "time": 16085.204813957214, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 504528, "time": 16086.158573627472, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 504776, "time": 16093.482627868652, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 504824, "time": 16094.941529750824, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 505144, "time": 16104.754803419113, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 505672, "time": 16121.020576000214, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 505792, "time": 16124.914879083633, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 505800, "time": 16124.945724964142, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 505872, "time": 16127.40255188942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505952, "time": 16129.860120534897, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 506120, "time": 16134.8338534832, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 506328, "time": 16141.32481455803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506392, "time": 16143.32121181488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506672, "time": 16152.17269206047, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 506696, "time": 16152.696870803833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506784, "time": 16155.610518455505, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 506856, "time": 16157.614087820053, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 506872, "time": 16158.107910394669, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 506968, "time": 16161.052831888199, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 507144, "time": 16166.473952770233, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 507160, "time": 16167.002262115479, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 507160, "time": 16167.009554624557, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 507176, "time": 16167.503819227219, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 507400, "time": 16174.44270825386, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 507448, "time": 16175.921237707138, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 507552, "time": 16179.328621387482, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 507568, "time": 16179.818969964981, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 507840, "time": 16188.138187646866, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 508304, "time": 16202.900375127792, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 508312, "time": 16202.92775964737, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 508408, "time": 16205.842468261719, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 508416, "time": 16206.320928096771, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 508440, "time": 16206.860050201416, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 508480, "time": 16208.311071634293, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 508616, "time": 16212.253294229507, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 508880, "time": 16220.457442760468, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 509304, "time": 16233.317227125168, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 509328, "time": 16234.282187461853, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 509384, "time": 16235.769807815552, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 509456, "time": 16238.213417053223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509472, "time": 16238.709135770798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509657, "time": 16245.11458659172, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.423544812558302, "train/action_min": 0.0, "train/action_std": 1.7830775584747542, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010659808749379359, "train/actor_opt_grad_steps": 30750.0, "train/actor_opt_loss": -7.087536700250609, "train/adv_mag": 0.9698965819320868, "train/adv_max": 0.3617712152538015, "train/adv_mean": 0.0024589996978082226, "train/adv_min": -0.9449129899342855, "train/adv_std": 0.03788882875537027, "train/cont_avg": 0.9957342195273632, "train/cont_loss_mean": 0.012027436543594287, "train/cont_loss_std": 0.19079345835613745, "train/cont_neg_acc": 0.4471906410224402, "train/cont_neg_loss": 2.1794382514847923, "train/cont_pos_acc": 0.9998341199770495, "train/cont_pos_loss": 0.0025486850321051937, "train/cont_pred": 0.9957522895205674, "train/cont_rate": 0.9957342195273632, "train/dyn_loss_mean": 1.0000045791787295, "train/dyn_loss_std": 0.00013742043242317195, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4185169252627228, "train/extr_critic_critic_opt_grad_steps": 30750.0, "train/extr_critic_critic_opt_loss": 8832.726931747513, "train/extr_critic_mag": 1.197185808153295, "train/extr_critic_max": 1.197185808153295, "train/extr_critic_mean": 1.1398312387181753, "train/extr_critic_min": 0.9165235900167209, "train/extr_critic_std": 0.016733924807304172, "train/extr_return_normed_mag": 0.9581747642203943, "train/extr_return_normed_max": 0.30524791354563696, "train/extr_return_normed_mean": 0.03507629256760377, "train/extr_return_normed_min": -0.9305324332037969, "train/extr_return_normed_std": 0.0420560250753787, "train/extr_return_rate": 0.9984096893623694, "train/extr_return_raw_mag": 1.4124610821406047, "train/extr_return_raw_max": 1.4124610821406047, "train/extr_return_raw_mean": 1.1422895199030787, "train/extr_return_raw_min": 0.17668073539117082, "train/extr_return_raw_std": 0.04205602504294458, "train/extr_reward_mag": 0.3357403112288138, "train/extr_reward_max": 0.3357403112288138, "train/extr_reward_mean": 0.0024942736467462386, "train/extr_reward_min": 1.4293253125242926e-07, "train/extr_reward_std": 0.011471514712870862, "train/image_loss_mean": 0.08904415758243248, "train/image_loss_std": 0.09684744380896364, "train/model_loss_mean": 0.7085985929811772, "train/model_loss_std": 0.33869642601232625, "train/model_opt_grad_norm": 27.10496539974687, "train/model_opt_grad_steps": 30723.33830845771, "train/model_opt_loss": 2495.032813228778, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3519.9004975124376, "train/policy_entropy_mag": 1.362380584674095, "train/policy_entropy_max": 1.362380584674095, "train/policy_entropy_mean": 0.11357820586333821, "train/policy_entropy_min": 0.06468659832109859, "train/policy_entropy_std": 0.14767926771990694, "train/policy_logprob_mag": 6.551080234015166, "train/policy_logprob_max": -0.008608147358308681, "train/policy_logprob_mean": -0.11359207146796421, "train/policy_logprob_min": -6.551080234015166, "train/policy_logprob_std": 0.651765512886332, "train/policy_randomness_mag": 0.700125165543153, "train/policy_randomness_max": 0.700125165543153, "train/policy_randomness_mean": 0.05836765512601653, "train/policy_randomness_min": 0.0332423383694383, "train/policy_randomness_std": 0.07589213537117143, "train/post_ent_mag": 29.136251829156826, "train/post_ent_max": 29.136251829156826, "train/post_ent_mean": 28.993206479656163, "train/post_ent_min": 28.887982980528875, "train/post_ent_std": 0.04592707200874736, "train/prior_ent_mag": 30.01864285255546, "train/prior_ent_max": 30.01864285255546, "train/prior_ent_mean": 28.654824309088106, "train/prior_ent_min": 27.31998599227981, "train/prior_ent_std": 0.4270759235270581, "train/rep_loss_mean": 1.0000045791787295, "train/rep_loss_std": 0.00013742043242317195, "train/reward_avg": 0.0009758792701322094, "train/reward_loss_mean": 0.007524225971457636, "train/reward_loss_std": 0.1446397569869177, "train/reward_max_data": 0.5557680341290004, "train/reward_max_pred": 0.17008524866246466, "train/reward_neg_acc": 0.9997614889002558, "train/reward_neg_loss": 0.0012490260791246646, "train/reward_pos_acc": 0.23958333488553762, "train/reward_pos_loss": 4.0710242666304115, "train/reward_pred": 0.0007527095517050938, "train/reward_rate": 0.0015790189676616916, "train_stats/mean_log_entropy": 0.09895123453302816, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.015606561675667763, "report/cont_loss_std": 0.2722182869911194, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.520808219909668, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0018606738885864615, "report/cont_pred": 0.9972847700119019, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08035838603973389, "report/image_loss_std": 0.08601788431406021, "report/model_loss_mean": 0.6992950439453125, "report/model_loss_std": 0.31574392318725586, "report/post_ent_mag": 28.983928680419922, "report/post_ent_max": 28.983928680419922, "report/post_ent_mean": 28.832672119140625, "report/post_ent_min": 28.7353515625, "report/post_ent_std": 0.04535306990146637, "report/prior_ent_mag": 30.034713745117188, "report/prior_ent_max": 30.034713745117188, "report/prior_ent_mean": 28.55787467956543, "report/prior_ent_min": 27.337480545043945, "report/prior_ent_std": 0.43832409381866455, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008514404180459678, "report/reward_loss_mean": 0.0033300674986094236, "report/reward_loss_std": 0.06725392490625381, "report/reward_max_data": 0.871874988079071, "report/reward_max_pred": 0.19293606281280518, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0012486474588513374, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 2.132622718811035, "report/reward_pred": 0.0007861912017688155, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.048441726714372635, "eval/cont_loss_std": 0.7362603545188904, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.755868911743164, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0025302483700215816, "eval/cont_pred": 0.9984183311462402, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2033557891845703, "eval/image_loss_std": 0.1506519466638565, "eval/model_loss_mean": 0.8519062995910645, "eval/model_loss_std": 0.7471405863761902, "eval/post_ent_mag": 28.984085083007812, "eval/post_ent_max": 28.984085083007812, "eval/post_ent_mean": 28.827224731445312, "eval/post_ent_min": 28.727710723876953, "eval/post_ent_std": 0.047047678381204605, "eval/prior_ent_mag": 30.027996063232422, "eval/prior_ent_max": 30.027996063232422, "eval/prior_ent_mean": 28.49908447265625, "eval/prior_ent_min": 27.234699249267578, "eval/prior_ent_std": 0.43871620297431946, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00010877987369894981, "eval/reward_loss_std": 0.0007173189078457654, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.005546450614929199, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00010877987369894981, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.393207538872957e-05, "eval/reward_rate": 0.0, "replay/size": 509153.0, "replay/inserts": 32144.0, "replay/samples": 32144.0, "replay/insert_wait_avg": 1.4403318516231401e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.069533535590392e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2616965765527131e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.287223815918, "timer/env.step_count": 4018.0, "timer/env.step_total": 40.247297525405884, "timer/env.step_frac": 0.040235740862379105, "timer/env.step_avg": 0.010016749010802859, "timer/env.step_min": 0.008072614669799805, "timer/env.step_max": 0.035219430923461914, "timer/replay._sample_count": 32144.0, "timer/replay._sample_total": 17.566609382629395, "timer/replay._sample_frac": 0.017561565282835367, "timer/replay._sample_avg": 0.0005464973053331693, "timer/replay._sample_min": 0.0004439353942871094, "timer/replay._sample_max": 0.032111406326293945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4477.0, "timer/agent.policy_total": 49.286558866500854, "timer/agent.policy_frac": 0.04927240665784113, "timer/agent.policy_avg": 0.011008836021108076, "timer/agent.policy_min": 0.00934910774230957, "timer/agent.policy_max": 0.09523487091064453, "timer/dataset_train_count": 2009.0, "timer/dataset_train_total": 0.23434972763061523, "timer/dataset_train_frac": 0.0002342824361353059, "timer/dataset_train_avg": 0.00011664993908940529, "timer/dataset_train_min": 0.00010085105895996094, "timer/dataset_train_max": 0.001077890396118164, "timer/agent.train_count": 2009.0, "timer/agent.train_total": 899.362699508667, "timer/agent.train_frac": 0.899104455296108, "timer/agent.train_avg": 0.4476668489341299, "timer/agent.train_min": 0.43608880043029785, "timer/agent.train_max": 0.729057788848877, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47685861587524414, "timer/agent.report_frac": 0.00047672169005229644, "timer/agent.report_avg": 0.23842930793762207, "timer/agent.report_min": 0.23087739944458008, "timer/agent.report_max": 0.24598121643066406, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.647804260253906e-05, "timer/dataset_eval_frac": 3.6467568248429497e-08, "timer/dataset_eval_avg": 3.647804260253906e-05, "timer/dataset_eval_min": 3.647804260253906e-05, "timer/dataset_eval_max": 3.647804260253906e-05, "fps": 32.134226134259215}
{"step": 509664, "time": 16245.13693523407, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 509912, "time": 16252.939307928085, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 16256.320013523102, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 16257.29723072052, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 510016, "time": 16257.529873609543, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 510016, "time": 16257.692301750183, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 510016, "time": 16258.815839290619, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 510016, "time": 16258.863471269608, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 510016, "time": 16259.031145811081, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 510016, "time": 16259.157502651215, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 510016, "time": 16259.2251226902, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 510056, "time": 16260.245000123978, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 510056, "time": 16260.251863002777, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 510352, "time": 16269.605101108551, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 510472, "time": 16273.023223161697, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 510568, "time": 16275.967645645142, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 510624, "time": 16277.896379947662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510640, "time": 16278.388915777206, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 510680, "time": 16279.407361030579, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 510752, "time": 16281.808311462402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510872, "time": 16285.26599574089, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 511040, "time": 16290.719134092331, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 511144, "time": 16293.646827220917, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 511232, "time": 16296.563680171967, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 511320, "time": 16299.056253910065, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 511504, "time": 16304.916042804718, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 511624, "time": 16308.345303058624, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 511776, "time": 16313.287145137787, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 511784, "time": 16313.319110393524, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 511832, "time": 16314.842834472656, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 512240, "time": 16327.794817447662, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 512496, "time": 16335.646231651306, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 512664, "time": 16340.560034513474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512768, "time": 16344.03201007843, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 512824, "time": 16345.534972190857, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 512912, "time": 16348.582643508911, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 512936, "time": 16349.126526594162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513176, "time": 16356.477425336838, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 513544, "time": 16367.71634221077, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 513720, "time": 16373.139250040054, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 513824, "time": 16376.56551027298, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 514096, "time": 16384.989817619324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514144, "time": 16386.467040777206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514160, "time": 16386.956717014313, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 514200, "time": 16387.976632118225, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 514256, "time": 16389.907096862793, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 514456, "time": 16395.769440174103, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 514552, "time": 16398.731353521347, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 514976, "time": 16412.134891986847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515192, "time": 16418.53440451622, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 515288, "time": 16421.443932533264, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 515304, "time": 16421.947198867798, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 515328, "time": 16422.940499067307, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 515472, "time": 16427.360264778137, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 515512, "time": 16428.36314535141, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 515824, "time": 16438.145390033722, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 515856, "time": 16439.273895263672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515920, "time": 16441.235763549805, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 515928, "time": 16441.264883041382, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 515976, "time": 16442.74948143959, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 516032, "time": 16444.68022108078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516472, "time": 16458.426510334015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516632, "time": 16463.27072572708, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 516792, "time": 16468.14777135849, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 516880, "time": 16471.202381134033, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 517416, "time": 16487.2909014225, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 517624, "time": 16493.631531000137, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 517800, "time": 16499.097930431366, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 517824, "time": 16500.057200670242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518168, "time": 16510.421789884567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518232, "time": 16512.39975976944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518288, "time": 16514.319058179855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518304, "time": 16514.811116695404, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 518352, "time": 16516.297303438187, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 518528, "time": 16521.66783642769, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 518624, "time": 16524.60489797592, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 518656, "time": 16525.58855986595, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 518656, "time": 16525.59707903862, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 518744, "time": 16528.059906482697, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 518784, "time": 16529.618423223495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519080, "time": 16538.412282705307, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 519176, "time": 16541.343281030655, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 519392, "time": 16548.113820791245, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 519688, "time": 16556.950983047485, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 519704, "time": 16557.444990873337, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 16567.681787252426, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 520000, "time": 16568.331376791, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 520000, "time": 16568.44164800644, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 520000, "time": 16568.53255701065, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 520000, "time": 16568.74898958206, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 520000, "time": 16569.886414527893, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 520000, "time": 16572.34632587433, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 520000, "time": 16572.8465487957, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16572.855575323105, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16572.863455295563, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520128, "time": 16576.78547167778, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 520160, "time": 16577.76665878296, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 520208, "time": 16579.23047852516, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 520480, "time": 16587.506917238235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520520, "time": 16588.610286712646, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 520736, "time": 16595.407750606537, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 520880, "time": 16599.802896261215, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 520896, "time": 16600.29175901413, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 521008, "time": 16603.70761013031, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 521096, "time": 16606.1654047966, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 521104, "time": 16606.63621044159, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 521304, "time": 16612.519047260284, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 521400, "time": 16615.47866153717, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 521544, "time": 16619.946241378784, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 521584, "time": 16621.412021398544, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 521616, "time": 16622.386499404907, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 521752, "time": 16626.331854343414, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 521960, "time": 16632.673726558685, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 521992, "time": 16633.656685590744, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 522112, "time": 16637.535567760468, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 522128, "time": 16638.032384634018, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 522280, "time": 16642.44346356392, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 522464, "time": 16648.312878847122, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 522472, "time": 16648.381351470947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522512, "time": 16649.928297519684, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 522616, "time": 16652.85400414467, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 522744, "time": 16656.813862085342, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 522896, "time": 16661.696687221527, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 523072, "time": 16667.11380839348, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 523136, "time": 16669.062091112137, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 523272, "time": 16672.984380483627, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 523496, "time": 16679.935472011566, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 523696, "time": 16686.26286673546, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 524040, "time": 16696.54203915596, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 524304, "time": 16705.358731031418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524424, "time": 16708.903252840042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524592, "time": 16714.252225399017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525056, "time": 16728.363564491272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525296, "time": 16735.713659524918, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 525384, "time": 16738.167846918106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525448, "time": 16740.262241840363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525584, "time": 16744.652576446533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525744, "time": 16749.547735214233, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 525928, "time": 16754.939347743988, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 526280, "time": 16765.690368652344, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 526352, "time": 16768.15259051323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526656, "time": 16777.540093183517, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 526656, "time": 16777.54891896248, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 526776, "time": 16781.0098195076, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 526784, "time": 16781.485574007034, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 527056, "time": 16789.802725553513, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 527064, "time": 16789.832361221313, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 527208, "time": 16794.239741563797, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 527208, "time": 16794.247996091843, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 527280, "time": 16796.652169942856, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 527368, "time": 16799.249339580536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527584, "time": 16806.03707933426, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 527744, "time": 16810.88932991028, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 527984, "time": 16818.203783750534, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 528072, "time": 16820.66427206993, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 528240, "time": 16825.99825978279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528272, "time": 16826.99119901657, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 528296, "time": 16827.501074552536, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 528584, "time": 16836.371490478516, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 528784, "time": 16842.68445134163, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 528928, "time": 16847.062387228012, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 528984, "time": 16848.543405056, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 528984, "time": 16848.551140785217, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 529368, "time": 16860.38505244255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529400, "time": 16861.381436109543, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 529520, "time": 16865.232395648956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530032, "time": 16880.888644695282, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 530056, "time": 16881.40664768219, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 16884.161526441574, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 530088, "time": 16884.324320316315, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 530088, "time": 16884.743795394897, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 530088, "time": 16885.36706495285, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 530088, "time": 16886.814115524292, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 530088, "time": 16888.983969926834, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 530088, "time": 16889.542639493942, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 16889.554227113724, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 16889.5636510849, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 16889.572047948837, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 16889.57948088646, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530104, "time": 16890.07042837143, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 530440, "time": 16900.3058385849, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 530584, "time": 16904.706544160843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530760, "time": 16910.07716536522, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 531096, "time": 16920.43790745735, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 531240, "time": 16924.83380961418, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 531296, "time": 16926.752321958542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531296, "time": 16926.77307367325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531712, "time": 16939.418061733246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531880, "time": 16944.293531894684, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 532128, "time": 16952.166791439056, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 532368, "time": 16959.502272367477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532616, "time": 16967.35552763939, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 532648, "time": 16968.33534836769, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 532688, "time": 16969.778467655182, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 532696, "time": 16969.806908369064, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 532808, "time": 16976.677919864655, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 532896, "time": 16979.71746492386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533352, "time": 16993.361904144287, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 533408, "time": 16995.312158823013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533424, "time": 16995.806943178177, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 533488, "time": 16997.759791374207, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 533608, "time": 17001.221328258514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533656, "time": 17002.70707654953, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 533800, "time": 17007.09962463379, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 534048, "time": 17015.06190276146, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 534232, "time": 17020.923054933548, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 534736, "time": 17036.564126968384, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 534800, "time": 17038.591739416122, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 534808, "time": 17038.621210813522, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 534856, "time": 17040.103728294373, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 534960, "time": 17043.507645606995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535008, "time": 17045.000725507736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535248, "time": 17052.354293346405, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 535552, "time": 17061.625364542007, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 535568, "time": 17062.120643377304, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 535736, "time": 17067.01357603073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535736, "time": 17067.024937152863, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 535744, "time": 17067.494167089462, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 535976, "time": 17074.454159259796, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 536072, "time": 17077.38460969925, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 536392, "time": 17087.104094028473, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 536512, "time": 17091.005956172943, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 536960, "time": 17104.80708050728, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 537216, "time": 17112.590579271317, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 537528, "time": 17121.87890648842, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 537568, "time": 17123.3328397274, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 537680, "time": 17126.743149995804, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 537880, "time": 17132.773025989532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538048, "time": 17138.146580934525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538048, "time": 17138.16097855568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538056, "time": 17138.200224637985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538256, "time": 17144.534126520157, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 538288, "time": 17145.50891828537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538496, "time": 17151.82272195816, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 538640, "time": 17156.23389005661, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 538648, "time": 17156.263016462326, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 538768, "time": 17160.25432896614, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 538872, "time": 17163.21516752243, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 538912, "time": 17164.657182216644, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 539192, "time": 17173.001083135605, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 539264, "time": 17175.415796995163, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 539312, "time": 17176.926609039307, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 539320, "time": 17176.955198287964, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 539624, "time": 17186.22155380249, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 539680, "time": 17188.174994945526, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 539816, "time": 17192.219732046127, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 17200.58138847351, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 540072, "time": 17200.73349905014, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 540072, "time": 17200.82424736023, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 540072, "time": 17201.0690305233, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 540072, "time": 17201.11913585663, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 540072, "time": 17201.54685330391, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 540072, "time": 17201.974658727646, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 540072, "time": 17202.746682167053, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 540136, "time": 17204.723814964294, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 540160, "time": 17205.680594205856, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 540184, "time": 17206.19543671608, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 540192, "time": 17206.671949386597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540248, "time": 17208.162099838257, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 540568, "time": 17217.943091630936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540616, "time": 17219.496364593506, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 540856, "time": 17227.32848572731, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 540880, "time": 17228.284874677658, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 541417, "time": 17245.462021827698, "train_stats/mean_log_entropy": 0.08744795683079061, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.189170338999686, "train/action_min": 0.0, "train/action_std": 1.6810087001503413, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0096245016118783, "train/actor_opt_grad_steps": 32750.0, "train/actor_opt_loss": -7.106340646032413, "train/adv_mag": 0.9488199877379527, "train/adv_max": 0.33485838156848696, "train/adv_mean": 0.0025506935010859554, "train/adv_min": -0.917607176843001, "train/adv_std": 0.03224925057560056, "train/cont_avg": 0.9954410725502513, "train/cont_loss_mean": 0.013207421370140797, "train/cont_loss_std": 0.19736615012179892, "train/cont_neg_acc": 0.4422999917708262, "train/cont_neg_loss": 2.2043331883459074, "train/cont_pos_acc": 0.9998324079130163, "train/cont_pos_loss": 0.0028212918767158, "train/cont_pred": 0.9954046879581471, "train/cont_rate": 0.9954410725502513, "train/dyn_loss_mean": 1.0000019085467162, "train/dyn_loss_std": 6.103588311450939e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.36515716365983136, "train/extr_critic_critic_opt_grad_steps": 32750.0, "train/extr_critic_critic_opt_loss": 3982.30431331462, "train/extr_critic_mag": 1.2441441473649375, "train/extr_critic_max": 1.2441441473649375, "train/extr_critic_mean": 1.194420175935755, "train/extr_critic_min": 0.9620903484785377, "train/extr_critic_std": 0.016048881665209132, "train/extr_return_normed_mag": 0.9389114580561767, "train/extr_return_normed_max": 0.27346982189159297, "train/extr_return_normed_mean": 0.03381636131545482, "train/extr_return_normed_min": -0.9058958160218282, "train/extr_return_normed_std": 0.036967393563096244, "train/extr_return_rate": 0.9989894565625407, "train/extr_return_raw_mag": 1.4366241555717123, "train/extr_return_raw_max": 1.4366241555717123, "train/extr_return_raw_mean": 1.196970761121817, "train/extr_return_raw_min": 0.25725851765829116, "train/extr_return_raw_std": 0.03696739353501617, "train/extr_reward_mag": 0.2906213124193738, "train/extr_reward_max": 0.2906213124193738, "train/extr_reward_mean": 0.002543844518090257, "train/extr_reward_min": 1.2220449783095163e-07, "train/extr_reward_std": 0.010436394429723522, "train/image_loss_mean": 0.08747679152380881, "train/image_loss_std": 0.0971283417700523, "train/model_loss_mean": 0.7095315180831219, "train/model_loss_std": 0.35738459502782055, "train/model_opt_grad_norm": 26.491889505675346, "train/model_opt_grad_steps": 32722.195979899498, "train/model_opt_loss": 3601.8106425683104, "train/model_opt_model_opt_grad_overflow": 0.005025125628140704, "train/model_opt_model_opt_grad_scale": 5050.251256281407, "train/policy_entropy_mag": 1.3214273949963364, "train/policy_entropy_max": 1.3214273949963364, "train/policy_entropy_mean": 0.1066826464767432, "train/policy_entropy_min": 0.06468653229612802, "train/policy_entropy_std": 0.13781351015795415, "train/policy_logprob_mag": 6.55108022929436, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10668292780168093, "train/policy_logprob_min": -6.55108022929436, "train/policy_logprob_std": 0.6440401817086953, "train/policy_randomness_mag": 0.6790793855585645, "train/policy_randomness_max": 0.6790793855585645, "train/policy_randomness_mean": 0.05482403851633695, "train/policy_randomness_min": 0.03324230339134758, "train/policy_randomness_std": 0.07082213867624201, "train/post_ent_mag": 29.13139110354323, "train/post_ent_max": 29.13139110354323, "train/post_ent_mean": 28.983899313001775, "train/post_ent_min": 28.875901667915997, "train/post_ent_std": 0.0491732923903657, "train/prior_ent_mag": 29.879839691085433, "train/prior_ent_max": 29.879839691085433, "train/prior_ent_mean": 28.60638414315842, "train/prior_ent_min": 27.318491470873656, "train/prior_ent_std": 0.4240811383304883, "train/rep_loss_mean": 1.0000019085467162, "train/rep_loss_std": 6.103588311450939e-05, "train/reward_avg": 0.0011664002381461724, "train/reward_loss_mean": 0.008846140294054982, "train/reward_loss_std": 0.15613317898657153, "train/reward_max_data": 0.6007380642783102, "train/reward_max_pred": 0.19957072231637774, "train/reward_neg_acc": 0.9997050244005481, "train/reward_neg_loss": 0.0015288361525321004, "train/reward_pos_acc": 0.26252525421706113, "train/reward_pos_loss": 3.904429389491226, "train/reward_pred": 0.0009309553667603426, "train/reward_rate": 0.0018353486180904522, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.012157633900642395, "report/cont_loss_std": 0.21110177040100098, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 1.8757472038269043, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0011738059110939503, "report/cont_pred": 0.9962186813354492, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08078131079673767, "report/image_loss_std": 0.10189803689718246, "report/model_loss_mean": 0.7017879486083984, "report/model_loss_std": 0.3526746332645416, "report/post_ent_mag": 28.972867965698242, "report/post_ent_max": 28.972867965698242, "report/post_ent_mean": 28.819427490234375, "report/post_ent_min": 28.72079086303711, "report/post_ent_std": 0.04894079640507698, "report/prior_ent_mag": 29.897859573364258, "report/prior_ent_max": 29.897859573364258, "report/prior_ent_mean": 28.728050231933594, "report/prior_ent_min": 27.690290451049805, "report/prior_ent_std": 0.38791191577911377, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0020935058128088713, "report/reward_loss_mean": 0.008848961442708969, "report/reward_loss_std": 0.163382425904274, "report/reward_max_data": 0.84375, "report/reward_max_pred": 0.5041148662567139, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0006754026981070638, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 2.790583610534668, "report/reward_pred": 0.0008951680501922965, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.05612765997648239, "eval/cont_loss_std": 0.7867349982261658, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.17193603515625, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0015849309274926782, "eval/cont_pred": 0.9985538721084595, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19877783954143524, "eval/image_loss_std": 0.15517489612102509, "eval/model_loss_mean": 0.8824917674064636, "eval/model_loss_std": 1.2991400957107544, "eval/post_ent_mag": 28.976654052734375, "eval/post_ent_max": 28.976654052734375, "eval/post_ent_mean": 28.816715240478516, "eval/post_ent_min": 28.728118896484375, "eval/post_ent_std": 0.04893121123313904, "eval/prior_ent_mag": 30.102449417114258, "eval/prior_ent_max": 30.102449417114258, "eval/prior_ent_mean": 28.745845794677734, "eval/prior_ent_min": 27.398778915405273, "eval/prior_ent_std": 0.3794052302837372, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005859375232830644, "eval/reward_loss_mean": 0.02758624032139778, "eval/reward_loss_std": 0.5974701642990112, "eval/reward_max_data": 0.32499998807907104, "eval/reward_max_pred": 0.22306716442108154, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.0011683314805850387, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 13.527137756347656, "eval/reward_pred": 0.0005282069323584437, "eval/reward_rate": 0.001953125, "replay/size": 540913.0, "replay/inserts": 31760.0, "replay/samples": 31760.0, "replay/insert_wait_avg": 1.4384687697557118e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.049771714871116e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6664.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2765984002854072e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3293828964233, "timer/env.step_count": 3970.0, "timer/env.step_total": 39.7273895740509, "timer/env.step_frac": 0.039714308360133795, "timer/env.step_avg": 0.01000689913704053, "timer/env.step_min": 0.00806736946105957, "timer/env.step_max": 0.036128997802734375, "timer/replay._sample_count": 31760.0, "timer/replay._sample_total": 17.24757957458496, "timer/replay._sample_frac": 0.017241900387495485, "timer/replay._sample_avg": 0.0005430598102829018, "timer/replay._sample_min": 0.0004229545593261719, "timer/replay._sample_max": 0.011740922927856445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4803.0, "timer/agent.policy_total": 53.28898620605469, "timer/agent.policy_frac": 0.05327143950501389, "timer/agent.policy_avg": 0.011094937790142555, "timer/agent.policy_min": 0.00899052619934082, "timer/agent.policy_max": 0.09407877922058105, "timer/dataset_train_count": 1985.0, "timer/dataset_train_total": 0.23244571685791016, "timer/dataset_train_frac": 0.00023236917842488105, "timer/dataset_train_avg": 0.00011710111680499252, "timer/dataset_train_min": 0.00010037422180175781, "timer/dataset_train_max": 0.0006468296051025391, "timer/agent.train_count": 1985.0, "timer/agent.train_total": 887.3133730888367, "timer/agent.train_frac": 0.887021203475647, "timer/agent.train_avg": 0.4470092559641495, "timer/agent.train_min": 0.4361915588378906, "timer/agent.train_max": 0.7011086940765381, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4828152656555176, "timer/agent.report_frac": 0.0004826562869297517, "timer/agent.report_avg": 0.2414076328277588, "timer/agent.report_min": 0.23479652404785156, "timer/agent.report_max": 0.24801874160766602, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00011324882507324219, "timer/dataset_eval_frac": 1.1321153512989257e-07, "timer/dataset_eval_avg": 0.00011324882507324219, "timer/dataset_eval_min": 0.00011324882507324219, "timer/dataset_eval_max": 0.00011324882507324219, "fps": 31.748919650477255}
{"step": 541440, "time": 17246.155484437943, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 541544, "time": 17249.366879940033, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 541664, "time": 17253.273589134216, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 541688, "time": 17253.795898914337, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 541728, "time": 17255.26663541794, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 541992, "time": 17263.12520813942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542128, "time": 17267.526094913483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542400, "time": 17275.86158132553, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 542448, "time": 17277.32837510109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542528, "time": 17279.911917209625, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 542728, "time": 17285.819981575012, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 542896, "time": 17291.156378269196, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 543008, "time": 17294.606604099274, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 543224, "time": 17300.98162817955, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 543456, "time": 17308.265652656555, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 543592, "time": 17312.304851293564, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 543624, "time": 17313.28062105179, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 543848, "time": 17320.095200061798, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 544088, "time": 17327.390065193176, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 544304, "time": 17334.239836215973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544408, "time": 17337.18442249298, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 544408, "time": 17337.192534923553, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 544528, "time": 17341.195765018463, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 544816, "time": 17349.981016159058, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 544840, "time": 17350.497240543365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545064, "time": 17357.327517986298, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 545200, "time": 17363.27644610405, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 545240, "time": 17364.30110025406, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 545264, "time": 17365.259227514267, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 545816, "time": 17382.052776813507, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 545904, "time": 17384.990712165833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 546080, "time": 17390.358992815018, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 546144, "time": 17392.29508829117, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 546280, "time": 17396.199665784836, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 546632, "time": 17407.12443304062, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 546776, "time": 17411.53555560112, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 546984, "time": 17417.954427957535, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 547128, "time": 17422.353269815445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547152, "time": 17423.320843935013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547304, "time": 17427.715049266815, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 547512, "time": 17434.172523736954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547576, "time": 17436.124598026276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547632, "time": 17438.077835798264, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 548008, "time": 17449.32187461853, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 548128, "time": 17453.240096330643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548192, "time": 17455.199940681458, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 548208, "time": 17455.69513463974, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 548680, "time": 17470.003760576248, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 548704, "time": 17470.955474853516, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 548880, "time": 17476.839900255203, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 548992, "time": 17480.253742456436, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 549160, "time": 17485.139861106873, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 549296, "time": 17489.63112449646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549480, "time": 17495.049832105637, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 549568, "time": 17497.97461295128, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 549824, "time": 17505.82363963127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549832, "time": 17505.853130102158, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 549888, "time": 17507.80081820488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549928, "time": 17508.797914981842, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 17514.097975730896, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 550056, "time": 17514.377308130264, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 550056, "time": 17514.4683907032, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 550056, "time": 17515.357669591904, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 550056, "time": 17515.586689949036, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 550056, "time": 17515.922246932983, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 550056, "time": 17517.963099956512, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 550056, "time": 17518.872213363647, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17518.88009595871, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17518.887074947357, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17518.894095897675, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550144, "time": 17521.816428422928, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 550232, "time": 17524.331832408905, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 550328, "time": 17527.28975701332, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 550344, "time": 17527.784199237823, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 550432, "time": 17530.71047449112, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 550608, "time": 17536.113545417786, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 550744, "time": 17540.07232260704, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 551024, "time": 17551.56551337242, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 551104, "time": 17554.024293899536, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 551120, "time": 17554.545082330704, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 551312, "time": 17560.436163663864, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 551472, "time": 17565.357320308685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551520, "time": 17566.83279657364, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 551656, "time": 17570.763776779175, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 551728, "time": 17573.179676294327, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 552000, "time": 17581.613936662674, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 552240, "time": 17588.961839675903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552328, "time": 17591.434363603592, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 552456, "time": 17595.337429523468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552824, "time": 17606.55916762352, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 553056, "time": 17613.93428015709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553072, "time": 17614.45833349228, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 553272, "time": 17620.3372733593, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 553624, "time": 17631.1089823246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553784, "time": 17636.030819892883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553968, "time": 17641.99942779541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554048, "time": 17644.490258216858, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 554192, "time": 17648.928245544434, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 554312, "time": 17652.380375146866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554672, "time": 17663.687049627304, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 554768, "time": 17666.660110235214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554936, "time": 17671.718089342117, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 555016, "time": 17674.201031684875, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 555384, "time": 17685.512244701385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 555624, "time": 17692.865137577057, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 555656, "time": 17693.86385369301, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 555920, "time": 17702.22175502777, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 556096, "time": 17707.587968826294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556280, "time": 17712.985231876373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556360, "time": 17715.40687584877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556408, "time": 17716.866760015488, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 556464, "time": 17718.82907819748, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 556736, "time": 17727.138452768326, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 556744, "time": 17727.16804075241, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 557248, "time": 17743.379403591156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557384, "time": 17747.277002573013, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 557696, "time": 17756.98777270317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557712, "time": 17757.498841762543, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 557968, "time": 17765.38757801056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557992, "time": 17765.89676094055, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 558064, "time": 17768.31805372238, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 558080, "time": 17768.8118391037, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 558416, "time": 17779.036418437958, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 558672, "time": 17786.828951835632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558776, "time": 17789.888120174408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 558800, "time": 17790.84352684021, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 558840, "time": 17791.864366531372, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 559104, "time": 17800.173958063126, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 559384, "time": 17808.508728981018, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 559536, "time": 17813.404103517532, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 559656, "time": 17816.848927021027, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 559680, "time": 17817.8035261631, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 559864, "time": 17823.295429229736, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 559872, "time": 17823.762461662292, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 559896, "time": 17824.273587703705, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 560016, "time": 17828.1780230999, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 17828.69351887703, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 17830.95129966736, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 560040, "time": 17831.415579319, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 560040, "time": 17832.032094478607, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 560040, "time": 17832.455219745636, "eval_episode/length": 180.0, "eval_episode/score": 0.4375, "eval_episode/reward_rate": 0.0055248618784530384}
{"step": 560040, "time": 17833.831558942795, "eval_episode/length": 243.0, "eval_episode/score": 0.24062499403953552, "eval_episode/reward_rate": 0.004098360655737705}
{"step": 560040, "time": 17833.988451242447, "eval_episode/length": 250.0, "eval_episode/score": 0.21875, "eval_episode/reward_rate": 0.00398406374501992}
{"step": 560040, "time": 17834.05983877182, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 560040, "time": 17834.808951854706, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17834.816902160645, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560952, "time": 17862.621015310287, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 560976, "time": 17863.57808494568, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 560984, "time": 17863.61483359337, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 561064, "time": 17866.053435325623, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 561104, "time": 17867.524961948395, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 561288, "time": 17872.92739200592, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 561336, "time": 17874.394592761993, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 561400, "time": 17876.365846157074, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 561408, "time": 17876.840687274933, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 561520, "time": 17880.363857507706, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 561824, "time": 17889.645015239716, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 561888, "time": 17891.616255044937, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 561920, "time": 17892.59650015831, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 562024, "time": 17895.557145357132, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 562064, "time": 17897.035329818726, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 562352, "time": 17905.85928964615, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 562392, "time": 17906.8635866642, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 562440, "time": 17908.394971609116, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 562912, "time": 17923.118325948715, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 563232, "time": 17932.99026966095, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 563256, "time": 17933.510118961334, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 563368, "time": 17936.973070144653, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 563496, "time": 17941.0000538826, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 563520, "time": 17941.95701599121, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 563672, "time": 17946.399703741074, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 563688, "time": 17946.889596939087, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 563800, "time": 17950.32138967514, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 563992, "time": 17956.226964235306, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 564200, "time": 17962.593431711197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564336, "time": 17967.01666855812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564496, "time": 17972.01594734192, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 564512, "time": 17972.513840198517, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 564744, "time": 17979.430015802383, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 565104, "time": 17990.716452360153, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 565184, "time": 17993.17237019539, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 565232, "time": 17994.65900683403, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 565544, "time": 18004.63274693489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565680, "time": 18009.003690719604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565768, "time": 18011.48011946678, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 565824, "time": 18013.408657312393, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 565984, "time": 18018.28732061386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566000, "time": 18018.785115480423, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 566040, "time": 18019.81783223152, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 566112, "time": 18022.244462013245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566304, "time": 18028.14848470688, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 566312, "time": 18028.17830467224, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 566528, "time": 18035.221305847168, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 566592, "time": 18037.176510334015, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 566760, "time": 18042.085638284683, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 566872, "time": 18045.514312028885, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 566880, "time": 18045.987812280655, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 567024, "time": 18050.426211118698, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 567136, "time": 18053.839846134186, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 567264, "time": 18057.746061086655, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 567472, "time": 18064.203011512756, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 567584, "time": 18067.61034178734, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 567736, "time": 18072.03313946724, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 567840, "time": 18075.428067922592, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 568000, "time": 18080.332832098007, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 568016, "time": 18080.833333969116, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 568024, "time": 18080.863356113434, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 568240, "time": 18087.718717336655, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 568344, "time": 18090.80776119232, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 568352, "time": 18091.28241300583, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 568448, "time": 18094.23672604561, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 568624, "time": 18099.59774708748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568720, "time": 18102.524925470352, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 568736, "time": 18103.01221060753, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 568840, "time": 18105.969746112823, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 568864, "time": 18106.929553985596, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 568992, "time": 18110.830758094788, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 569056, "time": 18112.790672063828, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 569168, "time": 18116.214040517807, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 569208, "time": 18117.21777653694, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 569296, "time": 18120.219124555588, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 569344, "time": 18121.693950414658, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 569680, "time": 18131.984437942505, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 569896, "time": 18138.436607837677, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 569976, "time": 18140.890693187714, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 570008, "time": 18141.86974811554, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 18143.565819740295, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 570024, "time": 18143.799599409103, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 570024, "time": 18143.82675886154, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 570024, "time": 18144.573971033096, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 570024, "time": 18144.640774965286, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 570024, "time": 18145.694463014603, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 570024, "time": 18145.742437124252, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 570024, "time": 18146.78015780449, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 570176, "time": 18151.77964258194, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 570208, "time": 18152.775038719177, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 570240, "time": 18153.759073019028, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 570320, "time": 18156.220640420914, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 570544, "time": 18163.10821700096, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 570552, "time": 18163.142154932022, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 570792, "time": 18170.45645713806, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 570824, "time": 18171.440486192703, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 571176, "time": 18182.279470443726, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 571192, "time": 18182.76898407936, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 571368, "time": 18188.147431373596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571480, "time": 18191.582771539688, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 571520, "time": 18193.019511461258, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 571736, "time": 18199.377836704254, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 571832, "time": 18202.323922395706, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 571848, "time": 18202.815191984177, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 571888, "time": 18204.26377248764, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 572088, "time": 18210.279926776886, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 572232, "time": 18214.678401708603, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 572376, "time": 18219.107841730118, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 572552, "time": 18224.49809026718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572736, "time": 18230.41120171547, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 572776, "time": 18231.441264867783, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 572856, "time": 18233.898735046387, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 572856, "time": 18233.91006708145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573056, "time": 18240.391862869263, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 573209, "time": 18245.83326983452, "train_stats/mean_log_entropy": 0.09570928293697793, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.211807405105745, "train/action_min": 0.0, "train/action_std": 1.6695709312805023, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010920896569991278, "train/actor_opt_grad_steps": 34735.0, "train/actor_opt_loss": -9.463544159074022, "train/adv_mag": 0.9904416128240451, "train/adv_max": 0.2955679971762378, "train/adv_mean": 0.0024403562907867704, "train/adv_min": -0.9572816265351844, "train/adv_std": 0.03388494441304544, "train/cont_avg": 0.9953046085858586, "train/cont_loss_mean": 0.014052072666336152, "train/cont_loss_std": 0.20708813623177133, "train/cont_neg_acc": 0.4074268858444872, "train/cont_neg_loss": 2.3254305012039556, "train/cont_pos_acc": 0.9998265655353816, "train/cont_pos_loss": 0.002967481963240043, "train/cont_pred": 0.9954511664732538, "train/cont_rate": 0.9953046085858586, "train/dyn_loss_mean": 1.0000064312809644, "train/dyn_loss_std": 0.00017306015525728164, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3898590604464213, "train/extr_critic_critic_opt_grad_steps": 34735.0, "train/extr_critic_critic_opt_loss": 6823.464062006787, "train/extr_critic_mag": 1.3198741265017577, "train/extr_critic_max": 1.3198741265017577, "train/extr_critic_mean": 1.2381680788415852, "train/extr_critic_min": 1.1021927017154116, "train/extr_critic_std": 0.018813868707064727, "train/extr_return_normed_mag": 0.9795647976976453, "train/extr_return_normed_max": 0.3155088557137383, "train/extr_return_normed_mean": 0.03910022874296916, "train/extr_return_normed_min": -0.9340794733678451, "train/extr_return_normed_std": 0.040015903564941405, "train/extr_return_rate": 0.9993532751545762, "train/extr_return_raw_mag": 1.517017399421846, "train/extr_return_raw_max": 1.517017399421846, "train/extr_return_raw_mean": 1.2406088318487611, "train/extr_return_raw_min": 0.26742907034026253, "train/extr_return_raw_std": 0.040015903668421685, "train/extr_reward_mag": 0.3267090723972128, "train/extr_reward_max": 0.3267090723972128, "train/extr_reward_mean": 0.002338203911392037, "train/extr_reward_min": 1.1800515531289458e-07, "train/extr_reward_std": 0.01141389635288053, "train/image_loss_mean": 0.08695831486597808, "train/image_loss_std": 0.0974810780825639, "train/model_loss_mean": 0.7108806546288308, "train/model_loss_std": 0.3792249050480549, "train/model_opt_grad_norm": 24.97883226895573, "train/model_opt_grad_steps": 34705.30808080808, "train/model_opt_loss": 2659.308772539852, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3737.373737373737, "train/policy_entropy_mag": 1.3368435092646667, "train/policy_entropy_max": 1.3368435092646667, "train/policy_entropy_mean": 0.11565387169971611, "train/policy_entropy_min": 0.06468650977117847, "train/policy_entropy_std": 0.15111138118487416, "train/policy_logprob_mag": 6.551080243756073, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11545525412216331, "train/policy_logprob_min": -6.551080243756073, "train/policy_logprob_std": 0.651304793177229, "train/policy_randomness_mag": 0.6870017045676106, "train/policy_randomness_max": 0.6870017045676106, "train/policy_randomness_mean": 0.059434336563101924, "train/policy_randomness_min": 0.03324229125347403, "train/policy_randomness_std": 0.07765589236761584, "train/post_ent_mag": 29.076078048860182, "train/post_ent_max": 29.076078048860182, "train/post_ent_mean": 28.923284020086733, "train/post_ent_min": 28.805982233297946, "train/post_ent_std": 0.05231139810774663, "train/prior_ent_mag": 29.812986325736, "train/prior_ent_max": 29.812986325736, "train/prior_ent_mean": 28.5457201485682, "train/prior_ent_min": 27.438848312454994, "train/prior_ent_std": 0.3881358549450383, "train/rep_loss_mean": 1.0000064312809644, "train/rep_loss_std": 0.00017306015525728164, "train/reward_avg": 0.0012728604344760463, "train/reward_loss_mean": 0.009866383587565235, "train/reward_loss_std": 0.17071176568520105, "train/reward_max_data": 0.6177872468275253, "train/reward_max_pred": 0.20721918765944664, "train/reward_neg_acc": 0.9996589455339644, "train/reward_neg_loss": 0.0017985931307787659, "train/reward_pos_acc": 0.24456800886256966, "train/reward_pos_loss": 4.002362254137051, "train/reward_pred": 0.0010306487322051191, "train/reward_rate": 0.0019975142045454545, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.003209299873560667, "report/cont_loss_std": 0.020290616899728775, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.10797970741987228, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0027984355110675097, "report/cont_pred": 0.9938175678253174, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0808190330862999, "report/image_loss_std": 0.09225896000862122, "report/model_loss_mean": 0.6865522861480713, "report/model_loss_std": 0.10246293246746063, "report/post_ent_mag": 28.967350006103516, "report/post_ent_max": 28.967350006103516, "report/post_ent_mean": 28.81282615661621, "report/post_ent_min": 28.712059020996094, "report/post_ent_std": 0.05512614920735359, "report/prior_ent_mag": 29.499866485595703, "report/prior_ent_max": 29.499866485595703, "report/prior_ent_mean": 27.995637893676758, "report/prior_ent_min": 26.871360778808594, "report/prior_ent_std": 0.4211972951889038, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006256103515625, "report/reward_loss_mean": 0.0025239326059818268, "report/reward_loss_std": 0.03220357373356819, "report/reward_max_data": 0.640625, "report/reward_max_pred": 0.5941950082778931, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.001544424332678318, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 1.0045608282089233, "report/reward_pred": 0.0013623414561152458, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01886330544948578, "eval/cont_loss_std": 0.4093798100948334, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.951896667480469, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013818294974043965, "eval/cont_pred": 0.9986708164215088, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14649192988872528, "eval/image_loss_std": 0.15977968275547028, "eval/model_loss_mean": 0.7657697200775146, "eval/model_loss_std": 0.44338124990463257, "eval/post_ent_mag": 28.979991912841797, "eval/post_ent_max": 28.979991912841797, "eval/post_ent_mean": 28.798397064208984, "eval/post_ent_min": 28.67711639404297, "eval/post_ent_std": 0.05211358144879341, "eval/prior_ent_mag": 29.499866485595703, "eval/prior_ent_max": 29.499866485595703, "eval/prior_ent_mean": 27.961830139160156, "eval/prior_ent_min": 26.854568481445312, "eval/prior_ent_std": 0.43652161955833435, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00041445065289735794, "eval/reward_loss_std": 0.0023515820503234863, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.022489190101623535, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00041445065289735794, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00020957307424396276, "eval/reward_rate": 0.0, "replay/size": 572705.0, "replay/inserts": 31792.0, "replay/samples": 31792.0, "replay/insert_wait_avg": 1.4405605717406058e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.04178763371829e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2553614506401187e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2218952178955078e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3480751514435, "timer/env.step_count": 3974.0, "timer/env.step_total": 40.01742124557495, "timer/env.step_frac": 0.04000349702229065, "timer/env.step_avg": 0.01006980907035102, "timer/env.step_min": 0.008165359497070312, "timer/env.step_max": 0.042420387268066406, "timer/replay._sample_count": 31792.0, "timer/replay._sample_total": 17.139458179473877, "timer/replay._sample_frac": 0.01713349443580338, "timer/replay._sample_avg": 0.0005391122980458567, "timer/replay._sample_min": 0.00037670135498046875, "timer/replay._sample_max": 0.012353658676147461, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4763.0, "timer/agent.policy_total": 52.36227607727051, "timer/agent.policy_frac": 0.052344056411907765, "timer/agent.policy_avg": 0.010993549459851041, "timer/agent.policy_min": 0.00934457778930664, "timer/agent.policy_max": 0.08773326873779297, "timer/dataset_train_count": 1987.0, "timer/dataset_train_total": 0.23183655738830566, "timer/dataset_train_frac": 0.00023175588892217116, "timer/dataset_train_avg": 0.0001166766770952721, "timer/dataset_train_min": 0.00010156631469726562, "timer/dataset_train_max": 0.0005197525024414062, "timer/agent.train_count": 1987.0, "timer/agent.train_total": 890.7295877933502, "timer/agent.train_frac": 0.8904196548371446, "timer/agent.train_avg": 0.4482786048280575, "timer/agent.train_min": 0.4347045421600342, "timer/agent.train_max": 1.9910118579864502, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4856741428375244, "timer/agent.report_frac": 0.0004855051505587171, "timer/agent.report_avg": 0.2428370714187622, "timer/agent.report_min": 0.23523783683776855, "timer/agent.report_max": 0.25043630599975586, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.506111145019531e-05, "timer/dataset_eval_frac": 4.5045432254541477e-08, "timer/dataset_eval_avg": 4.506111145019531e-05, "timer/dataset_eval_min": 4.506111145019531e-05, "timer/dataset_eval_max": 4.506111145019531e-05, "fps": 31.780340483628304}
{"step": 573624, "time": 18258.88670682907, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 573672, "time": 18260.35302901268, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 573744, "time": 18262.784042596817, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 573952, "time": 18269.266610860825, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 574160, "time": 18275.59953045845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574200, "time": 18276.63007044792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574328, "time": 18280.533820152283, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 574400, "time": 18282.97531557083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574496, "time": 18285.90881919861, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 575040, "time": 18302.68675851822, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 575088, "time": 18304.159732818604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575168, "time": 18306.63499546051, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575224, "time": 18308.137770414352, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 575544, "time": 18317.982735157013, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 575640, "time": 18320.930685281754, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 575720, "time": 18323.36545586586, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 575904, "time": 18329.351375102997, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 575936, "time": 18330.343499660492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576152, "time": 18336.73101091385, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 576456, "time": 18346.021230459213, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 576464, "time": 18346.49286341667, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 576488, "time": 18347.007222652435, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 576504, "time": 18347.49721121788, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 576512, "time": 18347.965129375458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576640, "time": 18351.870975494385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577000, "time": 18362.709300518036, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 577216, "time": 18369.492228269577, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 577328, "time": 18372.935324192047, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 577424, "time": 18375.89409327507, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 577536, "time": 18379.34072470665, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 577784, "time": 18386.685643196106, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 577800, "time": 18387.176827192307, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 577848, "time": 18388.775117635727, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 577848, "time": 18388.78912639618, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 578040, "time": 18394.645648241043, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 578056, "time": 18395.134783029556, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 578136, "time": 18397.553554058075, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 578216, "time": 18399.998077869415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578528, "time": 18409.712079524994, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 578760, "time": 18416.62790465355, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 578816, "time": 18418.703590154648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578832, "time": 18419.220172405243, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 578968, "time": 18423.155640363693, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 579040, "time": 18425.617864370346, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 579048, "time": 18425.6464073658, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 579176, "time": 18429.592515707016, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 579208, "time": 18430.585990190506, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 579600, "time": 18442.851964712143, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 579672, "time": 18444.850700616837, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 18457.124918222427, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 580008, "time": 18457.153356075287, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 580008, "time": 18457.99875020981, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 580008, "time": 18458.133234024048, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 580008, "time": 18458.45995736122, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 580008, "time": 18458.72926902771, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 580008, "time": 18458.736499786377, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 580008, "time": 18459.159395456314, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 580368, "time": 18470.427762031555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580384, "time": 18470.92302298546, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 580464, "time": 18473.386690855026, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 580600, "time": 18477.34968495369, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 580616, "time": 18477.840711832047, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 580976, "time": 18489.20326113701, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 581072, "time": 18492.165242671967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581288, "time": 18498.541655778885, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 581360, "time": 18500.958866119385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581520, "time": 18505.893773794174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582016, "time": 18521.72177052498, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 582240, "time": 18528.557793855667, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 582696, "time": 18542.37508559227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582776, "time": 18544.830741643906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582912, "time": 18549.241308689117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583232, "time": 18559.11014866829, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 583280, "time": 18560.594383001328, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 583288, "time": 18560.627022981644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583384, "time": 18563.624289274216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583384, "time": 18563.633840084076, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 583736, "time": 18574.64103102684, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 583760, "time": 18575.601966142654, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 583832, "time": 18577.601809740067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583880, "time": 18579.078158140182, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 583992, "time": 18582.500482320786, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 584160, "time": 18587.78793501854, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 584584, "time": 18600.703343629837, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 584800, "time": 18607.589440107346, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 585064, "time": 18615.517016649246, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 585136, "time": 18618.001887083054, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 585224, "time": 18620.490253925323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585360, "time": 18624.898736953735, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 585576, "time": 18631.406508922577, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 585656, "time": 18633.82214975357, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 585696, "time": 18635.257922887802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585720, "time": 18635.791647434235, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 586072, "time": 18646.549854516983, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 586072, "time": 18646.55755352974, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 586144, "time": 18648.962717056274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586288, "time": 18653.339361667633, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 586304, "time": 18653.838624477386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586376, "time": 18655.83000421524, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 586600, "time": 18662.750285863876, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 586672, "time": 18665.18484735489, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 586832, "time": 18670.079117059708, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 587152, "time": 18679.85428929329, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 587280, "time": 18683.79337620735, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 587584, "time": 18693.117219686508, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 587760, "time": 18698.917615652084, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 587888, "time": 18702.82514500618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588216, "time": 18712.666608333588, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 588368, "time": 18717.5027050972, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 588456, "time": 18720.08701133728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588616, "time": 18725.001296043396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588912, "time": 18734.3047413826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589032, "time": 18737.792463302612, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 589088, "time": 18739.75097990036, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 589368, "time": 18748.061949253082, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 589464, "time": 18751.112661600113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589584, "time": 18755.01295375824, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 589592, "time": 18755.044683218002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589656, "time": 18757.004147529602, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 589688, "time": 18757.996658086777, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 589736, "time": 18759.48285293579, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 589760, "time": 18760.4392786026, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 590008, "time": 18768.39469909668, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 18771.96454191208, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 590096, "time": 18773.617473125458, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 590096, "time": 18773.986016988754, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 590096, "time": 18774.683742523193, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 590096, "time": 18775.01652765274, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 590096, "time": 18775.091056585312, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 590096, "time": 18776.964579343796, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 590096, "time": 18777.10177755356, "eval_episode/length": 267.0, "eval_episode/score": 0.16562500596046448, "eval_episode/reward_rate": 0.0037313432835820895}
{"step": 590216, "time": 18780.691699266434, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 590264, "time": 18782.155784606934, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 590504, "time": 18789.489336013794, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 590640, "time": 18793.878597974777, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 590672, "time": 18794.87456679344, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 590704, "time": 18795.852350711823, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 591112, "time": 18808.088076114655, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 591176, "time": 18810.177485227585, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 591288, "time": 18813.59014081955, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 591408, "time": 18817.50332212448, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 591424, "time": 18818.00591993332, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 591760, "time": 18828.242705345154, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 591880, "time": 18831.712626695633, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 591896, "time": 18832.210979938507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591904, "time": 18832.68225812912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592040, "time": 18836.61455988884, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 592128, "time": 18841.196152687073, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 592216, "time": 18843.666963338852, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 592288, "time": 18846.093234300613, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 592344, "time": 18847.581129312515, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 592712, "time": 18858.808284044266, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 593160, "time": 18872.6614048481, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 593432, "time": 18880.969314336777, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 593592, "time": 18885.905162096024, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 593600, "time": 18886.38168811798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593720, "time": 18889.84747314453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593824, "time": 18893.228021144867, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 593896, "time": 18895.21779203415, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 593944, "time": 18896.687803030014, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 594016, "time": 18899.239138364792, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 594216, "time": 18905.134855747223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594360, "time": 18909.52963757515, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 594416, "time": 18911.46621441841, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 594576, "time": 18916.353221416473, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 594848, "time": 18924.69120335579, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 594872, "time": 18925.204830884933, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 594872, "time": 18925.2120013237, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 595080, "time": 18931.71470451355, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 595400, "time": 18941.49349951744, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 595832, "time": 18954.699494838715, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 595872, "time": 18956.14648795128, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 596032, "time": 18961.211321115494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596136, "time": 18964.178968667984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596672, "time": 18980.69805574417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596728, "time": 18982.182812213898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596984, "time": 18990.10433769226, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 597160, "time": 18995.494155406952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597312, "time": 19000.381695747375, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 597392, "time": 19002.852602005005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597760, "time": 19014.127517700195, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 597928, "time": 19019.127862930298, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 597984, "time": 19021.05283355713, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 598032, "time": 19023.061341047287, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 598112, "time": 19025.51001882553, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 598120, "time": 19025.539799928665, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 598176, "time": 19027.467938661575, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 598256, "time": 19029.944556236267, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 598448, "time": 19035.810540676117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598872, "time": 19048.72305083275, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 598968, "time": 19051.636751413345, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 598992, "time": 19054.357068300247, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 599072, "time": 19056.809465646744, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 599376, "time": 19066.12627506256, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 599416, "time": 19067.12312889099, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 599440, "time": 19068.08059811592, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 599928, "time": 19082.837134599686, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 19089.991891145706, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 600080, "time": 19090.20569586754, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 600080, "time": 19090.340591669083, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 600080, "time": 19091.130855560303, "eval_episode/length": 162.0, "eval_episode/score": 0.4937500059604645, "eval_episode/reward_rate": 0.006134969325153374}
{"step": 600080, "time": 19092.610624551773, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 600080, "time": 19092.74889612198, "eval_episode/length": 238.0, "eval_episode/score": 0.2562499940395355, "eval_episode/reward_rate": 0.0041841004184100415}
{"step": 600080, "time": 19093.223470926285, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 600080, "time": 19093.506271839142, "eval_episode/length": 274.0, "eval_episode/score": 0.14374999701976776, "eval_episode/reward_rate": 0.0036363636363636364}
{"step": 600120, "time": 19094.54784965515, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 600312, "time": 19100.39527130127, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 600344, "time": 19101.376216173172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600480, "time": 19105.759592056274, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 600568, "time": 19108.23428916931, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600896, "time": 19118.54190135002, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 601024, "time": 19122.49372291565, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 601176, "time": 19126.982356786728, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 601280, "time": 19130.44274687767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601304, "time": 19130.962858438492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601632, "time": 19141.26029396057, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 601752, "time": 19144.713794708252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602400, "time": 19164.795042037964, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 602432, "time": 19165.781070947647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602720, "time": 19174.745944023132, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 603000, "time": 19183.12066602707, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 603208, "time": 19189.920715093613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603288, "time": 19192.358330488205, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 603336, "time": 19193.851269245148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603448, "time": 19198.10877776146, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 603456, "time": 19198.73441672325, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 603656, "time": 19204.63693833351, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 603664, "time": 19205.11064839363, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 603824, "time": 19209.995777606964, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 604064, "time": 19217.34092950821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604320, "time": 19225.129542589188, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 604568, "time": 19232.596314430237, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 604792, "time": 19239.469468832016, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 604824, "time": 19240.45223069191, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 604969, "time": 19245.852286100388, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2949338366637875, "train/action_min": 0.0, "train/action_std": 1.7186180419059256, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011251342537855008, "train/actor_opt_grad_steps": 36720.0, "train/actor_opt_loss": -9.334571892404975, "train/adv_mag": 0.9718315559415961, "train/adv_max": 0.263909406398409, "train/adv_mean": 0.0018995619665470235, "train/adv_min": -0.9393360542891612, "train/adv_std": 0.029897918547948252, "train/cont_avg": 0.995328203517588, "train/cont_loss_mean": 0.014344574667129609, "train/cont_loss_std": 0.20773920068639007, "train/cont_neg_acc": 0.37337663024663925, "train/cont_neg_loss": 2.4092580036629423, "train/cont_pos_acc": 0.9997830280107469, "train/cont_pos_loss": 0.003228744481404747, "train/cont_pred": 0.9952194807517468, "train/cont_rate": 0.995328203517588, "train/dyn_loss_mean": 1.00000066194103, "train/dyn_loss_std": 2.1161570333075434e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3271426932146801, "train/extr_critic_critic_opt_grad_steps": 36720.0, "train/extr_critic_critic_opt_loss": 10318.058709072708, "train/extr_critic_mag": 1.3594590467424248, "train/extr_critic_max": 1.3594590467424248, "train/extr_critic_mean": 1.280217492999743, "train/extr_critic_min": 1.1446017320431656, "train/extr_critic_std": 0.01974111987773947, "train/extr_return_normed_mag": 0.965091102087318, "train/extr_return_normed_max": 0.2721044388248693, "train/extr_return_normed_mean": 0.039628576922543984, "train/extr_return_normed_min": -0.9176392645093064, "train/extr_return_normed_std": 0.03646212214856741, "train/extr_return_rate": 0.9993480183371347, "train/extr_return_raw_mag": 1.5145933172810617, "train/extr_return_raw_max": 1.5145933172810617, "train/extr_return_raw_mean": 1.2821175165511856, "train/extr_return_raw_min": 0.32484961394688594, "train/extr_return_raw_std": 0.03646212204560712, "train/extr_reward_mag": 0.2889470161505081, "train/extr_reward_max": 0.2889470161505081, "train/extr_reward_mean": 0.0023521668313950975, "train/extr_reward_min": 3.174920776980606e-08, "train/extr_reward_std": 0.009372402218886506, "train/image_loss_mean": 0.08380283636214146, "train/image_loss_std": 0.09596467516080819, "train/model_loss_mean": 0.7090150674982886, "train/model_loss_std": 0.39418098012256864, "train/model_opt_grad_norm": 23.526446538953923, "train/model_opt_grad_steps": 36689.14572864322, "train/model_opt_loss": 3562.73103922935, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5025.125628140703, "train/policy_entropy_mag": 1.328306370644114, "train/policy_entropy_max": 1.328306370644114, "train/policy_entropy_mean": 0.11207243714051031, "train/policy_entropy_min": 0.06468650530181339, "train/policy_entropy_std": 0.145796054122436, "train/policy_logprob_mag": 6.551080243671359, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11166271196687641, "train/policy_logprob_min": -6.551080243671359, "train/policy_logprob_std": 0.6471850018405435, "train/policy_randomness_mag": 0.6826144834259646, "train/policy_randomness_max": 0.6826144834259646, "train/policy_randomness_mean": 0.057593842790504196, "train/policy_randomness_min": 0.03324228856506659, "train/policy_randomness_std": 0.07492435476438485, "train/post_ent_mag": 29.138815194518124, "train/post_ent_max": 29.138815194518124, "train/post_ent_mean": 28.98029275635379, "train/post_ent_min": 28.861535230473656, "train/post_ent_std": 0.054756565141168674, "train/prior_ent_mag": 29.774600484263356, "train/prior_ent_max": 29.774600484263356, "train/prior_ent_mean": 28.407436409188275, "train/prior_ent_min": 27.367439643821523, "train/prior_ent_std": 0.38137278619723103, "train/rep_loss_mean": 1.00000066194103, "train/rep_loss_std": 2.1161570333075434e-05, "train/reward_avg": 0.0014882610108844945, "train/reward_loss_mean": 0.01086723851157006, "train/reward_loss_std": 0.18296033980432505, "train/reward_max_data": 0.6998115565309573, "train/reward_max_pred": 0.23260981413587253, "train/reward_neg_acc": 0.9997491096731407, "train/reward_neg_loss": 0.00193210887715651, "train/reward_pos_acc": 0.22921842822562094, "train/reward_pos_loss": 3.8855561024468876, "train/reward_pred": 0.0011634539822163294, "train/reward_rate": 0.002272102701005025, "train_stats/mean_log_entropy": 0.09320610364278158, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.014470083639025688, "report/cont_loss_std": 0.17901912331581116, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.0342814922332764, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004559332504868507, "report/cont_pred": 0.9938861131668091, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0742904543876648, "report/image_loss_std": 0.08826376497745514, "report/model_loss_mean": 0.7063702344894409, "report/model_loss_std": 0.4402966797351837, "report/post_ent_mag": 29.099628448486328, "report/post_ent_max": 29.099628448486328, "report/post_ent_mean": 28.955543518066406, "report/post_ent_min": 28.843814849853516, "report/post_ent_std": 0.055977996438741684, "report/prior_ent_mag": 29.880382537841797, "report/prior_ent_max": 29.880382537841797, "report/prior_ent_mean": 28.593305587768555, "report/prior_ent_min": 27.50916862487793, "report/prior_ent_std": 0.37504345178604126, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002911376766860485, "report/reward_loss_mean": 0.017609652131795883, "report/reward_loss_std": 0.23164930939674377, "report/reward_max_data": 0.8374999761581421, "report/reward_max_pred": 0.2633817195892334, "report/reward_neg_acc": 0.9990195631980896, "report/reward_neg_loss": 0.0038115044590085745, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.536137580871582, "report/reward_pred": 0.002119516720995307, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.05629318207502365, "eval/cont_loss_std": 0.8118194341659546, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.2781400680542, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00123014603741467, "eval/cont_pred": 0.9987909197807312, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20422112941741943, "eval/image_loss_std": 0.16420896351337433, "eval/model_loss_mean": 0.8807945847511292, "eval/model_loss_std": 1.1652419567108154, "eval/post_ent_mag": 29.10083770751953, "eval/post_ent_max": 29.10083770751953, "eval/post_ent_mean": 28.93610191345215, "eval/post_ent_min": 28.83466339111328, "eval/post_ent_std": 0.051995594054460526, "eval/prior_ent_mag": 29.880382537841797, "eval/prior_ent_max": 29.880382537841797, "eval/prior_ent_mean": 28.48650360107422, "eval/prior_ent_min": 27.442062377929688, "eval/prior_ent_std": 0.41732627153396606, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008758545154705644, "eval/reward_loss_mean": 0.020280251279473305, "eval/reward_loss_std": 0.47391030192375183, "eval/reward_max_data": 0.621874988079071, "eval/reward_max_pred": 0.03215622901916504, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0004328496288508177, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.162302017211914, "eval/reward_pred": 0.00020922557450830936, "eval/reward_rate": 0.001953125, "replay/size": 604465.0, "replay/inserts": 31760.0, "replay/samples": 31760.0, "replay/insert_wait_avg": 1.4293929491595598e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.048495544894817e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2920106962561088e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0071895122528, "timer/env.step_count": 3970.0, "timer/env.step_total": 39.65593862533569, "timer/env.step_frac": 0.039655653520528814, "timer/env.step_avg": 0.009988901416961132, "timer/env.step_min": 0.008071422576904297, "timer/env.step_max": 0.04368472099304199, "timer/replay._sample_count": 31760.0, "timer/replay._sample_total": 17.093042135238647, "timer/replay._sample_frac": 0.017092919245486296, "timer/replay._sample_avg": 0.0005381940218903856, "timer/replay._sample_min": 0.0003902912139892578, "timer/replay._sample_max": 0.011684417724609375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4659.0, "timer/agent.policy_total": 51.66236424446106, "timer/agent.policy_frac": 0.051661992819930676, "timer/agent.policy_avg": 0.011088723812934333, "timer/agent.policy_min": 0.009429931640625, "timer/agent.policy_max": 0.10088014602661133, "timer/dataset_train_count": 1985.0, "timer/dataset_train_total": 0.2334458827972412, "timer/dataset_train_frac": 0.000233444204447273, "timer/dataset_train_avg": 0.00011760497873916433, "timer/dataset_train_min": 0.00010037422180175781, "timer/dataset_train_max": 0.0005137920379638672, "timer/agent.train_count": 1985.0, "timer/agent.train_total": 889.8584425449371, "timer/agent.train_frac": 0.8898520449427568, "timer/agent.train_avg": 0.44829140682364593, "timer/agent.train_min": 0.4353063106536865, "timer/agent.train_max": 0.7183198928833008, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4828493595123291, "timer/agent.report_frac": 0.0004828458880859005, "timer/agent.report_avg": 0.24142467975616455, "timer/agent.report_min": 0.23272109031677246, "timer/agent.report_max": 0.25012826919555664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.647804260253906e-05, "timer/dataset_eval_frac": 3.6477780345090315e-08, "timer/dataset_eval_avg": 3.647804260253906e-05, "timer/dataset_eval_min": 3.647804260253906e-05, "timer/dataset_eval_max": 3.647804260253906e-05, "fps": 31.759232025959548}
{"step": 605160, "time": 19251.52785372734, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 605456, "time": 19260.947926044464, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 605600, "time": 19265.40532517433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605704, "time": 19268.43325471878, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 605768, "time": 19270.451655864716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605784, "time": 19270.957129478455, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 605976, "time": 19278.384098529816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605992, "time": 19278.87752699852, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 606360, "time": 19290.791222572327, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 606360, "time": 19290.79942035675, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 606376, "time": 19291.294043779373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606608, "time": 19298.667473316193, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 606824, "time": 19305.0761384964, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 606888, "time": 19307.041295289993, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 606936, "time": 19308.508647680283, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 607064, "time": 19312.420163869858, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 607240, "time": 19317.797027111053, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 607472, "time": 19325.246618509293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607488, "time": 19325.74529862404, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 607688, "time": 19331.66959142685, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 607736, "time": 19333.139365911484, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 607808, "time": 19335.59209871292, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 607872, "time": 19337.532756567, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 608312, "time": 19350.799503326416, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 608328, "time": 19351.295092582703, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 608392, "time": 19353.259950876236, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 608432, "time": 19354.760070562363, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 608592, "time": 19359.662543296814, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 608688, "time": 19362.59599351883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608832, "time": 19366.999854326248, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 608840, "time": 19367.029520988464, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 609080, "time": 19374.427402973175, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 609184, "time": 19377.81446480751, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 609952, "time": 19401.410782575607, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 610008, "time": 19402.902916908264, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 19404.865014076233, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 19405.69354557991, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 610064, "time": 19406.04821038246, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 610064, "time": 19406.198663711548, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 610064, "time": 19406.773329257965, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 610064, "time": 19407.71898818016, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 610064, "time": 19407.752272844315, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 610064, "time": 19407.930788517, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 610064, "time": 19408.939985752106, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 610120, "time": 19410.435629606247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610640, "time": 19426.521321296692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610672, "time": 19427.516344070435, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 610744, "time": 19429.479432821274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610904, "time": 19434.36323404312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610968, "time": 19436.308696985245, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 611024, "time": 19438.252180337906, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 611024, "time": 19438.262217760086, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 611136, "time": 19441.803253650665, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 611224, "time": 19444.297082185745, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 611352, "time": 19448.22855949402, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 611464, "time": 19451.637035369873, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 611528, "time": 19453.609853982925, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 611880, "time": 19464.345308303833, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 612072, "time": 19470.300563812256, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 612112, "time": 19471.75551891327, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 612376, "time": 19479.587109327316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612504, "time": 19483.584141492844, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 612696, "time": 19489.545253515244, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 612720, "time": 19490.507466316223, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 612840, "time": 19493.968131542206, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 612896, "time": 19495.900853157043, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 612984, "time": 19498.42743897438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613096, "time": 19501.898243188858, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 613536, "time": 19515.57260298729, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 613536, "time": 19515.581465244293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613720, "time": 19521.032522201538, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 613760, "time": 19522.47832250595, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 613808, "time": 19523.948751688004, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 614064, "time": 19531.880651950836, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 614192, "time": 19535.827914237976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614400, "time": 19542.354038238525, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 614456, "time": 19544.21975493431, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 614616, "time": 19549.125158071518, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 614656, "time": 19550.566997289658, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 614712, "time": 19552.101816892624, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 614824, "time": 19555.58096218109, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 615008, "time": 19561.566542863846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 615320, "time": 19570.912139177322, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 615408, "time": 19573.810761213303, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 615480, "time": 19575.819286108017, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 615600, "time": 19579.710551977158, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 615848, "time": 19587.083884716034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 615976, "time": 19591.12570667267, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 616008, "time": 19592.10201072693, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 616232, "time": 19598.936796426773, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 616280, "time": 19600.421711444855, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 616376, "time": 19603.352053165436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 616488, "time": 19606.767287492752, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 616712, "time": 19613.610536813736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617048, "time": 19623.94174671173, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 617352, "time": 19633.222816467285, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 617632, "time": 19642.022899389267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617720, "time": 19644.520889282227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617976, "time": 19652.475867033005, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 618088, "time": 19655.944773197174, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 618128, "time": 19657.382319688797, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 618288, "time": 19662.271489858627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618648, "time": 19673.042736291885, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 618688, "time": 19674.518690109253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618816, "time": 19678.522309541702, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 619128, "time": 19687.923580169678, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 619360, "time": 19695.252986192703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619488, "time": 19699.174560070038, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 619664, "time": 19704.594076871872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620024, "time": 19715.48759150505, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 19717.378678560257, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 620048, "time": 19717.604922771454, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 620048, "time": 19717.860926628113, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 620048, "time": 19718.076232910156, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 620048, "time": 19718.166922807693, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 620048, "time": 19718.419221401215, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 620048, "time": 19718.50821709633, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 620048, "time": 19719.314262628555, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 620144, "time": 19722.25876545906, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 620344, "time": 19728.182092905045, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 620440, "time": 19731.12507033348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620568, "time": 19735.021524190903, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 620864, "time": 19744.393403053284, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 620960, "time": 19747.349358797073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621000, "time": 19748.3582303524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621016, "time": 19748.852829694748, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 621360, "time": 19759.59870839119, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 621440, "time": 19762.066194057465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621552, "time": 19765.51464152336, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 621640, "time": 19767.985055446625, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 621688, "time": 19769.5363008976, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 621864, "time": 19774.908286333084, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 621928, "time": 19776.884745121002, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 622312, "time": 19788.63736653328, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 622336, "time": 19789.595023870468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622360, "time": 19790.128612279892, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 622496, "time": 19794.491064071655, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 622544, "time": 19795.990118026733, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 622696, "time": 19800.989694833755, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 622880, "time": 19806.831694841385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623064, "time": 19812.20755314827, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 623176, "time": 19815.643222808838, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 623232, "time": 19817.573077201843, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 623408, "time": 19822.94598007202, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 623448, "time": 19823.948498487473, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 623752, "time": 19833.3230407238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623960, "time": 19839.69878411293, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 624144, "time": 19845.503949165344, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 624176, "time": 19846.483600139618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624392, "time": 19852.885616779327, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 624536, "time": 19857.894251585007, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 624704, "time": 19863.48975610733, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 624840, "time": 19867.49075961113, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 624856, "time": 19867.987372159958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625192, "time": 19878.29046869278, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 625200, "time": 19878.761338233948, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 625272, "time": 19880.76150393486, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 625432, "time": 19885.663338661194, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 625640, "time": 19892.19458913803, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 625696, "time": 19894.132086277008, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 625720, "time": 19894.666615009308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626064, "time": 19905.38525414467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626120, "time": 19906.869483947754, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 626336, "time": 19913.687569618225, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 626848, "time": 19929.510854959488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626888, "time": 19930.517649888992, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 627432, "time": 19947.124041557312, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 627512, "time": 19949.737649679184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627656, "time": 19954.156370401382, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 627744, "time": 19957.05691432953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627976, "time": 19963.93202161789, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 628032, "time": 19965.86754012108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628216, "time": 19971.2507686615, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 628224, "time": 19971.7229013443, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 628376, "time": 19976.132472515106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628504, "time": 19980.212928295135, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 628736, "time": 19987.58132481575, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 628832, "time": 19990.549046993256, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 628960, "time": 19994.466973543167, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 628984, "time": 19997.479388237, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 629200, "time": 20004.325122594833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629368, "time": 20009.340549707413, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 629456, "time": 20012.26452755928, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 629752, "time": 20021.065353155136, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 629792, "time": 20022.511956214905, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 20031.87126350403, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 630032, "time": 20032.215295553207, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 630032, "time": 20032.40905880928, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 630032, "time": 20032.625595331192, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 630032, "time": 20033.555862426758, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 630032, "time": 20033.88299059868, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 630032, "time": 20034.2256128788, "eval_episode/length": 184.0, "eval_episode/score": 0.42500001192092896, "eval_episode/reward_rate": 0.005405405405405406}
{"step": 630032, "time": 20034.579389572144, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 630032, "time": 20034.586777448654, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 630064, "time": 20035.568572998047, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 630136, "time": 20037.542596817017, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 630344, "time": 20044.02850294113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630400, "time": 20046.004567861557, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 630720, "time": 20055.800844669342, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 631048, "time": 20066.19328570366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631096, "time": 20067.667598962784, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 631144, "time": 20069.271625757217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631208, "time": 20071.254397392273, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 631232, "time": 20072.214072942734, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 631296, "time": 20074.170486211777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631560, "time": 20082.035355091095, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 631560, "time": 20082.045566797256, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 631792, "time": 20089.351024389267, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 631976, "time": 20094.74102783203, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 632064, "time": 20097.650831460953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632104, "time": 20099.77069425583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632192, "time": 20102.702756404877, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 632296, "time": 20105.673669815063, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 632464, "time": 20111.042852401733, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 633136, "time": 20131.691156864166, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 633160, "time": 20132.206954717636, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 633184, "time": 20133.15874004364, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 633544, "time": 20143.924907445908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 633608, "time": 20145.901787757874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 633680, "time": 20148.316004514694, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 633824, "time": 20152.710206985474, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 633936, "time": 20156.184802532196, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 634104, "time": 20161.232608556747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634288, "time": 20167.082617759705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634352, "time": 20169.095743894577, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 634368, "time": 20169.594400644302, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 634448, "time": 20172.02390217781, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 634800, "time": 20182.753059864044, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 634880, "time": 20185.2116894722, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 634936, "time": 20186.69082593918, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 635000, "time": 20188.791558742523, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 635224, "time": 20195.591086626053, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 635320, "time": 20198.55622458458, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 635416, "time": 20201.48917078972, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 635496, "time": 20203.96977210045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635728, "time": 20211.321039676666, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 635936, "time": 20217.706897735596, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 636232, "time": 20226.691668510437, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 636248, "time": 20227.190989017487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636592, "time": 20237.973821640015, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 636600, "time": 20238.00722360611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636833, "time": 20245.882051229477, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.331445128474403, "train/action_min": 0.0, "train/action_std": 1.7521876168610462, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01364171264655701, "train/actor_opt_grad_steps": 38710.0, "train/actor_opt_loss": -10.45648244757149, "train/adv_mag": 1.008973124039233, "train/adv_max": 0.2838464496123731, "train/adv_mean": 0.0020288038570621053, "train/adv_min": -0.9778251168715894, "train/adv_std": 0.035958899142941335, "train/cont_avg": 0.9950484846105527, "train/cont_loss_mean": 0.015155277577060363, "train/cont_loss_std": 0.21552848815449968, "train/cont_neg_acc": 0.4025533180495705, "train/cont_neg_loss": 2.39896757706366, "train/cont_pos_acc": 0.9998372418796597, "train/cont_pos_loss": 0.0032420849706041605, "train/cont_pred": 0.9950283313516396, "train/cont_rate": 0.9950484846105527, "train/dyn_loss_mean": 1.000001966054715, "train/dyn_loss_std": 6.289515163440576e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2523559406586927, "train/extr_critic_critic_opt_grad_steps": 38710.0, "train/extr_critic_critic_opt_loss": 12695.838258676193, "train/extr_critic_mag": 1.4158174787933504, "train/extr_critic_max": 1.4158174787933504, "train/extr_critic_mean": 1.3290226381627759, "train/extr_critic_min": 1.2510528456625627, "train/extr_critic_std": 0.020904420524011903, "train/extr_return_normed_mag": 1.0042126508214366, "train/extr_return_normed_max": 0.3453430680174324, "train/extr_return_normed_mean": 0.043138618398476485, "train/extr_return_normed_min": -0.9476066228732392, "train/extr_return_normed_std": 0.04279926986475686, "train/extr_return_rate": 0.9992750619524088, "train/extr_return_raw_mag": 1.6332558309612561, "train/extr_return_raw_max": 1.6332558309612561, "train/extr_return_raw_mean": 1.3310514472836825, "train/extr_return_raw_min": 0.3403061400705846, "train/extr_return_raw_std": 0.04279927001451727, "train/extr_reward_mag": 0.33973317170262934, "train/extr_reward_max": 0.33973317170262934, "train/extr_reward_mean": 0.002373310361740802, "train/extr_reward_min": 6.888979044391881e-08, "train/extr_reward_std": 0.010806553740868691, "train/image_loss_mean": 0.0840676900317621, "train/image_loss_std": 0.09720109470525579, "train/model_loss_mean": 0.7105953756289266, "train/model_loss_std": 0.40334055872269015, "train/model_opt_grad_norm": 24.14128107521402, "train/model_opt_grad_steps": 38677.29145728643, "train/model_opt_loss": 2660.1682429481393, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3743.718592964824, "train/policy_entropy_mag": 1.3067709081736043, "train/policy_entropy_max": 1.3067709081736043, "train/policy_entropy_mean": 0.11083953573026849, "train/policy_entropy_min": 0.06468649231009747, "train/policy_entropy_std": 0.1431615637924204, "train/policy_logprob_mag": 6.551080246067526, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1109523352740997, "train/policy_logprob_min": -6.551080246067526, "train/policy_logprob_std": 0.6479396502576281, "train/policy_randomness_mag": 0.6715474401287098, "train/policy_randomness_max": 0.6715474401287098, "train/policy_randomness_mean": 0.056960256386492124, "train/policy_randomness_min": 0.033242281638647446, "train/policy_randomness_std": 0.07357049435751523, "train/post_ent_mag": 29.025558423756355, "train/post_ent_max": 29.025558423756355, "train/post_ent_mean": 28.864624148038164, "train/post_ent_min": 28.738356844264658, "train/post_ent_std": 0.05700693545329511, "train/prior_ent_mag": 29.739848927636842, "train/prior_ent_max": 29.739848927636842, "train/prior_ent_mean": 28.37678388854367, "train/prior_ent_min": 27.197302746413342, "train/prior_ent_std": 0.40745373991266565, "train/rep_loss_mean": 1.000001966054715, "train/rep_loss_std": 6.289515163440576e-05, "train/reward_avg": 0.001533454629442252, "train/reward_loss_mean": 0.01137120512796182, "train/reward_loss_std": 0.18798248171712736, "train/reward_max_data": 0.6743090427550839, "train/reward_max_pred": 0.23356944951579797, "train/reward_neg_acc": 0.9996901163503752, "train/reward_neg_loss": 0.0020149286485969756, "train/reward_pos_acc": 0.21717408470443036, "train/reward_pos_loss": 3.91865546292946, "train/reward_pred": 0.0012159924989276047, "train/reward_rate": 0.0023751570351758793, "train_stats/mean_log_entropy": 0.09672363140378837, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.021411336958408356, "report/cont_loss_std": 0.2760735750198364, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.897742748260498, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0044585042633116245, "report/cont_pred": 0.9939357042312622, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09198981523513794, "report/image_loss_std": 0.10234444588422775, "report/model_loss_mean": 0.7269265651702881, "report/model_loss_std": 0.44237226247787476, "report/post_ent_mag": 28.601011276245117, "report/post_ent_max": 28.601011276245117, "report/post_ent_mean": 28.434402465820312, "report/post_ent_min": 28.304899215698242, "report/post_ent_std": 0.06488672643899918, "report/prior_ent_mag": 29.781293869018555, "report/prior_ent_max": 29.781293869018555, "report/prior_ent_mean": 28.511384963989258, "report/prior_ent_min": 27.286428451538086, "report/prior_ent_std": 0.4123929440975189, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001690673758275807, "report/reward_loss_mean": 0.013525434769690037, "report/reward_loss_std": 0.20591263473033905, "report/reward_max_data": 0.7124999761581421, "report/reward_max_pred": 0.46451544761657715, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0035292929969727993, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.41554594039917, "report/reward_pred": 0.002205965109169483, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.05796413868665695, "eval/cont_loss_std": 0.7474979162216187, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.40217399597168, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002890208503231406, "eval/cont_pred": 0.9973800182342529, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19511821866035461, "eval/image_loss_std": 0.16066142916679382, "eval/model_loss_mean": 0.8574472665786743, "eval/model_loss_std": 0.7688937187194824, "eval/post_ent_mag": 28.597576141357422, "eval/post_ent_max": 28.597576141357422, "eval/post_ent_mean": 28.41796112060547, "eval/post_ent_min": 28.303302764892578, "eval/post_ent_std": 0.059274446219205856, "eval/prior_ent_mag": 29.819272994995117, "eval/prior_ent_max": 29.819272994995117, "eval/prior_ent_mean": 28.38125228881836, "eval/prior_ent_min": 27.0377254486084, "eval/prior_ent_std": 0.4545636475086212, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.004364878870546818, "eval/reward_loss_std": 0.08121771365404129, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.6086784601211548, "eval/reward_neg_acc": 0.9970703125, "eval/reward_neg_loss": 0.004364878870546818, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0014754545409232378, "eval/reward_rate": 0.0, "replay/size": 636329.0, "replay/inserts": 31864.0, "replay/samples": 31856.0, "replay/insert_wait_avg": 1.4347539844747587e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.174205621003745e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4144.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3202198683985412e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4007091522216797e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.007734298706, "timer/env.step_count": 3983.0, "timer/env.step_total": 39.94366478919983, "timer/env.step_frac": 0.03994335585535432, "timer/env.step_avg": 0.010028537481596744, "timer/env.step_min": 0.0077571868896484375, "timer/env.step_max": 0.03537249565124512, "timer/replay._sample_count": 31856.0, "timer/replay._sample_total": 17.161543130874634, "timer/replay._sample_frac": 0.017161410399400386, "timer/replay._sample_avg": 0.0005387224739727095, "timer/replay._sample_min": 0.0003762245178222656, "timer/replay._sample_max": 0.03341794013977051, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4501.0, "timer/agent.policy_total": 50.14661455154419, "timer/agent.policy_frac": 0.05014622670564787, "timer/agent.policy_avg": 0.01114121629672166, "timer/agent.policy_min": 0.009286880493164062, "timer/agent.policy_max": 0.09090495109558105, "timer/dataset_train_count": 1991.0, "timer/dataset_train_total": 0.23521184921264648, "timer/dataset_train_frac": 0.00023521003002801558, "timer/dataset_train_avg": 0.00011813754355230863, "timer/dataset_train_min": 0.00010180473327636719, "timer/dataset_train_max": 0.0011131763458251953, "timer/agent.train_count": 1991.0, "timer/agent.train_total": 892.3177931308746, "timer/agent.train_frac": 0.8923108917318993, "timer/agent.train_avg": 0.4481756871576467, "timer/agent.train_min": 0.437441349029541, "timer/agent.train_max": 0.7233896255493164, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48041605949401855, "timer/agent.report_frac": 0.00048041234384144923, "timer/agent.report_avg": 0.24020802974700928, "timer/agent.report_min": 0.23319149017333984, "timer/agent.report_max": 0.2472245693206787, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.221366882324219e-05, "timer/dataset_eval_frac": 5.221326499025434e-08, "timer/dataset_eval_avg": 5.221366882324219e-05, "timer/dataset_eval_min": 5.221366882324219e-05, "timer/dataset_eval_max": 5.221366882324219e-05, "fps": 31.863155558432204}
{"step": 637112, "time": 20254.644644260406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637160, "time": 20256.11793589592, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 637168, "time": 20256.594672203064, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 637464, "time": 20265.48183774948, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 637632, "time": 20272.55471611023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637728, "time": 20275.501995563507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637912, "time": 20281.01157283783, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 638016, "time": 20284.413759231567, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 638200, "time": 20289.851719856262, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 638288, "time": 20292.760008573532, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 638520, "time": 20299.644551753998, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 638840, "time": 20309.565443515778, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 638904, "time": 20311.522002458572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 638912, "time": 20311.998652935028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639160, "time": 20319.854981660843, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 639216, "time": 20321.779588460922, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 639480, "time": 20329.652820825577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639696, "time": 20336.49314713478, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 639944, "time": 20343.986385583878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 20347.655844926834, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 640016, "time": 20347.909425973892, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 640016, "time": 20348.001263141632, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 640016, "time": 20348.60253882408, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 640016, "time": 20348.649307012558, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 640016, "time": 20348.656111478806, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 640016, "time": 20349.22678232193, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 640016, "time": 20349.34357190132, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 640224, "time": 20355.73093366623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640264, "time": 20356.73394703865, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 640296, "time": 20357.739423036575, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 640536, "time": 20365.060224056244, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 640576, "time": 20366.51287841797, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 640600, "time": 20367.05489230156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640912, "time": 20376.94781780243, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 641128, "time": 20383.30451989174, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 641208, "time": 20385.749126195908, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 641216, "time": 20386.229079723358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641224, "time": 20386.260412931442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641232, "time": 20386.75358390808, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 641232, "time": 20386.760995864868, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 641568, "time": 20397.00475502014, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 641848, "time": 20405.43204140663, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 642280, "time": 20418.684331178665, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 642776, "time": 20433.97065591812, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 642912, "time": 20438.36354446411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643224, "time": 20447.64794278145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643440, "time": 20454.457318782806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643544, "time": 20457.438163518906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643544, "time": 20457.44678092003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643688, "time": 20461.955746650696, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 643736, "time": 20463.450899362564, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 643776, "time": 20464.89969754219, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 643880, "time": 20467.88161921501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644104, "time": 20474.702561855316, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 644144, "time": 20476.18305683136, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 644176, "time": 20477.168841838837, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 644592, "time": 20490.030988931656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644656, "time": 20491.98666191101, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 644792, "time": 20495.93785595894, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 645008, "time": 20502.727553606033, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 645528, "time": 20518.26714873314, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 645752, "time": 20525.20153570175, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 645856, "time": 20528.56903553009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645856, "time": 20528.578085184097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646288, "time": 20541.757791519165, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 646296, "time": 20541.786679267883, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 646416, "time": 20545.69636940956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646456, "time": 20546.697370529175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646480, "time": 20547.650920152664, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 646488, "time": 20547.681129217148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646704, "time": 20554.64663386345, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 646840, "time": 20558.625514268875, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 646896, "time": 20560.56260228157, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 647024, "time": 20564.493186235428, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 647352, "time": 20574.886094093323, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 647368, "time": 20575.385880231857, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 647544, "time": 20580.893659830093, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 647736, "time": 20586.76804304123, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 647840, "time": 20590.197166204453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648040, "time": 20596.06873846054, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 648040, "time": 20596.076577425003, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 648160, "time": 20599.9787709713, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 648288, "time": 20603.924738883972, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 648608, "time": 20613.84663915634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648680, "time": 20615.820409059525, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 648776, "time": 20618.78260421753, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 648816, "time": 20620.227623939514, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 648872, "time": 20621.698912143707, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 648960, "time": 20624.619138002396, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 649016, "time": 20626.105031251907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 649040, "time": 20627.062022686005, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 649064, "time": 20627.573160648346, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 649192, "time": 20631.487847566605, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 649400, "time": 20637.863475084305, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 649528, "time": 20641.872819662094, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 649592, "time": 20643.855219125748, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 649608, "time": 20644.355827093124, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 20657.4121966362, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 650000, "time": 20657.766155958176, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 650000, "time": 20657.821145296097, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 650000, "time": 20659.0096077919, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 650000, "time": 20659.382863998413, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 650000, "time": 20659.888484954834, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 650000, "time": 20660.625816822052, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 650000, "time": 20662.092210292816, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 650024, "time": 20662.615594148636, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 650104, "time": 20665.086567163467, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 650232, "time": 20669.119379281998, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 650408, "time": 20674.513704776764, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 650712, "time": 20683.82373046875, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 650808, "time": 20686.751611948013, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 650824, "time": 20687.242322206497, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 650968, "time": 20691.658259153366, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 651128, "time": 20696.561978816986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651184, "time": 20698.652345895767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651296, "time": 20702.066125392914, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 651352, "time": 20703.57174396515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651416, "time": 20705.533002614975, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 651488, "time": 20707.957402944565, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 651528, "time": 20708.954643011093, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 651624, "time": 20711.867675304413, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 651920, "time": 20721.150847911835, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 652264, "time": 20731.549748897552, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 652360, "time": 20734.494032859802, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 652416, "time": 20736.427195072174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652696, "time": 20744.729077100754, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 652904, "time": 20751.088431358337, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 653168, "time": 20759.470928668976, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 653280, "time": 20762.909592866898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653496, "time": 20769.294206380844, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 653512, "time": 20769.783910036087, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 653584, "time": 20772.20781636238, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 653664, "time": 20774.638820171356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653800, "time": 20778.585191726685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653840, "time": 20780.030054330826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653952, "time": 20783.460990428925, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 654120, "time": 20788.410229682922, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 654432, "time": 20798.235186338425, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 654552, "time": 20801.671523094177, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 654576, "time": 20802.630427837372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654744, "time": 20807.53980064392, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 654760, "time": 20808.036776542664, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 654776, "time": 20808.538019895554, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 654864, "time": 20811.46794629097, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 654984, "time": 20814.935511112213, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 655232, "time": 20822.89350605011, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 655288, "time": 20824.383473157883, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 655480, "time": 20830.86745238304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655720, "time": 20838.197781324387, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 655824, "time": 20841.625247001648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655976, "time": 20846.090883255005, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 656056, "time": 20848.63724565506, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 656184, "time": 20852.57308769226, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 656312, "time": 20856.502790927887, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 657024, "time": 20878.457775115967, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 657056, "time": 20879.480714797974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 657072, "time": 20879.99411201477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 657080, "time": 20880.02249932289, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 657264, "time": 20885.851870536804, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 657552, "time": 20894.66263484955, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 657576, "time": 20895.18038368225, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 657632, "time": 20897.117069482803, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 657792, "time": 20902.03106689453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 657880, "time": 20904.5133728981, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 658032, "time": 20909.47683572769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658072, "time": 20910.473976135254, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 658088, "time": 20910.96498823166, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 658136, "time": 20912.436171770096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658616, "time": 20927.08979701996, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 658720, "time": 20930.50153183937, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 658736, "time": 20930.993084192276, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 658792, "time": 20932.48489165306, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 659080, "time": 20941.469128608704, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 659120, "time": 20942.918372154236, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 659160, "time": 20943.957107782364, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 659176, "time": 20944.456323862076, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 659400, "time": 20951.284284830093, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 659528, "time": 20955.202574253082, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 659664, "time": 20959.599040985107, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 659864, "time": 20965.523000240326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659944, "time": 20967.99985218048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660048, "time": 20971.51092839241, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 20973.11920285225, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 660088, "time": 20973.681217193604, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 660088, "time": 20973.976487636566, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 660088, "time": 20974.066514968872, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 660088, "time": 20974.520157814026, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 660088, "time": 20974.891130924225, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 660088, "time": 20975.23704624176, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 660088, "time": 20975.666791439056, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 660096, "time": 20976.13566660881, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 660112, "time": 20976.6496489048, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 660184, "time": 20978.62223958969, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 660280, "time": 20981.57273197174, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 660448, "time": 20986.927164316177, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 660600, "time": 20991.336619853973, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 660632, "time": 20992.311581850052, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 661144, "time": 21008.096496343613, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 661432, "time": 21016.897879600525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 661488, "time": 21018.851306200027, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 661496, "time": 21018.880521059036, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 661792, "time": 21029.9607026577, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 661952, "time": 21034.871608257294, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 661960, "time": 21034.90115046501, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 661976, "time": 21035.3970143795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662240, "time": 21043.708322048187, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 662360, "time": 21047.1468064785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662368, "time": 21047.617540359497, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 662592, "time": 21054.479840278625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662656, "time": 21056.4355840683, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 662760, "time": 21059.48584842682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662896, "time": 21063.880610466003, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 663328, "time": 21077.0952398777, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 663424, "time": 21080.032872200012, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 663432, "time": 21080.062676906586, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 663640, "time": 21086.954840183258, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 663728, "time": 21089.955466747284, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 663744, "time": 21090.45880508423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663936, "time": 21096.330699443817, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 664552, "time": 21114.915503025055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664664, "time": 21118.39888525009, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 664680, "time": 21118.945907115936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664872, "time": 21124.776971817017, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 664896, "time": 21125.743902921677, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 664904, "time": 21125.773909807205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664984, "time": 21128.252455234528, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 665200, "time": 21135.088963985443, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 665504, "time": 21144.34108400345, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 665528, "time": 21144.850990772247, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 665528, "time": 21144.858231306076, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 665672, "time": 21149.346470594406, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 665888, "time": 21156.205276489258, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 666000, "time": 21159.619139909744, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 666008, "time": 21159.647594690323, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 666120, "time": 21163.071336746216, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 666864, "time": 21186.05773615837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666912, "time": 21187.521659612656, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 666992, "time": 21189.981887578964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667208, "time": 21196.33486843109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667240, "time": 21197.303556919098, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 667272, "time": 21198.27829670906, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 667392, "time": 21202.135519742966, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 667680, "time": 21210.989262104034, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 667696, "time": 21211.477745771408, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 667840, "time": 21215.873994350433, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 667896, "time": 21217.36329627037, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 667984, "time": 21220.295914888382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668200, "time": 21226.67289185524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668312, "time": 21230.09067583084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668624, "time": 21239.91120481491, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 668632, "time": 21239.940930843353, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 668809, "time": 21246.288422346115, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1817572021484377, "train/action_min": 0.0, "train/action_std": 1.638127173781395, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012251600354211405, "train/actor_opt_grad_steps": 40705.0, "train/actor_opt_loss": -12.035054869651795, "train/adv_mag": 0.9889215031266212, "train/adv_max": 0.2790161496400833, "train/adv_mean": 0.00034886016946984456, "train/adv_min": -0.9476708355545997, "train/adv_std": 0.03375558353494853, "train/cont_avg": 0.9951611328125, "train/cont_loss_mean": 0.014974500153912232, "train/cont_loss_std": 0.21469015675829722, "train/cont_neg_acc": 0.38640675336122515, "train/cont_neg_loss": 2.442605541861849, "train/cont_pos_acc": 0.9998919558525086, "train/cont_pos_loss": 0.003219931471394375, "train/cont_pred": 0.9950413966178894, "train/cont_rate": 0.9951611328125, "train/dyn_loss_mean": 1.0000006031990052, "train/dyn_loss_std": 1.9304018642287702e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2010596012463793, "train/extr_critic_critic_opt_grad_steps": 40705.0, "train/extr_critic_critic_opt_loss": 13471.232612304688, "train/extr_critic_mag": 1.474041335582733, "train/extr_critic_max": 1.474041335582733, "train/extr_critic_mean": 1.3717281013727187, "train/extr_critic_min": 1.2829599481821061, "train/extr_critic_std": 0.019786139521747827, "train/extr_return_normed_mag": 0.99028981924057, "train/extr_return_normed_max": 0.34210842311382295, "train/extr_return_normed_mean": 0.03703838639426976, "train/extr_return_normed_min": -0.916154083609581, "train/extr_return_normed_std": 0.04011627492494881, "train/extr_return_rate": 0.9995309594273567, "train/extr_return_raw_mag": 1.6771465808153152, "train/extr_return_raw_max": 1.6771465808153152, "train/extr_return_raw_mean": 1.3720766150951385, "train/extr_return_raw_min": 0.4188840740919113, "train/extr_return_raw_std": 0.04011627503670752, "train/extr_reward_mag": 0.36383095383644104, "train/extr_reward_max": 0.36383095383644104, "train/extr_reward_mean": 0.0023469780225423165, "train/extr_reward_min": 3.516674041748047e-08, "train/extr_reward_std": 0.01132609108230099, "train/image_loss_mean": 0.0819629131257534, "train/image_loss_std": 0.09658405710011721, "train/model_loss_mean": 0.7089115083217621, "train/model_loss_std": 0.41520386673510074, "train/model_opt_grad_norm": 22.924099974632263, "train/model_opt_grad_steps": 40671.225, "train/model_opt_loss": 2659.6654461669923, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3750.0, "train/policy_entropy_mag": 1.2948260223865509, "train/policy_entropy_max": 1.2948260223865509, "train/policy_entropy_mean": 0.10249105367809534, "train/policy_entropy_min": 0.06468649353832007, "train/policy_entropy_std": 0.1307283204048872, "train/policy_logprob_mag": 6.551080236434936, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10196083713322877, "train/policy_logprob_min": -6.551080236434936, "train/policy_logprob_std": 0.6374016216397286, "train/policy_randomness_mag": 0.6654089865088463, "train/policy_randomness_max": 0.6654089865088463, "train/policy_randomness_mean": 0.05266998492181301, "train/policy_randomness_min": 0.03324228225275874, "train/policy_randomness_std": 0.06718107119202614, "train/post_ent_mag": 29.040674295425415, "train/post_ent_max": 29.040674295425415, "train/post_ent_mean": 28.876968908309937, "train/post_ent_min": 28.749920310974122, "train/post_ent_std": 0.05900622248649597, "train/prior_ent_mag": 29.75389147758484, "train/prior_ent_max": 29.75389147758484, "train/prior_ent_mean": 28.30199080467224, "train/prior_ent_min": 27.16225098609924, "train/prior_ent_std": 0.4057519419491291, "train/rep_loss_mean": 1.0000006031990052, "train/rep_loss_std": 1.9304018642287702e-05, "train/reward_avg": 0.001607391358775203, "train/reward_loss_mean": 0.011973711387254298, "train/reward_loss_std": 0.19881751216365956, "train/reward_max_data": 0.7205156249552965, "train/reward_max_pred": 0.25927338242530823, "train/reward_neg_acc": 0.9997062861919404, "train/reward_neg_loss": 0.002091818011831492, "train/reward_pos_acc": 0.21878307095911137, "train/reward_pos_loss": 4.009479718548911, "train/reward_pred": 0.0012935624353121967, "train/reward_rate": 0.002451171875, "train_stats/mean_log_entropy": 0.08614094040073488, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.024207446724176407, "report/cont_loss_std": 0.31851306557655334, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 3.7498879432678223, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002248625736683607, "report/cont_pred": 0.9967527389526367, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07072420418262482, "report/image_loss_std": 0.08987893164157867, "report/model_loss_mean": 0.70627760887146, "report/model_loss_std": 0.5045854449272156, "report/post_ent_mag": 28.994094848632812, "report/post_ent_max": 28.994094848632812, "report/post_ent_mean": 28.829158782958984, "report/post_ent_min": 28.679393768310547, "report/post_ent_std": 0.059054452925920486, "report/prior_ent_mag": 29.741878509521484, "report/prior_ent_max": 29.741878509521484, "report/prior_ent_mean": 28.198925018310547, "report/prior_ent_min": 27.26239585876465, "report/prior_ent_std": 0.42327260971069336, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0012969970703125, "report/reward_loss_mean": 0.0113458801060915, "report/reward_loss_std": 0.21891091763973236, "report/reward_max_data": 0.715624988079071, "report/reward_max_pred": 0.03231918811798096, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0016685203881934285, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.95647668838501, "report/reward_pred": 0.0008649645606055856, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.032464418560266495, "eval/cont_loss_std": 0.5472244620323181, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.833677291870117, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.003665557596832514, "eval/cont_pred": 0.9975576996803284, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1625022292137146, "eval/image_loss_std": 0.14632479846477509, "eval/model_loss_mean": 0.7968671321868896, "eval/model_loss_std": 0.580027163028717, "eval/post_ent_mag": 28.993831634521484, "eval/post_ent_max": 28.993831634521484, "eval/post_ent_mean": 28.811687469482422, "eval/post_ent_min": 28.68880844116211, "eval/post_ent_std": 0.05591179430484772, "eval/prior_ent_mag": 29.741878509521484, "eval/prior_ent_max": 29.741878509521484, "eval/prior_ent_mean": 28.147972106933594, "eval/prior_ent_min": 27.114307403564453, "eval/prior_ent_std": 0.4069172739982605, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001900465227663517, "eval/reward_loss_std": 0.03975650295615196, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.3731600046157837, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.001900465227663517, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0006912092212587595, "eval/reward_rate": 0.0, "replay/size": 668305.0, "replay/inserts": 31976.0, "replay/samples": 31984.0, "replay/insert_wait_avg": 1.4327259579091362e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.822471395380918e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4392.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.266245850665539e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3928551673889, "timer/env.step_count": 3997.0, "timer/env.step_total": 40.44645929336548, "timer/env.step_frac": 0.04043057593268981, "timer/env.step_avg": 0.010119204226511254, "timer/env.step_min": 0.008271217346191406, "timer/env.step_max": 0.049527883529663086, "timer/replay._sample_count": 31984.0, "timer/replay._sample_total": 16.625322103500366, "timer/replay._sample_frac": 0.016618793324667, "timer/replay._sample_avg": 0.0005198012163425578, "timer/replay._sample_min": 0.0003752708435058594, "timer/replay._sample_max": 0.025790691375732422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4546.0, "timer/agent.policy_total": 50.142919301986694, "timer/agent.policy_frac": 0.050123228132808506, "timer/agent.policy_avg": 0.011030118632201208, "timer/agent.policy_min": 0.009299516677856445, "timer/agent.policy_max": 0.08293294906616211, "timer/dataset_train_count": 1999.0, "timer/dataset_train_total": 0.23307013511657715, "timer/dataset_train_frac": 0.0002329786082664286, "timer/dataset_train_avg": 0.00011659336424040878, "timer/dataset_train_min": 9.989738464355469e-05, "timer/dataset_train_max": 0.00040721893310546875, "timer/agent.train_count": 1999.0, "timer/agent.train_total": 895.9877564907074, "timer/agent.train_frac": 0.8956359012987831, "timer/agent.train_avg": 0.44821798723897316, "timer/agent.train_min": 0.4348335266113281, "timer/agent.train_max": 2.1423919200897217, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4797971248626709, "timer/agent.report_frac": 0.0004796087081033678, "timer/agent.report_avg": 0.23989856243133545, "timer/agent.report_min": 0.23372912406921387, "timer/agent.report_max": 0.24606800079345703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.384214317160139e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 31.962909599542556}
{"step": 669392, "time": 21264.06272006035, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 669504, "time": 21267.454299926758, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 669552, "time": 21269.01589369774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669568, "time": 21269.556690454483, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 669664, "time": 21272.481441497803, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 669856, "time": 21278.34236264229, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 21284.699987649918, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 21286.001856565475, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 670072, "time": 21286.355756759644, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 670072, "time": 21287.406584501266, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 670072, "time": 21288.652323961258, "eval_episode/length": 189.0, "eval_episode/score": 0.40937501192092896, "eval_episode/reward_rate": 0.005263157894736842}
{"step": 670072, "time": 21288.74251484871, "eval_episode/length": 193.0, "eval_episode/score": 0.3968749940395355, "eval_episode/reward_rate": 0.005154639175257732}
{"step": 670072, "time": 21289.360862016678, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 670072, "time": 21289.614424705505, "eval_episode/length": 235.0, "eval_episode/score": 0.265625, "eval_episode/reward_rate": 0.00423728813559322}
{"step": 670072, "time": 21291.368969917297, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 670256, "time": 21297.200485229492, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 670512, "time": 21305.102525949478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670520, "time": 21305.130940437317, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 670752, "time": 21312.401597976685, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 670904, "time": 21316.854075431824, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 671216, "time": 21326.69775080681, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 671336, "time": 21330.247070789337, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 671736, "time": 21342.41980957985, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 671880, "time": 21347.30748796463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671976, "time": 21350.253969669342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671992, "time": 21350.746760368347, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 672184, "time": 21357.2606985569, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 672280, "time": 21360.289714813232, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 672384, "time": 21363.663992643356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672568, "time": 21369.16782951355, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 672568, "time": 21369.17900967598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672632, "time": 21371.13656449318, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 672832, "time": 21377.436125040054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672904, "time": 21379.404363632202, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 672976, "time": 21381.83143043518, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 673096, "time": 21385.260565280914, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 673200, "time": 21388.737345695496, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 673336, "time": 21392.627707719803, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 673504, "time": 21397.959649562836, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 673920, "time": 21410.639236450195, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 674176, "time": 21418.408031225204, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 674288, "time": 21421.909979343414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674608, "time": 21431.64282655716, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 674656, "time": 21433.097507715225, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 674696, "time": 21434.109582424164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674848, "time": 21438.971101999283, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 674880, "time": 21439.94803905487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675008, "time": 21443.881222248077, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 675120, "time": 21447.309141397476, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 675184, "time": 21449.431631565094, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 675376, "time": 21455.329793453217, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 675416, "time": 21456.346312999725, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 675432, "time": 21456.844486951828, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 676032, "time": 21475.341626644135, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 676104, "time": 21477.32788991928, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 676344, "time": 21484.812128305435, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 676376, "time": 21485.789538145065, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 676488, "time": 21489.21742630005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676520, "time": 21490.19610619545, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 677048, "time": 21506.302288532257, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 677088, "time": 21507.75592970848, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 677096, "time": 21507.786308526993, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 677152, "time": 21509.807493925095, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 677160, "time": 21509.839199066162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677320, "time": 21514.727121591568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677384, "time": 21516.674975395203, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 677408, "time": 21517.653987407684, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 677432, "time": 21518.168061494827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677544, "time": 21521.567594766617, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 677568, "time": 21522.531415224075, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 677648, "time": 21524.99142742157, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 677744, "time": 21527.912987947464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 677920, "time": 21537.9563536644, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 677952, "time": 21542.42884516716, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 678272, "time": 21552.133432388306, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 678448, "time": 21557.5058093071, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 678496, "time": 21558.964901447296, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 678496, "time": 21558.97239303589, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 678568, "time": 21560.957083702087, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 678784, "time": 21567.764234542847, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 678928, "time": 21572.26303935051, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 679016, "time": 21574.74200487137, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 679048, "time": 21575.72156572342, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 679560, "time": 21591.360671043396, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 679592, "time": 21592.340192079544, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 679632, "time": 21593.79858970642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679720, "time": 21596.24963068962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679960, "time": 21604.164844036102, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 680032, "time": 21606.5834441185, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 21608.560061216354, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 680056, "time": 21608.78540444374, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 680056, "time": 21609.04669380188, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 680056, "time": 21609.75978088379, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 680056, "time": 21609.80977153778, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 680056, "time": 21610.517828941345, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 680056, "time": 21610.721966981888, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 680056, "time": 21610.748929739, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 680080, "time": 21611.69558429718, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 680248, "time": 21616.59116625786, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 680584, "time": 21626.830619096756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680760, "time": 21632.299359083176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680848, "time": 21635.18991804123, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 681096, "time": 21642.53028178215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681096, "time": 21642.538595676422, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 681240, "time": 21646.958566188812, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 681416, "time": 21652.305250167847, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 681512, "time": 21655.241638183594, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 681576, "time": 21657.213859319687, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 681688, "time": 21660.735416650772, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 681904, "time": 21667.576385498047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681952, "time": 21669.051590919495, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 682032, "time": 21671.50188589096, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 682032, "time": 21671.5110578537, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 682192, "time": 21676.423476934433, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 682560, "time": 21687.67690229416, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 682696, "time": 21691.701730966568, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 683528, "time": 21717.046286582947, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 683552, "time": 21718.006722450256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683888, "time": 21728.30434513092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684000, "time": 21731.75089788437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684024, "time": 21732.268424987793, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 684216, "time": 21738.10508942604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684264, "time": 21739.558976888657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684352, "time": 21742.453445911407, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 684504, "time": 21746.85238313675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684800, "time": 21756.19530773163, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 684856, "time": 21757.679379463196, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 684872, "time": 21758.167634248734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 685056, "time": 21763.965544462204, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 685168, "time": 21767.39227128029, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 685280, "time": 21770.80993747711, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 685432, "time": 21775.194497585297, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 685488, "time": 21778.376376390457, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 685504, "time": 21778.925643205643, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 685536, "time": 21779.918648958206, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 685736, "time": 21785.80299282074, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 685944, "time": 21792.134038448334, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 686088, "time": 21796.55741405487, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 686216, "time": 21800.474395275116, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 686272, "time": 21802.40434741974, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 686336, "time": 21804.34185194969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686512, "time": 21809.809013843536, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 686880, "time": 21821.00539779663, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 686888, "time": 21821.03537249565, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 687032, "time": 21825.436915159225, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 687040, "time": 21825.905523061752, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 687432, "time": 21837.56315422058, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 687448, "time": 21838.058746814728, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 687616, "time": 21843.488275766373, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 687816, "time": 21849.365924358368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687864, "time": 21850.82625746727, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 688048, "time": 21856.674484729767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 688048, "time": 21856.68343257904, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 688520, "time": 21871.460381269455, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 688528, "time": 21871.931333065033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 688680, "time": 21876.333882570267, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 688752, "time": 21878.76330757141, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 688768, "time": 21879.258519887924, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 688848, "time": 21881.68027114868, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 689080, "time": 21888.507559776306, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 689216, "time": 21892.864022493362, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 689224, "time": 21892.892575740814, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 689344, "time": 21896.748630046844, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 689416, "time": 21898.838525295258, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 689552, "time": 21903.182936429977, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 689744, "time": 21909.023097753525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 689992, "time": 21916.341047286987, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 690016, "time": 21917.299235343933, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 21918.958343029022, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 690040, "time": 21919.07145690918, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 690040, "time": 21919.41230893135, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 690040, "time": 21919.42405819893, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 690040, "time": 21919.676264047623, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 690040, "time": 21919.68246269226, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 690040, "time": 21920.71416425705, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 690040, "time": 21920.8612139225, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 690120, "time": 21924.165949821472, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 690176, "time": 21926.0907702446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690368, "time": 21932.03902864456, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 690768, "time": 21944.173600435257, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 690784, "time": 21944.665282964706, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 690984, "time": 21950.52131295204, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 691032, "time": 21952.00337767601, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 691256, "time": 21958.90764093399, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 691392, "time": 21963.26381421089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691536, "time": 21967.635962724686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691656, "time": 21971.089293956757, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 691704, "time": 21972.54503273964, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 691808, "time": 21975.920122385025, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 692040, "time": 21982.736337661743, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 692056, "time": 21983.226279973984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692208, "time": 21988.0830078125, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 692304, "time": 21991.157152414322, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 692432, "time": 21995.047965049744, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 692496, "time": 21996.990475177765, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 692496, "time": 21996.998109340668, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 692624, "time": 22000.864079236984, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 692832, "time": 22007.166113853455, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 693104, "time": 22015.410837888718, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 693120, "time": 22015.907288074493, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 693416, "time": 22024.782602787018, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 693456, "time": 22026.221784830093, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 693456, "time": 22026.229085445404, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 693704, "time": 22033.538253307343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 693752, "time": 22035.0067756176, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 693800, "time": 22036.462030172348, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 693832, "time": 22037.428812742233, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 694000, "time": 22042.73678612709, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 694104, "time": 22045.696508407593, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 694120, "time": 22046.185686826706, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 694184, "time": 22048.116627931595, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 694208, "time": 22049.226866722107, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 694280, "time": 22051.184210300446, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 694448, "time": 22056.512281894684, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 694496, "time": 22057.97226047516, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 694720, "time": 22064.788940906525, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 694848, "time": 22068.66451740265, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 694976, "time": 22072.522864580154, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 695008, "time": 22073.52085494995, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 695120, "time": 22076.907952785492, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 695536, "time": 22089.637893915176, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 695600, "time": 22091.58122754097, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 695720, "time": 22095.020572185516, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 695864, "time": 22099.404564857483, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 696088, "time": 22106.20627140999, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 696312, "time": 22113.132737636566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696368, "time": 22115.5292596817, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 696520, "time": 22119.931263446808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696760, "time": 22127.210520982742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697152, "time": 22139.41255402565, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 697160, "time": 22139.44151854515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697184, "time": 22140.391726732254, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 697472, "time": 22149.161971330643, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 697544, "time": 22151.125810861588, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 697800, "time": 22158.89174389839, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 697800, "time": 22158.900608301163, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 697824, "time": 22159.856444597244, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 697912, "time": 22162.30148625374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698032, "time": 22166.167993307114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698256, "time": 22173.767395973206, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 698264, "time": 22173.799360513687, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 698336, "time": 22176.19211935997, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 698488, "time": 22180.562775850296, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 698576, "time": 22183.4577088356, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 698688, "time": 22186.878507852554, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 698712, "time": 22187.390680789948, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 698944, "time": 22194.602483034134, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 699000, "time": 22196.09500026703, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 699032, "time": 22197.060886859894, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 699264, "time": 22204.405155181885, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 699448, "time": 22211.352494955063, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 699472, "time": 22212.335968255997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 22229.95707154274, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 700024, "time": 22230.47090792656, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 700024, "time": 22230.477625370026, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 700024, "time": 22230.825905799866, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 700024, "time": 22231.088807106018, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 700024, "time": 22231.096064567566, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 700024, "time": 22231.731278657913, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 700024, "time": 22231.79912877083, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 700224, "time": 22238.075791358948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700240, "time": 22238.568853139877, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 700473, "time": 22246.40462899208, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2348611234414455, "train/action_min": 0.0, "train/action_std": 1.701922428126287, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013143619380166961, "train/actor_opt_grad_steps": 42695.0, "train/actor_opt_loss": -11.756755485679165, "train/adv_mag": 0.9572031136715051, "train/adv_max": 0.2632789599775064, "train/adv_mean": 0.0012396733586729628, "train/adv_min": -0.9259256244909884, "train/adv_std": 0.03314448274540329, "train/cont_avg": 0.9948459201388888, "train/cont_loss_mean": 0.016744370568741226, "train/cont_loss_std": 0.22917133215062244, "train/cont_neg_acc": 0.3571423167607399, "train/cont_neg_loss": 2.5193270122399554, "train/cont_pos_acc": 0.9998413526048564, "train/cont_pos_loss": 0.003581929035282534, "train/cont_pred": 0.9948271865194495, "train/cont_rate": 0.9948459201388888, "train/dyn_loss_mean": 1.0000014979429919, "train/dyn_loss_std": 4.791330344471704e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.21200465915649377, "train/extr_critic_critic_opt_grad_steps": 42695.0, "train/extr_critic_critic_opt_loss": 13230.89244988952, "train/extr_critic_mag": 1.4764720767435402, "train/extr_critic_max": 1.4764720767435402, "train/extr_critic_mean": 1.3551862372292414, "train/extr_critic_min": 1.2708406544694997, "train/extr_critic_std": 0.02068677537067972, "train/extr_return_normed_mag": 0.9622461940302993, "train/extr_return_normed_max": 0.33348826326505104, "train/extr_return_normed_mean": 0.04079230708738017, "train/extr_return_normed_min": -0.8909338568196152, "train/extr_return_normed_std": 0.04031927753804308, "train/extr_return_rate": 0.9994588190256947, "train/extr_return_raw_mag": 1.6491209732161627, "train/extr_return_raw_max": 1.6491209732161627, "train/extr_return_raw_mean": 1.356425075217931, "train/extr_return_raw_min": 0.4246988531314965, "train/extr_return_raw_std": 0.04031927748159929, "train/extr_reward_mag": 0.3319763812151822, "train/extr_reward_max": 0.3319763812151822, "train/extr_reward_mean": 0.0024055374949121604, "train/extr_reward_min": 1.3125063192964804e-07, "train/extr_reward_std": 0.010751520009532646, "train/image_loss_mean": 0.08255977717914967, "train/image_loss_std": 0.09685185766129782, "train/model_loss_mean": 0.7120124679623228, "train/model_loss_std": 0.42462961172515695, "train/model_opt_grad_norm": 22.72915631592876, "train/model_opt_grad_steps": 42660.0101010101, "train/model_opt_loss": 3667.424530954072, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5151.515151515152, "train/policy_entropy_mag": 1.3209336893727082, "train/policy_entropy_max": 1.3209336893727082, "train/policy_entropy_mean": 0.10604531419548122, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13735060521749534, "train/policy_logprob_mag": 6.551080248572609, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10619169586535657, "train/policy_logprob_min": -6.551080248572609, "train/policy_logprob_std": 0.643482121554288, "train/policy_randomness_mag": 0.6788256737318906, "train/policy_randomness_max": 0.6788256737318906, "train/policy_randomness_mean": 0.054496513491477626, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07058425243906301, "train/post_ent_mag": 28.901542480545814, "train/post_ent_max": 28.901542480545814, "train/post_ent_mean": 28.731807833970194, "train/post_ent_min": 28.600755845657503, "train/post_ent_std": 0.06166081241510733, "train/prior_ent_mag": 29.818229444099195, "train/prior_ent_max": 29.818229444099195, "train/prior_ent_mean": 28.31882305337925, "train/prior_ent_min": 27.22657049545134, "train/prior_ent_std": 0.3896796178035062, "train/rep_loss_mean": 1.0000014979429919, "train/rep_loss_std": 4.791330344471704e-05, "train/reward_avg": 0.001719418932749029, "train/reward_loss_mean": 0.012707396988954508, "train/reward_loss_std": 0.19834477556257912, "train/reward_max_data": 0.7147727264749884, "train/reward_max_pred": 0.2353336847189701, "train/reward_neg_acc": 0.9995944885292438, "train/reward_neg_loss": 0.002272897728629448, "train/reward_pos_acc": 0.22523166215097581, "train/reward_pos_loss": 3.911497570050729, "train/reward_pred": 0.0013654305431474415, "train/reward_rate": 0.002623895202020202, "train_stats/mean_log_entropy": 0.08753007290803867, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.017085840925574303, "report/cont_loss_std": 0.2226107269525528, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 2.9833693504333496, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.005453357007354498, "report/cont_pred": 0.9936295747756958, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.073548823595047, "report/image_loss_std": 0.09380381554365158, "report/model_loss_mean": 0.7091113924980164, "report/model_loss_std": 0.5263420939445496, "report/post_ent_mag": 28.612438201904297, "report/post_ent_max": 28.612438201904297, "report/post_ent_mean": 28.44820213317871, "report/post_ent_min": 28.31907081604004, "report/post_ent_std": 0.05958087742328644, "report/prior_ent_mag": 29.74524688720703, "report/prior_ent_max": 29.74524688720703, "report/prior_ent_mean": 28.364595413208008, "report/prior_ent_min": 27.001102447509766, "report/prior_ent_std": 0.418120414018631, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002423095516860485, "report/reward_loss_mean": 0.01847672462463379, "report/reward_loss_std": 0.26771098375320435, "report/reward_max_data": 0.8656250238418579, "report/reward_max_pred": 0.060690879821777344, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004364080727100372, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.821479797363281, "report/reward_pred": 0.002314572921022773, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03502880036830902, "eval/cont_loss_std": 0.6057155728340149, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.910364151000977, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.0030738511122763157, "eval/cont_pred": 0.9973350167274475, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15027432143688202, "eval/image_loss_std": 0.1459154337644577, "eval/model_loss_mean": 0.8095772862434387, "eval/model_loss_std": 1.1169884204864502, "eval/post_ent_mag": 28.613574981689453, "eval/post_ent_max": 28.613574981689453, "eval/post_ent_mean": 28.413196563720703, "eval/post_ent_min": 28.294815063476562, "eval/post_ent_std": 0.06311329454183578, "eval/prior_ent_mag": 29.74524688720703, "eval/prior_ent_max": 29.74524688720703, "eval/prior_ent_mean": 28.239961624145508, "eval/prior_ent_min": 27.17501449584961, "eval/prior_ent_std": 0.40679988265037537, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0014526366721838713, "eval/reward_loss_mean": 0.024274148046970367, "eval/reward_loss_std": 0.5542760491371155, "eval/reward_max_data": 0.9125000238418579, "eval/reward_max_pred": 0.11269092559814453, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.00119382597040385, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 11.818318367004395, "eval/reward_pred": 0.000599101884290576, "eval/reward_rate": 0.001953125, "replay/size": 699969.0, "replay/inserts": 31664.0, "replay/samples": 31664.0, "replay/insert_wait_avg": 1.3915004002560023e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.323793160668402e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2170517950770098e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0991399288177, "timer/env.step_count": 3958.0, "timer/env.step_total": 39.965715408325195, "timer/env.step_frac": 0.03996175360291757, "timer/env.step_avg": 0.01009745209912208, "timer/env.step_min": 0.007875680923461914, "timer/env.step_max": 0.039543867111206055, "timer/replay._sample_count": 31664.0, "timer/replay._sample_total": 15.962791681289673, "timer/replay._sample_frac": 0.015961209288137, "timer/replay._sample_avg": 0.0005041306114606389, "timer/replay._sample_min": 0.00037932395935058594, "timer/replay._sample_max": 0.02297043800354004, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4641.0, "timer/agent.policy_total": 51.00117611885071, "timer/agent.policy_frac": 0.05099612036710753, "timer/agent.policy_avg": 0.010989264408285005, "timer/agent.policy_min": 0.008999347686767578, "timer/agent.policy_max": 0.09950470924377441, "timer/dataset_train_count": 1979.0, "timer/dataset_train_total": 0.2237555980682373, "timer/dataset_train_frac": 0.00022373341715318658, "timer/dataset_train_avg": 0.00011306498133816943, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.00037980079650878906, "timer/agent.train_count": 1979.0, "timer/agent.train_total": 880.6008050441742, "timer/agent.train_frac": 0.8805135109973709, "timer/agent.train_avg": 0.44497261497937046, "timer/agent.train_min": 0.4336435794830322, "timer/agent.train_max": 0.6806049346923828, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47480034828186035, "timer/agent.report_frac": 0.00047475328127534873, "timer/agent.report_avg": 0.23740017414093018, "timer/agent.report_min": 0.2311854362487793, "timer/agent.report_max": 0.24361491203308105, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.956097313582128e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 31.660322090550334}
{"step": 700576, "time": 22249.537186145782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 700888, "time": 22258.941166639328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701240, "time": 22269.768893957138, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 701248, "time": 22270.236602306366, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 701312, "time": 22272.193206310272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701344, "time": 22273.177879095078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701352, "time": 22273.20672750473, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 701688, "time": 22283.47988796234, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 701744, "time": 22285.43873977661, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 701760, "time": 22285.93870997429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701784, "time": 22286.46097588539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701800, "time": 22286.959186792374, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 702080, "time": 22295.826524734497, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 702088, "time": 22295.854248523712, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 702152, "time": 22297.808490037918, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 702240, "time": 22300.7175886631, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 702472, "time": 22307.58382177353, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 702584, "time": 22311.032138824463, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 702848, "time": 22319.410298109055, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 702944, "time": 22322.31742668152, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 702968, "time": 22322.82864665985, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 703016, "time": 22324.308255672455, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 703104, "time": 22327.200508356094, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 703416, "time": 22336.49741911888, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 703528, "time": 22339.927378177643, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 703576, "time": 22341.397669315338, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 703664, "time": 22344.3156144619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 703680, "time": 22344.80465388298, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 703744, "time": 22346.755086898804, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 703888, "time": 22351.255322933197, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 703936, "time": 22352.71883392334, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 704024, "time": 22355.191265821457, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 704168, "time": 22359.578434705734, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 704304, "time": 22363.94983124733, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 704392, "time": 22366.401816368103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 704408, "time": 22366.891956329346, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 704568, "time": 22372.277745246887, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 704576, "time": 22372.750869512558, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 704632, "time": 22374.288027763367, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 705304, "time": 22394.954146385193, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 705376, "time": 22397.3725233078, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 705768, "time": 22409.264591693878, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 705792, "time": 22410.22400355339, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 706240, "time": 22423.89195203781, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 706248, "time": 22423.923357009888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706480, "time": 22431.185616016388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706720, "time": 22438.579553365707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706760, "time": 22439.5784406662, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 706880, "time": 22443.469947576523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706960, "time": 22445.89063644409, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 707088, "time": 22449.795973300934, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 707168, "time": 22452.24263739586, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 707232, "time": 22454.186205148697, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 707752, "time": 22469.912719011307, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 708000, "time": 22477.713102817535, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 708080, "time": 22480.15594959259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 708240, "time": 22485.03446817398, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 708448, "time": 22491.386374235153, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 708792, "time": 22501.737324237823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 708856, "time": 22503.668629407883, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 708960, "time": 22507.050793647766, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 709072, "time": 22510.469299793243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709272, "time": 22516.31769824028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709312, "time": 22517.74889588356, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 709480, "time": 22522.64583182335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709888, "time": 22535.418050527573, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 709904, "time": 22535.912584781647, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 709960, "time": 22537.38286137581, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 22539.47647500038, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 710008, "time": 22539.990517377853, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 710008, "time": 22540.33430814743, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 710008, "time": 22540.48804116249, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 710008, "time": 22540.887709379196, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 710008, "time": 22541.154006958008, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 710008, "time": 22542.12440443039, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 710008, "time": 22542.194140672684, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 710016, "time": 22542.66441988945, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 710064, "time": 22544.160138130188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710104, "time": 22545.154304504395, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 710208, "time": 22548.54444217682, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 710392, "time": 22553.932228565216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710496, "time": 22557.299235343933, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 710592, "time": 22560.34533238411, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 710632, "time": 22561.353587388992, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 710672, "time": 22562.80790400505, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 711080, "time": 22574.994122505188, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 711192, "time": 22578.41576576233, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 711248, "time": 22580.34683227539, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 711544, "time": 22589.271364688873, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 711720, "time": 22594.64825105667, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 711760, "time": 22596.088468790054, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 711848, "time": 22598.569472551346, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 711936, "time": 22601.504893302917, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 712200, "time": 22609.380163669586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712376, "time": 22614.743594169617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712384, "time": 22615.21433353424, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 712808, "time": 22628.573457479477, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 712840, "time": 22629.553730487823, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 712904, "time": 22631.5022521019, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 713168, "time": 22639.790276050568, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 713296, "time": 22643.763815164566, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 713432, "time": 22647.730372428894, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 713560, "time": 22651.750095129013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713712, "time": 22656.61047887802, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 713744, "time": 22657.588391304016, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 713896, "time": 22662.02877140045, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 713944, "time": 22663.497323274612, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 714160, "time": 22670.298095464706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714208, "time": 22671.777148485184, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 714320, "time": 22675.170118570328, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 714424, "time": 22678.140110969543, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 714448, "time": 22679.222128868103, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 714696, "time": 22686.57873415947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714760, "time": 22688.562106132507, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 714976, "time": 22695.39299917221, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 715040, "time": 22697.353086709976, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 715512, "time": 22711.654832601547, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 715528, "time": 22712.158996105194, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 715536, "time": 22712.63210248947, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 715576, "time": 22713.644439935684, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 715672, "time": 22716.616779327393, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 715872, "time": 22722.981519699097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 716128, "time": 22730.79173564911, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 716472, "time": 22741.258594989777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 716520, "time": 22742.713836193085, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 716736, "time": 22749.536932706833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717216, "time": 22764.18883895874, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 717528, "time": 22773.615380048752, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 717600, "time": 22776.045863628387, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 717656, "time": 22777.53486442566, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 717824, "time": 22782.904851675034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717840, "time": 22783.400804281235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718064, "time": 22790.281688451767, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 718080, "time": 22790.778774023056, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 718120, "time": 22791.785348892212, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 718184, "time": 22793.725133895874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718328, "time": 22798.121290922165, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 718368, "time": 22799.714502334595, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 718536, "time": 22804.606920957565, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 718544, "time": 22805.07944393158, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 718624, "time": 22807.521449565887, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 718832, "time": 22813.86429166794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719096, "time": 22821.660365104675, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 719120, "time": 22822.612330198288, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 719144, "time": 22823.121254205704, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 719352, "time": 22829.518327236176, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 719504, "time": 22834.35839867592, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 719728, "time": 22841.168090581894, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 719744, "time": 22841.65596795082, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 719912, "time": 22846.56301999092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719920, "time": 22847.042229413986, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 719960, "time": 22848.061416625977, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 22853.79916024208, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 720096, "time": 22854.05664920807, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 720096, "time": 22854.17802143097, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 720096, "time": 22854.419980049133, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 720096, "time": 22854.6475982666, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 720096, "time": 22854.751928567886, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 720096, "time": 22855.34783601761, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 720096, "time": 22855.57147550583, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 720104, "time": 22855.60161757469, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 720192, "time": 22858.637489318848, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 720296, "time": 22861.583753824234, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 720304, "time": 22862.05495262146, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 720392, "time": 22864.49039053917, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 720640, "time": 22872.26288342476, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 720880, "time": 22879.598699331284, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 720912, "time": 22881.07531785965, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 721048, "time": 22884.986099481583, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 721592, "time": 22901.65365576744, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 721600, "time": 22902.124413967133, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 722056, "time": 22915.771213531494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722160, "time": 22919.23998093605, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 722224, "time": 22921.202771425247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722504, "time": 22929.505432367325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722560, "time": 22931.45405101776, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 722584, "time": 22931.96562886238, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 722832, "time": 22939.770424604416, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 722904, "time": 22941.732147932053, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 722952, "time": 22943.203513383865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723024, "time": 22945.629080057144, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 723192, "time": 22950.64590907097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723248, "time": 22952.56423854828, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 723256, "time": 22952.5922768116, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 723576, "time": 22962.36983513832, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 723768, "time": 22968.226288080215, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 723888, "time": 22972.133533000946, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 724032, "time": 22976.510227680206, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 724184, "time": 22981.002521276474, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 724288, "time": 22984.394079446793, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 724688, "time": 22996.527124643326, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 724704, "time": 22997.019873142242, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 725344, "time": 23016.67564702034, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 725344, "time": 23016.68327331543, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 725456, "time": 23020.098442077637, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 725496, "time": 23021.094586372375, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 725504, "time": 23021.565684318542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 725888, "time": 23033.26798582077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 726240, "time": 23044.084715366364, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 726288, "time": 23045.54440188408, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 726392, "time": 23048.515444278717, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 726408, "time": 23049.005903482437, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 726576, "time": 23054.320982694626, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 726600, "time": 23054.841066122055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 726656, "time": 23056.76402926445, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 727016, "time": 23067.523472309113, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 727096, "time": 23070.046499729156, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 727104, "time": 23070.517730236053, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 727216, "time": 23073.938565969467, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 727288, "time": 23075.908734083176, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 727576, "time": 23084.712715625763, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 727816, "time": 23092.062294483185, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 728016, "time": 23098.510506868362, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 728048, "time": 23099.501220703125, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 728120, "time": 23101.48237991333, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 728128, "time": 23101.95328783989, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 728168, "time": 23102.94386291504, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 728176, "time": 23103.414184093475, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 728312, "time": 23107.341954946518, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 728336, "time": 23108.2986035347, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 728528, "time": 23114.124965190887, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 728576, "time": 23115.600248098373, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 728600, "time": 23116.133842229843, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 728840, "time": 23123.437608718872, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 728880, "time": 23124.87627863884, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 728944, "time": 23126.850475788116, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 729048, "time": 23129.926377534866, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 729304, "time": 23138.256098508835, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 729312, "time": 23138.73058772087, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 729336, "time": 23139.249670267105, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 729592, "time": 23147.12001824379, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 729624, "time": 23148.101293325424, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 729712, "time": 23151.046464920044, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 729840, "time": 23154.980107307434, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 730040, "time": 23160.991089105606, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 730064, "time": 23161.964363336563, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 23163.244960546494, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 730080, "time": 23163.495399951935, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 730080, "time": 23163.604361772537, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 730080, "time": 23163.934293985367, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 730080, "time": 23164.310110092163, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 730080, "time": 23164.563886404037, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 730080, "time": 23164.8538210392, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 730080, "time": 23165.7338681221, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 730216, "time": 23169.665265083313, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 730272, "time": 23171.586106061935, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 730312, "time": 23172.577473402023, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 730624, "time": 23182.377739429474, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 730680, "time": 23183.88136601448, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 730792, "time": 23187.279972314835, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 730800, "time": 23187.74930000305, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 730992, "time": 23193.74497485161, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 731040, "time": 23195.22652697563, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 731336, "time": 23204.098171710968, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 731472, "time": 23208.48959994316, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 731688, "time": 23214.852516651154, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 731760, "time": 23217.258707523346, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 731888, "time": 23221.284086227417, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 732032, "time": 23225.671017885208, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 732152, "time": 23229.117983341217, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 732160, "time": 23229.593469142914, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 732184, "time": 23230.107206583023, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 732248, "time": 23232.05996966362, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 732280, "time": 23233.054740428925, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 732328, "time": 23234.522714614868, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 732384, "time": 23236.456829547882, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 732408, "time": 23236.971858501434, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 732616, "time": 23243.364495038986, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 732697, "time": 23246.83411216736, "train_stats/mean_log_entropy": 0.08630834045041291, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2129161322294775, "train/action_min": 0.0, "train/action_std": 1.714611795411181, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013128753473509603, "train/actor_opt_grad_steps": 44690.0, "train/actor_opt_loss": -13.21584395567576, "train/adv_mag": 1.066774483343855, "train/adv_max": 0.2760593280270325, "train/adv_mean": 0.0017190655278827038, "train/adv_min": -1.0370357629671618, "train/adv_std": 0.03487313040230998, "train/cont_avg": 0.9948159592661692, "train/cont_loss_mean": 0.016840350040378264, "train/cont_loss_std": 0.22786803594303887, "train/cont_neg_acc": 0.3265794114538686, "train/cont_neg_loss": 2.578611285279769, "train/cont_pos_acc": 0.9998436783676716, "train/cont_pos_loss": 0.003607252320223743, "train/cont_pred": 0.9947908891374199, "train/cont_rate": 0.9948159592661692, "train/dyn_loss_mean": 1.0000026178597219, "train/dyn_loss_std": 7.658097742412665e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2057934104191575, "train/extr_critic_critic_opt_grad_steps": 44690.0, "train/extr_critic_critic_opt_loss": 12602.022776741294, "train/extr_critic_mag": 1.5378235430266727, "train/extr_critic_max": 1.5378235430266727, "train/extr_critic_mean": 1.4318533465636902, "train/extr_critic_min": 1.327002845593353, "train/extr_critic_std": 0.023310035040870827, "train/extr_return_normed_mag": 1.064872911320397, "train/extr_return_normed_max": 0.3468749054628818, "train/extr_return_normed_mean": 0.04731870006158281, "train/extr_return_normed_min": -1.0021299200864573, "train/extr_return_normed_std": 0.043284173647117855, "train/extr_return_rate": 0.9995517626923708, "train/extr_return_raw_mag": 1.7331274907980392, "train/extr_return_raw_max": 1.7331274907980392, "train/extr_return_raw_mean": 1.4335713439912938, "train/extr_return_raw_min": 0.38412266524870003, "train/extr_return_raw_std": 0.043284173647117855, "train/extr_reward_mag": 0.33659039326568146, "train/extr_reward_max": 0.33659039326568146, "train/extr_reward_mean": 0.0025136934909552556, "train/extr_reward_min": 1.1920928955078125e-07, "train/extr_reward_std": 0.011141032538844726, "train/image_loss_mean": 0.0803291762979766, "train/image_loss_std": 0.09537261809727446, "train/model_loss_mean": 0.7104848688514671, "train/model_loss_std": 0.4348974937749146, "train/model_opt_grad_norm": 22.124603674779483, "train/model_opt_grad_steps": 44653.159203980096, "train/model_opt_loss": 3818.3933846393033, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5373.134328358209, "train/policy_entropy_mag": 1.3238908586217397, "train/policy_entropy_max": 1.3238908586217397, "train/policy_entropy_mean": 0.103934838218772, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1337839859857488, "train/policy_logprob_mag": 6.55108023638749, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10399618337106942, "train/policy_logprob_min": -6.55108023638749, "train/policy_logprob_std": 0.6415179579412166, "train/policy_randomness_mag": 0.6803453582436291, "train/policy_randomness_max": 0.6803453582436291, "train/policy_randomness_mean": 0.05341194373606449, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06875137237841217, "train/post_ent_mag": 28.96236683480182, "train/post_ent_max": 28.96236683480182, "train/post_ent_mean": 28.79191317012654, "train/post_ent_min": 28.66189550523141, "train/post_ent_std": 0.0609222961339488, "train/prior_ent_mag": 29.74793203553157, "train/prior_ent_max": 29.74793203553157, "train/prior_ent_mean": 28.415573461731867, "train/prior_ent_min": 27.379324822876583, "train/prior_ent_std": 0.3764407449397282, "train/rep_loss_mean": 1.0000026178597219, "train/rep_loss_std": 7.658097742412665e-05, "train/reward_avg": 0.0018480746905187339, "train/reward_loss_mean": 0.013313745113149915, "train/reward_loss_std": 0.20787166264278822, "train/reward_max_data": 0.7426772394880133, "train/reward_max_pred": 0.24216324535768424, "train/reward_neg_acc": 0.9996052013700875, "train/reward_neg_loss": 0.002418291379421931, "train/reward_pos_acc": 0.1791573192592691, "train/reward_pos_loss": 4.0051067019008215, "train/reward_pred": 0.0014581595285707593, "train/reward_rate": 0.002711054104477612, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.008238350972533226, "report/cont_loss_std": 0.12324431538581848, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.7333760261535645, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002905400702729821, "report/cont_pred": 0.9970085024833679, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06787612289190292, "report/image_loss_std": 0.08445917814970016, "report/model_loss_mean": 0.6812260150909424, "report/model_loss_std": 0.2158670872449875, "report/post_ent_mag": 28.667741775512695, "report/post_ent_max": 28.667741775512695, "report/post_ent_mean": 28.459667205810547, "report/post_ent_min": 28.31053924560547, "report/post_ent_std": 0.07002823799848557, "report/prior_ent_mag": 29.026742935180664, "report/prior_ent_max": 29.026742935180664, "report/prior_ent_mean": 28.011398315429688, "report/prior_ent_min": 27.23419761657715, "report/prior_ent_std": 0.28486502170562744, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005981445428915322, "report/reward_loss_mean": 0.005111466161906719, "report/reward_loss_std": 0.09457380324602127, "report/reward_max_data": 0.612500011920929, "report/reward_max_pred": 0.05057215690612793, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0021645650267601013, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.0197908878326416, "report/reward_pred": 0.001198972575366497, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04740869998931885, "eval/cont_loss_std": 0.649948239326477, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.875144004821777, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.004093024879693985, "eval/cont_pred": 0.9977983236312866, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12653547525405884, "eval/image_loss_std": 0.11849284172058105, "eval/model_loss_mean": 0.7966512441635132, "eval/model_loss_std": 0.9726890325546265, "eval/post_ent_mag": 28.664386749267578, "eval/post_ent_max": 28.664386749267578, "eval/post_ent_mean": 28.428640365600586, "eval/post_ent_min": 28.297935485839844, "eval/post_ent_std": 0.07409519702196121, "eval/prior_ent_mag": 29.026742935180664, "eval/prior_ent_max": 29.026742935180664, "eval/prior_ent_mean": 28.026103973388672, "eval/prior_ent_min": 26.799625396728516, "eval/prior_ent_std": 0.29365983605384827, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0011077880626544356, "eval/reward_loss_mean": 0.022707052528858185, "eval/reward_loss_std": 0.44434279203414917, "eval/reward_max_data": 0.809374988079071, "eval/reward_max_pred": 0.7186857461929321, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.004318971652537584, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.419015884399414, "eval/reward_pred": 0.001008414663374424, "eval/reward_rate": 0.001953125, "replay/size": 732193.0, "replay/inserts": 32224.0, "replay/samples": 32224.0, "replay/insert_wait_avg": 1.3053757550107923e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.143255229976469e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0862242759375602e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2516975402832031e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4060199260712, "timer/env.step_count": 4028.0, "timer/env.step_total": 39.70256567001343, "timer/env.step_frac": 0.03968645217963342, "timer/env.step_avg": 0.00985664490318109, "timer/env.step_min": 0.007926464080810547, "timer/env.step_max": 0.03465461730957031, "timer/replay._sample_count": 32224.0, "timer/replay._sample_total": 16.26483654975891, "timer/replay._sample_frac": 0.01625823538223097, "timer/replay._sample_avg": 0.0005047429415888441, "timer/replay._sample_min": 0.00039005279541015625, "timer/replay._sample_max": 0.011058568954467773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4515.0, "timer/agent.policy_total": 48.34546375274658, "timer/agent.policy_frac": 0.04832584249774832, "timer/agent.policy_avg": 0.010707743909799908, "timer/agent.policy_min": 0.008693933486938477, "timer/agent.policy_max": 0.09000873565673828, "timer/dataset_train_count": 2014.0, "timer/dataset_train_total": 0.21741747856140137, "timer/dataset_train_frac": 0.00021732923856002812, "timer/dataset_train_avg": 0.00010795306780605828, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0006456375122070312, "timer/agent.train_count": 2014.0, "timer/agent.train_total": 901.3268346786499, "timer/agent.train_frac": 0.9009610265492574, "timer/agent.train_avg": 0.44753070242236836, "timer/agent.train_min": 0.4358539581298828, "timer/agent.train_max": 0.7028131484985352, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4796562194824219, "timer/agent.report_frac": 0.0004794615485399297, "timer/agent.report_avg": 0.23982810974121094, "timer/agent.report_min": 0.23362374305725098, "timer/agent.report_max": 0.2460324764251709, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.883693969916429e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 32.21032617166139}
{"step": 732832, "time": 23251.15572333336, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 733016, "time": 23256.55513548851, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 733048, "time": 23257.53579545021, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 733176, "time": 23261.430566072464, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 733296, "time": 23265.320935726166, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 733624, "time": 23275.104113817215, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 733688, "time": 23277.074365854263, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 733728, "time": 23278.649418592453, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 733792, "time": 23280.599824666977, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 733848, "time": 23282.081449985504, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 733984, "time": 23286.422780036926, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 733992, "time": 23286.45153903961, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 734184, "time": 23292.284032344818, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 734248, "time": 23294.251700162888, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 734464, "time": 23301.04972577095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 734600, "time": 23304.965953826904, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 734688, "time": 23307.875170230865, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 734712, "time": 23308.418518066406, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 734976, "time": 23316.723803520203, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 735168, "time": 23322.587885141373, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 735192, "time": 23323.101284742355, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 735232, "time": 23324.534772872925, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 735240, "time": 23324.562068223953, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 735280, "time": 23326.000450372696, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 735728, "time": 23339.7054708004, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 735824, "time": 23342.638770103455, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 735840, "time": 23343.126499176025, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 735992, "time": 23347.51712179184, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 736080, "time": 23350.397472143173, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 736224, "time": 23354.78144645691, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 736264, "time": 23355.79297399521, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 736392, "time": 23359.71159887314, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 736400, "time": 23360.18163704872, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 736576, "time": 23365.54762506485, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 736920, "time": 23375.863881349564, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 736976, "time": 23377.776105880737, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 737000, "time": 23378.29352760315, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 737088, "time": 23381.21979355812, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 737096, "time": 23381.249792814255, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 737112, "time": 23381.741585731506, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 737216, "time": 23385.140861034393, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 737472, "time": 23393.427475214005, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 738072, "time": 23411.591742277145, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 738104, "time": 23412.572451353073, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 738152, "time": 23414.035158872604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 738520, "time": 23425.15454530716, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 738568, "time": 23426.606287002563, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 738624, "time": 23428.645268917084, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 738792, "time": 23433.520748376846, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 738992, "time": 23439.824934244156, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 739184, "time": 23445.64697289467, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 739232, "time": 23447.10848903656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739288, "time": 23448.59986805916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739400, "time": 23451.981271982193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739408, "time": 23452.449140787125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739504, "time": 23455.369950294495, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 739584, "time": 23457.77840781212, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 739656, "time": 23459.865483283997, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 739664, "time": 23460.33370614052, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 23473.643012285233, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 740064, "time": 23474.14289665222, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 740064, "time": 23474.189165115356, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 740064, "time": 23474.374663352966, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 740064, "time": 23474.425958395004, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 740064, "time": 23474.670773983, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 740064, "time": 23475.327530145645, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 740064, "time": 23477.07183098793, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 740200, "time": 23480.959453582764, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 740240, "time": 23482.385675430298, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 740272, "time": 23483.38457632065, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 740400, "time": 23487.26856327057, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 740440, "time": 23488.346636772156, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 740600, "time": 23493.29834318161, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 740600, "time": 23493.305904388428, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 741064, "time": 23507.359605789185, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 741064, "time": 23507.36691880226, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 741496, "time": 23520.59320449829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741568, "time": 23523.01487970352, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 741896, "time": 23532.77994465828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742008, "time": 23536.17486858368, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 742256, "time": 23543.952632665634, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 742712, "time": 23557.689431667328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742912, "time": 23563.988644123077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742912, "time": 23563.99719262123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743040, "time": 23567.88127875328, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 743376, "time": 23578.097824573517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743592, "time": 23584.62398123741, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 743672, "time": 23587.078782320023, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 743704, "time": 23588.058881044388, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 743808, "time": 23591.45154929161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743880, "time": 23593.42256474495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744144, "time": 23601.665843248367, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 744312, "time": 23606.537155389786, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 744568, "time": 23614.40123438835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744672, "time": 23617.79572749138, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 744784, "time": 23621.21900987625, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 745024, "time": 23628.48366189003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745264, "time": 23635.78523015976, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 745424, "time": 23640.726856470108, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 745496, "time": 23643.2235455513, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 745592, "time": 23646.135670900345, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 745688, "time": 23649.063501119614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745976, "time": 23657.8183927536, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 746016, "time": 23659.25120806694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746192, "time": 23664.631529808044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746472, "time": 23673.069771051407, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 746624, "time": 23677.917726516724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746712, "time": 23680.394734859467, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 746872, "time": 23685.256578683853, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 747032, "time": 23690.10819220543, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 747032, "time": 23690.11631655693, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 747336, "time": 23699.428564548492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747336, "time": 23699.43570637703, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 747520, "time": 23705.26778459549, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 747560, "time": 23706.26484489441, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 747808, "time": 23714.02291369438, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 747880, "time": 23715.993022203445, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 747904, "time": 23716.9516954422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748288, "time": 23728.74871993065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748304, "time": 23729.24797654152, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 748344, "time": 23730.24227333069, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 748448, "time": 23733.629080057144, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 748464, "time": 23734.117393493652, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 748664, "time": 23739.95523929596, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 748808, "time": 23744.35833954811, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 748992, "time": 23750.170603513718, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 749024, "time": 23751.150557994843, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 749024, "time": 23751.161524772644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 749272, "time": 23758.56786966324, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 749352, "time": 23761.031887054443, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 749360, "time": 23761.50821995735, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 749600, "time": 23768.817540884018, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 749664, "time": 23770.757563829422, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 749856, "time": 23776.613136291504, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 749960, "time": 23779.564571142197, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 23783.16205239296, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 750048, "time": 23784.05657029152, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 750048, "time": 23784.203904390335, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 750048, "time": 23784.394420146942, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 750048, "time": 23784.42267394066, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 750048, "time": 23784.87476181984, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 750048, "time": 23785.06935930252, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 750048, "time": 23785.07620024681, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 750360, "time": 23794.464834928513, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 750504, "time": 23798.85430264473, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 750616, "time": 23802.289587259293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 750640, "time": 23803.245893239975, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 750776, "time": 23807.188988685608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 750872, "time": 23810.149703741074, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 751104, "time": 23817.447066307068, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 751120, "time": 23817.940881967545, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 751208, "time": 23820.488086223602, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 751248, "time": 23821.934153318405, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 751488, "time": 23829.256713867188, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 751544, "time": 23830.742159843445, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 751560, "time": 23831.235986709595, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 751752, "time": 23837.069271564484, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 751768, "time": 23837.563708543777, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 752000, "time": 23844.852037668228, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 752312, "time": 23854.32845544815, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 752560, "time": 23862.144604206085, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 752672, "time": 23865.567556619644, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 752736, "time": 23867.856984376907, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 752768, "time": 23868.86500787735, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 752816, "time": 23870.319979429245, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 753064, "time": 23877.632545232773, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 753104, "time": 23879.223010778427, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 753192, "time": 23881.67782139778, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 753208, "time": 23882.17168021202, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 753304, "time": 23885.108675956726, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 753496, "time": 23890.931792736053, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 753520, "time": 23891.890195131302, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 753624, "time": 23894.839608430862, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 753896, "time": 23903.566819667816, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 754064, "time": 23908.98684501648, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 754184, "time": 23912.395154953003, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 754232, "time": 23913.863102912903, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 754232, "time": 23913.87672686577, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 754352, "time": 23917.76071214676, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 754560, "time": 23924.101707696915, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 754584, "time": 23924.613115549088, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 754656, "time": 23927.031243801117, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 754968, "time": 23936.246381521225, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 755080, "time": 23939.747160434723, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 755088, "time": 23940.217806100845, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 755160, "time": 23942.209711313248, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 755296, "time": 23946.550362110138, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 755408, "time": 23949.948830127716, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 755424, "time": 23950.443007946014, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 755456, "time": 23951.41599202156, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 755488, "time": 23952.413449287415, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 755512, "time": 23952.921976327896, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 755640, "time": 23956.81743001938, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 755720, "time": 23959.25458240509, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 755728, "time": 23959.72733926773, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 756152, "time": 23972.50860953331, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 756232, "time": 23974.945208072662, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 756528, "time": 23984.165640354156, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 756632, "time": 23987.11529636383, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 756664, "time": 23988.085698843002, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 756824, "time": 23992.95699071884, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 756912, "time": 23995.85262942314, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 757176, "time": 24003.943860769272, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 757312, "time": 24008.33739256859, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 757440, "time": 24012.25741481781, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 757640, "time": 24018.15797829628, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 757672, "time": 24019.14754509926, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 757736, "time": 24021.12491106987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757760, "time": 24022.086867570877, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 757808, "time": 24023.552755117416, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 757824, "time": 24024.05150771141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 758160, "time": 24034.38539004326, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 758200, "time": 24035.394807100296, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 758312, "time": 24038.792971611023, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 758360, "time": 24040.262230157852, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 758368, "time": 24040.73525071144, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 758568, "time": 24046.579389810562, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 758648, "time": 24048.999078035355, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 758768, "time": 24052.887211084366, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 758832, "time": 24054.845185041428, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 758928, "time": 24057.76623725891, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 759608, "time": 24078.3308904171, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 759880, "time": 24086.634098529816, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 759952, "time": 24089.219473838806, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 759984, "time": 24090.19979596138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 24092.073421239853, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 760032, "time": 24093.029945373535, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 760032, "time": 24093.31223130226, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 760032, "time": 24093.422709703445, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 760032, "time": 24093.618329286575, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 760032, "time": 24094.25134921074, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 760032, "time": 24094.921140909195, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 760032, "time": 24095.01095342636, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 760040, "time": 24095.039650201797, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 760056, "time": 24095.535975933075, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 760128, "time": 24097.97138094902, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 760304, "time": 24103.334710597992, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 760448, "time": 24107.704993247986, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 760488, "time": 24108.69226169586, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 760800, "time": 24118.452511310577, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 760816, "time": 24118.99470114708, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 760856, "time": 24119.992736816406, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 760936, "time": 24122.43697118759, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 760944, "time": 24122.90826034546, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 760968, "time": 24123.421066999435, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 760992, "time": 24124.384752988815, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 761192, "time": 24130.247382879257, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 761344, "time": 24135.103185892105, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 761368, "time": 24135.615916252136, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 761464, "time": 24138.546778202057, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 761640, "time": 24144.003274440765, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 761736, "time": 24146.9582798481, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 761864, "time": 24151.18427157402, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 762048, "time": 24157.274836063385, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 762112, "time": 24159.220119714737, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 762352, "time": 24166.577852725983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 762480, "time": 24170.477044820786, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 762704, "time": 24177.291902542114, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 762848, "time": 24181.77777171135, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 762912, "time": 24183.717371940613, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 763024, "time": 24187.128391981125, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 763032, "time": 24187.158403158188, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 763160, "time": 24191.06228351593, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 763168, "time": 24191.533742904663, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 763472, "time": 24200.84160399437, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 763840, "time": 24212.17394733429, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 763904, "time": 24214.145796060562, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 764016, "time": 24217.586641550064, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 764024, "time": 24217.61513018608, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 764152, "time": 24221.508568763733, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 764264, "time": 24224.91507768631, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 764344, "time": 24227.371297359467, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 764472, "time": 24231.273294210434, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 764696, "time": 24238.0840446949, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 764728, "time": 24239.205049276352, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 764768, "time": 24240.6517663002, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 764953, "time": 24247.009060144424, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1688017892365408, "train/action_min": 0.0, "train/action_std": 1.7079609620689165, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010675144804835246, "train/actor_opt_grad_steps": 46705.0, "train/actor_opt_loss": -13.651447333911857, "train/adv_mag": 1.0105042788061764, "train/adv_max": 0.2530431357940825, "train/adv_mean": 0.001230106485707546, "train/adv_min": -0.9743339549196829, "train/adv_std": 0.02883185861669112, "train/cont_avg": 0.9946820853960396, "train/cont_loss_mean": 0.017118718958054068, "train/cont_loss_std": 0.22720622713908112, "train/cont_neg_acc": 0.3357971581713398, "train/cont_neg_loss": 2.553464026972974, "train/cont_pos_acc": 0.99980561774556, "train/cont_pos_loss": 0.0037652358676694185, "train/cont_pred": 0.9945486804636399, "train/cont_rate": 0.9946820853960396, "train/dyn_loss_mean": 1.0000000525229047, "train/dyn_loss_std": 1.682548052954054e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1414474338652695, "train/extr_critic_critic_opt_grad_steps": 46705.0, "train/extr_critic_critic_opt_loss": 11212.660064395111, "train/extr_critic_mag": 1.56070873996999, "train/extr_critic_max": 1.56070873996999, "train/extr_critic_mean": 1.464907710505004, "train/extr_critic_min": 1.361268966504843, "train/extr_critic_std": 0.023282079016882003, "train/extr_return_normed_mag": 1.020987867128731, "train/extr_return_normed_max": 0.3106534298103635, "train/extr_return_normed_mean": 0.04658185540338849, "train/extr_return_normed_min": -0.9486856661220588, "train/extr_return_normed_std": 0.03803583535153677, "train/extr_return_rate": 0.9996438970660219, "train/extr_return_raw_mag": 1.7302079838101228, "train/extr_return_raw_max": 1.7302079838101228, "train/extr_return_raw_mean": 1.4661364956657486, "train/extr_return_raw_min": 0.47086888787770037, "train/extr_return_raw_std": 0.03803583528698966, "train/extr_reward_mag": 0.3044639566157124, "train/extr_reward_max": 0.3044639566157124, "train/extr_reward_mean": 0.0023021865042507426, "train/extr_reward_min": 9.08823296575263e-08, "train/extr_reward_std": 0.009314547776991483, "train/image_loss_mean": 0.08095849408666686, "train/image_loss_std": 0.09600798785686493, "train/model_loss_mean": 0.7119834290282561, "train/model_loss_std": 0.4368608681724803, "train/model_opt_grad_norm": 20.813109209041784, "train/model_opt_grad_steps": 46666.376237623765, "train/model_opt_loss": 3950.258618647509, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5544.554455445545, "train/policy_entropy_mag": 1.3274568478659827, "train/policy_entropy_max": 1.3274568478659827, "train/policy_entropy_mean": 0.1022883140214599, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1314058357683739, "train/policy_logprob_mag": 6.551080248143413, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10211852886299096, "train/policy_logprob_min": -6.551080248143413, "train/policy_logprob_std": 0.6387436791221694, "train/policy_randomness_mag": 0.6821779130709054, "train/policy_randomness_max": 0.6821779130709054, "train/policy_randomness_mean": 0.0525657976285951, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06752924490166773, "train/post_ent_mag": 28.900561483779757, "train/post_ent_max": 28.900561483779757, "train/post_ent_mean": 28.720694919623952, "train/post_ent_min": 28.582027548610576, "train/post_ent_std": 0.0654369207043754, "train/prior_ent_mag": 29.140339851379395, "train/prior_ent_max": 29.140339851379395, "train/prior_ent_mean": 27.98707856282149, "train/prior_ent_min": 26.95937447500701, "train/prior_ent_std": 0.3325424729892523, "train/rep_loss_mean": 1.0000000525229047, "train/rep_loss_std": 1.682548052954054e-06, "train/reward_avg": 0.0018850496506472901, "train/reward_loss_mean": 0.01390616265056415, "train/reward_loss_std": 0.20934674474134082, "train/reward_max_data": 0.7311417084224153, "train/reward_max_pred": 0.2554941555060963, "train/reward_neg_acc": 0.9996024514779006, "train/reward_neg_loss": 0.0025841759593862265, "train/reward_pos_acc": 0.2137907289360699, "train/reward_pos_loss": 3.8789673529173196, "train/reward_pred": 0.0015549926786904804, "train/reward_rate": 0.002900680693069307, "train_stats/mean_log_entropy": 0.0851885261871512, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.013104883022606373, "report/cont_loss_std": 0.1893085539340973, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.1494507789611816, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0026223217137157917, "report/cont_pred": 0.9956173896789551, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06896793842315674, "report/image_loss_std": 0.08393712341785431, "report/model_loss_mean": 0.6926578283309937, "report/model_loss_std": 0.4033743441104889, "report/post_ent_mag": 28.90254020690918, "report/post_ent_max": 28.90254020690918, "report/post_ent_mean": 28.716163635253906, "report/post_ent_min": 28.56505584716797, "report/post_ent_std": 0.07056534290313721, "report/prior_ent_mag": 29.27573013305664, "report/prior_ent_max": 29.27573013305664, "report/prior_ent_mean": 28.084148406982422, "report/prior_ent_min": 27.17815399169922, "report/prior_ent_std": 0.3381868600845337, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001129150390625, "report/reward_loss_mean": 0.010584966279566288, "report/reward_loss_std": 0.2080584168434143, "report/reward_max_data": 0.621874988079071, "report/reward_max_pred": 0.028612256050109863, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.001415481325238943, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.696191787719727, "report/reward_pred": 0.0007395282154902816, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.030549945309758186, "eval/cont_loss_std": 0.5124786496162415, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.861017227172852, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.004603422246873379, "eval/cont_pred": 0.9965395927429199, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13511988520622253, "eval/image_loss_std": 0.1353117674589157, "eval/model_loss_mean": 0.7767050266265869, "eval/model_loss_std": 0.6647102236747742, "eval/post_ent_mag": 28.904632568359375, "eval/post_ent_max": 28.904632568359375, "eval/post_ent_mean": 28.700468063354492, "eval/post_ent_min": 28.533143997192383, "eval/post_ent_std": 0.06835874915122986, "eval/prior_ent_mag": 29.27573013305664, "eval/prior_ent_max": 29.27573013305664, "eval/prior_ent_mean": 28.04702377319336, "eval/prior_ent_min": 27.118396759033203, "eval/prior_ent_std": 0.3491176962852478, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0002655029238667339, "eval/reward_loss_mean": 0.011035194620490074, "eval/reward_loss_std": 0.2594928741455078, "eval/reward_max_data": 0.2718749940395355, "eval/reward_max_pred": 0.5752570629119873, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.003138577565550804, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.089275360107422, "eval/reward_pred": 0.0011779868509620428, "eval/reward_rate": 0.0009765625, "replay/size": 764449.0, "replay/inserts": 32256.0, "replay/samples": 32256.0, "replay/insert_wait_avg": 1.298847593485363e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.126750351890685e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.4050991208721493e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1622369289398, "timer/env.step_count": 4032.0, "timer/env.step_total": 39.98261308670044, "timer/env.step_frac": 0.03997612748254677, "timer/env.step_avg": 0.009916322690153878, "timer/env.step_min": 0.00798344612121582, "timer/env.step_max": 0.04695773124694824, "timer/replay._sample_count": 32256.0, "timer/replay._sample_total": 16.34400510787964, "timer/replay._sample_frac": 0.01634135393680221, "timer/replay._sample_avg": 0.0005066965869258321, "timer/replay._sample_min": 0.00038909912109375, "timer/replay._sample_max": 0.011340618133544922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4514.0, "timer/agent.policy_total": 48.82417321205139, "timer/agent.policy_frac": 0.04881625341301531, "timer/agent.policy_avg": 0.010816165975199687, "timer/agent.policy_min": 0.009145498275756836, "timer/agent.policy_max": 0.08921170234680176, "timer/dataset_train_count": 2016.0, "timer/dataset_train_total": 0.21980595588684082, "timer/dataset_train_frac": 0.00021977030102812982, "timer/dataset_train_avg": 0.0001090307320867266, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.001069784164428711, "timer/agent.train_count": 2016.0, "timer/agent.train_total": 899.3844957351685, "timer/agent.train_frac": 0.8992386060253428, "timer/agent.train_avg": 0.44612326177339706, "timer/agent.train_min": 0.43599486351013184, "timer/agent.train_max": 0.7048249244689941, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4779527187347412, "timer/agent.report_frac": 0.00047787518973154265, "timer/agent.report_avg": 0.2389763593673706, "timer/agent.report_min": 0.23198509216308594, "timer/agent.report_max": 0.24596762657165527, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8605588609341006e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 32.25022920363614}
{"step": 765224, "time": 24254.984119176865, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 765296, "time": 24257.408168554306, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 765336, "time": 24258.40798354149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 765808, "time": 24273.147030830383, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 765952, "time": 24277.534499168396, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 766008, "time": 24279.011034727097, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 766032, "time": 24279.995455265045, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 766096, "time": 24281.94948744774, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 766104, "time": 24281.978415966034, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 766200, "time": 24284.912272930145, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 766456, "time": 24292.68071603775, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 767040, "time": 24310.700641155243, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 767064, "time": 24311.212096452713, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 767080, "time": 24311.699601888657, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 767384, "time": 24320.918092250824, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 767400, "time": 24321.40683698654, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 767480, "time": 24323.840626478195, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 767696, "time": 24330.72820711136, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 767888, "time": 24336.60936808586, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 767968, "time": 24339.05503964424, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 768008, "time": 24340.054569721222, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 768024, "time": 24340.54968738556, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 768032, "time": 24341.019204854965, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 768296, "time": 24348.848371505737, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 768360, "time": 24350.80589032173, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 768632, "time": 24359.201936483383, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 768664, "time": 24360.180096387863, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 768752, "time": 24363.093677520752, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 768800, "time": 24364.55870127678, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 769224, "time": 24377.28253340721, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 769240, "time": 24377.79719400406, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 769272, "time": 24378.77293777466, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 769296, "time": 24379.720485687256, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 769368, "time": 24381.685477018356, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 769456, "time": 24384.609236955643, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 769736, "time": 24393.034881591797, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 769856, "time": 24396.9237344265, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 769872, "time": 24397.438205718994, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 769888, "time": 24397.927058935165, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 24402.53834271431, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 770016, "time": 24402.743017673492, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 770016, "time": 24402.809753656387, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 770016, "time": 24403.000608205795, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 770016, "time": 24403.028306484222, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 770016, "time": 24403.352764368057, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 770016, "time": 24403.816811561584, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 770016, "time": 24404.193367004395, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 770096, "time": 24407.1496489048, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 770344, "time": 24414.49882864952, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 770536, "time": 24420.460881710052, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 770536, "time": 24420.46777510643, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 770744, "time": 24426.777106523514, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 770744, "time": 24426.785385131836, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 770824, "time": 24429.24601006508, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 770824, "time": 24429.25337076187, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 770856, "time": 24430.247658491135, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 770992, "time": 24434.596493005753, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 771008, "time": 24435.088094472885, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 771064, "time": 24436.57208418846, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 771416, "time": 24447.251388549805, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 771520, "time": 24450.709706783295, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 771632, "time": 24454.114048957825, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 771920, "time": 24462.88206243515, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 772136, "time": 24469.25444841385, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 772320, "time": 24475.128832101822, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 772336, "time": 24475.62268471718, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 772480, "time": 24480.111974477768, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 772488, "time": 24480.141728401184, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 772704, "time": 24486.925800561905, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 772952, "time": 24494.2744474411, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 772976, "time": 24495.23349571228, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 773104, "time": 24499.144987344742, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 773120, "time": 24499.640509605408, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 773136, "time": 24500.137505054474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773304, "time": 24505.05481863022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773384, "time": 24507.48400425911, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 773416, "time": 24508.567853689194, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 773672, "time": 24516.390585184097, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 773832, "time": 24521.254405736923, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 773864, "time": 24522.228788137436, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 774048, "time": 24528.060338258743, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 774104, "time": 24529.555688858032, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 774240, "time": 24533.935311555862, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 774304, "time": 24535.90973830223, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 774464, "time": 24540.86622262001, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 774664, "time": 24546.73195695877, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 774664, "time": 24546.74043750763, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 774688, "time": 24547.718154907227, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 774792, "time": 24550.687208414078, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 774920, "time": 24554.60342311859, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 774928, "time": 24555.081849098206, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 775184, "time": 24562.88426065445, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 775216, "time": 24563.864651203156, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 775272, "time": 24565.372107982635, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 775336, "time": 24567.358330965042, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 775432, "time": 24570.391643047333, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 775544, "time": 24573.802231550217, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 775600, "time": 24575.744467496872, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 775944, "time": 24586.02144575119, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 776000, "time": 24587.956502199173, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 776048, "time": 24589.40696454048, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 776232, "time": 24594.794027090073, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 776424, "time": 24600.70669555664, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 776568, "time": 24605.089056015015, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 776600, "time": 24606.093849897385, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 776800, "time": 24612.375375270844, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 776840, "time": 24613.371594905853, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 776880, "time": 24614.809825897217, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 777208, "time": 24624.53072500229, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 777360, "time": 24629.45841741562, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 777392, "time": 24630.451184511185, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 777536, "time": 24634.807408571243, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 777600, "time": 24636.77553462982, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 777656, "time": 24638.2545838356, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 777808, "time": 24643.12648487091, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 777872, "time": 24645.092327594757, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 777880, "time": 24645.120970249176, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 777920, "time": 24646.571343898773, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 778040, "time": 24650.00919365883, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 778296, "time": 24658.366582393646, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 778648, "time": 24669.1980612278, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 778744, "time": 24672.11249399185, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 779016, "time": 24680.34009552002, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 779104, "time": 24683.20219182968, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 779272, "time": 24688.068880796432, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 779296, "time": 24689.122597694397, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 779352, "time": 24690.60424208641, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 779376, "time": 24691.551450252533, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 779656, "time": 24699.76024389267, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 779672, "time": 24700.25306582451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 779704, "time": 24701.233100414276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 779832, "time": 24705.112481355667, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 779952, "time": 24708.95010948181, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 24711.273415327072, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 780000, "time": 24711.81721520424, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 780000, "time": 24712.338170528412, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 780000, "time": 24713.39192008972, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 780000, "time": 24714.629042625427, "eval_episode/length": 205.0, "eval_episode/score": 0.359375, "eval_episode/reward_rate": 0.0048543689320388345}
{"step": 780000, "time": 24715.276169538498, "eval_episode/length": 193.0, "eval_episode/score": 0.3968749940395355, "eval_episode/reward_rate": 0.005154639175257732}
{"step": 780000, "time": 24716.352157354355, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 24716.360097408295, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 24716.367589235306, "eval_episode/length": 288.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.0034602076124567475}
{"step": 780000, "time": 24716.374989509583, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780080, "time": 24718.921682596207, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 780192, "time": 24722.359258890152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780272, "time": 24724.819252729416, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 780480, "time": 24731.15141773224, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 780520, "time": 24732.149601221085, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 780680, "time": 24737.01507639885, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 780704, "time": 24737.971999406815, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 780744, "time": 24738.96320939064, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 781208, "time": 24753.23245882988, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 781360, "time": 24758.165704727173, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 781744, "time": 24769.886273622513, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 781776, "time": 24770.865504026413, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 781936, "time": 24775.747195720673, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 781968, "time": 24776.726294755936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782048, "time": 24779.27029490471, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 782152, "time": 24782.21824169159, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 782280, "time": 24786.13260936737, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 782344, "time": 24788.08480811119, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 782368, "time": 24789.073148727417, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 782944, "time": 24806.704279899597, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 783040, "time": 24809.776776075363, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 783200, "time": 24814.679859161377, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 783200, "time": 24814.68737268448, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 783344, "time": 24819.11096763611, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 783416, "time": 24821.084275484085, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 783424, "time": 24821.553820610046, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 783448, "time": 24822.069766759872, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 783784, "time": 24832.364627599716, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 783920, "time": 24836.735880851746, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 784064, "time": 24841.227149248123, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 784136, "time": 24843.217799901962, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 784152, "time": 24843.710361003876, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 784256, "time": 24847.1199157238, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 784608, "time": 24857.886749267578, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 784888, "time": 24866.156287670135, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 784920, "time": 24867.143422842026, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 785000, "time": 24869.706743717194, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 785056, "time": 24871.608043909073, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 785216, "time": 24876.458144664764, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 785248, "time": 24877.47437095642, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 785304, "time": 24878.95588326454, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 785688, "time": 24890.642434358597, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 785976, "time": 24899.48975634575, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 786176, "time": 24905.7816324234, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 786248, "time": 24907.763106822968, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 786408, "time": 24912.66252040863, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 786488, "time": 24915.601639270782, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 786856, "time": 24926.89754676819, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 786984, "time": 24930.91635942459, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 787216, "time": 24938.307931661606, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 787224, "time": 24938.33936214447, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 787320, "time": 24941.30429840088, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 787520, "time": 24947.649391651154, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 787576, "time": 24949.1342689991, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 787608, "time": 24950.116003274918, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 787704, "time": 24953.061990976334, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 787896, "time": 24959.005028247833, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 787912, "time": 24959.506546020508, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 788016, "time": 24962.914833068848, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 788104, "time": 24965.371389389038, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 788200, "time": 24968.30059528351, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 788456, "time": 24976.111729860306, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 788504, "time": 24977.57501268387, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 788552, "time": 24979.034574747086, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 788832, "time": 24987.876283168793, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 788840, "time": 24987.905704021454, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 788992, "time": 24992.848562717438, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 789144, "time": 24997.27728009224, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 789224, "time": 24999.7089240551, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 789400, "time": 25005.090916872025, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 789520, "time": 25008.94095635414, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 789688, "time": 25013.830027341843, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 789912, "time": 25020.76016974449, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 789960, "time": 25022.22480916977, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 789968, "time": 25022.697917222977, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 789984, "time": 25023.18652319908, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 25026.82178092003, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 790088, "time": 25027.180235624313, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 790088, "time": 25027.57023525238, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 790088, "time": 25027.764306545258, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 790088, "time": 25027.862287282944, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 790088, "time": 25028.29216194153, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 790088, "time": 25029.372030973434, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 790088, "time": 25029.64987063408, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 790192, "time": 25033.075329065323, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 790264, "time": 25035.048734903336, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 790416, "time": 25039.90905356407, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 790648, "time": 25046.743588209152, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 790680, "time": 25047.744572877884, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 790784, "time": 25051.234558582306, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 790808, "time": 25051.75724506378, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 790984, "time": 25057.137744426727, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 791024, "time": 25058.617740631104, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 791080, "time": 25060.104985952377, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 791224, "time": 25064.507395029068, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 791320, "time": 25067.439808368683, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 791320, "time": 25067.449102163315, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 791512, "time": 25073.28019118309, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 791560, "time": 25074.745087623596, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 791576, "time": 25075.237495660782, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 791600, "time": 25076.199475049973, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 791760, "time": 25081.180636167526, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 792112, "time": 25092.020375967026, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 792176, "time": 25093.993934631348, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 792256, "time": 25096.433824300766, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 792360, "time": 25099.40506052971, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 792360, "time": 25099.41201376915, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 792568, "time": 25105.744554758072, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 792672, "time": 25109.272244930267, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 792728, "time": 25110.75775027275, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 792896, "time": 25116.13564991951, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 792912, "time": 25116.65416121483, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 793216, "time": 25125.929454803467, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 793240, "time": 25126.484734535217, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 793520, "time": 25137.210390806198, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 793584, "time": 25139.275845766068, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 793632, "time": 25140.73806452751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 793768, "time": 25144.687539339066, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 793888, "time": 25148.58090686798, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 794016, "time": 25152.46393942833, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 794152, "time": 25156.371741771698, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 794312, "time": 25161.23697257042, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 794400, "time": 25164.1521692276, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 794504, "time": 25167.133821249008, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 794664, "time": 25172.638818979263, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 794856, "time": 25178.49908566475, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 794856, "time": 25178.50700902939, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 795072, "time": 25185.28184247017, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 795088, "time": 25185.77196455002, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 795112, "time": 25186.28486943245, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 795216, "time": 25189.698890924454, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 795600, "time": 25201.44969177246, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 795744, "time": 25205.82757639885, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 795832, "time": 25208.280277729034, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 796000, "time": 25213.59401869774, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 796016, "time": 25214.084377527237, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 796040, "time": 25214.595071077347, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 796192, "time": 25219.43657398224, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 796216, "time": 25219.951277256012, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 796264, "time": 25221.412158489227, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 796320, "time": 25223.351328849792, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 796600, "time": 25231.73788833618, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 796760, "time": 25236.610127687454, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 797081, "time": 25247.37852859497, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1909106809701493, "train/action_min": 0.0, "train/action_std": 1.7244614623672334, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012132996090905583, "train/actor_opt_grad_steps": 48720.0, "train/actor_opt_loss": -13.428347805839273, "train/adv_mag": 1.068028993274442, "train/adv_max": 0.3229124457088869, "train/adv_mean": 0.0024948113724480464, "train/adv_min": -1.0110926396811186, "train/adv_std": 0.03428589111073545, "train/cont_avg": 0.9945050139925373, "train/cont_loss_mean": 0.01840043850289426, "train/cont_loss_std": 0.23750543614747513, "train/cont_neg_acc": 0.29983237407990354, "train/cont_neg_loss": 2.6368725299812037, "train/cont_pos_acc": 0.9998484778760085, "train/cont_pos_loss": 0.0038134910534622507, "train/cont_pred": 0.9946920557401666, "train/cont_rate": 0.9945050139925373, "train/dyn_loss_mean": 1.0000006446790932, "train/dyn_loss_std": 2.0619766758893852e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1616860515349985, "train/extr_critic_critic_opt_grad_steps": 48720.0, "train/extr_critic_critic_opt_loss": 7096.260133657883, "train/extr_critic_mag": 1.6227478589584579, "train/extr_critic_max": 1.6227478589584579, "train/extr_critic_mean": 1.525983118892309, "train/extr_critic_min": 1.4229433002756602, "train/extr_critic_std": 0.024843003647170257, "train/extr_return_normed_mag": 1.0720112323760986, "train/extr_return_normed_max": 0.3884381470988639, "train/extr_return_normed_mean": 0.050390443685858405, "train/extr_return_normed_min": -0.9742127734037181, "train/extr_return_normed_std": 0.04394869257079725, "train/extr_return_rate": 0.9995818823131163, "train/extr_return_raw_mag": 1.8665244947025432, "train/extr_return_raw_max": 1.8665244947025432, "train/extr_return_raw_mean": 1.5284768615789082, "train/extr_return_raw_min": 0.5038735741999611, "train/extr_return_raw_std": 0.0439486927283344, "train/extr_reward_mag": 0.3870223547095683, "train/extr_reward_max": 0.3870223547095683, "train/extr_reward_mean": 0.002511425443058509, "train/extr_reward_min": 8.006594074306204e-08, "train/extr_reward_std": 0.011380659872712336, "train/image_loss_mean": 0.08173964042865221, "train/image_loss_std": 0.0976765136887778, "train/model_loss_mean": 0.7152813305309162, "train/model_loss_std": 0.4611192638082291, "train/model_opt_grad_norm": 21.343097663044336, "train/model_opt_grad_steps": 48679.39800995025, "train/model_opt_loss": 3683.9575960529382, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5149.253731343284, "train/policy_entropy_mag": 1.3523916296697969, "train/policy_entropy_max": 1.3523916296697969, "train/policy_entropy_mean": 0.10178649325424166, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1311937811511073, "train/policy_logprob_mag": 6.551080248249111, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10118358052192043, "train/policy_logprob_min": -6.551080248249111, "train/policy_logprob_std": 0.6363734276733588, "train/policy_randomness_mag": 0.6949918569617011, "train/policy_randomness_max": 0.6949918569617011, "train/policy_randomness_mean": 0.052307912570178805, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0674202708499645, "train/post_ent_mag": 28.93760415452037, "train/post_ent_max": 28.93760415452037, "train/post_ent_mean": 28.749532851413708, "train/post_ent_min": 28.59660601260057, "train/post_ent_std": 0.07098369606172861, "train/prior_ent_mag": 29.170143497523977, "train/prior_ent_max": 29.170143497523977, "train/prior_ent_mean": 27.99859413222887, "train/prior_ent_min": 27.009168520495667, "train/prior_ent_std": 0.3490396760292907, "train/rep_loss_mean": 1.0000006446790932, "train/rep_loss_std": 2.0619766758893852e-05, "train/reward_avg": 0.0021281987286041913, "train/reward_loss_mean": 0.01514084237762055, "train/reward_loss_std": 0.2244573460372897, "train/reward_max_data": 0.7665578358950307, "train/reward_max_pred": 0.24925800223848713, "train/reward_neg_acc": 0.9995662240839717, "train/reward_neg_loss": 0.002723825143578356, "train/reward_pos_acc": 0.1630643988365954, "train/reward_pos_loss": 4.005269058010121, "train/reward_pred": 0.0016102764184415265, "train/reward_rate": 0.0031337453358208957, "train_stats/mean_log_entropy": 0.08865683319476934, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.011823877692222595, "report/cont_loss_std": 0.15185007452964783, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 1.9990339279174805, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004030896816402674, "report/cont_pred": 0.9948687553405762, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09077826142311096, "report/image_loss_std": 0.10068171471357346, "report/model_loss_mean": 0.7159291505813599, "report/model_loss_std": 0.37301668524742126, "report/post_ent_mag": 29.069608688354492, "report/post_ent_max": 29.069608688354492, "report/post_ent_mean": 28.89014434814453, "report/post_ent_min": 28.747947692871094, "report/post_ent_std": 0.06970206648111343, "report/prior_ent_mag": 29.28681182861328, "report/prior_ent_max": 29.28681182861328, "report/prior_ent_mean": 28.55467987060547, "report/prior_ent_min": 27.649818420410156, "report/prior_ent_std": 0.3044857382774353, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0020416260231286287, "report/reward_loss_mean": 0.013326985761523247, "report/reward_loss_std": 0.19214709103107452, "report/reward_max_data": 0.8656250238418579, "report/reward_max_pred": 0.09871840476989746, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0031765075400471687, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.4678726196289062, "report/reward_pred": 0.001821274752728641, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03653673082590103, "eval/cont_loss_std": 0.5051915049552917, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.994511604309082, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0023955381475389004, "eval/cont_pred": 0.9976941347122192, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17152369022369385, "eval/image_loss_std": 0.14560608565807343, "eval/model_loss_mean": 0.8346788883209229, "eval/model_loss_std": 0.9643842577934265, "eval/post_ent_mag": 29.060636520385742, "eval/post_ent_max": 29.060636520385742, "eval/post_ent_mean": 28.873180389404297, "eval/post_ent_min": 28.74022674560547, "eval/post_ent_std": 0.06672979891300201, "eval/prior_ent_mag": 29.306034088134766, "eval/prior_ent_max": 29.306034088134766, "eval/prior_ent_mean": 28.490955352783203, "eval/prior_ent_min": 27.516845703125, "eval/prior_ent_std": 0.3143846392631531, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0020996094681322575, "eval/reward_loss_mean": 0.026618432253599167, "eval/reward_loss_std": 0.4772467017173767, "eval/reward_max_data": 0.828125, "eval/reward_max_pred": 0.15474653244018555, "eval/reward_neg_acc": 0.9980410933494568, "eval/reward_neg_loss": 0.0020470074377954006, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.389093399047852, "eval/reward_pred": 0.001048271544277668, "eval/reward_rate": 0.0029296875, "replay/size": 796577.0, "replay/inserts": 32128.0, "replay/samples": 32128.0, "replay/insert_wait_avg": 1.2939669696458308e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.207957345650966e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.154303979530609e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3541424274445, "timer/env.step_count": 4016.0, "timer/env.step_total": 40.05275583267212, "timer/env.step_frac": 0.04003857647400819, "timer/env.step_avg": 0.009973295775067758, "timer/env.step_min": 0.008130788803100586, "timer/env.step_max": 0.041036367416381836, "timer/replay._sample_count": 32128.0, "timer/replay._sample_total": 16.509004831314087, "timer/replay._sample_frac": 0.016503160362042968, "timer/replay._sample_avg": 0.0005138509969906028, "timer/replay._sample_min": 0.00039958953857421875, "timer/replay._sample_max": 0.030833959579467773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4572.0, "timer/agent.policy_total": 49.257750272750854, "timer/agent.policy_frac": 0.0492403121890641, "timer/agent.policy_avg": 0.010773786148895638, "timer/agent.policy_min": 0.009068489074707031, "timer/agent.policy_max": 0.08231282234191895, "timer/dataset_train_count": 2008.0, "timer/dataset_train_total": 0.22098970413208008, "timer/dataset_train_frac": 0.00022091147000784117, "timer/dataset_train_avg": 0.00011005463353191238, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0006880760192871094, "timer/agent.train_count": 2008.0, "timer/agent.train_total": 898.6858153343201, "timer/agent.train_frac": 0.8983676652286184, "timer/agent.train_avg": 0.44755269687964144, "timer/agent.train_min": 0.4323594570159912, "timer/agent.train_max": 2.3823795318603516, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48042726516723633, "timer/agent.report_frac": 0.0004802571857216872, "timer/agent.report_avg": 0.24021363258361816, "timer/agent.report_min": 0.23487067222595215, "timer/agent.report_max": 0.24555659294128418, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.076957702636719e-05, "timer/dataset_eval_frac": 4.075514390077532e-08, "timer/dataset_eval_avg": 4.076957702636719e-05, "timer/dataset_eval_min": 4.076957702636719e-05, "timer/dataset_eval_max": 4.076957702636719e-05, "fps": 32.116081631863246}
{"step": 797136, "time": 25249.038580179214, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 797168, "time": 25250.017167568207, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 797232, "time": 25251.982679605484, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 797272, "time": 25252.982301712036, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 797328, "time": 25254.899919509888, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 797392, "time": 25256.887797117233, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 797400, "time": 25256.91778898239, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 797448, "time": 25258.421504735947, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 797496, "time": 25259.968008756638, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 797736, "time": 25267.32307934761, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 797872, "time": 25271.72305703163, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 797888, "time": 25272.216453790665, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 798048, "time": 25277.122809171677, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 798496, "time": 25291.010689020157, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 798640, "time": 25295.447642564774, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 798784, "time": 25299.85708808899, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 798856, "time": 25301.85022854805, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 798888, "time": 25302.82949566841, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 798912, "time": 25303.78819322586, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 798992, "time": 25306.2448720932, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 799072, "time": 25308.66725063324, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 799360, "time": 25317.40219759941, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 799424, "time": 25319.407757997513, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 799544, "time": 25322.83931875229, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 799616, "time": 25325.224160432816, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 799688, "time": 25327.20398235321, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 799712, "time": 25328.15239596367, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 799816, "time": 25331.117608070374, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 25340.30108141899, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 800072, "time": 25340.368710279465, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 800072, "time": 25340.773006677628, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 800072, "time": 25343.623157262802, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 800072, "time": 25345.216286420822, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 25345.224873542786, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 25345.231660842896, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 25345.238839626312, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 25345.245394945145, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800224, "time": 25350.249935865402, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 800360, "time": 25354.166340351105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 800528, "time": 25359.52658390999, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 800536, "time": 25359.556917905807, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 800592, "time": 25361.490075826645, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 800952, "time": 25372.249596834183, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 800992, "time": 25373.680018901825, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 801024, "time": 25374.662608861923, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 801272, "time": 25382.051998138428, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 801344, "time": 25384.45591545105, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 801856, "time": 25399.946543455124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802024, "time": 25404.851580381393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802032, "time": 25405.341153621674, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 802032, "time": 25405.3502805233, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 802080, "time": 25406.822056531906, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 802264, "time": 25412.328401327133, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 802584, "time": 25422.05799460411, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 802848, "time": 25430.844532251358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 803064, "time": 25437.174262046814, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 803080, "time": 25437.668076992035, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 803192, "time": 25441.18244576454, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 803264, "time": 25443.62969493866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 803336, "time": 25445.66796731949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 803944, "time": 25464.246399641037, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 803976, "time": 25465.255516529083, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 803984, "time": 25465.729006290436, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 803992, "time": 25465.75813627243, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 804088, "time": 25468.783125162125, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 804200, "time": 25472.212719917297, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 804448, "time": 25480.019943237305, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 804576, "time": 25483.905223846436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804616, "time": 25484.921361207962, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 804704, "time": 25487.807688474655, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 804840, "time": 25491.725489854813, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 804888, "time": 25493.193424463272, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 804904, "time": 25493.69541311264, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 805096, "time": 25499.735726118088, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 805160, "time": 25501.67249107361, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 805280, "time": 25505.547711372375, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 805296, "time": 25506.043771743774, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 805328, "time": 25507.028212308884, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 805536, "time": 25513.36167383194, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 805632, "time": 25516.29275918007, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 805744, "time": 25519.70646548271, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 805848, "time": 25522.61411190033, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 805928, "time": 25525.05100274086, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 806224, "time": 25534.303381204605, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 806280, "time": 25535.77127289772, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 806296, "time": 25536.26237797737, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 806320, "time": 25537.21111178398, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 806888, "time": 25554.23087120056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 807112, "time": 25561.168402910233, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 807160, "time": 25562.659730911255, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 807400, "time": 25570.01020383835, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 807552, "time": 25574.88355898857, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 807928, "time": 25586.09068632126, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 808056, "time": 25590.074921369553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808240, "time": 25595.87149167061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808536, "time": 25604.683721780777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808576, "time": 25606.121230125427, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 808896, "time": 25615.892797470093, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 808928, "time": 25616.89067864418, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 809096, "time": 25621.90570139885, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 809104, "time": 25622.38328385353, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 809200, "time": 25625.306807756424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809472, "time": 25633.62122964859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809664, "time": 25639.4647397995, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 809864, "time": 25645.364808321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 25652.60368514061, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 810056, "time": 25653.771181106567, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 810056, "time": 25653.83757853508, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 810056, "time": 25654.05378651619, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 810056, "time": 25654.212691783905, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 810056, "time": 25654.458906412125, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 810056, "time": 25655.073868989944, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 810056, "time": 25655.20616054535, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 810096, "time": 25656.648950576782, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 810192, "time": 25659.587201833725, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 810424, "time": 25666.436217546463, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 810480, "time": 25668.38210582733, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 810752, "time": 25676.705117702484, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 810800, "time": 25678.161583662033, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 811056, "time": 25686.534083127975, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 811144, "time": 25688.9872879982, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 811208, "time": 25690.949466466904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 811216, "time": 25691.422949552536, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 811240, "time": 25691.937811613083, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 811768, "time": 25707.952655553818, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 811912, "time": 25712.424491882324, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 811944, "time": 25713.397844552994, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 812112, "time": 25718.737827777863, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 812160, "time": 25720.219834327698, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 812216, "time": 25721.715974330902, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 812224, "time": 25722.19006562233, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 812304, "time": 25724.645753622055, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 812496, "time": 25730.519252300262, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 812616, "time": 25734.007643461227, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 812712, "time": 25736.92389369011, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 812784, "time": 25739.45872950554, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 812800, "time": 25739.952367782593, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 813120, "time": 25749.700843334198, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 813208, "time": 25752.17493534088, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 813488, "time": 25760.973856687546, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 813528, "time": 25761.974169254303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813640, "time": 25765.409140348434, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 813664, "time": 25766.369936466217, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 813792, "time": 25770.340007066727, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 813944, "time": 25774.759546518326, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 814152, "time": 25781.101875782013, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 814352, "time": 25787.442959308624, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 814472, "time": 25790.873210191727, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 814472, "time": 25790.88738179207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 814528, "time": 25792.83410358429, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 814680, "time": 25797.248344182968, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 814960, "time": 25806.051310300827, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 815024, "time": 25808.00666999817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 815032, "time": 25808.03434085846, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 815368, "time": 25818.272887706757, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 815744, "time": 25829.976933717728, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 815760, "time": 25830.467028856277, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 815928, "time": 25835.342168569565, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 815952, "time": 25836.314145088196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 816048, "time": 25839.217571496964, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 816384, "time": 25849.477919578552, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 816560, "time": 25854.821918725967, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 816600, "time": 25855.826384544373, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 816768, "time": 25861.233918905258, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 816784, "time": 25861.723326206207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 816888, "time": 25864.650847434998, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 816912, "time": 25865.625121355057, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 817168, "time": 25873.41650724411, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 817232, "time": 25875.39595556259, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 817272, "time": 25876.39533305168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817432, "time": 25881.308485031128, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 817736, "time": 25890.710081338882, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 817824, "time": 25893.58570957184, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 817944, "time": 25897.051694869995, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 817992, "time": 25898.50538253784, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 818064, "time": 25900.930623054504, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 818224, "time": 25905.781601428986, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 818248, "time": 25906.296092271805, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 818448, "time": 25912.59791278839, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 818560, "time": 25916.05979657173, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 818560, "time": 25916.078576803207, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 818608, "time": 25917.56454348564, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 818864, "time": 25925.469876766205, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 818896, "time": 25926.444881916046, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 818896, "time": 25926.453095674515, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 818976, "time": 25928.85788154602, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 819112, "time": 25932.747584581375, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 819120, "time": 25933.212931871414, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 819224, "time": 25936.613981962204, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 819328, "time": 25939.9985806942, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 819528, "time": 25945.875977754593, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 819624, "time": 25948.903272628784, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 819680, "time": 25950.869421720505, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 819736, "time": 25952.362179756165, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 819744, "time": 25952.83446121216, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 819912, "time": 25957.734802007675, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 819976, "time": 25959.691858291626, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 25962.321624994278, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 820040, "time": 25962.709115743637, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 820040, "time": 25963.2731924057, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 820040, "time": 25964.07137989998, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 820040, "time": 25964.117679834366, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 820040, "time": 25964.47361779213, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 820040, "time": 25964.767613887787, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 820040, "time": 25965.00948047638, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 820272, "time": 25972.32050061226, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 820368, "time": 25975.231191396713, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 820640, "time": 25983.618331432343, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 820648, "time": 25983.64697122574, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 820800, "time": 25988.466386795044, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 821024, "time": 25995.294098854065, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 821048, "time": 25995.806608438492, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 821104, "time": 25997.742104768753, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 821160, "time": 25999.228805541992, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 821200, "time": 26000.671073675156, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 821320, "time": 26004.1298391819, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 821528, "time": 26010.57437634468, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 821592, "time": 26012.53012561798, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 821656, "time": 26014.48551106453, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 821672, "time": 26014.979991674423, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 822000, "time": 26025.201809167862, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 822024, "time": 26025.719269037247, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 822288, "time": 26034.103778362274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822416, "time": 26038.010859012604, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 822480, "time": 26040.033135652542, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 822520, "time": 26041.047625541687, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 822936, "time": 26053.725656986237, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 822960, "time": 26054.688468933105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823040, "time": 26057.167261600494, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 823160, "time": 26060.689263105392, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 823464, "time": 26070.06138563156, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 823472, "time": 26070.55409359932, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 823616, "time": 26074.949286937714, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 823880, "time": 26082.78319144249, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 823888, "time": 26083.254362106323, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 824120, "time": 26090.11184644699, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 824368, "time": 26097.89559984207, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 824480, "time": 26101.450404405594, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 824528, "time": 26102.90840601921, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 824680, "time": 26107.325391054153, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 824728, "time": 26108.78690981865, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 824792, "time": 26110.764921188354, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 824864, "time": 26113.168749332428, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 824920, "time": 26114.679713726044, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 824944, "time": 26115.645196914673, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 825448, "time": 26130.87399816513, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 825664, "time": 26137.64449262619, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 825760, "time": 26140.584340572357, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 825792, "time": 26141.562169790268, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 826016, "time": 26148.385714054108, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 826088, "time": 26150.383956193924, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 826112, "time": 26151.34592103958, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 826432, "time": 26161.232890844345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 826808, "time": 26172.491605758667, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 826960, "time": 26177.325476408005, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 826968, "time": 26177.35671854019, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 827016, "time": 26178.830323934555, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 827112, "time": 26181.757092237473, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 827256, "time": 26186.13702225685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827304, "time": 26187.597316026688, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 827592, "time": 26197.05256462097, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 827624, "time": 26198.02524447441, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 827848, "time": 26204.883238554, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 827872, "time": 26205.83913707733, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 827896, "time": 26206.35667872429, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 827912, "time": 26206.846255779266, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 827960, "time": 26208.33078432083, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 828096, "time": 26212.700931549072, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 828600, "time": 26227.921887397766, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 828688, "time": 26230.812955856323, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 828704, "time": 26231.304507017136, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 828848, "time": 26235.69952392578, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 828992, "time": 26240.090483427048, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 829128, "time": 26244.02860045433, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 829209, "time": 26247.453605890274, "train_stats/mean_log_entropy": 0.08857871783545697, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.323375549316406, "train/action_min": 0.0, "train/action_std": 1.7868371254205704, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013736103862756864, "train/actor_opt_grad_steps": 50725.0, "train/actor_opt_loss": -16.501613403558732, "train/adv_mag": 1.1215242457389831, "train/adv_max": 0.27926986157894135, "train/adv_mean": 0.0021779161514132285, "train/adv_min": -1.082820526957512, "train/adv_std": 0.03531000418122858, "train/cont_avg": 0.9943701171875, "train/cont_loss_mean": 0.018778146337717773, "train/cont_loss_std": 0.23720876317936926, "train/cont_neg_acc": 0.2846143640950322, "train/cont_neg_loss": 2.6128496882272882, "train/cont_pos_acc": 0.9998919126391411, "train/cont_pos_loss": 0.003989257087232545, "train/cont_pred": 0.994475149512291, "train/cont_rate": 0.9943701171875, "train/dyn_loss_mean": 1.0000012338161468, "train/dyn_loss_std": 3.9461487904191014e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2661816237308085, "train/extr_critic_critic_opt_grad_steps": 50725.0, "train/extr_critic_critic_opt_loss": 4738.146257324219, "train/extr_critic_mag": 1.6757028996944427, "train/extr_critic_max": 1.6757028996944427, "train/extr_critic_mean": 1.5862373751401901, "train/extr_critic_min": 1.4742428547143935, "train/extr_critic_std": 0.025560172349214552, "train/extr_return_normed_mag": 1.123843938112259, "train/extr_return_normed_max": 0.35028930962085725, "train/extr_return_normed_mean": 0.05280719556845725, "train/extr_return_normed_min": -1.0506118267774582, "train/extr_return_normed_std": 0.045771331088617445, "train/extr_return_rate": 0.9995547246932983, "train/extr_return_raw_mag": 1.8858974903821946, "train/extr_return_raw_max": 1.8858974903821946, "train/extr_return_raw_mean": 1.5884154438972473, "train/extr_return_raw_min": 0.4849963539838791, "train/extr_return_raw_std": 0.04577133090235293, "train/extr_reward_mag": 0.34236205875873565, "train/extr_reward_max": 0.34236205875873565, "train/extr_reward_mean": 0.002637633574777283, "train/extr_reward_min": 1.1324882507324218e-07, "train/extr_reward_std": 0.010778467780910432, "train/image_loss_mean": 0.08119506629183888, "train/image_loss_std": 0.09671098755672575, "train/model_loss_mean": 0.7163001182675361, "train/model_loss_std": 0.4723173778876662, "train/model_opt_grad_norm": 20.83605968952179, "train/model_opt_grad_steps": 50682.475, "train/model_opt_loss": 3689.4421997070312, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5150.0, "train/policy_entropy_mag": 1.3471721225976945, "train/policy_entropy_max": 1.3471721225976945, "train/policy_entropy_mean": 0.10386264614760876, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13521355107426644, "train/policy_logprob_mag": 6.551080248355865, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1036841281875968, "train/policy_logprob_min": -6.551080248355865, "train/policy_logprob_std": 0.6406072002649307, "train/policy_randomness_mag": 0.6923095625638962, "train/policy_randomness_max": 0.6923095625638962, "train/policy_randomness_mean": 0.05337484436109662, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06948602348566055, "train/post_ent_mag": 29.094989490509032, "train/post_ent_max": 29.094989490509032, "train/post_ent_mean": 28.915413160324096, "train/post_ent_min": 28.765050897598268, "train/post_ent_std": 0.06856382796540857, "train/prior_ent_mag": 29.271422882080078, "train/prior_ent_max": 29.271422882080078, "train/prior_ent_mean": 28.288548631668093, "train/prior_ent_min": 27.41631428718567, "train/prior_ent_std": 0.2870171532779932, "train/rep_loss_mean": 1.0000012338161468, "train/rep_loss_std": 3.9461487904191014e-05, "train/reward_avg": 0.002265029895643238, "train/reward_loss_mean": 0.016326141763711347, "train/reward_loss_std": 0.23439038604497908, "train/reward_max_data": 0.7881249988079071, "train/reward_max_pred": 0.28020132184028623, "train/reward_neg_acc": 0.999465807378292, "train/reward_neg_loss": 0.002964451120933518, "train/reward_pos_acc": 0.17658931833838448, "train/reward_pos_loss": 3.9088834599795077, "train/reward_pred": 0.001757254409021698, "train/reward_rate": 0.003408203125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.021635573357343674, "report/cont_loss_std": 0.22563238441944122, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 2.1449334621429443, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0049166930839419365, "report/cont_pred": 0.9928785562515259, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07759594172239304, "report/image_loss_std": 0.09856874495744705, "report/model_loss_mean": 0.7176088094711304, "report/model_loss_std": 0.45402246713638306, "report/post_ent_mag": 29.390762329101562, "report/post_ent_max": 29.390762329101562, "report/post_ent_mean": 29.228063583374023, "report/post_ent_min": 29.07840347290039, "report/post_ent_std": 0.06416233628988266, "report/prior_ent_mag": 29.65746307373047, "report/prior_ent_max": 29.65746307373047, "report/prior_ent_mean": 28.96358871459961, "report/prior_ent_min": 28.133766174316406, "report/prior_ent_std": 0.2576347589492798, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003570556640625, "report/reward_loss_mean": 0.018377240747213364, "report/reward_loss_std": 0.2257392257452011, "report/reward_max_data": 0.8062499761581421, "report/reward_max_pred": 0.6491347551345825, "report/reward_neg_acc": 0.999018669128418, "report/reward_neg_loss": 0.0039721024222671986, "report/reward_pos_acc": 0.4000000059604645, "report/reward_pos_loss": 2.9541447162628174, "report/reward_pred": 0.0029164464212954044, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03866812586784363, "eval/cont_loss_std": 0.5921032428741455, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.296743869781494, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0030544090550392866, "eval/cont_pred": 0.9970504641532898, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13132795691490173, "eval/image_loss_std": 0.1485476940870285, "eval/model_loss_mean": 0.7854975461959839, "eval/model_loss_std": 0.7442983984947205, "eval/post_ent_mag": 29.394840240478516, "eval/post_ent_max": 29.394840240478516, "eval/post_ent_mean": 29.20096778869629, "eval/post_ent_min": 29.07330894470215, "eval/post_ent_std": 0.06255115568637848, "eval/prior_ent_mag": 29.65746307373047, "eval/prior_ent_max": 29.65746307373047, "eval/prior_ent_mean": 28.917211532592773, "eval/prior_ent_min": 27.793182373046875, "eval/prior_ent_std": 0.26533830165863037, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.00213623046875, "eval/reward_loss_mean": 0.015501405112445354, "eval/reward_loss_std": 0.25406119227409363, "eval/reward_max_data": 0.8343750238418579, "eval/reward_max_pred": 0.2060917615890503, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.0019550940487533808, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.625762939453125, "eval/reward_pred": 0.0010659550316631794, "eval/reward_rate": 0.0029296875, "replay/size": 828705.0, "replay/inserts": 32128.0, "replay/samples": 32128.0, "replay/insert_wait_avg": 1.316793648845171e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.215897705450475e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5200.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.152799679682805e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0597672462463, "timer/env.step_count": 4016.0, "timer/env.step_total": 39.767669439315796, "timer/env.step_frac": 0.03976529277727032, "timer/env.step_avg": 0.00990230812731967, "timer/env.step_min": 0.007998943328857422, "timer/env.step_max": 0.035924434661865234, "timer/replay._sample_count": 32128.0, "timer/replay._sample_total": 16.399681091308594, "timer/replay._sample_frac": 0.016398700986108638, "timer/replay._sample_avg": 0.0005104482411388382, "timer/replay._sample_min": 0.00040340423583984375, "timer/replay._sample_max": 0.010793209075927734, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4666.0, "timer/agent.policy_total": 50.21199131011963, "timer/agent.policy_frac": 0.050208990457023206, "timer/agent.policy_avg": 0.010761249744989205, "timer/agent.policy_min": 0.008698463439941406, "timer/agent.policy_max": 0.0884866714477539, "timer/dataset_train_count": 2008.0, "timer/dataset_train_total": 0.2171616554260254, "timer/dataset_train_frac": 0.0002171486770475722, "timer/dataset_train_avg": 0.00010814823477391703, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.00033855438232421875, "timer/agent.train_count": 2008.0, "timer/agent.train_total": 897.3644971847534, "timer/agent.train_frac": 0.8973108673851828, "timer/agent.train_avg": 0.4468946699127258, "timer/agent.train_min": 0.4338490962982178, "timer/agent.train_max": 0.700824499130249, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4806334972381592, "timer/agent.report_frac": 0.00048060477281435524, "timer/agent.report_avg": 0.2403167486190796, "timer/agent.report_min": 0.23295116424560547, "timer/agent.report_max": 0.2476823329925537, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146937160372439e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 32.12554212991144}
{"step": 829280, "time": 26249.75055861473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829328, "time": 26251.239733219147, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 829368, "time": 26252.23941230774, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 829424, "time": 26254.213685274124, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 829424, "time": 26254.22679042816, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 829704, "time": 26262.613572120667, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 829816, "time": 26266.07194685936, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 829856, "time": 26267.527156352997, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 829896, "time": 26268.582285165787, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 830000, "time": 26272.05850982666, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 26273.838082551956, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 830024, "time": 26274.497704267502, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 830024, "time": 26274.69855260849, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 830024, "time": 26275.506888389587, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 830024, "time": 26275.5359082222, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 830024, "time": 26275.605835676193, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 830024, "time": 26275.713224887848, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 830024, "time": 26277.504429101944, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 830320, "time": 26286.854995250702, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 830712, "time": 26298.495964050293, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 830752, "time": 26299.92911672592, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 830760, "time": 26299.957507371902, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 831160, "time": 26312.2435567379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831168, "time": 26312.718460559845, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 831416, "time": 26320.042313337326, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 831456, "time": 26321.52245616913, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 831592, "time": 26325.426460027695, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 831736, "time": 26329.798744916916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831784, "time": 26331.264508724213, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 832168, "time": 26343.09914112091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832312, "time": 26347.49535012245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832592, "time": 26356.269708633423, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 832864, "time": 26364.521599054337, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 832912, "time": 26366.034637451172, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 832992, "time": 26368.532567739487, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 833008, "time": 26369.03761458397, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 833480, "time": 26383.18953728676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 833496, "time": 26383.68408179283, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 833728, "time": 26390.967953443527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 833728, "time": 26390.975791931152, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 833768, "time": 26391.973762512207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 833792, "time": 26392.94016098976, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 833792, "time": 26392.947610616684, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 834080, "time": 26401.8079123497, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 834312, "time": 26408.657697200775, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 834792, "time": 26423.208550691605, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 834896, "time": 26426.62504196167, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 835072, "time": 26432.143306970596, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 835184, "time": 26435.555371284485, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 835392, "time": 26441.882424354553, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 835448, "time": 26443.359204769135, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 835784, "time": 26454.040881872177, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 835952, "time": 26459.49476456642, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 836040, "time": 26461.986201763153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 836104, "time": 26463.957048416138, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 836216, "time": 26470.26131606102, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 836224, "time": 26470.733703136444, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 836624, "time": 26482.86540699005, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 836744, "time": 26486.270515203476, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 836848, "time": 26489.755215406418, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 837088, "time": 26497.074914216995, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 837376, "time": 26505.813083410263, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 837408, "time": 26506.802443742752, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 837616, "time": 26513.08948779106, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 837680, "time": 26515.0419652462, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 837760, "time": 26517.48353099823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 837760, "time": 26517.48991250992, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 837880, "time": 26520.985929489136, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 837968, "time": 26523.867833137512, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 838256, "time": 26532.623430490494, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 838264, "time": 26532.65194940567, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 838592, "time": 26542.80537056923, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 838632, "time": 26543.79736971855, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 838680, "time": 26545.26640367508, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 838736, "time": 26547.165261745453, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 838992, "time": 26555.046140670776, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 839280, "time": 26563.876971006393, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 839304, "time": 26564.38997030258, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 839624, "time": 26574.1110162735, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 839664, "time": 26575.55750989914, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 839768, "time": 26578.51148533821, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 839824, "time": 26580.458696603775, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 839856, "time": 26581.431654691696, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 26586.47218799591, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 840008, "time": 26587.825732946396, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 840008, "time": 26587.886071681976, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 840008, "time": 26588.34041452408, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 840008, "time": 26588.383087158203, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 840008, "time": 26588.410222530365, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 840008, "time": 26588.45776104927, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 840008, "time": 26588.648109197617, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 840104, "time": 26591.540546894073, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 840176, "time": 26593.94935154915, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 840376, "time": 26599.754532814026, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 840512, "time": 26604.08804321289, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 840640, "time": 26607.97767162323, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 840912, "time": 26616.309643030167, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 840928, "time": 26616.796151399612, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 840992, "time": 26618.723641872406, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 841192, "time": 26624.52113556862, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 841192, "time": 26624.532478809357, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 841240, "time": 26626.000472068787, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 841336, "time": 26628.890813350677, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 841336, "time": 26628.898480415344, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 841560, "time": 26635.657382011414, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 841568, "time": 26636.127574682236, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 841840, "time": 26644.468064069748, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 842152, "time": 26653.618836164474, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 842480, "time": 26663.685099601746, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 842544, "time": 26665.636899471283, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 842680, "time": 26669.618114948273, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 842816, "time": 26673.91283917427, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 843240, "time": 26686.508857011795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843480, "time": 26693.72943663597, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 843480, "time": 26693.737181186676, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 843552, "time": 26696.119254112244, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 843688, "time": 26700.091763973236, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 843784, "time": 26703.181282758713, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 844072, "time": 26712.2032494545, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 844128, "time": 26714.130764722824, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 844152, "time": 26714.64126443863, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 844256, "time": 26717.982973575592, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 844536, "time": 26726.213552236557, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 844648, "time": 26729.730893850327, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 844792, "time": 26734.094334840775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 844824, "time": 26735.0727519989, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 844888, "time": 26736.992724895477, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 844968, "time": 26739.421073436737, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 845048, "time": 26741.841963768005, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 845368, "time": 26751.486192703247, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 845440, "time": 26753.88594675064, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 845696, "time": 26761.70295023918, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 845848, "time": 26766.06459760666, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 845984, "time": 26770.37948679924, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 846024, "time": 26771.36742258072, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 846056, "time": 26772.352105140686, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 846104, "time": 26773.804692029953, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 846424, "time": 26783.51545381546, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 846424, "time": 26783.522732257843, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 846448, "time": 26784.46645283699, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 846656, "time": 26790.827778816223, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 846984, "time": 26800.491475582123, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 847056, "time": 26802.91440963745, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 847368, "time": 26812.120737552643, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 847432, "time": 26814.065856218338, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 847568, "time": 26818.455890893936, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 847640, "time": 26820.483570337296, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 847784, "time": 26824.80841755867, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 847864, "time": 26827.2436504364, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 848280, "time": 26839.807669639587, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 848544, "time": 26847.990093946457, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 848784, "time": 26855.321761369705, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 848912, "time": 26859.179974079132, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 849112, "time": 26864.99804878235, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 849136, "time": 26865.945267915726, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 849264, "time": 26869.808653593063, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 849272, "time": 26869.837776899338, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 849456, "time": 26875.580676794052, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 849512, "time": 26877.043407917023, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 849680, "time": 26882.369825839996, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 849736, "time": 26883.86548948288, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 849768, "time": 26884.82646870613, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 849904, "time": 26889.13029026985, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 849904, "time": 26889.139753103256, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 850016, "time": 26892.49025630951, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 850088, "time": 26894.48255300522, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 26895.53741455078, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 850096, "time": 26895.782216072083, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 850096, "time": 26895.885762929916, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 850096, "time": 26896.314965724945, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 850096, "time": 26896.68087053299, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 850096, "time": 26897.04246520996, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 850096, "time": 26897.06800198555, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 850096, "time": 26897.313843011856, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 850128, "time": 26898.285014629364, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 850168, "time": 26899.272513628006, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 850288, "time": 26903.120735168457, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 850480, "time": 26908.97690963745, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 850528, "time": 26910.447295427322, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 850816, "time": 26919.136567115784, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 851032, "time": 26925.43270778656, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 851104, "time": 26927.82196688652, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 851160, "time": 26929.307822465897, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 851176, "time": 26929.796322345734, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 851272, "time": 26932.685451984406, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 851480, "time": 26939.027181625366, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 851720, "time": 26946.25843477249, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 851832, "time": 26949.64357972145, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 851976, "time": 26954.189218759537, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 852312, "time": 26964.631452798843, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 852328, "time": 26965.12798523903, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 852328, "time": 26965.13729786873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852520, "time": 26970.999433517456, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 852712, "time": 26976.790696382523, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 852760, "time": 26978.25037741661, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 852792, "time": 26979.21540403366, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 853128, "time": 26989.312970876694, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 853176, "time": 26990.752980947495, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 853320, "time": 26995.103796243668, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 853376, "time": 26997.01577115059, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 853496, "time": 27000.48123216629, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 853616, "time": 27004.339293003082, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 853808, "time": 27010.141521453857, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 853968, "time": 27014.981529951096, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 854088, "time": 27018.40287566185, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 854120, "time": 27019.368994235992, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 854296, "time": 27024.670161008835, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 854512, "time": 27031.538890838623, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 854592, "time": 27033.943160057068, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 854744, "time": 27038.317301273346, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 854744, "time": 27038.324930667877, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 854752, "time": 27038.792718410492, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 855000, "time": 27046.07909822464, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 855072, "time": 27048.45174598694, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 855104, "time": 27049.417444467545, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 855128, "time": 27049.924453258514, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 855504, "time": 27061.613192796707, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 855544, "time": 27062.59814453125, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 855672, "time": 27066.484280586243, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 855856, "time": 27072.228143453598, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 855864, "time": 27072.256723880768, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 855872, "time": 27072.722388267517, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 855888, "time": 27073.21861934662, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 855920, "time": 27074.204214334488, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 856048, "time": 27078.11966586113, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 856208, "time": 27082.956552028656, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 856304, "time": 27085.882403612137, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 856640, "time": 27096.258125305176, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 856712, "time": 27098.227017641068, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 856720, "time": 27098.69699072838, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 856840, "time": 27102.15249490738, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 857072, "time": 27109.416740179062, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 857112, "time": 27110.40742468834, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 857192, "time": 27112.834490537643, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 857416, "time": 27119.733691453934, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 857560, "time": 27124.07722210884, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 857696, "time": 27128.377023935318, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 857696, "time": 27128.38465166092, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 857944, "time": 27135.639639377594, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 857952, "time": 27136.109369516373, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 858104, "time": 27140.48482990265, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 858392, "time": 27149.34146308899, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 858456, "time": 27152.107966899872, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 858568, "time": 27155.525441408157, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 858600, "time": 27156.5096719265, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 858760, "time": 27161.40415287018, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 858912, "time": 27166.24898982048, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 859232, "time": 27175.97410082817, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 859384, "time": 27180.462322711945, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 859440, "time": 27182.977747917175, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 859488, "time": 27184.474096775055, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 859496, "time": 27184.503665685654, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 859560, "time": 27186.475887298584, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 859776, "time": 27193.34338402748, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 859880, "time": 27196.31448674202, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 860000, "time": 27200.189851522446, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 860024, "time": 27200.70179772377, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 860056, "time": 27201.689022302628, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 27202.64689064026, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 27204.08277773857, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 860080, "time": 27204.598786354065, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 860080, "time": 27204.76389694214, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 860080, "time": 27204.96740746498, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 860080, "time": 27205.48790359497, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 860080, "time": 27206.022443771362, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 860080, "time": 27206.87031197548, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 860080, "time": 27207.16710305214, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 860376, "time": 27216.48628258705, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 860424, "time": 27217.949219226837, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 860456, "time": 27218.935400009155, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 860480, "time": 27219.87951374054, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 860576, "time": 27222.77495455742, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 860968, "time": 27234.316511154175, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 861000, "time": 27235.277572393417, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 861000, "time": 27235.284866571426, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 861064, "time": 27237.233822107315, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 861369, "time": 27247.51326918602, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2304016416938746, "train/action_min": 0.0, "train/action_std": 1.7563155195606288, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011428597801369591, "train/actor_opt_grad_steps": 52730.0, "train/actor_opt_loss": -17.34796662591583, "train/adv_mag": 1.012603321182194, "train/adv_max": 0.24891962459431358, "train/adv_mean": 0.0027666456204242782, "train/adv_min": -0.9604055581994317, "train/adv_std": 0.028760214174045853, "train/cont_avg": 0.9946410525497512, "train/cont_loss_mean": 0.01814291830318262, "train/cont_loss_std": 0.23024649209162193, "train/cont_neg_acc": 0.2815450227898152, "train/cont_neg_loss": 2.6305640891277746, "train/cont_pos_acc": 0.9998680056624152, "train/cont_pos_loss": 0.004027394371672501, "train/cont_pred": 0.9945257030316254, "train/cont_rate": 0.9946410525497512, "train/dyn_loss_mean": 1.0000000059308105, "train/dyn_loss_std": 1.9123077228090804e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17801312745470016, "train/extr_critic_critic_opt_grad_steps": 52730.0, "train/extr_critic_critic_opt_loss": 8876.648311178482, "train/extr_critic_mag": 1.760900604191111, "train/extr_critic_max": 1.760900604191111, "train/extr_critic_mean": 1.6489716614063699, "train/extr_critic_min": 1.4843666221371932, "train/extr_critic_std": 0.03134433184727211, "train/extr_return_normed_mag": 1.0336599195774514, "train/extr_return_normed_max": 0.30760245655306534, "train/extr_return_normed_mean": 0.061784550473464664, "train/extr_return_normed_min": -0.92636462527128, "train/extr_return_normed_std": 0.04363192471476337, "train/extr_return_rate": 0.9997179152360604, "train/extr_return_raw_mag": 1.897556659594104, "train/extr_return_raw_max": 1.897556659594104, "train/extr_return_raw_mean": 1.6517388530038482, "train/extr_return_raw_min": 0.6635895777697587, "train/extr_return_raw_std": 0.043631924566493105, "train/extr_reward_mag": 0.28298677852497767, "train/extr_reward_max": 0.28298677852497767, "train/extr_reward_mean": 0.002265523213300094, "train/extr_reward_min": 1.0497534452979244e-07, "train/extr_reward_std": 0.008851282687774345, "train/image_loss_mean": 0.08149021313484035, "train/image_loss_std": 0.09758540958314393, "train/model_loss_mean": 0.7153699828024528, "train/model_loss_std": 0.46198621877835166, "train/model_opt_grad_norm": 20.562777884563996, "train/model_opt_grad_steps": 52685.50248756219, "train/model_opt_loss": 3629.5678929570895, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5074.626865671642, "train/policy_entropy_mag": 1.2889608785287658, "train/policy_entropy_max": 1.2889608785287658, "train/policy_entropy_mean": 0.09881302821843778, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1254867726371656, "train/policy_logprob_mag": 6.551080243504463, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09868746376897565, "train/policy_logprob_min": -6.551080243504463, "train/policy_logprob_std": 0.6354871605759236, "train/policy_randomness_mag": 0.6623948981512838, "train/policy_randomness_max": 0.6623948981512838, "train/policy_randomness_mean": 0.050779853942827205, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06448744806410069, "train/post_ent_mag": 29.123295542019516, "train/post_ent_max": 29.123295542019516, "train/post_ent_mean": 28.932514370970466, "train/post_ent_min": 28.772282937272863, "train/post_ent_std": 0.07257218525480869, "train/prior_ent_mag": 29.45018552903512, "train/prior_ent_max": 29.45018552903512, "train/prior_ent_mean": 28.652853799696587, "train/prior_ent_min": 27.65348272181269, "train/prior_ent_std": 0.27722719371022275, "train/rep_loss_mean": 1.0000000059308105, "train/rep_loss_std": 1.9123077228090804e-07, "train/reward_avg": 0.0021543891757144014, "train/reward_loss_mean": 0.015736826777745464, "train/reward_loss_std": 0.2281709121706993, "train/reward_max_data": 0.7801927847797004, "train/reward_max_pred": 0.27707335011876044, "train/reward_neg_acc": 0.9995026982838835, "train/reward_neg_loss": 0.0029872316097961137, "train/reward_pos_acc": 0.18243145965265506, "train/reward_pos_loss": 3.899451300802857, "train/reward_pred": 0.0017751867255075505, "train/reward_rate": 0.003250349813432836, "train_stats/mean_log_entropy": 0.07867689671941468, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.005982292350381613, "report/cont_loss_std": 0.08213520050048828, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.2960875034332275, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034576249308884144, "report/cont_pred": 0.9956067800521851, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07442429661750793, "report/image_loss_std": 0.09420106559991837, "report/model_loss_mean": 0.6862643957138062, "report/model_loss_std": 0.23072509467601776, "report/post_ent_mag": 28.995262145996094, "report/post_ent_max": 28.995262145996094, "report/post_ent_mean": 28.78418731689453, "report/post_ent_min": 28.63083839416504, "report/post_ent_std": 0.06844070553779602, "report/prior_ent_mag": 29.157501220703125, "report/prior_ent_max": 29.157501220703125, "report/prior_ent_mean": 28.28766632080078, "report/prior_ent_min": 27.375396728515625, "report/prior_ent_std": 0.2689020037651062, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006988525274209678, "report/reward_loss_mean": 0.005857748910784721, "report/reward_loss_std": 0.11666189134120941, "report/reward_max_data": 0.715624988079071, "report/reward_max_pred": 0.058539748191833496, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0022244227584451437, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.722750663757324, "report/reward_pred": 0.0010858881287276745, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020718537271022797, "eval/cont_loss_std": 0.27748703956604004, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.41610050201416, "eval/cont_pos_acc": 0.9980410933494568, "eval/cont_pos_loss": 0.007803604006767273, "eval/cont_pred": 0.9950383901596069, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11920030415058136, "eval/image_loss_std": 0.13758662343025208, "eval/model_loss_mean": 0.7504534721374512, "eval/model_loss_std": 0.456291139125824, "eval/post_ent_mag": 29.003293991088867, "eval/post_ent_max": 29.003293991088867, "eval/post_ent_mean": 28.793922424316406, "eval/post_ent_min": 28.628101348876953, "eval/post_ent_std": 0.07433310896158218, "eval/prior_ent_mag": 29.157501220703125, "eval/prior_ent_max": 29.157501220703125, "eval/prior_ent_mean": 28.314208984375, "eval/prior_ent_min": 27.255537033081055, "eval/prior_ent_std": 0.2770633399486542, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.001220703125, "eval/reward_loss_mean": 0.010534634813666344, "eval/reward_loss_std": 0.2083568125963211, "eval/reward_max_data": 0.831250011920929, "eval/reward_max_pred": 0.07267343997955322, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013689597835764289, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.694194316864014, "eval/reward_pred": 0.0007259928388521075, "eval/reward_rate": 0.001953125, "replay/size": 860865.0, "replay/inserts": 32160.0, "replay/samples": 32160.0, "replay/insert_wait_avg": 1.2761695468010594e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.103636959892007e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5608.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1418413333647941e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0398666858673, "timer/env.step_count": 4020.0, "timer/env.step_total": 39.34697365760803, "timer/env.step_frac": 0.03934540508670312, "timer/env.step_avg": 0.009787804392439809, "timer/env.step_min": 0.007788896560668945, "timer/env.step_max": 0.05440068244934082, "timer/replay._sample_count": 32160.0, "timer/replay._sample_total": 16.298524141311646, "timer/replay._sample_frac": 0.01629787439907267, "timer/replay._sample_avg": 0.0005067949048915313, "timer/replay._sample_min": 0.00034809112548828125, "timer/replay._sample_max": 0.008821487426757812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4721.0, "timer/agent.policy_total": 50.17358756065369, "timer/agent.policy_frac": 0.050171587385739916, "timer/agent.policy_avg": 0.010627745723502158, "timer/agent.policy_min": 0.008719444274902344, "timer/agent.policy_max": 0.08677124977111816, "timer/dataset_train_count": 2010.0, "timer/dataset_train_total": 0.2134850025177002, "timer/dataset_train_frac": 0.00021347649191745687, "timer/dataset_train_avg": 0.00010621144403865681, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0005333423614501953, "timer/agent.train_count": 2010.0, "timer/agent.train_total": 893.0033078193665, "timer/agent.train_frac": 0.8929677081562557, "timer/agent.train_avg": 0.444280252646451, "timer/agent.train_min": 0.43135571479797363, "timer/agent.train_max": 0.7190051078796387, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4780912399291992, "timer/agent.report_frac": 0.00047807218077574633, "timer/agent.report_avg": 0.2390456199645996, "timer/agent.report_min": 0.23099327087402344, "timer/agent.report_max": 0.24709796905517578, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.123158876236636e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 32.15815626133232}
{"step": 861408, "time": 27248.696956157684, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 861456, "time": 27250.159376859665, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 861576, "time": 27253.61471772194, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 861672, "time": 27256.536105632782, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 861704, "time": 27257.51252412796, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 861712, "time": 27258.00279903412, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 861760, "time": 27259.45730161667, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 862208, "time": 27273.09563112259, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 862288, "time": 27275.523766994476, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 862336, "time": 27276.980776309967, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 862464, "time": 27280.854927539825, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 862536, "time": 27282.82954788208, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 862808, "time": 27291.071806907654, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 862928, "time": 27294.939733982086, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 863024, "time": 27297.87080192566, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 863080, "time": 27299.43590259552, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 863184, "time": 27302.813609838486, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 863208, "time": 27303.323472499847, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 863336, "time": 27307.21699666977, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 863384, "time": 27308.67301416397, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 863904, "time": 27324.65924501419, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 864048, "time": 27329.13759660721, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 864104, "time": 27330.62162041664, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 864208, "time": 27334.01127052307, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 864392, "time": 27339.35161757469, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 864416, "time": 27340.30157637596, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 864528, "time": 27343.678003311157, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 864544, "time": 27344.16548204422, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 865016, "time": 27358.358407974243, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 865176, "time": 27363.282754659653, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 865200, "time": 27364.235766649246, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 865296, "time": 27367.137979507446, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 865400, "time": 27370.067801475525, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 865592, "time": 27375.839119911194, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 865704, "time": 27379.19991183281, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 865880, "time": 27384.50949525833, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 865960, "time": 27386.926064014435, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 866032, "time": 27389.431263446808, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 866056, "time": 27389.943095207214, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 866120, "time": 27391.87732076645, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 866184, "time": 27393.824762821198, "episode/length": 284.0, "episode/score": 0.11249999701976776, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.0}
{"step": 866584, "time": 27405.925843715668, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 866632, "time": 27407.368724107742, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 866704, "time": 27409.774425268173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 866704, "time": 27409.781497955322, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 866848, "time": 27414.14634871483, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 866864, "time": 27414.636535167694, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 867192, "time": 27424.397946596146, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 867288, "time": 27427.30553650856, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 867376, "time": 27430.218648910522, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 867592, "time": 27436.55057001114, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 867664, "time": 27438.960449695587, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 867768, "time": 27441.894068956375, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 867896, "time": 27445.791776180267, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 867976, "time": 27448.242525100708, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 868016, "time": 27449.79491686821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868168, "time": 27454.23869085312, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 868248, "time": 27456.69171524048, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 868536, "time": 27465.97213792801, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 868560, "time": 27466.937284231186, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 868576, "time": 27467.428430080414, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 868640, "time": 27469.399924516678, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 868656, "time": 27470.575598716736, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 868816, "time": 27475.442101240158, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 869376, "time": 27492.515612363815, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 869544, "time": 27497.33303141594, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 869552, "time": 27497.81527042389, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 869624, "time": 27499.757828950882, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 869920, "time": 27508.974370718002, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 27514.55211663246, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 870064, "time": 27515.03829908371, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 870064, "time": 27515.156851768494, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 870064, "time": 27515.481306552887, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 870064, "time": 27515.67144203186, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 870064, "time": 27515.8304336071, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 870064, "time": 27515.87525486946, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 870064, "time": 27515.917679071426, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 870080, "time": 27516.411139965057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870136, "time": 27517.893893003464, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 870192, "time": 27519.842628240585, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 870224, "time": 27520.816107988358, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 870696, "time": 27534.920904636383, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 870704, "time": 27535.39124894142, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 870768, "time": 27537.332344532013, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 870784, "time": 27537.8230407238, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 870872, "time": 27540.39173769951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871000, "time": 27544.293655633926, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 871160, "time": 27549.1531894207, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 871192, "time": 27550.127616643906, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 871496, "time": 27559.322148799896, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 871504, "time": 27559.78920006752, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 871760, "time": 27567.519884109497, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 871856, "time": 27570.52832508087, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 872128, "time": 27578.722067832947, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 872320, "time": 27584.494304656982, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 872376, "time": 27585.955761432648, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 872440, "time": 27587.90900874138, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 872496, "time": 27589.81538581848, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 872552, "time": 27591.29422569275, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 872760, "time": 27597.689054965973, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 872928, "time": 27603.11061024666, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 873224, "time": 27611.85801053047, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 873296, "time": 27614.27846264839, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 873392, "time": 27617.19256043434, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 873456, "time": 27619.118743896484, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 873576, "time": 27622.547023296356, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 873600, "time": 27623.492076158524, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 873640, "time": 27624.484775543213, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 873800, "time": 27629.48838019371, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 873808, "time": 27629.965462446213, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 874168, "time": 27640.63257241249, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 874200, "time": 27641.624653339386, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 874232, "time": 27642.60022878647, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 874496, "time": 27650.774216651917, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 874680, "time": 27656.118832826614, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 875248, "time": 27673.70157647133, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 875368, "time": 27677.12499856949, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 875512, "time": 27681.490248441696, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 875608, "time": 27684.396080732346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 875760, "time": 27689.325620174408, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 875888, "time": 27693.231487751007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 875952, "time": 27695.19105386734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876120, "time": 27700.09478163719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876360, "time": 27707.404987335205, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 876392, "time": 27708.38280415535, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 876472, "time": 27710.83715558052, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 876600, "time": 27715.274800539017, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 876664, "time": 27717.222959518433, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 876864, "time": 27723.602071762085, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 876984, "time": 27727.032606124878, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 877000, "time": 27727.52396297455, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 877056, "time": 27729.429796934128, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 877336, "time": 27737.7010409832, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 877384, "time": 27739.148643255234, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 877456, "time": 27741.56059551239, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 877464, "time": 27741.58920288086, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 877496, "time": 27742.561230421066, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 877592, "time": 27745.495653390884, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 877704, "time": 27748.985047101974, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 878216, "time": 27764.49628686905, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 878432, "time": 27771.25545024872, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 878568, "time": 27775.155430555344, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 878648, "time": 27777.578636169434, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 878800, "time": 27782.524407863617, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 878800, "time": 27782.532059192657, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 878880, "time": 27784.979882001877, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 879048, "time": 27789.882731199265, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 879168, "time": 27793.752492666245, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 879272, "time": 27796.68161702156, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 879368, "time": 27799.60510110855, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 879368, "time": 27799.613154649734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 880008, "time": 27819.225987434387, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 27821.751624822617, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 880048, "time": 27822.12820124626, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 880048, "time": 27822.155743598938, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 880048, "time": 27822.267842054367, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 880048, "time": 27822.84050154686, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 880048, "time": 27823.145431041718, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 880048, "time": 27823.214009284973, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 880048, "time": 27823.383950471878, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 880136, "time": 27825.880351543427, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 880160, "time": 27826.84785437584, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 880184, "time": 27827.365844488144, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 880408, "time": 27834.23174595833, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 880560, "time": 27839.197289943695, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 880736, "time": 27844.54339170456, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 880808, "time": 27846.53076171875, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 880952, "time": 27850.883470773697, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 880952, "time": 27850.8959274292, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 880992, "time": 27852.329899787903, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 881184, "time": 27858.170117139816, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 881376, "time": 27864.014832019806, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 881480, "time": 27866.940168380737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 881760, "time": 27875.701578855515, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 881840, "time": 27878.113736629486, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 881936, "time": 27881.006275892258, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 882032, "time": 27883.92370223999, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 882208, "time": 27889.225882530212, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 882216, "time": 27889.255322933197, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 882264, "time": 27890.701857089996, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 882448, "time": 27896.475871562958, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 882496, "time": 27897.9518764019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882592, "time": 27901.004135608673, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 882608, "time": 27901.500856399536, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 882696, "time": 27904.00289440155, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 882832, "time": 27908.367956638336, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 883032, "time": 27914.208208084106, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 883040, "time": 27914.68456530571, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 883168, "time": 27918.60011291504, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 883192, "time": 27919.123336791992, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 883208, "time": 27919.626827955246, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 883248, "time": 27921.099373102188, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 883264, "time": 27921.601145505905, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 883400, "time": 27925.588463544846, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 883640, "time": 27932.98861837387, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 884160, "time": 27949.020413398743, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 884160, "time": 27949.028013944626, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 884184, "time": 27950.14751625061, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 884272, "time": 27953.038410425186, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 884408, "time": 27956.90385890007, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 884456, "time": 27958.437270641327, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 884504, "time": 27959.954739570618, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 884520, "time": 27960.446776390076, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 884656, "time": 27964.794340133667, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 884976, "time": 27974.948074817657, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 885016, "time": 27975.938992500305, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 885032, "time": 27976.430874586105, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 885272, "time": 27983.722559928894, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 885352, "time": 27986.157858133316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885384, "time": 27987.137907505035, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 885480, "time": 27990.20786881447, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 885608, "time": 27994.10391640663, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 886016, "time": 28006.62820339203, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 886056, "time": 28007.63396549225, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 886144, "time": 28010.502804756165, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 886376, "time": 28017.325640916824, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 886400, "time": 28018.275085926056, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 886552, "time": 28022.730326890945, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 886624, "time": 28025.132529973984, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 886832, "time": 28031.459148406982, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 886936, "time": 28034.38563466072, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 886984, "time": 28035.838818073273, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 886984, "time": 28035.84591126442, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 887088, "time": 28039.224425315857, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 887104, "time": 28039.709832906723, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 887272, "time": 28044.580417633057, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 887288, "time": 28045.07073712349, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 887416, "time": 28050.191424369812, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 887512, "time": 28053.098534345627, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 887776, "time": 28061.345804929733, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 887808, "time": 28062.34044456482, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 888104, "time": 28071.055616378784, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 888224, "time": 28074.9496986866, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 888304, "time": 28077.37734222412, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 888320, "time": 28077.868458271027, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 888984, "time": 28097.951498746872, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 889216, "time": 28105.18053174019, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 889392, "time": 28110.697440862656, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 889416, "time": 28111.206886291504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889592, "time": 28116.53473186493, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 889800, "time": 28122.851890563965, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 28130.65223288536, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 890032, "time": 28131.698483467102, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 890032, "time": 28131.82040333748, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 890032, "time": 28132.175977945328, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 890032, "time": 28132.503443717957, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 890032, "time": 28132.627922534943, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 890032, "time": 28133.820273160934, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 890032, "time": 28134.429520606995, "eval_episode/length": 227.0, "eval_episode/score": 0.2906250059604645, "eval_episode/reward_rate": 0.0043859649122807015}
{"step": 890032, "time": 28134.436650514603, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 890112, "time": 28136.86185836792, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 890376, "time": 28144.758222341537, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 890416, "time": 28146.18672132492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890440, "time": 28146.695504188538, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 890504, "time": 28148.627060890198, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 890536, "time": 28149.6295068264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890616, "time": 28152.052959680557, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 890672, "time": 28153.98837208748, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 891032, "time": 28164.674033880234, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 891072, "time": 28166.11180138588, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 891112, "time": 28167.10961985588, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 891200, "time": 28170.101665496826, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 891608, "time": 28182.193432331085, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 891720, "time": 28185.59700846672, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 891968, "time": 28193.281784534454, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 892048, "time": 28195.675151586533, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 892168, "time": 28199.21022415161, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 892312, "time": 28203.546312093735, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 892344, "time": 28204.517926216125, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 892560, "time": 28211.237486600876, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 892600, "time": 28212.23967218399, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 892744, "time": 28216.554158210754, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 892952, "time": 28223.286417007446, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 893080, "time": 28227.19356560707, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 893216, "time": 28231.630245923996, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 893264, "time": 28233.088673114777, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 893336, "time": 28235.02948331833, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 893416, "time": 28237.486857414246, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 893424, "time": 28237.959973812103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 893721, "time": 28247.60048699379, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.213889737434575, "train/action_min": 0.0, "train/action_std": 1.7343313059783334, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012335512852479745, "train/actor_opt_grad_steps": 54750.0, "train/actor_opt_loss": -19.720838476284385, "train/adv_mag": 1.0673820379332368, "train/adv_max": 0.28830383505140034, "train/adv_mean": 0.0011058208008587719, "train/adv_min": -1.025551014345855, "train/adv_std": 0.031563736356134194, "train/cont_avg": 0.9941454356527094, "train/cont_loss_mean": 0.01972088019542506, "train/cont_loss_std": 0.24726051578912975, "train/cont_neg_acc": 0.2937826605999998, "train/cont_neg_loss": 2.6710617429911725, "train/cont_pos_acc": 0.999864472250633, "train/cont_pos_loss": 0.004152860445442972, "train/cont_pred": 0.9942819851959868, "train/cont_rate": 0.9941454356527094, "train/dyn_loss_mean": 1.0000000352342728, "train/dyn_loss_std": 1.1265057648343993e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11930974972952763, "train/extr_critic_critic_opt_grad_steps": 54750.0, "train/extr_critic_critic_opt_loss": 11830.405129117918, "train/extr_critic_mag": 1.8257203160835604, "train/extr_critic_max": 1.8257203160835604, "train/extr_critic_mean": 1.7020929100478224, "train/extr_critic_min": 1.4616858471790557, "train/extr_critic_std": 0.03168118577175246, "train/extr_return_normed_mag": 1.0998240527261067, "train/extr_return_normed_max": 0.32920922669283864, "train/extr_return_normed_mean": 0.061412295464224415, "train/extr_return_normed_min": -1.0080232849262032, "train/extr_return_normed_std": 0.045688469265702324, "train/extr_return_rate": 0.9997373737137893, "train/extr_return_raw_mag": 1.970995994037008, "train/extr_return_raw_max": 1.970995994037008, "train/extr_return_raw_mean": 1.7031991323226778, "train/extr_return_raw_min": 0.6337634824179663, "train/extr_return_raw_std": 0.04568846920147318, "train/extr_reward_mag": 0.3004652349819691, "train/extr_reward_max": 0.3004652349819691, "train/extr_reward_mean": 0.002266450700226235, "train/extr_reward_min": 5.520036067868688e-08, "train/extr_reward_std": 0.009195422464660529, "train/image_loss_mean": 0.08274790229908939, "train/image_loss_std": 0.09836039615088496, "train/model_loss_mean": 0.7193719383531016, "train/model_loss_std": 0.48322989758599566, "train/model_opt_grad_norm": 19.774448916242626, "train/model_opt_grad_steps": 54703.51724137931, "train/model_opt_loss": 3669.3109581858066, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5098.522167487685, "train/policy_entropy_mag": 1.291057078709156, "train/policy_entropy_max": 1.291057078709156, "train/policy_entropy_mean": 0.09754357853986947, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12304927841783157, "train/policy_logprob_mag": 6.551080257434563, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09782333686727608, "train/policy_logprob_min": -6.551080257434563, "train/policy_logprob_std": 0.6367532933874084, "train/policy_randomness_mag": 0.6634721333170172, "train/policy_randomness_max": 0.6634721333170172, "train/policy_randomness_mean": 0.05012748579453365, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06323482371462977, "train/post_ent_mag": 28.985014544331968, "train/post_ent_max": 28.985014544331968, "train/post_ent_mean": 28.784050448187465, "train/post_ent_min": 28.607383558902836, "train/post_ent_std": 0.08043718870197024, "train/prior_ent_mag": 29.185411857266732, "train/prior_ent_max": 29.185411857266732, "train/prior_ent_mean": 28.26747282620134, "train/prior_ent_min": 27.246628127074594, "train/prior_ent_std": 0.2958911148638561, "train/rep_loss_mean": 1.0000000352342728, "train/rep_loss_std": 1.1265057648343993e-06, "train/reward_avg": 0.002415067921857134, "train/reward_loss_mean": 0.016903110514876658, "train/reward_loss_std": 0.23722951395409594, "train/reward_max_data": 0.7931342355429832, "train/reward_max_pred": 0.3164393702164072, "train/reward_neg_acc": 0.9995750732022554, "train/reward_neg_loss": 0.003074937545937564, "train/reward_pos_acc": 0.18876451346559905, "train/reward_pos_loss": 3.8390154539056085, "train/reward_pred": 0.0018782453999161867, "train/reward_rate": 0.0035935575738916255, "train_stats/mean_log_entropy": 0.07679521192715863, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.014655344188213348, "report/cont_loss_std": 0.1541280597448349, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 1.5360889434814453, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005688152275979519, "report/cont_pred": 0.992174506187439, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07693484425544739, "report/image_loss_std": 0.09686348587274551, "report/model_loss_mean": 0.7077049016952515, "report/model_loss_std": 0.4020264446735382, "report/post_ent_mag": 28.97829818725586, "report/post_ent_max": 28.97829818725586, "report/post_ent_mean": 28.77338409423828, "report/post_ent_min": 28.589279174804688, "report/post_ent_std": 0.0821283832192421, "report/prior_ent_mag": 29.450122833251953, "report/prior_ent_max": 29.450122833251953, "report/prior_ent_mean": 28.457738876342773, "report/prior_ent_min": 27.558929443359375, "report/prior_ent_std": 0.3075745105743408, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0019287110771983862, "report/reward_loss_mean": 0.016114704310894012, "report/reward_loss_std": 0.22232237458229065, "report/reward_max_data": 0.856249988079071, "report/reward_max_pred": 0.22618317604064941, "report/reward_neg_acc": 0.9980410933494568, "report/reward_neg_loss": 0.004260382615029812, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.050536155700684, "report/reward_pred": 0.00226070755161345, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03743994981050491, "eval/cont_loss_std": 0.5254938006401062, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.6071977615356445, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004612307529896498, "eval/cont_pred": 0.9953663945198059, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13244564831256866, "eval/image_loss_std": 0.12645849585533142, "eval/model_loss_mean": 0.8007806539535522, "eval/model_loss_std": 0.924329936504364, "eval/post_ent_mag": 28.980045318603516, "eval/post_ent_max": 28.980045318603516, "eval/post_ent_mean": 28.774812698364258, "eval/post_ent_min": 28.603755950927734, "eval/post_ent_std": 0.08546704053878784, "eval/prior_ent_mag": 29.450122833251953, "eval/prior_ent_max": 29.450122833251953, "eval/prior_ent_mean": 28.44530487060547, "eval/prior_ent_min": 27.446575164794922, "eval/prior_ent_std": 0.3385881781578064, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.003182983258739114, "eval/reward_loss_mean": 0.030895018950104713, "eval/reward_loss_std": 0.45594921708106995, "eval/reward_max_data": 0.78125, "eval/reward_max_pred": 0.19127953052520752, "eval/reward_neg_acc": 0.9980372786521912, "eval/reward_neg_loss": 0.00381270470097661, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.550271034240723, "eval/reward_pred": 0.0020642320159822702, "eval/reward_rate": 0.0048828125, "replay/size": 893217.0, "replay/inserts": 32352.0, "replay/samples": 32352.0, "replay/insert_wait_avg": 1.293600607814468e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.111699870267089e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3880.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1189696715050137e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0680470466614, "timer/env.step_count": 4044.0, "timer/env.step_total": 39.46513915061951, "timer/env.step_frac": 0.039462453847181195, "timer/env.step_avg": 0.009758936486305516, "timer/env.step_min": 0.007583141326904297, "timer/env.step_max": 0.03940391540527344, "timer/replay._sample_count": 32352.0, "timer/replay._sample_total": 16.41160225868225, "timer/replay._sample_frac": 0.016410485573604687, "timer/replay._sample_avg": 0.0005072824634854801, "timer/replay._sample_min": 0.0003819465637207031, "timer/replay._sample_max": 0.009966611862182617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4529.0, "timer/agent.policy_total": 47.73299789428711, "timer/agent.policy_frac": 0.04772975002575997, "timer/agent.policy_avg": 0.010539412208939525, "timer/agent.policy_min": 0.008996248245239258, "timer/agent.policy_max": 0.07990765571594238, "timer/dataset_train_count": 2022.0, "timer/dataset_train_total": 0.21513032913208008, "timer/dataset_train_frac": 0.00021511569114460717, "timer/dataset_train_avg": 0.00010639482152921863, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0009546279907226562, "timer/agent.train_count": 2022.0, "timer/agent.train_total": 899.6183564662933, "timer/agent.train_frac": 0.8995571442593233, "timer/agent.train_avg": 0.4449151120011342, "timer/agent.train_min": 0.4330449104309082, "timer/agent.train_max": 0.6833491325378418, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4723799228668213, "timer/agent.report_frac": 0.0004723477809953275, "timer/agent.report_avg": 0.23618996143341064, "timer/agent.report_min": 0.22860956192016602, "timer/agent.report_max": 0.24377036094665527, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.799003601074219e-05, "timer/dataset_eval_frac": 9.798336853189166e-08, "timer/dataset_eval_avg": 9.799003601074219e-05, "timer/dataset_eval_min": 9.799003601074219e-05, "timer/dataset_eval_max": 9.799003601074219e-05, "fps": 32.34923826633932}
{"step": 893808, "time": 28250.19921708107, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 893896, "time": 28252.636362552643, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 894152, "time": 28260.45422720909, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 894480, "time": 28270.662715673447, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 894480, "time": 28270.67020893097, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 894752, "time": 28278.95247244835, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 894856, "time": 28281.895042657852, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 894928, "time": 28284.308665275574, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 895056, "time": 28288.19281935692, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 895200, "time": 28292.6493434906, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 895304, "time": 28295.572823286057, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 895392, "time": 28298.485190153122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895448, "time": 28299.96004319191, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 895528, "time": 28302.400075912476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895640, "time": 28305.803867816925, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 895752, "time": 28309.19715476036, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 896008, "time": 28316.962555408478, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 896080, "time": 28319.458747148514, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 896136, "time": 28320.944091320038, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 896544, "time": 28333.54257273674, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 896616, "time": 28335.520352840424, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 896744, "time": 28339.37620997429, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 896776, "time": 28340.364447832108, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 897008, "time": 28347.622552633286, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 897024, "time": 28348.113710403442, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 897192, "time": 28353.140499591827, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 897216, "time": 28354.095661640167, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 897248, "time": 28355.10928082466, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 897328, "time": 28357.554272413254, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 897800, "time": 28371.719393730164, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 897832, "time": 28372.70175552368, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 897960, "time": 28376.60262656212, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 898152, "time": 28382.508342027664, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 898240, "time": 28385.417035341263, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 898304, "time": 28387.35170316696, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 898432, "time": 28391.247834682465, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 898480, "time": 28392.705486297607, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 898552, "time": 28394.69401717186, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 898728, "time": 28400.029898643494, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 898912, "time": 28405.86436676979, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 899112, "time": 28411.84438085556, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 899328, "time": 28418.63677096367, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 899328, "time": 28418.644124031067, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 899592, "time": 28426.403267621994, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 899624, "time": 28427.387298583984, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 899632, "time": 28427.882881879807, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 899840, "time": 28434.203928232193, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 28440.69909644127, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 900016, "time": 28441.600499391556, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 900016, "time": 28441.62694811821, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 900016, "time": 28441.90885567665, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 900016, "time": 28441.972852230072, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 900016, "time": 28442.33616733551, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 900016, "time": 28442.442192077637, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 900016, "time": 28442.959448337555, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 900032, "time": 28443.44965672493, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 900072, "time": 28444.460029125214, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 900088, "time": 28444.956488847733, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 900120, "time": 28445.94423890114, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 900336, "time": 28452.697162628174, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 900616, "time": 28460.93631863594, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 900640, "time": 28461.8883228302, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 900784, "time": 28466.26873755455, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 900832, "time": 28467.720367908478, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 901064, "time": 28474.58769249916, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 901096, "time": 28475.5828769207, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 901104, "time": 28476.05378460884, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 901224, "time": 28479.956092596054, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 901456, "time": 28487.246108055115, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 901488, "time": 28488.217613697052, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 901680, "time": 28494.00976037979, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 901776, "time": 28496.906502723694, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 901792, "time": 28497.39285326004, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 901952, "time": 28502.297370672226, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 902176, "time": 28509.110182762146, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 902328, "time": 28513.49624991417, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 902432, "time": 28516.87815761566, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 902528, "time": 28519.78623008728, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 902616, "time": 28522.22761940956, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 902616, "time": 28522.242429494858, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 902768, "time": 28527.05755996704, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 902920, "time": 28531.51681828499, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 902944, "time": 28532.46561217308, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 902960, "time": 28532.959711551666, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 903160, "time": 28538.85330939293, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 903224, "time": 28540.790533304214, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 903264, "time": 28542.228057146072, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 903392, "time": 28546.111973524094, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 903536, "time": 28550.491022586823, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 903592, "time": 28551.961215257645, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 903648, "time": 28553.89401292801, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 903688, "time": 28554.90196800232, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 903824, "time": 28559.425223588943, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 904024, "time": 28565.31236433983, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 904032, "time": 28565.783757925034, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 904184, "time": 28570.20538520813, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 904376, "time": 28576.059185028076, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 904392, "time": 28576.551062107086, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 904488, "time": 28579.48495197296, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 904744, "time": 28587.230580806732, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 904784, "time": 28588.759502887726, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 905264, "time": 28603.330761432648, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 905288, "time": 28603.839773654938, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 905320, "time": 28604.80988883972, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 905376, "time": 28606.720102071762, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 905568, "time": 28612.558488368988, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 905616, "time": 28614.01761865616, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 905792, "time": 28619.46287202835, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 905944, "time": 28623.85416316986, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 906104, "time": 28628.767761468887, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 906200, "time": 28631.72792172432, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 906280, "time": 28634.156809329987, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 906336, "time": 28636.087409496307, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 906368, "time": 28637.077847242355, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 906472, "time": 28640.003436088562, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 906584, "time": 28643.40191078186, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 906592, "time": 28643.87188744545, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 906776, "time": 28649.318731307983, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 907200, "time": 28662.44773030281, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 907200, "time": 28662.456876277924, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 907224, "time": 28662.96995162964, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 907392, "time": 28668.31330180168, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 907544, "time": 28672.76065850258, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 907608, "time": 28674.728486299515, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 907696, "time": 28677.658190488815, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 907696, "time": 28677.665247440338, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 907712, "time": 28678.159962892532, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 907928, "time": 28684.583253383636, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 908296, "time": 28695.79265522957, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 908392, "time": 28698.713156461716, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 908392, "time": 28698.724192380905, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 908464, "time": 28701.148312091827, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 908472, "time": 28701.178431510925, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 908616, "time": 28705.52764225006, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 908968, "time": 28716.27702856064, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 909192, "time": 28723.096495628357, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 909320, "time": 28727.246021270752, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 909400, "time": 28730.01529431343, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 909464, "time": 28731.947612285614, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 909504, "time": 28733.37864923477, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 909584, "time": 28735.814130306244, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 909864, "time": 28744.143497228622, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 28749.406937122345, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 910000, "time": 28750.046681642532, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 910000, "time": 28750.505517482758, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 910000, "time": 28750.608918905258, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 910000, "time": 28750.932654619217, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 910000, "time": 28751.115119457245, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 910000, "time": 28751.179624795914, "eval_episode/length": 11.0, "eval_episode/score": 0.965624988079071, "eval_episode/reward_rate": 0.08333333333333333}
{"step": 910000, "time": 28751.940521240234, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 910048, "time": 28753.417115211487, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 910136, "time": 28755.845815896988, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 910240, "time": 28759.210067987442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910296, "time": 28760.684032440186, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 910360, "time": 28762.642776727676, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 910456, "time": 28765.572846889496, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 910552, "time": 28768.592762708664, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 910640, "time": 28771.47438788414, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 910776, "time": 28775.39289212227, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 910776, "time": 28775.403819084167, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 911152, "time": 28787.05457663536, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 911248, "time": 28789.9508395195, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 911280, "time": 28790.91224718094, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 911368, "time": 28793.377094745636, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 911424, "time": 28795.29524040222, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 911640, "time": 28801.725036382675, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 911832, "time": 28807.52322101593, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 911856, "time": 28808.47628903389, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 911856, "time": 28808.482966899872, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 911888, "time": 28809.446674585342, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 911960, "time": 28811.408980846405, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 912176, "time": 28818.176899433136, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 912248, "time": 28820.131490707397, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 912496, "time": 28827.905086755753, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 912520, "time": 28828.466599941254, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 912848, "time": 28838.633325576782, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 912904, "time": 28840.097454071045, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 912976, "time": 28842.50213289261, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 912992, "time": 28842.991218090057, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 913176, "time": 28848.352582216263, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 913312, "time": 28852.70199251175, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 913424, "time": 28856.08452105522, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 913496, "time": 28858.035128355026, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 913632, "time": 28862.458795309067, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 913808, "time": 28867.7845621109, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 913824, "time": 28868.2718334198, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 913880, "time": 28869.76831126213, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 913904, "time": 28870.727821350098, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 914256, "time": 28881.410622119904, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 914296, "time": 28882.404200553894, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 914376, "time": 28884.855453968048, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 914544, "time": 28890.236649274826, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 914640, "time": 28893.14896082878, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 914776, "time": 28897.065395355225, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 914808, "time": 28898.039678812027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915096, "time": 28906.788650035858, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 915136, "time": 28908.239936351776, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 915200, "time": 28910.213686466217, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 915288, "time": 28912.65691280365, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 915296, "time": 28913.127242565155, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 915360, "time": 28915.092472076416, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 915640, "time": 28923.401698589325, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 915680, "time": 28924.832181215286, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 915736, "time": 28926.323098421097, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 915832, "time": 28929.2293446064, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 915848, "time": 28929.715398073196, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 915872, "time": 28930.658591747284, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 915976, "time": 28933.589555740356, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 916192, "time": 28940.349450826645, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 916248, "time": 28941.829701423645, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 916264, "time": 28942.314448833466, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 916328, "time": 28944.272337675095, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 916512, "time": 28950.188841581345, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 916544, "time": 28951.154629468918, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 916720, "time": 28956.51469349861, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 916912, "time": 28962.358453035355, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 917232, "time": 28972.058219909668, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 917264, "time": 28973.027222394943, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 917576, "time": 28982.820618867874, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 917632, "time": 28984.742939710617, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 917704, "time": 28986.719702482224, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 917768, "time": 28988.67834544182, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 917848, "time": 28991.109582901, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 918144, "time": 29000.372545957565, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 918248, "time": 29003.33695077896, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 918272, "time": 29004.308037996292, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 918344, "time": 29006.339468717575, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 918376, "time": 29007.369275331497, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 918528, "time": 29012.47266435623, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 918560, "time": 29013.471207857132, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 918712, "time": 29017.93958759308, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 918832, "time": 29021.817074537277, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 918968, "time": 29025.736735105515, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 918984, "time": 29026.221626996994, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 919080, "time": 29029.134063005447, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 919216, "time": 29033.472212314606, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 919288, "time": 29035.418412446976, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 919488, "time": 29041.836748838425, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 919696, "time": 29048.134851932526, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 919696, "time": 29048.142135858536, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 919776, "time": 29050.560471773148, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 919936, "time": 29055.44627213478, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 919960, "time": 29055.980218172073, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 920040, "time": 29058.41085958481, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 29061.771225452423, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 920088, "time": 29061.93126296997, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 920088, "time": 29062.44126534462, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 920088, "time": 29062.663786411285, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 920088, "time": 29062.690765619278, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 920088, "time": 29062.88071846962, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 920088, "time": 29063.30147409439, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 920088, "time": 29063.501924276352, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 920296, "time": 29069.930169820786, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 920344, "time": 29071.38646006584, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 920560, "time": 29078.14095044136, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 920696, "time": 29082.032325029373, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 920752, "time": 29083.971603870392, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 921024, "time": 29092.226343393326, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 921128, "time": 29095.224584579468, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 921488, "time": 29106.54227733612, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 921496, "time": 29106.57146525383, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 921528, "time": 29107.549260616302, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 921528, "time": 29107.55743408203, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 921600, "time": 29109.981433153152, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 921656, "time": 29111.462009191513, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 921896, "time": 29118.762689590454, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 922080, "time": 29124.55459690094, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 922456, "time": 29135.831379890442, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 922640, "time": 29141.624664068222, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 922648, "time": 29141.654049158096, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 922680, "time": 29142.647287607193, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 922920, "time": 29149.91968345642, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 922952, "time": 29150.888617515564, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 923160, "time": 29157.212586402893, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 923176, "time": 29157.705503225327, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 923232, "time": 29159.737479686737, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 923496, "time": 29167.533194065094, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 923528, "time": 29168.511939525604, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 923568, "time": 29169.940702676773, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 923808, "time": 29177.23451566696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923880, "time": 29179.19476389885, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 923888, "time": 29179.663531064987, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 923984, "time": 29182.577493667603, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 923992, "time": 29182.607137918472, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 924168, "time": 29187.945658683777, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 924216, "time": 29189.483528137207, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 924376, "time": 29194.337923288345, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 924632, "time": 29202.10551047325, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 924736, "time": 29205.45947265625, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 924952, "time": 29213.796771287918, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 924968, "time": 29214.28384232521, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 925168, "time": 29220.679453611374, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 925208, "time": 29221.671441316605, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 925224, "time": 29222.156797409058, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 925232, "time": 29222.64286518097, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 925272, "time": 29223.634993314743, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 925712, "time": 29237.682544708252, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 925776, "time": 29239.622717380524, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 925776, "time": 29239.629723787308, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 925824, "time": 29241.083550930023, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 926000, "time": 29246.423793315887, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 926025, "time": 29247.948986768723, "train_stats/mean_log_entropy": 0.07640327125895324, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.157972883469988, "train/action_min": 0.0, "train/action_std": 1.7193174551029016, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01232999196451268, "train/actor_opt_grad_steps": 56775.0, "train/actor_opt_loss": -21.156105060388548, "train/adv_mag": 1.0994768721042294, "train/adv_max": 0.34525936782950223, "train/adv_mean": 0.0015251246687233168, "train/adv_min": -1.0236629678471254, "train/adv_std": 0.03248348251667501, "train/cont_avg": 0.9940487701113861, "train/cont_loss_mean": 0.019588686555789988, "train/cont_loss_std": 0.23996540065393737, "train/cont_neg_acc": 0.2848584918618792, "train/cont_neg_loss": 2.5848559251995664, "train/cont_pos_acc": 0.9998784522608956, "train/cont_pos_loss": 0.004235710479010192, "train/cont_pred": 0.9941558168076052, "train/cont_rate": 0.9940487701113861, "train/dyn_loss_mean": 1.0000001357333494, "train/dyn_loss_std": 4.3315029159040735e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09642072818656959, "train/extr_critic_critic_opt_grad_steps": 56775.0, "train/extr_critic_critic_opt_loss": 13114.57606068224, "train/extr_critic_mag": 1.8800211247831289, "train/extr_critic_max": 1.8800211247831289, "train/extr_critic_mean": 1.7585812942816479, "train/extr_critic_min": 1.414440926938954, "train/extr_critic_std": 0.03369635651533556, "train/extr_return_normed_mag": 1.1005945382731976, "train/extr_return_normed_max": 0.30845247636927237, "train/extr_return_normed_mean": 0.06476060120333539, "train/extr_return_normed_min": -1.0078897936509388, "train/extr_return_normed_std": 0.04773543035556184, "train/extr_return_rate": 0.9997176991240813, "train/extr_return_raw_mag": 2.0037983726746966, "train/extr_return_raw_max": 2.0037983726746966, "train/extr_return_raw_mean": 1.7601065836330452, "train/extr_return_raw_min": 0.6874561026544854, "train/extr_return_raw_std": 0.04773543002360528, "train/extr_reward_mag": 0.2748111108742138, "train/extr_reward_max": 0.2748111108742138, "train/extr_reward_mean": 0.002202282038731685, "train/extr_reward_min": 2.950724988880724e-09, "train/extr_reward_std": 0.00884880304410316, "train/image_loss_mean": 0.08369380053095889, "train/image_loss_std": 0.09949515634539104, "train/model_loss_mean": 0.7206609077972941, "train/model_loss_std": 0.48227166255364323, "train/model_opt_grad_norm": 19.327051386974826, "train/model_opt_grad_steps": 56726.574257425746, "train/model_opt_loss": 3726.1121838258045, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5198.019801980198, "train/policy_entropy_mag": 1.3080828124933903, "train/policy_entropy_max": 1.3080828124933903, "train/policy_entropy_mean": 0.09549524542866367, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11971298690036972, "train/policy_logprob_mag": 6.551080257585733, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09571452910947327, "train/policy_logprob_min": -6.551080257585733, "train/policy_logprob_std": 0.6347259061761422, "train/policy_randomness_mag": 0.6722216302215462, "train/policy_randomness_max": 0.6722216302215462, "train/policy_randomness_mean": 0.04907485073672073, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06152030888317835, "train/post_ent_mag": 29.11579916736867, "train/post_ent_max": 29.11579916736867, "train/post_ent_mean": 28.915601994731638, "train/post_ent_min": 28.736589705589974, "train/post_ent_std": 0.08043524519641801, "train/prior_ent_mag": 29.29240088887734, "train/prior_ent_max": 29.29240088887734, "train/prior_ent_mean": 28.304609308148375, "train/prior_ent_min": 27.377673489032407, "train/prior_ent_std": 0.2919054255627169, "train/rep_loss_mean": 1.0000001357333494, "train/rep_loss_std": 4.3315029159040735e-06, "train/reward_avg": 0.002421192105313173, "train/reward_loss_mean": 0.01737831736509089, "train/reward_loss_std": 0.24002732072800104, "train/reward_max_data": 0.7757735152055721, "train/reward_max_pred": 0.3087134101603291, "train/reward_neg_acc": 0.999514887238493, "train/reward_neg_loss": 0.0032147780189862346, "train/reward_pos_acc": 0.18998564577581895, "train/reward_pos_loss": 3.8416486385479645, "train/reward_pred": 0.0019346136653952595, "train/reward_rate": 0.0036741955445544552, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.021967226639389992, "report/cont_loss_std": 0.3113243281841278, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.0893144607543945, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002009683521464467, "report/cont_pred": 0.9976195096969604, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06563794612884521, "report/image_loss_std": 0.09200992435216904, "report/model_loss_mean": 0.7050982713699341, "report/model_loss_std": 0.6066796183586121, "report/post_ent_mag": 29.12352180480957, "report/post_ent_max": 29.12352180480957, "report/post_ent_mean": 28.913619995117188, "report/post_ent_min": 28.734006881713867, "report/post_ent_std": 0.07615789026021957, "report/prior_ent_mag": 29.18143081665039, "report/prior_ent_max": 29.18143081665039, "report/prior_ent_mean": 28.236133575439453, "report/prior_ent_min": 27.20783233642578, "report/prior_ent_std": 0.28490498661994934, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0018188476096838713, "report/reward_loss_mean": 0.017493054270744324, "report/reward_loss_std": 0.29702794551849365, "report/reward_max_data": 0.721875011920929, "report/reward_max_pred": 0.05254507064819336, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.001643292373046279, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.41169548034668, "report/reward_pred": 0.000826146686449647, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04258058965206146, "eval/cont_loss_std": 0.6170895099639893, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.245323181152344, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002331608207896352, "eval/cont_pred": 0.9976954460144043, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1496199071407318, "eval/image_loss_std": 0.14313797652721405, "eval/model_loss_mean": 0.8153469562530518, "eval/model_loss_std": 0.942423403263092, "eval/post_ent_mag": 29.12069320678711, "eval/post_ent_max": 29.12069320678711, "eval/post_ent_mean": 28.921100616455078, "eval/post_ent_min": 28.772605895996094, "eval/post_ent_std": 0.07810651510953903, "eval/prior_ent_mag": 29.18143081665039, "eval/prior_ent_max": 29.18143081665039, "eval/prior_ent_mean": 28.216602325439453, "eval/prior_ent_min": 27.270721435546875, "eval/prior_ent_std": 0.2878793478012085, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0016662597190588713, "eval/reward_loss_mean": 0.023146430030465126, "eval/reward_loss_std": 0.4178824722766876, "eval/reward_max_data": 0.6625000238418579, "eval/reward_max_pred": 0.11998307704925537, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.0015175914159044623, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.384160995483398, "eval/reward_pred": 0.0007466924143955112, "eval/reward_rate": 0.0029296875, "replay/size": 925521.0, "replay/inserts": 32304.0, "replay/samples": 32304.0, "replay/insert_wait_avg": 1.2731820772991964e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.277635635746299e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0908252061015427e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3315806388855, "timer/env.step_count": 4038.0, "timer/env.step_total": 39.530051708221436, "timer/env.step_frac": 0.03951694865314022, "timer/env.step_avg": 0.009789512557756671, "timer/env.step_min": 0.007718086242675781, "timer/env.step_max": 0.04394054412841797, "timer/replay._sample_count": 32304.0, "timer/replay._sample_total": 16.500408411026, "timer/replay._sample_frac": 0.016494939008611147, "timer/replay._sample_avg": 0.0005107853024710872, "timer/replay._sample_min": 0.0003991127014160156, "timer/replay._sample_max": 0.02848362922668457, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4533.0, "timer/agent.policy_total": 48.355459690093994, "timer/agent.policy_frac": 0.04833943127058993, "timer/agent.policy_avg": 0.010667429889718508, "timer/agent.policy_min": 0.009046554565429688, "timer/agent.policy_max": 0.08933138847351074, "timer/dataset_train_count": 2019.0, "timer/dataset_train_total": 0.21605730056762695, "timer/dataset_train_frac": 0.0002159856838965704, "timer/dataset_train_avg": 0.00010701203594236105, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0005002021789550781, "timer/agent.train_count": 2019.0, "timer/agent.train_total": 899.1833198070526, "timer/agent.train_frac": 0.8988852668559837, "timer/agent.train_avg": 0.4453607329405907, "timer/agent.train_min": 0.4321107864379883, "timer/agent.train_max": 0.6945352554321289, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47591447830200195, "timer/agent.report_frac": 0.0004757567265826476, "timer/agent.report_avg": 0.23795723915100098, "timer/agent.report_min": 0.23052144050598145, "timer/agent.report_max": 0.2453930377960205, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.38690185546875e-05, "timer/dataset_eval_frac": 4.385447725909994e-08, "timer/dataset_eval_avg": 4.38690185546875e-05, "timer/dataset_eval_min": 4.38690185546875e-05, "timer/dataset_eval_max": 4.38690185546875e-05, "fps": 32.29276758170912}
{"step": 926384, "time": 29258.990266799927, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 926432, "time": 29260.44165301323, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 926648, "time": 29266.795947551727, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 926728, "time": 29269.259399414062, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 926792, "time": 29271.206644535065, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 926880, "time": 29274.11965560913, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 926960, "time": 29276.540999174118, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 927024, "time": 29278.586626768112, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 927096, "time": 29280.542638778687, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 927304, "time": 29286.831506729126, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 927520, "time": 29293.585852622986, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 927632, "time": 29296.980304956436, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 927656, "time": 29297.4912378788, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 927832, "time": 29302.802150964737, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 928024, "time": 29308.748142957687, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 928216, "time": 29314.818581342697, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 928240, "time": 29315.770145893097, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 928344, "time": 29318.717818260193, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 928408, "time": 29320.650773525238, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 928472, "time": 29322.62425684929, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 928584, "time": 29326.026136636734, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 928624, "time": 29327.50574374199, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 928888, "time": 29335.353268146515, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 929000, "time": 29338.82670688629, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 929000, "time": 29338.83318567276, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 929096, "time": 29341.749069213867, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 929304, "time": 29348.042315483093, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 929480, "time": 29353.363297462463, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 929528, "time": 29354.817101478577, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 929552, "time": 29355.787415981293, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 929808, "time": 29363.540325403214, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 929976, "time": 29368.451841831207, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 29371.70871257782, "eval_episode/length": 12.0, "eval_episode/score": 0.9624999761581421, "eval_episode/reward_rate": 0.07692307692307693}
{"step": 930072, "time": 29372.26879143715, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 930072, "time": 29372.6667368412, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 930072, "time": 29373.444511651993, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 930072, "time": 29373.550370931625, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 930072, "time": 29374.006786108017, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 930072, "time": 29374.17861199379, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 930072, "time": 29374.532660245895, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 930280, "time": 29380.87264728546, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 930280, "time": 29380.880214691162, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 930536, "time": 29388.698888778687, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 930688, "time": 29393.544694185257, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 930960, "time": 29401.877269029617, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 931112, "time": 29406.30992627144, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 931168, "time": 29408.257271289825, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 931248, "time": 29410.682034015656, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 931312, "time": 29412.64329600334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931400, "time": 29415.092223405838, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 931456, "time": 29417.008694171906, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 931464, "time": 29417.037664175034, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 931496, "time": 29418.033729314804, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 932128, "time": 29437.425116062164, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 932200, "time": 29439.38533115387, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 932248, "time": 29440.84149289131, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 932448, "time": 29447.12268424034, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 932448, "time": 29447.129679441452, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 932608, "time": 29451.970368146896, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 932680, "time": 29453.93440246582, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 932880, "time": 29460.348413705826, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 933000, "time": 29463.76957511902, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 933064, "time": 29465.722192764282, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 933064, "time": 29465.72929096222, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 933064, "time": 29465.736591100693, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 933104, "time": 29467.19355392456, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 933352, "time": 29474.49946832657, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 933496, "time": 29478.88242292404, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 933600, "time": 29482.26776242256, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 933632, "time": 29483.248542308807, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 933688, "time": 29484.741629600525, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 933864, "time": 29490.210824012756, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 933928, "time": 29492.644550323486, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 934048, "time": 29496.553448200226, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 934104, "time": 29498.030651569366, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 934224, "time": 29501.91753220558, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 934328, "time": 29504.844646692276, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 934448, "time": 29508.70569062233, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 934768, "time": 29518.562537431717, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 934784, "time": 29519.052818775177, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 934824, "time": 29520.053509235382, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 934880, "time": 29521.980042696, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 934976, "time": 29524.885640859604, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 934984, "time": 29524.914637565613, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 935248, "time": 29533.16429543495, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 935440, "time": 29538.978427648544, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 935456, "time": 29539.46555018425, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 935680, "time": 29546.24440908432, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 935688, "time": 29546.274974822998, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 935696, "time": 29546.750520944595, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 935728, "time": 29547.72132706642, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 935760, "time": 29548.777700662613, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 935920, "time": 29553.61773633957, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 935936, "time": 29554.1119120121, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 936296, "time": 29564.784837007523, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 936400, "time": 29568.16371870041, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 936536, "time": 29572.060558080673, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 936592, "time": 29573.989360809326, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 936696, "time": 29576.896021842957, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 936800, "time": 29580.36495733261, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 936824, "time": 29580.87395119667, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 936976, "time": 29585.710518836975, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 937112, "time": 29589.618694067, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 937144, "time": 29590.58878350258, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 937224, "time": 29593.006675481796, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 937344, "time": 29596.86100792885, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 937368, "time": 29597.37054157257, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 937704, "time": 29607.547491788864, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 937720, "time": 29608.054352521896, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 937784, "time": 29610.091317653656, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 937872, "time": 29612.976363420486, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 937928, "time": 29614.452528953552, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 937952, "time": 29615.405475854874, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 938144, "time": 29621.18223619461, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 938152, "time": 29621.210726737976, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 938232, "time": 29623.635464906693, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 938416, "time": 29629.416677951813, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 938448, "time": 29630.390157699585, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 938552, "time": 29633.33250808716, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 938696, "time": 29637.702288150787, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 938968, "time": 29646.01672434807, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 938992, "time": 29646.98683643341, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 939024, "time": 29647.95850419998, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 939032, "time": 29647.987080335617, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 939496, "time": 29662.072286605835, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 939520, "time": 29663.02063512802, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 939568, "time": 29664.472028017044, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 940000, "time": 29679.896471500397, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 940032, "time": 29680.8697617054, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 29682.54888510704, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 940056, "time": 29682.96542239189, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 940056, "time": 29683.662475824356, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 940056, "time": 29683.771718263626, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 940056, "time": 29683.96771645546, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 940056, "time": 29684.268080949783, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 940056, "time": 29684.526558876038, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 940056, "time": 29684.575463056564, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 940096, "time": 29686.003847122192, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 940200, "time": 29688.953092098236, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 940248, "time": 29690.41356730461, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 940360, "time": 29693.845123529434, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 940416, "time": 29695.77060675621, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 940448, "time": 29696.77262353897, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 940784, "time": 29707.053555727005, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 940864, "time": 29709.47256731987, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 940864, "time": 29709.479140758514, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 940896, "time": 29710.450820207596, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 941016, "time": 29713.895704507828, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 941136, "time": 29717.7549097538, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 941152, "time": 29718.24457859993, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 941216, "time": 29720.17481803894, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 941216, "time": 29720.18160176277, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 941712, "time": 29735.400691509247, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 941880, "time": 29740.27038693428, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 941936, "time": 29742.20066165924, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 942064, "time": 29746.099229812622, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 942128, "time": 29748.53310608864, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 942288, "time": 29753.43014383316, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 942336, "time": 29754.89284300804, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 942528, "time": 29760.87509250641, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 942712, "time": 29766.22665500641, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 942784, "time": 29768.613330841064, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 942928, "time": 29772.9983689785, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 942984, "time": 29774.489746809006, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 943040, "time": 29776.422978401184, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 943144, "time": 29779.34468126297, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 943600, "time": 29793.500034332275, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 943664, "time": 29795.480314970016, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 943856, "time": 29801.306992292404, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 943896, "time": 29802.306929588318, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 943928, "time": 29803.28901410103, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 944000, "time": 29805.719050884247, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 944168, "time": 29810.596307754517, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 944208, "time": 29812.034163236618, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 944296, "time": 29814.50222659111, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 944488, "time": 29820.371661901474, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 944632, "time": 29824.759100675583, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 944728, "time": 29827.721711874008, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 944824, "time": 29830.730618953705, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 945288, "time": 29845.05841732025, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 945296, "time": 29845.542325496674, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 945336, "time": 29846.542400836945, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 945464, "time": 29850.52395939827, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 945656, "time": 29856.454927921295, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 945672, "time": 29856.955404996872, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 945736, "time": 29858.950675725937, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 945976, "time": 29866.291402101517, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 946184, "time": 29872.582447767258, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 946256, "time": 29875.01180100441, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 946264, "time": 29875.04192662239, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 946472, "time": 29881.41367316246, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 946496, "time": 29882.355880975723, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 946608, "time": 29885.75445151329, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 946656, "time": 29887.19905090332, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 946952, "time": 29895.90046787262, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 947024, "time": 29898.33488035202, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 947224, "time": 29904.195029497147, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 947360, "time": 29908.68939113617, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 947472, "time": 29912.116240262985, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 947544, "time": 29914.069802761078, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 947568, "time": 29915.023865699768, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 947752, "time": 29920.36349582672, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 947944, "time": 29926.171609163284, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 948304, "time": 29937.303751707077, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 948440, "time": 29941.328991651535, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 948496, "time": 29943.259561538696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 948544, "time": 29944.71468782425, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 948616, "time": 29946.694583654404, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 949048, "time": 29959.760186195374, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 949160, "time": 29963.15081000328, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 949392, "time": 29970.52862715721, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 949440, "time": 29971.982782125473, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 949544, "time": 29974.910014867783, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 949608, "time": 29976.857666254044, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 949640, "time": 29977.833821058273, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 949752, "time": 29981.233826875687, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 949776, "time": 29982.185321569443, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 949872, "time": 29985.107442617416, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 949920, "time": 29986.56226348877, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 29991.12225317955, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 950040, "time": 29991.484521865845, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 950040, "time": 29991.548169374466, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 950040, "time": 29991.68796658516, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 950040, "time": 29991.71387219429, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 950040, "time": 29991.99667739868, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 950040, "time": 29992.35609459877, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 950040, "time": 29992.461356639862, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 950168, "time": 29996.312599897385, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 950200, "time": 29997.30879354477, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 950336, "time": 30002.28222680092, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 950544, "time": 30008.597975730896, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 950728, "time": 30013.92488360405, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 950784, "time": 30015.841871261597, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 950800, "time": 30016.33004307747, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 950992, "time": 30022.168343544006, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 951152, "time": 30027.01044869423, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 951288, "time": 30030.960090875626, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 951344, "time": 30032.89576816559, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 951432, "time": 30035.334039211273, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 951640, "time": 30041.7132062912, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 951672, "time": 30042.69401717186, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 951768, "time": 30045.62122607231, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 951800, "time": 30046.62375664711, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 952024, "time": 30053.425659656525, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 952480, "time": 30067.565592765808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 952576, "time": 30070.46832728386, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 952648, "time": 30072.455195188522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 952776, "time": 30076.36284518242, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 952928, "time": 30081.23053097725, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 953040, "time": 30084.695147275925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 953112, "time": 30086.679371595383, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 953136, "time": 30087.636758565903, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 953256, "time": 30091.154473543167, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 953288, "time": 30092.121850967407, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 953528, "time": 30099.365475654602, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 953736, "time": 30105.706658124924, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 953824, "time": 30108.58193039894, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 953872, "time": 30110.07412815094, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 953928, "time": 30111.852469444275, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 953984, "time": 30113.790086507797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 954112, "time": 30117.73500394821, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 954232, "time": 30121.2672894001, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 954248, "time": 30121.759651184082, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 954312, "time": 30123.702086925507, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 954456, "time": 30128.0956530571, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 954648, "time": 30133.949439287186, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 954864, "time": 30140.72540163994, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 954984, "time": 30144.116270780563, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 955152, "time": 30149.523109912872, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 955224, "time": 30151.472506046295, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 955280, "time": 30153.39169859886, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 955552, "time": 30161.67772102356, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 955776, "time": 30168.50239634514, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 955848, "time": 30170.477602243423, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 955880, "time": 30171.446813583374, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 955968, "time": 30174.351950883865, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 956088, "time": 30177.780279397964, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 956400, "time": 30187.586774349213, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 956400, "time": 30187.59501504898, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 956416, "time": 30188.09014582634, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 956536, "time": 30191.52339196205, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 956616, "time": 30193.965943574905, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 956712, "time": 30196.873431682587, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 956776, "time": 30198.8345348835, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 956808, "time": 30200.180315971375, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 957160, "time": 30210.95228910446, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 957176, "time": 30211.443093061447, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 957232, "time": 30213.371394634247, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 957248, "time": 30213.858827590942, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 957320, "time": 30215.81147813797, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 957520, "time": 30222.084918022156, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 957784, "time": 30229.83185338974, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 957872, "time": 30232.726966142654, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 957904, "time": 30233.70751476288, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 958016, "time": 30237.105991363525, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 958304, "time": 30245.995717287064, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 958328, "time": 30246.50834774971, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 958345, "time": 30248.01459789276, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.162118137472927, "train/action_min": 0.0, "train/action_std": 1.74358201558047, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013090758169494053, "train/actor_opt_grad_steps": 58795.0, "train/actor_opt_loss": -23.82570698709771, "train/adv_mag": 1.1004782608239958, "train/adv_max": 0.41939527917616437, "train/adv_mean": 0.0015447266453313456, "train/adv_min": -1.0246365837531515, "train/adv_std": 0.033695705345656614, "train/cont_avg": 0.9939327428836634, "train/cont_loss_mean": 0.020528338042705662, "train/cont_loss_std": 0.24440149649387538, "train/cont_neg_acc": 0.25794608850437817, "train/cont_neg_loss": 2.659385002780669, "train/cont_pos_acc": 0.9999123885489927, "train/cont_pos_loss": 0.0045451536373521135, "train/cont_pred": 0.9939486664710658, "train/cont_rate": 0.9939327428836634, "train/dyn_loss_mean": 1.0000025157881256, "train/dyn_loss_std": 7.721401133233368e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10021240659758891, "train/extr_critic_critic_opt_grad_steps": 58795.0, "train/extr_critic_critic_opt_loss": 13101.788458191522, "train/extr_critic_mag": 1.9243082669701908, "train/extr_critic_max": 1.9243082669701908, "train/extr_critic_mean": 1.806388761147414, "train/extr_critic_min": 1.3286437114866654, "train/extr_critic_std": 0.036885798512266414, "train/extr_return_normed_mag": 1.1316371146995243, "train/extr_return_normed_max": 0.29447288147293693, "train/extr_return_normed_mean": 0.07132364473868125, "train/extr_return_normed_min": -1.049665910772758, "train/extr_return_normed_std": 0.050791559003219744, "train/extr_return_rate": 0.9996635556811153, "train/extr_return_raw_mag": 2.0310824123939666, "train/extr_return_raw_max": 2.0310824123939666, "train/extr_return_raw_mean": 1.8079332839144338, "train/extr_return_raw_min": 0.6869436201482716, "train/extr_return_raw_std": 0.05079155889256756, "train/extr_reward_mag": 0.2618889655217086, "train/extr_reward_max": 0.2618889655217086, "train/extr_reward_mean": 0.002535818457040973, "train/extr_reward_min": 1.475362494440362e-08, "train/extr_reward_std": 0.0093730798539807, "train/image_loss_mean": 0.08366711031977493, "train/image_loss_std": 0.09853366876740267, "train/model_loss_mean": 0.7235419301703425, "train/model_loss_std": 0.5045827336535595, "train/model_opt_grad_norm": 18.65038770968371, "train/model_opt_grad_steps": 58744.648514851484, "train/model_opt_loss": 3816.69857576578, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5297.029702970297, "train/policy_entropy_mag": 1.2884204187015496, "train/policy_entropy_max": 1.2884204187015496, "train/policy_entropy_mean": 0.09208076262828147, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11296438872076497, "train/policy_logprob_mag": 6.551080255225154, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09194332409170594, "train/policy_logprob_min": -6.551080255225154, "train/policy_logprob_std": 0.6287134997915513, "train/policy_randomness_mag": 0.6621171554716507, "train/policy_randomness_max": 0.6621171554716507, "train/policy_randomness_mean": 0.047320153951497364, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.058052215374784895, "train/post_ent_mag": 28.987959266889213, "train/post_ent_max": 28.987959266889213, "train/post_ent_mean": 28.792565043609923, "train/post_ent_min": 28.604654906999947, "train/post_ent_std": 0.08300130862263169, "train/prior_ent_mag": 29.289371584901716, "train/prior_ent_max": 29.289371584901716, "train/prior_ent_mean": 28.36125887502538, "train/prior_ent_min": 27.339986159069703, "train/prior_ent_std": 0.29658669926742515, "train/rep_loss_mean": 1.0000025157881256, "train/rep_loss_std": 7.721401133233368e-05, "train/reward_avg": 0.002627669219538514, "train/reward_loss_mean": 0.01934494991270401, "train/reward_loss_std": 0.2559473615250375, "train/reward_max_data": 0.7970915845420101, "train/reward_max_pred": 0.2872680443348271, "train/reward_neg_acc": 0.9995145009885921, "train/reward_neg_loss": 0.0035290469272560116, "train/reward_pos_acc": 0.15809283553812634, "train/reward_pos_loss": 3.956897056221369, "train/reward_pred": 0.002082849634317958, "train/reward_rate": 0.004031946163366337, "train_stats/mean_log_entropy": 0.07593767871677658, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.017235588282346725, "report/cont_loss_std": 0.2037002146244049, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.6083306074142456, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00470728101208806, "report/cont_pred": 0.9915907979011536, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09934395551681519, "report/image_loss_std": 0.11433582007884979, "report/model_loss_mean": 0.7386182546615601, "report/model_loss_std": 0.5155311226844788, "report/post_ent_mag": 28.877635955810547, "report/post_ent_max": 28.877635955810547, "report/post_ent_mean": 28.676651000976562, "report/post_ent_min": 28.485557556152344, "report/post_ent_std": 0.09084077179431915, "report/prior_ent_mag": 29.239315032958984, "report/prior_ent_max": 29.239315032958984, "report/prior_ent_mean": 28.31252670288086, "report/prior_ent_min": 27.4478816986084, "report/prior_ent_std": 0.284729927778244, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0041046142578125, "report/reward_loss_mean": 0.022038720548152924, "report/reward_loss_std": 0.2744893431663513, "report/reward_max_data": 0.8374999761581421, "report/reward_max_pred": 0.5956041812896729, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0032865582033991814, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.20365571975708, "report/reward_pred": 0.002724037505686283, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.028473716229200363, "eval/cont_loss_std": 0.38658109307289124, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.103771209716797, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.004649022594094276, "eval/cont_pred": 0.9957121014595032, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1298290491104126, "eval/image_loss_std": 0.12710346281528473, "eval/model_loss_mean": 0.7832499146461487, "eval/model_loss_std": 0.8169383406639099, "eval/post_ent_mag": 28.88112449645996, "eval/post_ent_max": 28.88112449645996, "eval/post_ent_mean": 28.654659271240234, "eval/post_ent_min": 28.4604434967041, "eval/post_ent_std": 0.10385649651288986, "eval/prior_ent_mag": 29.239315032958984, "eval/prior_ent_max": 29.239315032958984, "eval/prior_ent_mean": 28.25682258605957, "eval/prior_ent_min": 27.250926971435547, "eval/prior_ent_std": 0.31071266531944275, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0017120360862463713, "eval/reward_loss_mean": 0.024947116151452065, "eval/reward_loss_std": 0.4281066358089447, "eval/reward_max_data": 0.78125, "eval/reward_max_pred": 0.06811094284057617, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0021862201392650604, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.771239280700684, "eval/reward_pred": 0.0011305795051157475, "eval/reward_rate": 0.0029296875, "replay/size": 957841.0, "replay/inserts": 32320.0, "replay/samples": 32320.0, "replay/insert_wait_avg": 1.2802605581755685e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.002883245449255e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3440.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1255574780841207e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0501832962036, "timer/env.step_count": 4040.0, "timer/env.step_total": 39.563647985458374, "timer/env.step_frac": 0.03956166265082326, "timer/env.step_avg": 0.009792982174618409, "timer/env.step_min": 0.007709503173828125, "timer/env.step_max": 0.04314064979553223, "timer/replay._sample_count": 32320.0, "timer/replay._sample_total": 16.53339672088623, "timer/replay._sample_frac": 0.016532567062176342, "timer/replay._sample_avg": 0.0005115531163640541, "timer/replay._sample_min": 0.0004172325134277344, "timer/replay._sample_max": 0.01950526237487793, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4470.0, "timer/agent.policy_total": 47.362730503082275, "timer/agent.policy_frac": 0.047360353804419, "timer/agent.policy_avg": 0.010595689150577691, "timer/agent.policy_min": 0.009076595306396484, "timer/agent.policy_max": 0.07930827140808105, "timer/dataset_train_count": 2020.0, "timer/dataset_train_total": 0.21786808967590332, "timer/dataset_train_frac": 0.00021785715688566926, "timer/dataset_train_avg": 0.000107855489938566, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.001077413558959961, "timer/agent.train_count": 2020.0, "timer/agent.train_total": 901.7393922805786, "timer/agent.train_frac": 0.9016941422963507, "timer/agent.train_avg": 0.4464056397428607, "timer/agent.train_min": 0.43166613578796387, "timer/agent.train_max": 2.6375203132629395, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4779181480407715, "timer/agent.report_frac": 0.00047789416573629836, "timer/agent.report_avg": 0.23895907402038574, "timer/agent.report_min": 0.23058176040649414, "timer/agent.report_max": 0.24733638763427734, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.123126657440337e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 32.31782751176296}
{"step": 958488, "time": 30252.568895101547, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 958696, "time": 30258.85702443123, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 958760, "time": 30260.780408382416, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 958760, "time": 30260.787897109985, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 958976, "time": 30267.5078394413, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 959072, "time": 30270.522018909454, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 959152, "time": 30272.968260526657, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 959424, "time": 30281.20445084572, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 959560, "time": 30285.121616840363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 959608, "time": 30286.582583665848, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 959624, "time": 30287.074941396713, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 959680, "time": 30289.023107528687, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 959816, "time": 30292.923020124435, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 959992, "time": 30298.228358507156, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 30299.2982981205, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 30300.568104743958, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 960024, "time": 30300.668333530426, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 960024, "time": 30300.73084282875, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 960024, "time": 30300.975061655045, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 960024, "time": 30301.000769138336, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 960024, "time": 30301.13523864746, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 960024, "time": 30301.87728190422, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 960024, "time": 30302.0125579834, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 960040, "time": 30302.50168275833, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 960208, "time": 30307.801857233047, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 960296, "time": 30310.246220588684, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 960424, "time": 30314.099689483643, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 960424, "time": 30314.13013291359, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 960440, "time": 30314.646988391876, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 960536, "time": 30317.558994293213, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 960704, "time": 30322.907574892044, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 961008, "time": 30332.29354763031, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 961056, "time": 30333.74584722519, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 961136, "time": 30336.202567338943, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 961320, "time": 30341.590252637863, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 961336, "time": 30342.085552692413, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 961608, "time": 30350.376240730286, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 961656, "time": 30351.836931705475, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 961680, "time": 30352.79038643837, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 961736, "time": 30354.288967609406, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 962016, "time": 30363.201204538345, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 962104, "time": 30365.66588950157, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 962216, "time": 30369.071835041046, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 962280, "time": 30371.023811340332, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 962296, "time": 30371.51199555397, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 962336, "time": 30372.952291965485, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 962344, "time": 30372.981845140457, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 962360, "time": 30373.490961313248, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 962680, "time": 30383.17359471321, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 962728, "time": 30384.627878189087, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 963176, "time": 30398.36312365532, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 963280, "time": 30401.74001646042, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 963408, "time": 30405.637373209, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 963440, "time": 30406.61807656288, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 963496, "time": 30408.122210741043, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 963536, "time": 30409.578159332275, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 963552, "time": 30410.070267677307, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 963616, "time": 30412.01571416855, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 963624, "time": 30412.044033050537, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 963992, "time": 30423.37827730179, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 964088, "time": 30426.288068294525, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 964400, "time": 30436.04193878174, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 964408, "time": 30436.07074213028, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 964456, "time": 30437.557422876358, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 964504, "time": 30439.021671056747, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 964616, "time": 30442.416822195053, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 964632, "time": 30442.91093659401, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 964920, "time": 30451.83501434326, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 964928, "time": 30452.300796747208, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 965032, "time": 30455.23685002327, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 965064, "time": 30456.207939386368, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 965112, "time": 30457.684824466705, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 965184, "time": 30460.10398864746, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 965192, "time": 30460.132963180542, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 965480, "time": 30468.91268348694, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 965480, "time": 30468.922401189804, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 965744, "time": 30477.153419733047, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 965848, "time": 30480.212116479874, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 965912, "time": 30482.16997051239, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 965968, "time": 30484.091409921646, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 966096, "time": 30487.97353386879, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 966120, "time": 30488.489343881607, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 966832, "time": 30511.050851345062, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 966856, "time": 30511.561420679092, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 966864, "time": 30512.031804800034, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 966944, "time": 30514.46892786026, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 967232, "time": 30523.273602962494, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 967248, "time": 30523.761425733566, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 967424, "time": 30529.09200167656, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 967744, "time": 30538.950592279434, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 967760, "time": 30539.45277762413, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 967792, "time": 30540.470862865448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 968136, "time": 30550.855065107346, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 968232, "time": 30553.785160779953, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 968480, "time": 30561.55838227272, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 968584, "time": 30564.492646455765, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 968752, "time": 30569.981419324875, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 968832, "time": 30572.43098092079, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 968944, "time": 30575.86020755768, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 969072, "time": 30579.76262331009, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 969080, "time": 30579.791255235672, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 969168, "time": 30582.694382429123, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 969344, "time": 30588.035200834274, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 969384, "time": 30589.03642463684, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 969384, "time": 30589.045315742493, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 969488, "time": 30592.4451110363, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 969552, "time": 30594.40903687477, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 969712, "time": 30599.37126851082, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 969952, "time": 30606.648161888123, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 30609.051582336426, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 970008, "time": 30609.99426817894, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 970008, "time": 30610.32415652275, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 970008, "time": 30610.676470518112, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 970008, "time": 30611.55721449852, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 970008, "time": 30611.76943564415, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 970008, "time": 30612.351713895798, "eval_episode/length": 214.0, "eval_episode/score": 0.33125001192092896, "eval_episode/reward_rate": 0.004651162790697674}
{"step": 970008, "time": 30613.07023048401, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 970160, "time": 30617.91224837303, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 970176, "time": 30618.40522503853, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 970184, "time": 30618.43362545967, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 970256, "time": 30620.85358953476, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 970488, "time": 30627.656332731247, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 970544, "time": 30629.721705436707, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 970592, "time": 30631.17202448845, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 970840, "time": 30638.485208511353, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 971080, "time": 30645.767501592636, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 971448, "time": 30656.92576599121, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 971872, "time": 30670.135823726654, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 971944, "time": 30672.08741426468, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 972096, "time": 30676.940208911896, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 972240, "time": 30681.34721469879, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 972280, "time": 30682.36079454422, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 972408, "time": 30686.233194112778, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 972496, "time": 30689.249759674072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972840, "time": 30699.479818344116, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 973184, "time": 30710.11209177971, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 973288, "time": 30713.064643144608, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 973392, "time": 30716.423758983612, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 973536, "time": 30720.865683555603, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 973592, "time": 30722.35862851143, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 973608, "time": 30722.847804546356, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 973656, "time": 30724.297129631042, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 973664, "time": 30724.77219104767, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 973888, "time": 30731.581352233887, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 974104, "time": 30737.937480211258, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 974448, "time": 30748.729267835617, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 974512, "time": 30750.684294223785, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 974616, "time": 30753.627803325653, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 974816, "time": 30759.923490524292, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 974904, "time": 30762.904821157455, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 975256, "time": 30773.543279886246, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 975256, "time": 30773.55162191391, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 975496, "time": 30780.87683391571, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 975504, "time": 30781.345993995667, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 975584, "time": 30783.755800008774, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 975632, "time": 30785.22849702835, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 975712, "time": 30787.659289121628, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 975816, "time": 30790.59984087944, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 975856, "time": 30792.0236120224, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 976008, "time": 30796.419412612915, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 976104, "time": 30799.319111824036, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 976192, "time": 30802.233540296555, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 976408, "time": 30808.74093914032, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 976696, "time": 30817.549811840057, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 976896, "time": 30823.867337226868, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 976896, "time": 30823.881183624268, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 977208, "time": 30833.12340950966, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 977216, "time": 30833.59712576866, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 977272, "time": 30835.099660634995, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 977280, "time": 30835.57408761978, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 977320, "time": 30836.576351881027, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 977344, "time": 30837.521782636642, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 977480, "time": 30841.50074505806, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 977560, "time": 30843.92821788788, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 977736, "time": 30849.274574279785, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 977840, "time": 30852.64920282364, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 977936, "time": 30855.57946562767, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 978080, "time": 30859.95458459854, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 978312, "time": 30866.795307397842, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 978472, "time": 30871.778446912766, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 978632, "time": 30876.667365312576, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 978936, "time": 30885.92162680626, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 978984, "time": 30887.385509490967, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 979248, "time": 30895.624717712402, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 979424, "time": 30901.080498456955, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 979488, "time": 30903.039353132248, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 979496, "time": 30903.06698703766, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 979576, "time": 30905.48554944992, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 979760, "time": 30911.313558340073, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 979776, "time": 30911.805763483047, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 979792, "time": 30912.315193891525, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 979944, "time": 30916.69606900215, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 980056, "time": 30920.132202386856, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 30922.544845581055, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 980096, "time": 30923.161247968674, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 980096, "time": 30924.01200723648, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 980096, "time": 30924.242825984955, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 980096, "time": 30925.987778186798, "eval_episode/length": 191.0, "eval_episode/score": 0.40312498807907104, "eval_episode/reward_rate": 0.005208333333333333}
{"step": 980096, "time": 30926.89266848564, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 980096, "time": 30927.389574289322, "eval_episode/length": 264.0, "eval_episode/score": 0.17499999701976776, "eval_episode/reward_rate": 0.0037735849056603774}
{"step": 980096, "time": 30927.69314980507, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 980344, "time": 30935.12119293213, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 980544, "time": 30941.412059783936, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 980808, "time": 30949.177231550217, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 980936, "time": 30953.04953098297, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 981088, "time": 30957.88179254532, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 981312, "time": 30964.76005935669, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 981552, "time": 30972.057490110397, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 981592, "time": 30973.05967617035, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 981736, "time": 30977.455430984497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981808, "time": 30979.859680891037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981816, "time": 30979.88843846321, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 981904, "time": 30982.788313150406, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 982336, "time": 30996.02188563347, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 982424, "time": 30998.471383333206, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 982640, "time": 31005.227724552155, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 982848, "time": 31011.538756132126, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 982872, "time": 31012.05142879486, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 983184, "time": 31022.265708208084, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 983216, "time": 31023.247435569763, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 983224, "time": 31023.27525448799, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 983472, "time": 31031.05183172226, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 983480, "time": 31031.079608678818, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 983640, "time": 31035.95100426674, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 983688, "time": 31037.40891814232, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 983728, "time": 31038.8453373909, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 983824, "time": 31041.762170553207, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 984064, "time": 31049.18046092987, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 984272, "time": 31055.54035139084, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 984392, "time": 31058.963437080383, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 984456, "time": 31060.922736167908, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 984496, "time": 31062.367223739624, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 984584, "time": 31064.816548347473, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 984736, "time": 31069.663553476334, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 985016, "time": 31077.960086107254, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 985144, "time": 31081.96428990364, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 985176, "time": 31082.955646038055, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 985192, "time": 31084.359008789062, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 985400, "time": 31090.703134059906, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 985464, "time": 31092.63492846489, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 985648, "time": 31098.49848985672, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 985688, "time": 31099.50528717041, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 986016, "time": 31109.845242738724, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 986096, "time": 31112.31016278267, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 986256, "time": 31117.21320796013, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 986656, "time": 31129.382304906845, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 986704, "time": 31130.87376475334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986760, "time": 31132.35377717018, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 986776, "time": 31132.846212148666, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 986880, "time": 31136.299170970917, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 987032, "time": 31140.843337535858, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 987104, "time": 31143.252870559692, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 987224, "time": 31146.698662042618, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 987264, "time": 31148.133529901505, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 987536, "time": 31156.35908818245, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 987592, "time": 31157.841219186783, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 987656, "time": 31159.80974650383, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 987744, "time": 31162.71267771721, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 987808, "time": 31164.68471956253, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 987824, "time": 31165.17912888527, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 988088, "time": 31173.1183886528, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 988208, "time": 31177.037700891495, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 988432, "time": 31183.87353825569, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 988448, "time": 31184.362357139587, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 988480, "time": 31185.339121580124, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 988528, "time": 31186.794873952866, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 988536, "time": 31186.823276281357, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 988688, "time": 31191.672183036804, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 989112, "time": 31204.48900961876, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 989208, "time": 31207.41868829727, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 989216, "time": 31207.894354104996, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 989392, "time": 31213.285163402557, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 989440, "time": 31214.75236749649, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 989456, "time": 31215.249653339386, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 989760, "time": 31224.524254322052, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 989912, "time": 31229.024364948273, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 990016, "time": 31232.424777269363, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 990064, "time": 31233.9016559124, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 31236.382611751556, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 990080, "time": 31236.492945194244, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 990080, "time": 31236.906421661377, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 990080, "time": 31236.974596977234, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 990080, "time": 31237.08943605423, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 990080, "time": 31237.580263137817, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 990080, "time": 31237.702798128128, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 990080, "time": 31237.80716562271, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 990184, "time": 31240.723635673523, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 990240, "time": 31242.672868728638, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 990393, "time": 31248.072623729706, "train_stats/mean_log_entropy": 0.07801478970213793, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.167693786621094, "train/action_min": 0.0, "train/action_std": 1.7530530393123627, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012936414640862495, "train/actor_opt_grad_steps": 60805.0, "train/actor_opt_loss": -27.114890699386596, "train/adv_mag": 1.090027859210968, "train/adv_max": 0.4584024178981781, "train/adv_mean": 0.0006649211743933847, "train/adv_min": -0.9923415207862853, "train/adv_std": 0.032992887855507434, "train/cont_avg": 0.993994140625, "train/cont_loss_mean": 0.020114540082868188, "train/cont_loss_std": 0.2414719378016889, "train/cont_neg_acc": 0.2747839579358697, "train/cont_neg_loss": 2.595220948686474, "train/cont_pos_acc": 0.9998624634742737, "train/cont_pos_loss": 0.004535299106501043, "train/cont_pred": 0.9939227363467217, "train/cont_rate": 0.993994140625, "train/dyn_loss_mean": 1.0000010859966277, "train/dyn_loss_std": 1.9107763655483723e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10584196997340768, "train/extr_critic_critic_opt_grad_steps": 60805.0, "train/extr_critic_critic_opt_loss": 12297.40427734375, "train/extr_critic_mag": 1.9671084022521972, "train/extr_critic_max": 1.9671084022521972, "train/extr_critic_mean": 1.8502736604213714, "train/extr_critic_min": 1.3081476432085037, "train/extr_critic_std": 0.03852729005739093, "train/extr_return_normed_mag": 1.107168790102005, "train/extr_return_normed_max": 0.2949480468034744, "train/extr_return_normed_mean": 0.0723564862459898, "train/extr_return_normed_min": -1.0166146975755692, "train/extr_return_normed_std": 0.0512506743427366, "train/extr_return_rate": 0.9997194319963455, "train/extr_return_raw_mag": 2.0735294675827025, "train/extr_return_raw_max": 2.0735294675827025, "train/extr_return_raw_mean": 1.8509379988908767, "train/extr_return_raw_min": 0.7619667232036591, "train/extr_return_raw_std": 0.051250674268230795, "train/extr_reward_mag": 0.2570652639865875, "train/extr_reward_max": 0.2570652639865875, "train/extr_reward_mean": 0.0024866738717537373, "train/extr_reward_min": 9.5367431640625e-09, "train/extr_reward_std": 0.009213186821434648, "train/image_loss_mean": 0.08369181703776121, "train/image_loss_std": 0.09894192654639483, "train/model_loss_mean": 0.7228621712327004, "train/model_loss_std": 0.49797205574810505, "train/model_opt_grad_norm": 19.227266800403594, "train/model_opt_grad_steps": 60752.77, "train/model_opt_loss": 3811.8993981933595, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5275.0, "train/policy_entropy_mag": 1.2813040792942048, "train/policy_entropy_max": 1.2813040792942048, "train/policy_entropy_mean": 0.09112551920115948, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11113100610673428, "train/policy_logprob_mag": 6.551080260276795, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09096339307725429, "train/policy_logprob_min": -6.551080260276795, "train/policy_logprob_std": 0.6282468363642693, "train/policy_randomness_mag": 0.65846008092165, "train/policy_randomness_max": 0.65846008092165, "train/policy_randomness_mean": 0.04682925594970584, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05711004361510277, "train/post_ent_mag": 29.06353145599365, "train/post_ent_max": 29.06353145599365, "train/post_ent_mean": 28.842096376419068, "train/post_ent_min": 28.633452253341673, "train/post_ent_std": 0.09373440124094486, "train/prior_ent_mag": 29.30656138420105, "train/prior_ent_max": 29.30656138420105, "train/prior_ent_mean": 28.37815628051758, "train/prior_ent_min": 27.334070682525635, "train/prior_ent_std": 0.30380318224430086, "train/rep_loss_mean": 1.0000010859966277, "train/rep_loss_std": 1.9107763655483723e-05, "train/reward_avg": 0.002596252446528524, "train/reward_loss_mean": 0.019055141729768365, "train/reward_loss_std": 0.2513198347762227, "train/reward_max_data": 0.7817500005662441, "train/reward_max_pred": 0.2964161503314972, "train/reward_neg_acc": 0.9995243999361992, "train/reward_neg_loss": 0.0036019366842810997, "train/reward_pos_acc": 0.17075295348962147, "train/reward_pos_loss": 3.912766350232638, "train/reward_pred": 0.002116658286540769, "train/reward_rate": 0.003955078125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.016413457691669464, "report/cont_loss_std": 0.24653641879558563, "report/cont_neg_acc": 0.5714285969734192, "report/cont_neg_loss": 1.926087737083435, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003269190900027752, "report/cont_pred": 0.9929181337356567, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07904725521802902, "report/image_loss_std": 0.09245526790618896, "report/model_loss_mean": 0.7083466053009033, "report/model_loss_std": 0.4535142779350281, "report/post_ent_mag": 29.299808502197266, "report/post_ent_max": 29.299808502197266, "report/post_ent_mean": 29.08250617980957, "report/post_ent_min": 28.85895538330078, "report/post_ent_std": 0.09394147247076035, "report/prior_ent_mag": 29.37684440612793, "report/prior_ent_max": 29.37684440612793, "report/prior_ent_mean": 28.592885971069336, "report/prior_ent_min": 27.395925521850586, "report/prior_ent_std": 0.3196471333503723, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0017730712424963713, "report/reward_loss_mean": 0.012885939329862595, "report/reward_loss_std": 0.2106173038482666, "report/reward_max_data": 0.840624988079071, "report/reward_max_pred": 0.4959155321121216, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002967106644064188, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.3885955810546875, "report/reward_pred": 0.0019846907816827297, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.054534707218408585, "eval/cont_loss_std": 0.6168377995491028, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.276522636413574, "eval/cont_pos_acc": 0.999015748500824, "eval/cont_pos_loss": 0.005542680621147156, "eval/cont_pred": 0.9958930015563965, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11406323313713074, "eval/image_loss_std": 0.12270907312631607, "eval/model_loss_mean": 0.8113805651664734, "eval/model_loss_std": 1.0722845792770386, "eval/post_ent_mag": 29.30058479309082, "eval/post_ent_max": 29.30058479309082, "eval/post_ent_mean": 29.07080078125, "eval/post_ent_min": 28.845897674560547, "eval/post_ent_std": 0.09765487164258957, "eval/prior_ent_mag": 29.37684440612793, "eval/prior_ent_max": 29.37684440612793, "eval/prior_ent_mean": 28.57892608642578, "eval/prior_ent_min": 27.65214729309082, "eval/prior_ent_std": 0.30487892031669617, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0040130615234375, "eval/reward_loss_mean": 0.042782627046108246, "eval/reward_loss_std": 0.522703230381012, "eval/reward_max_data": 0.815625011920929, "eval/reward_max_pred": 0.733466386795044, "eval/reward_neg_acc": 0.9970530867576599, "eval/reward_neg_loss": 0.005568260792642832, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.356820583343506, "eval/reward_pred": 0.0022669362369924784, "eval/reward_rate": 0.005859375, "replay/size": 989889.0, "replay/inserts": 32048.0, "replay/samples": 32048.0, "replay/insert_wait_avg": 1.2731528317874751e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.120500499822471e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1041405655088879e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0402886867523, "timer/env.step_count": 4006.0, "timer/env.step_total": 39.21144700050354, "timer/env.step_frac": 0.03920986728644284, "timer/env.step_avg": 0.009788179480904529, "timer/env.step_min": 0.0077877044677734375, "timer/env.step_max": 0.03548264503479004, "timer/replay._sample_count": 32048.0, "timer/replay._sample_total": 16.376855850219727, "timer/replay._sample_frac": 0.016376196074785875, "timer/replay._sample_avg": 0.0005110102299744049, "timer/replay._sample_min": 0.00040721893310546875, "timer/replay._sample_max": 0.009932279586791992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4846.0, "timer/agent.policy_total": 51.467220067977905, "timer/agent.policy_frac": 0.05146514660480768, "timer/agent.policy_avg": 0.010620557174572411, "timer/agent.policy_min": 0.009014368057250977, "timer/agent.policy_max": 0.09094500541687012, "timer/dataset_train_count": 2003.0, "timer/dataset_train_total": 0.21523356437683105, "timer/dataset_train_frac": 0.00021522489324852565, "timer/dataset_train_avg": 0.00010745559879023019, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.001085519790649414, "timer/agent.train_count": 2003.0, "timer/agent.train_total": 893.9958608150482, "timer/agent.train_frac": 0.8939598443469102, "timer/agent.train_avg": 0.44632843775089776, "timer/agent.train_min": 0.43300580978393555, "timer/agent.train_max": 0.7236032485961914, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4793274402618408, "timer/agent.report_frac": 0.00047930812956675084, "timer/agent.report_avg": 0.2396637201309204, "timer/agent.report_min": 0.23129868507385254, "timer/agent.report_max": 0.24802875518798828, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.218521147880761e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 32.04615724266035}
{"step": 990448, "time": 31249.729895353317, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 990464, "time": 31250.22488975525, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 990536, "time": 31252.21560239792, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 990680, "time": 31256.629150867462, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 990752, "time": 31259.18547487259, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 990992, "time": 31266.529027938843, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 991056, "time": 31268.488659858704, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 991224, "time": 31273.421871185303, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 991456, "time": 31281.202507019043, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 991472, "time": 31281.71622467041, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 991696, "time": 31288.664944648743, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 991752, "time": 31290.162048339844, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 991776, "time": 31291.125074625015, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 991928, "time": 31295.552232980728, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 992224, "time": 31304.802686929703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 992312, "time": 31307.285290956497, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 992480, "time": 31312.629106283188, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 992488, "time": 31312.657101631165, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 992520, "time": 31313.633209228516, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 992584, "time": 31315.59002637863, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 992608, "time": 31316.565705299377, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 992608, "time": 31316.588788747787, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 993064, "time": 31330.433319330215, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 993072, "time": 31330.91962480545, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 993088, "time": 31331.406303167343, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 993416, "time": 31341.14091515541, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 993432, "time": 31341.62967300415, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 993512, "time": 31344.04603767395, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 993592, "time": 31346.493186950684, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 993680, "time": 31349.48867201805, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 993888, "time": 31355.79877972603, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 994032, "time": 31360.209564208984, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 994128, "time": 31363.11824941635, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 994336, "time": 31369.413304567337, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 994496, "time": 31374.30241560936, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 994624, "time": 31378.230749368668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 994856, "time": 31385.150567293167, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 995024, "time": 31390.634625911713, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 995056, "time": 31391.607966899872, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 995248, "time": 31397.419730186462, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 995264, "time": 31397.91113305092, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 995304, "time": 31398.912033081055, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 995336, "time": 31399.90270614624, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 995656, "time": 31409.756866693497, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 995744, "time": 31412.641932725906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 995976, "time": 31419.461463689804, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 996160, "time": 31425.245349884033, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 996224, "time": 31427.17733025551, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 996232, "time": 31427.20642018318, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 996296, "time": 31429.17212319374, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 996584, "time": 31437.881812095642, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 996848, "time": 31446.194788455963, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 996888, "time": 31447.188942432404, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 996952, "time": 31449.136054754257, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 997048, "time": 31452.024046182632, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 997232, "time": 31457.78803753853, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 997248, "time": 31458.272346735, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 997392, "time": 31462.60296845436, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 997440, "time": 31464.046909093857, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 997744, "time": 31473.283101081848, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 997848, "time": 31476.211094141006, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 997984, "time": 31480.556661844254, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 998056, "time": 31482.52636218071, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 998128, "time": 31484.93631362915, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 998216, "time": 31487.381198644638, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 998328, "time": 31490.778160333633, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 998432, "time": 31494.17533349991, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 998624, "time": 31500.1250064373, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 998688, "time": 31502.09734559059, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 998720, "time": 31503.07722377777, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 998912, "time": 31508.93312883377, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 998984, "time": 31510.90452528, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 999008, "time": 31511.87656736374, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 999088, "time": 31514.28160881996, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 999192, "time": 31517.213094234467, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 999224, "time": 31518.178045749664, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 999240, "time": 31518.66439151764, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 999528, "time": 31527.8677713871, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 999656, "time": 31531.805834770203, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 999664, "time": 31532.270421028137, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 999784, "time": 31535.66215133667, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 999888, "time": 31539.036207914352, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1000000, "time": 31542.440187454224, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 31545.163737535477, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1000064, "time": 31545.695657014847, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1000064, "time": 31545.849863052368, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1000064, "time": 31546.517534971237, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1000064, "time": 31546.584124803543, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1000064, "time": 31547.025399923325, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 1000064, "time": 31547.139207839966, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1000064, "time": 31547.34537935257, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1000080, "time": 31547.832761764526, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1000416, "time": 31557.9608502388, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1000576, "time": 31562.85950422287, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1000632, "time": 31564.351130485535, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1000664, "time": 31565.321033000946, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1001016, "time": 31575.97794365883, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1001336, "time": 31585.625899791718, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1001352, "time": 31586.11051940918, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1001400, "time": 31587.572756290436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1001488, "time": 31590.538420915604, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1001648, "time": 31595.382244348526, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1001800, "time": 31599.8007311821, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1001944, "time": 31604.237957000732, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1002232, "time": 31612.99799466133, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1002264, "time": 31613.962619304657, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1002352, "time": 31616.853191375732, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1002384, "time": 31617.816735506058, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1002424, "time": 31618.921085357666, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1002600, "time": 31624.271212100983, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1002728, "time": 31628.181300640106, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1002768, "time": 31629.62679862976, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1002856, "time": 31632.113821983337, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1003032, "time": 31637.492283582687, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1003080, "time": 31638.965086460114, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1003120, "time": 31640.406265497208, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1003416, "time": 31649.369192123413, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1003568, "time": 31654.250925779343, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1003736, "time": 31659.152936458588, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1003784, "time": 31660.61970758438, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1003864, "time": 31663.084433555603, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1004032, "time": 31668.437127828598, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1004096, "time": 31670.380561351776, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1004144, "time": 31671.84407877922, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1004184, "time": 31672.834115982056, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1004328, "time": 31677.203612804413, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1004464, "time": 31681.651768684387, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1004568, "time": 31684.573140621185, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1004904, "time": 31694.76131129265, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1005048, "time": 31699.121572494507, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1005064, "time": 31699.611925840378, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 1005136, "time": 31702.037374973297, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1005224, "time": 31704.49355196953, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1005224, "time": 31704.50360584259, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1005280, "time": 31706.457075834274, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1005728, "time": 31720.212216854095, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1005864, "time": 31724.153037786484, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1005872, "time": 31724.64797782898, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1006000, "time": 31728.50774860382, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1006184, "time": 31733.908473968506, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1006248, "time": 31735.873610258102, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1006312, "time": 31737.820331335068, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1006352, "time": 31739.366158246994, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1006512, "time": 31744.22768354416, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1006632, "time": 31747.642974853516, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1006776, "time": 31752.021789312363, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1006904, "time": 31755.920689105988, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1006960, "time": 31757.832846164703, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1007000, "time": 31758.851272583008, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1007400, "time": 31771.04887485504, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1007464, "time": 31772.99512219429, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1007568, "time": 31776.39619421959, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1007624, "time": 31778.131276369095, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1007664, "time": 31779.91129374504, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1007712, "time": 31781.37039756775, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1007720, "time": 31781.399010419846, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1008040, "time": 31791.22242331505, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1008120, "time": 31793.707334041595, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1008376, "time": 31801.59504032135, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1008520, "time": 31805.97722864151, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1008520, "time": 31805.986875772476, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1008528, "time": 31806.45956301689, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1008720, "time": 31812.307542324066, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1008784, "time": 31814.278019189835, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1008800, "time": 31814.767768383026, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1008864, "time": 31816.70793890953, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1008864, "time": 31816.719607830048, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1008992, "time": 31820.611356973648, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1009256, "time": 31828.404529094696, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1009328, "time": 31830.8785135746, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1009344, "time": 31831.365829229355, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1009496, "time": 31835.763871192932, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1009624, "time": 31839.679022550583, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1009840, "time": 31846.459804296494, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1009880, "time": 31847.47471666336, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1010000, "time": 31851.336910009384, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1010008, "time": 31851.364750146866, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 31853.75903725624, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 1010048, "time": 31854.213256835938, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1010048, "time": 31854.361986637115, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1010048, "time": 31854.79207110405, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 1010048, "time": 31855.1439204216, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1010048, "time": 31855.477408647537, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 1010048, "time": 31855.503056526184, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1010048, "time": 31855.660013198853, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1010096, "time": 31857.11299610138, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1010536, "time": 31870.36849808693, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1010592, "time": 31872.272250175476, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1010688, "time": 31875.219965696335, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1010752, "time": 31877.15812277794, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1010880, "time": 31881.035807847977, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1010880, "time": 31881.043875694275, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1011176, "time": 31889.877519607544, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1011304, "time": 31893.721891641617, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1011304, "time": 31893.730127096176, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1011632, "time": 31903.885684728622, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1011768, "time": 31907.780029058456, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1011792, "time": 31908.7419154644, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1011968, "time": 31914.03985953331, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1012064, "time": 31916.939318180084, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1012112, "time": 31918.478477716446, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1012592, "time": 31933.008309841156, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1012640, "time": 31934.460692167282, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1012656, "time": 31935.65867972374, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1012840, "time": 31941.056875944138, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1012928, "time": 31944.00888109207, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1012992, "time": 31945.96460556984, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1013088, "time": 31949.00914168358, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1013160, "time": 31950.975293636322, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1013304, "time": 31955.36634492874, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1013360, "time": 31957.304581403732, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1013480, "time": 31960.74926328659, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1013680, "time": 31967.044818639755, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1013744, "time": 31968.990895032883, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1014088, "time": 31979.266293525696, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1014120, "time": 31980.23479771614, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1014144, "time": 31981.18283724785, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1014168, "time": 31981.69313812256, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 1014296, "time": 31985.55961251259, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1014408, "time": 31988.974860191345, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1014456, "time": 31990.43895840645, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1014736, "time": 31999.120973825455, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1015344, "time": 32017.645806074142, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1015408, "time": 32019.585189819336, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1015696, "time": 32028.326159000397, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1015744, "time": 32029.768922805786, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1015808, "time": 32031.88575744629, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1015968, "time": 32037.111439466476, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1016056, "time": 32039.69978070259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1016216, "time": 32044.53037571907, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 1016280, "time": 32046.471457719803, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1016432, "time": 32051.304736614227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1016440, "time": 32051.332490205765, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1016704, "time": 32059.563916921616, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1016784, "time": 32062.01010131836, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1016792, "time": 32062.0378408432, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1016976, "time": 32067.84405016899, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1017120, "time": 32072.324108362198, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1017144, "time": 32072.83201265335, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1017168, "time": 32073.78909111023, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1017280, "time": 32077.186872959137, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1017344, "time": 32079.127069473267, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1017632, "time": 32087.862417459488, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1017784, "time": 32092.237927675247, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1017952, "time": 32097.533747911453, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1017984, "time": 32098.587503433228, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1017992, "time": 32098.616088867188, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1018272, "time": 32107.324367284775, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1018424, "time": 32111.74799466133, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1018464, "time": 32113.195586919785, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1018632, "time": 32118.079390764236, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1018648, "time": 32118.57232618332, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1018688, "time": 32120.028212547302, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1018776, "time": 32122.4660384655, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1018960, "time": 32128.269116163254, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1019096, "time": 32132.264815568924, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1019128, "time": 32133.2435131073, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1019224, "time": 32136.165493249893, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1019664, "time": 32149.7472949028, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1019736, "time": 32151.696880578995, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1019768, "time": 32152.684228658676, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1019896, "time": 32156.588601350784, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1019920, "time": 32157.53519654274, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1020032, "time": 32161.689098358154, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1020032, "time": 32162.395025014877, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1020032, "time": 32162.54498076439, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1020032, "time": 32162.96548652649, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1020032, "time": 32163.336874246597, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 1020032, "time": 32163.401562929153, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1020032, "time": 32163.801962852478, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1020032, "time": 32163.848714590073, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 1020128, "time": 32166.76250767708, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1020248, "time": 32170.156903266907, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1020288, "time": 32171.60867214203, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1020296, "time": 32171.636308908463, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1020416, "time": 32175.474821805954, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1020616, "time": 32181.353434562683, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1020712, "time": 32184.254205942154, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1020920, "time": 32190.712220191956, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1021168, "time": 32198.437252521515, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1021416, "time": 32205.701509952545, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1021424, "time": 32206.171998023987, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1021544, "time": 32209.58506989479, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1021704, "time": 32214.442575216293, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1021776, "time": 32216.87109684944, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1021784, "time": 32216.89886021614, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1021808, "time": 32217.84290289879, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1021896, "time": 32220.380741596222, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1022200, "time": 32229.624455213547, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1022464, "time": 32237.86700153351, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1022688, "time": 32244.687000513077, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1022777, "time": 32248.14906311035, "train_stats/mean_log_entropy": 0.07542069305139087, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.145363987082302, "train/action_min": 0.0, "train/action_std": 1.7543469331052044, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012348660394678464, "train/actor_opt_grad_steps": 62815.0, "train/actor_opt_loss": -25.14906333696724, "train/adv_mag": 1.1103550390441819, "train/adv_max": 0.4325859523055577, "train/adv_mean": 0.00048316645916202106, "train/adv_min": -1.0036025590235644, "train/adv_std": 0.03235283542867049, "train/cont_avg": 0.9940439356435643, "train/cont_loss_mean": 0.02044920178618983, "train/cont_loss_std": 0.2426030938467472, "train/cont_neg_acc": 0.2539989507539355, "train/cont_neg_loss": 2.644707313687795, "train/cont_pos_acc": 0.9998930055316132, "train/cont_pos_loss": 0.0045431754419275805, "train/cont_pred": 0.9940561808571957, "train/cont_rate": 0.9940439356435643, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0913707953831642, "train/extr_critic_critic_opt_grad_steps": 62815.0, "train/extr_critic_critic_opt_loss": 12449.731082727414, "train/extr_critic_mag": 1.9686750563064424, "train/extr_critic_max": 1.9686750563064424, "train/extr_critic_mean": 1.8441962959742781, "train/extr_critic_min": 1.3481933037833411, "train/extr_critic_std": 0.039383896552763954, "train/extr_return_normed_mag": 1.09124890471449, "train/extr_return_normed_max": 0.29473227734612945, "train/extr_return_normed_mean": 0.07318715869200111, "train/extr_return_normed_min": -0.996551258139091, "train/extr_return_normed_std": 0.05139639785531724, "train/extr_return_rate": 0.9997470278551083, "train/extr_return_raw_mag": 2.0662237700849477, "train/extr_return_raw_max": 2.0662237700849477, "train/extr_return_raw_mean": 1.8446787359690902, "train/extr_return_raw_min": 0.7749402345997272, "train/extr_return_raw_std": 0.05139639805817958, "train/extr_reward_mag": 0.25895156187586266, "train/extr_reward_max": 0.25895156187586266, "train/extr_reward_mean": 0.0023966141069298704, "train/extr_reward_min": 1.0032464962194462e-08, "train/extr_reward_std": 0.008928372390973981, "train/image_loss_mean": 0.0848083892966261, "train/image_loss_std": 0.10004034369151191, "train/model_loss_mean": 0.7247765961259899, "train/model_loss_std": 0.5054937945217779, "train/model_opt_grad_norm": 18.220512076989927, "train/model_opt_grad_steps": 62760.82673267327, "train/model_opt_loss": 3804.1400364035426, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5222.772277227723, "train/policy_entropy_mag": 1.3218239162227896, "train/policy_entropy_max": 1.3218239162227896, "train/policy_entropy_mean": 0.090770704358226, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11093307839761866, "train/policy_logprob_mag": 6.551080271749213, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0903968579034404, "train/policy_logprob_min": -6.551080271749213, "train/policy_logprob_std": 0.6268320136731214, "train/policy_randomness_mag": 0.6792831594991212, "train/policy_randomness_max": 0.6792831594991212, "train/policy_randomness_mean": 0.04664691675933871, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05700832841419937, "train/post_ent_mag": 29.109900974991298, "train/post_ent_max": 29.109900974991298, "train/post_ent_mean": 28.873151193750967, "train/post_ent_min": 28.645837717717235, "train/post_ent_std": 0.10233157991182686, "train/prior_ent_mag": 29.364113599947185, "train/prior_ent_max": 29.364113599947185, "train/prior_ent_mean": 28.530526208405448, "train/prior_ent_min": 27.50813033793232, "train/prior_ent_std": 0.306124681735983, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0026935388640694246, "train/reward_loss_mean": 0.019518983974536455, "train/reward_loss_std": 0.2561851283350941, "train/reward_max_data": 0.8026608904399494, "train/reward_max_pred": 0.32481937361235663, "train/reward_neg_acc": 0.9994708326193366, "train/reward_neg_loss": 0.0036375791285104017, "train/reward_pos_acc": 0.169621921551587, "train/reward_pos_loss": 3.8708588933225854, "train/reward_pred": 0.0021380646180794898, "train/reward_rate": 0.004075456373762376, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.02260538935661316, "report/cont_loss_std": 0.2680695950984955, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.594831943511963, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005077291280031204, "report/cont_pred": 0.9948190450668335, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10316525399684906, "report/image_loss_std": 0.11382069438695908, "report/model_loss_mean": 0.7566035985946655, "report/model_loss_std": 0.6899687647819519, "report/post_ent_mag": 29.52503204345703, "report/post_ent_max": 29.52503204345703, "report/post_ent_mean": 29.341333389282227, "report/post_ent_min": 29.115964889526367, "report/post_ent_std": 0.08439558744430542, "report/prior_ent_mag": 29.416015625, "report/prior_ent_max": 29.416015625, "report/prior_ent_mean": 28.577505111694336, "report/prior_ent_min": 27.527233123779297, "report/prior_ent_std": 0.264496386051178, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0033477782271802425, "report/reward_loss_mean": 0.03083290159702301, "report/reward_loss_std": 0.3908039629459381, "report/reward_max_data": 0.893750011920929, "report/reward_max_pred": 0.1055452823638916, "report/reward_neg_acc": 0.999018669128418, "report/reward_neg_loss": 0.004904970992356539, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.314945220947266, "report/reward_pred": 0.002475001383572817, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.048416003584861755, "eval/cont_loss_std": 0.5974439382553101, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.664773941040039, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0028756840620189905, "eval/cont_pred": 0.9971630573272705, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10826253145933151, "eval/image_loss_std": 0.1233694776892662, "eval/model_loss_mean": 0.7986142635345459, "eval/model_loss_std": 1.1062493324279785, "eval/post_ent_mag": 29.52857780456543, "eval/post_ent_max": 29.52857780456543, "eval/post_ent_mean": 29.279298782348633, "eval/post_ent_min": 29.093631744384766, "eval/post_ent_std": 0.09559090435504913, "eval/prior_ent_mag": 29.208751678466797, "eval/prior_ent_max": 29.208751678466797, "eval/prior_ent_mean": 28.47542953491211, "eval/prior_ent_min": 27.554908752441406, "eval/prior_ent_std": 0.28499436378479004, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.004077148623764515, "eval/reward_loss_mean": 0.04193570464849472, "eval/reward_loss_std": 0.5384083390235901, "eval/reward_max_data": 0.831250011920929, "eval/reward_max_pred": 0.07409060001373291, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002455424051731825, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.74042272567749, "eval/reward_pred": 0.0011024647392332554, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32384.0, "replay/samples": 32384.0, "replay/insert_wait_avg": 1.2219688402334221e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.957470393463557e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3560.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.066454340902607e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0269606113434, "timer/env.step_count": 4048.0, "timer/env.step_total": 39.96265983581543, "timer/env.step_frac": 0.039961582447122404, "timer/env.step_avg": 0.009872198576041361, "timer/env.step_min": 0.007815361022949219, "timer/env.step_max": 0.04033303260803223, "timer/replay._sample_count": 32384.0, "timer/replay._sample_total": 16.46006727218628, "timer/replay._sample_frac": 0.01645962351067395, "timer/replay._sample_avg": 0.0005082777690274913, "timer/replay._sample_min": 0.0004115104675292969, "timer/replay._sample_max": 0.00988149642944336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4493.0, "timer/agent.policy_total": 47.46940612792969, "timer/agent.policy_frac": 0.04746812635822374, "timer/agent.policy_avg": 0.010565191659899775, "timer/agent.policy_min": 0.00899648666381836, "timer/agent.policy_max": 0.08205747604370117, "timer/dataset_train_count": 2024.0, "timer/dataset_train_total": 0.21984314918518066, "timer/dataset_train_frac": 0.00021983722223927306, "timer/dataset_train_avg": 0.00010861815671204579, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0004968643188476562, "timer/agent.train_count": 2024.0, "timer/agent.train_total": 901.1620602607727, "timer/agent.train_frac": 0.9011377650357227, "timer/agent.train_avg": 0.4452381720655992, "timer/agent.train_min": 0.4314000606536865, "timer/agent.train_max": 0.7329084873199463, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47357773780822754, "timer/agent.report_frac": 0.00047356497020711993, "timer/agent.report_avg": 0.23678886890411377, "timer/agent.report_min": 0.23117518424987793, "timer/agent.report_max": 0.2424025535583496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7178985255519942e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 32.38259808336673}
{"step": 1022888, "time": 32251.450655937195, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1022928, "time": 32252.897416353226, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1022960, "time": 32253.869435310364, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1022992, "time": 32254.860961914062, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1023080, "time": 32257.296536922455, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1023120, "time": 32258.71767950058, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1023296, "time": 32264.03401350975, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1023320, "time": 32264.574590921402, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1023416, "time": 32267.495508670807, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1023904, "time": 32282.51637196541, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1023976, "time": 32284.48027896881, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1024024, "time": 32286.401350021362, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 1024072, "time": 32287.84384417534, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1024152, "time": 32290.27100801468, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1024184, "time": 32291.23790717125, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1024328, "time": 32295.6087808609, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1024400, "time": 32297.994918107986, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1024624, "time": 32304.77753686905, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1024680, "time": 32306.25107073784, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1024744, "time": 32308.18683362007, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1024808, "time": 32310.219520568848, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1024904, "time": 32313.10898399353, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1024928, "time": 32314.078460216522, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1024936, "time": 32314.107582569122, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1025184, "time": 32321.796216249466, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1025200, "time": 32322.284627199173, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1025368, "time": 32327.15110850334, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1025704, "time": 32337.283266067505, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1026016, "time": 32346.991229057312, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1026056, "time": 32348.008475780487, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1026168, "time": 32351.425137043, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1026368, "time": 32357.727281808853, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1026384, "time": 32358.21941280365, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1026512, "time": 32362.12660741806, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1026704, "time": 32367.951029777527, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1026720, "time": 32368.4683945179, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1026744, "time": 32369.037019491196, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1026888, "time": 32373.396765947342, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1027152, "time": 32381.669325590134, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1027200, "time": 32383.127041578293, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1027416, "time": 32389.483450889587, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1027576, "time": 32394.34451508522, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 1027616, "time": 32395.77187395096, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1027648, "time": 32396.765653133392, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1027864, "time": 32403.18182992935, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1028096, "time": 32410.432169914246, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1028304, "time": 32416.784194231033, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1028416, "time": 32420.166954755783, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1028504, "time": 32422.642356157303, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1028608, "time": 32426.042325019836, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1028648, "time": 32427.039632081985, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 1028672, "time": 32427.989449977875, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1028920, "time": 32435.37523174286, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1028960, "time": 32436.809811353683, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1029328, "time": 32447.971955776215, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1029488, "time": 32452.844842910767, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1029576, "time": 32455.348152399063, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1029624, "time": 32456.794360876083, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1029880, "time": 32464.648935079575, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1029928, "time": 32466.139157772064, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1030016, "time": 32469.934214115143, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1030016, "time": 32469.940222024918, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1030016, "time": 32470.12994146347, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1030016, "time": 32470.35891532898, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1030016, "time": 32470.494972229004, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1030016, "time": 32471.10961651802, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1030016, "time": 32471.25100851059, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1030016, "time": 32471.428113937378, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 1030232, "time": 32477.84916615486, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1030384, "time": 32482.656732559204, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 1030464, "time": 32485.086897611618, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1030528, "time": 32487.054536819458, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1030560, "time": 32488.027925252914, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1030568, "time": 32488.057164669037, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1030584, "time": 32488.66059923172, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1030960, "time": 32500.371965646744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1031248, "time": 32509.145045042038, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1031296, "time": 32510.60133767128, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1031408, "time": 32514.003109693527, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1031792, "time": 32525.78695178032, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 1031800, "time": 32525.816957950592, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1032080, "time": 32534.525228500366, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1032088, "time": 32534.55379486084, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1032248, "time": 32539.926363945007, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1032352, "time": 32543.311677455902, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1032392, "time": 32544.303883314133, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1032408, "time": 32544.791756868362, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1032544, "time": 32549.251794338226, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 1032640, "time": 32552.171313524246, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1032984, "time": 32562.41230225563, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1033056, "time": 32564.806092977524, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1033072, "time": 32565.314539909363, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1033112, "time": 32566.315442323685, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1033296, "time": 32572.136133909225, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 1033696, "time": 32584.322140455246, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1033696, "time": 32584.33198451996, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1033816, "time": 32587.770521640778, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1033832, "time": 32588.258115768433, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1033840, "time": 32588.727592229843, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1033968, "time": 32592.6240336895, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1034136, "time": 32597.49835920334, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1034192, "time": 32599.448296546936, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1034280, "time": 32601.894558668137, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1034528, "time": 32609.77515411377, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1034544, "time": 32610.271186113358, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1034800, "time": 32618.055496931076, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1034840, "time": 32619.070491552353, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1035024, "time": 32624.902547597885, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1035120, "time": 32627.81944823265, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1035272, "time": 32632.229152917862, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1035488, "time": 32639.15051627159, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 1035552, "time": 32641.083261489868, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1035736, "time": 32646.44609975815, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1035824, "time": 32649.353285074234, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1035840, "time": 32649.840611934662, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1036008, "time": 32654.721732616425, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1036368, "time": 32665.898236989975, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1036440, "time": 32667.891644716263, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1036512, "time": 32670.464723587036, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1036536, "time": 32670.985967874527, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1036552, "time": 32671.488045692444, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1036656, "time": 32674.927955150604, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1036792, "time": 32678.845503807068, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1036864, "time": 32681.244984149933, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1036944, "time": 32683.694251537323, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1037008, "time": 32685.640138864517, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1037296, "time": 32694.401699543, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1037432, "time": 32698.355916023254, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1037616, "time": 32704.257529497147, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1037712, "time": 32707.192895174026, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1037824, "time": 32710.615337371826, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1037888, "time": 32712.568854808807, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1038072, "time": 32717.96609520912, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1038120, "time": 32719.432891607285, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1038176, "time": 32721.347385168076, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1038336, "time": 32726.20726299286, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1038464, "time": 32730.207301855087, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1038600, "time": 32734.108738660812, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1038792, "time": 32739.958482980728, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1038984, "time": 32745.813345193863, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1038984, "time": 32745.820919036865, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1039016, "time": 32746.829321861267, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1039144, "time": 32750.73664021492, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1039368, "time": 32757.612843990326, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1039616, "time": 32765.54538655281, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1039696, "time": 32768.003554582596, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1039760, "time": 32769.94893026352, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1039800, "time": 32770.95888066292, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1039984, "time": 32776.76778841019, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1040000, "time": 32778.53752541542, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1040000, "time": 32778.66688346863, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1040000, "time": 32778.73145246506, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1040000, "time": 32779.55981636047, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1040000, "time": 32780.0433382988, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1040000, "time": 32780.82512617111, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1040000, "time": 32780.832235097885, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1040000, "time": 32781.02506232262, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 1040072, "time": 32782.994948625565, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1040120, "time": 32784.48652839661, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 1040336, "time": 32791.39275598526, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1040392, "time": 32793.09573984146, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1040464, "time": 32795.78271269798, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1040616, "time": 32800.17398381233, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1040672, "time": 32802.0781621933, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1040888, "time": 32808.363545656204, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1041016, "time": 32812.25281262398, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1041048, "time": 32813.22453570366, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1041120, "time": 32815.64318847656, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1041232, "time": 32819.17258644104, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1041248, "time": 32819.661378622055, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1041288, "time": 32820.654150009155, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1041320, "time": 32821.62593007088, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1041624, "time": 32830.81523871422, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1041640, "time": 32831.304706573486, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1041688, "time": 32832.75655269623, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1041744, "time": 32834.70019578934, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1041784, "time": 32835.7020573616, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1041792, "time": 32836.171917915344, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1041904, "time": 32839.62537646294, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1041992, "time": 32842.06303071976, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1042200, "time": 32848.46377849579, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1042384, "time": 32854.33904194832, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1042544, "time": 32859.22570872307, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1042584, "time": 32860.22431397438, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1042656, "time": 32862.64951968193, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1042656, "time": 32862.656876564026, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1042720, "time": 32864.61783123016, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1042728, "time": 32864.64702630043, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1042896, "time": 32869.95975255966, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1043024, "time": 32873.85346508026, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1043320, "time": 32882.65938591957, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1043464, "time": 32887.01197695732, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1043536, "time": 32889.43917107582, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1043608, "time": 32891.39519071579, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1043632, "time": 32892.37115907669, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1043680, "time": 32893.82382440567, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1043960, "time": 32902.10667014122, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1044152, "time": 32907.94984817505, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1044280, "time": 32911.93564462662, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1044280, "time": 32911.943442583084, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1044296, "time": 32912.432188510895, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1044336, "time": 32913.86198067665, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1044760, "time": 32926.50331521034, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1044776, "time": 32926.99443101883, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1044968, "time": 32932.82698726654, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1045016, "time": 32934.283012866974, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1045112, "time": 32937.22051167488, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1045152, "time": 32938.735548496246, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1045648, "time": 32953.7936091423, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1045672, "time": 32954.31015968323, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1045680, "time": 32954.78190279007, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1045760, "time": 32957.22328186035, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1045848, "time": 32959.67097949982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1045872, "time": 32960.64105463028, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1046000, "time": 32964.51390552521, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1046128, "time": 32968.43239402771, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1046256, "time": 32972.39583349228, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1046280, "time": 32972.90375113487, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1046464, "time": 32978.77855396271, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1046480, "time": 32979.264031887054, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1046488, "time": 32979.29247760773, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1046528, "time": 32980.73351049423, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1046648, "time": 32984.14395427704, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1046824, "time": 32989.50620508194, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1046984, "time": 32994.376011133194, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1047192, "time": 33000.814598083496, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1047200, "time": 33001.28500080109, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1047224, "time": 33001.79423069954, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1047368, "time": 33006.155947208405, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1047560, "time": 33011.9353659153, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1047672, "time": 33015.33662724495, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1047784, "time": 33018.732912540436, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1047936, "time": 33023.55541419983, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1048080, "time": 33027.933658123016, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1048152, "time": 33030.00076293945, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1048512, "time": 33041.203823804855, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1048536, "time": 33041.71540403366, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1048544, "time": 33042.1858150959, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1048584, "time": 33043.41479563713, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1048792, "time": 33050.02128648758, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1048880, "time": 33052.92700815201, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1049096, "time": 33059.44229006767, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1049104, "time": 33059.9143409729, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1049216, "time": 33063.29857468605, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1049288, "time": 33065.27790570259, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1049296, "time": 33065.74703788757, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1049504, "time": 33072.05563020706, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1049624, "time": 33075.478133678436, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1049736, "time": 33078.872435331345, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1049744, "time": 33079.34094119072, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1049912, "time": 33084.207203388214, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1049912, "time": 33084.21725940704, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1050000, "time": 33087.124606609344, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1050032, "time": 33088.12763381004, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1050088, "time": 33090.15743017197, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1050088, "time": 33090.6715824604, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 1050088, "time": 33090.81185555458, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1050088, "time": 33091.08518862724, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1050088, "time": 33092.064078330994, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1050088, "time": 33092.48433279991, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1050088, "time": 33092.5303940773, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 1050088, "time": 33092.81840276718, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1050384, "time": 33101.98850560188, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1050416, "time": 33102.954758405685, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1050536, "time": 33106.377945661545, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1050648, "time": 33109.75671219826, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1050816, "time": 33115.04501724243, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1050896, "time": 33117.4686691761, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1051024, "time": 33121.39133644104, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1051056, "time": 33122.35534954071, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1051176, "time": 33125.76180410385, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1051216, "time": 33127.203891038895, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1051344, "time": 33131.13580226898, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1051392, "time": 33132.60913348198, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1051392, "time": 33132.617382764816, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1051408, "time": 33133.11215686798, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1051456, "time": 33134.58512830734, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1051624, "time": 33139.4415974617, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1051672, "time": 33140.909019470215, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1051968, "time": 33150.172750234604, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1052128, "time": 33154.9824051857, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1052144, "time": 33155.4720556736, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1052208, "time": 33157.40504074097, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1052424, "time": 33163.82077932358, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1052440, "time": 33164.33471393585, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1052528, "time": 33167.242085933685, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1052576, "time": 33168.699754953384, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1052688, "time": 33172.10542011261, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1052696, "time": 33172.13473391533, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1052880, "time": 33177.90006995201, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1052944, "time": 33179.97321128845, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1053120, "time": 33185.29707980156, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1053224, "time": 33188.190947532654, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1053304, "time": 33190.631737947464, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1053352, "time": 33192.07987880707, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1053560, "time": 33198.355754852295, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1053688, "time": 33202.24433898926, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1053808, "time": 33206.128568172455, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1054008, "time": 33212.15820264816, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1054056, "time": 33213.637388944626, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 1054096, "time": 33215.07158589363, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1054248, "time": 33219.51249217987, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1054272, "time": 33220.47474527359, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1054336, "time": 33222.42809224129, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1054392, "time": 33223.93150925636, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1054464, "time": 33226.33863186836, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1054672, "time": 33232.65667772293, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1054776, "time": 33235.56807899475, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1054968, "time": 33241.46265411377, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1055016, "time": 33242.93301153183, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1055096, "time": 33245.3532166481, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1055161, "time": 33248.41021203995, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1702634313423643, "train/action_min": 0.0, "train/action_std": 1.7706267410898444, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011830186225895958, "train/actor_opt_grad_steps": 64840.0, "train/actor_opt_loss": -25.91205806920094, "train/adv_mag": 1.0957030040289968, "train/adv_max": 0.43822011630523383, "train/adv_mean": 0.0006958953376381722, "train/adv_min": -0.9972824122518155, "train/adv_std": 0.03230838485869574, "train/cont_avg": 0.9938183112684729, "train/cont_loss_mean": 0.02176083353224206, "train/cont_loss_std": 0.249443400999889, "train/cont_neg_acc": 0.23816294957117495, "train/cont_neg_loss": 2.705303791414928, "train/cont_pos_acc": 0.9998015027328078, "train/cont_pos_loss": 0.0049682684378065355, "train/cont_pred": 0.9937356578305437, "train/cont_rate": 0.9938183112684729, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08972888145357223, "train/extr_critic_critic_opt_grad_steps": 64840.0, "train/extr_critic_critic_opt_loss": 11420.224888392857, "train/extr_critic_mag": 2.0028270876466348, "train/extr_critic_max": 2.0028270876466348, "train/extr_critic_mean": 1.8757851893091437, "train/extr_critic_min": 1.3748201090714027, "train/extr_critic_std": 0.04052098681737343, "train/extr_return_normed_mag": 1.1072532232171797, "train/extr_return_normed_max": 0.31148646559034077, "train/extr_return_normed_mean": 0.07472357585145335, "train/extr_return_normed_min": -1.0088580893765529, "train/extr_return_normed_std": 0.05216213829558471, "train/extr_return_rate": 0.9997245413916451, "train/extr_return_raw_mag": 2.1132431981598803, "train/extr_return_raw_max": 2.1132431981598803, "train/extr_return_raw_mean": 1.8764803990941916, "train/extr_return_raw_min": 0.7928986431929865, "train/extr_return_raw_std": 0.05216213822217998, "train/extr_reward_mag": 0.25662281301808476, "train/extr_reward_max": 0.25662281301808476, "train/extr_reward_mean": 0.002551643651556866, "train/extr_reward_min": 1.1216243499605526e-07, "train/extr_reward_std": 0.009217939128539538, "train/image_loss_mean": 0.08602546239868174, "train/image_loss_std": 0.10074101711435271, "train/model_loss_mean": 0.7296290200919353, "train/model_loss_std": 0.532059666705249, "train/model_opt_grad_norm": 18.60751964071114, "train/model_opt_grad_steps": 64783.89655172414, "train/model_opt_loss": 3775.7247344519706, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5172.413793103448, "train/policy_entropy_mag": 1.2948227833057273, "train/policy_entropy_max": 1.2948227833057273, "train/policy_entropy_mean": 0.09042677297967995, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11002255866093001, "train/policy_logprob_mag": 6.5510802597835145, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09006894196342365, "train/policy_logprob_min": -6.5510802597835145, "train/policy_logprob_std": 0.6263787411703852, "train/policy_randomness_mag": 0.6654073223104617, "train/policy_randomness_max": 0.6654073223104617, "train/policy_randomness_mean": 0.046470171785706955, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05654041360825154, "train/post_ent_mag": 29.236859579978905, "train/post_ent_max": 29.236859579978905, "train/post_ent_mean": 29.001602191643176, "train/post_ent_min": 28.769516197918673, "train/post_ent_std": 0.1031962046996126, "train/prior_ent_mag": 29.137330285434064, "train/prior_ent_max": 29.137330285434064, "train/prior_ent_mean": 28.318543185154205, "train/prior_ent_min": 27.38641505875611, "train/prior_ent_std": 0.29275506404526713, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.003028170577837659, "train/reward_loss_mean": 0.021842704160285775, "train/reward_loss_std": 0.2731135771908049, "train/reward_max_data": 0.8117149005382519, "train/reward_max_pred": 0.34634245499014266, "train/reward_neg_acc": 0.9994105373697327, "train/reward_neg_loss": 0.003976512013296849, "train/reward_pos_acc": 0.16038032602703217, "train/reward_pos_loss": 3.9002813844397517, "train/reward_pred": 0.0023632633397722698, "train/reward_rate": 0.004541256157635468, "train_stats/mean_log_entropy": 0.07561203489527885, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.01108596846461296, "report/cont_loss_std": 0.14193688333034515, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.3551700115203857, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003164059715345502, "report/cont_pred": 0.9940863251686096, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08219783008098602, "report/image_loss_std": 0.10270661860704422, "report/model_loss_mean": 0.7069013714790344, "report/model_loss_std": 0.3633519113063812, "report/post_ent_mag": 29.14549446105957, "report/post_ent_max": 29.14549446105957, "report/post_ent_mean": 28.894485473632812, "report/post_ent_min": 28.66422462463379, "report/post_ent_std": 0.10399334877729416, "report/prior_ent_mag": 28.856382369995117, "report/prior_ent_max": 28.856382369995117, "report/prior_ent_mean": 28.085439682006836, "report/prior_ent_min": 27.259567260742188, "report/prior_ent_std": 0.3173385262489319, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023925781715661287, "report/reward_loss_mean": 0.013617543503642082, "report/reward_loss_std": 0.19236043095588684, "report/reward_max_data": 0.7562500238418579, "report/reward_max_pred": 0.3209284543991089, "report/reward_neg_acc": 0.9990195631980896, "report/reward_neg_loss": 0.0024102276656776667, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 2.871483087539673, "report/reward_pred": 0.0016280780546367168, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.040811292827129364, "eval/cont_loss_std": 0.551997721195221, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.290891647338867, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003973884042352438, "eval/cont_pred": 0.9960005283355713, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11990942060947418, "eval/image_loss_std": 0.11976756900548935, "eval/model_loss_mean": 0.7824393510818481, "eval/model_loss_std": 0.7581051588058472, "eval/post_ent_mag": 29.145095825195312, "eval/post_ent_max": 29.145095825195312, "eval/post_ent_mean": 28.937599182128906, "eval/post_ent_min": 28.712677001953125, "eval/post_ent_std": 0.09234978258609772, "eval/prior_ent_mag": 31.600685119628906, "eval/prior_ent_max": 31.600685119628906, "eval/prior_ent_mean": 28.143028259277344, "eval/prior_ent_min": 27.381505966186523, "eval/prior_ent_std": 0.32896754145622253, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002774047665297985, "eval/reward_loss_mean": 0.021718574687838554, "eval/reward_loss_std": 0.29955610632896423, "eval/reward_max_data": 0.831250011920929, "eval/reward_max_pred": 0.055135250091552734, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.0032662302255630493, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.727066516876221, "eval/reward_pred": 0.001686406903900206, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32384.0, "replay/samples": 32384.0, "replay/insert_wait_avg": 1.2161158643692378e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.019681269001112e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0958403832951167e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1820571422577, "timer/env.step_count": 4048.0, "timer/env.step_total": 40.29801106452942, "timer/env.step_frac": 0.04029067585922286, "timer/env.step_avg": 0.009955042259024065, "timer/env.step_min": 0.007767438888549805, "timer/env.step_max": 0.04020857810974121, "timer/replay._sample_count": 32384.0, "timer/replay._sample_total": 16.346877336502075, "timer/replay._sample_frac": 0.01634390181244476, "timer/replay._sample_avg": 0.0005047825264483101, "timer/replay._sample_min": 0.0004112720489501953, "timer/replay._sample_max": 0.010961532592773438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4479.0, "timer/agent.policy_total": 48.00267791748047, "timer/agent.policy_frac": 0.0479939402778678, "timer/agent.policy_avg": 0.010717275712766348, "timer/agent.policy_min": 0.009049415588378906, "timer/agent.policy_max": 0.09431624412536621, "timer/dataset_train_count": 2024.0, "timer/dataset_train_total": 0.2183668613433838, "timer/dataset_train_frac": 0.000218327113333053, "timer/dataset_train_avg": 0.00010788876548586155, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.00036907196044921875, "timer/agent.train_count": 2024.0, "timer/agent.train_total": 900.9590435028076, "timer/agent.train_frac": 0.9007950473307307, "timer/agent.train_avg": 0.4451378673432844, "timer/agent.train_min": 0.4322319030761719, "timer/agent.train_max": 0.679051399230957, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4782285690307617, "timer/agent.report_frac": 0.0004781415199520445, "timer/agent.report_avg": 0.23911428451538086, "timer/agent.report_min": 0.23060178756713867, "timer/agent.report_max": 0.24762678146362305, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7651521018885474e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 32.377540153102544}
{"step": 1055184, "time": 33249.05463218689, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1055264, "time": 33251.55494785309, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1055296, "time": 33252.52287006378, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1055328, "time": 33253.521433353424, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1055584, "time": 33261.29102730751, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1055584, "time": 33261.29806160927, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1055960, "time": 33272.67263817787, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1056120, "time": 33277.5246424675, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1056296, "time": 33282.85107374191, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 1056344, "time": 33284.308806180954, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1056464, "time": 33288.16162443161, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1056496, "time": 33289.129896879196, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1056552, "time": 33290.62772703171, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1056728, "time": 33295.97483253479, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1056896, "time": 33301.838486909866, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1056992, "time": 33304.761877298355, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1057160, "time": 33309.63656663895, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1057616, "time": 33323.6374437809, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1057800, "time": 33329.059361457825, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1057928, "time": 33332.962879657745, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1058128, "time": 33339.22614979744, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1058264, "time": 33343.12948203087, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1058360, "time": 33346.06985974312, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1058456, "time": 33348.97127199173, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 1058576, "time": 33352.84096121788, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1058728, "time": 33357.22008919716, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1058840, "time": 33360.7335600853, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1058920, "time": 33363.15507674217, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1059056, "time": 33367.52693915367, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1059064, "time": 33367.5557513237, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1059112, "time": 33369.02738904953, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1059544, "time": 33382.22268462181, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1059552, "time": 33382.69438314438, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1059568, "time": 33383.183668375015, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1060072, "time": 33399.554916381836, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1060072, "time": 33399.61882376671, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1060072, "time": 33399.951419353485, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1060072, "time": 33400.33129119873, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1060072, "time": 33400.467896699905, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1060072, "time": 33400.51487827301, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 1060072, "time": 33400.80138421059, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1060072, "time": 33401.26528429985, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 1060112, "time": 33402.715812683105, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1060200, "time": 33405.15082025528, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1060408, "time": 33411.43957948685, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1060424, "time": 33411.92676949501, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1060472, "time": 33413.39695048332, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1060488, "time": 33413.885075092316, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1060616, "time": 33417.76700735092, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1060688, "time": 33420.27564120293, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1060776, "time": 33422.73600912094, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1060792, "time": 33423.229712724686, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1060912, "time": 33427.14237952232, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1061008, "time": 33430.09353685379, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1061024, "time": 33432.43073773384, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1061056, "time": 33433.40569925308, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1061184, "time": 33437.30560064316, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1061216, "time": 33438.28146672249, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1061472, "time": 33446.070143938065, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1061752, "time": 33454.38882994652, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1061768, "time": 33454.88278532028, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1061928, "time": 33459.77647399902, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1062040, "time": 33463.19523906708, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1062256, "time": 33469.92991518974, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1062368, "time": 33473.32689714432, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1062392, "time": 33473.8342063427, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1062432, "time": 33475.254266023636, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1062688, "time": 33483.09177136421, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1062896, "time": 33489.42150259018, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1062936, "time": 33490.41415643692, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1062968, "time": 33491.38813829422, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1063128, "time": 33496.24490070343, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1063200, "time": 33498.67471241951, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1063336, "time": 33502.58942556381, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1063584, "time": 33510.385120391846, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1063704, "time": 33513.80797433853, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1063872, "time": 33519.136298418045, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1063896, "time": 33519.65464377403, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1064056, "time": 33524.526791095734, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1064136, "time": 33527.02228856087, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1064272, "time": 33531.4767434597, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1064320, "time": 33532.960716724396, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1064560, "time": 33540.31598043442, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1064848, "time": 33549.086609601974, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1064928, "time": 33551.527032613754, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1065104, "time": 33557.33740210533, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1065184, "time": 33559.757544755936, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1065288, "time": 33562.70059275627, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1065440, "time": 33567.57168364525, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1065560, "time": 33571.158047914505, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1065624, "time": 33573.09817123413, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1065640, "time": 33573.601868629456, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1065736, "time": 33576.54057979584, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1065808, "time": 33578.94778132439, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1065888, "time": 33581.385571718216, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1065944, "time": 33582.85444641113, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1066136, "time": 33588.712553977966, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1066320, "time": 33594.50529885292, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1066392, "time": 33596.50325465202, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1066400, "time": 33596.98010802269, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 1066544, "time": 33601.505491256714, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1066664, "time": 33604.92214155197, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1066968, "time": 33614.13229608536, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1066992, "time": 33615.10074234009, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1067168, "time": 33620.440484285355, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1067224, "time": 33621.92562627792, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1067296, "time": 33624.32104516029, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1067632, "time": 33634.67924833298, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1067680, "time": 33636.13602375984, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1067760, "time": 33638.575978040695, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1068088, "time": 33648.330801963806, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1068088, "time": 33648.33856391907, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1068144, "time": 33650.269827604294, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1068464, "time": 33660.12631440163, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1068544, "time": 33662.55933260918, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1068656, "time": 33665.99950838089, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1068696, "time": 33667.00132203102, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1068944, "time": 33674.77526664734, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1068992, "time": 33676.24141597748, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 1069096, "time": 33679.207958459854, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1069152, "time": 33681.13534402847, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1069296, "time": 33685.55064153671, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1069680, "time": 33697.37259745598, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1069688, "time": 33697.40103983879, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1069816, "time": 33701.31476378441, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1069840, "time": 33702.27514910698, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1070056, "time": 33709.974715948105, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1070056, "time": 33710.02080440521, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1070056, "time": 33710.06895470619, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 1070056, "time": 33710.11589503288, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1070056, "time": 33710.28934383392, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1070056, "time": 33710.72901248932, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1070056, "time": 33710.929030656815, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1070056, "time": 33711.23122692108, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1070096, "time": 33712.68725466728, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1070120, "time": 33713.20385503769, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1070200, "time": 33715.68177461624, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1070336, "time": 33720.18817162514, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1070632, "time": 33728.98916339874, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1070744, "time": 33732.40025186539, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1070808, "time": 33734.3419148922, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1070808, "time": 33734.34886074066, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1070856, "time": 33735.822771310806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1071072, "time": 33742.61408281326, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1071264, "time": 33748.6514236927, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1071432, "time": 33753.54880928993, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1071560, "time": 33757.48287463188, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1071568, "time": 33757.98048520088, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1071680, "time": 33761.4019446373, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1071768, "time": 33763.850198984146, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1072288, "time": 33779.978702783585, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1072392, "time": 33782.906613111496, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1072432, "time": 33784.372150182724, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1072480, "time": 33785.826978206635, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1072584, "time": 33788.74496173859, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1072736, "time": 33793.59377145767, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1072792, "time": 33795.108869075775, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1072840, "time": 33796.57815051079, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1072928, "time": 33799.50192070007, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1073000, "time": 33801.47928285599, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1073048, "time": 33802.95487618446, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1073120, "time": 33805.39562344551, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1073344, "time": 33812.889043569565, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1073600, "time": 33820.6858253479, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1073704, "time": 33823.62520837784, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1073720, "time": 33824.13362503052, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1073752, "time": 33825.09934568405, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1074144, "time": 33837.23387050629, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1074320, "time": 33842.723335027695, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1074368, "time": 33844.20819759369, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1074408, "time": 33845.20839357376, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1074472, "time": 33847.155088186264, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1074648, "time": 33852.500962495804, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 1074720, "time": 33854.92345404625, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1074880, "time": 33859.80750417709, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1074912, "time": 33860.79100394249, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1075048, "time": 33864.74510383606, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1075112, "time": 33866.7119615078, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1075248, "time": 33871.17794585228, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1075328, "time": 33873.617785692215, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1075416, "time": 33876.05445599556, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1075496, "time": 33878.48833799362, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1075808, "time": 33888.18903660774, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1075816, "time": 33888.21679902077, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1075920, "time": 33891.575859069824, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1075928, "time": 33891.604620695114, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1076072, "time": 33895.97154831886, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1076144, "time": 33898.43376517296, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1076344, "time": 33904.294859170914, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1076520, "time": 33909.624248981476, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1076576, "time": 33911.51951241493, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1076632, "time": 33913.00038099289, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1076768, "time": 33917.30749440193, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1076912, "time": 33921.66342997551, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1076936, "time": 33922.17457151413, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1077032, "time": 33925.09456205368, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1077272, "time": 33932.49784255028, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1077296, "time": 33933.45398044586, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1077376, "time": 33935.89284491539, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1077584, "time": 33942.2473628521, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1077840, "time": 33949.987765312195, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1077880, "time": 33951.00275707245, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1077928, "time": 33952.46434211731, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1078032, "time": 33955.86727929115, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1078224, "time": 33961.82134246826, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1078240, "time": 33962.313977479935, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1078328, "time": 33964.74401640892, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1078552, "time": 33971.5303838253, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1078712, "time": 33976.393827199936, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 1078736, "time": 33977.343998909, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1078752, "time": 33977.837743997574, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1078976, "time": 33984.65474295616, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1079296, "time": 33994.53564667702, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1079368, "time": 33996.53388237953, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1079448, "time": 33998.98342490196, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1079496, "time": 34000.47599029541, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1079632, "time": 34004.83893227577, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1079856, "time": 34011.66831088066, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1080040, "time": 34017.74525809288, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 1080040, "time": 34018.41259908676, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1080040, "time": 34019.12084388733, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1080040, "time": 34019.42172455788, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1080040, "time": 34019.78086733818, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1080040, "time": 34019.984068870544, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 1080040, "time": 34020.81645202637, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1080040, "time": 34020.864282369614, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 1080048, "time": 34021.33175730705, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1080048, "time": 34021.339550733566, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1080224, "time": 34026.68487262726, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1080232, "time": 34026.71387028694, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1080336, "time": 34030.10021734238, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1080408, "time": 34032.0651371479, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1080728, "time": 34041.81358337402, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1080832, "time": 34045.19869470596, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1080912, "time": 34047.645726680756, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1080992, "time": 34050.20356583595, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1081096, "time": 34053.172424554825, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1081120, "time": 34054.130194187164, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1081256, "time": 34058.07651758194, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1081504, "time": 34066.349422216415, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1081664, "time": 34071.194482803345, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1081752, "time": 34073.65303230286, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1082064, "time": 34083.48742175102, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1082304, "time": 34090.766095638275, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1082536, "time": 34097.62888288498, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1082576, "time": 34099.08193922043, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1082680, "time": 34102.01469326019, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1082752, "time": 34104.42774271965, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1082768, "time": 34104.919683218, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1082840, "time": 34106.90732860565, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 1082904, "time": 34108.970047712326, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1082976, "time": 34111.37334942818, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1083024, "time": 34112.83142375946, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1083520, "time": 34127.916692495346, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1083568, "time": 34129.38012838364, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1083752, "time": 34134.75482726097, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1083824, "time": 34137.186859846115, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1084120, "time": 34146.106504917145, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1084152, "time": 34147.091393470764, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1084248, "time": 34150.016570568085, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1084488, "time": 34157.38005876541, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1084496, "time": 34157.85869050026, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1084552, "time": 34159.349566459656, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1084696, "time": 34163.76485538483, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 1084984, "time": 34172.686775922775, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1085008, "time": 34173.63272404671, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1085072, "time": 34175.60035562515, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1085136, "time": 34177.54763889313, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1085376, "time": 34184.86492848396, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1085648, "time": 34193.12054562569, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1085832, "time": 34198.50744342804, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1085904, "time": 34200.95618438721, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1085992, "time": 34203.39759993553, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1086144, "time": 34208.275800943375, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1086152, "time": 34208.30589580536, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1086216, "time": 34210.27545309067, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1086448, "time": 34217.51111245155, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1086496, "time": 34218.97002363205, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1086584, "time": 34221.446784734726, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1086640, "time": 34223.38748717308, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1086744, "time": 34226.33496904373, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1087096, "time": 34237.204803943634, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1087168, "time": 34239.63894915581, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1087216, "time": 34241.09748482704, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1087320, "time": 34244.077986478806, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1087433, "time": 34248.52632665634, "train_stats/mean_log_entropy": 0.07375805773611727, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.160733199238184, "train/action_min": 0.0, "train/action_std": 1.7583828227436957, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012191409152464487, "train/actor_opt_grad_steps": 66860.0, "train/actor_opt_loss": -25.369468783857812, "train/adv_mag": 0.9741634035584938, "train/adv_max": 0.42555239307346626, "train/adv_mean": 0.0009371385186926122, "train/adv_min": -0.8372338974653785, "train/adv_std": 0.028910875125829853, "train/cont_avg": 0.9938053871268657, "train/cont_loss_mean": 0.022595291815939087, "train/cont_loss_std": 0.2532000800233279, "train/cont_neg_acc": 0.19467830787695461, "train/cont_neg_loss": 2.8114928298940263, "train/cont_pos_acc": 0.9998485093093037, "train/cont_pos_loss": 0.005002947655084788, "train/cont_pred": 0.9939120539385288, "train/cont_rate": 0.9938053871268657, "train/dyn_loss_mean": 1.0000091755568092, "train/dyn_loss_std": 0.0002934797782803056, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0899229724312303, "train/extr_critic_critic_opt_grad_steps": 66860.0, "train/extr_critic_critic_opt_loss": 10128.20411127954, "train/extr_critic_mag": 2.021158902799312, "train/extr_critic_max": 2.021158902799312, "train/extr_critic_mean": 1.9046885611406013, "train/extr_critic_min": 1.4036149023777216, "train/extr_critic_std": 0.03790106845843555, "train/extr_return_normed_mag": 0.9471054047494385, "train/extr_return_normed_max": 0.2770936168841462, "train/extr_return_normed_mean": 0.07250904768186422, "train/extr_return_normed_min": -0.8372516044929846, "train/extr_return_normed_std": 0.04846588205268134, "train/extr_return_rate": 0.9998079502760474, "train/extr_return_raw_mag": 2.1102090765587724, "train/extr_return_raw_max": 2.1102090765587724, "train/extr_return_raw_mean": 1.9056246096815044, "train/extr_return_raw_min": 0.9958638551816419, "train/extr_return_raw_std": 0.04846588221948538, "train/extr_reward_mag": 0.22782968585170918, "train/extr_reward_max": 0.22782968585170918, "train/extr_reward_mean": 0.0026080869369913095, "train/extr_reward_min": 3.3212538382307215e-08, "train/extr_reward_std": 0.009062846951112521, "train/image_loss_mean": 0.08623213193087435, "train/image_loss_std": 0.10040850462901652, "train/model_loss_mean": 0.7320293579528581, "train/model_loss_std": 0.5464524985175228, "train/model_opt_grad_norm": 18.104914579818498, "train/model_opt_grad_steps": 66802.03980099503, "train/model_opt_loss": 4098.122506364661, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5597.014925373134, "train/policy_entropy_mag": 1.2764791534907782, "train/policy_entropy_max": 1.2764791534907782, "train/policy_entropy_mean": 0.08890775505879625, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10651352671693214, "train/policy_logprob_mag": 6.551080271972353, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08861926972717787, "train/policy_logprob_min": -6.551080271972353, "train/policy_logprob_std": 0.6254929333776977, "train/policy_randomness_mag": 0.6559805594273468, "train/policy_randomness_max": 0.6559805594273468, "train/policy_randomness_mean": 0.045689551372877994, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.054737128224687195, "train/post_ent_mag": 29.343875704713128, "train/post_ent_max": 29.343875704713128, "train/post_ent_mean": 29.114105148695003, "train/post_ent_min": 28.8793507950816, "train/post_ent_std": 0.10231708653678942, "train/prior_ent_mag": 29.309053677231518, "train/prior_ent_max": 29.309053677231518, "train/prior_ent_mean": 28.403341359760038, "train/prior_ent_min": 27.525718622539767, "train/prior_ent_std": 0.2828384524405892, "train/rep_loss_mean": 1.0000091755568092, "train/rep_loss_std": 0.0002934797782803056, "train/reward_avg": 0.0031045031127408702, "train/reward_loss_mean": 0.02319640759610344, "train/reward_loss_std": 0.2833799917751284, "train/reward_max_data": 0.8204601997166724, "train/reward_max_pred": 0.29283510867636003, "train/reward_neg_acc": 0.9994533284386592, "train/reward_neg_loss": 0.004183657900592433, "train/reward_pos_acc": 0.14265971957006265, "train/reward_pos_loss": 3.9791785822578922, "train/reward_pred": 0.0023823123626800172, "train/reward_rate": 0.0047516324626865674, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.017331376671791077, "report/cont_loss_std": 0.19858235120773315, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 2.541924238204956, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004943776410073042, "report/cont_pred": 0.9940488338470459, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09259134531021118, "report/image_loss_std": 0.1052776500582695, "report/model_loss_mean": 0.733535885810852, "report/model_loss_std": 0.5428138375282288, "report/post_ent_mag": 29.22492790222168, "report/post_ent_max": 29.22492790222168, "report/post_ent_mean": 28.987323760986328, "report/post_ent_min": 28.751604080200195, "report/post_ent_std": 0.10815978795289993, "report/prior_ent_mag": 29.285703659057617, "report/prior_ent_max": 29.285703659057617, "report/prior_ent_mean": 28.498746871948242, "report/prior_ent_min": 27.652156829833984, "report/prior_ent_std": 0.2657410502433777, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0025512694846838713, "report/reward_loss_mean": 0.02361314743757248, "report/reward_loss_std": 0.31167852878570557, "report/reward_max_data": 0.940625011920929, "report/reward_max_pred": 0.0559234619140625, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.004155229777097702, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.985382556915283, "report/reward_pred": 0.002137135248631239, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.033696502447128296, "eval/cont_loss_std": 0.4331234097480774, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.019412994384766, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004311142023652792, "eval/cont_pred": 0.9956773519515991, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08577664196491241, "eval/image_loss_std": 0.09953717887401581, "eval/model_loss_mean": 0.7578514814376831, "eval/model_loss_std": 0.9516988396644592, "eval/post_ent_mag": 29.22835922241211, "eval/post_ent_max": 29.22835922241211, "eval/post_ent_mean": 28.96750831604004, "eval/post_ent_min": 28.753963470458984, "eval/post_ent_std": 0.10187490284442902, "eval/prior_ent_mag": 29.285703659057617, "eval/prior_ent_max": 29.285703659057617, "eval/prior_ent_mean": 28.47064208984375, "eval/prior_ent_min": 27.558868408203125, "eval/prior_ent_std": 0.2857745289802551, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.004595947451889515, "eval/reward_loss_mean": 0.03837834298610687, "eval/reward_loss_std": 0.49229052662849426, "eval/reward_max_data": 0.8999999761581421, "eval/reward_max_pred": 0.09178757667541504, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.003180023981258273, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.010360240936279, "eval/reward_pred": 0.0016734738601371646, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32272.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.2112789716706396e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.971788788409179e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1111641752308813e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1445996761322, "timer/env.step_count": 4034.0, "timer/env.step_total": 39.926870584487915, "timer/env.step_frac": 0.03992109800664531, "timer/env.step_avg": 0.009897588146873554, "timer/env.step_min": 0.0078067779541015625, "timer/env.step_max": 0.04023909568786621, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 16.232972145080566, "timer/replay._sample_frac": 0.016230625201932945, "timer/replay._sample_avg": 0.0005030048384073056, "timer/replay._sample_min": 0.00041294097900390625, "timer/replay._sample_max": 0.029327869415283203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4498.0, "timer/agent.policy_total": 47.632890939712524, "timer/agent.policy_frac": 0.04762600423492468, "timer/agent.policy_avg": 0.010589793450358499, "timer/agent.policy_min": 0.009027242660522461, "timer/agent.policy_max": 0.0926060676574707, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.20999717712402344, "timer/dataset_train_frac": 0.0002099668159904327, "timer/dataset_train_avg": 0.00010411362276847965, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0005013942718505859, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 899.6289067268372, "timer/agent.train_frac": 0.8994988394859662, "timer/agent.train_avg": 0.44602325569005313, "timer/agent.train_min": 0.4336080551147461, "timer/agent.train_max": 0.6966500282287598, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4789445400238037, "timer/agent.report_frac": 0.0004788752948112663, "timer/agent.report_avg": 0.23947227001190186, "timer/agent.report_min": 0.23175501823425293, "timer/agent.report_max": 0.24718952178955078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.717578840737578e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 32.26673682581595}
{"step": 1087456, "time": 34249.167598724365, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1087528, "time": 34251.23125123978, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1087656, "time": 34255.1259431839, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1087832, "time": 34260.56247282028, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1087848, "time": 34261.054691553116, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1087984, "time": 34265.423713207245, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1088032, "time": 34266.895515203476, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1088176, "time": 34271.277776002884, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1088272, "time": 34274.209223508835, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1088288, "time": 34274.69626927376, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1088800, "time": 34290.44958090782, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1088808, "time": 34290.47827219963, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1088960, "time": 34295.35106611252, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1088968, "time": 34295.379593372345, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1088976, "time": 34295.84684467316, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1089144, "time": 34300.73724293709, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1089176, "time": 34301.70703172684, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1089248, "time": 34304.12459039688, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1089288, "time": 34305.1136507988, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1089768, "time": 34320.43787908554, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1089824, "time": 34322.3723988533, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1089992, "time": 34327.26533317566, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1090024, "time": 34329.08242726326, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 1090024, "time": 34329.7803003788, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1090024, "time": 34329.98721528053, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1090024, "time": 34330.49628615379, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1090024, "time": 34330.63392448425, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 1090024, "time": 34330.76894569397, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 1090024, "time": 34331.224229335785, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1090024, "time": 34331.54142212868, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 1090032, "time": 34332.03965497017, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1090320, "time": 34340.80939292908, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1090344, "time": 34341.323991298676, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1090464, "time": 34345.192450761795, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 1090512, "time": 34346.66076731682, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1090512, "time": 34346.66824603081, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1090672, "time": 34351.6562628746, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1090688, "time": 34352.15001249313, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1090688, "time": 34352.15691137314, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1090888, "time": 34358.0097155571, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1091056, "time": 34363.36015915871, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1091072, "time": 34363.8524389267, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1091112, "time": 34364.84569764137, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1091392, "time": 34373.56586313248, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1091416, "time": 34374.074477910995, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1091552, "time": 34378.4142138958, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1091576, "time": 34379.01178479195, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1091608, "time": 34379.98741745949, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1091928, "time": 34389.73349905014, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1091944, "time": 34390.218895196915, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1092040, "time": 34393.146886348724, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1092072, "time": 34394.141167879105, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1092168, "time": 34397.07687044144, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1092416, "time": 34404.88562965393, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1092568, "time": 34409.42283678055, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1092736, "time": 34414.7605240345, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1092928, "time": 34420.621372938156, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1092936, "time": 34420.65031552315, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1092936, "time": 34420.65868854523, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 1093048, "time": 34424.06997919083, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1093280, "time": 34431.331055402756, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1093312, "time": 34432.30707025528, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1093368, "time": 34433.79422545433, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1093416, "time": 34435.290690898895, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1093464, "time": 34436.74936103821, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1093752, "time": 34445.57356953621, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1093856, "time": 34448.941831588745, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1093976, "time": 34452.36206793785, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1094056, "time": 34454.801958322525, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1094184, "time": 34458.67145180702, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1094232, "time": 34460.14893937111, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1094272, "time": 34461.602684259415, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1094576, "time": 34470.92593789101, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1094688, "time": 34474.3426759243, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1094704, "time": 34474.834731817245, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1094760, "time": 34476.33402657509, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1094920, "time": 34481.26400184631, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1094984, "time": 34483.21677851677, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1095000, "time": 34483.7330019474, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1095016, "time": 34484.229563713074, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 1095128, "time": 34487.62801742554, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1095168, "time": 34489.09346175194, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1095432, "time": 34496.87956571579, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1095624, "time": 34502.83452105522, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1095816, "time": 34508.65996646881, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1095904, "time": 34511.5541946888, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1095992, "time": 34514.0254714489, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1096136, "time": 34518.38446807861, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1096232, "time": 34521.277874708176, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1096496, "time": 34529.55306363106, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1096528, "time": 34530.524453639984, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1096584, "time": 34532.003958940506, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1096736, "time": 34536.8390982151, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1096760, "time": 34537.36867880821, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1096832, "time": 34539.74864602089, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1096920, "time": 34542.19485759735, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1097168, "time": 34549.862434625626, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1097232, "time": 34551.80536413193, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1097240, "time": 34551.83358311653, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1097320, "time": 34554.265998125076, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1097336, "time": 34554.75355052948, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1097344, "time": 34555.225024700165, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1097448, "time": 34558.16972351074, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1097672, "time": 34565.106095552444, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1097688, "time": 34565.601209163666, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1098000, "time": 34575.82430720329, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1098024, "time": 34576.34008073807, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1098040, "time": 34576.84607505798, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1098120, "time": 34579.268620967865, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1098336, "time": 34586.02516198158, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1098504, "time": 34591.01989722252, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1098512, "time": 34591.512937784195, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1098760, "time": 34598.84615802765, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 1098840, "time": 34601.28691840172, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1098952, "time": 34604.705825567245, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1099104, "time": 34609.53682589531, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1099120, "time": 34610.021941661835, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1099680, "time": 34627.17067694664, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1099696, "time": 34627.66026639938, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1100008, "time": 34638.03438735008, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1100008, "time": 34638.604108572006, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1100008, "time": 34639.04906487465, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1100008, "time": 34639.40487027168, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1100008, "time": 34639.55503678322, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 1100008, "time": 34639.68099498749, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1100008, "time": 34639.98619055748, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 1100008, "time": 34640.11363005638, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 1100256, "time": 34647.95336174965, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1100304, "time": 34649.50530457497, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1100336, "time": 34650.47292757034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100368, "time": 34651.441974163055, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1100496, "time": 34655.32106399536, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1100584, "time": 34657.790169000626, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1100696, "time": 34661.21190357208, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 1100784, "time": 34664.124843120575, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1100968, "time": 34669.521008491516, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1100984, "time": 34670.01002931595, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1101056, "time": 34672.41276502609, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1101480, "time": 34685.09724736214, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1101640, "time": 34689.91270184517, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1101712, "time": 34692.318162441254, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1101744, "time": 34693.27501487732, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1101808, "time": 34695.21614360809, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1102048, "time": 34702.46703052521, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1102128, "time": 34704.885083436966, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1102432, "time": 34714.22895812988, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1102432, "time": 34714.23672032356, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1102480, "time": 34715.70123100281, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1102560, "time": 34718.150010585785, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1102608, "time": 34719.61652803421, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1102792, "time": 34724.9853618145, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1103232, "time": 34738.644874572754, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1103248, "time": 34739.135909318924, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1103256, "time": 34739.164165735245, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1103296, "time": 34740.58809041977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1103368, "time": 34742.55299806595, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1103528, "time": 34747.41711950302, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1103584, "time": 34749.329777002335, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1103960, "time": 34760.621344566345, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1104088, "time": 34764.56155896187, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1104088, "time": 34764.57269310951, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1104368, "time": 34773.45167803764, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1104456, "time": 34775.9281103611, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1104784, "time": 34786.09598779678, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1104792, "time": 34786.12403512001, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1105360, "time": 34803.67588829994, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1105368, "time": 34803.704929828644, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1105680, "time": 34813.42796111107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1105680, "time": 34813.43632435799, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 1106208, "time": 34830.011461257935, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1106240, "time": 34830.97275471687, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1106272, "time": 34831.94100475311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1106336, "time": 34833.866137742996, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1106456, "time": 34837.274316072464, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1106680, "time": 34844.0681476593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1106888, "time": 34850.3488240242, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1106944, "time": 34852.27247452736, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1106944, "time": 34852.28171014786, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1107024, "time": 34854.750497579575, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1107272, "time": 34862.52275013924, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1107432, "time": 34867.39467167854, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1107464, "time": 34868.36178922653, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1107480, "time": 34868.86893367767, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1107600, "time": 34872.725512742996, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 1107720, "time": 34876.18628573418, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1107776, "time": 34878.1003985405, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1107920, "time": 34882.49913215637, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1108056, "time": 34886.43704533577, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1108232, "time": 34891.919462919235, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1108232, "time": 34891.92641425133, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1108344, "time": 34895.35208129883, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1108648, "time": 34904.61998081207, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1108656, "time": 34905.08726477623, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1108672, "time": 34905.575231552124, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1108680, "time": 34905.60308480263, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1108832, "time": 34910.43592810631, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1108976, "time": 34914.91555118561, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1109208, "time": 34921.845624923706, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1109272, "time": 34923.81139540672, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1109336, "time": 34925.762295246124, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1109456, "time": 34929.61623644829, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1109608, "time": 34934.05847811699, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1109608, "time": 34934.06633710861, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1109736, "time": 34938.048417806625, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1109904, "time": 34943.42395758629, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1109976, "time": 34945.38994932175, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1110096, "time": 34951.52062416077, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1110096, "time": 34951.85811829567, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1110096, "time": 34951.86535835266, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1110096, "time": 34952.153643369675, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1110096, "time": 34952.180812597275, "eval_episode/length": 14.0, "eval_episode/score": 0.956250011920929, "eval_episode/reward_rate": 0.06666666666666667}
{"step": 1110096, "time": 34952.328548669815, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1110096, "time": 34952.66209936142, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1110096, "time": 34952.91331100464, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1110312, "time": 34959.27424573898, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1110312, "time": 34959.282290935516, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1110416, "time": 34962.67748904228, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1110472, "time": 34964.15781545639, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1110688, "time": 34970.92888593674, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1110816, "time": 34974.803132772446, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1111128, "time": 34984.14300918579, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1111232, "time": 34987.53212594986, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1111360, "time": 34991.46103596687, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1111520, "time": 34996.34089231491, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1111696, "time": 35001.66118431091, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1111736, "time": 35002.652354478836, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1111752, "time": 35003.14295458794, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1111768, "time": 35003.633427381516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1111816, "time": 35005.1033744812, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1112168, "time": 35015.92738986015, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1112216, "time": 35017.39039301872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112312, "time": 35020.31305909157, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1112312, "time": 35020.32083487511, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1112640, "time": 35030.490602493286, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1112640, "time": 35030.498274326324, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1112936, "time": 35039.3196811676, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1113096, "time": 35044.164153814316, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1113144, "time": 35045.6164457798, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1113232, "time": 35048.5344414711, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1113320, "time": 35050.97345972061, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1113664, "time": 35061.600855112076, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1113960, "time": 35070.47297215462, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1114016, "time": 35072.39459466934, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1114120, "time": 35075.57425737381, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1114168, "time": 35077.34965109825, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1114232, "time": 35079.351461172104, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1114384, "time": 35084.2199113369, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1114528, "time": 35088.605345487595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1114544, "time": 35089.096717357635, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1114720, "time": 35094.46552038193, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1114776, "time": 35095.94697403908, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1115016, "time": 35103.39236950874, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1115376, "time": 35114.494896411896, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1115448, "time": 35116.44737005234, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1115592, "time": 35120.81094241142, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1115688, "time": 35123.7254588604, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1115776, "time": 35126.62446522713, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1115920, "time": 35131.137219429016, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1115936, "time": 35131.62816643715, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1116000, "time": 35133.592707157135, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1116280, "time": 35141.940868377686, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1116336, "time": 35143.90363764763, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1116384, "time": 35145.389343738556, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1116448, "time": 35147.375965833664, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1116576, "time": 35151.22762751579, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1116616, "time": 35152.23751592636, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1116784, "time": 35157.566227674484, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1117152, "time": 35168.881133794785, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1117184, "time": 35169.858212947845, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1117344, "time": 35174.69860816002, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1117360, "time": 35175.19785404205, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1117432, "time": 35177.19926857948, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1117472, "time": 35178.63349151611, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1117536, "time": 35180.57966852188, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1117584, "time": 35182.05996179581, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1118088, "time": 35197.23485827446, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1118136, "time": 35198.68680047989, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1118200, "time": 35200.64631342888, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1118472, "time": 35208.84962773323, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1118520, "time": 35210.32370185852, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1118544, "time": 35211.27057433128, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1118560, "time": 35211.75960469246, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1118568, "time": 35211.787536382675, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1118608, "time": 35213.21127939224, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1118824, "time": 35219.624166965485, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1119096, "time": 35227.89462471008, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1119344, "time": 35235.62712311745, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1119672, "time": 35245.39872932434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1119753, "time": 35248.98319387436, "train_stats/mean_log_entropy": 0.07624784349040552, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1591219760403773, "train/action_min": 0.0, "train/action_std": 1.7684316357763687, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012325546005740762, "train/actor_opt_grad_steps": 68875.0, "train/actor_opt_loss": -26.7432753260773, "train/adv_mag": 0.9837228608603524, "train/adv_max": 0.4035067853361073, "train/adv_mean": 0.0010916201168800056, "train/adv_min": -0.8996656141658821, "train/adv_std": 0.031180342059988198, "train/cont_avg": 0.9932994275990099, "train/cont_loss_mean": 0.023848917266114218, "train/cont_loss_std": 0.258567429894563, "train/cont_neg_acc": 0.1957792254293909, "train/cont_neg_loss": 2.74251854154143, "train/cont_pos_acc": 0.9998295805831947, "train/cont_pos_loss": 0.005307914588904691, "train/cont_pred": 0.9934852610130122, "train/cont_rate": 0.9932994275990099, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10277087045925679, "train/extr_critic_critic_opt_grad_steps": 68875.0, "train/extr_critic_critic_opt_loss": 8664.931261119276, "train/extr_critic_mag": 2.0496028354852505, "train/extr_critic_max": 2.0496028354852505, "train/extr_critic_mean": 1.9289985493858262, "train/extr_critic_min": 1.4687024354934692, "train/extr_critic_std": 0.041454942214607014, "train/extr_return_normed_mag": 1.0213769007437299, "train/extr_return_normed_max": 0.30841790626544763, "train/extr_return_normed_mean": 0.07970363963948618, "train/extr_return_normed_min": -0.9073372571775229, "train/extr_return_normed_std": 0.05243740013182754, "train/extr_return_rate": 0.9998169621028522, "train/extr_return_raw_mag": 2.1588034488186976, "train/extr_return_raw_max": 2.1588034488186976, "train/extr_return_raw_mean": 1.930089293139996, "train/extr_return_raw_min": 0.9430482853757273, "train/extr_return_raw_std": 0.05243739989208113, "train/extr_reward_mag": 0.25155619996609074, "train/extr_reward_max": 0.25155619996609074, "train/extr_reward_mean": 0.0028252502612880256, "train/extr_reward_min": 7.671884971089883e-09, "train/extr_reward_std": 0.009740866801360309, "train/image_loss_mean": 0.0872954987542759, "train/image_loss_std": 0.10072136098648062, "train/model_loss_mean": 0.7356626055028179, "train/model_loss_std": 0.5565697268979384, "train/model_opt_grad_norm": 17.38199464401396, "train/model_opt_grad_steps": 68815.27722772278, "train/model_opt_loss": 4171.277224096922, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5668.316831683168, "train/policy_entropy_mag": 1.251705002076555, "train/policy_entropy_max": 1.251705002076555, "train/policy_entropy_mean": 0.08752574270019436, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10325473222402062, "train/policy_logprob_mag": 6.551080274109793, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08739144797667418, "train/policy_logprob_min": -6.551080274109793, "train/policy_logprob_std": 0.6243337386905556, "train/policy_randomness_mag": 0.6432491632381289, "train/policy_randomness_max": 0.6432491632381289, "train/policy_randomness_mean": 0.04497933699426675, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05306243896484375, "train/post_ent_mag": 29.37930105228235, "train/post_ent_max": 29.37930105228235, "train/post_ent_mean": 29.127597544452932, "train/post_ent_min": 28.867727251336127, "train/post_ent_std": 0.11200270787028983, "train/prior_ent_mag": 29.331581181818898, "train/prior_ent_max": 29.331581181818898, "train/prior_ent_mean": 28.45491373420942, "train/prior_ent_min": 27.59260885786302, "train/prior_ent_std": 0.28332951841968124, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0033493646270552845, "train/reward_loss_mean": 0.024518168333106407, "train/reward_loss_std": 0.2887556130195608, "train/reward_max_data": 0.8193688123385505, "train/reward_max_pred": 0.32877787209973475, "train/reward_neg_acc": 0.9993098593584382, "train/reward_neg_loss": 0.004459167626631068, "train/reward_pos_acc": 0.1467864675687091, "train/reward_pos_loss": 3.89740389585495, "train/reward_pred": 0.00257737169245092, "train/reward_rate": 0.0051342048267326735, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.02784864418208599, "report/cont_loss_std": 0.35723868012428284, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 3.370586633682251, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004840614274144173, "report/cont_pred": 0.9932980537414551, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07008422911167145, "report/image_loss_std": 0.08345141261816025, "report/model_loss_mean": 0.7228838205337524, "report/model_loss_std": 0.649563193321228, "report/post_ent_mag": 29.73158836364746, "report/post_ent_max": 29.73158836364746, "report/post_ent_mean": 29.484100341796875, "report/post_ent_min": 29.23952865600586, "report/post_ent_std": 0.11501466482877731, "report/prior_ent_mag": 29.327068328857422, "report/prior_ent_max": 29.327068328857422, "report/prior_ent_mean": 28.433582305908203, "report/prior_ent_min": 27.676132202148438, "report/prior_ent_std": 0.27846625447273254, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0042785643599927425, "report/reward_loss_mean": 0.024950917810201645, "report/reward_loss_std": 0.32007548213005066, "report/reward_max_data": 0.909375011920929, "report/reward_max_pred": 0.7500096559524536, "report/reward_neg_acc": 0.9990177154541016, "report/reward_neg_loss": 0.004639810416847467, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.471068859100342, "report/reward_pred": 0.003549182554706931, "report/reward_rate": 0.005859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.023329347372055054, "eval/cont_loss_std": 0.3151770234107971, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.841274261474609, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00443544564768672, "eval/cont_pred": 0.9955763220787048, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11357146501541138, "eval/image_loss_std": 0.1152665987610817, "eval/model_loss_mean": 0.7653335332870483, "eval/model_loss_std": 0.7664799094200134, "eval/post_ent_mag": 29.720256805419922, "eval/post_ent_max": 29.720256805419922, "eval/post_ent_mean": 29.489395141601562, "eval/post_ent_min": 29.20077896118164, "eval/post_ent_std": 0.10608093440532684, "eval/prior_ent_mag": 29.327068328857422, "eval/prior_ent_max": 29.327068328857422, "eval/prior_ent_mean": 28.390005111694336, "eval/prior_ent_min": 27.510601043701172, "eval/prior_ent_std": 0.30988171696662903, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0024963379837572575, "eval/reward_loss_mean": 0.028432689607143402, "eval/reward_loss_std": 0.4247902035713196, "eval/reward_max_data": 0.8531249761581421, "eval/reward_max_pred": 0.05809473991394043, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.0033783474937081337, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.417290210723877, "eval/reward_pred": 0.001735163852572441, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 32320.0, "replay/samples": 32320.0, "replay/insert_wait_avg": 1.2147175793600554e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.854461079776878e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3752.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1159031630070733e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3736946582794, "timer/env.step_count": 4040.0, "timer/env.step_total": 40.246769428253174, "timer/env.step_frac": 0.040231735043774, "timer/env.step_avg": 0.009962071640656727, "timer/env.step_min": 0.007760524749755859, "timer/env.step_max": 0.05566859245300293, "timer/replay._sample_count": 32320.0, "timer/replay._sample_total": 16.101425409317017, "timer/replay._sample_frac": 0.01609541064033791, "timer/replay._sample_avg": 0.000498187667367482, "timer/replay._sample_min": 0.00037598609924316406, "timer/replay._sample_max": 0.01026606559753418, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4509.0, "timer/agent.policy_total": 48.57889461517334, "timer/agent.policy_frac": 0.04856074772314715, "timer/agent.policy_avg": 0.010773762389703557, "timer/agent.policy_min": 0.008048534393310547, "timer/agent.policy_max": 0.0944509506225586, "timer/dataset_train_count": 2020.0, "timer/dataset_train_total": 0.2091984748840332, "timer/dataset_train_frac": 0.00020912032773462113, "timer/dataset_train_avg": 0.0001035636014277392, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.000331878662109375, "timer/agent.train_count": 2020.0, "timer/agent.train_total": 900.0927202701569, "timer/agent.train_frac": 0.8997564860775574, "timer/agent.train_avg": 0.44559045557928556, "timer/agent.train_min": 0.43372106552124023, "timer/agent.train_max": 0.7434439659118652, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4793672561645508, "timer/agent.report_frac": 0.0004791881860990949, "timer/agent.report_avg": 0.2396836280822754, "timer/agent.report_min": 0.23477530479431152, "timer/agent.report_max": 0.24459195137023926, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.931453054601717e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 32.307326755868104}
{"step": 1119808, "time": 35250.67127227783, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1119944, "time": 35254.534527778625, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1120080, "time": 35260.09249472618, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1120080, "time": 35260.27131509781, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1120080, "time": 35260.89994215965, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1120080, "time": 35261.21298599243, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 1120080, "time": 35261.407995939255, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1120080, "time": 35261.47449851036, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1120080, "time": 35261.7614068985, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 1120080, "time": 35262.15589904785, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1120112, "time": 35263.14034461975, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 1120176, "time": 35265.07073426247, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1120304, "time": 35268.96906709671, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1120336, "time": 35269.93781328201, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1120448, "time": 35273.335350990295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1120640, "time": 35279.23701643944, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1120656, "time": 35279.723155260086, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 1120784, "time": 35283.59452581406, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1120840, "time": 35285.08135890961, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1121032, "time": 35290.91830635071, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1121112, "time": 35293.36965632439, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1121304, "time": 35299.22034716606, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1121424, "time": 35303.07354307175, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1121536, "time": 35306.48583984375, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1121624, "time": 35309.02108979225, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1121864, "time": 35316.23282432556, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1121904, "time": 35317.67934632301, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1121944, "time": 35318.66776800156, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1122096, "time": 35323.47081279755, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1122368, "time": 35332.12918949127, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1122464, "time": 35335.02349948883, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 1122560, "time": 35337.93307495117, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1122584, "time": 35338.484609127045, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1122672, "time": 35341.40641236305, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1122720, "time": 35342.8515458107, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1122776, "time": 35344.32035064697, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1123032, "time": 35352.08479475975, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1123232, "time": 35358.35158276558, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1123344, "time": 35361.74014878273, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1123368, "time": 35362.250945329666, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1123560, "time": 35368.089267492294, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1123584, "time": 35369.19600605965, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1123768, "time": 35374.57338428497, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1123840, "time": 35376.983865737915, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1124160, "time": 35386.65744423866, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 1124280, "time": 35390.078553676605, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1124360, "time": 35392.49025249481, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1124600, "time": 35399.85440278053, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1124632, "time": 35400.818059682846, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1124752, "time": 35404.715371608734, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1124768, "time": 35405.21604681015, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1124880, "time": 35408.584990501404, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1124928, "time": 35410.066667318344, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1125032, "time": 35412.97455883026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1125224, "time": 35418.7865486145, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1125392, "time": 35424.10834693909, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1125696, "time": 35433.42157244682, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1125736, "time": 35434.44850897789, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1125752, "time": 35434.94084239006, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1125872, "time": 35439.64529275894, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1126024, "time": 35443.99416542053, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1126080, "time": 35445.92199277878, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1126096, "time": 35446.40996623039, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1126272, "time": 35451.714253902435, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1126440, "time": 35456.56907701492, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1126456, "time": 35457.05581331253, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1126456, "time": 35457.06358623505, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1126632, "time": 35462.462785959244, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1126808, "time": 35467.82307314873, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1126840, "time": 35468.821209192276, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1127048, "time": 35475.14661812782, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1127288, "time": 35482.40100359917, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1127344, "time": 35484.34168720245, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1127536, "time": 35490.23166203499, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1127552, "time": 35490.718027591705, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1127656, "time": 35493.663319826126, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1127848, "time": 35499.48123717308, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1127864, "time": 35499.9749546051, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1127864, "time": 35499.98220086098, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1128128, "time": 35508.25857949257, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 1128256, "time": 35512.12993788719, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1128392, "time": 35516.04469370842, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1128408, "time": 35516.53605556488, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1128416, "time": 35517.01044559479, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1128856, "time": 35530.30859017372, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1128928, "time": 35532.741223335266, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1129120, "time": 35538.5458009243, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1129168, "time": 35539.990369558334, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1129344, "time": 35545.27894663811, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1129400, "time": 35546.75660800934, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 1129424, "time": 35547.70088720322, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1129672, "time": 35555.083401441574, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1129696, "time": 35556.05513906479, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1129888, "time": 35561.927119493484, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1129912, "time": 35562.44110059738, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 1129944, "time": 35563.414324998856, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1130024, "time": 35565.849402189255, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1130032, "time": 35566.34600329399, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1130048, "time": 35566.84319162369, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1130056, "time": 35566.87259078026, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1130064, "time": 35568.415583372116, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1130064, "time": 35569.00322461128, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1130064, "time": 35569.55824589729, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1130064, "time": 35569.92491030693, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 1130064, "time": 35570.01452612877, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1130064, "time": 35570.12167620659, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1130064, "time": 35570.46664762497, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1130064, "time": 35570.47332286835, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 1130168, "time": 35573.41223978996, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1130464, "time": 35582.66160917282, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1130600, "time": 35587.08914089203, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1131000, "time": 35599.36072254181, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1131000, "time": 35599.36828804016, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1131104, "time": 35602.735162973404, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1131152, "time": 35604.209876298904, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1131336, "time": 35609.71703124046, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1131472, "time": 35614.05925107002, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1131528, "time": 35615.53024840355, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1131920, "time": 35627.718623399734, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1132064, "time": 35632.111446619034, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1132072, "time": 35632.141127586365, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1132112, "time": 35633.6021399498, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1132192, "time": 35636.0238199234, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1132512, "time": 35645.83962678909, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1132712, "time": 35651.68983435631, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1132920, "time": 35658.0391125679, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1133064, "time": 35662.3972094059, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1133064, "time": 35662.405888319016, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1133152, "time": 35665.30066084862, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1133200, "time": 35666.75893807411, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1133224, "time": 35667.27103996277, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1133264, "time": 35668.80536913872, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1133440, "time": 35674.12236189842, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1133528, "time": 35676.5762963295, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1133592, "time": 35678.56630063057, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1133960, "time": 35689.8005232811, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1134272, "time": 35699.60052347183, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1134296, "time": 35700.114741802216, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1134360, "time": 35702.0676817894, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 1134360, "time": 35702.07463145256, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1134448, "time": 35704.94123482704, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1134536, "time": 35707.3893198967, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1134544, "time": 35707.860067129135, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1134592, "time": 35709.321925878525, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1134944, "time": 35720.02025914192, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1135232, "time": 35728.92062687874, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1135504, "time": 35737.216923475266, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1135576, "time": 35739.18275475502, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1135584, "time": 35739.658866643906, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1135864, "time": 35747.935096263885, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1135880, "time": 35748.42557501793, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1135896, "time": 35748.91416621208, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1136064, "time": 35754.234385728836, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1136104, "time": 35755.227877140045, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1136224, "time": 35759.220587968826, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1136368, "time": 35763.65735054016, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1136472, "time": 35766.667595386505, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1136648, "time": 35771.985478401184, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1136704, "time": 35773.89688038826, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1136792, "time": 35776.36234140396, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1136872, "time": 35778.79524517059, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1137008, "time": 35783.1559574604, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1137048, "time": 35784.147827386856, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1137216, "time": 35789.553114414215, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1137280, "time": 35791.53371858597, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1137312, "time": 35792.5193259716, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1137328, "time": 35793.02061057091, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1137608, "time": 35801.2798101902, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1137688, "time": 35803.71059656143, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1137872, "time": 35809.532299518585, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1137880, "time": 35809.56027698517, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1137888, "time": 35810.04121208191, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1137944, "time": 35811.52712583542, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1138568, "time": 35830.57073926926, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1138656, "time": 35833.44281387329, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1138792, "time": 35837.86349487305, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1138824, "time": 35838.83152341843, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1139152, "time": 35849.21178650856, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1139248, "time": 35852.14190864563, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1139576, "time": 35861.8940308094, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1139848, "time": 35870.1827480793, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 1139856, "time": 35870.65303301811, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 1139904, "time": 35872.121972084045, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1140048, "time": 35877.74169969559, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1140048, "time": 35878.059106349945, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1140048, "time": 35878.084216833115, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1140048, "time": 35878.64783811569, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1140048, "time": 35878.7490363121, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1140048, "time": 35879.282601356506, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1140048, "time": 35879.46147823334, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1140048, "time": 35879.58775305748, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1140056, "time": 35879.613990068436, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1140216, "time": 35884.459393024445, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1140256, "time": 35885.898065805435, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1140432, "time": 35891.23820376396, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1140440, "time": 35891.26578235626, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1140664, "time": 35897.98303103447, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 1140736, "time": 35900.36553454399, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1140832, "time": 35903.2833878994, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1140840, "time": 35903.311051130295, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1141040, "time": 35909.66173481941, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1141440, "time": 35921.77285480499, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1141472, "time": 35922.7490940094, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1141480, "time": 35922.778540849686, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1141544, "time": 35924.75316929817, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 1141584, "time": 35926.20438480377, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1142112, "time": 35942.1789662838, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1142256, "time": 35946.543464660645, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1142272, "time": 35947.03256511688, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1142368, "time": 35949.96176600456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1142400, "time": 35950.93426132202, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 1142400, "time": 35950.942029953, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1142512, "time": 35954.35566329956, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1142808, "time": 35963.082938194275, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1142856, "time": 35964.564318180084, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1143064, "time": 35971.01897740364, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1143192, "time": 35974.97370386124, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1143248, "time": 35976.91892242432, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 1143472, "time": 35983.72320127487, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1143640, "time": 35988.58531188965, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 1143696, "time": 35990.50860238075, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1143864, "time": 35995.389676094055, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1143936, "time": 35997.78279662132, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1143992, "time": 35999.41588258743, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1144304, "time": 36009.08806228638, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1144392, "time": 36011.5259912014, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1144496, "time": 36014.91917037964, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1144696, "time": 36020.738255262375, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1144864, "time": 36026.08715581894, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1144872, "time": 36026.11951589584, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1145168, "time": 36035.47749662399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1145288, "time": 36038.88834643364, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1145328, "time": 36040.31623339653, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1145432, "time": 36043.25864601135, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1145488, "time": 36045.168378829956, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1145616, "time": 36049.05129027367, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1145616, "time": 36049.05886101723, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1145664, "time": 36050.51694011688, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1145752, "time": 36052.980003118515, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1145976, "time": 36059.86699819565, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1146016, "time": 36061.29732966423, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1146048, "time": 36062.29251861572, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1146296, "time": 36069.61235666275, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1146320, "time": 36070.56485772133, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1146384, "time": 36072.53428244591, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1146624, "time": 36079.841983795166, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1146664, "time": 36080.834345817566, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1146664, "time": 36080.84190201759, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1146792, "time": 36084.7262198925, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1147000, "time": 36091.76782250404, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1147120, "time": 36095.68404984474, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1147272, "time": 36100.09024620056, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1147288, "time": 36100.57774090767, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1147336, "time": 36102.05860829353, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1147576, "time": 36109.31073617935, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1147624, "time": 36110.767845630646, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1147728, "time": 36114.14374041557, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1147824, "time": 36117.28606915474, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1147888, "time": 36119.3086643219, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1147920, "time": 36120.27591252327, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1148056, "time": 36124.18934226036, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1148232, "time": 36129.58493542671, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1148616, "time": 36141.25551342964, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1148960, "time": 36152.00370621681, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1148968, "time": 36152.034308195114, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1149272, "time": 36161.29536771774, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1149320, "time": 36162.749365091324, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1149392, "time": 36165.16781234741, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1149504, "time": 36168.57009220123, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1149512, "time": 36168.59901022911, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1149616, "time": 36171.96600198746, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1149936, "time": 36181.706902980804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1150032, "time": 36185.94250559807, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1150032, "time": 36186.376074552536, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1150032, "time": 36186.551346063614, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1150032, "time": 36186.72367596626, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1150032, "time": 36187.127086400986, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 1150032, "time": 36187.388016462326, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 1150032, "time": 36187.44800114632, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1150032, "time": 36187.57046556473, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 1150112, "time": 36189.985813617706, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1150112, "time": 36189.99258518219, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1150200, "time": 36192.45204472542, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1150248, "time": 36193.915120601654, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1150320, "time": 36196.33609676361, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1150344, "time": 36196.85034275055, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1150400, "time": 36198.798278570175, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1150568, "time": 36203.67461228371, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1150600, "time": 36204.652522325516, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1150864, "time": 36213.0294008255, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1151064, "time": 36218.89842534065, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1151216, "time": 36223.74022912979, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1151312, "time": 36226.66993188858, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1151320, "time": 36226.69785404205, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1151368, "time": 36228.157591342926, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1151416, "time": 36229.611287117004, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1151584, "time": 36234.93359732628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1151760, "time": 36240.35209465027, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1151768, "time": 36240.37962150574, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1151960, "time": 36246.217284440994, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1152025, "time": 36249.20855093002, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.116612198329208, "train/action_min": 0.0, "train/action_std": 1.7449038955244687, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010669305572507552, "train/actor_opt_grad_steps": 70895.0, "train/actor_opt_loss": -25.548853203801826, "train/adv_mag": 0.8351179839360832, "train/adv_max": 0.34584006932702394, "train/adv_mean": 0.00076020332107592, "train/adv_min": -0.7246374617708792, "train/adv_std": 0.028525083404181913, "train/cont_avg": 0.9935459854579208, "train/cont_loss_mean": 0.02312459188541121, "train/cont_loss_std": 0.24865964490293277, "train/cont_neg_acc": 0.19331515941879537, "train/cont_neg_loss": 2.716716662491902, "train/cont_pos_acc": 0.9998589045930617, "train/cont_pos_loss": 0.005559410924082714, "train/cont_pred": 0.9932818480647436, "train/cont_rate": 0.9935459854579208, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09361155504489889, "train/extr_critic_critic_opt_grad_steps": 70895.0, "train/extr_critic_critic_opt_loss": 7557.2727558400375, "train/extr_critic_mag": 2.065121012158913, "train/extr_critic_max": 2.065121012158913, "train/extr_critic_mean": 1.946746557655901, "train/extr_critic_min": 1.5708800271005914, "train/extr_critic_std": 0.03740085118293467, "train/extr_return_normed_mag": 0.8262405301084613, "train/extr_return_normed_max": 0.29848562372793064, "train/extr_return_normed_mean": 0.07258042086395297, "train/extr_return_normed_min": -0.680849280687842, "train/extr_return_normed_std": 0.047970420929907574, "train/extr_return_rate": 0.9998514407342023, "train/extr_return_raw_mag": 2.173410707181043, "train/extr_return_raw_max": 2.173410707181043, "train/extr_return_raw_mean": 1.9475056056929108, "train/extr_return_raw_min": 1.1940758027652703, "train/extr_return_raw_std": 0.04797042083769742, "train/extr_reward_mag": 0.2445163349113842, "train/extr_reward_max": 0.2445163349113842, "train/extr_reward_mean": 0.002922537459387896, "train/extr_reward_min": 1.1802899955522896e-09, "train/extr_reward_std": 0.0099850460739419, "train/image_loss_mean": 0.08740023589960419, "train/image_loss_std": 0.10061399963232551, "train/model_loss_mean": 0.7346535413572104, "train/model_loss_std": 0.5428264997530692, "train/model_opt_grad_norm": 17.51315395902879, "train/model_opt_grad_steps": 70833.41584158415, "train/model_opt_loss": 3782.090223255724, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5148.514851485149, "train/policy_entropy_mag": 1.2648802576678815, "train/policy_entropy_max": 1.2648802576678815, "train/policy_entropy_mean": 0.08722943506471001, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.10316472183359732, "train/policy_logprob_mag": 6.551080262306893, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08698491586169393, "train/policy_logprob_min": -6.551080262306893, "train/policy_logprob_std": 0.6238688631813125, "train/policy_randomness_mag": 0.650019905944862, "train/policy_randomness_max": 0.650019905944862, "train/policy_randomness_mean": 0.04482706595617946, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05301618293886728, "train/post_ent_mag": 29.474592303285505, "train/post_ent_max": 29.474592303285505, "train/post_ent_mean": 29.238393953531094, "train/post_ent_min": 28.98133057887011, "train/post_ent_std": 0.10832683686720262, "train/prior_ent_mag": 29.301377891313912, "train/prior_ent_max": 29.301377891313912, "train/prior_ent_mean": 28.43789564264883, "train/prior_ent_min": 27.603240853489034, "train/prior_ent_std": 0.2776485960377325, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0032742188640900124, "train/reward_loss_mean": 0.02412869130713072, "train/reward_loss_std": 0.2815935665944425, "train/reward_max_data": 0.8152537136384757, "train/reward_max_pred": 0.3401955254007094, "train/reward_neg_acc": 0.9993390045543709, "train/reward_neg_loss": 0.00468008891946756, "train/reward_pos_acc": 0.16251518271199547, "train/reward_pos_loss": 3.8202663267603016, "train/reward_pred": 0.002703651108105879, "train/reward_rate": 0.005047184405940594, "train_stats/mean_log_entropy": 0.07452019262336083, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.024943076074123383, "report/cont_loss_std": 0.2551303803920746, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 2.8346991539001465, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.005603555124253035, "report/cont_pred": 0.9937018752098083, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09155359864234924, "report/image_loss_std": 0.10630352050065994, "report/model_loss_mean": 0.7476619482040405, "report/model_loss_std": 0.6232892870903015, "report/post_ent_mag": 29.649028778076172, "report/post_ent_max": 29.649028778076172, "report/post_ent_mean": 29.416345596313477, "report/post_ent_min": 29.13523292541504, "report/post_ent_std": 0.1127520278096199, "report/prior_ent_mag": 29.298185348510742, "report/prior_ent_max": 29.298185348510742, "report/prior_ent_mean": 28.456260681152344, "report/prior_ent_min": 27.51712417602539, "report/prior_ent_std": 0.2689582109451294, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.004302978515625, "report/reward_loss_mean": 0.03116517700254917, "report/reward_loss_std": 0.33231455087661743, "report/reward_max_data": 0.75, "report/reward_max_pred": 0.24583685398101807, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0048767514526844025, "report/reward_pos_acc": 0.1428571492433548, "report/reward_pos_loss": 3.8504984378814697, "report/reward_pred": 0.002752341330051422, "report/reward_rate": 0.0068359375, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.03677055612206459, "eval/cont_loss_std": 0.42902880907058716, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.5694475173950195, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.005572189576923847, "eval/cont_pred": 0.9944281578063965, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1072169840335846, "eval/image_loss_std": 0.11706049740314484, "eval/model_loss_mean": 0.7742540836334229, "eval/model_loss_std": 0.7224640250205994, "eval/post_ent_mag": 29.623958587646484, "eval/post_ent_max": 29.623958587646484, "eval/post_ent_mean": 29.41598892211914, "eval/post_ent_min": 29.18054962158203, "eval/post_ent_std": 0.09561799466609955, "eval/prior_ent_mag": 29.298185348510742, "eval/prior_ent_max": 29.298185348510742, "eval/prior_ent_mean": 28.429298400878906, "eval/prior_ent_min": 27.5812931060791, "eval/prior_ent_std": 0.28916648030281067, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.004534912295639515, "eval/reward_loss_mean": 0.03026656061410904, "eval/reward_loss_std": 0.33346110582351685, "eval/reward_max_data": 0.8656250238418579, "eval/reward_max_pred": 0.1921842098236084, "eval/reward_neg_acc": 0.9990177154541016, "eval/reward_neg_loss": 0.004777030553668737, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.354990005493164, "eval/reward_pred": 0.002465323079377413, "eval/reward_rate": 0.005859375, "replay/size": 1000000.0, "replay/inserts": 32272.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.1918047719150707e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.882101085437781e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1002540588378906e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.271301984787, "timer/env.step_count": 4034.0, "timer/env.step_total": 39.827892780303955, "timer/env.step_frac": 0.03981709032467043, "timer/env.step_avg": 0.009873052250942973, "timer/env.step_min": 0.007815122604370117, "timer/env.step_max": 0.0388033390045166, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 16.164968490600586, "timer/replay._sample_frac": 0.016160584092061094, "timer/replay._sample_avg": 0.0005008976354301123, "timer/replay._sample_min": 0.0004105567932128906, "timer/replay._sample_max": 0.025714397430419922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4659.0, "timer/agent.policy_total": 49.33187818527222, "timer/agent.policy_frac": 0.04931849797888383, "timer/agent.policy_avg": 0.010588512166832414, "timer/agent.policy_min": 0.008993148803710938, "timer/agent.policy_max": 0.08077096939086914, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.20934343338012695, "timer/dataset_train_frac": 0.00020928665349564417, "timer/dataset_train_avg": 0.00010378950588999849, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0007407665252685547, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 897.5768136978149, "timer/agent.train_frac": 0.8973333653747732, "timer/agent.train_avg": 0.44500585706386464, "timer/agent.train_min": 0.43035268783569336, "timer/agent.train_max": 0.8260862827301025, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4800114631652832, "timer/agent.report_frac": 0.00047988127042415506, "timer/agent.report_avg": 0.2400057315826416, "timer/agent.report_min": 0.23331689834594727, "timer/agent.report_max": 0.24669456481933594, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.836411567220734e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 32.26265892957111}
{"step": 1152208, "time": 36254.73532271385, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1152472, "time": 36262.561007261276, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1152600, "time": 36266.4603638649, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1152696, "time": 36269.46027684212, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1152792, "time": 36272.433315992355, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1152952, "time": 36277.303154706955, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1153072, "time": 36281.159467458725, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1153120, "time": 36284.036336898804, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1153128, "time": 36284.06573176384, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1153168, "time": 36285.497390031815, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1153376, "time": 36291.80735254288, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 1153440, "time": 36293.7568089962, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1153664, "time": 36300.64954280853, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1153680, "time": 36301.136952877045, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1153736, "time": 36302.63487172127, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1154280, "time": 36319.10290288925, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1154432, "time": 36323.93983268738, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1154552, "time": 36327.355081796646, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1154728, "time": 36332.79404425621, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1154824, "time": 36335.692516088486, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 1155176, "time": 36346.84853935242, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1155224, "time": 36348.29015088081, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1155296, "time": 36350.69363975525, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1155368, "time": 36352.7098839283, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1155384, "time": 36353.21201443672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1155432, "time": 36354.69435238838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1155544, "time": 36358.13059902191, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1155776, "time": 36365.51271867752, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1155808, "time": 36366.51181721687, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1155856, "time": 36367.98329806328, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1155920, "time": 36369.926898002625, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1155928, "time": 36369.95535111427, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1156040, "time": 36373.37492394447, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1156232, "time": 36379.21265745163, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1156240, "time": 36379.68104815483, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1156376, "time": 36383.61338829994, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1156488, "time": 36387.010330200195, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1156560, "time": 36389.47996711731, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1156616, "time": 36390.97112250328, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1157008, "time": 36403.0842461586, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1157176, "time": 36407.93583536148, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1157288, "time": 36411.34078121185, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1157328, "time": 36412.771594285965, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1157448, "time": 36416.204984903336, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1157568, "time": 36420.15804672241, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1157832, "time": 36427.92047381401, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1157936, "time": 36431.30125164986, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1157944, "time": 36431.329860687256, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1157968, "time": 36432.287023067474, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1158232, "time": 36440.088636636734, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1158392, "time": 36444.953624248505, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1158424, "time": 36445.93511915207, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1158560, "time": 36450.41090011597, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1158584, "time": 36450.920590639114, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1158648, "time": 36452.846484422684, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1158664, "time": 36453.33586335182, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1158896, "time": 36460.61423063278, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1158984, "time": 36463.04983997345, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1159176, "time": 36468.87052989006, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1159216, "time": 36470.29528093338, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1159424, "time": 36476.595883607864, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1159584, "time": 36481.56416678429, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1159640, "time": 36483.0547785759, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1159680, "time": 36484.49594831467, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1159840, "time": 36489.3408434391, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1159880, "time": 36490.33078980446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1160016, "time": 36495.3529624939, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1160016, "time": 36495.81281757355, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1160016, "time": 36495.999198913574, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1160016, "time": 36496.80998778343, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1160016, "time": 36496.859587192535, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1160016, "time": 36496.988052845, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1160016, "time": 36497.47892212868, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1160016, "time": 36497.6789932251, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1160080, "time": 36499.638833999634, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1160120, "time": 36500.66137099266, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1160488, "time": 36511.91502523422, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1160768, "time": 36520.607034921646, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1160944, "time": 36525.92719388008, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1160976, "time": 36526.89841413498, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1160976, "time": 36526.90465307236, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1161008, "time": 36527.87739491463, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1161096, "time": 36530.33004140854, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1161112, "time": 36530.82148337364, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1161216, "time": 36534.18055891991, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1161448, "time": 36541.093457221985, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 1161568, "time": 36544.98115038872, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1161576, "time": 36545.00852584839, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1161600, "time": 36545.96294093132, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 1161672, "time": 36547.9206840992, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1161728, "time": 36549.848533153534, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1161848, "time": 36553.2389216423, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1161944, "time": 36556.16788029671, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1162184, "time": 36563.43305969238, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1162760, "time": 36580.9971973896, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 1162912, "time": 36585.84734940529, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1162912, "time": 36585.85484290123, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1163128, "time": 36592.201609134674, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 1163400, "time": 36601.147478580475, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1163496, "time": 36604.059953689575, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1163544, "time": 36605.51488113403, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 1163576, "time": 36606.480984687805, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1163656, "time": 36608.92207860947, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1163712, "time": 36610.833584308624, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1163920, "time": 36617.17869925499, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1164008, "time": 36619.632140636444, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1164016, "time": 36620.0990626812, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1164120, "time": 36623.05978155136, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1164160, "time": 36624.50832724571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1164592, "time": 36637.741735458374, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1164768, "time": 36643.07994747162, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1164824, "time": 36644.567751169205, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1165000, "time": 36649.912006139755, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1165032, "time": 36650.88198494911, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1165120, "time": 36653.78023672104, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1165128, "time": 36653.810326337814, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1165408, "time": 36662.6315741539, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1165568, "time": 36667.551634550095, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1165632, "time": 36669.50877022743, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1165760, "time": 36673.404267549515, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1165880, "time": 36676.86184167862, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1165944, "time": 36678.80339026451, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1166064, "time": 36682.67151784897, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1166104, "time": 36683.6664083004, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1166200, "time": 36686.62642264366, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1166232, "time": 36687.61255073547, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1166384, "time": 36692.61901855469, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1166456, "time": 36694.57339787483, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1166688, "time": 36701.84835743904, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1166856, "time": 36706.76725435257, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1166880, "time": 36707.72409534454, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.0}
{"step": 1166904, "time": 36708.236478328705, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1167032, "time": 36712.11985230446, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1167136, "time": 36715.50413274765, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1167272, "time": 36719.49657559395, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1167384, "time": 36722.95548629761, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1167408, "time": 36723.903326272964, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1167744, "time": 36734.1140024662, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1167744, "time": 36734.1250770092, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1167808, "time": 36736.11489367485, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1168144, "time": 36746.31716132164, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1168160, "time": 36746.80562710762, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1168200, "time": 36747.80016684532, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1168216, "time": 36748.3154964447, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 1168312, "time": 36751.310138225555, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1168472, "time": 36756.18154621124, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1168536, "time": 36758.13178181648, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1168536, "time": 36758.13868713379, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1168584, "time": 36759.60488367081, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1168664, "time": 36762.050021886826, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1168912, "time": 36769.80855989456, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1169000, "time": 36772.24113583565, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1169192, "time": 36778.04739999771, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1169200, "time": 36778.616285562515, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1169200, "time": 36778.62373375893, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1169240, "time": 36779.65334391594, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1169432, "time": 36785.45667695999, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1169456, "time": 36786.40736198425, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1169504, "time": 36787.8589451313, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1169536, "time": 36788.82459497452, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1169592, "time": 36790.32720255852, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1169664, "time": 36792.73136353493, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1169944, "time": 36801.04323005676, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1170000, "time": 36803.85755777359, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 1170000, "time": 36804.189865112305, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1170000, "time": 36804.1956512928, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1170000, "time": 36804.693701028824, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1170000, "time": 36805.24149417877, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1170000, "time": 36805.3315615654, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1170000, "time": 36805.33830785751, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 1170000, "time": 36805.572152137756, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1170120, "time": 36809.51734995842, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1170192, "time": 36811.936477184296, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1170360, "time": 36816.81115150452, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1170648, "time": 36825.54409456253, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1170696, "time": 36827.02365851402, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1170696, "time": 36827.03201556206, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 1170720, "time": 36827.98778104782, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1170736, "time": 36828.4848845005, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1170776, "time": 36829.490131378174, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1171008, "time": 36836.73677635193, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1171136, "time": 36840.72394371033, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1171192, "time": 36842.21486711502, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1171248, "time": 36844.13346505165, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1171272, "time": 36844.6421148777, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1171352, "time": 36847.07246899605, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 1171352, "time": 36847.078541755676, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1171656, "time": 36856.76446199417, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1171704, "time": 36858.21338582039, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1171704, "time": 36858.22043657303, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1171840, "time": 36862.53899049759, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1171952, "time": 36865.911583423615, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1172056, "time": 36868.93842744827, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1172128, "time": 36871.34261393547, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1172240, "time": 36874.70691943169, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1172280, "time": 36875.715925216675, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1172344, "time": 36877.64810633659, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1172440, "time": 36880.56590342522, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1172688, "time": 36888.298916101456, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1172776, "time": 36890.7573633194, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 1172776, "time": 36890.764691352844, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1172792, "time": 36891.25712442398, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1172880, "time": 36894.136444568634, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1173328, "time": 36907.71818780899, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1173536, "time": 36913.97295618057, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1173616, "time": 36916.415707826614, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1173672, "time": 36917.88897180557, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1173792, "time": 36921.77035331726, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1173800, "time": 36921.7994453907, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1173888, "time": 36924.72645020485, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1173976, "time": 36927.18334388733, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1174000, "time": 36928.13290429115, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1174240, "time": 36935.54195189476, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1174328, "time": 36937.971074581146, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1174544, "time": 36944.76939320564, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1174616, "time": 36946.7143406868, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1174624, "time": 36947.17968440056, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1174864, "time": 36954.476123571396, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1175080, "time": 36960.90897464752, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 1175120, "time": 36962.35017132759, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1175208, "time": 36964.80902147293, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1175232, "time": 36965.76234149933, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1175320, "time": 36968.237493276596, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1175328, "time": 36968.708701848984, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1175496, "time": 36973.61024594307, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1175696, "time": 36979.92911553383, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1175720, "time": 36980.438339948654, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1175768, "time": 36981.89483380318, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1175864, "time": 36984.843780756, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1175968, "time": 36988.22926259041, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1175992, "time": 36988.829325675964, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1176232, "time": 36996.08896327019, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1176336, "time": 36999.44989109039, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1176512, "time": 37004.747881412506, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1176840, "time": 37014.46132850647, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1176880, "time": 37015.88969516754, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1177016, "time": 37019.908920526505, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1177128, "time": 37023.31841993332, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1177136, "time": 37023.78907060623, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1177256, "time": 37027.2144613266, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1177272, "time": 37027.70662498474, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1177400, "time": 37031.609414339066, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1177456, "time": 37033.53153920174, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 1177680, "time": 37040.33055663109, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1177920, "time": 37047.64506196976, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1178008, "time": 37050.21851682663, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1178032, "time": 37051.19655632973, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1178376, "time": 37061.45515036583, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1178400, "time": 37062.41330599785, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1178432, "time": 37063.39272356033, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1178520, "time": 37065.85583162308, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1178800, "time": 37074.53625679016, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1178816, "time": 37075.02566862106, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1178920, "time": 37077.97970747948, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1179136, "time": 37084.78654003143, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1179152, "time": 37085.29518246651, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1179256, "time": 37088.1900844574, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1179272, "time": 37088.67981982231, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1179336, "time": 37090.63031244278, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1179480, "time": 37094.98867726326, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1179504, "time": 37095.93670511246, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1179672, "time": 37101.29581475258, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1179720, "time": 37102.763996362686, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1179752, "time": 37103.74361658096, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
