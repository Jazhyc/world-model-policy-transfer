{"step": 1560, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1560, "eval_episode/length": 211.0, "eval_episode/score": 0.34062498807907104, "eval_episode/reward_rate": 0.0047169811320754715}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.87799072265625, "train/action_min": 0.0, "train/action_std": 1.8544297218322754, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0009567987290211022, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.8501710891723633, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.597876787185669, "train/cont_loss_std": 0.2394682914018631, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.6875, "train/cont_pos_loss": 0.597876787185669, "train/cont_pred": 0.5650764107704163, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.976642608642578, "train/dyn_loss_std": 0.3734270930290222, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 10.424358367919922, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 41370.078125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5010.94140625, "train/image_loss_std": 39.80582809448242, "train/model_loss_mean": 5023.6669921875, "train/model_loss_std": 39.79979705810547, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50236668.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9332869052886963, "train/policy_entropy_max": 1.9332869052886963, "train/policy_entropy_mean": 1.647597312927246, "train/policy_entropy_min": 0.6286575794219971, "train/policy_entropy_std": 0.13871420919895172, "train/policy_logprob_mag": 4.649711608886719, "train/policy_logprob_max": -0.14944732189178467, "train/policy_logprob_mean": -1.657705307006836, "train/policy_logprob_min": -4.649711608886719, "train/policy_logprob_std": 0.7196218371391296, "train/policy_randomness_mag": 0.9935129880905151, "train/policy_randomness_max": 0.9935129880905151, "train/policy_randomness_mean": 0.8466975688934326, "train/policy_randomness_min": 0.3230661153793335, "train/policy_randomness_std": 0.07128500193357468, "train/post_ent_mag": 105.61492919921875, "train/post_ent_max": 105.61492919921875, "train/post_ent_mean": 105.30361938476562, "train/post_ent_min": 104.97484588623047, "train/post_ent_std": 0.10633634775876999, "train/prior_ent_mag": 106.34268188476562, "train/prior_ent_max": 106.34268188476562, "train/prior_ent_mean": 105.59134674072266, "train/prior_ent_min": 104.74049377441406, "train/prior_ent_std": 0.2681574523448944, "train/rep_loss_mean": 10.976642608642578, "train/rep_loss_std": 0.3734270930290222, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.6130075454711914, "report/cont_loss_std": 0.25925904512405396, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.65625, "report/cont_pos_loss": 0.6130075454711914, "report/cont_pred": 0.5590754747390747, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.978172302246094, "report/dyn_loss_std": 0.3497298061847687, "report/image_loss_mean": 5009.61328125, "report/image_loss_std": 38.740230560302734, "report/model_loss_mean": 5022.3544921875, "report/model_loss_std": 38.756378173828125, "report/post_ent_mag": 105.63516998291016, "report/post_ent_max": 105.63516998291016, "report/post_ent_mean": 105.30760192871094, "report/post_ent_min": 104.97439575195312, "report/post_ent_std": 0.10750836879014969, "report/prior_ent_mag": 106.32608032226562, "report/prior_ent_max": 106.32608032226562, "report/prior_ent_mean": 105.56214904785156, "report/prior_ent_min": 104.52832794189453, "report/prior_ent_std": 0.2824935019016266, "report/rep_loss_mean": 10.978172302246094, "report/rep_loss_std": 0.3497298061847687, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.6682547330856323, "eval/cont_loss_std": 0.2842901945114136, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.5927734375, "eval/cont_pos_loss": 0.6682547330856323, "eval/cont_pred": 0.5323569774627686, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 10.999186515808105, "eval/dyn_loss_std": 0.3506993353366852, "eval/image_loss_mean": 4997.7861328125, "eval/image_loss_std": 40.8612174987793, "eval/model_loss_mean": 5010.59521484375, "eval/model_loss_std": 40.885589599609375, "eval/post_ent_mag": 105.60539245605469, "eval/post_ent_max": 105.60539245605469, "eval/post_ent_mean": 105.29170227050781, "eval/post_ent_min": 104.92385864257812, "eval/post_ent_std": 0.10642435401678085, "eval/prior_ent_mag": 106.33694458007812, "eval/prior_ent_max": 106.33694458007812, "eval/prior_ent_mean": 105.57867431640625, "eval/prior_ent_min": 104.8619384765625, "eval/prior_ent_std": 0.26712363958358765, "eval/rep_loss_mean": 10.999186515808105, "eval/rep_loss_std": 0.3506993353366852, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 7.071355207979172e-07, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.600098746163505e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 9.87157685739694e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.386718477521624e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 60.91897797584534, "timer/env.step_count": 196.0, "timer/env.step_total": 0.18238472938537598, "timer/env.step_frac": 0.002993890170936426, "timer/env.step_avg": 0.000930534333598857, "timer/env.step_min": 0.0007908344268798828, "timer/env.step_max": 0.0052988529205322266, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 29.954979181289673, "timer/replay._sample_frac": 0.49171834749373117, "timer/replay._sample_avg": 0.2674551712615149, "timer/replay._sample_min": 0.0003485679626464844, "timer/replay._sample_max": 1.682560920715332, "timer/agent.save_count": 1.0, "timer/agent.save_total": 1.0774614810943604, "timer/agent.save_frac": 0.017686795098919402, "timer/agent.save_avg": 1.0774614810943604, "timer/agent.save_min": 1.0774614810943604, "timer/agent.save_max": 1.0774614810943604, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 7.970698118209839, "timer/agent.policy_frac": 0.13084096915365617, "timer/agent.policy_avg": 0.027485165924861513, "timer/agent.policy_min": 0.00575709342956543, "timer/agent.policy_max": 5.185277462005615, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.600120544433594e-05, "timer/dataset_train_frac": 5.909686380262418e-07, "timer/dataset_train_avg": 3.600120544433594e-05, "timer/dataset_train_min": 3.600120544433594e-05, "timer/dataset_train_max": 3.600120544433594e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 42.76081991195679, "timer/agent.train_frac": 0.7019293713186004, "timer/agent.train_avg": 42.76081991195679, "timer/agent.train_min": 42.76081991195679, "timer/agent.train_max": 42.76081991195679, "timer/agent.report_count": 2.0, "timer/agent.report_total": 8.76318907737732, "timer/agent.report_frac": 0.143849903077034, "timer/agent.report_avg": 4.38159453868866, "timer/agent.report_min": 0.21209931373596191, "timer/agent.report_max": 8.551089763641357, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.814697265625e-05, "timer/dataset_eval_frac": 6.261919343324416e-07, "timer/dataset_eval_avg": 3.814697265625e-05, "timer/dataset_eval_min": 3.814697265625e-05, "timer/dataset_eval_max": 3.814697265625e-05}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 2312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 4624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 6936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 7160, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 9472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 11.0, "eval_episode/score": 0.965624988079071, "eval_episode/reward_rate": 0.08333333333333333}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 11784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 13872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 14096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 15808, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 16408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 18720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 20808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 21032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 21273, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0025044262893803, "train/action_min": 0.0, "train/action_std": 2.000981379330643, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00011591859548366856, "train/actor_opt_grad_steps": 620.0, "train/actor_opt_loss": -3.316836233031217, "train/adv_mag": 0.00020485231147995042, "train/adv_max": 0.00020477766368991618, "train/adv_mean": 0.00012263704501295196, "train/adv_min": 1.8915343441082818e-05, "train/adv_std": 5.697874923435679e-05, "train/cont_avg": 0.9970385543699187, "train/cont_loss_mean": 0.025139954966656348, "train/cont_loss_std": 0.29607104514321014, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.822093613379825, "train/cont_pos_acc": 0.9972926068112133, "train/cont_pos_loss": 0.007936370909756005, "train/cont_pred": 0.9934702186080498, "train/cont_rate": 0.9970385543699187, "train/dyn_loss_mean": 1.1093861639984255, "train/dyn_loss_std": 0.00712431443969955, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.732289324204127, "train/extr_critic_critic_opt_grad_steps": 620.0, "train/extr_critic_critic_opt_loss": 8076.297037264196, "train/extr_critic_mag": 0.0001653791443119204, "train/extr_critic_max": 0.00016537623676827283, "train/extr_critic_mean": 0.00016460419609353995, "train/extr_critic_min": 0.00016427621608827172, "train/extr_critic_std": 9.473129894072143e-08, "train/extr_return_normed_mag": 0.00023559927563605965, "train/extr_return_normed_max": 0.00023557731828471873, "train/extr_return_normed_mean": 0.00015362196894884631, "train/extr_return_normed_min": 5.0135051597358656e-05, "train/extr_return_normed_std": 5.696914967147867e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.00036922574970369896, "train/extr_return_raw_max": 0.00036919658104239873, "train/extr_return_raw_mean": 0.0002872412397312901, "train/extr_return_raw_min": 0.00018375431422702906, "train/extr_return_raw_std": 5.6969150248564136e-05, "train/extr_reward_mag": 1.9908920536196328e-05, "train/extr_reward_max": 1.9905043811332888e-05, "train/extr_reward_mean": 1.987804624449857e-05, "train/extr_reward_min": 1.9838170307438547e-05, "train/extr_reward_std": 1.4691921239667939e-08, "train/image_loss_mean": 42.47264070796773, "train/image_loss_std": 0.5717588740332824, "train/model_loss_mean": 43.33222791334478, "train/model_loss_std": 0.8223596387883512, "train/model_opt_grad_norm": 104.35779594984211, "train/model_opt_grad_steps": 610.0, "train/model_opt_loss": 823.4216904213758, "train/model_opt_model_opt_grad_overflow": 0.008130081300813009, "train/model_opt_model_opt_grad_scale": 11.512322154471544, "train/policy_entropy_mag": 1.9457864150768374, "train/policy_entropy_max": 1.9457864150768374, "train/policy_entropy_mean": 1.9402158095584652, "train/policy_entropy_min": 1.8651627040490872, "train/policy_entropy_std": 0.0036160075957546146, "train/policy_logprob_mag": 2.4446844201746996, "train/policy_logprob_max": -1.4550754209844077, "train/policy_logprob_mean": -1.940219630070818, "train/policy_logprob_min": -2.4446844201746996, "train/policy_logprob_std": 0.09298984609483703, "train/policy_randomness_mag": 0.9999364711404816, "train/policy_randomness_max": 0.9999364711404816, "train/policy_randomness_mean": 0.9970737501857726, "train/policy_randomness_min": 0.9585040754419032, "train/policy_randomness_std": 0.0018582604645668128, "train/post_ent_mag": 85.63660865101387, "train/post_ent_max": 85.63660865101387, "train/post_ent_mean": 85.6071750671883, "train/post_ent_min": 85.41184079550146, "train/post_ent_std": 0.03792400640715671, "train/prior_ent_mag": 88.73219255897088, "train/prior_ent_max": 88.73219255897088, "train/prior_ent_mean": 88.62333586157823, "train/prior_ent_min": 88.2975989240941, "train/prior_ent_std": 0.06312489983572708, "train/rep_loss_mean": 1.1093861639984255, "train/rep_loss_std": 0.00712431443969955, "train/reward_avg": 6.59973626555042e-05, "train/reward_loss_mean": 0.1688125308951348, "train/reward_loss_std": 0.03198147370990991, "train/reward_max_data": 0.0675812993592363, "train/reward_max_pred": 1.9872091649993647e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.1678144501084916, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.47970461845398, "train/reward_pred": 1.9832690269118403e-05, "train/reward_rate": 9.527439024390244e-05, "train_stats/mean_log_entropy": 1.9233197561682087, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.009086464531719685, "report/cont_loss_std": 0.1758173108100891, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.632492542266846, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003589488798752427, "report/cont_pred": 0.9964168071746826, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2978176474571228, "report/image_loss_std": 0.07189378887414932, "report/model_loss_mean": 0.9080561995506287, "report/model_loss_std": 0.1900378167629242, "report/post_ent_mag": 74.24241638183594, "report/post_ent_max": 74.24241638183594, "report/post_ent_mean": 74.22247314453125, "report/post_ent_min": 74.15894317626953, "report/post_ent_std": 0.011678319424390793, "report/prior_ent_mag": 80.9426040649414, "report/prior_ent_max": 80.9426040649414, "report/prior_ent_mean": 80.87074279785156, "report/prior_ent_min": 80.46720123291016, "report/prior_ent_std": 0.0609610378742218, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0011520772241055965, "report/reward_loss_std": 2.6120112579519628e-06, "report/reward_max_data": 0.0, "report/reward_max_pred": 2.4437904357910156e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0011520772241055965, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 2.4391338229179382e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003589458065107465, "eval/cont_loss_std": 6.0020356613676995e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003589458065107465, "eval/cont_pred": 0.9964168667793274, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.31301477551460266, "eval/image_loss_std": 0.07662973552942276, "eval/model_loss_mean": 0.9177563190460205, "eval/model_loss_std": 0.0766296535730362, "eval/post_ent_mag": 74.24050903320312, "eval/post_ent_max": 74.24050903320312, "eval/post_ent_mean": 74.22330474853516, "eval/post_ent_min": 74.1600570678711, "eval/post_ent_std": 0.011390307918190956, "eval/prior_ent_mag": 80.92658996582031, "eval/prior_ent_max": 80.92658996582031, "eval/prior_ent_mean": 80.87405395507812, "eval/prior_ent_min": 80.46720123291016, "eval/prior_ent_std": 0.05976865440607071, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011520646512508392, "eval/reward_loss_std": 2.542774609537446e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 2.4437904357910156e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011520646512508392, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.4394015781581402e-05, "eval/reward_rate": 0.0, "replay/size": 20769.0, "replay/inserts": 19712.0, "replay/samples": 19712.0, "replay/insert_wait_avg": 1.2124731362640083e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.344219215504535e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 7992.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.120783878445213e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.6838312149047852e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 491.7942385673523, "timer/env.step_count": 2464.0, "timer/env.step_total": 4.707662343978882, "timer/env.step_frac": 0.009572422722341748, "timer/env.step_avg": 0.0019105772499914294, "timer/env.step_min": 0.0010333061218261719, "timer/env.step_max": 0.008025884628295898, "timer/replay._sample_count": 19712.0, "timer/replay._sample_total": 1316.2456638813019, "timer/replay._sample_frac": 2.6764153799679766, "timer/replay._sample_avg": 0.06677382629267968, "timer/replay._sample_min": 0.00023221969604492188, "timer/replay._sample_max": 0.0893557071685791, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3042.0, "timer/agent.policy_total": 19.67520833015442, "timer/agent.policy_frac": 0.0400069923296994, "timer/agent.policy_avg": 0.006467852837000138, "timer/agent.policy_min": 0.005092620849609375, "timer/agent.policy_max": 0.009738922119140625, "timer/dataset_train_count": 1232.0, "timer/dataset_train_total": 0.09209179878234863, "timer/dataset_train_frac": 0.00018725676626595223, "timer/dataset_train_avg": 7.474983667398428e-05, "timer/dataset_train_min": 5.793571472167969e-05, "timer/dataset_train_max": 0.00017595291137695312, "timer/agent.train_count": 1232.0, "timer/agent.train_total": 461.21302676200867, "timer/agent.train_frac": 0.9378170596417927, "timer/agent.train_avg": 0.3743612230211109, "timer/agent.train_min": 0.3511810302734375, "timer/agent.train_max": 0.4222567081451416, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4071018695831299, "timer/agent.report_frac": 0.0008277890175555125, "timer/agent.report_avg": 0.20355093479156494, "timer/agent.report_min": 0.1969306468963623, "timer/agent.report_max": 0.21017122268676758, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 6.835586311716498e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 40.08126781436945}
{"step": 22744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 23344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 25656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 27968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 29680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 271.0, "eval_episode/score": 0.15312500298023224, "eval_episode/reward_rate": 0.003676470588235294}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 30768, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 32368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 32592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 32648, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617}
{"step": 34456, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726}
{"step": 34680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 34960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 36992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 37216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 37272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 39080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 39304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 39304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 39304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 39304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 39304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 39528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 39584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 41113, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000402142924647, "train/action_min": 0.0, "train/action_std": 2.000295622694877, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 7.525057266790217e-05, "train/actor_opt_grad_steps": 1855.0, "train/actor_opt_loss": -2.720777566514669, "train/adv_mag": 0.0002651934431219894, "train/adv_max": 0.0002651934431219894, "train/adv_mean": 0.0001556753918961359, "train/adv_min": 1.9427921694342887e-05, "train/adv_std": 7.232752707955848e-05, "train/cont_avg": 0.9965584047379032, "train/cont_loss_mean": 0.023055915566792172, "train/cont_loss_std": 0.3182075131254083, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.704605034987131, "train/cont_pos_acc": 0.9999999865408866, "train/cont_pos_loss": 0.00345070950025993, "train/cont_pred": 0.9965555927445812, "train/cont_rate": 0.9965584047379032, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2118625264134138, "train/extr_critic_critic_opt_grad_steps": 1855.0, "train/extr_critic_critic_opt_loss": 1510.9643436554938, "train/extr_critic_mag": 0.002216157413298084, "train/extr_critic_max": 0.002216157413298084, "train/extr_critic_mean": 0.002210468466434958, "train/extr_critic_min": 0.0022042239865949077, "train/extr_critic_std": 1.2335956196898957e-06, "train/extr_return_normed_mag": 0.00047770409981885383, "train/extr_return_normed_max": 0.00047770409981885383, "train/extr_return_normed_mean": 0.00037225699516937075, "train/extr_return_normed_min": 0.00023785867726415274, "train/extr_return_normed_std": 7.227226594677045e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0024715908680997428, "train/extr_return_raw_max": 0.0024715908680997428, "train/extr_return_raw_mean": 0.0023661438425469604, "train/extr_return_raw_min": 0.0022317454455450417, "train/extr_return_raw_std": 7.227226626949437e-05, "train/extr_reward_mag": 3.131839536851452e-05, "train/extr_reward_max": 3.131839536851452e-05, "train/extr_reward_mean": 3.1236711258257386e-05, "train/extr_reward_min": 3.10376767189272e-05, "train/extr_reward_std": 3.70057305569325e-08, "train/image_loss_mean": 0.2821353218488155, "train/image_loss_std": 0.08480930451544062, "train/model_loss_mean": 0.9068439324055949, "train/model_loss_std": 0.3551407659486417, "train/model_opt_grad_norm": 94.51132605152745, "train/model_opt_grad_steps": 1845.0, "train/model_opt_loss": 24.28205943876697, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 26.77671370967742, "train/policy_entropy_mag": 1.94587857780918, "train/policy_entropy_max": 1.94587857780918, "train/policy_entropy_mean": 1.9444463262634892, "train/policy_entropy_min": 1.9238774151571336, "train/policy_entropy_std": 0.0009619220260403029, "train/policy_logprob_mag": 2.2183586166751, "train/policy_logprob_max": -1.6698396119379229, "train/policy_logprob_mean": -1.9444036637583086, "train/policy_logprob_min": -2.2183586166751, "train/policy_logprob_std": 0.05375875021901823, "train/policy_randomness_mag": 0.9999838384889788, "train/policy_randomness_max": 0.9999838384889788, "train/policy_randomness_mean": 0.9992477961124913, "train/policy_randomness_min": 0.988677472356827, "train/policy_randomness_std": 0.0004943301605488805, "train/post_ent_mag": 64.87973954600673, "train/post_ent_max": 64.87973954600673, "train/post_ent_mean": 64.85379785107028, "train/post_ent_min": 64.78528025842482, "train/post_ent_std": 0.014617254987599389, "train/prior_ent_mag": 69.44547437852428, "train/prior_ent_max": 69.44547437852428, "train/prior_ent_mean": 69.31444943335748, "train/prior_ent_min": 69.1474550001083, "train/prior_ent_std": 0.04295460059637985, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 4.2257001510851325e-05, "train/reward_loss_mean": 0.0016526682415015756, "train/reward_loss_std": 0.03136357585156929, "train/reward_max_data": 0.04128024174321082, "train/reward_max_pred": 3.133377721232753e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0006215239367109814, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.906048427928578, "train/reward_pred": 3.122165611374282e-05, "train/reward_rate": 9.450604838709677e-05, "train_stats/mean_log_entropy": 1.9375787753325242, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025676466524600983, "report/cont_loss_std": 0.36159634590148926, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.799907207489014, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003032427979633212, "report/cont_pred": 0.9969721436500549, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.3536061942577362, "report/image_loss_std": 0.08094875514507294, "report/model_loss_mean": 0.9796940088272095, "report/model_loss_std": 0.36716338992118835, "report/post_ent_mag": 56.43659210205078, "report/post_ent_max": 56.43659210205078, "report/post_ent_mean": 56.41432189941406, "report/post_ent_min": 56.34484100341797, "report/post_ent_std": 0.015232465229928493, "report/prior_ent_mag": 58.23988342285156, "report/prior_ent_max": 58.23988342285156, "report/prior_ent_mean": 58.01880645751953, "report/prior_ent_min": 57.961456298828125, "report/prior_ent_std": 0.05273810774087906, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0004113311879336834, "report/reward_loss_std": 4.246828098075639e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.9591064453125e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0004113311879336834, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.959094803780317e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0030324398539960384, "eval/cont_loss_std": 3.7014353893027874e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0030324398539960384, "eval/cont_pred": 0.9969720840454102, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.37062621116638184, "eval/image_loss_std": 0.08564092218875885, "eval/model_loss_mean": 0.9740700125694275, "eval/model_loss_std": 0.08564089238643646, "eval/post_ent_mag": 56.43791198730469, "eval/post_ent_max": 56.43791198730469, "eval/post_ent_mean": 56.41471862792969, "eval/post_ent_min": 56.3436164855957, "eval/post_ent_std": 0.014520126394927502, "eval/prior_ent_mag": 58.27842330932617, "eval/prior_ent_max": 58.27842330932617, "eval/prior_ent_mean": 58.016319274902344, "eval/prior_ent_min": 57.95534896850586, "eval/prior_ent_std": 0.05180977284908295, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0004113391041755676, "eval/reward_loss_std": 4.036399730011908e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.9591064453125e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0004113391041755676, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.9591064453125e-05, "eval/reward_rate": 0.0, "replay/size": 40609.0, "replay/inserts": 19840.0, "replay/samples": 19840.0, "replay/insert_wait_avg": 1.23817834161943e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.428709330097321e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12616.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.241540001337916e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.08289098739624, "timer/env.step_count": 2480.0, "timer/env.step_total": 4.704040050506592, "timer/env.step_frac": 0.009406520669440678, "timer/env.step_avg": 0.0018967903429462064, "timer/env.step_min": 0.001073598861694336, "timer/env.step_max": 0.007916450500488281, "timer/replay._sample_count": 19840.0, "timer/replay._sample_total": 1323.6181826591492, "timer/replay._sample_frac": 2.6467975739896064, "timer/replay._sample_avg": 0.06671462614209421, "timer/replay._sample_min": 0.0003249645233154297, "timer/replay._sample_max": 0.08991026878356934, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3058.0, "timer/agent.policy_total": 20.06177020072937, "timer/agent.policy_frac": 0.040116889744254404, "timer/agent.policy_avg": 0.006560421909983443, "timer/agent.policy_min": 0.0050373077392578125, "timer/agent.policy_max": 0.09427595138549805, "timer/dataset_train_count": 1240.0, "timer/dataset_train_total": 0.09328317642211914, "timer/dataset_train_frac": 0.00018653542863251082, "timer/dataset_train_avg": 7.522836808235414e-05, "timer/dataset_train_min": 5.340576171875e-05, "timer/dataset_train_max": 0.00020313262939453125, "timer/agent.train_count": 1240.0, "timer/agent.train_total": 468.971045255661, "timer/agent.train_frac": 0.9377866223931277, "timer/agent.train_avg": 0.37820245585133955, "timer/agent.train_min": 0.35384297370910645, "timer/agent.train_max": 0.6820549964904785, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4042370319366455, "timer/agent.report_frac": 0.0008083400556625594, "timer/agent.report_avg": 0.20211851596832275, "timer/agent.report_min": 0.19435620307922363, "timer/agent.report_max": 0.20988082885742188, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 6.483910436086028e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 39.67284527407047}
{"step": 41392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 41896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 43928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 44152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 44208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 46520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 48832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 278.0, "eval_episode/score": 0.13124999403953552, "eval_episode/reward_rate": 0.0035842293906810036}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 50864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 50864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 50864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 50864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 50864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 51088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 51144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 52952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 53456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 55768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 57576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 57800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 57800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 57800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 57800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 57800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 58024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 58080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 59888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 60392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 61225, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0024205767919145, "train/action_min": 0.0, "train/action_std": 1.9995944622963193, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 5.149296994060269e-05, "train/actor_opt_grad_steps": 3105.0, "train/actor_opt_loss": -3.7557595211953396, "train/adv_mag": 0.00018801596311349717, "train/adv_max": 0.00018801596311349717, "train/adv_mean": 0.00010156437910486674, "train/adv_min": 2.1092238880339123e-07, "train/adv_std": 4.790194305762328e-05, "train/cont_avg": 0.9967835441468254, "train/cont_loss_mean": 0.02179055851662443, "train/cont_loss_std": 0.3100396970084264, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.7000491716028225, "train/cont_pos_acc": 0.9999999848623125, "train/cont_pos_loss": 0.003434326635518422, "train/cont_pred": 0.9965718426401653, "train/cont_rate": 0.9967835441468254, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.06841618073956361, "train/extr_critic_critic_opt_grad_steps": 3105.0, "train/extr_critic_critic_opt_loss": 2986.452408079117, "train/extr_critic_mag": 0.0055398836968437075, "train/extr_critic_max": 0.0055398836968437075, "train/extr_critic_mean": 0.005528267698421601, "train/extr_critic_min": 0.005510865695892818, "train/extr_critic_std": 4.244455945061938e-06, "train/extr_return_normed_mag": 0.00035857190636710986, "train/extr_return_normed_max": 0.00035857190636710986, "train/extr_return_normed_mean": 0.0002859845204396166, "train/extr_return_normed_min": 0.00019114830582920049, "train/extr_return_normed_std": 4.736740344115889e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.005702419158455635, "train/extr_return_raw_max": 0.005702419158455635, "train/extr_return_raw_mean": 0.005629832046993431, "train/extr_return_raw_min": 0.005534995557917725, "train/extr_return_raw_std": 4.736740373710557e-05, "train/extr_reward_mag": 3.2681321340893945e-05, "train/extr_reward_max": 3.2681321340893945e-05, "train/extr_reward_mean": 3.264149536190662e-05, "train/extr_reward_min": 3.257630363343254e-05, "train/extr_reward_std": 1.8304464978138737e-08, "train/image_loss_mean": 0.26855588597910746, "train/image_loss_std": 0.08382631045958353, "train/model_loss_mean": 0.8916706703011952, "train/model_loss_std": 0.3482601299054093, "train/model_opt_grad_norm": 76.13842292059036, "train/model_opt_grad_steps": 3095.0, "train/model_opt_loss": 54.69539699857197, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 61.38392857142857, "train/policy_entropy_mag": 1.9458939111421978, "train/policy_entropy_max": 1.9458939111421978, "train/policy_entropy_mean": 1.9450497182588729, "train/policy_entropy_min": 1.9315310092199416, "train/policy_entropy_std": 0.0005836450099383318, "train/policy_logprob_mag": 2.160492696459331, "train/policy_logprob_max": -1.7236677143308852, "train/policy_logprob_mean": -1.9450977794707767, "train/policy_logprob_min": -2.160492696459331, "train/policy_logprob_std": 0.0413931350090674, "train/policy_randomness_mag": 0.9999917154274289, "train/policy_randomness_max": 0.9999917154274289, "train/policy_randomness_mean": 0.9995578749785348, "train/policy_randomness_min": 0.9926106428343152, "train/policy_randomness_std": 0.0002999342243475396, "train/post_ent_mag": 49.052510216122585, "train/post_ent_max": 49.052510216122585, "train/post_ent_mean": 48.946430176023455, "train/post_ent_min": 48.903605536809046, "train/post_ent_std": 0.018031550016963764, "train/prior_ent_mag": 56.15377038622659, "train/prior_ent_max": 56.15377038622659, "train/prior_ent_mean": 56.018277334788486, "train/prior_ent_min": 55.80356497991653, "train/prior_ent_std": 0.05488511914062121, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 3.819541321025186e-05, "train/reward_loss_mean": 0.0013241995355143907, "train/reward_loss_std": 0.03259351016735561, "train/reward_max_data": 0.037624007889202664, "train/reward_max_pred": 3.271065061054533e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00025977177204959657, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.612870136896769, "train/reward_pred": 3.267803399394902e-05, "train/reward_rate": 0.00010075644841269841, "train_stats/mean_log_entropy": 1.9383809434043036, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02555961161851883, "report/cont_loss_std": 0.34624552726745605, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.554657936096191, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0038768805097788572, "report/cont_pred": 0.9961307048797607, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24975770711898804, "report/image_loss_std": 0.08160900324583054, "report/model_loss_mean": 0.8754761815071106, "report/model_loss_std": 0.35655373334884644, "report/post_ent_mag": 43.63117980957031, "report/post_ent_max": 43.63117980957031, "report/post_ent_mean": 43.4798583984375, "report/post_ent_min": 43.449302673339844, "report/post_ent_std": 0.02201397903263569, "report/prior_ent_mag": 53.70924377441406, "report/prior_ent_max": 53.70924377441406, "report/prior_ent_mean": 53.642879486083984, "report/prior_ent_min": 53.2657470703125, "report/prior_ent_std": 0.06456294655799866, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.000158785842359066, "report/reward_loss_std": 2.1052834142665233e-08, "report/reward_max_data": 0.0, "report/reward_max_pred": 2.0623207092285156e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000158785842359066, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 2.0552892237901688e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0038768956437706947, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038768956437706947, "eval/cont_pred": 0.9961307048797607, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23295322060585022, "eval/image_loss_std": 0.07812931388616562, "eval/model_loss_mean": 0.8369889259338379, "eval/model_loss_std": 0.07812930643558502, "eval/post_ent_mag": 43.62873840332031, "eval/post_ent_max": 43.62873840332031, "eval/post_ent_mean": 43.47901916503906, "eval/post_ent_min": 43.45207977294922, "eval/post_ent_std": 0.01962578110396862, "eval/prior_ent_mag": 53.70518493652344, "eval/prior_ent_max": 53.70518493652344, "eval/prior_ent_mean": 53.64393615722656, "eval/prior_ent_min": 53.2657470703125, "eval/prior_ent_std": 0.05761110410094261, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001587849110364914, "eval/reward_loss_std": 3.645268265017876e-08, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 2.0623207092285156e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001587849110364914, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.0548352040350437e-05, "eval/reward_rate": 0.0, "replay/size": 60721.0, "replay/inserts": 20112.0, "replay/samples": 20112.0, "replay/insert_wait_avg": 1.2023589301886971e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.225245688961154e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1983317899868976e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.06693601608276, "timer/env.step_count": 2514.0, "timer/env.step_total": 4.673261404037476, "timer/env.step_frac": 0.009345271737556305, "timer/env.step_avg": 0.0018588947510093379, "timer/env.step_min": 0.001085042953491211, "timer/env.step_max": 0.00755620002746582, "timer/replay._sample_count": 20112.0, "timer/replay._sample_total": 1332.7058365345001, "timer/replay._sample_frac": 2.665054896754139, "timer/replay._sample_avg": 0.06626421223819114, "timer/replay._sample_min": 0.0002925395965576172, "timer/replay._sample_max": 0.09087824821472168, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3092.0, "timer/agent.policy_total": 19.94747567176819, "timer/agent.policy_frac": 0.03988961124021736, "timer/agent.policy_avg": 0.006451318134465779, "timer/agent.policy_min": 0.005019426345825195, "timer/agent.policy_max": 0.009105682373046875, "timer/dataset_train_count": 1257.0, "timer/dataset_train_total": 0.09317278861999512, "timer/dataset_train_frac": 0.00018632063411806648, "timer/dataset_train_avg": 7.412314130468983e-05, "timer/dataset_train_min": 6.246566772460938e-05, "timer/dataset_train_max": 0.0002315044403076172, "timer/agent.train_count": 1257.0, "timer/agent.train_total": 469.1739068031311, "timer/agent.train_frac": 0.9382222118921334, "timer/agent.train_avg": 0.3732489314265164, "timer/agent.train_min": 0.3521769046783447, "timer/agent.train_max": 0.4175081253051758, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4051542282104492, "timer/agent.report_frac": 0.0008101999933013347, "timer/agent.report_avg": 0.2025771141052246, "timer/agent.report_min": 0.1960756778717041, "timer/agent.report_max": 0.20907855033874512, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 6.627149309077967e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 40.218003905309175}
{"step": 62200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 62704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 64512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 64736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 64736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 64736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 64736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 64736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 64960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 65016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 66824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 67328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 69640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 71304, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856}
{"step": 71448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 71672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 71672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 71672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 71672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 71896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 71952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 73616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 73760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 73984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 73984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 73984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 73984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 74208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 74264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 75928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 76576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 78888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 80696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 80920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 80920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 80920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 80920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 81144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 81200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 81369, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.001171875, "train/action_min": 0.0, "train/action_std": 1.9987338552474976, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 1.5368436892458703e-05, "train/actor_opt_grad_steps": 4360.0, "train/actor_opt_loss": -5.304397617340088, "train/adv_mag": 6.051397323608398e-05, "train/adv_max": 5.6817580014467236e-05, "train/adv_mean": 2.0461972768544e-05, "train/adv_min": -1.6808986663818358e-05, "train/adv_std": 1.3693495165171043e-05, "train/cont_avg": 0.9965625, "train/cont_loss_mean": 0.02299908521026373, "train/cont_loss_std": 0.3217790743449114, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.697538527046762, "train/cont_pos_acc": 0.9999999794960022, "train/cont_pos_loss": 0.003414796719327569, "train/cont_pred": 0.9965911927223206, "train/cont_rate": 0.9965625, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.029601253539323805, "train/extr_critic_critic_opt_grad_steps": 4360.0, "train/extr_critic_critic_opt_loss": 3348.998240234375, "train/extr_critic_mag": 0.006485445022583008, "train/extr_critic_max": 0.006485445022583008, "train/extr_critic_mean": 0.00647125306352973, "train/extr_critic_min": 0.006453447341918946, "train/extr_critic_std": 4.4645637235589674e-06, "train/extr_return_normed_mag": 8.956257998943329e-05, "train/extr_return_normed_max": 8.261312171816826e-05, "train/extr_return_normed_mean": 5.954419542922551e-05, "train/extr_return_normed_min": 3.119805082678795e-05, "train/extr_return_normed_std": 1.2367044882921619e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.006514783620834351, "train/extr_return_raw_max": 0.006514783620834351, "train/extr_return_raw_mean": 0.006491715032607317, "train/extr_return_raw_min": 0.00646336854994297, "train/extr_return_raw_std": 1.2367044947495743e-05, "train/extr_reward_mag": 2.2678375244140626e-05, "train/extr_reward_max": 2.2678375244140626e-05, "train/extr_reward_mean": 2.2657770787191113e-05, "train/extr_reward_min": 2.263450622558594e-05, "train/extr_reward_std": 6.826922266611746e-09, "train/image_loss_mean": 0.2634062166213989, "train/image_loss_std": 0.08342540115118027, "train/model_loss_mean": 0.8871400222778321, "train/model_loss_std": 0.348647645175457, "train/model_opt_grad_norm": 67.82969026184082, "train/model_opt_grad_steps": 4350.0, "train/model_opt_loss": 122.98091735839844, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 138.75, "train/policy_entropy_mag": 1.9458976726531982, "train/policy_entropy_max": 1.9458976726531982, "train/policy_entropy_mean": 1.945290307044983, "train/policy_entropy_min": 1.9354835205078125, "train/policy_entropy_std": 0.0004326228799764067, "train/policy_logprob_mag": 2.136646203994751, "train/policy_logprob_max": -1.7576238040924073, "train/policy_logprob_mean": -1.9452614526748657, "train/policy_logprob_min": -2.136646203994751, "train/policy_logprob_std": 0.03518003183603287, "train/policy_randomness_mag": 0.9999936490058899, "train/policy_randomness_max": 0.9999936490058899, "train/policy_randomness_mean": 0.9996815180778503, "train/policy_randomness_min": 0.9946418323516846, "train/policy_randomness_std": 0.0002223241929896176, "train/post_ent_mag": 40.733804504394534, "train/post_ent_max": 40.733804504394534, "train/post_ent_mean": 40.678992279052736, "train/post_ent_min": 40.614976135253904, "train/post_ent_std": 0.017407038420438767, "train/prior_ent_mag": 49.521642822265626, "train/prior_ent_max": 49.521642822265626, "train/prior_ent_mean": 49.456342041015624, "train/prior_ent_min": 49.29363748168945, "train/prior_ent_std": 0.030462501764297486, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 2.0776367280632257e-05, "train/reward_loss_mean": 0.0007346952445805073, "train/reward_loss_std": 0.019335272461591474, "train/reward_max_data": 0.02127500009536743, "train/reward_max_pred": 2.2663116455078124e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00013017460523406042, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 11.054216248648506, "train/reward_pred": 2.2643186151981355e-05, "train/reward_rate": 5.46875e-05, "train_stats/mean_log_entropy": 1.9386248422993555, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.01450195163488388, "report/cont_loss_std": 0.25076380372047424, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.683096408843994, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003408808493986726, "report/cont_pred": 0.9965971112251282, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25544804334640503, "report/image_loss_std": 0.07928632944822311, "report/model_loss_mean": 0.8700734376907349, "report/model_loss_std": 0.26275181770324707, "report/post_ent_mag": 37.989463806152344, "report/post_ent_max": 37.989463806152344, "report/post_ent_mean": 37.96717071533203, "report/post_ent_min": 37.87226867675781, "report/post_ent_std": 0.02240440808236599, "report/prior_ent_mag": 47.85467529296875, "report/prior_ent_max": 47.85467529296875, "report/prior_ent_mean": 47.810203552246094, "report/prior_ent_min": 47.6617431640625, "report/prior_ent_std": 0.02849557250738144, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00012350082397460938, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 2.8967857360839844e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00012350082397460938, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 2.8967857360839844e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003408808493986726, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003408808493986726, "eval/cont_pred": 0.9965971112251282, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2634829878807068, "eval/image_loss_std": 0.08116921782493591, "eval/model_loss_mean": 0.8670153021812439, "eval/model_loss_std": 0.08116921782493591, "eval/post_ent_mag": 37.98861312866211, "eval/post_ent_max": 37.98861312866211, "eval/post_ent_mean": 37.96698760986328, "eval/post_ent_min": 37.86811828613281, "eval/post_ent_std": 0.022194525226950645, "eval/prior_ent_mag": 47.85223388671875, "eval/prior_ent_max": 47.85223388671875, "eval/prior_ent_mean": 47.811927795410156, "eval/prior_ent_min": 47.658470153808594, "eval/prior_ent_std": 0.027123872190713882, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00012350082397460938, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 2.8967857360839844e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00012350082397460938, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.8967857360839844e-05, "eval/reward_rate": 0.0, "replay/size": 80865.0, "replay/inserts": 20144.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.184967796986211e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.178005568464187e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21864.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2004973566655882e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.25459265708923, "timer/env.step_count": 2518.0, "timer/env.step_total": 4.7443976402282715, "timer/env.step_frac": 0.009483966184155406, "timer/env.step_avg": 0.0018841928674456995, "timer/env.step_min": 0.0010821819305419922, "timer/env.step_max": 0.022194385528564453, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 1334.3771922588348, "timer/replay._sample_frac": 2.6673961855528905, "timer/replay._sample_avg": 0.06624191780474756, "timer/replay._sample_min": 0.0003345012664794922, "timer/replay._sample_max": 0.09328937530517578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3096.0, "timer/agent.policy_total": 20.01984930038452, "timer/agent.policy_frac": 0.040019321350054204, "timer/agent.policy_avg": 0.006466359593147455, "timer/agent.policy_min": 0.004908084869384766, "timer/agent.policy_max": 0.008661985397338867, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.09377861022949219, "timer/dataset_train_frac": 0.00018746176767991184, "timer/dataset_train_avg": 7.448658477322652e-05, "timer/dataset_train_min": 5.650520324707031e-05, "timer/dataset_train_max": 0.00023555755615234375, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 469.2531385421753, "timer/agent.train_frac": 0.9380286466731859, "timer/agent.train_avg": 0.3727189345053021, "timer/agent.train_min": 0.3521385192871094, "timer/agent.train_max": 0.4211769104003906, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4208502769470215, "timer/agent.report_frac": 0.0008412721904494393, "timer/agent.report_avg": 0.21042513847351074, "timer/agent.report_min": 0.20948338508605957, "timer/agent.report_max": 0.21136689186096191, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 6.577003869421521e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 40.266854924334815}
{"step": 82864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 83512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 85176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 85208, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417}
{"step": 85320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 85544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 85544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 85544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 85768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 85824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 87152, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236}
{"step": 87488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 87520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 87856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 87856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 87856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 88080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 88136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 89464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 89800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 89832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 254.0, "eval_episode/score": 0.20624999701976776, "eval_episode/reward_rate": 0.00392156862745098}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 90168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 90168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 90392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 90448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 91776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 92960, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 94088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 94456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 94792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 94792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 94792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 95016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 95072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 95272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 96400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 96768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 97584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 98712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 99896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 101024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 101392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 101561, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.99996155265748, "train/action_min": 0.0, "train/action_std": 1.9997479821753315, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 1.8163132869996458e-05, "train/actor_opt_grad_steps": 5620.0, "train/actor_opt_loss": -5.23867514565235, "train/adv_mag": 6.900376852924429e-05, "train/adv_max": 6.435384357890745e-05, "train/adv_mean": 2.3968351376454376e-05, "train/adv_min": -1.8389253899103073e-05, "train/adv_std": 1.572534851610848e-05, "train/cont_avg": 0.9967473548228346, "train/cont_loss_mean": 0.02191159743302333, "train/cont_loss_std": 0.30948626336119806, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.688955551240502, "train/cont_pos_acc": 0.9999999906134418, "train/cont_pos_loss": 0.0034420647563075456, "train/cont_pred": 0.996564008588866, "train/cont_rate": 0.9967473548228346, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.014570800833198734, "train/extr_critic_critic_opt_grad_steps": 5620.0, "train/extr_critic_critic_opt_loss": 3558.976612481545, "train/extr_critic_mag": 0.007049694774657723, "train/extr_critic_max": 0.007049694774657723, "train/extr_critic_mean": 0.007034784358904118, "train/extr_critic_min": 0.007016110607958216, "train/extr_critic_std": 4.6186570801820186e-06, "train/extr_return_normed_mag": 0.00010576724683440576, "train/extr_return_normed_max": 9.91842115488578e-05, "train/extr_return_normed_mean": 7.244691618680912e-05, "train/extr_return_normed_min": 4.038898875628869e-05, "train/extr_return_normed_std": 1.4428379216052973e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.007085489673818659, "train/extr_return_raw_max": 0.007085489673818659, "train/extr_return_raw_mean": 0.007058752748352571, "train/extr_return_raw_min": 0.007026694451026091, "train/extr_return_raw_std": 1.4428379092519244e-05, "train/extr_reward_mag": 2.4925066730168862e-05, "train/extr_reward_max": 2.4925066730168862e-05, "train/extr_reward_mean": 2.490186288494041e-05, "train/extr_reward_min": 2.4873440659890963e-05, "train/extr_reward_std": 8.584897762055004e-09, "train/image_loss_mean": 0.2590084587495158, "train/image_loss_std": 0.08344516202103434, "train/model_loss_mean": 0.8821661918182072, "train/model_loss_std": 0.351180299940541, "train/model_opt_grad_norm": 61.32045817938376, "train/model_opt_grad_steps": 5610.0, "train/model_opt_loss": 324.4120295967643, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 367.86417322834643, "train/policy_entropy_mag": 1.9459003679395661, "train/policy_entropy_max": 1.9459003679395661, "train/policy_entropy_mean": 1.9453996316654476, "train/policy_entropy_min": 1.9376498366904071, "train/policy_entropy_std": 0.0003555982456612217, "train/policy_logprob_mag": 2.1077491317208357, "train/policy_logprob_max": -1.78080213914706, "train/policy_logprob_mean": -1.9453879557256624, "train/policy_logprob_min": -2.1077491317208357, "train/policy_logprob_std": 0.03195605362494161, "train/policy_randomness_mag": 0.9999950331027113, "train/policy_randomness_max": 0.9999950331027113, "train/policy_randomness_mean": 0.999737709056674, "train/policy_randomness_min": 0.9957550994054539, "train/policy_randomness_std": 0.0001827413744456318, "train/post_ent_mag": 36.73904851477916, "train/post_ent_max": 36.73904851477916, "train/post_ent_mean": 36.71353750153789, "train/post_ent_min": 36.58687294186569, "train/post_ent_std": 0.03070660173071651, "train/prior_ent_mag": 46.90702982023945, "train/prior_ent_max": 46.90702982023945, "train/prior_ent_mean": 46.860739550252596, "train/prior_ent_min": 46.67232804786502, "train/prior_ent_std": 0.03666264090071043, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 3.123846602640811e-05, "train/reward_loss_mean": 0.0012461128791310186, "train/reward_loss_std": 0.03640121547244376, "train/reward_max_data": 0.031988189211041906, "train/reward_max_pred": 2.49288213534618e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00010802027025520362, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.572013310023717, "train/reward_pred": 2.4910672479785803e-05, "train/reward_rate": 0.00010765255905511811, "train_stats/mean_log_entropy": 1.9385473318954012, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0255766399204731, "report/cont_loss_std": 0.351606160402298, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.640276908874512, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0035582073032855988, "report/cont_pred": 0.996448278427124, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2697366774082184, "report/image_loss_std": 0.08521181344985962, "report/model_loss_mean": 0.8954020738601685, "report/model_loss_std": 0.3651996850967407, "report/post_ent_mag": 36.523136138916016, "report/post_ent_max": 36.523136138916016, "report/post_ent_mean": 36.488365173339844, "report/post_ent_min": 36.295921325683594, "report/post_ent_std": 0.048668842762708664, "report/prior_ent_mag": 46.448448181152344, "report/prior_ent_max": 46.448448181152344, "report/prior_ent_mean": 46.40094757080078, "report/prior_ent_min": 46.20454406738281, "report/prior_ent_std": 0.04111349582672119, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 8.869171142578125e-05, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 2.110004425048828e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 8.869171142578125e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 2.110004425048828e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0035582075361162424, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0035582075361162424, "eval/cont_pred": 0.996448278427124, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.27009817957878113, "eval/image_loss_std": 0.08137599378824234, "eval/model_loss_mean": 0.8737450838088989, "eval/model_loss_std": 0.08137598633766174, "eval/post_ent_mag": 36.52302169799805, "eval/post_ent_max": 36.52302169799805, "eval/post_ent_mean": 36.49235534667969, "eval/post_ent_min": 36.30548858642578, "eval/post_ent_std": 0.04428765922784805, "eval/prior_ent_mag": 46.44757080078125, "eval/prior_ent_max": 46.44757080078125, "eval/prior_ent_mean": 46.403255462646484, "eval/prior_ent_min": 46.21236038208008, "eval/prior_ent_std": 0.03763220086693764, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 8.869171142578125e-05, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 2.110004425048828e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 8.869171142578125e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.110004425048828e-05, "eval/reward_rate": 0.0, "replay/size": 101057.0, "replay/inserts": 20192.0, "replay/samples": 20192.0, "replay/insert_wait_avg": 1.2021765656025398e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.15991080959701e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26488.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2070456178130576e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.0726444721222, "timer/env.step_count": 2524.0, "timer/env.step_total": 4.774120807647705, "timer/env.step_frac": 0.009546854562875115, "timer/env.step_avg": 0.0018914900188778546, "timer/env.step_min": 0.0009992122650146484, "timer/env.step_max": 0.007913589477539062, "timer/replay._sample_count": 20192.0, "timer/replay._sample_total": 1337.2023725509644, "timer/replay._sample_frac": 2.6740162401055114, "timer/replay._sample_avg": 0.06622436472617692, "timer/replay._sample_min": 0.0006127357482910156, "timer/replay._sample_max": 0.09040021896362305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3102.0, "timer/agent.policy_total": 19.912747859954834, "timer/agent.policy_frac": 0.03981971035623189, "timer/agent.policy_avg": 0.006419325551242693, "timer/agent.policy_min": 0.005074024200439453, "timer/agent.policy_max": 0.008853912353515625, "timer/dataset_train_count": 1262.0, "timer/dataset_train_total": 0.09395194053649902, "timer/dataset_train_frac": 0.0001878765846823613, "timer/dataset_train_avg": 7.44468625487314e-05, "timer/dataset_train_min": 5.435943603515625e-05, "timer/dataset_train_max": 0.00016617774963378906, "timer/agent.train_count": 1262.0, "timer/agent.train_total": 469.19683504104614, "timer/agent.train_frac": 0.9382573516620398, "timer/agent.train_avg": 0.3717883003494819, "timer/agent.train_min": 0.35135579109191895, "timer/agent.train_max": 0.7747607231140137, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4199192523956299, "timer/agent.report_frac": 0.0008397165032670355, "timer/agent.report_avg": 0.20995962619781494, "timer/agent.report_min": 0.20995831489562988, "timer/agent.report_max": 0.2099609375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 6.8654576030381e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 40.37761825724015}
{"step": 101728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 101728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 101728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 101952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 102008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 102208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 103336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 103704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 104040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 104040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 104040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 104264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 104320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 104520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 105648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106264, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736}
{"step": 106352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 106832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 107960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 108328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 108576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 108664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 108664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 108888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 108944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 109144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 109664, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 110640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 110888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 110976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 110976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 111256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 111456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 111976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 112584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 112952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 113200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 113288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 113288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 113568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 113768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 114288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 114896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 115264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 115512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 115600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 115600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 115880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 116080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 116600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 117208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 117576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 117608, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838}
{"step": 117824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 117912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 117912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 118192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 118912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 119520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 119888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 119920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 120224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 120224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 120504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 121224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 121705, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9967171805245534, "train/action_min": 0.0, "train/action_std": 2.0007497961558993, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.2048435023475794e-05, "train/actor_opt_grad_steps": 6885.0, "train/actor_opt_loss": -4.751250668177529, "train/adv_mag": 0.00011272188867368395, "train/adv_max": 0.00011049997844984607, "train/adv_mean": 4.937022041143257e-05, "train/adv_min": -1.8233474018791365e-05, "train/adv_std": 2.6480497569630802e-05, "train/cont_avg": 0.9963572668650794, "train/cont_loss_mean": 0.02411253849369666, "train/cont_loss_std": 0.3326365507784344, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.683959506806874, "train/cont_pos_acc": 0.9999999862814707, "train/cont_pos_loss": 0.003452987046099253, "train/cont_pred": 0.996553112117071, "train/cont_rate": 0.9963572668650794, "train/dyn_loss_mean": 1.0067676930200486, "train/dyn_loss_std": 0.0010942400318555653, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.009097962259566264, "train/extr_critic_critic_opt_grad_steps": 6885.0, "train/extr_critic_critic_opt_loss": 3812.4587751116073, "train/extr_critic_mag": 0.007748425006866455, "train/extr_critic_max": 0.007748425006866455, "train/extr_critic_mean": 0.007728938146361283, "train/extr_critic_min": 0.007708693307543557, "train/extr_critic_std": 5.365222104531977e-06, "train/extr_return_normed_mag": 0.00017549857378952087, "train/extr_return_normed_max": 0.00017403669300533476, "train/extr_return_normed_mean": 0.00013097676928103353, "train/extr_return_normed_min": 7.783317391479772e-05, "train/extr_return_normed_std": 2.5096128747951036e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.007821367872464988, "train/extr_return_raw_max": 0.007821367872464988, "train/extr_return_raw_mean": 0.007778308394971112, "train/extr_return_raw_min": 0.007725164353374451, "train/extr_return_raw_std": 2.5096128876976577e-05, "train/extr_reward_mag": 3.103793613494388e-05, "train/extr_reward_max": 3.103793613494388e-05, "train/extr_reward_mean": 3.100806711627806e-05, "train/extr_reward_min": 3.097076264638749e-05, "train/extr_reward_std": 1.2406011647434418e-08, "train/image_loss_mean": 0.2564232447554195, "train/image_loss_std": 0.08396866633778527, "train/model_loss_mean": 0.8860862169946943, "train/model_loss_std": 0.37531558033965884, "train/model_opt_grad_norm": 55.11278782193623, "train/model_opt_grad_steps": 6875.0, "train/model_opt_loss": 775.213640485491, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 873.015873015873, "train/policy_entropy_mag": 1.94588783998338, "train/policy_entropy_max": 1.94588783998338, "train/policy_entropy_mean": 1.945205253268045, "train/policy_entropy_min": 1.9339922032659016, "train/policy_entropy_std": 0.0004816934843325899, "train/policy_logprob_mag": 2.132733174732753, "train/policy_logprob_max": -1.7447040800064328, "train/policy_logprob_mean": -1.94517083205874, "train/policy_logprob_min": -2.132733174732753, "train/policy_logprob_std": 0.03588549769113934, "train/policy_randomness_mag": 0.9999885946985275, "train/policy_randomness_max": 0.9999885946985275, "train/policy_randomness_mean": 0.9996378119029696, "train/policy_randomness_min": 0.993875444408447, "train/policy_randomness_std": 0.00024754151314800043, "train/post_ent_mag": 43.6380796583872, "train/post_ent_max": 43.6380796583872, "train/post_ent_mean": 43.58309134225997, "train/post_ent_min": 43.05530859932067, "train/post_ent_std": 0.11084804794425884, "train/prior_ent_mag": 47.35990945119706, "train/prior_ent_max": 47.35990945119706, "train/prior_ent_mean": 47.306664118691096, "train/prior_ent_min": 47.134522937593005, "train/prior_ent_std": 0.037328872777935534, "train/rep_loss_mean": 1.0067676930200486, "train/rep_loss_std": 0.0010942400318555653, "train/reward_avg": 4.897344686989007e-05, "train/reward_loss_mean": 0.0014897969011808672, "train/reward_loss_std": 0.04252457942989767, "train/reward_max_data": 0.04481646832492617, "train/reward_max_pred": 3.077113439166357e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00011037824983109854, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.437721073627472, "train/reward_pred": 3.074311063669267e-05, "train/reward_rate": 0.00013175843253968253, "train_stats/mean_log_entropy": 1.9383622374333127, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014871370978653431, "report/cont_loss_std": 0.24179567396640778, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.480737686157227, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004174958914518356, "report/cont_pred": 0.9958336353302002, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2632206082344055, "report/image_loss_std": 0.07987312972545624, "report/model_loss_mean": 0.8782494068145752, "report/model_loss_std": 0.25221410393714905, "report/post_ent_mag": 46.888572692871094, "report/post_ent_max": 46.888572692871094, "report/post_ent_mean": 46.88166427612305, "report/post_ent_min": 46.84246826171875, "report/post_ent_std": 0.006282083224505186, "report/prior_ent_mag": 47.42234802246094, "report/prior_ent_max": 47.42234802246094, "report/prior_ent_mean": 47.39644241333008, "report/prior_ent_min": 47.33147048950195, "report/prior_ent_std": 0.013349739834666252, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00015735626220703125, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 5.0187110900878906e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00015735626220703125, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.0187110900878906e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009523168206214905, "eval/cont_loss_std": 0.1710589975118637, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.480737686157227, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004174958914518356, "eval/cont_pred": 0.9958336353302002, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26382043957710266, "eval/image_loss_std": 0.07903297245502472, "eval/model_loss_mean": 0.8832328915596008, "eval/model_loss_std": 0.5002461671829224, "eval/post_ent_mag": 46.888999938964844, "eval/post_ent_max": 46.888999938964844, "eval/post_ent_mean": 46.881595611572266, "eval/post_ent_min": 46.843605041503906, "eval/post_ent_std": 0.006714270915836096, "eval/prior_ent_mag": 47.420448303222656, "eval/prior_ent_max": 47.420448303222656, "eval/prior_ent_mean": 47.396705627441406, "eval/prior_ent_min": 47.33147048950195, "eval/prior_ent_std": 0.014245875179767609, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0003326415899209678, "eval/reward_loss_mean": 0.00988924503326416, "eval/reward_loss_std": 0.31126824021339417, "eval/reward_max_data": 0.34062498807907104, "eval/reward_max_pred": 5.0187110900878906e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00015735626220703125, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.965611457824707, "eval/reward_pred": 5.0187110900878906e-05, "eval/reward_rate": 0.0009765625, "replay/size": 121201.0, "replay/inserts": 20144.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.1845417113603344e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.172442783904133e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2028691677898684e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.258487701416016e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.35927653312683, "timer/env.step_count": 2518.0, "timer/env.step_total": 4.839675426483154, "timer/env.step_frac": 0.009672400719771082, "timer/env.step_avg": 0.0019220315434802042, "timer/env.step_min": 0.0010876655578613281, "timer/env.step_max": 0.008862733840942383, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 1334.2416055202484, "timer/replay._sample_frac": 2.666567141044928, "timer/replay._sample_avg": 0.06623518693011558, "timer/replay._sample_min": 0.0003247261047363281, "timer/replay._sample_max": 0.09201931953430176, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3096.0, "timer/agent.policy_total": 19.935207843780518, "timer/agent.policy_frac": 0.03984178724916812, "timer/agent.policy_avg": 0.0064390206213761365, "timer/agent.policy_min": 0.004941225051879883, "timer/agent.policy_max": 0.009292125701904297, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.09367537498474121, "timer/dataset_train_frac": 0.00018721622517682917, "timer/dataset_train_avg": 7.440458696166895e-05, "timer/dataset_train_min": 5.316734313964844e-05, "timer/dataset_train_max": 0.0001609325408935547, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 469.46541380882263, "timer/agent.train_frac": 0.9382566404317302, "timer/agent.train_avg": 0.37288754075363195, "timer/agent.train_min": 0.3521552085876465, "timer/agent.train_max": 0.42679262161254883, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4179713726043701, "timer/agent.report_frac": 0.0008353425072887559, "timer/agent.report_avg": 0.20898568630218506, "timer/agent.report_min": 0.20821928977966309, "timer/agent.report_max": 0.20975208282470703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 6.194432028512837e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 40.258605611670276}
{"step": 121832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 122816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 123144, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 123536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 124144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 124544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 124760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 124848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 124848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 125128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 125456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 125848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 126456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 126856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 127768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 128160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 128768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 129168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 129384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 129472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 129472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 129752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 130472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 131080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 131440, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 131480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 131696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 131784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 131784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 132064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 132392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 132784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 133752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 133792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 134704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 135096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 136064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 136104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 136320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 136408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 136408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 136688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 137016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 137408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 138376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 138416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 138632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 138720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 138720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 139000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 139328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 139720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 250.0, "eval_episode/score": 0.21875, "eval_episode/reward_rate": 0.00398406374501992}
{"step": 140088, "eval_episode/length": 259.0, "eval_episode/score": 0.19062499701976776, "eval_episode/reward_rate": 0.0038461538461538464}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 140728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 140944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 141032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 141032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 141312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 141640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 141785, "train_stats/mean_log_entropy": 1.9375511767113045, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.00004931640625, "train/action_min": 0.0, "train/action_std": 1.9979313049316407, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 3.2376847586419896e-05, "train/actor_opt_grad_steps": 8140.0, "train/actor_opt_loss": -4.823020296096802, "train/adv_mag": 0.0001405114233493805, "train/adv_max": 0.00012477129697799683, "train/adv_mean": 4.552221908625143e-05, "train/adv_min": -3.682155162096023e-05, "train/adv_std": 3.270541151141515e-05, "train/cont_avg": 0.996171875, "train/cont_loss_mean": 0.025162989573553205, "train/cont_loss_std": 0.33557165158353747, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.658752379378652, "train/cont_pos_acc": 0.9999999852180481, "train/cont_pos_loss": 0.0035134843718260525, "train/cont_pred": 0.9964927711486816, "train/cont_rate": 0.996171875, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0062215185668319465, "train/extr_critic_critic_opt_grad_steps": 8140.0, "train/extr_critic_critic_opt_loss": 4304.8646875, "train/extr_critic_mag": 0.009152637481689454, "train/extr_critic_max": 0.009152637481689454, "train/extr_critic_mean": 0.009128473930060863, "train/extr_critic_min": 0.009098350524902344, "train/extr_critic_std": 7.737916602309269e-06, "train/extr_return_normed_mag": 0.00021415969729423522, "train/extr_return_normed_max": 0.00020220481604337693, "train/extr_return_normed_mean": 0.00014600457033702696, "train/extr_return_normed_min": 8.181785047054291e-05, "train/extr_return_normed_std": 3.068245248141466e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.009230195842683316, "train/extr_return_raw_max": 0.009230195842683316, "train/extr_return_raw_mean": 0.009173996083438397, "train/extr_return_raw_min": 0.009109808877110482, "train/extr_return_raw_std": 3.068245232225309e-05, "train/extr_reward_mag": 3.461933135986328e-05, "train/extr_reward_max": 3.461933135986328e-05, "train/extr_reward_mean": 3.4590360010042786e-05, "train/extr_reward_min": 3.456401824951172e-05, "train/extr_reward_std": 1.0019372360225986e-08, "train/image_loss_mean": 0.2498485904932022, "train/image_loss_std": 0.08330423396825791, "train/model_loss_mean": 0.876420871257782, "train/model_loss_std": 0.37655205941200254, "train/model_opt_grad_norm": 50.38304837036133, "train/model_opt_grad_steps": 8130.0, "train/model_opt_loss": 1752.29398828125, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2000.0, "train/policy_entropy_mag": 1.9458909511566163, "train/policy_entropy_max": 1.9458909511566163, "train/policy_entropy_mean": 1.944933074951172, "train/policy_entropy_min": 1.9299213161468507, "train/policy_entropy_std": 0.0006799632073380053, "train/policy_logprob_mag": 2.1621534061431884, "train/policy_logprob_max": -1.692391032218933, "train/policy_logprob_mean": -1.9448891401290893, "train/policy_logprob_min": -2.1621534061431884, "train/policy_logprob_std": 0.044228764712810516, "train/policy_randomness_mag": 0.9999901943206787, "train/policy_randomness_max": 0.9999901943206787, "train/policy_randomness_mean": 0.9994979391098022, "train/policy_randomness_min": 0.9917834248542786, "train/policy_randomness_std": 0.00034943198203109206, "train/post_ent_mag": 47.34517120361328, "train/post_ent_max": 47.34517120361328, "train/post_ent_mean": 47.33627258300781, "train/post_ent_min": 47.29840902709961, "train/post_ent_std": 0.006610965006053448, "train/prior_ent_mag": 47.54819592285156, "train/prior_ent_max": 47.54819592285156, "train/prior_ent_mean": 47.51899853515625, "train/prior_ent_min": 47.47101077270508, "train/prior_ent_std": 0.011838872022926807, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 5.13671871740371e-05, "train/reward_loss_mean": 0.0014092734083533287, "train/reward_loss_std": 0.041728789613073476, "train/reward_max_data": 0.05259999966621399, "train/reward_max_pred": 3.4626007080078125e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00010461190092610196, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.437395095825195, "train/reward_pred": 3.461037203669548e-05, "train/reward_rate": 0.000125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.036698706448078156, "report/cont_loss_std": 0.4337829351425171, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.686989784240723, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0033964025788009167, "report/cont_pred": 0.9966095685958862, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2457168698310852, "report/image_loss_std": 0.08637736737728119, "report/model_loss_mean": 0.8825691342353821, "report/model_loss_std": 0.44439658522605896, "report/post_ent_mag": 48.22083282470703, "report/post_ent_max": 48.22083282470703, "report/post_ent_mean": 48.212303161621094, "report/post_ent_min": 48.173919677734375, "report/post_ent_std": 0.006598681211471558, "report/prior_ent_mag": 47.516204833984375, "report/prior_ent_max": 47.516204833984375, "report/prior_ent_mean": 47.476402282714844, "report/prior_ent_min": 47.444419860839844, "report/prior_ent_std": 0.011019954457879066, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00015354156494140625, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 5.3048133850097656e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00015354156494140625, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.3048133850097656e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014497179538011551, "eval/cont_loss_std": 0.25093621015548706, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.6869893074035645, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003396411892026663, "eval/cont_pred": 0.9966095089912415, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24437859654426575, "eval/image_loss_std": 0.08940050005912781, "eval/model_loss_mean": 0.8695471286773682, "eval/model_loss_std": 0.5623801350593567, "eval/post_ent_mag": 48.21996307373047, "eval/post_ent_max": 48.21996307373047, "eval/post_ent_mean": 48.21259307861328, "eval/post_ent_min": 48.173988342285156, "eval/post_ent_std": 0.006232508923858404, "eval/prior_ent_mag": 47.51416778564453, "eval/prior_ent_max": 47.51416778564453, "eval/prior_ent_mean": 47.476417541503906, "eval/prior_ent_min": 47.433319091796875, "eval/prior_ent_std": 0.010889174416661263, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008056640508584678, "eval/reward_loss_mean": 0.010671271942555904, "eval/reward_loss_std": 0.33640292286872864, "eval/reward_max_data": 0.824999988079071, "eval/reward_max_pred": 5.3048133850097656e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00015354156494140625, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.770309448242188, "eval/reward_pred": 5.3048133850097656e-05, "eval/reward_rate": 0.0009765625, "replay/size": 141281.0, "replay/inserts": 20080.0, "replay/samples": 20080.0, "replay/insert_wait_avg": 1.20150852963269e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.28201638939846e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 35736.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.166931073145883e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.3867268562317, "timer/env.step_count": 2510.0, "timer/env.step_total": 4.857004642486572, "timer/env.step_frac": 0.009706501755155587, "timer/env.step_avg": 0.0019350616105524192, "timer/env.step_min": 0.001081705093383789, "timer/env.step_max": 0.009783744812011719, "timer/replay._sample_count": 20080.0, "timer/replay._sample_total": 1331.2096252441406, "timer/replay._sample_frac": 2.660361583944684, "timer/replay._sample_avg": 0.06629530006195919, "timer/replay._sample_min": 0.0003185272216796875, "timer/replay._sample_max": 0.09307670593261719, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3088.0, "timer/agent.policy_total": 19.999634504318237, "timer/agent.policy_frac": 0.03996835533582093, "timer/agent.policy_avg": 0.006476565577823263, "timer/agent.policy_min": 0.005186319351196289, "timer/agent.policy_max": 0.00891423225402832, "timer/dataset_train_count": 1255.0, "timer/dataset_train_total": 0.0937497615814209, "timer/dataset_train_frac": 0.00018735461304183744, "timer/dataset_train_avg": 7.470100524416007e-05, "timer/dataset_train_min": 5.984306335449219e-05, "timer/dataset_train_max": 0.0001533031463623047, "timer/agent.train_count": 1255.0, "timer/agent.train_total": 469.3661766052246, "timer/agent.train_frac": 0.9380068483312913, "timer/agent.train_avg": 0.3739969534702985, "timer/agent.train_min": 0.35238075256347656, "timer/agent.train_max": 0.4215579032897949, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41878747940063477, "timer/agent.report_frac": 0.0008369276340156769, "timer/agent.report_avg": 0.20939373970031738, "timer/agent.report_min": 0.2091665267944336, "timer/agent.report_max": 0.20962095260620117, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 6.575267118439929e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 40.12838489411875}
{"step": 142032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 143952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 144344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 144856, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291}
{"step": 145312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 145352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 145568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 145656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 145936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 146264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 146656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 147168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 147624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 147664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 147880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 147968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 148248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 148576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 148968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 149480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 149936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 149976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 150280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 150560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 150872, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564}
{"step": 150888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 151280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 151792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 152056, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774}
{"step": 152288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 152504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 152592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 153184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 153200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 153592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 154104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 154368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 154600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 154816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 154904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 155496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 155512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 155904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 156416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 156680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 156912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 157128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 157216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 157808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 157824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 158216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 158728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 158992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 159224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 159440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 159528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 160136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 160528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 161040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 161304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 161536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 161752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 161840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 161865, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.997831314329117, "train/action_min": 0.0, "train/action_std": 1.9986873846205453, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 3.380157906056931e-05, "train/actor_opt_grad_steps": 9395.0, "train/actor_opt_loss": -4.822943610804422, "train/adv_mag": 0.00014517604122086177, "train/adv_max": 0.00013107240998319218, "train/adv_mean": 4.561609144939356e-05, "train/adv_min": -4.6163716072600987e-05, "train/adv_std": 3.3642842113511594e-05, "train/cont_avg": 0.9966207837301587, "train/cont_loss_mean": 0.022649147414735386, "train/cont_loss_std": 0.3151427485250482, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.662098470281382, "train/cont_pos_acc": 0.9999999867545234, "train/cont_pos_loss": 0.003511992253599659, "train/cont_pred": 0.9964942723985702, "train/cont_rate": 0.9966207837301587, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.005484542766925953, "train/extr_critic_critic_opt_grad_steps": 9395.0, "train/extr_critic_critic_opt_loss": 4733.80169968378, "train/extr_critic_mag": 0.010436776138487317, "train/extr_critic_max": 0.010436776138487317, "train/extr_critic_mean": 0.010406654254193343, "train/extr_critic_min": 0.01037056673140753, "train/extr_critic_std": 9.64286962361228e-06, "train/extr_return_normed_mag": 0.0002101659331293333, "train/extr_return_normed_max": 0.0001994833897148806, "train/extr_return_normed_mean": 0.0001403884578363677, "train/extr_return_normed_min": 7.220147739327143e-05, "train/extr_return_normed_std": 3.08598455953798e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.010511364824774246, "train/extr_return_raw_max": 0.010511364824774246, "train/extr_return_raw_mean": 0.010452270493029601, "train/extr_return_raw_min": 0.010384082912452637, "train/extr_return_raw_std": 3.08598456143276e-05, "train/extr_reward_mag": 3.8478109571668836e-05, "train/extr_reward_max": 3.8478109571668836e-05, "train/extr_reward_mean": 3.84494618888961e-05, "train/extr_reward_min": 3.842701987614707e-05, "train/extr_reward_std": 1.1731143250818448e-08, "train/image_loss_mean": 0.24820187747005432, "train/image_loss_std": 0.08355682869515722, "train/model_loss_mean": 0.8719370999033489, "train/model_loss_std": 0.3531516015174843, "train/model_opt_grad_norm": 49.61712204463898, "train/model_opt_grad_steps": 9384.20634920635, "train/model_opt_loss": 2197.094482421875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2519.84126984127, "train/policy_entropy_mag": 1.9458878163307431, "train/policy_entropy_max": 1.9458878163307431, "train/policy_entropy_mean": 1.9448601300754245, "train/policy_entropy_min": 1.9345295381924463, "train/policy_entropy_std": 0.0006690398417598021, "train/policy_logprob_mag": 2.1519715804902333, "train/policy_logprob_max": -1.7330842311420138, "train/policy_logprob_mean": -1.944884444986071, "train/policy_logprob_min": -2.1519715804902333, "train/policy_logprob_std": 0.04579605794851742, "train/policy_randomness_mag": 0.9999885833452619, "train/policy_randomness_max": 0.9999885833452619, "train/policy_randomness_mean": 0.9994604511866494, "train/policy_randomness_min": 0.9941515823205312, "train/policy_randomness_std": 0.00034381847159700496, "train/post_ent_mag": 49.000146260337225, "train/post_ent_max": 49.000146260337225, "train/post_ent_mean": 48.98847582983592, "train/post_ent_min": 48.957850864955354, "train/post_ent_std": 0.005788798806154066, "train/prior_ent_mag": 47.4535109202067, "train/prior_ent_max": 47.4535109202067, "train/prior_ent_mean": 47.411079437013655, "train/prior_ent_min": 47.38103921072824, "train/prior_ent_std": 0.011743122142636113, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 3.940642798422939e-05, "train/reward_loss_mean": 0.0010860551163435928, "train/reward_loss_std": 0.031200757457626193, "train/reward_max_data": 0.040352182255850896, "train/reward_max_pred": 3.8487570626395086e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00011055637664939573, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.48867932955424, "train/reward_pred": 3.846525861364272e-05, "train/reward_rate": 9.300595238095238e-05, "train_stats/mean_log_entropy": 1.9374323042345718, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.009437468834221363, "report/cont_loss_std": 0.1719130575656891, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.507968902587891, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0040625594556331635, "report/cont_pred": 0.9959458112716675, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24498367309570312, "report/image_loss_std": 0.07529313862323761, "report/model_loss_mean": 0.8544936180114746, "report/model_loss_std": 0.18567070364952087, "report/post_ent_mag": 49.43096160888672, "report/post_ent_max": 49.43096160888672, "report/post_ent_mean": 49.4157829284668, "report/post_ent_min": 49.39093017578125, "report/post_ent_std": 0.006168000865727663, "report/prior_ent_mag": 47.418853759765625, "report/prior_ent_max": 47.418853759765625, "report/prior_ent_mean": 47.37739562988281, "report/prior_ent_min": 47.342742919921875, "report/prior_ent_std": 0.012753298506140709, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 7.2479248046875e-05, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 2.9802322387695312e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 7.2479248046875e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 2.9802322387695312e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.025562211871147156, "eval/cont_loss_std": 0.3433215618133545, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.507968902587891, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004062574822455645, "eval/cont_pred": 0.9959457516670227, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24665020406246185, "eval/image_loss_std": 0.07774442434310913, "eval/model_loss_mean": 0.8834198117256165, "eval/model_loss_std": 0.6205915808677673, "eval/post_ent_mag": 49.43016815185547, "eval/post_ent_max": 49.43016815185547, "eval/post_ent_mean": 49.41592025756836, "eval/post_ent_min": 49.390869140625, "eval/post_ent_std": 0.006453847046941519, "eval/prior_ent_mag": 47.431884765625, "eval/prior_ent_max": 47.431884765625, "eval/prior_ent_mean": 47.37940216064453, "eval/prior_ent_min": 47.34260559082031, "eval/prior_ent_std": 0.01299302838742733, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0009429931524209678, "eval/reward_loss_mean": 0.01120736449956894, "eval/reward_loss_std": 0.3561422824859619, "eval/reward_max_data": 0.965624988079071, "eval/reward_max_pred": 2.9802322387695312e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 7.2479248046875e-05, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 11.40219497680664, "eval/reward_pred": 2.9802322387695312e-05, "eval/reward_rate": 0.0009765625, "replay/size": 161361.0, "replay/inserts": 20080.0, "replay/samples": 20080.0, "replay/insert_wait_avg": 1.20150852963269e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.137872885897815e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 40360.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1944647066320927e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2308096885681, "timer/env.step_count": 2510.0, "timer/env.step_total": 4.891763925552368, "timer/env.step_frac": 0.009779013668905889, "timer/env.step_avg": 0.0019489099304989515, "timer/env.step_min": 0.0010824203491210938, "timer/env.step_max": 0.008228540420532227, "timer/replay._sample_count": 20080.0, "timer/replay._sample_total": 1334.4146575927734, "timer/replay._sample_frac": 2.6675979003043584, "timer/replay._sample_avg": 0.06645491322673175, "timer/replay._sample_min": 0.00047779083251953125, "timer/replay._sample_max": 0.09201407432556152, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3088.0, "timer/agent.policy_total": 19.89186692237854, "timer/agent.policy_frac": 0.03976537737602118, "timer/agent.policy_avg": 0.006441666749474916, "timer/agent.policy_min": 0.005065441131591797, "timer/agent.policy_max": 0.009278297424316406, "timer/dataset_train_count": 1255.0, "timer/dataset_train_total": 0.09353065490722656, "timer/dataset_train_frac": 0.0001869749985320907, "timer/dataset_train_avg": 7.452641825277017e-05, "timer/dataset_train_min": 5.7220458984375e-05, "timer/dataset_train_max": 0.00015807151794433594, "timer/agent.train_count": 1255.0, "timer/agent.train_total": 469.32881569862366, "timer/agent.train_frac": 0.9382245287746604, "timer/agent.train_avg": 0.3739671838236045, "timer/agent.train_min": 0.35193896293640137, "timer/agent.train_max": 0.8754611015319824, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4171607494354248, "timer/agent.report_frac": 0.0008339365376057888, "timer/agent.report_avg": 0.2085803747177124, "timer/agent.report_min": 0.20821714401245117, "timer/agent.report_max": 0.20894360542297363, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 6.339007995179166e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 40.14081832874144}
{"step": 162432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 162448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 162840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 163352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 163616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 163848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 164064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 164152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 164744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 164760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 165152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 165664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 165928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 166160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 166376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 166464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 167056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 167072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 167464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 167976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 168000, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333}
{"step": 168240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 168472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 168688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 169368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 169384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 169776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 170312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 170552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 170784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 171000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 171680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 171696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 172088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 172600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 172624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 172864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 173096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 173312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 173992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 174008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 174400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 174912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 174936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 175176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 175408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 175624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 176304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 176320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 176712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 177224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 177248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 177488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 177720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 177936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 178616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 178632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 179024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 179536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 179560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 179800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 180248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 180928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 180944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 181336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 181680, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 181848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 181872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 181993, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.99608251953125, "train/action_min": 0.0, "train/action_std": 2.003784433364868, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 9.548163611907512e-05, "train/actor_opt_grad_steps": 10650.0, "train/actor_opt_loss": -5.113209254860878, "train/adv_mag": 0.00020851314812898636, "train/adv_max": 0.00017751573026180269, "train/adv_mean": 3.003927736085643e-05, "train/adv_min": -0.0001189430058002472, "train/adv_std": 4.559358295500715e-05, "train/cont_avg": 0.99646875, "train/cont_loss_mean": 0.02346983783505857, "train/cont_loss_std": 0.3250749417580664, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.666835974871628, "train/cont_pos_acc": 0.9999999871253967, "train/cont_pos_loss": 0.003500935923308134, "train/cont_pred": 0.9965053029060363, "train/cont_rate": 0.99646875, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.004806219280231744, "train/extr_critic_critic_opt_grad_steps": 10650.0, "train/extr_critic_critic_opt_loss": 4922.24022265625, "train/extr_critic_mag": 0.01106751823425293, "train/extr_critic_max": 0.01106751823425293, "train/extr_critic_mean": 0.010998111739754677, "train/extr_critic_min": 0.010904997825622558, "train/extr_critic_std": 2.3165634220276844e-05, "train/extr_return_normed_mag": 0.0002446698620915413, "train/extr_return_normed_max": 0.00021362818032503127, "train/extr_return_normed_mean": 0.00012012773121750797, "train/extr_return_normed_min": 3.84899228811264e-06, "train/extr_return_normed_std": 3.912742629700005e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.011121650911867618, "train/extr_return_raw_max": 0.011121650911867618, "train/extr_return_raw_mean": 0.01102815092355013, "train/extr_return_raw_min": 0.0109118717238307, "train/extr_return_raw_std": 3.9127426383402056e-05, "train/extr_reward_mag": 3.790855407714844e-05, "train/extr_reward_max": 3.790855407714844e-05, "train/extr_reward_mean": 3.777861574781127e-05, "train/extr_reward_min": 3.772926330566406e-05, "train/extr_reward_std": 3.456163511916799e-08, "train/image_loss_mean": 0.24168269515037535, "train/image_loss_std": 0.08503882366418838, "train/model_loss_mean": 0.8661033291816711, "train/model_loss_std": 0.3576137773394585, "train/model_opt_grad_norm": 44.75664129564839, "train/model_opt_grad_steps": 10637.864, "train/model_opt_loss": 2252.665998046875, "train/model_opt_model_opt_grad_overflow": 0.008, "train/model_opt_model_opt_grad_scale": 2580.0, "train/policy_entropy_mag": 1.9458442392349242, "train/policy_entropy_max": 1.9458442392349242, "train/policy_entropy_mean": 1.942046145439148, "train/policy_entropy_min": 1.90286314868927, "train/policy_entropy_std": 0.003120504625141621, "train/policy_logprob_mag": 2.3515473251342773, "train/policy_logprob_max": -1.5650102043151854, "train/policy_logprob_mean": -1.942030979156494, "train/policy_logprob_min": -2.3515473251342773, "train/policy_logprob_std": 0.08074553707242012, "train/policy_randomness_mag": 0.9999661860466004, "train/policy_randomness_max": 0.9999661860466004, "train/policy_randomness_mean": 0.9980143632888794, "train/policy_randomness_min": 0.9778782773017883, "train/policy_randomness_std": 0.0016036222649272532, "train/post_ent_mag": 50.87856277465821, "train/post_ent_max": 50.87856277465821, "train/post_ent_mean": 50.80091802978516, "train/post_ent_min": 50.74483004760742, "train/post_ent_std": 0.02534106731414795, "train/prior_ent_mag": 47.801533325195315, "train/prior_ent_max": 47.801533325195315, "train/prior_ent_mean": 47.406132690429686, "train/prior_ent_min": 47.26206246948242, "train/prior_ent_std": 0.07774723439663649, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 4.914550797548145e-05, "train/reward_loss_mean": 0.0009507712870836257, "train/reward_loss_std": 0.02705976652194667, "train/reward_max_data": 0.05032500016689301, "train/reward_max_pred": 3.787326812744141e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00010474287823308259, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.829279899597168, "train/reward_pred": 3.777390625327826e-05, "train/reward_rate": 7.8125e-05, "train_stats/mean_log_entropy": 1.9347557391439165, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014439964666962624, "report/cont_loss_std": 0.25300559401512146, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.73370885848999, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032476584892719984, "report/cont_pred": 0.9967577457427979, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2393721342086792, "report/image_loss_std": 0.08455885201692581, "report/model_loss_mean": 0.8539185523986816, "report/model_loss_std": 0.26745209097862244, "report/post_ent_mag": 54.76332092285156, "report/post_ent_max": 54.76332092285156, "report/post_ent_mean": 54.42528533935547, "report/post_ent_min": 54.24585723876953, "report/post_ent_std": 0.09366356581449509, "report/prior_ent_mag": 49.9459228515625, "report/prior_ent_max": 49.9459228515625, "report/prior_ent_mean": 48.38331985473633, "report/prior_ent_min": 47.78379821777344, "report/prior_ent_std": 0.3896633982658386, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00010642688721418381, "report/reward_loss_std": 8.903010098038067e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.2438507080078125e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00010642688721418381, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.1196937672793865e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.031216977164149284, "eval/cont_loss_std": 0.39928650856018066, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.731372833251953, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032476182095706463, "eval/cont_pred": 0.9967577457427979, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2017369270324707, "eval/image_loss_std": 0.08166801184415817, "eval/model_loss_mean": 0.8330604434013367, "eval/model_loss_std": 0.4091498851776123, "eval/post_ent_mag": 54.77191162109375, "eval/post_ent_max": 54.77191162109375, "eval/post_ent_mean": 54.43724060058594, "eval/post_ent_min": 54.23657989501953, "eval/post_ent_std": 0.0921374037861824, "eval/prior_ent_mag": 50.633663177490234, "eval/prior_ent_max": 50.633663177490234, "eval/prior_ent_mean": 48.447444915771484, "eval/prior_ent_min": 47.82069396972656, "eval/prior_ent_std": 0.44727057218551636, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00010653119534254074, "eval/reward_loss_std": 9.511201142231585e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.2557716369628906e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00010653119534254074, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.123291000723839e-05, "eval/reward_rate": 0.0, "replay/size": 181489.0, "replay/inserts": 20128.0, "replay/samples": 20128.0, "replay/insert_wait_avg": 1.1966651118995654e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.160563511386017e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44984.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2103455289424909e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2849040031433, "timer/env.step_count": 2516.0, "timer/env.step_total": 4.909236192703247, "timer/env.step_frac": 0.009812880927289387, "timer/env.step_avg": 0.0019512067538566165, "timer/env.step_min": 0.0010654926300048828, "timer/env.step_max": 0.007981061935424805, "timer/replay._sample_count": 20128.0, "timer/replay._sample_total": 1336.9596338272095, "timer/replay._sample_frac": 2.6723965147243565, "timer/replay._sample_avg": 0.06642287528950762, "timer/replay._sample_min": 0.050191402435302734, "timer/replay._sample_max": 0.09116387367248535, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3094.0, "timer/agent.policy_total": 19.891807794570923, "timer/agent.policy_frac": 0.03976095947609473, "timer/agent.policy_avg": 0.006429155718995127, "timer/agent.policy_min": 0.005009889602661133, "timer/agent.policy_max": 0.008953094482421875, "timer/dataset_train_count": 1258.0, "timer/dataset_train_total": 0.09281134605407715, "timer/dataset_train_frac": 0.0001855169830459126, "timer/dataset_train_avg": 7.377690465347945e-05, "timer/dataset_train_min": 6.127357482910156e-05, "timer/dataset_train_max": 0.0001552104949951172, "timer/agent.train_count": 1258.0, "timer/agent.train_total": 469.3400790691376, "timer/agent.train_frac": 0.9381455952670295, "timer/agent.train_avg": 0.3730843235843701, "timer/agent.train_min": 0.3525269031524658, "timer/agent.train_max": 0.41933631896972656, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41829514503479004, "timer/agent.report_frac": 0.0008361138656947399, "timer/agent.report_avg": 0.20914757251739502, "timer/agent.report_min": 0.20850729942321777, "timer/agent.report_max": 0.20978784561157227, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 6.528948820072499e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 40.23244939711089}
{"step": 182112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 182344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 182560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 183240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 183256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 183992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 184160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 184184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 184424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 184656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 184872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 185552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 185568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 186152, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877}
{"step": 186304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 186472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 186496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 186736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 187184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 187240, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 187864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 187880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 187944, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714}
{"step": 188128, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015}
{"step": 188784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 189048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 189496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 189552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 190192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 190256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 190440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 191096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 191360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 191808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 191864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 192488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 192504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 192568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 192752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 193408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 193672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 194120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 194176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 194800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 194816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 194880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 195064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 195208, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 195720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 195984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 196432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 197112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 197128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 197192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 197376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 197520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 198032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 198296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 198512, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714}
{"step": 198744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 199440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 199504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 199688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 199832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 200608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 200824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 201056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 201752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 201816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 202000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 202089, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0122021871899802, "train/action_min": 0.0, "train/action_std": 1.9890882779681494, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00021007256908065064, "train/actor_opt_grad_steps": 11905.0, "train/actor_opt_loss": -4.561187727110727, "train/adv_mag": 0.0004552476078508392, "train/adv_max": 0.00038166149770693176, "train/adv_mean": 5.680946028996733e-05, "train/adv_min": -0.0003891782243810003, "train/adv_std": 7.326888185667081e-05, "train/cont_avg": 0.9964502728174603, "train/cont_loss_mean": 0.023599007323990385, "train/cont_loss_std": 0.32574061625765766, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.669268185092557, "train/cont_pos_acc": 0.9999999862814707, "train/cont_pos_loss": 0.0034873781962290644, "train/cont_pred": 0.9965188162667411, "train/cont_rate": 0.9964502728174603, "train/dyn_loss_mean": 1.0000003084303841, "train/dyn_loss_std": 9.854786127569184e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.014274795344727675, "train/extr_critic_critic_opt_grad_steps": 11905.0, "train/extr_critic_critic_opt_loss": 5357.756793309772, "train/extr_critic_mag": 0.012886939540741936, "train/extr_critic_max": 0.012886939540741936, "train/extr_critic_mean": 0.0124156955511324, "train/extr_critic_min": 0.012248570956881083, "train/extr_critic_std": 5.910385308587658e-05, "train/extr_return_normed_mag": 0.0005680288202942363, "train/extr_return_normed_max": 0.0005440930835902691, "train/extr_return_normed_mean": 0.0002389065796359362, "train/extr_return_normed_min": 4.735191367448322e-05, "train/extr_return_normed_std": 6.253598822363457e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.012777690886564198, "train/extr_return_raw_max": 0.012777690886564198, "train/extr_return_raw_mean": 0.01247250505294355, "train/extr_return_raw_min": 0.012280949716648412, "train/extr_return_raw_std": 6.253598807927032e-05, "train/extr_reward_mag": 4.558336167108445e-05, "train/extr_reward_max": 4.558336167108445e-05, "train/extr_reward_mean": 4.5235293097022574e-05, "train/extr_reward_min": 4.5088548508901445e-05, "train/extr_reward_std": 6.901168069634122e-08, "train/image_loss_mean": 0.2116915840241644, "train/image_loss_std": 0.09409440202372414, "train/model_loss_mean": 0.8365354613652305, "train/model_loss_std": 0.367274526270136, "train/model_opt_grad_norm": 43.05496921236553, "train/model_opt_grad_steps": 11891.817460317461, "train/model_opt_loss": 2455.0429077148438, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2956.3492063492063, "train/policy_entropy_mag": 1.9417068882594033, "train/policy_entropy_max": 1.9417068882594033, "train/policy_entropy_mean": 1.923492125102452, "train/policy_entropy_min": 1.7734903891881306, "train/policy_entropy_std": 0.013178389179446394, "train/policy_logprob_mag": 2.931783038472372, "train/policy_logprob_max": -1.1220980504202465, "train/policy_logprob_mean": -1.9235433406300015, "train/policy_logprob_min": -2.931783038472372, "train/policy_logprob_std": 0.18883151549195487, "train/policy_randomness_mag": 0.9978400118767269, "train/policy_randomness_max": 0.9978400118767269, "train/policy_randomness_mean": 0.9884794718689389, "train/policy_randomness_min": 0.9113938259699988, "train/policy_randomness_std": 0.00677235275765674, "train/post_ent_mag": 56.104627457876056, "train/post_ent_max": 56.104627457876056, "train/post_ent_mean": 55.6085511767675, "train/post_ent_min": 55.28510348002116, "train/post_ent_std": 0.16060836317520294, "train/prior_ent_mag": 56.33885507734995, "train/prior_ent_max": 56.33885507734995, "train/prior_ent_mean": 52.756523798382474, "train/prior_ent_min": 50.66383573744032, "train/prior_ent_std": 0.884774208305374, "train/rep_loss_mean": 1.0000003084303841, "train/rep_loss_std": 9.854786127569184e-06, "train/reward_avg": 4.543728227006449e-05, "train/reward_loss_mean": 0.0012446592177545268, "train/reward_loss_std": 0.03590301399805298, "train/reward_max_data": 0.04652777704454604, "train/reward_max_pred": 4.5407386053176156e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001221440225125416, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.345228331429619, "train/reward_pred": 4.521663030905146e-05, "train/reward_rate": 0.00010850694444444444, "train_stats/mean_log_entropy": 1.9129886014593973, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.031330253928899765, "report/cont_loss_std": 0.40380653738975525, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.796012878417969, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030442785937339067, "report/cont_pred": 0.996960461139679, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18476466834545135, "report/image_loss_std": 0.09827135503292084, "report/model_loss_mean": 0.8162521123886108, "report/model_loss_std": 0.41442710161209106, "report/post_ent_mag": 55.01106262207031, "report/post_ent_max": 55.01106262207031, "report/post_ent_mean": 54.4819450378418, "report/post_ent_min": 54.205810546875, "report/post_ent_std": 0.1518612504005432, "report/prior_ent_mag": 55.25153350830078, "report/prior_ent_max": 55.25153350830078, "report/prior_ent_mean": 52.63072204589844, "report/prior_ent_min": 49.99977493286133, "report/prior_ent_std": 0.9821141958236694, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00015710573643445969, "report/reward_loss_std": 5.657223027810687e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 6.4849853515625e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00015710573643445969, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.469304207712412e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008701473474502563, "eval/cont_loss_std": 0.18094182014465332, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.796012878417969, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0030442785937339067, "eval/cont_pred": 0.996960461139679, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1927884817123413, "eval/image_loss_std": 0.1020977571606636, "eval/model_loss_mean": 0.8016471266746521, "eval/model_loss_std": 0.20643392205238342, "eval/post_ent_mag": 54.99616241455078, "eval/post_ent_max": 54.99616241455078, "eval/post_ent_mean": 54.50090789794922, "eval/post_ent_min": 54.17703628540039, "eval/post_ent_std": 0.1546291708946228, "eval/prior_ent_mag": 55.291648864746094, "eval/prior_ent_max": 55.291648864746094, "eval/prior_ent_mean": 52.73170471191406, "eval/prior_ent_min": 50.00400161743164, "eval/prior_ent_std": 0.9475008249282837, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.000157112255692482, "eval/reward_loss_std": 5.421769060376391e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 6.473064422607422e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000157112255692482, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.469897925853729e-05, "eval/reward_rate": 0.0, "replay/size": 201585.0, "replay/inserts": 20096.0, "replay/samples": 20096.0, "replay/insert_wait_avg": 1.2011807055989648e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.114681212006101e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 49608.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1952381233030537e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.407499313354492e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.3139009475708, "timer/env.step_count": 2512.0, "timer/env.step_total": 4.91865086555481, "timer/env.step_frac": 0.009831129729234223, "timer/env.step_avg": 0.0019580616503004815, "timer/env.step_min": 0.001028299331665039, "timer/env.step_max": 0.00814199447631836, "timer/replay._sample_count": 20096.0, "timer/replay._sample_total": 1335.700965166092, "timer/replay._sample_frac": 2.6697258713706287, "timer/replay._sample_avg": 0.06646601140356748, "timer/replay._sample_min": 0.0004792213439941406, "timer/replay._sample_max": 0.09109282493591309, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3090.0, "timer/agent.policy_total": 19.938331365585327, "timer/agent.policy_frac": 0.03985164379367248, "timer/agent.policy_avg": 0.006452534422519523, "timer/agent.policy_min": 0.005143642425537109, "timer/agent.policy_max": 0.009601593017578125, "timer/dataset_train_count": 1256.0, "timer/dataset_train_total": 0.09303665161132812, "timer/dataset_train_frac": 0.00018595655934228715, "timer/dataset_train_avg": 7.407376720647144e-05, "timer/dataset_train_min": 5.173683166503906e-05, "timer/dataset_train_max": 0.0001728534698486328, "timer/agent.train_count": 1256.0, "timer/agent.train_total": 469.29373359680176, "timer/agent.train_frac": 0.9379985899012234, "timer/agent.train_avg": 0.37364150764076576, "timer/agent.train_min": 0.3518853187561035, "timer/agent.train_max": 0.4185454845428467, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4046590328216553, "timer/agent.report_frac": 0.0008088102930085498, "timer/agent.report_avg": 0.20232951641082764, "timer/agent.report_min": 0.19527220726013184, "timer/agent.report_max": 0.20938682556152344, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 6.671531814527093e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 40.16624721915978}
{"step": 202144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 202432, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776}
{"step": 202656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 202792, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045}
{"step": 202920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 203368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 204064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 204128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 204312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 204744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 204968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 205104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 205232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 205680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 206376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 206440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 206624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 207056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 207280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 207416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 207544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 207992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 208688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 208752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 208936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 209368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 209592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 209728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 209856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 210488, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 211000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 211064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 211248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 211680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 211904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 212040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 212616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 212800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 213312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 213376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 213560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 213992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 214216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 214352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 214928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 215112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 215616, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876}
{"step": 215624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 215688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 216304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 216528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 216664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 217240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 217424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 217928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 217936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 218000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 218616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 218840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 218976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 219552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 219736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 220248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 220312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 220736, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757}
{"step": 220928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 221152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 221288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 222048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 222233, "train_stats/mean_log_entropy": 1.923469430963758, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9985903785342263, "train/action_min": 0.0, "train/action_std": 1.995916075176663, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 9.181529308007734e-05, "train/actor_opt_grad_steps": 13165.0, "train/actor_opt_loss": -4.21399694397336, "train/adv_mag": 0.0005528962623978418, "train/adv_max": 0.00048338157671784596, "train/adv_mean": 7.642001224533646e-05, "train/adv_min": -0.00044246567117552907, "train/adv_std": 9.52497788285467e-05, "train/cont_avg": 0.9966362847222222, "train/cont_loss_mean": 0.02256810225154613, "train/cont_loss_std": 0.31288134735838313, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.646887470464238, "train/cont_pos_acc": 0.9999999834431542, "train/cont_pos_loss": 0.0035568274491067442, "train/cont_pred": 0.9964495679688832, "train/cont_rate": 0.9966362847222222, "train/dyn_loss_mean": 1.0000128727110604, "train/dyn_loss_std": 0.000195417436540112, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.002338153743443804, "train/extr_critic_critic_opt_grad_steps": 13165.0, "train/extr_critic_critic_opt_loss": 6025.989188058035, "train/extr_critic_mag": 0.015198832466488793, "train/extr_critic_max": 0.015198832466488793, "train/extr_critic_mean": 0.014706724190286227, "train/extr_critic_min": 0.01445637619684613, "train/extr_critic_std": 6.820844620441286e-05, "train/extr_return_normed_mag": 0.0006177990904284848, "train/extr_return_normed_max": 0.0006162775754337273, "train/extr_return_normed_mean": 0.0002814969766260465, "train/extr_return_normed_min": 1.0526184702203387e-05, "train/extr_return_normed_std": 7.686803600956901e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.015117924032171094, "train/extr_return_raw_max": 0.015117924032171094, "train/extr_return_raw_mean": 0.014783144189370058, "train/extr_return_raw_min": 0.01451217264143957, "train/extr_return_raw_std": 7.686803592295046e-05, "train/extr_reward_mag": 5.557612767295232e-05, "train/extr_reward_max": 5.557612767295232e-05, "train/extr_reward_mean": 5.549609846234994e-05, "train/extr_reward_min": 5.53992059495714e-05, "train/extr_reward_std": 3.7461109886955455e-08, "train/image_loss_mean": 0.19827382089126677, "train/image_loss_std": 0.09744283403196032, "train/model_loss_mean": 0.822015779359, "train/model_loss_std": 0.35436638367791023, "train/model_opt_grad_norm": 40.700729703146315, "train/model_opt_grad_steps": 13150.785714285714, "train/model_opt_loss": 2409.897442530072, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2936.5079365079364, "train/policy_entropy_mag": 1.9457418587472703, "train/policy_entropy_max": 1.9457418587472703, "train/policy_entropy_mean": 1.9343698564029874, "train/policy_entropy_min": 1.8284047122985598, "train/policy_entropy_std": 0.009153573178789683, "train/policy_logprob_mag": 2.7180906855870806, "train/policy_logprob_max": -1.2324376233986445, "train/policy_logprob_mean": -1.9345223156232683, "train/policy_logprob_min": -2.7180906855870806, "train/policy_logprob_std": 0.1511935963044091, "train/policy_randomness_mag": 0.9999135756303393, "train/policy_randomness_max": 0.9999135756303393, "train/policy_randomness_mean": 0.9940695176048885, "train/policy_randomness_min": 0.9396142060794528, "train/policy_randomness_std": 0.004704006354413217, "train/post_ent_mag": 52.57307767111158, "train/post_ent_max": 52.57307767111158, "train/post_ent_mean": 52.08372443062918, "train/post_ent_min": 51.784335999261764, "train/post_ent_std": 0.1469998842193967, "train/prior_ent_mag": 54.229368421766495, "train/prior_ent_max": 54.229368421766495, "train/prior_ent_mean": 51.24791638813321, "train/prior_ent_min": 48.258639653523765, "train/prior_ent_std": 1.0801770521534815, "train/rep_loss_mean": 1.0000128727110604, "train/rep_loss_std": 0.000195417436540112, "train/reward_avg": 4.3184795007590086e-05, "train/reward_loss_mean": 0.001166113770552098, "train/reward_loss_std": 0.032791733044640885, "train/reward_max_data": 0.04422123008777225, "train/reward_max_pred": 5.559694199335008e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00014087402191112882, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.175573202279898, "train/reward_pred": 5.551155320265227e-05, "train/reward_rate": 0.00010075644841269841, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025659607723355293, "report/cont_loss_std": 0.3637336492538452, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.833985805511475, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.002881858730688691, "report/cont_pred": 0.9971219897270203, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1802387833595276, "report/image_loss_std": 0.103035569190979, "report/model_loss_mean": 0.8163129687309265, "report/model_loss_std": 0.6122593879699707, "report/post_ent_mag": 48.73646545410156, "report/post_ent_max": 48.73646545410156, "report/post_ent_mean": 48.376197814941406, "report/post_ent_min": 48.09449005126953, "report/post_ent_std": 0.12284567952156067, "report/prior_ent_mag": 52.9205436706543, "report/prior_ent_max": 52.9205436706543, "report/prior_ent_mean": 49.360408782958984, "report/prior_ent_min": 46.08762741088867, "report/prior_ent_std": 1.4859551191329956, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00022583008103538305, "report/reward_loss_mean": 0.01041453517973423, "report/reward_loss_std": 0.32950305938720703, "report/reward_max_data": 0.23125000298023224, "report/reward_max_pred": 4.470348358154297e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001125335693359375, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.549362182617188, "report/reward_pred": 4.470348358154297e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03141316398978233, "eval/cont_loss_std": 0.4072941839694977, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.845864772796631, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0028829812072217464, "eval/cont_pred": 0.9971210360527039, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2039644420146942, "eval/image_loss_std": 0.11491904407739639, "eval/model_loss_mean": 0.8456210494041443, "eval/model_loss_std": 0.6419108510017395, "eval/post_ent_mag": 48.803977966308594, "eval/post_ent_max": 48.803977966308594, "eval/post_ent_mean": 48.370399475097656, "eval/post_ent_min": 48.12566375732422, "eval/post_ent_std": 0.11287045478820801, "eval/prior_ent_mag": 52.68714141845703, "eval/prior_ent_max": 52.68714141845703, "eval/prior_ent_mean": 49.7069206237793, "eval/prior_ent_min": 46.340797424316406, "eval/prior_ent_std": 1.3296964168548584, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0003326415899209678, "eval/reward_loss_mean": 0.010243426077067852, "eval/reward_loss_std": 0.3240301311016083, "eval/reward_max_data": 0.34062498807907104, "eval/reward_max_pred": 4.470348358154297e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001125335693359375, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.374146461486816, "eval/reward_pred": 4.470348358154297e-05, "eval/reward_rate": 0.0009765625, "replay/size": 221729.0, "replay/inserts": 20144.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.191666809881936e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.136107148586331e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54232.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1937428510725291e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.0680215358734, "timer/env.step_count": 2518.0, "timer/env.step_total": 4.8876917362213135, "timer/env.step_frac": 0.009774053780142958, "timer/env.step_avg": 0.0019411007689520705, "timer/env.step_min": 0.0010464191436767578, "timer/env.step_max": 0.007957935333251953, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 1339.280266046524, "timer/replay._sample_frac": 2.6781961820577003, "timer/replay._sample_avg": 0.0664853190054867, "timer/replay._sample_min": 0.0003409385681152344, "timer/replay._sample_max": 0.09265017509460449, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3096.0, "timer/agent.policy_total": 19.791448831558228, "timer/agent.policy_frac": 0.03957751341661916, "timer/agent.policy_avg": 0.006392586831898652, "timer/agent.policy_min": 0.00493168830871582, "timer/agent.policy_max": 0.009355783462524414, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.09287142753601074, "timer/dataset_train_frac": 0.00018571758948067113, "timer/dataset_train_avg": 7.376602663702204e-05, "timer/dataset_train_min": 5.5789947509765625e-05, "timer/dataset_train_max": 0.00017571449279785156, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 469.04600286483765, "timer/agent.train_frac": 0.9379644021712148, "timer/agent.train_avg": 0.37255441053601085, "timer/agent.train_min": 0.35170412063598633, "timer/agent.train_max": 0.9915592670440674, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4049978256225586, "timer/agent.report_frac": 0.0008098854719377517, "timer/agent.report_avg": 0.2024989128112793, "timer/agent.report_min": 0.195875883102417, "timer/agent.report_max": 0.2091219425201416, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 6.293394315586844e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 40.2818656336871}
{"step": 222552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 222560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 222624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 223048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 223240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 223464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 223600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 224360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 224864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 224872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 224936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 225360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 225552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 225776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 225912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 226672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 227176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 227184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 227248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 227672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 227864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 228088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 228224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 228984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 229488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 229496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 229560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 229984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 230400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 230536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 231296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 231800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 231808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 231872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 232296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 232488, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154}
{"step": 232488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 232712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 232848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 234112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 234120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 234184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 234608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 234800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 234800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 235024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 235160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 236424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 236432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 236496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 236920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 237112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 237112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 237336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 237472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 238736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 238744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 238808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 239232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 239424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 239424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 239648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 239784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 241048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 241056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 241120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 241240, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495}
{"step": 241544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 241736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 241736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 241960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 242377, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0009286063058034, "train/action_min": 0.0, "train/action_std": 1.997682822129083, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.917903449484295e-05, "train/actor_opt_grad_steps": 14425.0, "train/actor_opt_loss": -5.542701276521834, "train/adv_mag": 0.0005416363063785764, "train/adv_max": 0.00043575034757691717, "train/adv_mean": 6.703590430326643e-06, "train/adv_min": -0.0005202611893533715, "train/adv_std": 8.453175489973676e-05, "train/cont_avg": 0.9963572668650794, "train/cont_loss_mean": 0.0240443064942069, "train/cont_loss_std": 0.3282297424279571, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6758014205994645, "train/cont_pos_acc": 0.9999999815509433, "train/cont_pos_loss": 0.0033832214724656847, "train/cont_pred": 0.9966223320317646, "train/cont_rate": 0.9963572668650794, "train/dyn_loss_mean": 1.0000023889163183, "train/dyn_loss_std": 6.227482513095887e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0015604817687297269, "train/extr_critic_critic_opt_grad_steps": 14425.0, "train/extr_critic_critic_opt_loss": 6150.742009238591, "train/extr_critic_mag": 0.01568506539814056, "train/extr_critic_max": 0.01568506539814056, "train/extr_critic_mean": 0.015160473758384349, "train/extr_critic_min": 0.014895707841903444, "train/extr_critic_std": 6.916789081717272e-05, "train/extr_return_normed_mag": 0.0004924279637634754, "train/extr_return_normed_max": 0.0004910991586271733, "train/extr_return_normed_mean": 0.00010972337636014836, "train/extr_return_normed_min": -0.00011671236198809411, "train/extr_return_normed_std": 6.25621438043059e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.015548552260808056, "train/extr_return_raw_max": 0.015548552260808056, "train/extr_return_raw_mean": 0.015167177314796144, "train/extr_return_raw_min": 0.014940740740192788, "train/extr_return_raw_std": 6.256214383317874e-05, "train/extr_reward_mag": 4.617940811883836e-05, "train/extr_reward_max": 4.617940811883836e-05, "train/extr_reward_mean": 4.5995954404509304e-05, "train/extr_reward_min": 4.574041517954024e-05, "train/extr_reward_std": 8.366476716540533e-08, "train/image_loss_mean": 0.1940567506447671, "train/image_loss_std": 0.0994170724990822, "train/model_loss_mean": 0.8196179819485497, "train/model_loss_std": 0.3754817240294956, "train/model_opt_grad_norm": 39.10121763320196, "train/model_opt_grad_steps": 14409.904761904761, "train/model_opt_loss": 2711.804654560392, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3313.4920634920636, "train/policy_entropy_mag": 1.9457635406463865, "train/policy_entropy_max": 1.9457635406463865, "train/policy_entropy_mean": 1.9367866298509022, "train/policy_entropy_min": 1.8610404379784116, "train/policy_entropy_std": 0.0069616523179565635, "train/policy_logprob_mag": 2.614730513285077, "train/policy_logprob_max": -1.3261620430719285, "train/policy_logprob_mean": -1.9367668448932587, "train/policy_logprob_min": -2.614730513285077, "train/policy_logprob_std": 0.13463051167745438, "train/policy_randomness_mag": 0.9999247193336487, "train/policy_randomness_max": 0.9999247193336487, "train/policy_randomness_mean": 0.9953114901270185, "train/policy_randomness_min": 0.9563856512781174, "train/policy_randomness_std": 0.0035775817915915495, "train/post_ent_mag": 49.096612022036595, "train/post_ent_max": 49.096612022036595, "train/post_ent_mean": 48.6773192390563, "train/post_ent_min": 48.39406276884533, "train/post_ent_std": 0.13422658897581555, "train/prior_ent_mag": 50.39073971339634, "train/prior_ent_max": 50.39073971339634, "train/prior_ent_mean": 47.87551186576722, "train/prior_ent_min": 45.42109843662807, "train/prior_ent_std": 1.0186612695928603, "train/rep_loss_mean": 1.0000023889163183, "train/rep_loss_std": 6.227482513095887e-05, "train/reward_avg": 8.135598747887545e-05, "train/reward_loss_mean": 0.0015154734386929444, "train/reward_loss_std": 0.04335909639958929, "train/reward_max_data": 0.0779761899085272, "train/reward_max_pred": 4.6141563899933344e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00011273306269671709, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.664014458656311, "train/reward_pred": 4.5985499921713084e-05, "train/reward_rate": 0.00013175843253968253, "train_stats/mean_log_entropy": 1.9273982759979036, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014445429667830467, "report/cont_loss_std": 0.25284865498542786, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.729821681976318, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032607398461550474, "report/cont_pred": 0.9967446327209473, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.21808591485023499, "report/image_loss_std": 0.11470382660627365, "report/model_loss_mean": 0.8433377146720886, "report/model_loss_std": 0.5715600848197937, "report/post_ent_mag": 44.46464538574219, "report/post_ent_max": 44.46464538574219, "report/post_ent_mean": 44.20277786254883, "report/post_ent_min": 43.96478271484375, "report/post_ent_std": 0.08546682447195053, "report/prior_ent_mag": 48.97555923461914, "report/prior_ent_max": 48.97555923461914, "report/prior_ent_mean": 45.7550048828125, "report/prior_ent_min": 43.3484001159668, "report/prior_ent_std": 1.2618465423583984, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018310546875, "report/reward_loss_mean": 0.010806383565068245, "report/reward_loss_std": 0.34197622537612915, "report/reward_max_data": 0.1875, "report/reward_max_pred": 4.780292510986328e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00011440456000855193, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.948700904846191, "report/reward_pred": 4.7440873458981514e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008666245266795158, "eval/cont_loss_std": 0.17132964730262756, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.488517761230469, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0033095967955887318, "eval/cont_pred": 0.9966951012611389, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1834840029478073, "eval/image_loss_std": 0.09137586504220963, "eval/model_loss_mean": 0.7922646999359131, "eval/model_loss_std": 0.19159387052059174, "eval/post_ent_mag": 44.459686279296875, "eval/post_ent_max": 44.459686279296875, "eval/post_ent_mean": 44.195518493652344, "eval/post_ent_min": 43.961700439453125, "eval/post_ent_std": 0.08838307112455368, "eval/prior_ent_mag": 49.039249420166016, "eval/prior_ent_max": 49.039249420166016, "eval/prior_ent_mean": 45.77198028564453, "eval/prior_ent_min": 43.349159240722656, "eval/prior_ent_std": 1.4216864109039307, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00011441204696893692, "eval/reward_loss_std": 1.6340133868197881e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.780292510986328e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00011441204696893692, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.7448091208934784e-05, "eval/reward_rate": 0.0, "replay/size": 241873.0, "replay/inserts": 20144.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.1863289038466498e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.116814938303589e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 58856.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1829665787904732e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2574439048767, "timer/env.step_count": 2518.0, "timer/env.step_total": 4.900075435638428, "timer/env.step_frac": 0.009795107489835114, "timer/env.step_avg": 0.0019460188386173263, "timer/env.step_min": 0.001068115234375, "timer/env.step_max": 0.00969076156616211, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 1339.3274433612823, "timer/replay._sample_frac": 2.677276389746144, "timer/replay._sample_avg": 0.06648766100880076, "timer/replay._sample_min": 0.0003261566162109375, "timer/replay._sample_max": 0.0942387580871582, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3096.0, "timer/agent.policy_total": 19.863736867904663, "timer/agent.policy_frac": 0.03970702907057936, "timer/agent.policy_avg": 0.0064159356808477595, "timer/agent.policy_min": 0.005003452301025391, "timer/agent.policy_max": 0.010625123977661133, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.09391307830810547, "timer/dataset_train_frac": 0.00018772949698668136, "timer/dataset_train_avg": 7.459339023677956e-05, "timer/dataset_train_min": 5.412101745605469e-05, "timer/dataset_train_max": 0.00013256072998046875, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 469.2473511695862, "timer/agent.train_frac": 0.9380117315332003, "timer/agent.train_avg": 0.3727143377041987, "timer/agent.train_min": 0.34662771224975586, "timer/agent.train_max": 0.42812466621398926, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4201321601867676, "timer/agent.report_frac": 0.0008398319011653831, "timer/agent.report_avg": 0.2100660800933838, "timer/agent.report_min": 0.20926952362060547, "timer/agent.report_max": 0.2108626365661621, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 6.52930720669595e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 40.266609534922125}
{"step": 243360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 243368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 243432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 243552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 243856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 243952, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 244048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 244048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 244272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 245568, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842}
{"step": 245672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 245680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 245744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 245992, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925}
{"step": 246264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 246360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 246584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 247880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 247984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 247992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 248056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 248304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 248576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 248672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 248896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 250296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 250304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 250368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 250616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 250760, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 250888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 250984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 251208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 252504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 252608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 252680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 252928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 253072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 253096, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015}
{"step": 253296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 253520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 254816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 254920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 254992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 255240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 255384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 255408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 255608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 255832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 257128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 257232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 257304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 257552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 257696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 257720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 257920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 258144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 259440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 259544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 259616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 259864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 260000, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222}
{"step": 260000, "eval_episode/length": 269.0, "eval_episode/score": 0.15937499701976776, "eval_episode/reward_rate": 0.003703703703703704}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 260232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 260456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 261752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 261856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 261928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 262176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 262312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 262344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 262473, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0380166015625, "train/action_min": 0.0, "train/action_std": 1.9818365964889526, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0011329630960535723, "train/actor_opt_grad_steps": 15680.0, "train/actor_opt_loss": -1.1832321790456772, "train/adv_mag": 0.003608871132135391, "train/adv_max": 0.00355444847792387, "train/adv_mean": 0.00026294552196691256, "train/adv_min": -0.0009528674855828285, "train/adv_std": 0.0005943441914278083, "train/cont_avg": 0.9965546875, "train/cont_loss_mean": 0.02295367952622473, "train/cont_loss_std": 0.3181737503139957, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.661602141427212, "train/cont_pos_acc": 0.9999999823570251, "train/cont_pos_loss": 0.003465193374082446, "train/cont_pred": 0.9965406908988953, "train/cont_rate": 0.9965546875, "train/dyn_loss_mean": 1.188966700553894, "train/dyn_loss_std": 0.07996287196828053, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.051091841926216144, "train/extr_critic_critic_opt_grad_steps": 15680.0, "train/extr_critic_critic_opt_loss": 6542.28642578125, "train/extr_critic_mag": 0.016820717811584472, "train/extr_critic_max": 0.016820717811584472, "train/extr_critic_mean": 0.016428266249597073, "train/extr_critic_min": 0.016163719177246093, "train/extr_critic_std": 9.15057687961962e-05, "train/extr_return_normed_mag": 0.0039355790838599206, "train/extr_return_normed_max": 0.003932126581668854, "train/extr_return_normed_mean": 0.0007032274094199238, "train/extr_return_normed_min": -0.00039061971008777616, "train/extr_return_normed_std": 0.0005776887810934568, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.01992011009156704, "train/extr_return_raw_max": 0.01992011009156704, "train/extr_return_raw_mean": 0.016691211700439454, "train/extr_return_raw_min": 0.015597363762557506, "train/extr_return_raw_std": 0.0005776887807296589, "train/extr_reward_mag": 0.0006917963027954101, "train/extr_reward_max": 0.0006917963027954101, "train/extr_reward_mean": 8.855198684614152e-05, "train/extr_reward_min": -1.0176658630371093e-05, "train/extr_reward_std": 0.0001190596965556665, "train/image_loss_mean": 0.21698337876796722, "train/image_loss_std": 0.09578934669494629, "train/model_loss_mean": 0.9546477999687195, "train/model_loss_std": 0.4023097809553146, "train/model_opt_grad_norm": 36.3725181350708, "train/model_opt_grad_steps": 15663.088, "train/model_opt_loss": 1638.192994140625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1645.0, "train/policy_entropy_mag": 1.940969889640808, "train/policy_entropy_max": 1.940969889640808, "train/policy_entropy_mean": 1.9309626760482788, "train/policy_entropy_min": 1.8419990510940552, "train/policy_entropy_std": 0.006129702622070909, "train/policy_logprob_mag": 2.639252685546875, "train/policy_logprob_max": -1.3054388358592988, "train/policy_logprob_mean": -1.9309219703674316, "train/policy_logprob_min": -2.639252685546875, "train/policy_logprob_std": 0.12705508905649185, "train/policy_randomness_mag": 0.9974612684249878, "train/policy_randomness_max": 0.9974612684249878, "train/policy_randomness_mean": 0.9923185758590698, "train/policy_randomness_min": 0.9466003112792969, "train/policy_randomness_std": 0.0031500441804528235, "train/post_ent_mag": 71.01796600341797, "train/post_ent_max": 71.01796600341797, "train/post_ent_mean": 70.81549145507813, "train/post_ent_min": 70.4518208618164, "train/post_ent_std": 0.0980513668358326, "train/prior_ent_mag": 72.5562216796875, "train/prior_ent_max": 72.5562216796875, "train/prior_ent_mean": 70.94239129638672, "train/prior_ent_min": 68.8017138671875, "train/prior_ent_std": 0.7876502510309219, "train/rep_loss_mean": 1.188966700553894, "train/rep_loss_std": 0.07996287196828053, "train/reward_avg": 6.381836079526693e-05, "train/reward_loss_mean": 0.0013307013772428035, "train/reward_loss_std": 0.034723303020514094, "train/reward_max_data": 0.061050000786781314, "train/reward_max_pred": 0.0001857128143310547, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00016138428781414406, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.08255437704233, "train/reward_pred": 6.194602325558662e-05, "train/reward_rate": 0.0001171875, "train_stats/mean_log_entropy": 1.9214321689473257, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014586446806788445, "report/cont_loss_std": 0.24903833866119385, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.644169330596924, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003569653257727623, "report/cont_pred": 0.9964367151260376, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24445678293704987, "report/image_loss_std": 0.08666975051164627, "report/model_loss_mean": 0.8591989874839783, "report/model_loss_std": 0.26566749811172485, "report/post_ent_mag": 101.02812957763672, "report/post_ent_max": 101.02812957763672, "report/post_ent_mean": 100.94784545898438, "report/post_ent_min": 100.41081237792969, "report/post_ent_std": 0.10203900933265686, "report/prior_ent_mag": 100.86093139648438, "report/prior_ent_max": 100.86093139648438, "report/prior_ent_mean": 100.68633270263672, "report/prior_ent_min": 98.99949645996094, "report/prior_ent_std": 0.2938852608203888, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00015570595860481262, "report/reward_loss_std": 1.846207396738464e-06, "report/reward_max_data": 0.0, "report/reward_max_pred": 7.510185241699219e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00015570595860481262, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.294153328984976e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02007131837308407, "eval/cont_loss_std": 0.30443814396858215, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.6363844871521, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0035689303185790777, "eval/cont_pred": 0.9964373707771301, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2517850399017334, "eval/image_loss_std": 0.08527159690856934, "eval/model_loss_mean": 0.872012197971344, "eval/model_loss_std": 0.3130043148994446, "eval/post_ent_mag": 101.02630615234375, "eval/post_ent_max": 101.02630615234375, "eval/post_ent_mean": 100.94097900390625, "eval/post_ent_min": 100.41109466552734, "eval/post_ent_std": 0.1079750806093216, "eval/prior_ent_mag": 100.85755920410156, "eval/prior_ent_max": 100.85755920410156, "eval/prior_ent_mean": 100.67355346679688, "eval/prior_ent_min": 98.99949645996094, "eval/prior_ent_std": 0.3097952902317047, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00015579164028167725, "eval/reward_loss_std": 1.9844296730298083e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.56978988647461e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00015579164028167725, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.299066055566072e-05, "eval/reward_rate": 0.0, "replay/size": 261969.0, "replay/inserts": 20096.0, "replay/samples": 20096.0, "replay/insert_wait_avg": 1.2129735035501468e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.179339913046284e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 63480.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2265872790326709e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.0009639263153, "timer/env.step_count": 2512.0, "timer/env.step_total": 4.899020433425903, "timer/env.step_frac": 0.009798021977709362, "timer/env.step_avg": 0.001950246987828783, "timer/env.step_min": 0.0010509490966796875, "timer/env.step_max": 0.008283853530883789, "timer/replay._sample_count": 20096.0, "timer/replay._sample_total": 1336.182272195816, "timer/replay._sample_frac": 2.6723593924765474, "timer/replay._sample_avg": 0.06648996179318352, "timer/replay._sample_min": 0.0003402233123779297, "timer/replay._sample_max": 0.09102416038513184, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3090.0, "timer/agent.policy_total": 19.91606593132019, "timer/agent.policy_frac": 0.03983205507230823, "timer/agent.policy_avg": 0.006445328780362521, "timer/agent.policy_min": 0.0051708221435546875, "timer/agent.policy_max": 0.009687185287475586, "timer/dataset_train_count": 1256.0, "timer/dataset_train_total": 0.09570693969726562, "timer/dataset_train_frac": 0.00019141351037749174, "timer/dataset_train_avg": 7.619979275260002e-05, "timer/dataset_train_min": 6.270408630371094e-05, "timer/dataset_train_max": 0.00015926361083984375, "timer/agent.train_count": 1256.0, "timer/agent.train_total": 468.98507857322693, "timer/agent.train_frac": 0.937968348881705, "timer/agent.train_avg": 0.37339576319524437, "timer/agent.train_min": 0.35161828994750977, "timer/agent.train_max": 0.4187660217285156, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4037477970123291, "timer/agent.report_frac": 0.0008074940372951542, "timer/agent.report_avg": 0.20187389850616455, "timer/agent.report_min": 0.19419384002685547, "timer/agent.report_max": 0.20955395698547363, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 6.389605601703907e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 40.191301254823806}
{"step": 262544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 262768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 264064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 264168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 264240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 264488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 264624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 264656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 264856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 265080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 266376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 266480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 266552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 266800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 266936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 266968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 267168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 267392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 268520, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609}
{"step": 268688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 268792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 268864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 269112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 269248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 269280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 269704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270368, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 270832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 271000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 271104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 271176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 271424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 271560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 271592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 272680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 273144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 273312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 273416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 273488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 273736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 273872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 273904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 274272, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 274992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 275456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 275624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 275728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 275800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 276048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 276216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 276584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 277304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 277768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 277936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 278040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 278112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 278360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 278528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 278632, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625}
{"step": 279176, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 279616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 280248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 280352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 280424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 280672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 280840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 281488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 281928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 282392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 282560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 282601, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0069822281125993, "train/action_min": 0.0, "train/action_std": 1.99847064794056, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 3.732307008220463e-05, "train/actor_opt_grad_steps": 16935.0, "train/actor_opt_loss": -4.921438175061392, "train/adv_mag": 0.00029281878636942967, "train/adv_max": 0.0002572954824519536, "train/adv_mean": 4.0365857097232574e-05, "train/adv_min": -0.00019374078819676052, "train/adv_std": 7.116387008402002e-05, "train/cont_avg": 0.9965587797619048, "train/cont_loss_mean": 0.02297637012550637, "train/cont_loss_std": 0.32101338497358706, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.673190970574656, "train/cont_pos_acc": 0.9999999862814707, "train/cont_pos_loss": 0.0034612860874317234, "train/cont_pred": 0.9965447930116502, "train/cont_rate": 0.9965587797619048, "train/dyn_loss_mean": 1.0000000037844219, "train/dyn_loss_std": 1.0165846712576847e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.004158038471937217, "train/extr_critic_critic_opt_grad_steps": 16935.0, "train/extr_critic_critic_opt_loss": 6983.258448040675, "train/extr_critic_mag": 0.018473809673672632, "train/extr_critic_max": 0.018473809673672632, "train/extr_critic_mean": 0.0183495907556443, "train/extr_critic_min": 0.018250139932783824, "train/extr_critic_std": 4.314649445332757e-05, "train/extr_return_normed_mag": 0.00033123468950627344, "train/extr_return_normed_max": 0.0003076874104047578, "train/extr_return_normed_mean": 0.0001690403721155354, "train/extr_return_normed_min": 2.2523415585358936e-05, "train/extr_return_normed_std": 5.450944351492032e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.018528602706889313, "train/extr_return_raw_max": 0.018528602706889313, "train/extr_return_raw_mean": 0.0183899567743379, "train/extr_return_raw_min": 0.018243438712069914, "train/extr_return_raw_std": 5.4509443572666014e-05, "train/extr_reward_mag": 6.490378152756464e-05, "train/extr_reward_max": 6.490378152756464e-05, "train/extr_reward_mean": 6.146272723512199e-05, "train/extr_reward_min": 5.7215728457011875e-05, "train/extr_reward_std": 9.494972783750922e-07, "train/image_loss_mean": 0.24139113475879034, "train/image_loss_std": 0.08474268365119185, "train/model_loss_mean": 0.8666878744723305, "train/model_loss_std": 0.3819892940421899, "train/model_opt_grad_norm": 35.14419308162871, "train/model_opt_grad_steps": 16917.0, "train/model_opt_loss": 897.8880271306114, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1036.7063492063492, "train/policy_entropy_mag": 1.945875310708606, "train/policy_entropy_max": 1.945875310708606, "train/policy_entropy_mean": 1.9440986665468367, "train/policy_entropy_min": 1.8756559651995461, "train/policy_entropy_std": 0.001959992931150491, "train/policy_logprob_mag": 2.440037078327603, "train/policy_logprob_max": -1.4549551388574025, "train/policy_logprob_mean": -1.9440657846511356, "train/policy_logprob_min": -2.440037078327603, "train/policy_logprob_std": 0.06013746521184369, "train/policy_randomness_mag": 0.9999821550316281, "train/policy_randomness_max": 0.9999821550316281, "train/policy_randomness_mean": 0.9990691381787496, "train/policy_randomness_min": 0.9638965460989211, "train/policy_randomness_std": 0.0010072371699765975, "train/post_ent_mag": 102.30969698466951, "train/post_ent_max": 102.30969698466951, "train/post_ent_mean": 102.21922217475043, "train/post_ent_min": 101.6695063757518, "train/post_ent_std": 0.1096527422113078, "train/prior_ent_mag": 101.42636792621916, "train/prior_ent_max": 101.42636792621916, "train/prior_ent_mean": 101.22731968713185, "train/prior_ent_min": 99.71439985244993, "train/prior_ent_std": 0.2740273729912818, "train/rep_loss_mean": 1.0000000037844219, "train/rep_loss_std": 1.0165846712576847e-07, "train/reward_avg": 9.973919487305148e-05, "train/reward_loss_mean": 0.002320345620521241, "train/reward_loss_std": 0.06455269593470081, "train/reward_max_data": 0.09151785661067281, "train/reward_max_pred": 6.462184209672231e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00016205401432613605, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.906041088104248, "train/reward_pred": 6.129564107617452e-05, "train/reward_rate": 0.00021701388888888888, "train_stats/mean_log_entropy": 1.9361257939271523, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.031207788735628128, "report/cont_loss_std": 0.3989053964614868, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.725922584533691, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032651235815137625, "report/cont_pred": 0.9967401027679443, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2380601167678833, "report/image_loss_std": 0.09443692117929459, "report/model_loss_mean": 0.8694683313369751, "report/model_loss_std": 0.4074813425540924, "report/post_ent_mag": 103.11233520507812, "report/post_ent_max": 103.11233520507812, "report/post_ent_mean": 103.04533386230469, "report/post_ent_min": 102.68487548828125, "report/post_ent_std": 0.07467307150363922, "report/prior_ent_mag": 102.9258041381836, "report/prior_ent_max": 102.9258041381836, "report/prior_ent_mean": 102.73218536376953, "report/prior_ent_min": 101.85366821289062, "report/prior_ent_std": 0.17658387124538422, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00020040571689605713, "report/reward_loss_std": 5.235357093624771e-06, "report/reward_max_data": 0.0, "report/reward_max_pred": 8.702278137207031e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00020040571689605713, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.896637544035912e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.025619246065616608, "eval/cont_loss_std": 0.3569668233394623, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.725922107696533, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0032651114743202925, "eval/cont_pred": 0.9967401027679443, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24469201266765594, "eval/image_loss_std": 0.08715604245662689, "eval/model_loss_mean": 0.8705118298530579, "eval/model_loss_std": 0.3661622405052185, "eval/post_ent_mag": 103.1144790649414, "eval/post_ent_max": 103.1144790649414, "eval/post_ent_mean": 103.04287719726562, "eval/post_ent_min": 102.68545532226562, "eval/post_ent_std": 0.07323107868432999, "eval/prior_ent_mag": 102.95336151123047, "eval/prior_ent_max": 102.95336151123047, "eval/prior_ent_mean": 102.73993682861328, "eval/prior_ent_min": 101.85366821289062, "eval/prior_ent_std": 0.17350740730762482, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00020055007189512253, "eval/reward_loss_std": 5.353620053938357e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 8.606910705566406e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00020055007189512253, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.902283687144518e-05, "eval/reward_rate": 0.0, "replay/size": 282097.0, "replay/inserts": 20128.0, "replay/samples": 20128.0, "replay/insert_wait_avg": 1.2042222985781623e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.13888694144584e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68104.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.184100923241216e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.6093254089355469e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2301597595215, "timer/env.step_count": 2516.0, "timer/env.step_total": 4.92236852645874, "timer/env.step_frac": 0.009840207413373674, "timer/env.step_avg": 0.001956426282376288, "timer/env.step_min": 0.001074075698852539, "timer/env.step_max": 0.008207559585571289, "timer/replay._sample_count": 20128.0, "timer/replay._sample_total": 1338.029905796051, "timer/replay._sample_frac": 2.6748285358069768, "timer/replay._sample_avg": 0.0664760485788976, "timer/replay._sample_min": 0.0003299713134765625, "timer/replay._sample_max": 0.08865499496459961, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3094.0, "timer/agent.policy_total": 19.94730257987976, "timer/agent.policy_frac": 0.03987624934384033, "timer/agent.policy_avg": 0.006447091977983116, "timer/agent.policy_min": 0.005047798156738281, "timer/agent.policy_max": 0.009130716323852539, "timer/dataset_train_count": 1258.0, "timer/dataset_train_total": 0.09592843055725098, "timer/dataset_train_frac": 0.0001917685862910929, "timer/dataset_train_avg": 7.625471427444434e-05, "timer/dataset_train_min": 5.14984130859375e-05, "timer/dataset_train_max": 0.00023221969604492188, "timer/agent.train_count": 1258.0, "timer/agent.train_total": 469.16466426849365, "timer/agent.train_frac": 0.9378975959667003, "timer/agent.train_avg": 0.37294488415619526, "timer/agent.train_min": 0.3525710105895996, "timer/agent.train_max": 0.418658971786499, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4179837703704834, "timer/agent.report_frac": 0.0008355829056197314, "timer/agent.report_avg": 0.2089918851852417, "timer/agent.report_min": 0.20850467681884766, "timer/agent.report_max": 0.20947909355163574, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 6.624986888245375e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 40.23683955818299}
{"step": 282664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 282736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 282984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 283152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 283800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 284240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 284704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 284872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 284976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 285048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 285296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 285464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 286112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 286552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 287016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 287184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 287288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 287360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 287608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 287776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 288424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 288864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 289328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 289496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 289600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 289672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 289920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 290056, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 290736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 291176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 291640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 291808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 291912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 291984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 292232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 292400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 293048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 293488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 293952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 294120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 294224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 294296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 294544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 294712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 295360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 295800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 296264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 296432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 296536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 296608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 296856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 297024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 297672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 298112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 298576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 298744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 298848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 298920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 299168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 299336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 299984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300384, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333}
{"step": 300424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 300888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 301056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 301152, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 301232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 301480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 301648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 302296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 302489, "train_stats/mean_log_entropy": 1.5088466116360255, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.252440421811996, "train/action_min": 0.0, "train/action_std": 1.7582877691714995, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0011394977542999363, "train/actor_opt_grad_steps": 18185.0, "train/actor_opt_loss": 6.901456223004648, "train/adv_mag": 0.00545898727291534, "train/adv_max": 0.005405449338497654, "train/adv_mean": 0.0011841727783620068, "train/adv_min": -0.0006373698462642008, "train/adv_std": 0.0008751528454130523, "train/cont_avg": 0.9961803805443549, "train/cont_loss_mean": 0.025096695883304723, "train/cont_loss_std": 0.33658729481788713, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.626636528387302, "train/cont_pos_acc": 0.9999999846181562, "train/cont_pos_loss": 0.0036277294650884167, "train/cont_pred": 0.9963789394786281, "train/cont_rate": 0.9961803805443549, "train/dyn_loss_mean": 1.000047234758254, "train/dyn_loss_std": 0.0009563330118438781, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.24597538704655297, "train/extr_critic_critic_opt_grad_steps": 18185.0, "train/extr_critic_critic_opt_loss": 8400.211827431956, "train/extr_critic_mag": 0.026114031191795103, "train/extr_critic_max": 0.026114031191795103, "train/extr_critic_mean": 0.02535914903086039, "train/extr_critic_min": 0.024846467279618787, "train/extr_critic_std": 0.00015669707004088842, "train/extr_return_normed_mag": 0.007396109372137054, "train/extr_return_normed_max": 0.007220746814123084, "train/extr_return_normed_mean": 0.002795012512258895, "train/extr_return_normed_min": 0.0010945973917841911, "train/extr_return_normed_std": 0.0009051674693299931, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.030969054888813727, "train/extr_return_raw_max": 0.030969054888813727, "train/extr_return_raw_mean": 0.026543321523575053, "train/extr_return_raw_min": 0.02484290542141084, "train/extr_return_raw_std": 0.0009051674715303834, "train/extr_reward_mag": 0.0009516852517281809, "train/extr_reward_max": 0.0009516852517281809, "train/extr_reward_mean": 0.0002207738267726757, "train/extr_reward_min": 3.754900347801947e-05, "train/extr_reward_std": 0.0001903601714830881, "train/image_loss_mean": 0.21470455669106975, "train/image_loss_std": 0.09396990364597689, "train/model_loss_mean": 0.8423431645477971, "train/model_loss_std": 0.4055095906219175, "train/model_opt_grad_norm": 32.54843354994251, "train/model_opt_grad_steps": 18167.0, "train/model_opt_loss": 2072.549353814894, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2469.7580645161293, "train/policy_entropy_mag": 1.598031596310677, "train/policy_entropy_max": 1.598031596310677, "train/policy_entropy_mean": 1.480844366454309, "train/policy_entropy_min": 1.2488723601545058, "train/policy_entropy_std": 0.06447315706792588, "train/policy_logprob_mag": 4.140104013104593, "train/policy_logprob_max": -0.9096942939945767, "train/policy_logprob_mean": -1.4814796089645355, "train/policy_logprob_min": -4.140104013104593, "train/policy_logprob_std": 0.4057599096709201, "train/policy_randomness_mag": 0.8212258385554436, "train/policy_randomness_max": 0.8212258385554436, "train/policy_randomness_mean": 0.7610035089235152, "train/policy_randomness_min": 0.6417934745850582, "train/policy_randomness_std": 0.03313265082702386, "train/post_ent_mag": 92.66527065154045, "train/post_ent_max": 92.66527065154045, "train/post_ent_mean": 92.20739247722011, "train/post_ent_min": 91.6818527098625, "train/post_ent_std": 0.2034279743600036, "train/prior_ent_mag": 93.88869543998472, "train/prior_ent_max": 93.88869543998472, "train/prior_ent_mean": 92.03925501915717, "train/prior_ent_min": 90.39027915462371, "train/prior_ent_std": 0.5243379732053126, "train/rep_loss_mean": 1.000047234758254, "train/rep_loss_std": 0.0009563330118438781, "train/reward_avg": 0.00013518794836390072, "train/reward_loss_mean": 0.002513548689744165, "train/reward_loss_std": 0.07504241748430404, "train/reward_max_data": 0.13843245912463434, "train/reward_max_pred": 0.0006705378332445698, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00017110584107168477, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.29499526321888, "train/reward_pred": 6.304502359501296e-05, "train/reward_rate": 0.00025201612903225806, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020031915977597237, "report/cont_loss_std": 0.3151339888572693, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.833661079406738, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002949752612039447, "report/cont_pred": 0.9970546364784241, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.17588859796524048, "report/image_loss_std": 0.10137508064508438, "report/model_loss_mean": 0.7960612177848816, "report/model_loss_std": 0.3249777853488922, "report/post_ent_mag": 79.08613586425781, "report/post_ent_max": 79.08613586425781, "report/post_ent_mean": 77.91756439208984, "report/post_ent_min": 76.84632873535156, "report/post_ent_std": 0.5008603930473328, "report/prior_ent_mag": 81.24688720703125, "report/prior_ent_max": 81.24688720703125, "report/prior_ent_mean": 77.50507354736328, "report/prior_ent_min": 74.59417724609375, "report/prior_ent_std": 1.0260446071624756, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00014071259647607803, "report/reward_loss_std": 0.00036389962770044804, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.001343369483947754, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00014071259647607803, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.016949191689491e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008705859072506428, "eval/cont_loss_std": 0.18289019167423248, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.858328819274902, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0029877531342208385, "eval/cont_pred": 0.9970168471336365, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0000139474868774, "eval/dyn_loss_std": 0.0004459973133634776, "eval/image_loss_mean": 0.15670695900917053, "eval/image_loss_std": 0.10140279680490494, "eval/model_loss_mean": 0.7655726671218872, "eval/model_loss_std": 0.2100410759449005, "eval/post_ent_mag": 79.1245346069336, "eval/post_ent_max": 79.1245346069336, "eval/post_ent_mean": 78.09046173095703, "eval/post_ent_min": 76.922607421875, "eval/post_ent_std": 0.5124744772911072, "eval/prior_ent_mag": 81.9885025024414, "eval/prior_ent_max": 81.9885025024414, "eval/prior_ent_mean": 77.54470825195312, "eval/prior_ent_min": 74.0807876586914, "eval/prior_ent_std": 1.197234034538269, "eval/rep_loss_mean": 1.0000139474868774, "eval/rep_loss_std": 0.0004459973133634776, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00015150569379329681, "eval/reward_loss_std": 0.00036563779576681554, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001408696174621582, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00015150569379329681, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.475788541138172e-05, "eval/reward_rate": 0.0, "replay/size": 301985.0, "replay/inserts": 19888.0, "replay/samples": 19888.0, "replay/insert_wait_avg": 1.2261869441283296e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.274387683392722e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 72728.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.207612790038429e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.04663252830505, "timer/env.step_count": 2486.0, "timer/env.step_total": 4.955103874206543, "timer/env.step_frac": 0.009909283558521035, "timer/env.step_avg": 0.001993203489222262, "timer/env.step_min": 0.0010859966278076172, "timer/env.step_max": 0.008089780807495117, "timer/replay._sample_count": 19888.0, "timer/replay._sample_total": 1341.5789647102356, "timer/replay._sample_frac": 2.682907707881216, "timer/replay._sample_avg": 0.06745670578792415, "timer/replay._sample_min": 0.00032210350036621094, "timer/replay._sample_max": 0.09949779510498047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3064.0, "timer/agent.policy_total": 19.944822788238525, "timer/agent.policy_frac": 0.03988592561336678, "timer/agent.policy_avg": 0.006509406915221451, "timer/agent.policy_min": 0.005045652389526367, "timer/agent.policy_max": 0.009377002716064453, "timer/dataset_train_count": 1243.0, "timer/dataset_train_total": 0.09463953971862793, "timer/dataset_train_frac": 0.00018926142795946312, "timer/dataset_train_avg": 7.613800460066608e-05, "timer/dataset_train_min": 6.556510925292969e-05, "timer/dataset_train_max": 0.0001475811004638672, "timer/agent.train_count": 1243.0, "timer/agent.train_total": 468.72055101394653, "timer/agent.train_frac": 0.9373536796838936, "timer/agent.train_avg": 0.37708813436359334, "timer/agent.train_min": 0.3513612747192383, "timer/agent.train_max": 1.1235592365264893, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.42102932929992676, "timer/agent.report_frac": 0.0008419801312752455, "timer/agent.report_avg": 0.21051466464996338, "timer/agent.report_min": 0.20933794975280762, "timer/agent.report_max": 0.21169137954711914, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 6.722776930493062e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 39.7716356211565}
{"step": 302696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 303200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 303368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 303464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 303544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 303792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 303960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 304608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 305008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 305512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 305680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 305776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 305856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 306104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 306272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 306616, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453}
{"step": 306920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 307824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 307992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 308088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 308168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 308416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 308584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 308928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 309232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 310272, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 310304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 310400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 310480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 310728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 310896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 311240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 311912, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045}
{"step": 312584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 312616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 312712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 312792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 313040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 313208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 313512, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 313552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 314144, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838}
{"step": 314224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 314680, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322}
{"step": 314896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 314960, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384}
{"step": 315024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 315200, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112}
{"step": 315864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 316456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 316536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 316992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 317040, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464}
{"step": 317208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 317336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 317512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 318176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 318768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 318848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 319304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 319352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 319520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 319648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 319824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 321080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 321160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 321616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 321664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 321832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 321960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 322136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 322633, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8635321723090277, "train/action_min": 0.0, "train/action_std": 1.447051772049495, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0022803971584099123, "train/actor_opt_grad_steps": 19435.0, "train/actor_opt_loss": 8.780697653750105, "train/adv_mag": 0.022666177934124357, "train/adv_max": 0.02221227546651212, "train/adv_mean": 0.0020745407629499187, "train/adv_min": -0.002915433149725672, "train/adv_std": 0.0029418287569627404, "train/cont_avg": 0.9963262648809523, "train/cont_loss_mean": 0.02422957834861581, "train/cont_loss_std": 0.33204802137518685, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.637023195387825, "train/cont_pos_acc": 0.9999999834431542, "train/cont_pos_loss": 0.003523660241626203, "train/cont_pred": 0.9964823107870798, "train/cont_rate": 0.9963262648809523, "train/dyn_loss_mean": 1.000034268886324, "train/dyn_loss_std": 0.0009206433303714019, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2569874424398655, "train/extr_critic_critic_opt_grad_steps": 19435.0, "train/extr_critic_critic_opt_loss": 13003.668891059027, "train/extr_critic_mag": 0.07013149299318829, "train/extr_critic_max": 0.07013149299318829, "train/extr_critic_mean": 0.06791700203976934, "train/extr_critic_min": 0.06579363062268212, "train/extr_critic_std": 0.0006449016239327778, "train/extr_return_normed_mag": 0.027939583485325176, "train/extr_return_normed_max": 0.027939583485325176, "train/extr_return_normed_mean": 0.006927054598770429, "train/extr_return_normed_min": 0.0022917366808369046, "train/extr_return_normed_std": 0.0031109692377319174, "train/extr_return_rate": 1.5500993449388752e-06, "train/extr_return_raw_mag": 0.09100406862322301, "train/extr_return_raw_max": 0.09100406862322301, "train/extr_return_raw_mean": 0.06999154270641388, "train/extr_return_raw_min": 0.06535622193699792, "train/extr_return_raw_std": 0.0031109692178673985, "train/extr_reward_mag": 0.01063763906085302, "train/extr_reward_max": 0.01063763906085302, "train/extr_reward_mean": 0.0004006877904560367, "train/extr_reward_min": 5.6397347223191035e-06, "train/extr_reward_std": 0.001025415634464321, "train/image_loss_mean": 0.1822954003536512, "train/image_loss_std": 0.1020453687579859, "train/model_loss_mean": 0.8078690157050178, "train/model_loss_std": 0.37397086431109716, "train/model_opt_grad_norm": 32.56127781338162, "train/model_opt_grad_steps": 19416.333333333332, "train/model_opt_loss": 2695.1959402901784, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3333.3333333333335, "train/policy_entropy_mag": 1.5816301542615134, "train/policy_entropy_max": 1.5816301542615134, "train/policy_entropy_mean": 1.0257559780563628, "train/policy_entropy_min": 0.23236256140092063, "train/policy_entropy_std": 0.27239639601773685, "train/policy_logprob_mag": 6.160194518074157, "train/policy_logprob_max": -0.047949504173759906, "train/policy_logprob_mean": -1.0265755263112841, "train/policy_logprob_min": -6.160194518074157, "train/policy_logprob_std": 0.9191799873397464, "train/policy_randomness_mag": 0.8127971651062132, "train/policy_randomness_max": 0.8127971651062132, "train/policy_randomness_mean": 0.5271343319188981, "train/policy_randomness_min": 0.11941074192642219, "train/policy_randomness_std": 0.1399840647798209, "train/post_ent_mag": 78.03138157678029, "train/post_ent_max": 78.03138157678029, "train/post_ent_mean": 76.9362197754875, "train/post_ent_min": 75.8767940581791, "train/post_ent_std": 0.4793051845497555, "train/prior_ent_mag": 79.57286871047248, "train/prior_ent_max": 79.57286871047248, "train/prior_ent_mean": 75.99763361612956, "train/prior_ent_min": 73.06829906645275, "train/prior_ent_std": 0.9593071152293493, "train/rep_loss_mean": 1.000034268886324, "train/rep_loss_std": 0.0009206433303714019, "train/reward_avg": 6.575811500032802e-05, "train/reward_loss_mean": 0.0013234522341499253, "train/reward_loss_std": 0.03768448713994336, "train/reward_max_data": 0.06733630976033589, "train/reward_max_pred": 0.0014747646119859484, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00015760338857713607, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.84851469713099, "train/reward_pred": 5.796423555159616e-05, "train/reward_rate": 0.00013175843253968253, "train_stats/mean_log_entropy": 1.0350669553018597, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.019552405923604965, "report/cont_loss_std": 0.2890532314777374, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.347341060638428, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003897787304595113, "report/cont_pred": 0.9961072206497192, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1968870609998703, "report/image_loss_std": 0.10936218500137329, "report/model_loss_mean": 0.8164936304092407, "report/model_loss_std": 0.310886412858963, "report/post_ent_mag": 78.54242706298828, "report/post_ent_max": 78.54242706298828, "report/post_ent_mean": 77.53042602539062, "report/post_ent_min": 76.6480484008789, "report/post_ent_std": 0.4365512430667877, "report/prior_ent_mag": 78.55519104003906, "report/prior_ent_max": 78.55519104003906, "report/prior_ent_mean": 75.72758483886719, "report/prior_ent_min": 73.53021240234375, "report/prior_ent_std": 0.8095086812973022, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.411636084318161e-05, "report/reward_loss_std": 0.00022569413704331964, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0010175704956054688, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.411636084318161e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 1.6623642295598984e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014826998114585876, "eval/cont_loss_std": 0.24577733874320984, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.570232391357422, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003955361898988485, "eval/cont_pred": 0.9960530400276184, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16084560751914978, "eval/image_loss_std": 0.08465030044317245, "eval/model_loss_mean": 0.7757160067558289, "eval/model_loss_std": 0.25938454270362854, "eval/post_ent_mag": 78.43486022949219, "eval/post_ent_max": 78.43486022949219, "eval/post_ent_mean": 77.60308837890625, "eval/post_ent_min": 76.6539306640625, "eval/post_ent_std": 0.4146535396575928, "eval/prior_ent_mag": 78.0628662109375, "eval/prior_ent_max": 78.0628662109375, "eval/prior_ent_mean": 75.64566040039062, "eval/prior_ent_min": 73.20037841796875, "eval/prior_ent_std": 0.8068087697029114, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 4.338473081588745e-05, "eval/reward_loss_std": 0.00020116042287554592, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0010832548141479492, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 4.338473081588745e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 1.3367854990065098e-05, "eval/reward_rate": 0.0, "replay/size": 322129.0, "replay/inserts": 20144.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.2040469644560143e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.218010274449258e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 77352.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2067362511446731e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.3634400367737, "timer/env.step_count": 2518.0, "timer/env.step_total": 4.967849969863892, "timer/env.step_frac": 0.009928483123184988, "timer/env.step_avg": 0.0019729348569753344, "timer/env.step_min": 0.0010251998901367188, "timer/env.step_max": 0.00806570053100586, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 1341.0748162269592, "timer/replay._sample_frac": 2.68020144742869, "timer/replay._sample_avg": 0.06657440509466636, "timer/replay._sample_min": 0.0002970695495605469, "timer/replay._sample_max": 0.0920097827911377, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3096.0, "timer/agent.policy_total": 19.928882360458374, "timer/agent.policy_frac": 0.03982881394970368, "timer/agent.policy_avg": 0.006436977506608002, "timer/agent.policy_min": 0.0050792694091796875, "timer/agent.policy_max": 0.010325193405151367, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.09648728370666504, "timer/dataset_train_frac": 0.0001928343999305261, "timer/dataset_train_avg": 7.663803312681894e-05, "timer/dataset_train_min": 5.793571472167969e-05, "timer/dataset_train_max": 0.0001544952392578125, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 469.1892068386078, "timer/agent.train_frac": 0.9376968205433339, "timer/agent.train_avg": 0.37266815475663845, "timer/agent.train_min": 0.34946274757385254, "timer/agent.train_max": 0.41856956481933594, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4203948974609375, "timer/agent.report_frac": 0.0008401790854864236, "timer/agent.report_avg": 0.21019744873046875, "timer/agent.report_min": 0.20976018905639648, "timer/agent.report_max": 0.21063470840454102, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 6.623222210775749e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 40.25809961431677}
{"step": 322800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 323392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 323472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 323928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 323976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 324144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 324216, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333}
{"step": 324272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 324448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 325112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 325136, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 325704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 325784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 326240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 326328, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052}
{"step": 326528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 326584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 326760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 327056, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 327448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 327480, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 328016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 328096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 328432, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907}
{"step": 328552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 328640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 329368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 329544, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 329760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 329792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 330096, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 330096, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 330096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 330408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 330864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 330952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 331376, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506}
{"step": 331680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 331856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 332104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 332640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 332720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 333176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 333264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 333688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 333992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 334168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 334416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 334952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 335032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 335216, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705}
{"step": 335488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 336000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 336304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 336480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 336728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 337128, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771}
{"step": 337264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 337528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 337560, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 337800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 337880, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695}
{"step": 338032, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748}
{"step": 338416, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 338792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 338904, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 339000, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556}
{"step": 339040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 339128, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 339576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 340024, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494}
{"step": 340080, "eval_episode/length": 17.0, "eval_episode/score": 0.9468749761581421, "eval_episode/reward_rate": 0.05555555555555555}
{"step": 340080, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 340080, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 340080, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 340080, "eval_episode/length": 248.0, "eval_episode/score": 0.22499999403953552, "eval_episode/reward_rate": 0.004016064257028112}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 340160, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705}
{"step": 340192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 340632, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629}
{"step": 341312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 341352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 341440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 341888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 342424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 342472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 342504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 342520, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315}
{"step": 342777, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8527124798487105, "train/action_min": 0.0, "train/action_std": 1.5668017925724151, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0021170745021663606, "train/actor_opt_grad_steps": 20695.0, "train/actor_opt_loss": 10.373781288308757, "train/adv_mag": 0.011189473881607964, "train/adv_max": 0.010917944390149344, "train/adv_mean": 0.0019055045800881103, "train/adv_min": -0.0029732632849897656, "train/adv_std": 0.0020719557748331376, "train/cont_avg": 0.9965432787698413, "train/cont_loss_mean": 0.022938193376397804, "train/cont_loss_std": 0.3219473432261674, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6356845703125, "train/cont_pos_acc": 0.9999999839162069, "train/cont_pos_loss": 0.003488124699317037, "train/cont_pred": 0.9965175125333998, "train/cont_rate": 0.9965432787698413, "train/dyn_loss_mean": 1.0000025715146745, "train/dyn_loss_std": 8.226795762311667e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2778476811104661, "train/extr_critic_critic_opt_grad_steps": 20695.0, "train/extr_critic_critic_opt_loss": 12218.211255270337, "train/extr_critic_mag": 0.10924935624712989, "train/extr_critic_max": 0.10924935624712989, "train/extr_critic_mean": 0.10804742420949633, "train/extr_critic_min": 0.10536451472176446, "train/extr_critic_std": 0.0004964254176085223, "train/extr_return_normed_mag": 0.016657883153548315, "train/extr_return_normed_max": 0.016576782519382143, "train/extr_return_normed_mean": 0.007014399978014274, "train/extr_return_normed_min": 0.00191387055175645, "train/extr_return_normed_std": 0.002266130768620069, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.11951530701111233, "train/extr_return_raw_max": 0.11951530701111233, "train/extr_return_raw_mean": 0.10995292864621632, "train/extr_return_raw_min": 0.10485239504348665, "train/extr_return_raw_std": 0.0022661307820170703, "train/extr_reward_mag": 0.004159235765063573, "train/extr_reward_max": 0.004159235765063573, "train/extr_reward_mean": 0.0005351910278824064, "train/extr_reward_min": 2.757897452702598e-06, "train/extr_reward_std": 0.0009802339905397117, "train/image_loss_mean": 0.17370365051523087, "train/image_loss_std": 0.10281551611565408, "train/model_loss_mean": 0.7984439673877898, "train/model_loss_std": 0.3749159983699284, "train/model_opt_grad_norm": 30.037261826651438, "train/model_opt_grad_steps": 20675.25396825397, "train/model_opt_loss": 2250.0585821242557, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2817.4603174603176, "train/policy_entropy_mag": 1.678719071168748, "train/policy_entropy_max": 1.678719071168748, "train/policy_entropy_mean": 1.051156759262085, "train/policy_entropy_min": 0.16527810562697667, "train/policy_entropy_std": 0.30524154622403404, "train/policy_logprob_mag": 6.230506662338499, "train/policy_logprob_max": -0.029353665890142558, "train/policy_logprob_mean": -1.0518173319952828, "train/policy_logprob_min": -6.230506662338499, "train/policy_logprob_std": 0.9439977322305951, "train/policy_randomness_mag": 0.8626910008135296, "train/policy_randomness_max": 0.8626910008135296, "train/policy_randomness_mean": 0.5401877514899723, "train/policy_randomness_min": 0.0849361489157355, "train/policy_randomness_std": 0.1568631347682741, "train/post_ent_mag": 78.76914227198041, "train/post_ent_max": 78.76914227198041, "train/post_ent_mean": 77.78997657412575, "train/post_ent_min": 76.84168509831504, "train/post_ent_std": 0.4193157125560064, "train/prior_ent_mag": 79.79221216837566, "train/prior_ent_max": 79.79221216837566, "train/prior_ent_mean": 76.84842863537017, "train/prior_ent_min": 74.14767667982314, "train/prior_ent_std": 0.8275920133742075, "train/rep_loss_mean": 1.0000025715146745, "train/rep_loss_std": 8.226795762311667e-05, "train/reward_avg": 9.627569306758232e-05, "train/reward_loss_mean": 0.0018005523911958177, "train/reward_loss_std": 0.050915101935855106, "train/reward_max_data": 0.09747023827263288, "train/reward_max_pred": 0.0030384971981956845, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00019059426342700757, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.988941326141357, "train/reward_pred": 7.308544387804373e-05, "train/reward_rate": 0.00020151289682539681, "train_stats/mean_log_entropy": 1.0883415871196322, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014436033554375172, "report/cont_loss_std": 0.2593812346458435, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.877804756164551, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029617317486554384, "report/cont_pred": 0.9970431327819824, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.17447376251220703, "report/image_loss_std": 0.09602797776460648, "report/model_loss_mean": 0.7891726493835449, "report/model_loss_std": 0.27415433526039124, "report/post_ent_mag": 78.74238586425781, "report/post_ent_max": 78.74238586425781, "report/post_ent_mean": 77.90690612792969, "report/post_ent_min": 77.00985717773438, "report/post_ent_std": 0.37571749091148376, "report/prior_ent_mag": 79.35757446289062, "report/prior_ent_max": 79.35757446289062, "report/prior_ent_mean": 76.35725402832031, "report/prior_ent_min": 73.65498352050781, "report/prior_ent_std": 0.8221048712730408, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0002628243528306484, "report/reward_loss_std": 0.0008680517203174531, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.004029273986816406, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002628243528306484, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 9.296613279730082e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020242758095264435, "eval/cont_loss_std": 0.3195001780986786, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.9141669273376465, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0029246648773550987, "eval/cont_pred": 0.9970804452896118, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19210615754127502, "eval/image_loss_std": 0.10434016585350037, "eval/model_loss_mean": 0.8125873804092407, "eval/model_loss_std": 0.3423297107219696, "eval/post_ent_mag": 78.75019836425781, "eval/post_ent_max": 78.75019836425781, "eval/post_ent_mean": 77.8809814453125, "eval/post_ent_min": 76.96151733398438, "eval/post_ent_std": 0.3624117076396942, "eval/prior_ent_mag": 78.90708923339844, "eval/prior_ent_max": 78.90708923339844, "eval/prior_ent_mean": 76.41111755371094, "eval/prior_ent_min": 73.83348846435547, "eval/prior_ent_std": 0.7807607650756836, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00023846374824643135, "eval/reward_loss_std": 0.0006901160231791437, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0029610395431518555, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00023846374824643135, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.410972077399492e-05, "eval/reward_rate": 0.0, "replay/size": 342273.0, "replay/inserts": 20144.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.1886131962298212e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.153742359212886e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 81976.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.178635445433092e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.556510925292969e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.19953513145447, "timer/env.step_count": 2518.0, "timer/env.step_total": 4.938318729400635, "timer/env.step_frac": 0.009872697558790862, "timer/env.step_avg": 0.001961206802780236, "timer/env.step_min": 0.001085519790649414, "timer/env.step_max": 0.00778961181640625, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 1341.427889585495, "timer/replay._sample_frac": 2.6817855583031727, "timer/replay._sample_avg": 0.06659193256480814, "timer/replay._sample_min": 0.0003447532653808594, "timer/replay._sample_max": 0.0908203125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3096.0, "timer/agent.policy_total": 19.973593950271606, "timer/agent.policy_frac": 0.039931252525099735, "timer/agent.policy_avg": 0.006451419234583852, "timer/agent.policy_min": 0.0051479339599609375, "timer/agent.policy_max": 0.011688232421875, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.09482741355895996, "timer/dataset_train_frac": 0.00018957917170802434, "timer/dataset_train_avg": 7.53196295146624e-05, "timer/dataset_train_min": 5.650520324707031e-05, "timer/dataset_train_max": 0.00016880035400390625, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 469.0217182636261, "timer/agent.train_frac": 0.9376692406168776, "timer/agent.train_avg": 0.3725351217344131, "timer/agent.train_min": 0.3525266647338867, "timer/agent.train_max": 0.42659425735473633, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.407193660736084, "timer/agent.report_frac": 0.0008140624533548833, "timer/agent.report_avg": 0.203596830368042, "timer/agent.report_min": 0.19668102264404297, "timer/agent.report_max": 0.21051263809204102, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 6.482398419121101e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 40.27142899919347}
{"step": 342944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 343616, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154}
{"step": 343624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 343648, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993}
{"step": 343752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 344176, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 344200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 344784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 344832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 344952, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 345256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 345400, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 345928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 345936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 346064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 346264, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 346512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 346592, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 347096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 347264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 347280, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609}
{"step": 347488, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301}
{"step": 347568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 348248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 348824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 348904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 348960, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 349408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 349576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 349592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 349800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 349880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 350040, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 350064, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 350064, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 350064, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350296, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 351136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 351216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 351720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 351768, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 351904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 352112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 352192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 352296, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004}
{"step": 352352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 352904, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 353432, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 353448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 353736, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776}
{"step": 353936, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 354032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 354080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 354328, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 354424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 354504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 354608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 354952, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 355120, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248}
{"step": 355512, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 355744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 356344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 356504, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 356552, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856}
{"step": 356640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 356736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 356872, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 357072, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 357264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 357352, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 357432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 357792, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444}
{"step": 357856, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 358656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 358672, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774}
{"step": 358816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 358984, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725}
{"step": 359016, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 359136, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625}
{"step": 359184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 359296, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 359488, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 359576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 359616, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 360048, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 360048, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 360048, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 360048, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 360048, "eval_episode/length": 202.0, "eval_episode/score": 0.3687500059604645, "eval_episode/reward_rate": 0.0049261083743842365}
{"step": 360048, "eval_episode/length": 210.0, "eval_episode/score": 0.34375, "eval_episode/reward_rate": 0.004739336492890996}
{"step": 360048, "eval_episode/length": 216.0, "eval_episode/score": 0.32499998807907104, "eval_episode/reward_rate": 0.004608294930875576}
{"step": 360048, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 360104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 360608, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704}
{"step": 360688, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609}
{"step": 360976, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222}
{"step": 361448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 361736, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725}
{"step": 361800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 361888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 361928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 362336, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629}
{"step": 363000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 363001, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7294109674889273, "train/action_min": 0.0, "train/action_std": 1.5705046362764254, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002032063735967986, "train/actor_opt_grad_steps": 21960.0, "train/actor_opt_loss": 12.793256963566533, "train/adv_mag": 0.013681874969812829, "train/adv_max": 0.01343458491986192, "train/adv_mean": 0.0025538309952665037, "train/adv_min": -0.004215419527113907, "train/adv_std": 0.0024254706960472124, "train/cont_avg": 0.9965166707677166, "train/cont_loss_mean": 0.023113336993425382, "train/cont_loss_std": 0.3157621215764015, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.61693540433558, "train/cont_pos_acc": 0.9999999859201627, "train/cont_pos_loss": 0.0035643227284730184, "train/cont_pred": 0.9964416942258519, "train/cont_rate": 0.9965166707677166, "train/dyn_loss_mean": 1.0000108940394845, "train/dyn_loss_std": 0.0003080084242406081, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3142481538371777, "train/extr_critic_critic_opt_grad_steps": 21960.0, "train/extr_critic_critic_opt_loss": 3944.782228965459, "train/extr_critic_mag": 0.16879903331516297, "train/extr_critic_max": 0.16879903331516297, "train/extr_critic_mean": 0.16669307238473666, "train/extr_critic_min": 0.16279660529039036, "train/extr_critic_std": 0.0009377968630947789, "train/extr_return_normed_mag": 0.01999402890993854, "train/extr_return_normed_max": 0.01999402890993854, "train/extr_return_normed_mean": 0.008048793362459538, "train/extr_return_normed_min": 0.000657891194651446, "train/extr_return_normed_std": 0.002777012656296156, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.18119213090637537, "train/extr_return_raw_max": 0.18119213090637537, "train/extr_return_raw_mean": 0.1692469034373291, "train/extr_return_raw_min": 0.1618559931910883, "train/extr_return_raw_std": 0.002777012658129468, "train/extr_reward_mag": 0.006157860042541984, "train/extr_reward_max": 0.006157860042541984, "train/extr_reward_mean": 0.0008186538451430057, "train/extr_reward_min": 1.6379544115441991e-06, "train/extr_reward_std": 0.0015744340890655514, "train/image_loss_mean": 0.1694933506916827, "train/image_loss_std": 0.10503250618619243, "train/model_loss_mean": 0.7944992747832471, "train/model_loss_std": 0.3708312749041347, "train/model_opt_grad_norm": 30.145215777900276, "train/model_opt_grad_steps": 21939.12598425197, "train/model_opt_loss": 2315.9422280619465, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2913.3858267716537, "train/policy_entropy_mag": 1.6988733697125291, "train/policy_entropy_max": 1.6988733697125291, "train/policy_entropy_mean": 0.8262835952240651, "train/policy_entropy_min": 0.07775814162464592, "train/policy_entropy_std": 0.3913077010413793, "train/policy_logprob_mag": 6.502904854421541, "train/policy_logprob_max": -0.010752138263714595, "train/policy_logprob_mean": -0.8260185713843098, "train/policy_logprob_min": -6.502904854421541, "train/policy_logprob_std": 0.9858116803206797, "train/policy_randomness_mag": 0.8730482590480113, "train/policy_randomness_max": 0.8730482590480113, "train/policy_randomness_mean": 0.4246257942492568, "train/policy_randomness_min": 0.03995978254384882, "train/policy_randomness_std": 0.2010923897422205, "train/post_ent_mag": 77.27715355580247, "train/post_ent_max": 77.27715355580247, "train/post_ent_mean": 76.49438380444144, "train/post_ent_min": 75.66909495676596, "train/post_ent_std": 0.3431912193617483, "train/prior_ent_mag": 78.40358043280173, "train/prior_ent_max": 78.40358043280173, "train/prior_ent_mean": 75.37195869505875, "train/prior_ent_min": 72.63054128331463, "train/prior_ent_std": 0.8756814711675869, "train/rep_loss_mean": 1.0000108940394845, "train/rep_loss_std": 0.0003080084242406081, "train/reward_avg": 0.00010714793776475465, "train/reward_loss_mean": 0.001886030519747828, "train/reward_loss_std": 0.04990791134739306, "train/reward_max_data": 0.10223917387367233, "train/reward_max_pred": 0.00464557568857989, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00024019468403957588, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.013096049979881, "train/reward_pred": 9.716526187193676e-05, "train/reward_rate": 0.00023068405511811023, "train_stats/mean_log_entropy": 0.863413146008616, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.019516021013259888, "report/cont_loss_std": 0.2997763752937317, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.533024787902832, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003315700450912118, "report/cont_pred": 0.9966871738433838, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1537368893623352, "report/image_loss_std": 0.10570365190505981, "report/model_loss_mean": 0.7733595967292786, "report/model_loss_std": 0.3178909718990326, "report/post_ent_mag": 73.01935577392578, "report/post_ent_max": 73.01935577392578, "report/post_ent_mean": 72.28872680664062, "report/post_ent_min": 71.44744110107422, "report/post_ent_std": 0.35775265097618103, "report/prior_ent_mag": 75.63885498046875, "report/prior_ent_max": 75.63885498046875, "report/prior_ent_mean": 72.74981689453125, "report/prior_ent_min": 69.69683074951172, "report/prior_ent_std": 0.9299246668815613, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00010665738955140114, "report/reward_loss_std": 0.0007154904888011515, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.004729747772216797, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00010665738955140114, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.811165854334831e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008774857968091965, "eval/cont_loss_std": 0.17862774431705475, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.7220282554626465, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0031900554895401, "eval/cont_pred": 0.9968151450157166, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23064446449279785, "eval/image_loss_std": 0.1146143227815628, "eval/model_loss_mean": 0.8394910097122192, "eval/model_loss_std": 0.20858436822891235, "eval/post_ent_mag": 73.00845336914062, "eval/post_ent_max": 73.00845336914062, "eval/post_ent_mean": 72.21165466308594, "eval/post_ent_min": 71.43867492675781, "eval/post_ent_std": 0.3442685306072235, "eval/prior_ent_mag": 75.87224578857422, "eval/prior_ent_max": 75.87224578857422, "eval/prior_ent_mean": 72.91355895996094, "eval/prior_ent_min": 70.53470611572266, "eval/prior_ent_std": 0.913230299949646, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 7.162243127822876e-05, "eval/reward_loss_std": 0.0005867993459105492, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0052689313888549805, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 7.162243127822876e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.2420502975583076e-05, "eval/reward_rate": 0.0, "replay/size": 362497.0, "replay/inserts": 20224.0, "replay/samples": 20224.0, "replay/insert_wait_avg": 1.21023600237279e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.076651143122323e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 86104.0, "eval_replay/inserts": 4128.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2341973393462425e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.37889647483826, "timer/env.step_count": 2528.0, "timer/env.step_total": 5.026179790496826, "timer/env.step_frac": 0.010044747741973505, "timer/env.step_avg": 0.00198820403105096, "timer/env.step_min": 0.001085042953491211, "timer/env.step_max": 0.00780034065246582, "timer/replay._sample_count": 20224.0, "timer/replay._sample_total": 1343.383572101593, "timer/replay._sample_frac": 2.684732672712039, "timer/replay._sample_avg": 0.06642521618382086, "timer/replay._sample_min": 0.00032019615173339844, "timer/replay._sample_max": 0.09382200241088867, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3044.0, "timer/agent.policy_total": 19.696202516555786, "timer/agent.policy_frac": 0.03936257635027223, "timer/agent.policy_avg": 0.006470500169696382, "timer/agent.policy_min": 0.004996061325073242, "timer/agent.policy_max": 0.009359598159790039, "timer/dataset_train_count": 1264.0, "timer/dataset_train_total": 0.09444952011108398, "timer/dataset_train_frac": 0.00018875600225445042, "timer/dataset_train_avg": 7.472272160687024e-05, "timer/dataset_train_min": 5.53131103515625e-05, "timer/dataset_train_max": 0.00016617774963378906, "timer/agent.train_count": 1264.0, "timer/agent.train_total": 469.52311754226685, "timer/agent.train_frac": 0.9383351713072835, "timer/agent.train_avg": 0.3714581626125529, "timer/agent.train_min": 0.35045409202575684, "timer/agent.train_max": 0.4260244369506836, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.40528392791748047, "timer/agent.report_frac": 0.0008099540783448295, "timer/agent.report_avg": 0.20264196395874023, "timer/agent.report_min": 0.19477558135986328, "timer/agent.report_max": 0.2105083465576172, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 6.67066523176147e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 40.41676421065513}
{"step": 363208, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545}
{"step": 363208, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036}
{"step": 363696, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 363712, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417}
{"step": 364112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 364200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 364240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 364648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 365520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 365520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 365680, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129}
{"step": 365808, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453}
{"step": 366024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 366152, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213}
{"step": 366400, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903}
{"step": 366424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 366552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 367024, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213}
{"step": 367176, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877}
{"step": 367328, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947}
{"step": 367840, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294}
{"step": 367968, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653}
{"step": 368120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 368336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 368488, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 368504, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705}
{"step": 368624, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667}
{"step": 368848, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571}
{"step": 369336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 369488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 369640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 370032, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 370032, "eval_episode/length": 211.0, "eval_episode/score": 0.34062498807907104, "eval_episode/reward_rate": 0.0047169811320754715}
{"step": 370032, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370096, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641}
{"step": 370152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 370432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 370480, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895}
{"step": 370800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 371064, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 371096, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 371648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 371800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 371952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 372240, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947}
{"step": 372368, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 372464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 372592, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625}
{"step": 373112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 373240, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625}
{"step": 373376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 373408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 374112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 374264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 374552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 374680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 374904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 375552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 375632, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 375688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 375720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 376424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 376576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 376864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 376992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 377184, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725}
{"step": 377552, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 377944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 377944, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 378000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 378032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 378232, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 378472, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 378744, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 378888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 379176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 379304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 379592, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 379824, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 380016, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 380312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 380344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 380408, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 380688, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 380784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 381056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 381072, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641}
{"step": 381464, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 381552, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 381568, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 381904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 382568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 382576, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 382624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 383000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 383081, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.61858837890625, "train/action_min": 0.0, "train/action_std": 1.524852523803711, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0019081337093375622, "train/actor_opt_grad_steps": 23220.0, "train/actor_opt_loss": 13.411780377298594, "train/adv_mag": 0.01392125403881073, "train/adv_max": 0.01370263147354126, "train/adv_mean": 0.0032337804376147685, "train/adv_min": -0.005208815336227417, "train/adv_std": 0.00245193487778306, "train/cont_avg": 0.996171875, "train/cont_loss_mean": 0.024749376017600296, "train/cont_loss_std": 0.3331854485878721, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.540227440095717, "train/cont_pos_acc": 0.9999999871253967, "train/cont_pos_loss": 0.0035855935383588074, "train/cont_pred": 0.9964186611175537, "train/cont_rate": 0.996171875, "train/dyn_loss_mean": 1.0000097465515136, "train/dyn_loss_std": 0.0002604553427663632, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.19861813825368882, "train/extr_critic_critic_opt_grad_steps": 23220.0, "train/extr_critic_critic_opt_loss": 11009.2765, "train/extr_critic_mag": 0.23011709403991698, "train/extr_critic_max": 0.23011709403991698, "train/extr_critic_mean": 0.22460087621212005, "train/extr_critic_min": 0.21615221691131592, "train/extr_critic_std": 0.002132958246394992, "train/extr_return_normed_mag": 0.02314600622653961, "train/extr_return_normed_max": 0.023134362816810607, "train/extr_return_normed_mean": 0.010915828756755218, "train/extr_return_normed_min": 0.0009383493661880493, "train/extr_return_normed_std": 0.003156378550454974, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.24005318057537078, "train/extr_return_raw_max": 0.24005318057537078, "train/extr_return_raw_mean": 0.2278346573114395, "train/extr_return_raw_min": 0.21785716712474823, "train/extr_return_raw_std": 0.003156378541141748, "train/extr_reward_mag": 0.0075869569778442385, "train/extr_reward_max": 0.0075869569778442385, "train/extr_reward_mean": 0.0011063198265619577, "train/extr_reward_min": 9.937286376953125e-07, "train/extr_reward_std": 0.0021777916662395, "train/image_loss_mean": 0.16137069308757782, "train/image_loss_std": 0.10643099534511566, "train/model_loss_mean": 0.7885090279579162, "train/model_loss_std": 0.39096584177017213, "train/model_opt_grad_norm": 29.02426395877715, "train/model_opt_grad_steps": 23198.216, "train/model_opt_loss": 2413.1407451171876, "train/model_opt_model_opt_grad_overflow": 0.008, "train/model_opt_model_opt_grad_scale": 3040.0, "train/policy_entropy_mag": 1.6465143671035767, "train/policy_entropy_max": 1.6465143671035767, "train/policy_entropy_mean": 0.5906429696083069, "train/policy_entropy_min": 0.06631304967403412, "train/policy_entropy_std": 0.3830416910648346, "train/policy_logprob_mag": 6.544402530670166, "train/policy_logprob_max": -0.008862264484167099, "train/policy_logprob_mean": -0.5913471894264222, "train/policy_logprob_min": -6.544402530670166, "train/policy_logprob_std": 0.9538667764663696, "train/policy_randomness_mag": 0.846141056060791, "train/policy_randomness_max": 0.846141056060791, "train/policy_randomness_mean": 0.30353045964241027, "train/policy_randomness_min": 0.03407816842198372, "train/policy_randomness_std": 0.19684450125694275, "train/post_ent_mag": 73.98992120361328, "train/post_ent_max": 73.98992120361328, "train/post_ent_mean": 73.2199697265625, "train/post_ent_min": 72.39330541992187, "train/post_ent_std": 0.3186384847164154, "train/prior_ent_mag": 75.42600274658203, "train/prior_ent_max": 75.42600274658203, "train/prior_ent_mean": 72.27350646972656, "train/prior_ent_min": 69.44740356445313, "train/prior_ent_std": 0.9331144313812256, "train/rep_loss_mean": 1.0000097465515136, "train/rep_loss_std": 0.0002604553427663632, "train/reward_avg": 0.00016572265536524356, "train/reward_loss_mean": 0.0023830860294401647, "train/reward_loss_std": 0.060116300149122254, "train/reward_max_data": 0.149324999332428, "train/reward_max_pred": 0.006577485084533692, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0003538711522705853, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.464787651510799, "train/reward_pred": 0.00014971147757023573, "train/reward_rate": 0.0003125, "train_stats/mean_log_entropy": 0.6054602151979571, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.034227531403303146, "report/cont_loss_std": 0.40122365951538086, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.223416805267334, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003642917377874255, "report/cont_pred": 0.9963479042053223, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.17340447008609772, "report/image_loss_std": 0.10786657780408859, "report/model_loss_mean": 0.8197702169418335, "report/model_loss_std": 0.607662558555603, "report/post_ent_mag": 70.97856903076172, "report/post_ent_max": 70.97856903076172, "report/post_ent_mean": 70.17276000976562, "report/post_ent_min": 69.37956237792969, "report/post_ent_std": 0.3209156394004822, "report/prior_ent_mag": 73.38687133789062, "report/prior_ent_max": 73.38687133789062, "report/prior_ent_mean": 70.47132110595703, "report/prior_ent_min": 67.73787689208984, "report/prior_ent_std": 1.1194376945495605, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0013153075706213713, "report/reward_loss_mean": 0.012138240039348602, "report/reward_loss_std": 0.2719882130622864, "report/reward_max_data": 0.8187500238418579, "report/reward_max_pred": 0.005627870559692383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001508415152784437, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.137699127197266, "report/reward_pred": 6.534927524626255e-05, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02559814602136612, "eval/cont_loss_std": 0.3504800498485565, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.608501434326172, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0037044084165245295, "eval/cont_pred": 0.9963028430938721, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19715702533721924, "eval/image_loss_std": 0.12188101559877396, "eval/model_loss_mean": 0.8229767680168152, "eval/model_loss_std": 0.3678504526615143, "eval/post_ent_mag": 70.94076538085938, "eval/post_ent_max": 70.94076538085938, "eval/post_ent_mean": 70.23443603515625, "eval/post_ent_min": 69.50914001464844, "eval/post_ent_std": 0.2933163642883301, "eval/prior_ent_mag": 74.32474517822266, "eval/prior_ent_max": 74.32474517822266, "eval/prior_ent_mean": 70.36376953125, "eval/prior_ent_min": 67.56010437011719, "eval/prior_ent_std": 1.0811830759048462, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00022155791521072388, "eval/reward_loss_std": 0.0012126527726650238, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0068323612213134766, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00022155791521072388, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.475850336253643e-05, "eval/reward_rate": 0.0, "replay/size": 382577.0, "replay/inserts": 20080.0, "replay/samples": 20080.0, "replay/insert_wait_avg": 1.2119334057507763e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.130986293473567e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 90728.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.207354984481442e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.3967320919037, "timer/env.step_count": 2510.0, "timer/env.step_total": 5.037560701370239, "timer/env.step_frac": 0.01006713349288027, "timer/env.step_avg": 0.002006996295366629, "timer/env.step_min": 0.0010700225830078125, "timer/env.step_max": 0.008245229721069336, "timer/replay._sample_count": 20080.0, "timer/replay._sample_total": 1334.870949268341, "timer/replay._sample_frac": 2.6676252334581125, "timer/replay._sample_avg": 0.06647763691575403, "timer/replay._sample_min": 0.0003223419189453125, "timer/replay._sample_max": 0.09000229835510254, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3088.0, "timer/agent.policy_total": 19.923351764678955, "timer/agent.policy_frac": 0.039815111664278015, "timer/agent.policy_avg": 0.006451862618095517, "timer/agent.policy_min": 0.005120277404785156, "timer/agent.policy_max": 0.010839700698852539, "timer/dataset_train_count": 1255.0, "timer/dataset_train_total": 0.09428548812866211, "timer/dataset_train_frac": 0.00018842147056896742, "timer/dataset_train_avg": 7.512787898698177e-05, "timer/dataset_train_min": 5.602836608886719e-05, "timer/dataset_train_max": 0.0002300739288330078, "timer/agent.train_count": 1255.0, "timer/agent.train_total": 469.07385301589966, "timer/agent.train_frac": 0.9374039096037677, "timer/agent.train_avg": 0.3737640263074898, "timer/agent.train_min": 0.3525674343109131, "timer/agent.train_max": 1.3202073574066162, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.421658992767334, "timer/agent.report_frac": 0.0008426493734373377, "timer/agent.report_avg": 0.210829496383667, "timer/agent.report_min": 0.20950603485107422, "timer/agent.report_max": 0.21215295791625977, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 6.479843827568659e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 40.127689983658286}
{"step": 383096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 383776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 383864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 383880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 383920, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 384168, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776}
{"step": 384768, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 384880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 384888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 384936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 385312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 386088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 386176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 386416, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 386480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 386888, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004}
{"step": 387080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 387192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 387248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 387440, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903}
{"step": 387576, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 387616, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838}
{"step": 387984, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 388328, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641}
{"step": 388488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 388504, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 388792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 388824, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 388928, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756}
{"step": 389200, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 389224, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 389560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 389800, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736}
{"step": 389872, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322}
{"step": 390000, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 390000, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 390000, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 390000, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 390000, "eval_episode/length": 248.0, "eval_episode/score": 0.22499999403953552, "eval_episode/reward_rate": 0.004016064257028112}
{"step": 390000, "eval_episode/length": 180.0, "eval_episode/score": 0.4375, "eval_episode/reward_rate": 0.0055248618784530384}
{"step": 390000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390312, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 390320, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 390344, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842}
{"step": 390544, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04}
{"step": 390640, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294}
{"step": 391104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 391112, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 391240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 391352, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903}
{"step": 391512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 391792, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 391824, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291}
{"step": 392184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 392632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 392896, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304}
{"step": 392952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 393424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 393552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 393616, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664}
{"step": 393824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 394104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 394136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 394344, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 394496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 395208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 395264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 395616, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291}
{"step": 395680, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676}
{"step": 395816, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705}
{"step": 395928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 396048, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 396136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 396192, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 396416, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 396504, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 396576, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111}
{"step": 396656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 396808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 397008, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444}
{"step": 397184, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 397392, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357}
{"step": 397440, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 397928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 397984, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 398072, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 398504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 398728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 399256, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642}
{"step": 399704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 399752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 399928, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875}
{"step": 400056, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 400088, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 400088, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 400088, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 400088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 400296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 400384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 400440, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757}
{"step": 400896, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154}
{"step": 401040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 402240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 402368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 402448, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062}
{"step": 402552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 402608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 402752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 402904, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232}
{"step": 403065, "train_stats/mean_log_entropy": 0.5293566870568979, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4193359375, "train/action_min": 0.0, "train/action_std": 1.606810209274292, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0022031206265091894, "train/actor_opt_grad_steps": 24470.0, "train/actor_opt_loss": 9.351832903862, "train/adv_mag": 0.016794261693954468, "train/adv_max": 0.01577556562423706, "train/adv_mean": 0.0028747330370970303, "train/adv_min": -0.007887256383895874, "train/adv_std": 0.0029210374280810355, "train/cont_avg": 0.996359375, "train/cont_loss_mean": 0.02349368880316615, "train/cont_loss_std": 0.31891313396021725, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.45830902626844, "train/cont_pos_acc": 0.9999999833106995, "train/cont_pos_loss": 0.0036254184283316137, "train/cont_pred": 0.9963773832321167, "train/cont_rate": 0.996359375, "train/dyn_loss_mean": 1.000028419494629, "train/dyn_loss_std": 0.00025622540875338016, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13864245785959065, "train/extr_critic_critic_opt_grad_steps": 24470.0, "train/extr_critic_critic_opt_loss": 11718.1629609375, "train/extr_critic_mag": 0.30958937644958495, "train/extr_critic_max": 0.30958937644958495, "train/extr_critic_mean": 0.30249548959732053, "train/extr_critic_min": 0.29474534606933595, "train/extr_critic_std": 0.002514920812100172, "train/extr_return_normed_mag": 0.028280192852020263, "train/extr_return_normed_max": 0.028256953477859496, "train/extr_return_normed_mean": 0.011986710984769161, "train/extr_return_normed_min": 0.001029731035232544, "train/extr_return_normed_std": 0.0037920312844216823, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.32164044737815856, "train/extr_return_raw_max": 0.32164044737815856, "train/extr_return_raw_mean": 0.3053702175617218, "train/extr_return_raw_min": 0.2944132249355316, "train/extr_return_raw_std": 0.0037920312825590373, "train/extr_reward_mag": 0.01265880298614502, "train/extr_reward_max": 0.01265880298614502, "train/extr_reward_mean": 0.001280171881429851, "train/extr_reward_min": 3.108978271484375e-07, "train/extr_reward_std": 0.0027746050362475218, "train/image_loss_mean": 0.15611821299791337, "train/image_loss_std": 0.10961744850873947, "train/model_loss_mean": 0.7837083520889282, "train/model_loss_std": 0.4083569070696831, "train/model_opt_grad_norm": 27.728263984680176, "train/model_opt_grad_steps": 24447.048, "train/model_opt_loss": 2283.8607412109377, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2940.0, "train/policy_entropy_mag": 1.6854774551391603, "train/policy_entropy_max": 1.6854774551391603, "train/policy_entropy_mean": 0.5424309713840485, "train/policy_entropy_min": 0.06525031995773316, "train/policy_entropy_std": 0.3875154278278351, "train/policy_logprob_mag": 6.5493714714050295, "train/policy_logprob_max": -0.00869572539627552, "train/policy_logprob_mean": -0.541980283498764, "train/policy_logprob_min": -6.5493714714050295, "train/policy_logprob_std": 0.9512147312164306, "train/policy_randomness_mag": 0.8661641206741333, "train/policy_randomness_max": 0.8661641206741333, "train/policy_randomness_mean": 0.27875439631938936, "train/policy_randomness_min": 0.03353203317523003, "train/policy_randomness_std": 0.19914354753494262, "train/post_ent_mag": 69.97639385986328, "train/post_ent_max": 69.97639385986328, "train/post_ent_mean": 69.26227410888671, "train/post_ent_min": 68.51460693359375, "train/post_ent_std": 0.27888425028324126, "train/prior_ent_mag": 72.64658221435546, "train/prior_ent_max": 72.64658221435546, "train/prior_ent_mean": 70.05742193603515, "train/prior_ent_min": 67.62263131713867, "train/prior_ent_std": 0.8341368143558502, "train/rep_loss_mean": 1.000028419494629, "train/rep_loss_std": 0.00025622540875338016, "train/reward_avg": 0.00033610839484026655, "train/reward_loss_mean": 0.004079372718930245, "train/reward_loss_std": 0.09897727781534195, "train/reward_max_data": 0.27342499846220014, "train/reward_max_pred": 0.009274625778198242, "train/reward_neg_acc": 0.9999999995231629, "train/reward_neg_loss": 0.0004507179179636296, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.360305220992477, "train/reward_pred": 0.00019951337110251188, "train/reward_rate": 0.0005703125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.01988605037331581, "report/cont_loss_std": 0.3107379674911499, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.750613212585449, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030474811792373657, "report/cont_pred": 0.9969585537910461, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.16346068680286407, "report/image_loss_std": 0.12143965065479279, "report/model_loss_mean": 0.7835277318954468, "report/model_loss_std": 0.33201679587364197, "report/post_ent_mag": 68.75431823730469, "report/post_ent_max": 68.75431823730469, "report/post_ent_mean": 68.10684967041016, "report/post_ent_min": 67.33074951171875, "report/post_ent_std": 0.2602095603942871, "report/prior_ent_mag": 73.00440216064453, "report/prior_ent_max": 73.00440216064453, "report/prior_ent_mean": 71.00033569335938, "report/prior_ent_min": 68.37130737304688, "report/prior_ent_std": 0.8046566247940063, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00018093083053827286, "report/reward_loss_std": 0.0008943958091549575, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.004030704498291016, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00018093083053827286, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 7.8974524512887e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.008957521989941597, "eval/cont_loss_std": 0.19019955396652222, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.092106819152832, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003011139575392008, "eval/cont_pred": 0.9969956874847412, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18538036942481995, "eval/image_loss_std": 0.09889763593673706, "eval/model_loss_mean": 0.794426679611206, "eval/model_loss_std": 0.21257241070270538, "eval/post_ent_mag": 68.632080078125, "eval/post_ent_max": 68.632080078125, "eval/post_ent_mean": 68.05194091796875, "eval/post_ent_min": 67.39993286132812, "eval/post_ent_std": 0.21877358853816986, "eval/prior_ent_mag": 73.24107360839844, "eval/prior_ent_max": 73.24107360839844, "eval/prior_ent_mean": 70.77461242675781, "eval/prior_ent_min": 68.56399536132812, "eval/prior_ent_std": 0.6864885091781616, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 8.874759078025818e-05, "eval/reward_loss_std": 0.0004557390930131078, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.003075838088989258, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 8.874759078025818e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.8456288166344166e-05, "eval/reward_rate": 0.0, "replay/size": 402561.0, "replay/inserts": 19984.0, "replay/samples": 19984.0, "replay/insert_wait_avg": 1.2062901587749692e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.331728532850695e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 95352.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1832759454588577e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.109476089477539e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.1708312034607, "timer/env.step_count": 2498.0, "timer/env.step_total": 5.084622621536255, "timer/env.step_frac": 0.010165771980949284, "timer/env.step_avg": 0.002035477430558949, "timer/env.step_min": 0.0010700225830078125, "timer/env.step_max": 0.012848377227783203, "timer/replay._sample_count": 19984.0, "timer/replay._sample_total": 1339.8588905334473, "timer/replay._sample_frac": 2.678802534945138, "timer/replay._sample_avg": 0.06704658179210604, "timer/replay._sample_min": 0.012449026107788086, "timer/replay._sample_max": 0.12310433387756348, "timer/agent.save_count": 1.0, "timer/agent.save_total": 1.0825600624084473, "timer/agent.save_frac": 0.002164380637318854, "timer/agent.save_avg": 1.0825600624084473, "timer/agent.save_min": 1.0825600624084473, "timer/agent.save_max": 1.0825600624084473, "timer/agent.policy_count": 3076.0, "timer/agent.policy_total": 20.988783597946167, "timer/agent.policy_frac": 0.041963229937749605, "timer/agent.policy_avg": 0.006823401689839456, "timer/agent.policy_min": 0.005048036575317383, "timer/agent.policy_max": 1.0702815055847168, "timer/dataset_train_count": 1249.0, "timer/dataset_train_total": 0.09481072425842285, "timer/dataset_train_frac": 0.0001895566841238999, "timer/dataset_train_avg": 7.590930685222006e-05, "timer/dataset_train_min": 5.888938903808594e-05, "timer/dataset_train_max": 0.0001533031463623047, "timer/agent.train_count": 1249.0, "timer/agent.train_total": 465.6080665588379, "timer/agent.train_frac": 0.9308980802389828, "timer/agent.train_avg": 0.3727846809918638, "timer/agent.train_min": 0.3522827625274658, "timer/agent.train_max": 0.421738862991333, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.406923770904541, "timer/agent.report_frac": 0.0008135695756696607, "timer/agent.report_avg": 0.2034618854522705, "timer/agent.report_min": 0.1986534595489502, "timer/agent.report_max": 0.20827031135559082, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 6.53043786226454e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 39.95389028800378}
{"step": 403096, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 403208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 403888, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 404328, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225}
{"step": 404552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 404760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 404864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 405064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 405168, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 405176, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 405216, "episode/length": 5.0, "episode/score": 0.984375, "episode/reward_rate": 0.16666666666666666}
{"step": 405216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 405304, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625}
{"step": 405408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 405648, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 405688, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 405704, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 405784, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705}
{"step": 406176, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 406200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 406264, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 406504, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 406736, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655}
{"step": 407104, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 407128, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674}
{"step": 407376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 407528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 407616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 407968, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494}
{"step": 408288, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 408488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 408512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 408672, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676}
{"step": 409024, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877}
{"step": 409280, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 409416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 409688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 409696, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 409704, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 410040, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 410072, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 410072, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 410072, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 410072, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 410072, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 410072, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 410072, "eval_episode/length": 183.0, "eval_episode/score": 0.4281249940395355, "eval_episode/reward_rate": 0.005434782608695652}
{"step": 410072, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 410176, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213}
{"step": 410280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 410464, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417}
{"step": 410712, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 410824, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 410824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 411016, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 411048, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 411072, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 411536, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 411728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 411832, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703}
{"step": 412008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 412352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 412640, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 413136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 413136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 413200, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 413328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 413360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 413536, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456}
{"step": 413624, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 413768, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 414040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 414320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 414424, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 414784, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 415384, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 415448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 415448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 415512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 415656, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774}
{"step": 415688, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345}
{"step": 415744, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 415864, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 416352, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 416504, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674}
{"step": 416632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 416728, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 417032, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 417528, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 417760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 417760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 418000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 418056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 418160, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 418336, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236}
{"step": 418600, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 418664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 418664, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 418848, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 419032, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213}
{"step": 419136, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 419168, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 419352, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 419520, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842}
{"step": 419576, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 419640, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 419880, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 419896, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 419944, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453}
{"step": 420056, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 420056, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 420056, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 420056, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 420056, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 420056, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 420056, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 420056, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 420072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 420160, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 420200, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125}
{"step": 420328, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 420584, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 420672, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 420688, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 420744, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05}
{"step": 420816, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 420992, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 421104, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 421224, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 421304, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 421368, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 421392, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 421736, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 421888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 421928, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 422088, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 422296, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 422304, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 422472, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 422832, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629}
{"step": 423048, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 423176, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 423177, "train_stats/mean_log_entropy": 0.4772806844067952, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.498171851748512, "train/action_min": 0.0, "train/action_std": 1.616216778755188, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002334443128867341, "train/actor_opt_grad_steps": 25725.0, "train/actor_opt_loss": 8.231928514671468, "train/adv_mag": 0.021393307854258824, "train/adv_max": 0.020701091913949875, "train/adv_mean": 0.003289436103913763, "train/adv_min": -0.008544642064306471, "train/adv_std": 0.0036489147959010942, "train/cont_avg": 0.9963417658730159, "train/cont_loss_mean": 0.02371088524038593, "train/cont_loss_std": 0.31801638992536546, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.486471211323972, "train/cont_pos_acc": 0.999999982023996, "train/cont_pos_loss": 0.003730989846637443, "train/cont_pred": 0.9962734778722128, "train/cont_rate": 0.9963417658730159, "train/dyn_loss_mean": 1.0000109615780057, "train/dyn_loss_std": 0.0002620803672023555, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.36631315222956123, "train/extr_critic_critic_opt_grad_steps": 25725.0, "train/extr_critic_critic_opt_loss": 5447.32321312314, "train/extr_critic_mag": 0.36501290116991314, "train/extr_critic_max": 0.36501290116991314, "train/extr_critic_mean": 0.35996342320290825, "train/extr_critic_min": 0.3533393040535942, "train/extr_critic_std": 0.0019672150596133655, "train/extr_return_normed_mag": 0.03146978739708189, "train/extr_return_normed_max": 0.031416638976051695, "train/extr_return_normed_mean": 0.011248196878272759, "train/extr_return_normed_min": -0.0013944095089322044, "train/extr_return_normed_std": 0.004419357253475085, "train/extr_return_rate": 2.0667990495909064e-06, "train/extr_return_raw_mag": 0.3834212805543627, "train/extr_return_raw_max": 0.3834212805543627, "train/extr_return_raw_mean": 0.3632528552460292, "train/extr_return_raw_min": 0.3506102320693788, "train/extr_return_raw_std": 0.004419357262714397, "train/extr_reward_mag": 0.015186748807392424, "train/extr_reward_max": 0.015186748807392424, "train/extr_reward_mean": 0.0014422577129037577, "train/extr_reward_min": 2.658556378076947e-07, "train/extr_reward_std": 0.003095387457130802, "train/image_loss_mean": 0.14940306993703995, "train/image_loss_std": 0.10832068211739025, "train/model_loss_mean": 0.7767369174768054, "train/model_loss_std": 0.39630210931812015, "train/model_opt_grad_norm": 27.076984942905487, "train/model_opt_grad_steps": 25701.444444444445, "train/model_opt_loss": 2809.456352112785, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3611.1111111111113, "train/policy_entropy_mag": 1.658059243171934, "train/policy_entropy_max": 1.658059243171934, "train/policy_entropy_mean": 0.5161646289957894, "train/policy_entropy_min": 0.06479481885594035, "train/policy_entropy_std": 0.38051626393719323, "train/policy_logprob_mag": 6.550307921000889, "train/policy_logprob_max": -0.008625089915262328, "train/policy_logprob_mean": -0.516445216205385, "train/policy_logprob_min": -6.550307921000889, "train/policy_logprob_std": 0.9334598997282604, "train/policy_randomness_mag": 0.8520739466424972, "train/policy_randomness_max": 0.8520739466424972, "train/policy_randomness_mean": 0.2652561611362866, "train/policy_randomness_min": 0.03329795211671837, "train/policy_randomness_std": 0.1955466883050071, "train/post_ent_mag": 67.65380441574823, "train/post_ent_max": 67.65380441574823, "train/post_ent_mean": 66.89893655928354, "train/post_ent_min": 66.12251645042782, "train/post_ent_std": 0.28653996863535475, "train/prior_ent_mag": 71.97372642395989, "train/prior_ent_max": 71.97372642395989, "train/prior_ent_mean": 69.82717901562887, "train/prior_ent_min": 67.19790831066314, "train/prior_ent_std": 0.8093014884562719, "train/rep_loss_mean": 1.0000109615780057, "train/rep_loss_std": 0.0002620803672023555, "train/reward_avg": 0.0002734714082815492, "train/reward_loss_mean": 0.003616363364493563, "train/reward_loss_std": 0.086609341303489, "train/reward_max_data": 0.23343253939870803, "train/reward_max_pred": 0.011845697486211382, "train/reward_neg_acc": 0.9999922495039683, "train/reward_neg_loss": 0.0005358814049118553, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.392371532764841, "train/reward_pred": 0.0002378829669887348, "train/reward_rate": 0.00048828125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.038215164095163345, "report/cont_loss_std": 0.454267293214798, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.954434394836426, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0033455092925578356, "report/cont_pred": 0.9966651797294617, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.17001262307167053, "report/image_loss_std": 0.10798025131225586, "report/model_loss_mean": 0.8083375692367554, "report/model_loss_std": 0.46342453360557556, "report/post_ent_mag": 67.11798858642578, "report/post_ent_max": 67.11798858642578, "report/post_ent_mean": 66.4905776977539, "report/post_ent_min": 65.74043273925781, "report/post_ent_std": 0.2404843121767044, "report/prior_ent_mag": 70.56670379638672, "report/prior_ent_max": 70.56670379638672, "report/prior_ent_mean": 68.71791076660156, "report/prior_ent_min": 65.298095703125, "report/prior_ent_std": 0.8960076570510864, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00010975915938615799, "report/reward_loss_std": 0.0004806393408216536, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.002315998077392578, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00010975915938615799, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.6441564336419106e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0198366641998291, "eval/cont_loss_std": 0.30354878306388855, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.618251800537109, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0033868644386529922, "eval/cont_pred": 0.9966185688972473, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1925012767314911, "eval/image_loss_std": 0.09777060896158218, "eval/model_loss_mean": 0.8124139904975891, "eval/model_loss_std": 0.31704023480415344, "eval/post_ent_mag": 67.13672637939453, "eval/post_ent_max": 67.13672637939453, "eval/post_ent_mean": 66.41039276123047, "eval/post_ent_min": 65.74418640136719, "eval/post_ent_std": 0.23847529292106628, "eval/prior_ent_mag": 70.46647644042969, "eval/prior_ent_max": 70.46647644042969, "eval/prior_ent_mean": 68.49879455566406, "eval/prior_ent_min": 65.54750061035156, "eval/prior_ent_std": 0.8591475486755371, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 7.601920515298843e-05, "eval/reward_loss_std": 0.0004925169632770121, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.004997849464416504, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 7.601920515298843e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.2245065085589886e-05, "eval/reward_rate": 0.0, "replay/size": 422673.0, "replay/inserts": 20112.0, "replay/samples": 20112.0, "replay/insert_wait_avg": 1.192507804530712e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.178301696655953e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 98272.0, "eval_replay/inserts": 2920.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0861109380852686e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.407499313354492e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.1899743080139, "timer/env.step_count": 2514.0, "timer/env.step_total": 5.183320760726929, "timer/env.step_frac": 0.01036270422632476, "timer/env.step_avg": 0.0020617823232804014, "timer/env.step_min": 0.001054525375366211, "timer/env.step_max": 0.008003711700439453, "timer/replay._sample_count": 20112.0, "timer/replay._sample_total": 1336.8356864452362, "timer/replay._sample_frac": 2.6726559009797763, "timer/replay._sample_avg": 0.06646955481529615, "timer/replay._sample_min": 0.0003495216369628906, "timer/replay._sample_max": 0.09421634674072266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2879.0, "timer/agent.policy_total": 18.69541311264038, "timer/agent.policy_frac": 0.037376625028329453, "timer/agent.policy_avg": 0.006493717649406176, "timer/agent.policy_min": 0.005071163177490234, "timer/agent.policy_max": 0.009519338607788086, "timer/dataset_train_count": 1257.0, "timer/dataset_train_total": 0.09628987312316895, "timer/dataset_train_frac": 0.00019250660362871294, "timer/dataset_train_avg": 7.66029221345815e-05, "timer/dataset_train_min": 5.2928924560546875e-05, "timer/dataset_train_max": 0.000179290771484375, "timer/agent.train_count": 1257.0, "timer/agent.train_total": 469.9534845352173, "timer/agent.train_frac": 0.939549988352671, "timer/agent.train_avg": 0.3738691205530766, "timer/agent.train_min": 0.35007166862487793, "timer/agent.train_max": 0.4202003479003906, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4215116500854492, "timer/agent.report_frac": 0.0008427031162881424, "timer/agent.report_avg": 0.2107558250427246, "timer/agent.report_min": 0.2092454433441162, "timer/agent.report_max": 0.212266206741333, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.76837158203125e-05, "timer/dataset_eval_frac": 9.533121067906323e-08, "timer/dataset_eval_avg": 4.76837158203125e-05, "timer/dataset_eval_min": 4.76837158203125e-05, "timer/dataset_eval_max": 4.76837158203125e-05, "fps": 40.20809636760699}
{"step": 423248, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291}
{"step": 423280, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154}
{"step": 423536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 423624, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169}
{"step": 423680, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093}
{"step": 423928, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 424240, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 424256, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875}
{"step": 424368, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 424520, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 424560, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625}
{"step": 424672, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 424824, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 424928, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 424936, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 425304, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 425360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 425440, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291}
{"step": 425680, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 425848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 425888, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 425920, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 426032, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 426032, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 426776, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 426904, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 426984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 427280, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 427488, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663}
{"step": 427672, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805}
{"step": 427704, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474}
{"step": 427848, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225}
{"step": 427992, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 428008, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05}
{"step": 428048, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 428160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 428248, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333}
{"step": 428384, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 428424, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304}
{"step": 428872, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 428944, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 428960, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 429088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 429176, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 429216, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291}
{"step": 429296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 429488, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 429608, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 429712, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 430040, "eval_episode/length": 277.0, "eval_episode/score": 0.13437500596046448, "eval_episode/reward_rate": 0.0035971223021582736}
{"step": 430040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430312, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 430360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 431272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 431400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 431488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 431608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 431920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 432024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 432064, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 432344, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 432536, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 432624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 432672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 433168, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 433296, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 433328, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182}
{"step": 433352, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 433584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 433592, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 433640, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748}
{"step": 433664, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 433680, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 433688, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952}
{"step": 433928, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 433968, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 434112, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 434120, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 434136, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 434280, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 434376, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333}
{"step": 434528, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 434552, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 434632, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 435120, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 435312, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 435688, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695}
{"step": 435736, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 435744, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 435904, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475}
{"step": 435952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 436240, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 436248, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 436520, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 436592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 436688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 436864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 437368, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 437552, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 438000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 438056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 438256, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 438552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 438560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 438608, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 438712, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 438880, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 439000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 439096, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 439176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 439240, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 439472, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 439816, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 439864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 439904, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 439952, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 440024, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 440024, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 440024, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 440024, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 440024, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 440024, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 440024, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 440024, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 440024, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 440408, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 440672, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 440792, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 440920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 441024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 441520, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653}
{"step": 441544, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761}
{"step": 441568, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 441784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 442120, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 442336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 442352, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 442464, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311}
{"step": 442800, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045}
{"step": 443232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 443289, "train_stats/mean_log_entropy": 0.2221004711320767, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.20840673828125, "train/action_min": 0.0, "train/action_std": 1.7970283203125, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0050016813306137916, "train/actor_opt_grad_steps": 26980.0, "train/actor_opt_loss": 23.066319672107696, "train/adv_mag": 0.047884382009506225, "train/adv_max": 0.04772860789299011, "train/adv_mean": 0.011077612617984414, "train/adv_min": -0.015049862384796142, "train/adv_std": 0.007985775975510478, "train/cont_avg": 0.9960625, "train/cont_loss_mean": 0.024690101735293866, "train/cont_loss_std": 0.3229120104182512, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.273043405718919, "train/cont_pos_acc": 0.999992133140564, "train/cont_pos_loss": 0.00392294791713357, "train/cont_pred": 0.9960807971954345, "train/cont_rate": 0.9960625, "train/dyn_loss_mean": 1.0000142822265625, "train/dyn_loss_std": 0.0004568044114857912, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9086898302733898, "train/extr_critic_critic_opt_grad_steps": 26980.0, "train/extr_critic_critic_opt_loss": 9447.70053515625, "train/extr_critic_mag": 0.5285081987380982, "train/extr_critic_max": 0.5285081987380982, "train/extr_critic_mean": 0.5179173727035522, "train/extr_critic_min": 0.5004931354522705, "train/extr_critic_std": 0.004563164625316858, "train/extr_return_normed_mag": 0.07552632546424866, "train/extr_return_normed_max": 0.07548725390434265, "train/extr_return_normed_mean": 0.032814822195097806, "train/extr_return_normed_min": 0.005647687435150146, "train/extr_return_normed_std": 0.009728445259854198, "train/extr_return_rate": 0.6233666706106742, "train/extr_return_raw_mag": 0.5716673934459686, "train/extr_return_raw_max": 0.5716673934459686, "train/extr_return_raw_mean": 0.5289949872493744, "train/extr_return_raw_min": 0.5018278269767761, "train/extr_return_raw_std": 0.009728445246815681, "train/extr_reward_mag": 0.02685448455810547, "train/extr_reward_max": 0.02685448455810547, "train/extr_reward_mean": 0.002831597562413663, "train/extr_reward_min": -7.1821212768554685e-06, "train/extr_reward_std": 0.006171755157411098, "train/image_loss_mean": 0.14143051731586456, "train/image_loss_std": 0.10832708764076233, "train/model_loss_mean": 0.7710780005455017, "train/model_loss_std": 0.415528324007988, "train/model_opt_grad_norm": 26.664996574401854, "train/model_opt_grad_steps": 26955.608, "train/model_opt_loss": 2638.7583671875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3420.0, "train/policy_entropy_mag": 1.5649837942123412, "train/policy_entropy_max": 1.5649837942123412, "train/policy_entropy_mean": 0.28983121609687806, "train/policy_entropy_min": 0.06471681177616119, "train/policy_entropy_std": 0.29198358571529387, "train/policy_logprob_mag": 6.550943122863769, "train/policy_logprob_max": -0.00861302775144577, "train/policy_logprob_mean": -0.2890983291864395, "train/policy_logprob_min": -6.550943122863769, "train/policy_logprob_std": 0.8000054888725281, "train/policy_randomness_mag": 0.8042426257133484, "train/policy_randomness_max": 0.8042426257133484, "train/policy_randomness_mean": 0.14894379138946534, "train/policy_randomness_min": 0.033257864236831663, "train/policy_randomness_std": 0.15004988992214202, "train/post_ent_mag": 65.44427633666992, "train/post_ent_max": 65.44427633666992, "train/post_ent_mean": 64.61717120361328, "train/post_ent_min": 63.764974090576175, "train/post_ent_std": 0.3173399884700775, "train/prior_ent_mag": 68.87253009033203, "train/prior_ent_max": 68.87253009033203, "train/prior_ent_mean": 66.33342330932618, "train/prior_ent_min": 62.88830404663086, "train/prior_ent_std": 1.057251036643982, "train/rep_loss_mean": 1.0000142822265625, "train/rep_loss_std": 0.0004568044114857912, "train/reward_avg": 0.00041745605587493627, "train/reward_loss_mean": 0.004948788553476333, "train/reward_loss_std": 0.11205144315864891, "train/reward_max_data": 0.330475000500679, "train/reward_max_pred": 0.020045089721679687, "train/reward_neg_acc": 0.9999999990463256, "train/reward_neg_loss": 0.0008488702037138864, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.728352683431962, "train/reward_pred": 0.00039742934424430134, "train/reward_rate": 0.0007265625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.033187247812747955, "report/cont_loss_std": 0.42763805389404297, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.1365580558776855, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032394041772931814, "report/cont_pred": 0.9967753887176514, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.15420950949192047, "report/image_loss_std": 0.10621711611747742, "report/model_loss_mean": 0.7879210710525513, "report/model_loss_std": 0.4399762451648712, "report/post_ent_mag": 64.53569793701172, "report/post_ent_max": 64.53569793701172, "report/post_ent_mean": 63.65776824951172, "report/post_ent_min": 62.90013122558594, "report/post_ent_std": 0.32409876585006714, "report/prior_ent_mag": 66.11613464355469, "report/prior_ent_max": 66.11613464355469, "report/prior_ent_mean": 62.99359893798828, "report/prior_ent_min": 59.89049530029297, "report/prior_ent_std": 1.0997657775878906, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0005242926999926567, "report/reward_loss_std": 0.0030566377099603415, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.02240729331970215, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005242926999926567, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002482410054653883, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.011448249220848083, "eval/cont_loss_std": 0.19171994924545288, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.345088005065918, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0029675450641661882, "eval/cont_pred": 0.9970191717147827, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13945084810256958, "eval/image_loss_std": 0.09967969357967377, "eval/model_loss_mean": 0.7575476169586182, "eval/model_loss_std": 0.38759899139404297, "eval/post_ent_mag": 64.41673278808594, "eval/post_ent_max": 64.41673278808594, "eval/post_ent_mean": 63.69251251220703, "eval/post_ent_min": 62.88071823120117, "eval/post_ent_std": 0.3258553445339203, "eval/prior_ent_mag": 66.77206420898438, "eval/prior_ent_max": 66.77206420898438, "eval/prior_ent_mean": 63.33457565307617, "eval/prior_ent_min": 59.51266860961914, "eval/prior_ent_std": 1.0873312950134277, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008026122814044356, "eval/reward_loss_mean": 0.006648543290793896, "eval/reward_loss_std": 0.2053309977054596, "eval/reward_max_data": 0.8218749761581421, "eval/reward_max_pred": 0.009753108024597168, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00022895548318047076, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.573886871337891, "eval/reward_pred": 0.00011037057265639305, "eval/reward_rate": 0.0009765625, "replay/size": 442785.0, "replay/inserts": 20112.0, "replay/samples": 20112.0, "replay/insert_wait_avg": 1.211913692258897e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.276694407800691e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4208.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.204614403583251e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 5.811452865600586e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.0367453098297, "timer/env.step_count": 2514.0, "timer/env.step_total": 5.182939767837524, "timer/env.step_frac": 0.010365117796745323, "timer/env.step_avg": 0.0020616307747961513, "timer/env.step_min": 0.0010802745819091797, "timer/env.step_max": 0.008748769760131836, "timer/replay._sample_count": 20112.0, "timer/replay._sample_total": 1339.9681568145752, "timer/replay._sample_frac": 2.679739377921741, "timer/replay._sample_avg": 0.0666253061264208, "timer/replay._sample_min": 0.0004968643188476562, "timer/replay._sample_max": 0.09339594841003418, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3040.0, "timer/agent.policy_total": 19.632564067840576, "timer/agent.policy_frac": 0.03926224272913377, "timer/agent.policy_avg": 0.006458080285473873, "timer/agent.policy_min": 0.005200862884521484, "timer/agent.policy_max": 0.016564369201660156, "timer/dataset_train_count": 1257.0, "timer/dataset_train_total": 0.09605574607849121, "timer/dataset_train_frac": 0.00019209737480187328, "timer/dataset_train_avg": 7.641666354693017e-05, "timer/dataset_train_min": 6.628036499023438e-05, "timer/dataset_train_max": 0.0002384185791015625, "timer/agent.train_count": 1257.0, "timer/agent.train_total": 468.8305950164795, "timer/agent.train_frac": 0.9375922857948881, "timer/agent.train_avg": 0.3729758114689574, "timer/agent.train_min": 0.3525660037994385, "timer/agent.train_max": 0.41906309127807617, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.40687108039855957, "timer/agent.report_frac": 0.0008136823627760728, "timer/agent.report_avg": 0.20343554019927979, "timer/agent.report_min": 0.19553017616271973, "timer/agent.report_max": 0.21134090423583984, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 6.675229648080543e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 40.22058186272475}
{"step": 443664, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667}
{"step": 443832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 443912, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695}
{"step": 444096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 444128, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 444296, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 444432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 444640, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 444664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 444904, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 445112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 445256, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 445504, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 445904, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 445976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 446232, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925}
{"step": 446360, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715}
{"step": 446576, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 446744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 446896, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 446912, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 446952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 446960, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329}
{"step": 447072, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 447208, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 447312, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 447528, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 447672, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 447752, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 447808, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 447840, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 447944, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 447952, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 448072, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 448240, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 448360, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776}
{"step": 448616, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 448800, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 448936, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 448976, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 449008, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 449208, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 449384, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 449792, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 449792, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 449984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 450008, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 450008, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 450008, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 450008, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 450008, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 450008, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 450008, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 450008, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 450120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 450176, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 450264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 450384, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 450832, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 450960, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315}
{"step": 451008, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 451104, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 451320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 451360, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 451568, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 451696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 451816, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805}
{"step": 451904, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805}
{"step": 452184, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 452280, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 453320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 453416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 453632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 453776, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 453880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 454128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 454216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 454496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 454512, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036}
{"step": 454808, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 455080, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 455296, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 455472, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 455512, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 455664, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333}
{"step": 455728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 455944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 456048, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 456088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 456112, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 456192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 456416, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571}
{"step": 457608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 457824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 458040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 458224, "episode/length": 263.0, "episode/score": 0.17812499403953552, "episode/reward_rate": 0.003787878787878788}
{"step": 458256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 458360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 458400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 458712, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564}
{"step": 458728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 458768, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 458800, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 458816, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 459192, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 459480, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 459728, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 459920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 460096, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 460096, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 460096, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 460096, "eval_episode/length": 232.0, "eval_episode/score": 0.2750000059604645, "eval_episode/reward_rate": 0.004291845493562232}
{"step": 460096, "eval_episode/length": 233.0, "eval_episode/score": 0.2718749940395355, "eval_episode/reward_rate": 0.004273504273504274}
{"step": 460096, "eval_episode/length": 239.0, "eval_episode/score": 0.25312501192092896, "eval_episode/reward_rate": 0.004166666666666667}
{"step": 460096, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 460096, "eval_episode/length": 259.0, "eval_episode/score": 0.19062499701976776, "eval_episode/reward_rate": 0.0038461538461538464}
{"step": 460312, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051}
{"step": 460352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 460536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 461024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 461104, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 461112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 461552, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667}
{"step": 461616, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 461688, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444}
{"step": 461792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 462040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 462160, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 462184, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 462232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 462560, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 462848, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 463016, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907}
{"step": 463184, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704}
{"step": 463328, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 463328, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 463465, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2776359498031495, "train/action_min": 0.0, "train/action_std": 1.6109123577283124, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004555116619320777, "train/actor_opt_grad_steps": 28240.0, "train/actor_opt_loss": 9.262673159841242, "train/adv_mag": 0.08077990633296216, "train/adv_max": 0.07072689589552993, "train/adv_mean": 0.007190874605231064, "train/adv_min": -0.03279932746737022, "train/adv_std": 0.009193911202486575, "train/cont_avg": 0.9959476500984252, "train/cont_loss_mean": 0.024251240745597466, "train/cont_loss_std": 0.31650352947355254, "train/cont_neg_acc": 0.0013123359971159087, "train/cont_neg_loss": 5.010246712391771, "train/cont_pos_acc": 0.9999845271974098, "train/cont_pos_loss": 0.003993309220284459, "train/cont_pred": 0.9959890204151784, "train/cont_rate": 0.9959476500984252, "train/dyn_loss_mean": 1.000010603994835, "train/dyn_loss_std": 0.00033324830578713435, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.744665177480325, "train/extr_critic_critic_opt_grad_steps": 28240.0, "train/extr_critic_critic_opt_loss": 11526.760211614173, "train/extr_critic_mag": 0.7120025270567165, "train/extr_critic_max": 0.7120025270567165, "train/extr_critic_mean": 0.6967216673798449, "train/extr_critic_min": 0.6723956498574084, "train/extr_critic_std": 0.00631300714160279, "train/extr_return_normed_mag": 0.10620908943686898, "train/extr_return_normed_max": 0.09717778380461566, "train/extr_return_normed_mean": 0.026574688722511505, "train/extr_return_normed_min": -0.014883858481730064, "train/extr_return_normed_std": 0.011452137113101488, "train/extr_return_rate": 0.999996925432851, "train/extr_return_raw_mag": 0.7745156030016621, "train/extr_return_raw_max": 0.7745156030016621, "train/extr_return_raw_mean": 0.7039125420915799, "train/extr_return_raw_min": 0.6624539607153164, "train/extr_return_raw_std": 0.011452137127767985, "train/extr_reward_mag": 0.07263279712106299, "train/extr_reward_max": 0.07263279712106299, "train/extr_reward_mean": 0.00267876104651547, "train/extr_reward_min": 5.772733312892163e-07, "train/extr_reward_std": 0.007199615051265894, "train/image_loss_mean": 0.13818750014220635, "train/image_loss_std": 0.10946441952168472, "train/model_loss_mean": 0.7685399421556728, "train/model_loss_std": 0.4255582453228357, "train/model_opt_grad_norm": 27.205938737223466, "train/model_opt_grad_steps": 28214.79527559055, "train/model_opt_loss": 2676.692899929257, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3484.251968503937, "train/policy_entropy_mag": 1.5293703717509592, "train/policy_entropy_max": 1.5293703717509592, "train/policy_entropy_mean": 0.24599046723579798, "train/policy_entropy_min": 0.06469222175793385, "train/policy_entropy_std": 0.266684687982394, "train/policy_logprob_mag": 6.551058720415972, "train/policy_logprob_max": -0.008609224704834889, "train/policy_logprob_mean": -0.24534305730673273, "train/policy_logprob_min": -6.551058720415972, "train/policy_logprob_std": 0.7649879943667435, "train/policy_randomness_mag": 0.7859409423325006, "train/policy_randomness_max": 0.7859409423325006, "train/policy_randomness_mean": 0.12641410036819187, "train/policy_randomness_min": 0.033245227556294346, "train/policy_randomness_std": 0.13704882702958865, "train/post_ent_mag": 62.50442934411717, "train/post_ent_max": 62.50442934411717, "train/post_ent_mean": 61.646934329055426, "train/post_ent_min": 60.7912038968304, "train/post_ent_std": 0.32360619118833167, "train/prior_ent_mag": 65.37118653425081, "train/prior_ent_max": 65.37118653425081, "train/prior_ent_mean": 62.01977710273322, "train/prior_ent_min": 58.595110705518344, "train/prior_ent_std": 1.125110483545018, "train/rep_loss_mean": 1.000010603994835, "train/rep_loss_std": 0.00033324830578713435, "train/reward_avg": 0.0005965585752544324, "train/reward_loss_mean": 0.00609481800714229, "train/reward_loss_std": 0.13171343672488942, "train/reward_max_data": 0.4326033458465666, "train/reward_max_pred": 0.02711646481761782, "train/reward_neg_acc": 0.9999922861264446, "train/reward_neg_loss": 0.0009366945918387272, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.402797531198572, "train/reward_pred": 0.00045712989861306945, "train/reward_rate": 0.000953494094488189, "train_stats/mean_log_entropy": 0.20148408853759367, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.019147245213389397, "report/cont_loss_std": 0.2821803092956543, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.201493263244629, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003919978626072407, "report/cont_pred": 0.996096134185791, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1292838156223297, "report/image_loss_std": 0.10601159185171127, "report/model_loss_mean": 0.7488141059875488, "report/model_loss_std": 0.30129101872444153, "report/post_ent_mag": 60.46051025390625, "report/post_ent_max": 60.46051025390625, "report/post_ent_mean": 59.453311920166016, "report/post_ent_min": 58.55274200439453, "report/post_ent_std": 0.33813872933387756, "report/prior_ent_mag": 63.3880615234375, "report/prior_ent_max": 63.3880615234375, "report/prior_ent_mean": 60.180274963378906, "report/prior_ent_min": 56.4473991394043, "report/prior_ent_std": 1.182332992553711, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0003830334171652794, "report/reward_loss_std": 0.00258198962546885, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.022920727729797363, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0003830334171652794, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00018444133456796408, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0209354180842638, "eval/cont_loss_std": 0.3239726424217224, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.9870405197143555, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00340523780323565, "eval/cont_pred": 0.9966261386871338, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2019348442554474, "eval/image_loss_std": 0.13582958281040192, "eval/model_loss_mean": 0.822996199131012, "eval/model_loss_std": 0.346551775932312, "eval/post_ent_mag": 60.465728759765625, "eval/post_ent_max": 60.465728759765625, "eval/post_ent_mean": 59.415409088134766, "eval/post_ent_min": 58.636985778808594, "eval/post_ent_std": 0.3333812654018402, "eval/prior_ent_mag": 63.36109924316406, "eval/prior_ent_max": 63.36109924316406, "eval/prior_ent_mean": 59.95796203613281, "eval/prior_ent_min": 57.16668701171875, "eval/prior_ent_std": 1.0674340724945068, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00012587429955601692, "eval/reward_loss_std": 0.0008441917598247528, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0059375762939453125, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00012587429955601692, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 6.084679625928402e-05, "eval/reward_rate": 0.0, "replay/size": 462961.0, "replay/inserts": 20176.0, "replay/samples": 20176.0, "replay/insert_wait_avg": 1.2047370211837975e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.281226773001106e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3608.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2024014593492325e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2858872413635, "timer/env.step_count": 2522.0, "timer/env.step_total": 5.194730520248413, "timer/env.step_frac": 0.010383524006429166, "timer/env.step_avg": 0.00205976626496765, "timer/env.step_min": 0.0010790824890136719, "timer/env.step_max": 0.007725715637207031, "timer/replay._sample_count": 20176.0, "timer/replay._sample_total": 1340.9682261943817, "timer/replay._sample_frac": 2.680403865854865, "timer/replay._sample_avg": 0.06646353222612915, "timer/replay._sample_min": 0.00031948089599609375, "timer/replay._sample_max": 0.09036755561828613, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2973.0, "timer/agent.policy_total": 19.2795832157135, "timer/agent.policy_frac": 0.03853713188277894, "timer/agent.policy_avg": 0.0064848917644512285, "timer/agent.policy_min": 0.00517725944519043, "timer/agent.policy_max": 0.009655952453613281, "timer/dataset_train_count": 1261.0, "timer/dataset_train_total": 0.09632277488708496, "timer/dataset_train_frac": 0.00019253546290945824, "timer/dataset_train_avg": 7.63860229080769e-05, "timer/dataset_train_min": 5.5789947509765625e-05, "timer/dataset_train_max": 0.00017404556274414062, "timer/agent.train_count": 1261.0, "timer/agent.train_total": 469.71640968322754, "timer/agent.train_frac": 0.9388959826016685, "timer/agent.train_avg": 0.3724951702483961, "timer/agent.train_min": 0.34631824493408203, "timer/agent.train_max": 0.4187624454498291, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.421750545501709, "timer/agent.report_frac": 0.0008430190742083335, "timer/agent.report_avg": 0.2108752727508545, "timer/agent.report_min": 0.21072959899902344, "timer/agent.report_max": 0.21102094650268555, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 6.624248922522308e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 40.328311747441425}
{"step": 463520, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045}
{"step": 463648, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 463656, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506}
{"step": 463720, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506}
{"step": 463736, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695}
{"step": 464896, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641}
{"step": 465328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 465640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 465640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 465832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 465968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 466032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 466048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 466736, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 466920, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 466976, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464}
{"step": 467280, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705}
{"step": 467440, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453}
{"step": 467528, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322}
{"step": 467528, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 467872, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761}
{"step": 468072, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 468160, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 468280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 468344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 468392, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 468440, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 468528, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 468640, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 469016, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 469136, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 469288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 469600, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 469904, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 469952, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311}
{"step": 470080, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 470080, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 470080, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 470080, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 470080, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 470080, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 470080, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 470080, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 470360, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 470384, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 470568, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 470704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 470752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 470840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 470952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 471008, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 471056, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 471192, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 471520, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 471568, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 471912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 471944, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 472176, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655}
{"step": 472208, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495}
{"step": 472288, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 472344, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444}
{"step": 472600, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 472608, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 472664, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 472696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 472920, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 473000, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 473264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 473344, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 473440, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 473664, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 473688, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 474352, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 474488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 474520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 474544, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625}
{"step": 474824, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 475008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 475016, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 475264, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 475528, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 475656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 475752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 476000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 476088, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 476312, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 476800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 476912, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 476976, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301}
{"step": 477040, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 477136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 477232, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125}
{"step": 477304, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304}
{"step": 477488, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 477496, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045}
{"step": 477544, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 477576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 477584, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 477600, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703}
{"step": 477744, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 477912, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 477952, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 478176, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 478200, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 478328, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 478400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 478424, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 478504, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 478664, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 478664, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 478712, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 478808, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 479088, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 479160, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111}
{"step": 479160, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 479208, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 479448, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 479896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 480064, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 480064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 481024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 481120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 481120, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415}
{"step": 481192, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839}
{"step": 481416, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 481472, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475}
{"step": 481472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 481504, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 481568, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774}
{"step": 481600, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 481872, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 482128, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 482216, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 482256, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 482392, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 482640, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 482656, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757}
{"step": 482960, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 482984, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 483240, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 483312, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525}
{"step": 483432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 483497, "train_stats/mean_log_entropy": 0.14421297363320687, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.29435986328125, "train/action_min": 0.0, "train/action_std": 1.6188388843536377, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010264870513230563, "train/actor_opt_grad_steps": 29500.0, "train/actor_opt_loss": 9.225544665798544, "train/adv_mag": 0.3021934351921082, "train/adv_max": 0.18908442783355714, "train/adv_mean": 0.011407509906566702, "train/adv_min": -0.2000698266029358, "train/adv_std": 0.024458261717110873, "train/cont_avg": 0.995875, "train/cont_loss_mean": 0.024326474390923978, "train/cont_loss_std": 0.31870207035541537, "train/cont_neg_acc": 0.01093333351612091, "train/cont_neg_loss": 4.899871485710144, "train/cont_pos_acc": 0.999976463317871, "train/cont_pos_loss": 0.003949455238878727, "train/cont_pred": 0.9960082097053528, "train/cont_rate": 0.995875, "train/dyn_loss_mean": 1.0000102434158324, "train/dyn_loss_std": 0.00030710577563149854, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0203309519588948, "train/extr_critic_critic_opt_grad_steps": 29500.0, "train/extr_critic_critic_opt_loss": 7254.217345703125, "train/extr_critic_mag": 0.8676959018707275, "train/extr_critic_max": 0.8676959018707275, "train/extr_critic_mean": 0.8542637591361999, "train/extr_critic_min": 0.829725266456604, "train/extr_critic_std": 0.007047289975918829, "train/extr_return_normed_mag": 0.31639044570922853, "train/extr_return_normed_max": 0.22351884603500366, "train/extr_return_normed_mean": 0.03929172396985814, "train/extr_return_normed_min": -0.1695604429244995, "train/extr_return_normed_std": 0.026118906926363705, "train/extr_return_rate": 0.9993406367301941, "train/extr_return_raw_mag": 1.0498983449935912, "train/extr_return_raw_max": 1.0498983449935912, "train/extr_return_raw_mean": 0.8656712608337402, "train/extr_return_raw_min": 0.6568190560340882, "train/extr_return_raw_std": 0.026118907004594804, "train/extr_reward_mag": 0.18420777988433837, "train/extr_reward_max": 0.18420777988433837, "train/extr_reward_mean": 0.0036142849680036305, "train/extr_reward_min": 4.444122314453125e-07, "train/extr_reward_std": 0.012966633163392544, "train/image_loss_mean": 0.130309396982193, "train/image_loss_std": 0.10828330063819885, "train/model_loss_mean": 0.761022629737854, "train/model_loss_std": 0.43114996612071993, "train/model_opt_grad_norm": 24.841014389038087, "train/model_opt_grad_steps": 29473.696, "train/model_opt_loss": 2098.6016572265626, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2760.0, "train/policy_entropy_mag": 1.4996741170883179, "train/policy_entropy_max": 1.4996741170883179, "train/policy_entropy_mean": 0.19972830760478974, "train/policy_entropy_min": 0.06468721574544907, "train/policy_entropy_std": 0.24063692104816437, "train/policy_logprob_mag": 6.551078060150147, "train/policy_logprob_max": -0.008608419187366963, "train/policy_logprob_mean": -0.2001624628305435, "train/policy_logprob_min": -6.551078060150147, "train/policy_logprob_std": 0.7311016454696655, "train/policy_randomness_mag": 0.7706800870895386, "train/policy_randomness_max": 0.7706800870895386, "train/policy_randomness_mean": 0.10264005291461945, "train/policy_randomness_min": 0.033242654860019684, "train/policy_randomness_std": 0.12366292154788971, "train/post_ent_mag": 59.37499438476563, "train/post_ent_max": 59.37499438476563, "train/post_ent_mean": 58.36708233642578, "train/post_ent_min": 57.422078125, "train/post_ent_std": 0.35216559529304503, "train/prior_ent_mag": 61.92705352783203, "train/prior_ent_max": 61.92705352783203, "train/prior_ent_mean": 58.45740869140625, "train/prior_ent_min": 55.09561837768555, "train/prior_ent_std": 1.197807596206665, "train/rep_loss_mean": 1.0000102434158324, "train/rep_loss_std": 0.00030710577563149854, "train/reward_avg": 0.0006538085912470706, "train/reward_loss_mean": 0.006380589351058006, "train/reward_loss_std": 0.13633233986236154, "train/reward_max_data": 0.4557000005841255, "train/reward_max_pred": 0.04381326484680176, "train/reward_neg_acc": 0.9999687337875366, "train/reward_neg_loss": 0.0010549037880264222, "train/reward_pos_acc": 0.03725490219452802, "train/reward_pos_loss": 5.079810495937572, "train/reward_pred": 0.0005067846290767192, "train/reward_rate": 0.0010625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.011172182857990265, "report/cont_loss_std": 0.19637450575828552, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.202086448669434, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002970785601064563, "report/cont_pred": 0.9969826340675354, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0000218152999878, "report/dyn_loss_std": 0.000698269868735224, "report/image_loss_mean": 0.13379062712192535, "report/image_loss_std": 0.10988694429397583, "report/model_loss_mean": 0.7456709742546082, "report/model_loss_std": 0.22758515179157257, "report/post_ent_mag": 56.68613052368164, "report/post_ent_max": 56.68613052368164, "report/post_ent_mean": 55.488670349121094, "report/post_ent_min": 54.35762023925781, "report/post_ent_std": 0.3755834698677063, "report/prior_ent_mag": 60.32297897338867, "report/prior_ent_max": 60.32297897338867, "report/prior_ent_mean": 56.21784210205078, "report/prior_ent_min": 52.271568298339844, "report/prior_ent_std": 1.2578237056732178, "report/rep_loss_mean": 1.0000218152999878, "report/rep_loss_std": 0.000698269868735224, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0006950637325644493, "report/reward_loss_std": 0.004520040471106768, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.03347480297088623, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0006950637325644493, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00032678828574717045, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03710997849702835, "eval/cont_loss_std": 0.4512662887573242, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.805789947509766, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003109897021204233, "eval/cont_pred": 0.9968951344490051, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18017339706420898, "eval/image_loss_std": 0.11598546802997589, "eval/model_loss_mean": 0.8239654302597046, "eval/model_loss_std": 0.5558095574378967, "eval/post_ent_mag": 56.541664123535156, "eval/post_ent_max": 56.541664123535156, "eval/post_ent_mean": 55.477657318115234, "eval/post_ent_min": 54.41621017456055, "eval/post_ent_std": 0.3787861764431, "eval/prior_ent_mag": 60.37444305419922, "eval/prior_ent_max": 60.37444305419922, "eval/prior_ent_mean": 56.3293571472168, "eval/prior_ent_min": 53.00577163696289, "eval/prior_ent_std": 1.2917760610580444, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008026122814044356, "eval/reward_loss_mean": 0.006682031787931919, "eval/reward_loss_std": 0.1897510588169098, "eval/reward_max_data": 0.8218749761581421, "eval/reward_max_pred": 0.04815328121185303, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0007517400663346052, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.073370456695557, "eval/reward_pred": 0.0003557325107976794, "eval/reward_rate": 0.0009765625, "replay/size": 482993.0, "replay/inserts": 20032.0, "replay/samples": 20032.0, "replay/insert_wait_avg": 1.193604435021885e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.273368602362684e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2373411527243993e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.0808777809143, "timer/env.step_count": 2504.0, "timer/env.step_total": 5.193958520889282, "timer/env.step_frac": 0.010386237010175698, "timer/env.step_avg": 0.0020742645850196813, "timer/env.step_min": 0.001081228256225586, "timer/env.step_max": 0.00847935676574707, "timer/replay._sample_count": 20032.0, "timer/replay._sample_total": 1333.0709669589996, "timer/replay._sample_frac": 2.6657107403795166, "timer/replay._sample_avg": 0.06654707303110022, "timer/replay._sample_min": 0.00035500526428222656, "timer/replay._sample_max": 0.08912873268127441, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2969.0, "timer/agent.policy_total": 19.313562870025635, "timer/agent.policy_frac": 0.038620878598135316, "timer/agent.policy_avg": 0.006505073381618604, "timer/agent.policy_min": 0.0051419734954833984, "timer/agent.policy_max": 0.010107755661010742, "timer/dataset_train_count": 1252.0, "timer/dataset_train_total": 0.09456014633178711, "timer/dataset_train_frac": 0.00018908970635188725, "timer/dataset_train_avg": 7.552727342794497e-05, "timer/dataset_train_min": 5.507469177246094e-05, "timer/dataset_train_max": 0.0001690387725830078, "timer/agent.train_count": 1252.0, "timer/agent.train_total": 469.1518921852112, "timer/agent.train_frac": 0.9381520330612338, "timer/agent.train_avg": 0.37472195861438595, "timer/agent.train_min": 0.3513314723968506, "timer/agent.train_max": 1.5160996913909912, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41596484184265137, "timer/agent.report_frac": 0.0008317951361957211, "timer/agent.report_avg": 0.20798242092132568, "timer/agent.report_min": 0.20787930488586426, "timer/agent.report_max": 0.2080855369567871, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 6.436260534803305e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 40.05691206400091}
{"step": 483520, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 483608, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 483632, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 483880, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 483992, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 484440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 485272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 485384, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 485552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 485744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 485920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 485944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 486128, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 486192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 486304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 486600, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052}
{"step": 486656, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 486760, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 487144, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 487544, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444}
{"step": 487864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 488256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 488440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 488504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 488968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 489072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 489456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 489496, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064}
{"step": 489560, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 489856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 490040, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 490048, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 490048, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 490048, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 490048, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 490048, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 490048, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 490048, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 490048, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 490080, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 490176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 490296, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 490752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 490816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 491264, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 491384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 491624, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051}
{"step": 491760, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 491768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 491776, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 491800, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213}
{"step": 491952, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045}
{"step": 492040, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225}
{"step": 492272, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 492640, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 492648, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 492792, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 493048, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 493328, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838}
{"step": 493408, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1}
{"step": 493408, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345}
{"step": 493448, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 493464, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 493576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 493808, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 493808, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 494128, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 494352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 494960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 495128, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308}
{"step": 495200, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714}
{"step": 495552, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667}
{"step": 495784, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417}
{"step": 495888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 496120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 496312, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757}
{"step": 496440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 496496, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839}
{"step": 497040, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 497208, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875}
{"step": 497272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 497720, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005}
{"step": 497760, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633}
{"step": 497840, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705}
{"step": 497864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 498112, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 498152, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 498752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 498896, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761}
{"step": 499192, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 499352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 499904, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 499928, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045}
{"step": 500032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 500032, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 500032, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 500032, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 500032, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 500032, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 500032, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 500032, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 500032, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 500152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 500176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 500216, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 500352, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 500392, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 500608, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207}
{"step": 500672, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 500728, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 500776, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 500888, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 501168, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335}
{"step": 501464, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 501480, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 501480, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 501496, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993}
{"step": 501760, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 502008, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 502032, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357}
{"step": 502056, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 502248, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 502288, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 502504, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 502704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 502752, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 502832, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 502864, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 502920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 503104, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 503416, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315}
{"step": 503673, "train_stats/mean_log_entropy": 0.1735188621541728, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4811507936507935, "train/action_min": 0.0, "train/action_std": 1.742419251373836, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011002220451787469, "train/actor_opt_grad_steps": 30755.0, "train/actor_opt_loss": -0.5307665579612293, "train/adv_mag": 0.4274875729803055, "train/adv_max": 0.23266272033963883, "train/adv_mean": 0.0059385723860551866, "train/adv_min": -0.3341868221759796, "train/adv_std": 0.02988603558494813, "train/cont_avg": 0.9958689856150794, "train/cont_loss_mean": 0.022032228254136584, "train/cont_loss_std": 0.2889724211501224, "train/cont_neg_acc": 0.0526666671037674, "train/cont_neg_loss": 4.376716890335083, "train/cont_pos_acc": 0.9999221218010735, "train/cont_pos_loss": 0.003976418332765914, "train/cont_pred": 0.9958652390374078, "train/cont_rate": 0.9958689856150794, "train/dyn_loss_mean": 1.0000130392256237, "train/dyn_loss_std": 0.0003932623659195434, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1487911484307713, "train/extr_critic_critic_opt_grad_steps": 30755.0, "train/extr_critic_critic_opt_loss": 7439.211604042659, "train/extr_critic_mag": 0.9434550328860207, "train/extr_critic_max": 0.9434550328860207, "train/extr_critic_mean": 0.9162323191052392, "train/extr_critic_min": 0.8833261860741509, "train/extr_critic_std": 0.010191251673469586, "train/extr_return_normed_mag": 0.4384818289961134, "train/extr_return_normed_max": 0.27116507197183276, "train/extr_return_normed_mean": 0.031097340796905983, "train/extr_return_normed_min": -0.30283096385380576, "train/extr_return_normed_std": 0.03248857170166004, "train/extr_return_rate": 0.9988064439523787, "train/extr_return_raw_mag": 1.1622385775286055, "train/extr_return_raw_max": 1.1622385775286055, "train/extr_return_raw_mean": 0.92217089732488, "train/extr_return_raw_min": 0.5882425417029669, "train/extr_return_raw_std": 0.032488571886446264, "train/extr_reward_mag": 0.23664469378335135, "train/extr_reward_max": 0.23664469378335135, "train/extr_reward_mean": 0.002929670150883289, "train/extr_reward_min": 3.453284975082155e-07, "train/extr_reward_std": 0.013537389239192836, "train/image_loss_mean": 0.12666750001528906, "train/image_loss_std": 0.1097135768523292, "train/model_loss_mean": 0.7559704544052245, "train/model_loss_std": 0.41610773368960335, "train/model_opt_grad_norm": 24.861829629020086, "train/model_opt_grad_steps": 30728.0, "train/model_opt_loss": 2850.945525638641, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3769.84126984127, "train/policy_entropy_mag": 1.5387820629846483, "train/policy_entropy_max": 1.5387820629846483, "train/policy_entropy_mean": 0.21492778190544673, "train/policy_entropy_min": 0.06468704396060534, "train/policy_entropy_std": 0.253622200280901, "train/policy_logprob_mag": 6.551079466229393, "train/policy_logprob_max": -0.008608371921120182, "train/policy_logprob_mean": -0.21442455904824392, "train/policy_logprob_min": -6.551079466229393, "train/policy_logprob_std": 0.7396733831791651, "train/policy_randomness_mag": 0.7907776004738278, "train/policy_randomness_max": 0.7907776004738278, "train/policy_randomness_mean": 0.11045103774420799, "train/policy_randomness_min": 0.033242566658863944, "train/policy_randomness_std": 0.13033603539779073, "train/post_ent_mag": 56.77563243442111, "train/post_ent_max": 56.77563243442111, "train/post_ent_mean": 55.60566145276267, "train/post_ent_min": 54.59692679511176, "train/post_ent_std": 0.37693051733667887, "train/prior_ent_mag": 59.00315145462278, "train/prior_ent_max": 59.00315145462278, "train/prior_ent_mean": 55.16560179089743, "train/prior_ent_min": 52.12976376972501, "train/prior_ent_std": 1.1790533245555939, "train/rep_loss_mean": 1.0000130392256237, "train/rep_loss_std": 0.0003932623659195434, "train/reward_avg": 0.0007897271084763656, "train/reward_loss_mean": 0.0072628795834524295, "train/reward_loss_std": 0.14568353862278088, "train/reward_max_data": 0.4859623016109542, "train/reward_max_pred": 0.06542819265335326, "train/reward_neg_acc": 0.9999146522983672, "train/reward_neg_loss": 0.0011401639254357192, "train/reward_pos_acc": 0.07565543122505874, "train/reward_pos_loss": 4.993739986687563, "train/reward_pred": 0.0005891514528128835, "train/reward_rate": 0.001240079365079365, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.027655839920043945, "report/cont_loss_std": 0.3364522457122803, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.3027801513671875, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.006969077046960592, "report/cont_pred": 0.9933217763900757, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.13330113887786865, "report/image_loss_std": 0.13476598262786865, "report/model_loss_mean": 0.7697998285293579, "report/model_loss_std": 0.44046205282211304, "report/post_ent_mag": 55.943172454833984, "report/post_ent_max": 55.943172454833984, "report/post_ent_mean": 54.825862884521484, "report/post_ent_min": 53.61028289794922, "report/post_ent_std": 0.3696407377719879, "report/prior_ent_mag": 56.75599670410156, "report/prior_ent_max": 56.75599670410156, "report/prior_ent_mean": 53.41591262817383, "report/prior_ent_min": 50.550437927246094, "report/prior_ent_std": 1.1086220741271973, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006958007579669356, "report/reward_loss_mean": 0.008842859417200089, "report/reward_loss_std": 0.1457815319299698, "report/reward_max_data": 0.7124999761581421, "report/reward_max_pred": 0.2190316915512085, "report/reward_neg_acc": 0.9980449676513672, "report/reward_neg_loss": 0.004351004492491484, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.604011058807373, "report/reward_pred": 0.0019930987618863583, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0322166308760643, "eval/cont_loss_std": 0.40966999530792236, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.829644680023193, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0037699807435274124, "eval/cont_pred": 0.996268630027771, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18158525228500366, "eval/image_loss_std": 0.12133792042732239, "eval/model_loss_mean": 0.822523832321167, "eval/model_loss_std": 0.5615483522415161, "eval/post_ent_mag": 55.857547760009766, "eval/post_ent_max": 55.857547760009766, "eval/post_ent_mean": 54.6876220703125, "eval/post_ent_min": 53.624088287353516, "eval/post_ent_std": 0.39982491731643677, "eval/prior_ent_mag": 56.77379608154297, "eval/prior_ent_max": 56.77379608154297, "eval/prior_ent_mean": 53.21808624267578, "eval/prior_ent_min": 50.61930847167969, "eval/prior_ent_std": 1.1088099479675293, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008056640508584678, "eval/reward_loss_mean": 0.008721958845853806, "eval/reward_loss_std": 0.22823336720466614, "eval/reward_max_data": 0.824999988079071, "eval/reward_max_pred": 0.22819459438323975, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.0016166550340130925, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.2774481773376465, "eval/reward_pred": 0.0006950481329113245, "eval/reward_rate": 0.0009765625, "replay/size": 503169.0, "replay/inserts": 20176.0, "replay/samples": 20176.0, "replay/insert_wait_avg": 1.1986158463238346e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.116262292219097e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2092643167173433e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 5.960464477539062e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2451717853546, "timer/env.step_count": 2522.0, "timer/env.step_total": 5.15117073059082, "timer/env.step_frac": 0.010297292250131075, "timer/env.step_avg": 0.002042494342026495, "timer/env.step_min": 0.0010673999786376953, "timer/env.step_max": 0.009995698928833008, "timer/replay._sample_count": 20176.0, "timer/replay._sample_total": 1344.8235356807709, "timer/replay._sample_frac": 2.6883288665858593, "timer/replay._sample_avg": 0.06665461616181458, "timer/replay._sample_min": 0.0003974437713623047, "timer/replay._sample_max": 0.0888059139251709, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2883.0, "timer/agent.policy_total": 18.658376932144165, "timer/agent.policy_frac": 0.0372984648018754, "timer/agent.policy_avg": 0.006471861578960862, "timer/agent.policy_min": 0.005060911178588867, "timer/agent.policy_max": 0.009776592254638672, "timer/dataset_train_count": 1261.0, "timer/dataset_train_total": 0.09464693069458008, "timer/dataset_train_frac": 0.00018920108785216067, "timer/dataset_train_avg": 7.505704258095169e-05, "timer/dataset_train_min": 5.936622619628906e-05, "timer/dataset_train_max": 0.0001277923583984375, "timer/agent.train_count": 1261.0, "timer/agent.train_total": 469.9993758201599, "timer/agent.train_frac": 0.939538055195518, "timer/agent.train_avg": 0.37271956845373505, "timer/agent.train_min": 0.35179567337036133, "timer/agent.train_max": 0.4185972213745117, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.42026686668395996, "timer/agent.report_frac": 0.0008401217850520069, "timer/agent.report_avg": 0.21013343334197998, "timer/agent.report_min": 0.20877957344055176, "timer/agent.report_max": 0.2114872932434082, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 6.624788076782676e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 40.33156545581501}
{"step": 503848, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 504144, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625}
{"step": 504344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 504344, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704}
{"step": 504672, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621}
{"step": 504680, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 505016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 505176, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 505304, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 505416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 505528, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 505728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 506096, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 506168, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 506264, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 506656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 506656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 506712, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 506808, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 507080, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 507304, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 507328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 507336, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 507616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 507728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 507904, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 508184, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 508216, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 508288, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 508480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 508608, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629}
{"step": 508712, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 509024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 509072, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 509080, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 509384, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 509536, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 509576, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609}
{"step": 509640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 509800, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 509904, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304}
{"step": 509928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 510016, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 510016, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 510016, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 510016, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 510016, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 510016, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 510016, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 510016, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 510016, "eval_episode/length": 178.0, "eval_episode/score": 0.4437499940395355, "eval_episode/reward_rate": 0.00558659217877095}
{"step": 510048, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 510792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 511392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 511696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 511808, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617}
{"step": 512016, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045}
{"step": 512112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 512120, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169}
{"step": 512152, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642}
{"step": 512328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 512600, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391}
{"step": 512656, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 513432, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 514120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 514328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 514424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 514432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 514464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 514640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 514912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 515744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 516056, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704}
{"step": 516368, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098}
{"step": 516432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 516736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 516744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 516872, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 516952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 516992, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464}
{"step": 518368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 518680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 518744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 519048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 519056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 519184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 519264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 519304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 520000, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 520000, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 520000, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 520000, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 520000, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 520000, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 520000, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 520000, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 520512, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055}
{"step": 520552, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641}
{"step": 520680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 520904, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736}
{"step": 521304, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 521360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 521368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 521496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 521568, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 521576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 521648, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 521848, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 522128, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 522168, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 522464, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 522864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 523672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 523680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 523721, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.64545361328125, "train/action_min": 0.0, "train/action_std": 1.8228291082382202, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.017176619235426186, "train/actor_opt_grad_steps": 32010.0, "train/actor_opt_loss": 1.0117546696662902, "train/adv_mag": 0.7530940418243408, "train/adv_max": 0.30809610319137576, "train/adv_mean": 0.009670714821550064, "train/adv_min": -0.6967571601867676, "train/adv_std": 0.048525795344263316, "train/cont_avg": 0.9957578125, "train/cont_loss_mean": 0.02088159605488181, "train/cont_loss_std": 0.2779289685189724, "train/cont_neg_acc": 0.0887841284275055, "train/cont_neg_loss": 3.9878802959918977, "train/cont_pos_acc": 0.999866503238678, "train/cont_pos_loss": 0.003928806096315384, "train/cont_pred": 0.9957445168495178, "train/cont_rate": 0.9957578125, "train/dyn_loss_mean": 1.8890057764053345, "train/dyn_loss_std": 0.020214970607572467, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9800648859143257, "train/extr_critic_critic_opt_grad_steps": 32010.0, "train/extr_critic_critic_opt_loss": 11729.52546875, "train/extr_critic_mag": 1.0830035037994385, "train/extr_critic_max": 1.0830035037994385, "train/extr_critic_mean": 1.049936731338501, "train/extr_critic_min": 1.003623830795288, "train/extr_critic_std": 0.014030450094491243, "train/extr_return_normed_mag": 0.7282612562179566, "train/extr_return_normed_max": 0.3736187257766724, "train/extr_return_normed_mean": 0.060096843883395194, "train/extr_return_normed_min": -0.641650978565216, "train/extr_return_normed_std": 0.05211965487897396, "train/extr_return_rate": 0.9977292051315307, "train/extr_return_raw_mag": 1.3731292786598206, "train/extr_return_raw_max": 1.3731292786598206, "train/extr_return_raw_mean": 1.0596074571609497, "train/extr_return_raw_min": 0.35785957431793214, "train/extr_return_raw_std": 0.05211965537071228, "train/extr_reward_mag": 0.3041274003982544, "train/extr_reward_max": 0.3041274003982544, "train/extr_reward_mean": 0.0039515213703271, "train/extr_reward_min": 1.5544891357421876e-07, "train/extr_reward_std": 0.018972381407395007, "train/image_loss_mean": 0.11777013230323792, "train/image_loss_std": 0.10668160808086395, "train/model_loss_mean": 1.2790490202903748, "train/model_loss_std": 0.4090582852959633, "train/model_opt_grad_norm": 26.599374526977538, "train/model_opt_grad_steps": 31982.0, "train/model_opt_loss": 3550.9345185546877, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3000.0, "train/policy_entropy_mag": 1.5040124320983888, "train/policy_entropy_max": 1.5040124320983888, "train/policy_entropy_mean": 0.17703921020030974, "train/policy_entropy_min": 0.0646868035197258, "train/policy_entropy_std": 0.22115617644786834, "train/policy_logprob_mag": 6.5510799522399905, "train/policy_logprob_max": -0.008608284838497638, "train/policy_logprob_mean": -0.17722595977783204, "train/policy_logprob_min": -6.5510799522399905, "train/policy_logprob_std": 0.7114174871444702, "train/policy_randomness_mag": 0.7729095411300659, "train/policy_randomness_max": 0.7729095411300659, "train/policy_randomness_mean": 0.09098016196489334, "train/policy_randomness_min": 0.03324244272708893, "train/policy_randomness_std": 0.11365179824829101, "train/post_ent_mag": 59.549685485839845, "train/post_ent_max": 59.549685485839845, "train/post_ent_mean": 58.13762005615234, "train/post_ent_min": 56.989816955566404, "train/post_ent_std": 0.45079318833351134, "train/prior_ent_mag": 60.77628393554688, "train/prior_ent_max": 60.77628393554688, "train/prior_ent_mean": 57.36450207519531, "train/prior_ent_min": 54.85424969482422, "train/prior_ent_std": 0.9221370415687561, "train/rep_loss_mean": 1.8890057764053345, "train/rep_loss_std": 0.020214970607572467, "train/reward_avg": 0.0007766357443761081, "train/reward_loss_mean": 0.006993767749518156, "train/reward_loss_std": 0.13864016422070563, "train/reward_max_data": 0.5124500012397766, "train/reward_max_pred": 0.07923612880706787, "train/reward_neg_acc": 0.9998512992858887, "train/reward_neg_loss": 0.0012797827955801039, "train/reward_pos_acc": 0.06759259303410849, "train/reward_pos_loss": 4.793654951784346, "train/reward_pred": 0.0006600338928401471, "train/reward_rate": 0.0012109375, "train_stats/mean_log_entropy": 0.14703812792289014, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.00972980260848999, "report/cont_loss_std": 0.12661713361740112, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.8538565635681152, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00416399585083127, "report/cont_pred": 0.9958195686340332, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.000004529953003, "report/dyn_loss_std": 0.0001439270272385329, "report/image_loss_mean": 0.10373681783676147, "report/image_loss_std": 0.10354376584291458, "report/model_loss_mean": 0.7192767858505249, "report/model_loss_std": 0.25872179865837097, "report/post_ent_mag": 59.34806823730469, "report/post_ent_max": 59.34806823730469, "report/post_ent_mean": 58.014503479003906, "report/post_ent_min": 57.03341293334961, "report/post_ent_std": 0.39724522829055786, "report/prior_ent_mag": 61.52684783935547, "report/prior_ent_max": 61.52684783935547, "report/prior_ent_mean": 57.94282913208008, "report/prior_ent_min": 55.12785720825195, "report/prior_ent_std": 0.9896624088287354, "report/rep_loss_mean": 1.000004529953003, "report/rep_loss_std": 0.0001439270272385329, "report/reward_avg": 0.0006042480235919356, "report/reward_loss_mean": 0.0058074831031262875, "report/reward_loss_std": 0.11857709288597107, "report/reward_max_data": 0.6187499761581421, "report/reward_max_pred": 0.06040918827056885, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002111971378326416, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.78631591796875, "report/reward_pred": 0.0010646050795912743, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02833186276257038, "eval/cont_loss_std": 0.41338077187538147, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.616686820983887, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0024951763916760683, "eval/cont_pred": 0.9975534081459045, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0000414848327637, "eval/dyn_loss_std": 0.0009659609640948474, "eval/image_loss_mean": 0.2174246907234192, "eval/image_loss_std": 0.14922945201396942, "eval/model_loss_mean": 0.8460308313369751, "eval/model_loss_std": 0.4322616159915924, "eval/post_ent_mag": 59.331947326660156, "eval/post_ent_max": 59.331947326660156, "eval/post_ent_mean": 57.949729919433594, "eval/post_ent_min": 56.990806579589844, "eval/post_ent_std": 0.4315570592880249, "eval/prior_ent_mag": 62.46287536621094, "eval/prior_ent_max": 62.46287536621094, "eval/prior_ent_mean": 58.00605392456055, "eval/prior_ent_min": 55.46110534667969, "eval/prior_ent_std": 0.9993849396705627, "eval/rep_loss_mean": 1.0000414848327637, "eval/rep_loss_std": 0.0009659609640948474, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00024935323745012283, "eval/reward_loss_std": 0.0018585211364552379, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.01802682876586914, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00024935323745012283, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00012216158211231232, "eval/reward_rate": 0.0, "replay/size": 523217.0, "replay/inserts": 20048.0, "replay/samples": 20048.0, "replay/insert_wait_avg": 1.1972898687254592e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.18472405880428e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.239520247264575e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.04696106910706, "timer/env.step_count": 2506.0, "timer/env.step_total": 5.0387701988220215, "timer/env.step_frac": 0.010076593982391302, "timer/env.step_avg": 0.0020106824416688033, "timer/env.step_min": 0.0010118484497070312, "timer/env.step_max": 0.00777888298034668, "timer/replay._sample_count": 20048.0, "timer/replay._sample_total": 1333.918303012848, "timer/replay._sample_frac": 2.6675860606390103, "timer/replay._sample_avg": 0.06653622820295531, "timer/replay._sample_min": 0.00033736228942871094, "timer/replay._sample_max": 0.08961677551269531, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3064.0, "timer/agent.policy_total": 19.90125060081482, "timer/agent.policy_frac": 0.03979876321669005, "timer/agent.policy_avg": 0.00649518622741998, "timer/agent.policy_min": 0.005170345306396484, "timer/agent.policy_max": 0.010153532028198242, "timer/dataset_train_count": 1253.0, "timer/dataset_train_total": 0.09486913681030273, "timer/dataset_train_frac": 0.0001897204546698399, "timer/dataset_train_avg": 7.571359681588406e-05, "timer/dataset_train_min": 5.507469177246094e-05, "timer/dataset_train_max": 0.0001990795135498047, "timer/agent.train_count": 1253.0, "timer/agent.train_total": 468.698025226593, "timer/agent.train_frac": 0.937308016480113, "timer/agent.train_avg": 0.37406067456232484, "timer/agent.train_min": 0.34763026237487793, "timer/agent.train_max": 0.440065860748291, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.42148733139038086, "timer/agent.report_frac": 0.0008428954962334644, "timer/agent.report_avg": 0.21074366569519043, "timer/agent.report_min": 0.21057772636413574, "timer/agent.report_max": 0.21090960502624512, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 6.293659374335622e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 40.0916049250815}
{"step": 523888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 524160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 524440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 524480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 524776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 525040, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294}
{"step": 525240, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609}
{"step": 525560, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 525616, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856}
{"step": 525664, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213}
{"step": 525792, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609}
{"step": 525992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 526160, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 526296, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357}
{"step": 526520, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 526648, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 526744, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213}
{"step": 526872, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 526888, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 527088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 527088, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 527400, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 527544, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 527560, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 527688, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609}
{"step": 527912, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 527976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 528024, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 528104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 528128, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 528576, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 528712, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756}
{"step": 528904, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 528992, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 529400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 529552, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 529704, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 529752, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045}
{"step": 529792, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333}
{"step": 529824, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715}
{"step": 529880, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456}
{"step": 529888, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 530088, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 530088, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 530088, "eval_episode/length": 269.0, "eval_episode/score": 0.15937499701976776, "eval_episode/reward_rate": 0.003703703703703704}
{"step": 530088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530112, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714}
{"step": 530168, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895}
{"step": 530904, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 531360, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 531712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 531784, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311}
{"step": 531824, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 531992, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015}
{"step": 532064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 532136, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475}
{"step": 532192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 532200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 532296, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 532608, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 532784, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 532904, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 532944, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 532952, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 533000, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 533304, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 533432, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 533528, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 533560, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 533560, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576}
{"step": 533560, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 533720, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842}
{"step": 533800, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 534032, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 534104, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 534488, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 534616, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 534696, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761}
{"step": 534712, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 534832, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838}
{"step": 534936, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 535168, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 535296, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 535432, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 535608, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 535744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 535872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 536440, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 536456, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 536488, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 536600, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907}
{"step": 536928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 537208, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 537328, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 537480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 537608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 537696, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 537744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 537752, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 537792, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374}
{"step": 538816, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976}
{"step": 538888, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182}
{"step": 539016, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633}
{"step": 539264, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652}
{"step": 539320, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 539520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 539600, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 539712, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142}
{"step": 539768, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 539768, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861}
{"step": 539792, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 539920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 540056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 540072, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 540072, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 540072, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 540072, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 540072, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 540072, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 540072, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 540072, "eval_episode/length": 209.0, "eval_episode/score": 0.34687501192092896, "eval_episode/reward_rate": 0.004761904761904762}
{"step": 540104, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564}
{"step": 540224, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 540328, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 540360, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 540656, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 540680, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705}
{"step": 540984, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 541240, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 541264, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 541504, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 541624, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 541960, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 542040, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 542080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 542080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 542224, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 542456, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655}
{"step": 542640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 542656, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 542928, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 542984, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 542992, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 542992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 543112, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 543472, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 543488, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 543728, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 543784, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 543816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 543929, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6911417643229165, "train/action_min": 0.0, "train/action_std": 1.6138757495653062, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.014208587902849392, "train/actor_opt_grad_steps": 33265.0, "train/actor_opt_loss": -6.5328630117906465, "train/adv_mag": 0.8864181912134564, "train/adv_max": 0.29279999600516426, "train/adv_mean": 0.0023330015300171143, "train/adv_min": -0.8558094387962705, "train/adv_std": 0.045829881655259266, "train/cont_avg": 0.9956287202380952, "train/cont_loss_mean": 0.018960433210142784, "train/cont_loss_std": 0.26162523182020303, "train/cont_neg_acc": 0.1651171605501856, "train/cont_neg_loss": 3.566515327919097, "train/cont_pos_acc": 0.9998598581268674, "train/cont_pos_loss": 0.0034973127601136056, "train/cont_pred": 0.9958563305082775, "train/cont_rate": 0.9956287202380952, "train/dyn_loss_mean": 1.000021357384939, "train/dyn_loss_std": 0.0005574197139284234, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5072461694833779, "train/extr_critic_critic_opt_grad_steps": 33265.0, "train/extr_critic_critic_opt_loss": 11876.609351748511, "train/extr_critic_mag": 1.1449173083381048, "train/extr_critic_max": 1.1449173083381048, "train/extr_critic_mean": 1.1051581965552435, "train/extr_critic_min": 1.0633537409797547, "train/extr_critic_std": 0.012073458035639117, "train/extr_return_normed_mag": 0.8680486272251795, "train/extr_return_normed_max": 0.34617580307854545, "train/extr_return_normed_mean": 0.03206052676227594, "train/extr_return_normed_min": -0.8236973342441377, "train/extr_return_normed_std": 0.04834032112673398, "train/extr_return_rate": 0.9976072065413945, "train/extr_return_raw_mag": 1.4216064233628531, "train/extr_return_raw_max": 1.4216064233628531, "train/extr_return_raw_mean": 1.1074911895252408, "train/extr_return_raw_min": 0.25173328604016987, "train/extr_return_raw_std": 0.04834032077194443, "train/extr_reward_mag": 0.3391591424033755, "train/extr_reward_max": 0.3391591424033755, "train/extr_reward_mean": 0.0028206013817070347, "train/extr_reward_min": 1.3907750447591147e-07, "train/extr_reward_std": 0.013882101101372096, "train/image_loss_mean": 0.11408771314318218, "train/image_loss_std": 0.10678354041680457, "train/model_loss_mean": 0.7409459532253326, "train/model_loss_std": 0.40007620210212375, "train/model_opt_grad_norm": 24.116586185636976, "train/model_opt_grad_steps": 33236.65079365079, "train/model_opt_loss": 3883.400318932912, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5238.0952380952385, "train/policy_entropy_mag": 1.388281674612136, "train/policy_entropy_max": 1.388281674612136, "train/policy_entropy_mean": 0.14251349215942716, "train/policy_entropy_min": 0.06468667462468147, "train/policy_entropy_std": 0.1827484126247111, "train/policy_logprob_mag": 6.551080219329349, "train/policy_logprob_max": -0.008608220788162379, "train/policy_logprob_mean": -0.1428170566047941, "train/policy_logprob_min": -6.551080219329349, "train/policy_logprob_std": 0.6794613339598217, "train/policy_randomness_mag": 0.7134356929196252, "train/policy_randomness_max": 0.7134356929196252, "train/policy_randomness_mean": 0.07323745203514893, "train/policy_randomness_min": 0.033242376521229744, "train/policy_randomness_std": 0.09391411216486067, "train/post_ent_mag": 58.71167285858639, "train/post_ent_max": 58.71167285858639, "train/post_ent_mean": 57.339020017593626, "train/post_ent_min": 56.26110325162373, "train/post_ent_std": 0.42897890886617085, "train/prior_ent_mag": 60.87491447206528, "train/prior_ent_max": 60.87491447206528, "train/prior_ent_mean": 57.4019657316662, "train/prior_ent_min": 54.525757683648, "train/prior_ent_std": 1.077767036263905, "train/rep_loss_mean": 1.000021357384939, "train/rep_loss_std": 0.0005574197139284234, "train/reward_avg": 0.000957452682621171, "train/reward_loss_mean": 0.007884968881539646, "train/reward_loss_std": 0.1516040216573322, "train/reward_max_data": 0.5624503963996493, "train/reward_max_pred": 0.11739836231110588, "train/reward_neg_acc": 0.9997903520152682, "train/reward_neg_loss": 0.001280613388290577, "train/reward_pos_acc": 0.1420875426494714, "train/reward_pos_loss": 4.476470587229488, "train/reward_pred": 0.0006912572425790131, "train/reward_rate": 0.00146484375, "train_stats/mean_log_entropy": 0.11621606425530669, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.01847788318991661, "report/cont_loss_std": 0.2830142080783844, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.676450729370117, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002812034450471401, "report/cont_pred": 0.9951746463775635, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12876220047473907, "report/image_loss_std": 0.10542911291122437, "report/model_loss_mean": 0.7522983551025391, "report/model_loss_std": 0.37035563588142395, "report/post_ent_mag": 57.62324523925781, "report/post_ent_max": 57.62324523925781, "report/post_ent_mean": 56.11957550048828, "report/post_ent_min": 54.97615051269531, "report/post_ent_std": 0.47625768184661865, "report/prior_ent_mag": 60.22679138183594, "report/prior_ent_max": 60.22679138183594, "report/prior_ent_mean": 56.698631286621094, "report/prior_ent_min": 53.75890350341797, "report/prior_ent_std": 1.1755985021591187, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004058837948832661, "report/reward_loss_mean": 0.005058238282799721, "report/reward_loss_std": 0.14277206361293793, "report/reward_max_data": 0.4156250059604645, "report/reward_max_pred": 0.029135704040527344, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005958157125860453, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.5701165199279785, "report/reward_pred": 0.0003143956419080496, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03247169777750969, "eval/cont_loss_std": 0.4404878318309784, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.052332401275635, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0029336181469261646, "eval/cont_pred": 0.9970637559890747, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16697192192077637, "eval/image_loss_std": 0.13422074913978577, "eval/model_loss_mean": 0.8047692775726318, "eval/model_loss_std": 0.5200720429420471, "eval/post_ent_mag": 57.56283187866211, "eval/post_ent_max": 57.56283187866211, "eval/post_ent_mean": 56.11918258666992, "eval/post_ent_min": 55.024192810058594, "eval/post_ent_std": 0.47321727871894836, "eval/prior_ent_mag": 59.71500015258789, "eval/prior_ent_max": 59.71500015258789, "eval/prior_ent_mean": 56.72578430175781, "eval/prior_ent_min": 53.50437927246094, "eval/prior_ent_std": 1.1038541793823242, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0004760742303915322, "eval/reward_loss_mean": 0.005325648933649063, "eval/reward_loss_std": 0.1567331701517105, "eval/reward_max_data": 0.48750001192092896, "eval/reward_max_pred": 0.024153709411621094, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0004260183486621827, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.017647743225098, "eval/reward_pred": 0.00021534389816224575, "eval/reward_rate": 0.0009765625, "replay/size": 543425.0, "replay/inserts": 20208.0, "replay/samples": 20208.0, "replay/insert_wait_avg": 1.203289413301131e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.164910004616538e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3992.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2043363345648818e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.109476089477539e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2213008403778, "timer/env.step_count": 2526.0, "timer/env.step_total": 5.231381893157959, "timer/env.step_frac": 0.010458134998188151, "timer/env.step_avg": 0.0020710142094845442, "timer/env.step_min": 0.0010979175567626953, "timer/env.step_max": 0.00792694091796875, "timer/replay._sample_count": 20208.0, "timer/replay._sample_total": 1348.8177309036255, "timer/replay._sample_frac": 2.6964420120406616, "timer/replay._sample_avg": 0.06674672065041694, "timer/replay._sample_min": 0.0004277229309082031, "timer/replay._sample_max": 0.08908820152282715, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3025.0, "timer/agent.policy_total": 19.582016706466675, "timer/agent.policy_frac": 0.03914670701461263, "timer/agent.policy_avg": 0.006473393952550967, "timer/agent.policy_min": 0.004683494567871094, "timer/agent.policy_max": 0.009483575820922852, "timer/dataset_train_count": 1263.0, "timer/dataset_train_total": 0.09432244300842285, "timer/dataset_train_frac": 0.000188561428411705, "timer/dataset_train_avg": 7.468126920698563e-05, "timer/dataset_train_min": 5.793571472167969e-05, "timer/dataset_train_max": 0.00013184547424316406, "timer/agent.train_count": 1263.0, "timer/agent.train_total": 468.9094281196594, "timer/agent.train_frac": 0.9374039596712214, "timer/agent.train_avg": 0.3712663722245918, "timer/agent.train_min": 0.35207509994506836, "timer/agent.train_max": 0.41866064071655273, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4191715717315674, "timer/agent.report_frac": 0.0008379722555344087, "timer/agent.report_avg": 0.2095857858657837, "timer/agent.report_min": 0.20942091941833496, "timer/agent.report_max": 0.20975065231323242, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 7.006405178877712e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 40.39737565543159}
{"step": 544048, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 544416, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 544552, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 544800, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903}
{"step": 544816, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 544968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 545008, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 545160, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 545240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 545304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 545344, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 545528, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 545656, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 545784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 545800, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 545896, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 545992, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 546128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 546168, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 546232, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 546416, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 546664, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 546744, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 546760, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 546888, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 547024, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 547144, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667}
{"step": 547232, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 547312, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 547320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 547504, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 547552, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135}
{"step": 547816, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444}
{"step": 547896, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 548080, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 548112, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 548640, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 548696, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 548712, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 548728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 549072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 549368, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732}
{"step": 549392, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 549408, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 549624, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 549624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 549792, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 549984, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 550048, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 550056, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 550056, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 550056, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 550056, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 550056, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 550056, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 550056, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 550056, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 550208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 550208, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 550256, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464}
{"step": 550336, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 550376, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 550464, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464}
{"step": 550616, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 550728, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 550816, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 550848, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301}
{"step": 550944, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 551104, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 551240, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 551272, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 551384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 551576, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 551632, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 551928, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 552208, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 552480, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 552648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 552768, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154}
{"step": 553040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 553336, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 553416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 553584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 553688, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 553696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 553848, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 554032, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 554184, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 554424, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 554520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 554528, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154}
{"step": 554792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 554832, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 554976, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 555136, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 555416, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 555552, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 555584, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 555592, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 555648, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 555896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 555952, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 556000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 556096, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 556304, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 556648, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 556840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 556888, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839}
{"step": 556896, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 557040, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 557264, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 557568, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 557624, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 557728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 557760, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 557904, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 557992, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 558064, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 558200, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464}
{"step": 558208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 558304, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 558448, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 558520, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 558784, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 558936, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 558960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 558968, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 559056, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444}
{"step": 559064, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 559200, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 559264, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 559408, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 559576, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 559704, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 559944, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 560040, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 560040, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 560040, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 560040, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 560040, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 560040, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 560040, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 560040, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 560088, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 560608, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 560728, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 561080, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 561368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 561464, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 561512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 561576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 561720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 561888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 561912, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 561912, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 562016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 562064, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 562240, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 562256, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 562464, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 562752, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 562792, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 562872, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 562872, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 563640, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 563728, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 563864, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 564073, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3534192282056052, "train/action_min": 0.0, "train/action_std": 1.68302036183221, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010685588162954129, "train/actor_opt_grad_steps": 34525.0, "train/actor_opt_loss": -4.658633761226185, "train/adv_mag": 0.9697190258238051, "train/adv_max": 0.27500866613690816, "train/adv_mean": 0.0034837992241533817, "train/adv_min": -0.9466419721406604, "train/adv_std": 0.03740833723355853, "train/cont_avg": 0.9955279637896826, "train/cont_loss_mean": 0.017508068216210676, "train/cont_loss_std": 0.2505399409445032, "train/cont_neg_acc": 0.2714947135675521, "train/cont_neg_loss": 3.113885468433774, "train/cont_pos_acc": 0.9997429852447812, "train/cont_pos_loss": 0.003635545732409117, "train/cont_pred": 0.995460252440165, "train/cont_rate": 0.9955279637896826, "train/dyn_loss_mean": 1.0000209865115939, "train/dyn_loss_std": 0.000660152520681766, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.44337134290900493, "train/extr_critic_critic_opt_grad_steps": 34525.0, "train/extr_critic_critic_opt_loss": 5347.6280517578125, "train/extr_critic_mag": 1.2055554125044081, "train/extr_critic_max": 1.2055554125044081, "train/extr_critic_mean": 1.1752944323751662, "train/extr_critic_min": 1.1362971521559215, "train/extr_critic_std": 0.009916383396124556, "train/extr_return_normed_mag": 0.9527450667487251, "train/extr_return_normed_max": 0.32070728332277326, "train/extr_return_normed_mean": 0.03359315160750633, "train/extr_return_normed_min": -0.9211310072550698, "train/extr_return_normed_std": 0.039697942146587936, "train/extr_return_rate": 0.9985429502668834, "train/extr_return_raw_mag": 1.4658923054498338, "train/extr_return_raw_max": 1.4658923054498338, "train/extr_return_raw_mean": 1.1787782415511117, "train/extr_return_raw_min": 0.22405401487199086, "train/extr_return_raw_std": 0.039697942013541855, "train/extr_reward_mag": 0.34340788258446586, "train/extr_reward_max": 0.34340788258446586, "train/extr_reward_mean": 0.003196778230457788, "train/extr_reward_min": 1.3718529353066095e-07, "train/extr_reward_std": 0.011898653873700708, "train/image_loss_mean": 0.111789373710515, "train/image_loss_std": 0.10738390630909375, "train/model_loss_mean": 0.7372019702479953, "train/model_loss_std": 0.38538006391553653, "train/model_opt_grad_norm": 23.069271049802264, "train/model_opt_grad_steps": 34495.47619047619, "train/model_opt_loss": 3802.0111103360614, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5158.730158730159, "train/policy_entropy_mag": 1.340071543814644, "train/policy_entropy_max": 1.340071543814644, "train/policy_entropy_mean": 0.11390809200349308, "train/policy_entropy_min": 0.064686562215525, "train/policy_entropy_std": 0.14661715948392476, "train/policy_logprob_mag": 6.5510802571735685, "train/policy_logprob_max": -0.008608140058756347, "train/policy_logprob_mean": -0.1135590197074981, "train/policy_logprob_min": -6.5510802571735685, "train/policy_logprob_std": 0.6475997382686252, "train/policy_randomness_mag": 0.688660584744953, "train/policy_randomness_max": 0.688660584744953, "train/policy_randomness_mean": 0.05853718288597606, "train/policy_randomness_min": 0.03324232031665151, "train/policy_randomness_std": 0.0753463197440382, "train/post_ent_mag": 57.02435711451939, "train/post_ent_max": 57.02435711451939, "train/post_ent_mean": 55.691700587196955, "train/post_ent_min": 54.6419868771992, "train/post_ent_std": 0.41714151865906185, "train/prior_ent_mag": 59.821641982547824, "train/prior_ent_max": 59.821641982547824, "train/prior_ent_mean": 55.81404195513044, "train/prior_ent_min": 52.665534428187776, "train/prior_ent_std": 1.208193788452754, "train/rep_loss_mean": 1.0000209865115939, "train/rep_loss_std": 0.000660152520681766, "train/reward_avg": 0.001016501772345879, "train/reward_loss_mean": 0.007891910989576626, "train/reward_loss_std": 0.14782420260391, "train/reward_max_data": 0.5767609130532022, "train/reward_max_pred": 0.1562074971577478, "train/reward_neg_acc": 0.9997827036986275, "train/reward_neg_loss": 0.001428325112635595, "train/reward_pos_acc": 0.20016666784882545, "train/reward_pos_loss": 4.088010516166687, "train/reward_pred": 0.0007997223310956051, "train/reward_rate": 0.0015500992063492063, "train_stats/mean_log_entropy": 0.09783375001703666, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.018717234954237938, "report/cont_loss_std": 0.26218175888061523, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.571035146713257, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004786576144397259, "report/cont_pred": 0.9949720501899719, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0863940641283989, "report/image_loss_std": 0.10064618289470673, "report/model_loss_mean": 0.7126968502998352, "report/model_loss_std": 0.3484717309474945, "report/post_ent_mag": 56.22277069091797, "report/post_ent_max": 56.22277069091797, "report/post_ent_mean": 54.94127655029297, "report/post_ent_min": 53.9234619140625, "report/post_ent_std": 0.41385188698768616, "report/prior_ent_mag": 59.74318313598633, "report/prior_ent_max": 59.74318313598633, "report/prior_ent_mean": 54.983726501464844, "report/prior_ent_min": 52.02824020385742, "report/prior_ent_std": 1.3159127235412598, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00146484375, "report/reward_loss_mean": 0.007585515268146992, "report/reward_loss_std": 0.11904320120811462, "report/reward_max_data": 0.7593749761581421, "report/reward_max_pred": 0.20785212516784668, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.0025234699714928865, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.594290256500244, "report/reward_pred": 0.0014560630079358816, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.013319728896021843, "eval/cont_loss_std": 0.20044226944446564, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.788224220275879, "eval/cont_pos_acc": 0.9990224838256836, "eval/cont_pos_loss": 0.007674660068005323, "eval/cont_pred": 0.9944073557853699, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18210628628730774, "eval/image_loss_std": 0.14916887879371643, "eval/model_loss_mean": 0.7971566915512085, "eval/model_loss_std": 0.24999529123306274, "eval/post_ent_mag": 56.22138977050781, "eval/post_ent_max": 56.22138977050781, "eval/post_ent_mean": 54.82660675048828, "eval/post_ent_min": 53.80451583862305, "eval/post_ent_std": 0.4106200337409973, "eval/prior_ent_mag": 59.74318313598633, "eval/prior_ent_max": 59.74318313598633, "eval/prior_ent_mean": 54.90212631225586, "eval/prior_ent_min": 51.688411712646484, "eval/prior_ent_std": 1.35011887550354, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0017306089866906404, "eval/reward_loss_std": 0.018988285213708878, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.16430890560150146, "eval/reward_neg_acc": 0.9970703125, "eval/reward_neg_loss": 0.0017306089866906404, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0008145702304318547, "eval/reward_rate": 0.0, "replay/size": 563569.0, "replay/inserts": 20144.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.194081295095236e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.210790490233018e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2096.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.220643975352513e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.02759766578674, "timer/env.step_count": 2518.0, "timer/env.step_total": 5.330080270767212, "timer/env.step_frac": 0.010659572182913357, "timer/env.step_avg": 0.0021167912115834836, "timer/env.step_min": 0.001104116439819336, "timer/env.step_max": 0.008061647415161133, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 1340.8969781398773, "timer/replay._sample_frac": 2.6816459419428265, "timer/replay._sample_avg": 0.06656557675436246, "timer/replay._sample_min": 0.0004291534423828125, "timer/replay._sample_max": 0.08949446678161621, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2780.0, "timer/agent.policy_total": 18.048348665237427, "timer/agent.policy_frac": 0.0360947050712604, "timer/agent.policy_avg": 0.006492211750085406, "timer/agent.policy_min": 0.004993438720703125, "timer/agent.policy_max": 0.00988149642944336, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.0950477123260498, "timer/dataset_train_frac": 0.00019008493285120376, "timer/dataset_train_avg": 7.549460867835569e-05, "timer/dataset_train_min": 5.459785461425781e-05, "timer/dataset_train_max": 0.0001399517059326172, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 470.8155677318573, "timer/agent.train_frac": 0.9415791646895169, "timer/agent.train_avg": 0.3739599425987747, "timer/agent.train_min": 0.35282015800476074, "timer/agent.train_max": 0.4182109832763672, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4200878143310547, "timer/agent.report_frac": 0.0008401292574491799, "timer/agent.report_avg": 0.21004390716552734, "timer/agent.report_min": 0.20990896224975586, "timer/agent.report_max": 0.21017885208129883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 6.627670682542554e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 40.28514217130131}
{"step": 564224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 564312, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 564328, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495}
{"step": 564328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 564376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 564568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 564640, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564}
{"step": 564768, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 564936, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 564984, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 565176, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 565200, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 565296, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 565688, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 565688, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 565784, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652}
{"step": 566064, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 566080, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 566176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 566512, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 566624, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 566624, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875}
{"step": 566856, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315}
{"step": 566912, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 567088, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 567176, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 567192, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 567296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 567608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 567632, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 567864, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 568192, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 568400, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 568416, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 568824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 569168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 569224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 569296, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 569360, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 569400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 569624, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025}
{"step": 569944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 569968, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 570024, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 570024, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 570024, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 570024, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 570024, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 570024, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 570024, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 570024, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 570480, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357}
{"step": 570480, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 570504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 570712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 570768, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993}
{"step": 570808, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 571264, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 571384, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 571632, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 571712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 571760, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 572256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 572280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 572576, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 572592, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 573080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 573576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 573696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 573696, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 573960, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269}
{"step": 574024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 574232, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 574264, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129}
{"step": 574568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 574888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 575440, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294}
{"step": 575576, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 575640, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093}
{"step": 576008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 576008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 576176, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453}
{"step": 576272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 576544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 576744, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315}
{"step": 576864, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 576976, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 577304, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 577656, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 577752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 577952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 578256, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 578488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 578552, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 578568, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 578584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 579000, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 579032, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 579176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 579288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 579416, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 579560, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374}
{"step": 579616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 579664, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 579896, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 580000, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 580008, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 580008, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 580008, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 580008, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 580008, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 580008, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 580008, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 580008, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 580128, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 580136, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 580232, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 580528, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 580712, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 580744, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 580880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 580992, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 581168, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 581448, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 581472, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 581488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 581512, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736}
{"step": 581592, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 581688, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 582016, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 582248, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 582344, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 582440, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 582504, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 582544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 582664, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 582712, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 582824, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 582832, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705}
{"step": 582840, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456}
{"step": 582848, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 583048, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035}
{"step": 583080, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 583496, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 583552, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 583664, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 583680, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216}
{"step": 583760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 583840, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 584032, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391}
{"step": 584120, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 584153, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2343929230220736, "train/action_min": 0.0, "train/action_std": 1.6816150990743486, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013149705499277584, "train/actor_opt_grad_steps": 35785.0, "train/actor_opt_loss": -7.941927999494568, "train/adv_mag": 1.0173373279117404, "train/adv_max": 0.30604702423489283, "train/adv_mean": 0.0034009072755474164, "train/adv_min": -0.9862896014773657, "train/adv_std": 0.04391281524052223, "train/cont_avg": 0.9955047123015873, "train/cont_loss_mean": 0.01722055809786691, "train/cont_loss_std": 0.24426421098825005, "train/cont_neg_acc": 0.26318027682247613, "train/cont_neg_loss": 3.122953625891121, "train/cont_pos_acc": 0.9998287251071324, "train/cont_pos_loss": 0.003349318101610397, "train/cont_pred": 0.9956160088380178, "train/cont_rate": 0.9955047123015873, "train/dyn_loss_mean": 1.0000082840995184, "train/dyn_loss_std": 0.00025287741000139496, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5858043018314574, "train/extr_critic_critic_opt_grad_steps": 35785.0, "train/extr_critic_critic_opt_loss": 4537.499815925719, "train/extr_critic_mag": 1.2643432030602106, "train/extr_critic_max": 1.2643432030602106, "train/extr_critic_mean": 1.2147694031397502, "train/extr_critic_min": 1.1720445506156436, "train/extr_critic_std": 0.014511510955228929, "train/extr_return_normed_mag": 0.9984502659903632, "train/extr_return_normed_max": 0.3614200467155093, "train/extr_return_normed_mean": 0.03517368155723763, "train/extr_return_normed_min": -0.9550225337346395, "train/extr_return_normed_std": 0.047921960397313036, "train/extr_return_rate": 0.9988653707125831, "train/extr_return_raw_mag": 1.5444165998035007, "train/extr_return_raw_max": 1.5444165998035007, "train/extr_return_raw_mean": 1.2181703022548132, "train/extr_return_raw_min": 0.2279740193533519, "train/extr_return_raw_std": 0.04792196054514202, "train/extr_reward_mag": 0.34967337430469575, "train/extr_reward_max": 0.34967337430469575, "train/extr_reward_mean": 0.0031073077938460285, "train/extr_reward_min": 1.1920928955078125e-07, "train/extr_reward_std": 0.013982136395671182, "train/image_loss_mean": 0.10486339825013327, "train/image_loss_std": 0.10472968782460879, "train/model_loss_mean": 0.7310142895532032, "train/model_loss_std": 0.39853271067379015, "train/model_opt_grad_norm": 23.1300933625963, "train/model_opt_grad_steps": 35754.06349206349, "train/model_opt_loss": 2204.659470331101, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3015.873015873016, "train/policy_entropy_mag": 1.3388675602655562, "train/policy_entropy_max": 1.3388675602655562, "train/policy_entropy_mean": 0.12206587573838612, "train/policy_entropy_min": 0.06468651573809367, "train/policy_entropy_std": 0.15863674240452902, "train/policy_logprob_mag": 6.551080230682615, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.12259774377185201, "train/policy_logprob_min": -6.551080230682615, "train/policy_logprob_std": 0.6601772857090783, "train/policy_randomness_mag": 0.6880418644064948, "train/policy_randomness_max": 0.6880418644064948, "train/policy_randomness_mean": 0.0627294552645513, "train/policy_randomness_min": 0.03324229456484318, "train/policy_randomness_std": 0.0815231641606679, "train/post_ent_mag": 55.47532326834543, "train/post_ent_max": 55.47532326834543, "train/post_ent_mean": 54.116738728114534, "train/post_ent_min": 53.12568791707357, "train/post_ent_std": 0.4241807276294345, "train/prior_ent_mag": 59.15592992873419, "train/prior_ent_max": 59.15592992873419, "train/prior_ent_mean": 53.82519703819638, "train/prior_ent_min": 50.27894716414194, "train/prior_ent_std": 1.4792388828973921, "train/rep_loss_mean": 1.0000082840995184, "train/rep_loss_std": 0.00025287741000139496, "train/reward_avg": 0.0011213514535772867, "train/reward_loss_mean": 0.008925343605889273, "train/reward_loss_std": 0.16221324317083355, "train/reward_max_data": 0.5868055562651346, "train/reward_max_pred": 0.15187759342647733, "train/reward_neg_acc": 0.9996895123095739, "train/reward_neg_loss": 0.0015222474552472934, "train/reward_pos_acc": 0.13850000143051147, "train/reward_pos_loss": 4.3609354531764986, "train/reward_pred": 0.0008637936192653363, "train/reward_rate": 0.001705109126984127, "train_stats/mean_log_entropy": 0.10271882944636875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.006534251384437084, "report/cont_loss_std": 0.13648001849651337, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.6455471515655518, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0017183463787660003, "report/cont_pred": 0.996833324432373, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0000600814819336, "report/dyn_loss_std": 0.0019198405789211392, "report/image_loss_mean": 0.09069444239139557, "report/image_loss_std": 0.09612216055393219, "report/model_loss_mean": 0.7028220891952515, "report/model_loss_std": 0.3228808343410492, "report/post_ent_mag": 53.68255615234375, "report/post_ent_max": 53.68255615234375, "report/post_ent_mean": 52.239261627197266, "report/post_ent_min": 51.287071228027344, "report/post_ent_std": 0.4258790612220764, "report/prior_ent_mag": 58.397552490234375, "report/prior_ent_max": 58.397552490234375, "report/prior_ent_mean": 52.99124526977539, "report/prior_ent_min": 49.93756103515625, "report/prior_ent_std": 1.4400100708007812, "report/rep_loss_mean": 1.0000600814819336, "report/rep_loss_std": 0.0019198405789211392, "report/reward_avg": 0.0007080078357830644, "report/reward_loss_mean": 0.005557345226407051, "report/reward_loss_std": 0.1633611023426056, "report/reward_max_data": 0.7250000238418579, "report/reward_max_pred": 0.033617377281188965, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00045079615665599704, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.229557037353516, "report/reward_pred": 0.00022775563411414623, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04439319297671318, "eval/cont_loss_std": 0.6633319854736328, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.62502670288086, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.002900515217334032, "eval/cont_pred": 0.9972146153450012, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1870899200439453, "eval/image_loss_std": 0.15435519814491272, "eval/model_loss_mean": 0.8458656072616577, "eval/model_loss_std": 1.002550482749939, "eval/post_ent_mag": 53.6828498840332, "eval/post_ent_max": 53.6828498840332, "eval/post_ent_mean": 52.267356872558594, "eval/post_ent_min": 51.2675666809082, "eval/post_ent_std": 0.4375046193599701, "eval/prior_ent_mag": 58.397552490234375, "eval/prior_ent_max": 58.397552490234375, "eval/prior_ent_mean": 52.92211151123047, "eval/prior_ent_min": 49.723793029785156, "eval/prior_ent_std": 1.4324759244918823, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007720947032794356, "eval/reward_loss_mean": 0.014382497407495975, "eval/reward_loss_std": 0.44900912046432495, "eval/reward_max_data": 0.7906249761581421, "eval/reward_max_pred": 0.06072795391082764, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00034489473910070956, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 14.374849319458008, "eval/reward_pred": 0.0001617853995412588, "eval/reward_rate": 0.0009765625, "replay/size": 583649.0, "replay/inserts": 20080.0, "replay/samples": 20080.0, "replay/insert_wait_avg": 1.2107816825349968e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.343402049455984e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2128.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2378047283430744e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.106853723526, "timer/env.step_count": 2510.0, "timer/env.step_total": 5.285329818725586, "timer/env.step_frac": 0.0105684010914345, "timer/env.step_avg": 0.0021057090911257314, "timer/env.step_min": 0.0010519027709960938, "timer/env.step_max": 0.008486032485961914, "timer/replay._sample_count": 20080.0, "timer/replay._sample_total": 1342.760202407837, "timer/replay._sample_frac": 2.68494661172981, "timer/replay._sample_avg": 0.06687052800835841, "timer/replay._sample_min": 0.00034332275390625, "timer/replay._sample_max": 0.10529446601867676, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2776.0, "timer/agent.policy_total": 18.174482345581055, "timer/agent.policy_frac": 0.036341198306449225, "timer/agent.policy_avg": 0.006547003726794328, "timer/agent.policy_min": 0.0051157474517822266, "timer/agent.policy_max": 0.0161285400390625, "timer/dataset_train_count": 1255.0, "timer/dataset_train_total": 0.09500503540039062, "timer/dataset_train_frac": 0.0001899694729097079, "timer/dataset_train_avg": 7.570122342660607e-05, "timer/dataset_train_min": 5.6743621826171875e-05, "timer/dataset_train_max": 0.0001842975616455078, "timer/agent.train_count": 1255.0, "timer/agent.train_total": 470.8075940608978, "timer/agent.train_frac": 0.9414140009390359, "timer/agent.train_avg": 0.3751454932756158, "timer/agent.train_min": 0.35285472869873047, "timer/agent.train_max": 0.4274461269378662, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4280259609222412, "timer/agent.report_frac": 0.0008558690162620062, "timer/agent.report_avg": 0.2140129804611206, "timer/agent.report_min": 0.2137923240661621, "timer/agent.report_max": 0.2142336368560791, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 6.578946813275369e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 40.150755714442994}
{"step": 584384, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 584488, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 584600, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 584816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 585064, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 585280, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 585360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 585392, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025}
{"step": 585600, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 585696, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 585752, "episode/length": 6.0, "episode/score": 0.981249988079071, "episode/reward_rate": 0.14285714285714285}
{"step": 585864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 585992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 586080, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 586208, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 586264, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 586344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 586432, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 586464, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 586552, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 586568, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 586816, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 586928, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 587024, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 587128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 587240, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564}
{"step": 587376, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 587592, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 587696, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 587704, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 587808, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694}
{"step": 587880, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 587944, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 588016, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 588320, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 588528, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 588640, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 588776, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 588776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 588800, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 588824, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 588936, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952}
{"step": 589256, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756}
{"step": 589328, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 589408, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 589536, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 589712, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 589808, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 589816, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 589992, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 590056, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333}
{"step": 590096, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 590096, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 590096, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 590096, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 590096, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 590096, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 590096, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 590096, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 590440, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 590624, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 590664, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 590840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 590952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 591080, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 591360, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 591376, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 591440, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 591472, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 591488, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 591520, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1}
{"step": 591616, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125}
{"step": 591640, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616}
{"step": 591712, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 591720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 591824, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 592120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 592200, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 592304, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 592304, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 592400, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 592784, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 593480, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 593800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 593832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 593928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 594432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 594456, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 594512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 594616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 594712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 594952, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 594960, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 594960, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 595024, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 595208, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 595288, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025}
{"step": 595360, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 595512, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 595688, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 595792, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 595848, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 595872, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 596112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 596256, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 596288, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 596416, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 596504, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 596768, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 596824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 596944, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 597048, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 597208, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 597280, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 597336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 597528, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 597552, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 597632, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693}
{"step": 597688, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 597744, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 598184, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 598536, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 598688, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 598896, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 599056, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05}
{"step": 599128, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 599136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 599256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 599360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 599448, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 599520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 599720, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 599832, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 599968, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903}
{"step": 600008, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 600056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 600080, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 600080, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 600080, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 600080, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 600080, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 600080, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 600080, "eval_episode/length": 277.0, "eval_episode/score": 0.13437500596046448, "eval_episode/reward_rate": 0.0035971223021582736}
{"step": 600080, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 600080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600336, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667}
{"step": 600528, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 600640, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 600672, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676}
{"step": 600696, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 600848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 601272, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 601472, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694}
{"step": 601512, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 601528, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 601696, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 601792, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 601928, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 602040, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 602168, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 602272, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 602280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 602304, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 602528, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 602648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 602832, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 602920, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 602984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 603088, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 603144, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 603360, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 603496, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 603640, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 603800, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05}
{"step": 603856, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 603984, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 604073, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.171324206936744, "train/action_min": 0.0, "train/action_std": 1.721800321532834, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012726919182891688, "train/actor_opt_grad_steps": 37035.0, "train/actor_opt_loss": -6.08826955714293, "train/adv_mag": 1.111729948751388, "train/adv_max": 0.27431545142204533, "train/adv_mean": 0.002966745693547343, "train/adv_min": -1.0998060462936279, "train/adv_std": 0.043288574884495425, "train/cont_avg": 0.9955109627016129, "train/cont_loss_mean": 0.015165764881643437, "train/cont_loss_std": 0.2194135880338088, "train/cont_neg_acc": 0.3535522324663977, "train/cont_neg_loss": 2.642250430755197, "train/cont_pos_acc": 0.999809998177713, "train/cont_pos_loss": 0.0032547953991114253, "train/cont_pred": 0.995438918952019, "train/cont_rate": 0.9955109627016129, "train/dyn_loss_mean": 1.0000085013528024, "train/dyn_loss_std": 0.00026199570369968685, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.494524805025468, "train/extr_critic_critic_opt_grad_steps": 37035.0, "train/extr_critic_critic_opt_loss": 5646.40471624559, "train/extr_critic_mag": 1.2632458075400321, "train/extr_critic_max": 1.2632458075400321, "train/extr_critic_mean": 1.224037411712831, "train/extr_critic_min": 1.1432877769393306, "train/extr_critic_std": 0.015453044310091965, "train/extr_return_normed_mag": 1.0986513178194723, "train/extr_return_normed_max": 0.29578813910484314, "train/extr_return_normed_mean": 0.03426635706977498, "train/extr_return_normed_min": -1.0822077979964595, "train/extr_return_normed_std": 0.046692374079758604, "train/extr_return_rate": 0.9982385620955498, "train/extr_return_raw_mag": 1.4885258818826368, "train/extr_return_raw_max": 1.4885258818826368, "train/extr_return_raw_mean": 1.22700414734502, "train/extr_return_raw_min": 0.11052994478133417, "train/extr_return_raw_std": 0.04669237408726927, "train/extr_reward_mag": 0.3492907401054136, "train/extr_reward_max": 0.3492907401054136, "train/extr_reward_mean": 0.002785953141057924, "train/extr_reward_min": 1.1055700240596648e-07, "train/extr_reward_std": 0.010743651571007626, "train/image_loss_mean": 0.10146654385232157, "train/image_loss_std": 0.10389570266969743, "train/model_loss_mean": 0.7255438513332798, "train/model_loss_std": 0.3763257254275583, "train/model_opt_grad_norm": 23.096212563976163, "train/model_opt_grad_steps": 37003.6935483871, "train/model_opt_loss": 3715.054947391633, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5161.290322580645, "train/policy_entropy_mag": 1.3271239476819192, "train/policy_entropy_max": 1.3271239476819192, "train/policy_entropy_mean": 0.11469354360334334, "train/policy_entropy_min": 0.06468650987071375, "train/policy_entropy_std": 0.1474162806426325, "train/policy_logprob_mag": 6.551080246125498, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11425792191538119, "train/policy_logprob_min": -6.551080246125498, "train/policy_logprob_std": 0.6486736151479906, "train/policy_randomness_mag": 0.6820068368988652, "train/policy_randomness_max": 0.6820068368988652, "train/policy_randomness_mean": 0.05894082583366863, "train/policy_randomness_min": 0.03324229095972354, "train/policy_randomness_std": 0.07575698647527926, "train/post_ent_mag": 53.62250552638884, "train/post_ent_max": 53.62250552638884, "train/post_ent_mean": 52.202069897805494, "train/post_ent_min": 51.19085031940091, "train/post_ent_std": 0.44539302587509155, "train/prior_ent_mag": 57.94620132446289, "train/prior_ent_max": 57.94620132446289, "train/prior_ent_mean": 51.869055040421024, "train/prior_ent_min": 48.19069923893098, "train/prior_ent_std": 1.6168275562024885, "train/rep_loss_mean": 1.0000085013528024, "train/rep_loss_std": 0.00026199570369968685, "train/reward_avg": 0.0011698815131591888, "train/reward_loss_mean": 0.00890642131543568, "train/reward_loss_std": 0.15915078294253157, "train/reward_max_data": 0.6221018127135692, "train/reward_max_pred": 0.17739328742027283, "train/reward_neg_acc": 0.9997475147247314, "train/reward_neg_loss": 0.0015782258018471993, "train/reward_pos_acc": 0.22068733272125135, "train/reward_pos_loss": 3.98447296529446, "train/reward_pred": 0.000923086448775364, "train/reward_rate": 0.0018113659274193547, "train_stats/mean_log_entropy": 0.09679006265019471, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.024137314409017563, "report/cont_loss_std": 0.2982598841190338, "report/cont_neg_acc": 0.375, "report/cont_neg_loss": 2.534775972366333, "report/cont_pos_acc": 0.999015748500824, "report/cont_pos_loss": 0.004368509165942669, "report/cont_pred": 0.9930891394615173, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10688461363315582, "report/image_loss_std": 0.10545564442873001, "report/model_loss_mean": 0.7450965642929077, "report/model_loss_std": 0.48133525252342224, "report/post_ent_mag": 51.939369201660156, "report/post_ent_max": 51.939369201660156, "report/post_ent_mean": 50.49848937988281, "report/post_ent_min": 49.54611587524414, "report/post_ent_std": 0.4800536334514618, "report/prior_ent_mag": 57.25483703613281, "report/prior_ent_max": 57.25483703613281, "report/prior_ent_mean": 50.85844421386719, "report/prior_ent_min": 47.07714080810547, "report/prior_ent_std": 1.6914533376693726, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0020385743118822575, "report/reward_loss_mean": 0.014074600301682949, "report/reward_loss_std": 0.21424080431461334, "report/reward_max_data": 0.737500011920929, "report/reward_max_pred": 0.03584492206573486, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0024748805444687605, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.961846113204956, "report/reward_pred": 0.0013393767876550555, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02105456218123436, "eval/cont_loss_std": 0.359842449426651, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.588146209716797, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0017585053574293852, "eval/cont_pred": 0.9982871413230896, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16987647116184235, "eval/image_loss_std": 0.14076966047286987, "eval/model_loss_mean": 0.8083493709564209, "eval/model_loss_std": 0.7433001399040222, "eval/post_ent_mag": 51.95707702636719, "eval/post_ent_max": 51.95707702636719, "eval/post_ent_mean": 50.4033203125, "eval/post_ent_min": 49.61032485961914, "eval/post_ent_std": 0.4441591799259186, "eval/prior_ent_mag": 57.25483703613281, "eval/prior_ent_max": 57.25483703613281, "eval/prior_ent_mean": 50.31066131591797, "eval/prior_ent_min": 47.03429412841797, "eval/prior_ent_std": 1.684008240699768, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.001434326171875, "eval/reward_loss_mean": 0.01741829700767994, "eval/reward_loss_std": 0.3996630907058716, "eval/reward_max_data": 0.9468749761581421, "eval/reward_max_pred": 0.028901338577270508, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00038873005541972816, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.719526290893555, "eval/reward_pred": 0.0001981878885999322, "eval/reward_rate": 0.001953125, "replay/size": 603569.0, "replay/inserts": 19920.0, "replay/samples": 19920.0, "replay/insert_wait_avg": 1.2186995471816465e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.544309156486787e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3568.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2313838496871059e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2873680591583, "timer/env.step_count": 2490.0, "timer/env.step_total": 5.441298246383667, "timer/env.step_frac": 0.010876345464193773, "timer/env.step_avg": 0.0021852603399131194, "timer/env.step_min": 0.0010786056518554688, "timer/env.step_max": 0.008512258529663086, "timer/replay._sample_count": 19920.0, "timer/replay._sample_total": 1341.0775594711304, "timer/replay._sample_frac": 2.680614472985354, "timer/replay._sample_avg": 0.06732317065618125, "timer/replay._sample_min": 0.0003523826599121094, "timer/replay._sample_max": 0.09144473075866699, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2936.0, "timer/agent.policy_total": 19.342524766921997, "timer/agent.policy_frac": 0.038662828609805654, "timer/agent.policy_avg": 0.006588053394728201, "timer/agent.policy_min": 0.005063772201538086, "timer/agent.policy_max": 0.010343790054321289, "timer/dataset_train_count": 1245.0, "timer/dataset_train_total": 0.09496521949768066, "timer/dataset_train_frac": 0.0001898213418141934, "timer/dataset_train_avg": 7.62772847370929e-05, "timer/dataset_train_min": 5.817413330078125e-05, "timer/dataset_train_max": 0.00024080276489257812, "timer/agent.train_count": 1245.0, "timer/agent.train_total": 469.11787366867065, "timer/agent.train_frac": 0.9376968191073697, "timer/agent.train_avg": 0.37680150495475556, "timer/agent.train_min": 0.35051941871643066, "timer/agent.train_max": 1.736448049545288, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.42368602752685547, "timer/agent.report_frac": 0.000846885319472538, "timer/agent.report_avg": 0.21184301376342773, "timer/agent.report_min": 0.2107856273651123, "timer/agent.report_max": 0.21290040016174316, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 6.910167271230927e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 39.816390952214306}
{"step": 604080, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 604080, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 604128, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839}
{"step": 604160, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617}
{"step": 604248, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005}
{"step": 604256, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 604272, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555}
{"step": 604536, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 604744, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 605032, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 605280, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 605336, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 605480, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 605536, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762}
{"step": 605584, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 605832, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621}
{"step": 605848, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756}
{"step": 606056, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 606296, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 606400, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 606512, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 606560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 606568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 606664, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 606744, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 607104, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 607144, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 607248, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555}
{"step": 607360, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 607424, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 607792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 608176, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 608712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 608784, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 608824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 608872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 609056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 609440, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633}
{"step": 609560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 609664, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 609672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 609856, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 609872, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 609984, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667}
{"step": 610064, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 610064, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 610064, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 610064, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 610064, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 610064, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 610064, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 610064, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 610296, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 610304, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 610336, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 610552, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 610608, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 611024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 611104, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 611240, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 611680, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 611752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 611792, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 612168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 612464, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705}
{"step": 612560, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 612592, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 612608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 612616, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 612616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 612864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 613008, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 613128, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 613368, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 614072, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 614104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 614168, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 614392, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 614704, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 614776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 614920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 614928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 614928, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 615056, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 615176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 615264, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 615328, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 615792, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 616040, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809}
{"step": 616304, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 616312, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 616480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 616696, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 617024, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 617088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 617216, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664}
{"step": 617368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 617640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 618024, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 618200, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674}
{"step": 618288, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 618352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 618480, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633}
{"step": 618616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 619008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 619032, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 619376, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 619400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 619472, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 619808, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 620048, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 620048, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 620048, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 620048, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 620048, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 620048, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 620048, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 620048, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 620136, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 620136, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025}
{"step": 620232, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 620584, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 620600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 620664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 620792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 620896, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 621032, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 621312, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 621344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 621368, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 621432, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 621624, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 621760, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 621784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 621840, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 621856, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655}
{"step": 621968, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216}
{"step": 622016, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 622064, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 622328, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 622640, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 622704, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 622712, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 622720, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 622736, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875}
{"step": 622744, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 622920, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 623008, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703}
{"step": 623112, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 623200, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 623560, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 623592, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 623632, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 623656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 623744, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 624032, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 624064, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 624136, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 624137, "train_stats/mean_log_entropy": 0.09567097354103142, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.0877879309275795, "train/action_min": 0.0, "train/action_std": 1.789317115904793, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011565884392309402, "train/actor_opt_grad_steps": 38285.0, "train/actor_opt_loss": -5.1033458608897435, "train/adv_mag": 1.1096215039964705, "train/adv_max": 0.2804315497004797, "train/adv_mean": 0.003823345973585905, "train/adv_min": -1.0961299481846036, "train/adv_std": 0.037733303013420295, "train/cont_avg": 0.9952334449404762, "train/cont_loss_mean": 0.01666726360637103, "train/cont_loss_std": 0.2294221531104533, "train/cont_neg_acc": 0.33869553232192995, "train/cont_neg_loss": 2.704246160849929, "train/cont_pos_acc": 0.9997038585799081, "train/cont_pos_loss": 0.003448798576192487, "train/cont_pred": 0.9953508079051971, "train/cont_rate": 0.9952334449404762, "train/dyn_loss_mean": 1.0000151812084137, "train/dyn_loss_std": 0.00046882451640576907, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3189905889568821, "train/extr_critic_critic_opt_grad_steps": 38285.0, "train/extr_critic_critic_opt_loss": 11144.96449110243, "train/extr_critic_mag": 1.3436012760041252, "train/extr_critic_max": 1.3436012760041252, "train/extr_critic_mean": 1.2922628588146634, "train/extr_critic_min": 1.184090915180388, "train/extr_critic_std": 0.01833591673759714, "train/extr_return_normed_mag": 1.1024688926954118, "train/extr_return_normed_max": 0.2859411778904143, "train/extr_return_normed_mean": 0.03953647725136271, "train/extr_return_normed_min": -1.0838771027231973, "train/extr_return_normed_std": 0.04270869528963452, "train/extr_return_rate": 0.9987982043198177, "train/extr_return_raw_mag": 1.5424908390120855, "train/extr_return_raw_max": 1.5424908390120855, "train/extr_return_raw_mean": 1.2960862025382027, "train/extr_return_raw_min": 0.17267255839847384, "train/extr_return_raw_std": 0.04270869489049628, "train/extr_reward_mag": 0.3245386102842906, "train/extr_reward_max": 0.3245386102842906, "train/extr_reward_mean": 0.0026729705245492775, "train/extr_reward_min": 6.811959402901785e-08, "train/extr_reward_std": 0.009808335737842653, "train/image_loss_mean": 0.09909403117166625, "train/image_loss_std": 0.10179635119580087, "train/model_loss_mean": 0.7260792080372099, "train/model_loss_std": 0.40563366946483415, "train/model_opt_grad_norm": 22.30014897906591, "train/model_opt_grad_steps": 38252.1746031746, "train/model_opt_loss": 3043.1157836914062, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4226.190476190476, "train/policy_entropy_mag": 1.3145761593939767, "train/policy_entropy_max": 1.3145761593939767, "train/policy_entropy_mean": 0.11382958683229628, "train/policy_entropy_min": 0.06468651153975064, "train/policy_entropy_std": 0.14654610223240322, "train/policy_logprob_mag": 6.551080264742413, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11405712839156862, "train/policy_logprob_min": -6.551080264742413, "train/policy_logprob_std": 0.6512438574480632, "train/policy_randomness_mag": 0.6755585471789042, "train/policy_randomness_max": 0.6755585471789042, "train/policy_randomness_mean": 0.05849683952946511, "train/policy_randomness_min": 0.033242292406540065, "train/policy_randomness_std": 0.0753098036206904, "train/post_ent_mag": 52.62523959931873, "train/post_ent_max": 52.62523959931873, "train/post_ent_mean": 51.15728886922201, "train/post_ent_min": 50.184622749449716, "train/post_ent_std": 0.4585474010497805, "train/prior_ent_mag": 56.791395157102556, "train/prior_ent_max": 56.791395157102556, "train/prior_ent_mean": 50.810588079785546, "train/prior_ent_min": 47.27322227235825, "train/prior_ent_std": 1.5330999119887276, "train/rep_loss_mean": 1.0000151812084137, "train/rep_loss_std": 0.00046882451640576907, "train/reward_avg": 0.0013340783581721582, "train/reward_loss_mean": 0.01030877905912579, "train/reward_loss_std": 0.18128093561926295, "train/reward_max_data": 0.6510912722774914, "train/reward_max_pred": 0.18585993940868076, "train/reward_neg_acc": 0.9997126701332274, "train/reward_neg_loss": 0.0017084053395101653, "train/reward_pos_acc": 0.16258503536560706, "train/reward_pos_loss": 4.201957680284977, "train/reward_pred": 0.0010102382474874575, "train/reward_rate": 0.0020306299603174605, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0074469586834311485, "report/cont_loss_std": 0.0891590416431427, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.1463613510131836, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004100490361452103, "report/cont_pred": 0.9945123195648193, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10590852797031403, "report/image_loss_std": 0.11673892289400101, "report/model_loss_mean": 0.7182031869888306, "report/model_loss_std": 0.24795331060886383, "report/post_ent_mag": 53.19992446899414, "report/post_ent_max": 53.19992446899414, "report/post_ent_mean": 51.64398193359375, "report/post_ent_min": 50.65597152709961, "report/post_ent_std": 0.486040860414505, "report/prior_ent_mag": 54.67774963378906, "report/prior_ent_max": 54.67774963378906, "report/prior_ent_mean": 50.91290283203125, "report/prior_ent_min": 47.83964538574219, "report/prior_ent_std": 1.140434980392456, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006927490467205644, "report/reward_loss_mean": 0.004847672767937183, "report/reward_loss_std": 0.11650421470403671, "report/reward_max_data": 0.7093750238418579, "report/reward_max_pred": 0.041748881340026855, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0012101663742214441, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.7260169982910156, "report/reward_pred": 0.0006152751157060266, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.026677925139665604, "eval/cont_loss_std": 0.4257965385913849, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.595331192016602, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.004438979085534811, "eval/cont_pred": 0.9959872364997864, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17235052585601807, "eval/image_loss_std": 0.15558557212352753, "eval/model_loss_mean": 0.8100656270980835, "eval/model_loss_std": 0.7182071208953857, "eval/post_ent_mag": 53.223838806152344, "eval/post_ent_max": 53.223838806152344, "eval/post_ent_mean": 51.63017272949219, "eval/post_ent_min": 50.593257904052734, "eval/post_ent_std": 0.4936482906341553, "eval/prior_ent_mag": 54.701778411865234, "eval/prior_ent_max": 54.701778411865234, "eval/prior_ent_mean": 50.881103515625, "eval/prior_ent_min": 47.79856872558594, "eval/prior_ent_std": 1.1406227350234985, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005340576171875, "eval/reward_loss_mean": 0.011037166230380535, "eval/reward_loss_std": 0.32302936911582947, "eval/reward_max_data": 0.546875, "eval/reward_max_pred": 0.01861572265625, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009383250726386905, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.342153549194336, "eval/reward_pred": 0.00043506163638085127, "eval/reward_rate": 0.0009765625, "replay/size": 623633.0, "replay/inserts": 20064.0, "replay/samples": 20064.0, "replay/insert_wait_avg": 1.2020983003923578e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.254976487045653e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1966035172745988e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.33200240135193, "timer/env.step_count": 2508.0, "timer/env.step_total": 5.264527320861816, "timer/env.step_frac": 0.010522067938078373, "timer/env.step_avg": 0.002099093828094823, "timer/env.step_min": 0.0010867118835449219, "timer/env.step_max": 0.010092496871948242, "timer/replay._sample_count": 20064.0, "timer/replay._sample_total": 1339.3190038204193, "timer/replay._sample_frac": 2.6768605593732464, "timer/replay._sample_avg": 0.06675234269439889, "timer/replay._sample_min": 0.020211219787597656, "timer/replay._sample_max": 0.0895848274230957, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2878.0, "timer/agent.policy_total": 18.80056643486023, "timer/agent.policy_frac": 0.03757618210433591, "timer/agent.policy_avg": 0.006532510922467071, "timer/agent.policy_min": 0.005173206329345703, "timer/agent.policy_max": 0.010499238967895508, "timer/dataset_train_count": 1254.0, "timer/dataset_train_total": 0.09473586082458496, "timer/dataset_train_frac": 0.00018934599499911776, "timer/dataset_train_avg": 7.554693845660683e-05, "timer/dataset_train_min": 6.604194641113281e-05, "timer/dataset_train_max": 0.0002448558807373047, "timer/agent.train_count": 1254.0, "timer/agent.train_total": 469.2861006259918, "timer/agent.train_frac": 0.9379493983467881, "timer/agent.train_avg": 0.3742313402121147, "timer/agent.train_min": 0.3463742733001709, "timer/agent.train_max": 0.4182446002960205, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.42182135581970215, "timer/agent.report_frac": 0.0008430829005443653, "timer/agent.report_avg": 0.21091067790985107, "timer/agent.report_min": 0.21014976501464844, "timer/agent.report_max": 0.2116715908050537, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 7.052507042858689e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 40.100700133283716}
{"step": 624616, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 624928, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757}
{"step": 624960, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 625016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 625056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 625312, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 625328, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 625448, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 625488, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875}
{"step": 625512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 626112, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 626184, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 626280, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 626288, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 626400, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776}
{"step": 626456, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556}
{"step": 626696, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 626704, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 626824, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422}
{"step": 627120, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 627368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 627800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 627840, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761}
{"step": 628232, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 628592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 628712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 629008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 629136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 629176, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 629312, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 629432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 629680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 629712, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 629744, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 629808, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 629976, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703}
{"step": 630032, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 630032, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 630032, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 630032, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 630032, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 630032, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 630032, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 630032, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 630152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 630288, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 630416, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 630464, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 630496, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 630640, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 630696, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 630776, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 631024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 631240, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 631376, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 631504, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 631744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 631968, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 632120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 632208, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 632472, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494}
{"step": 632528, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 632640, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633}
{"step": 632776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 632848, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 632848, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 633008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 633072, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 633208, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 633256, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 633528, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 633656, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 634008, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 634064, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 634416, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391}
{"step": 634520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 634680, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 634744, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 634816, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 635120, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694}
{"step": 635160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 635160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 635168, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 635400, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 635536, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 635568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 635568, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 636008, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 636256, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 636680, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993}
{"step": 636832, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633}
{"step": 637056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 637432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 637712, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 637712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 637880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 637888, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 638320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 638432, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 638504, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 638568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 638744, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 638808, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 638920, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 638992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 639024, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 639144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 639184, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 639192, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616}
{"step": 639528, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 639600, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 639664, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 639696, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 639768, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 639840, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456}
{"step": 640016, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 640016, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 640016, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 640016, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 640016, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 640016, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 640016, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 640016, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 640032, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301}
{"step": 640096, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 640280, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 640360, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 640528, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 640728, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 640832, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494}
{"step": 641248, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 641256, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 641400, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 641496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 641768, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 641840, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 642024, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 642096, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 642152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 642232, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 642344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 642392, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703}
{"step": 642536, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 642712, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 642800, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 642896, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 643144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 643224, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 643280, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 643496, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 643760, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453}
{"step": 643864, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 643880, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 643912, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 643968, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 644080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 644080, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 644128, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035}
{"step": 644169, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.12373779296875, "train/action_min": 0.0, "train/action_std": 1.7295148668289184, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010999538348987698, "train/actor_opt_grad_steps": 39540.0, "train/actor_opt_loss": -5.806668700158596, "train/adv_mag": 1.1633953742980958, "train/adv_max": 0.29629930877685545, "train/adv_mean": 0.003385031415891717, "train/adv_min": -1.1504062747955321, "train/adv_std": 0.03911157313734293, "train/cont_avg": 0.9953125, "train/cont_loss_mean": 0.01596354740858078, "train/cont_loss_std": 0.22268381536751986, "train/cont_neg_acc": 0.3117392295671086, "train/cont_neg_loss": 2.72557236116019, "train/cont_pos_acc": 0.9997568078041077, "train/cont_pos_loss": 0.003404443368781358, "train/cont_pred": 0.995300371170044, "train/cont_rate": 0.9953125, "train/dyn_loss_mean": 1.0000134525299071, "train/dyn_loss_std": 0.00036934707281761805, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.24970821091532708, "train/extr_critic_critic_opt_grad_steps": 39540.0, "train/extr_critic_critic_opt_loss": 13400.4765078125, "train/extr_critic_mag": 1.4207426929473876, "train/extr_critic_max": 1.4207426929473876, "train/extr_critic_mean": 1.362479723930359, "train/extr_critic_min": 1.2224203052520752, "train/extr_critic_std": 0.020786605566740037, "train/extr_return_normed_mag": 1.1531452550888062, "train/extr_return_normed_max": 0.28356507205963133, "train/extr_return_normed_mean": 0.043324006281793115, "train/extr_return_normed_min": -1.1345133657455444, "train/extr_return_normed_std": 0.04502775365114212, "train/extr_return_rate": 0.9988302545547485, "train/extr_return_raw_mag": 1.6061057538986205, "train/extr_return_raw_max": 1.6061057538986205, "train/extr_return_raw_mean": 1.3658647556304933, "train/extr_return_raw_min": 0.18802731609344484, "train/extr_return_raw_std": 0.04502775326371193, "train/extr_reward_mag": 0.3157502965927124, "train/extr_reward_max": 0.3157502965927124, "train/extr_reward_mean": 0.002581378913484514, "train/extr_reward_min": 1.3065338134765626e-07, "train/extr_reward_std": 0.009852489549666643, "train/image_loss_mean": 0.09500873267650604, "train/image_loss_std": 0.10094748955965042, "train/model_loss_mean": 0.721441367149353, "train/model_loss_std": 0.4002296887040138, "train/model_opt_grad_norm": 21.627401741027832, "train/model_opt_grad_steps": 39506.0, "train/model_opt_loss": 2753.17953515625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3820.0, "train/policy_entropy_mag": 1.3012258338928222, "train/policy_entropy_max": 1.3012258338928222, "train/policy_entropy_mean": 0.11067615443468094, "train/policy_entropy_min": 0.06468651247024536, "train/policy_entropy_std": 0.14177217304706574, "train/policy_logprob_mag": 6.551080272674561, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11013237529993057, "train/policy_logprob_min": -6.551080272674561, "train/policy_logprob_std": 0.6441651339530945, "train/policy_randomness_mag": 0.6686978402137757, "train/policy_randomness_max": 0.6686978402137757, "train/policy_randomness_mean": 0.0568762956559658, "train/policy_randomness_min": 0.033242292940616605, "train/policy_randomness_std": 0.07285648864507675, "train/post_ent_mag": 51.663780456542966, "train/post_ent_max": 51.663780456542966, "train/post_ent_mean": 50.20565408325195, "train/post_ent_min": 49.19952926635742, "train/post_ent_std": 0.47511691617965696, "train/prior_ent_mag": 53.874083618164065, "train/prior_ent_max": 53.874083618164065, "train/prior_ent_mean": 49.947500396728515, "train/prior_ent_min": 46.58546875, "train/prior_ent_std": 1.2523072414398193, "train/rep_loss_mean": 1.0000134525299071, "train/rep_loss_std": 0.00036934707281761805, "train/reward_avg": 0.0014446289010811597, "train/reward_loss_mean": 0.010460993520915509, "train/reward_loss_std": 0.18011815460771322, "train/reward_max_data": 0.6817499997615815, "train/reward_max_pred": 0.20630387020111085, "train/reward_neg_acc": 0.9997338457107544, "train/reward_neg_loss": 0.00182107543037273, "train/reward_pos_acc": 0.18037840284939324, "train/reward_pos_loss": 4.088359793382032, "train/reward_pred": 0.0011047782264649868, "train/reward_rate": 0.0021484375, "train_stats/mean_log_entropy": 0.10016070222350913, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.004574560560286045, "report/cont_loss_std": 0.06898783892393112, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 0.7593120336532593, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0023569194599986076, "report/cont_pred": 0.9956996440887451, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10398654639720917, "report/image_loss_std": 0.11144008487462997, "report/model_loss_mean": 0.7105877995491028, "report/model_loss_std": 0.14237144589424133, "report/post_ent_mag": 50.09499740600586, "report/post_ent_max": 50.09499740600586, "report/post_ent_mean": 48.55847930908203, "report/post_ent_min": 47.614990234375, "report/post_ent_std": 0.4717424809932709, "report/prior_ent_mag": 53.37117004394531, "report/prior_ent_max": 53.37117004394531, "report/prior_ent_mean": 48.99365997314453, "report/prior_ent_min": 45.31939697265625, "report/prior_ent_std": 1.2773696184158325, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008148193592205644, "report/reward_loss_mean": 0.002026657108217478, "report/reward_loss_std": 0.028626494109630585, "report/reward_max_data": 0.8343750238418579, "report/reward_max_pred": 0.5924739837646484, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0011526948073878884, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8960899114608765, "report/reward_pred": 0.0011872814502567053, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.017532823607325554, "eval/cont_loss_std": 0.2626844346523285, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.227289199829102, "eval/cont_pos_acc": 0.9960899353027344, "eval/cont_pos_loss": 0.010485162027180195, "eval/cont_pred": 0.9941599369049072, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1501002311706543, "eval/image_loss_std": 0.12657181918621063, "eval/model_loss_mean": 0.7693246603012085, "eval/model_loss_std": 0.3051736354827881, "eval/post_ent_mag": 50.09496307373047, "eval/post_ent_max": 50.09496307373047, "eval/post_ent_mean": 48.476844787597656, "eval/post_ent_min": 47.548377990722656, "eval/post_ent_std": 0.47539573907852173, "eval/prior_ent_mag": 53.37117004394531, "eval/prior_ent_max": 53.37117004394531, "eval/prior_ent_mean": 48.795108795166016, "eval/prior_ent_min": 44.65500259399414, "eval/prior_ent_std": 1.2926530838012695, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0016915807500481606, "eval/reward_loss_std": 0.038294799625873566, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.44215261936187744, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.0016915807500481606, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000686566112563014, "eval/reward_rate": 0.0, "replay/size": 643665.0, "replay/inserts": 20032.0, "replay/samples": 20032.0, "replay/insert_wait_avg": 1.219859995400182e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.394886857785356e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2416344184380073e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.407499313354492e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.27050971984863, "timer/env.step_count": 2504.0, "timer/env.step_total": 5.3908164501190186, "timer/env.step_frac": 0.010775802981346781, "timer/env.step_avg": 0.0021528819688973718, "timer/env.step_min": 0.00109100341796875, "timer/env.step_max": 0.008717060089111328, "timer/replay._sample_count": 20032.0, "timer/replay._sample_total": 1350.0384628772736, "timer/replay._sample_frac": 2.6986169215396982, "timer/replay._sample_avg": 0.06739409259571054, "timer/replay._sample_min": 0.00032639503479003906, "timer/replay._sample_max": 0.0973520278930664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2812.0, "timer/agent.policy_total": 18.50154995918274, "timer/agent.policy_frac": 0.03698309134700665, "timer/agent.policy_avg": 0.006579498563009509, "timer/agent.policy_min": 0.005055665969848633, "timer/agent.policy_max": 0.011020660400390625, "timer/dataset_train_count": 1252.0, "timer/dataset_train_total": 0.09731245040893555, "timer/dataset_train_frac": 0.00019451966189938018, "timer/dataset_train_avg": 7.772559936815938e-05, "timer/dataset_train_min": 5.9604644775390625e-05, "timer/dataset_train_max": 0.00022935867309570312, "timer/agent.train_count": 1252.0, "timer/agent.train_total": 470.4313633441925, "timer/agent.train_frac": 0.9403539769066819, "timer/agent.train_avg": 0.37574390043465855, "timer/agent.train_min": 0.35422492027282715, "timer/agent.train_max": 0.5219976902008057, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41951727867126465, "timer/agent.report_frac": 0.0008385808687907553, "timer/agent.report_avg": 0.20975863933563232, "timer/agent.report_min": 0.20968198776245117, "timer/agent.report_max": 0.20983529090881348, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 6.910400133137199e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 40.04174212820849}
{"step": 644360, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 644464, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 644784, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 645056, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 645176, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294}
{"step": 645296, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052}
{"step": 645536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 645624, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 645664, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 645768, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 646064, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771}
{"step": 646392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 646424, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 646440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 646688, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 646880, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052}
{"step": 647080, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 647368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 647384, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 647496, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 647528, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 647784, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 647800, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 647848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 647896, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 647936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 648112, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 648208, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 648272, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 648576, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 648704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 648776, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 649048, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 649368, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 649488, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 649520, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 649696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 649712, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556}
{"step": 649944, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 650000, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 650000, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 650000, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 650000, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 650000, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 650000, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 650000, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 650000, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 650112, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 650208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 650368, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 650376, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 650424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 650504, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 650688, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 650768, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714}
{"step": 650832, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 650864, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 650928, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 650992, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 651016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 651160, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 651424, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 651440, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 651488, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 651488, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 651632, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 651672, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 651760, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 651848, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 652104, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 652184, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 652520, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 652936, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 653112, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 653192, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125}
{"step": 653240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 653432, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 653448, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 653752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 653816, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 653928, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 653944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 654072, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 654160, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 654168, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 654288, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 654360, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 654416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 654624, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 654624, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 654824, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 654992, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 655008, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 655064, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 655232, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 655544, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506}
{"step": 655592, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 655672, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 655680, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 655920, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 656104, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 656192, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 656248, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 656384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 656456, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 656480, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 656648, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 656672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 657080, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 657136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 657256, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 657464, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 657568, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564}
{"step": 657704, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 657880, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494}
{"step": 657920, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 657976, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 658040, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05}
{"step": 658136, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 658408, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 658424, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 658448, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564}
{"step": 658552, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 658560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 658696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 658768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 658840, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 659112, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 659144, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 659384, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 659384, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 659432, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 659480, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 659856, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 659864, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 659944, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 660088, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 660088, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 660088, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 660088, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 660088, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 660088, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 660088, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 660088, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 660088, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 660248, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406}
{"step": 660736, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 660736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 660760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 660816, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095}
{"step": 661048, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564}
{"step": 661056, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 661328, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 661704, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 661768, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 662168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 662176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 662392, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 662400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 662864, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 663064, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 663072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 663192, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 663312, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 663368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 663592, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 663616, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 663640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 663776, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 664000, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 664016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 664024, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 664072, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 664169, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.180296875, "train/action_min": 0.0, "train/action_std": 1.7321206188201905, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011101752068847419, "train/actor_opt_grad_steps": 40790.0, "train/actor_opt_loss": -7.965540182352066, "train/adv_mag": 1.2399374785423278, "train/adv_max": 0.3189378185272217, "train/adv_mean": 0.002204588942331611, "train/adv_min": -1.2293297114372252, "train/adv_std": 0.04341864164918661, "train/cont_avg": 0.99528125, "train/cont_loss_mean": 0.014907016441226006, "train/cont_loss_std": 0.21152385632693768, "train/cont_neg_acc": 0.3652508007287979, "train/cont_neg_loss": 2.406749832689762, "train/cont_pos_acc": 0.9997017498016357, "train/cont_pos_loss": 0.0035131435897201298, "train/cont_pred": 0.9950290055274963, "train/cont_rate": 0.99528125, "train/dyn_loss_mean": 1.0000091075897217, "train/dyn_loss_std": 0.00026614663255168126, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.24010412295162678, "train/extr_critic_critic_opt_grad_steps": 40790.0, "train/extr_critic_critic_opt_loss": 13218.4853671875, "train/extr_critic_mag": 1.4648027114868165, "train/extr_critic_max": 1.4648027114868165, "train/extr_critic_mean": 1.4086114444732667, "train/extr_critic_min": 1.2548941717147828, "train/extr_critic_std": 0.020412493377923967, "train/extr_return_normed_mag": 1.2324087038040161, "train/extr_return_normed_max": 0.30469886684417724, "train/extr_return_normed_mean": 0.04097049253433943, "train/extr_return_normed_min": -1.2181151762008666, "train/extr_return_normed_std": 0.048484786197543144, "train/extr_return_rate": 0.9988312973976136, "train/extr_return_raw_mag": 1.6745443353652953, "train/extr_return_raw_max": 1.6745443353652953, "train/extr_return_raw_mean": 1.4108160238265992, "train/extr_return_raw_min": 0.15173029232025145, "train/extr_return_raw_std": 0.048484786361455916, "train/extr_reward_mag": 0.36157918453216553, "train/extr_reward_max": 0.36157918453216553, "train/extr_reward_mean": 0.0026813782565295696, "train/extr_reward_min": 1.2683868408203126e-07, "train/extr_reward_std": 0.010075809560716152, "train/image_loss_mean": 0.09367519146203995, "train/image_loss_std": 0.10064403516054153, "train/model_loss_mean": 0.7187478222846985, "train/model_loss_std": 0.38847303760051727, "train/model_opt_grad_norm": 21.33356498902844, "train/model_opt_grad_steps": 40755.272, "train/model_opt_loss": 3623.16458203125, "train/model_opt_model_opt_grad_overflow": 0.008, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.2962437267303466, "train/policy_entropy_max": 1.2962437267303466, "train/policy_entropy_mean": 0.10043802922964096, "train/policy_entropy_min": 0.0646864977478981, "train/policy_entropy_std": 0.12704292541742324, "train/policy_logprob_mag": 6.551080253601074, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1007600104212761, "train/policy_logprob_min": -6.551080253601074, "train/policy_logprob_std": 0.6402462091445923, "train/policy_randomness_mag": 0.6661375432014466, "train/policy_randomness_max": 0.6661375432014466, "train/policy_randomness_mean": 0.051614939391613004, "train/policy_randomness_min": 0.03324228435754776, "train/policy_randomness_std": 0.06528715226054192, "train/post_ent_mag": 50.48152410888672, "train/post_ent_max": 50.48152410888672, "train/post_ent_mean": 49.02065432739258, "train/post_ent_min": 48.051582305908205, "train/post_ent_std": 0.46897192049026487, "train/prior_ent_mag": 52.82565765380859, "train/prior_ent_max": 52.82565765380859, "train/prior_ent_mean": 48.60359191894531, "train/prior_ent_min": 45.27711312866211, "train/prior_ent_std": 1.2696364107131959, "train/rep_loss_mean": 1.0000091075897217, "train/rep_loss_std": 0.00026614663255168126, "train/reward_avg": 0.0014124755865195767, "train/reward_loss_mean": 0.01016012382786721, "train/reward_loss_std": 0.17698106393776833, "train/reward_max_data": 0.7033250004053115, "train/reward_max_pred": 0.24851366996765137, "train/reward_neg_acc": 0.999718122959137, "train/reward_neg_loss": 0.0019314619679935276, "train/reward_pos_acc": 0.20235988365865387, "train/reward_pos_loss": 3.9580413250796562, "train/reward_pred": 0.0011924685845151543, "train/reward_rate": 0.002109375, "train_stats/mean_log_entropy": 0.08828054140707489, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.012976350262761116, "report/cont_loss_std": 0.174764484167099, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 1.9212473630905151, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0036129013169556856, "report/cont_pred": 0.9947147369384766, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07861215621232986, "report/image_loss_std": 0.087321437895298, "report/model_loss_mean": 0.7067575454711914, "report/model_loss_std": 0.43203383684158325, "report/post_ent_mag": 49.671531677246094, "report/post_ent_max": 49.671531677246094, "report/post_ent_mean": 48.19387435913086, "report/post_ent_min": 47.32295227050781, "report/post_ent_std": 0.47010859847068787, "report/prior_ent_mag": 52.059303283691406, "report/prior_ent_max": 52.059303283691406, "report/prior_ent_mean": 48.35809326171875, "report/prior_ent_min": 46.0414924621582, "report/prior_ent_std": 1.072985053062439, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023010254371911287, "report/reward_loss_mean": 0.015168970450758934, "report/reward_loss_std": 0.229878768324852, "report/reward_max_data": 0.737500011920929, "report/reward_max_pred": 0.22118449211120605, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0017912256298586726, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.4264938831329346, "report/reward_pred": 0.0012298519723117352, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.031058430671691895, "eval/cont_loss_std": 0.49502384662628174, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.771937370300293, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.005375143606215715, "eval/cont_pred": 0.9954495429992676, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20358659327030182, "eval/image_loss_std": 0.1477997601032257, "eval/model_loss_mean": 0.8454434871673584, "eval/model_loss_std": 0.7414161562919617, "eval/post_ent_mag": 49.681827545166016, "eval/post_ent_max": 49.681827545166016, "eval/post_ent_mean": 48.145835876464844, "eval/post_ent_min": 47.33406066894531, "eval/post_ent_std": 0.4550083875656128, "eval/prior_ent_mag": 52.105430603027344, "eval/prior_ent_max": 52.105430603027344, "eval/prior_ent_mean": 48.20083236694336, "eval/prior_ent_min": 45.6185302734375, "eval/prior_ent_std": 1.0923165082931519, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006652831798419356, "eval/reward_loss_mean": 0.010798418894410133, "eval/reward_loss_std": 0.3229963183403015, "eval/reward_max_data": 0.6812499761581421, "eval/reward_max_pred": 0.04358208179473877, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0007009773980826139, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.34048080444336, "eval/reward_pred": 0.0003229348221793771, "eval/reward_rate": 0.0009765625, "replay/size": 663665.0, "replay/inserts": 20000.0, "replay/samples": 20000.0, "replay/insert_wait_avg": 1.2491106986999513e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.37264347076416e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2008.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1849688343792797e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.0656991004944, "timer/env.step_count": 2500.0, "timer/env.step_total": 5.4841835498809814, "timer/env.step_frac": 0.010966926065406592, "timer/env.step_avg": 0.0021936734199523925, "timer/env.step_min": 0.0010509490966796875, "timer/env.step_max": 0.008459806442260742, "timer/replay._sample_count": 20000.0, "timer/replay._sample_total": 1345.973631620407, "timer/replay._sample_frac": 2.6915935926849426, "timer/replay._sample_avg": 0.06729868158102036, "timer/replay._sample_min": 0.0003483295440673828, "timer/replay._sample_max": 0.09267449378967285, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2751.0, "timer/agent.policy_total": 18.190578937530518, "timer/agent.policy_frac": 0.036376378084422255, "timer/agent.policy_avg": 0.006612351485834431, "timer/agent.policy_min": 0.005199909210205078, "timer/agent.policy_max": 0.009594917297363281, "timer/dataset_train_count": 1250.0, "timer/dataset_train_total": 0.09602546691894531, "timer/dataset_train_frac": 0.0001920257020061034, "timer/dataset_train_avg": 7.682037353515626e-05, "timer/dataset_train_min": 6.699562072753906e-05, "timer/dataset_train_max": 0.00015807151794433594, "timer/agent.train_count": 1250.0, "timer/agent.train_total": 470.46805334091187, "timer/agent.train_frac": 0.9408124856137463, "timer/agent.train_avg": 0.3763744426727295, "timer/agent.train_min": 0.35375452041625977, "timer/agent.train_max": 0.42355895042419434, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4268472194671631, "timer/agent.report_frac": 0.00085358227975837, "timer/agent.report_avg": 0.21342360973358154, "timer/agent.report_min": 0.21327948570251465, "timer/agent.report_max": 0.21356773376464844, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.7206878662109375e-05, "timer/dataset_eval_frac": 9.440135315624311e-08, "timer/dataset_eval_avg": 4.7206878662109375e-05, "timer/dataset_eval_min": 4.7206878662109375e-05, "timer/dataset_eval_max": 4.7206878662109375e-05, "fps": 39.994162095591285}
{"step": 664200, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216}
{"step": 664368, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 664544, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 664752, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 664808, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 664968, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 665280, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 665288, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 665384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 665624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 665800, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 665904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 666280, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 666304, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 666336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 666480, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 666680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 666800, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 667160, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 667208, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 667240, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 667248, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 667280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 667776, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 667896, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 667912, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 668032, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 668112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 668216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 668240, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 668376, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304}
{"step": 668464, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301}
{"step": 668480, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 668680, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 668792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 668824, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 668936, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 668976, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 669088, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 669432, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 669776, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 669808, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 670016, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 670040, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 670072, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 670072, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 670072, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 670072, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 670072, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 670072, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 670072, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 670072, "eval_episode/length": 187.0, "eval_episode/score": 0.4156250059604645, "eval_episode/reward_rate": 0.005319148936170213}
{"step": 670224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 670320, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 670552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 670656, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 670696, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 670824, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 670944, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 671016, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 671104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 671176, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 671200, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 671592, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 671624, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 671744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 671784, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 671944, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 671968, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 671992, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 672240, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 672312, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 672592, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 672608, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182}
{"step": 672768, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 672808, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 672864, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 672968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 673008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 673176, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 673920, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 673944, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 674192, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301}
{"step": 674264, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 674304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 674464, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495}
{"step": 674496, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 674808, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 674816, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 674840, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036}
{"step": 674864, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 674904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 675120, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 675400, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 675608, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 675648, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248}
{"step": 675800, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 675816, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061}
{"step": 675912, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 676024, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391}
{"step": 676288, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 676352, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 676360, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 676616, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 676904, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839}
{"step": 676904, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 677088, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 677096, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757}
{"step": 677176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 677336, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903}
{"step": 677696, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 677840, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 678104, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 678128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 678152, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 678320, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 678504, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315}
{"step": 678600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 678672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 679016, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 679144, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 679232, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 679256, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444}
{"step": 679264, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 679408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 679632, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 679664, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 679816, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 679896, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 680056, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 680056, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 680056, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 680056, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 680056, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 680056, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 680056, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 680056, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 680536, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 680544, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 680704, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128}
{"step": 680784, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444}
{"step": 680912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 681568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 681808, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633}
{"step": 681824, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 681960, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 681976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 682120, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294}
{"step": 682128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 682472, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 682512, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 682776, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 682808, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 682848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 683192, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 683224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 683376, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641}
{"step": 683448, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 683720, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 683784, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 683833, "train_stats/mean_log_entropy": 0.08858724885309736, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3625835635797765, "train/action_min": 0.0, "train/action_std": 1.817981621114219, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013607037244213185, "train/actor_opt_grad_steps": 42030.0, "train/actor_opt_loss": -9.104340066512426, "train/adv_mag": 1.2776703781228724, "train/adv_max": 0.36596944564726297, "train/adv_mean": 0.0011446417451954247, "train/adv_min": -1.2722558592393147, "train/adv_std": 0.04290709836877943, "train/cont_avg": 0.994823424796748, "train/cont_loss_mean": 0.016690473127125845, "train/cont_loss_std": 0.23070389973529712, "train/cont_neg_acc": 0.39501989239115054, "train/cont_neg_loss": 2.4910570062674218, "train/cont_pos_acc": 0.9998003922826876, "train/cont_pos_loss": 0.0033282579662944605, "train/cont_pred": 0.9949672682498528, "train/cont_rate": 0.994823424796748, "train/dyn_loss_mean": 1.0000048788582407, "train/dyn_loss_std": 0.0001543931968508258, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.21719983230700823, "train/extr_critic_critic_opt_grad_steps": 42030.0, "train/extr_critic_critic_opt_loss": 12735.0810546875, "train/extr_critic_mag": 1.5000279744466145, "train/extr_critic_max": 1.5000279744466145, "train/extr_critic_mean": 1.4296050992438463, "train/extr_critic_min": 1.195539345586203, "train/extr_critic_std": 0.02089448853176299, "train/extr_return_normed_mag": 1.2676201147761772, "train/extr_return_normed_max": 0.3140795928675954, "train/extr_return_normed_mean": 0.03889620928775247, "train/extr_return_normed_min": -1.2576464036615884, "train/extr_return_normed_std": 0.048214779606437295, "train/extr_return_rate": 0.9990171363683251, "train/extr_return_raw_mag": 1.7059330591341344, "train/extr_return_raw_max": 1.7059330591341344, "train/extr_return_raw_mean": 1.4307497390886632, "train/extr_return_raw_min": 0.1342070626049507, "train/extr_return_raw_std": 0.048214779924449884, "train/extr_reward_mag": 0.3428131303166955, "train/extr_reward_max": 0.3428131303166955, "train/extr_reward_mean": 0.0026143598550082588, "train/extr_reward_min": 1.1727092711906123e-07, "train/extr_reward_std": 0.010737547355635865, "train/image_loss_mean": 0.0949346661204245, "train/image_loss_std": 0.10307327779085655, "train/model_loss_mean": 0.7228816500524196, "train/model_loss_std": 0.4133771612513356, "train/model_opt_grad_norm": 20.793251262447697, "train/model_opt_grad_steps": 41994.12195121951, "train/model_opt_loss": 3879.812740170859, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5365.8536585365855, "train/policy_entropy_mag": 1.3316588818542356, "train/policy_entropy_max": 1.3316588818542356, "train/policy_entropy_mean": 0.10792837055718027, "train/policy_entropy_min": 0.06468649462955754, "train/policy_entropy_std": 0.13924505725139524, "train/policy_logprob_mag": 6.551080254035267, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10751011579986511, "train/policy_logprob_min": -6.551080254035267, "train/policy_logprob_std": 0.6420871920701934, "train/policy_randomness_mag": 0.6843373319967007, "train/policy_randomness_max": 0.6843373319967007, "train/policy_randomness_mean": 0.05546421372914702, "train/policy_randomness_min": 0.03324228279837748, "train/policy_randomness_std": 0.07155780784967469, "train/post_ent_mag": 50.55913903461239, "train/post_ent_max": 50.55913903461239, "train/post_ent_mean": 49.04851978581126, "train/post_ent_min": 48.0607230333778, "train/post_ent_std": 0.4836585480507796, "train/prior_ent_mag": 52.58844633024882, "train/prior_ent_max": 52.58844633024882, "train/prior_ent_mean": 48.50139131003279, "train/prior_ent_min": 45.44897231435388, "train/prior_ent_std": 1.1979870437606563, "train/rep_loss_mean": 1.0000048788582407, "train/rep_loss_std": 0.0001543931968508258, "train/reward_avg": 0.0015713327355603346, "train/reward_loss_mean": 0.01125355895676809, "train/reward_loss_std": 0.18650581708132494, "train/reward_max_data": 0.7035315048888446, "train/reward_max_pred": 0.23366670007628154, "train/reward_neg_acc": 0.9996816627378386, "train/reward_neg_loss": 0.0020134003725985625, "train/reward_pos_acc": 0.2103244850857068, "train/reward_pos_loss": 4.0436094213376, "train/reward_pred": 0.0012321545131035087, "train/reward_rate": 0.0022945248983739838, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.023493610322475433, "report/cont_loss_std": 0.2797321677207947, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 2.9587531089782715, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.006193457171320915, "report/cont_pred": 0.9924821853637695, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08572602272033691, "report/image_loss_std": 0.09918751567602158, "report/model_loss_mean": 0.7266820073127747, "report/model_loss_std": 0.5292508006095886, "report/post_ent_mag": 52.09334945678711, "report/post_ent_max": 52.09334945678711, "report/post_ent_mean": 50.7054328918457, "report/post_ent_min": 49.6223258972168, "report/post_ent_std": 0.45998188853263855, "report/prior_ent_mag": 53.44379425048828, "report/prior_ent_max": 53.44379425048828, "report/prior_ent_mean": 49.950653076171875, "report/prior_ent_min": 46.80768585205078, "report/prior_ent_std": 1.1295709609985352, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014892577892169356, "report/reward_loss_mean": 0.017462357878684998, "report/reward_loss_std": 0.29141515493392944, "report/reward_max_data": 0.6968749761581421, "report/reward_max_pred": 0.2112034559249878, "report/reward_neg_acc": 0.999020516872406, "report/reward_neg_loss": 0.003508451860398054, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 4.766441822052002, "report/reward_pred": 0.0020700087770819664, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.012029804289340973, "eval/cont_loss_std": 0.20639662444591522, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.127184867858887, "eval/cont_pos_acc": 0.9990224838256836, "eval/cont_pos_loss": 0.006052135024219751, "eval/cont_pred": 0.9955384731292725, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1378253698348999, "eval/image_loss_std": 0.13971732556819916, "eval/model_loss_mean": 0.7526374459266663, "eval/model_loss_std": 0.254901647567749, "eval/post_ent_mag": 52.08985900878906, "eval/post_ent_max": 52.08985900878906, "eval/post_ent_mean": 50.53556823730469, "eval/post_ent_min": 49.54844665527344, "eval/post_ent_std": 0.4622257649898529, "eval/prior_ent_mag": 53.40837860107422, "eval/prior_ent_max": 53.40837860107422, "eval/prior_ent_mean": 49.549468994140625, "eval/prior_ent_min": 46.95598602294922, "eval/prior_ent_std": 1.1234519481658936, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0027822465635836124, "eval/reward_loss_std": 0.02763260342180729, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.26773643493652344, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.0027822465635836124, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0012122798943892121, "eval/reward_rate": 0.0, "replay/size": 683329.0, "replay/inserts": 19664.0, "replay/samples": 19664.0, "replay/insert_wait_avg": 1.2520612789616534e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.644133073513443e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2648.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1795777208495357e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2381613254547, "timer/env.step_count": 2458.0, "timer/env.step_total": 5.42091178894043, "timer/env.step_frac": 0.010836661830390799, "timer/env.step_avg": 0.002205415699324829, "timer/env.step_min": 0.0010914802551269531, "timer/env.step_max": 0.008554935455322266, "timer/replay._sample_count": 19664.0, "timer/replay._sample_total": 1333.4367785453796, "timer/replay._sample_frac": 2.6656038695893223, "timer/replay._sample_avg": 0.06781106481618082, "timer/replay._sample_min": 0.0004978179931640625, "timer/replay._sample_max": 0.0950162410736084, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2789.0, "timer/agent.policy_total": 18.68973422050476, "timer/agent.policy_frac": 0.0373616722302504, "timer/agent.policy_avg": 0.006701231344748928, "timer/agent.policy_min": 0.005213260650634766, "timer/agent.policy_max": 0.01079702377319336, "timer/dataset_train_count": 1229.0, "timer/dataset_train_total": 0.09599137306213379, "timer/dataset_train_frac": 0.00019189134393063996, "timer/dataset_train_avg": 7.810526693420162e-05, "timer/dataset_train_min": 5.984306335449219e-05, "timer/dataset_train_max": 0.00023508071899414062, "timer/agent.train_count": 1229.0, "timer/agent.train_total": 469.4250707626343, "timer/agent.train_frac": 0.9384031588450257, "timer/agent.train_avg": 0.3819569330859514, "timer/agent.train_min": 0.3503415584564209, "timer/agent.train_max": 0.4884452819824219, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.430478572845459, "timer/agent.report_frac": 0.0008605472475447346, "timer/agent.report_avg": 0.2152392864227295, "timer/agent.report_min": 0.21510863304138184, "timer/agent.report_max": 0.21536993980407715, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.647804260253906e-05, "timer/dataset_eval_frac": 7.29213511138077e-08, "timer/dataset_eval_avg": 3.647804260253906e-05, "timer/dataset_eval_min": 3.647804260253906e-05, "timer/dataset_eval_max": 3.647804260253906e-05, "fps": 39.3088017693446}
{"step": 683944, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 684384, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 684432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 684928, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732}
{"step": 684944, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 684976, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154}
{"step": 685016, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653}
{"step": 685088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 685112, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216}
{"step": 685144, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667}
{"step": 685304, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 685504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 685616, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 685896, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 686208, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494}
{"step": 686488, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 686720, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 687256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 687328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 687336, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 687400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 687416, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 687520, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 687616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 687848, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 687928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 688032, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 688168, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 688320, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 688520, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 688664, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 688688, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 688920, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 688984, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 689312, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 689560, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 689568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 689640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 689688, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 689712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 690016, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 690040, "eval_episode/length": 11.0, "eval_episode/score": 0.965624988079071, "eval_episode/reward_rate": 0.08333333333333333}
{"step": 690040, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 690040, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 690040, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 690040, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 690040, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 690040, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 690040, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 690064, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 690312, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 690424, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 690712, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 690888, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 690912, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 691000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 691624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 691712, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 691736, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 691872, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 691952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 692024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 692104, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 692376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 692616, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 692624, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 692776, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 692904, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625}
{"step": 693136, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633}
{"step": 693152, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 693176, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694}
{"step": 693200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 693232, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 693480, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 693768, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 693896, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 693904, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 694488, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 694560, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 694688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 694712, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494}
{"step": 694792, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135}
{"step": 694872, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 694944, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 695144, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 695216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 695304, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 695488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 695568, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 695600, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 695984, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 696104, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 696144, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 696216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 696240, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 696296, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842}
{"step": 696456, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 696512, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035}
{"step": 696848, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705}
{"step": 696872, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 696912, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 697256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 697328, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 697384, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 697416, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 697448, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 697592, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 697808, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 697816, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 697840, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 697880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 697960, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 698480, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 698496, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 698528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 698592, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 698744, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 698840, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 698864, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 699024, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 699120, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 699144, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 699176, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 699640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 699808, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 699816, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 699968, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 700024, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 700024, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 700024, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 700024, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 700024, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 700024, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 700024, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 700024, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 700056, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 700080, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142}
{"step": 700128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 700192, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169}
{"step": 700208, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 700272, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664}
{"step": 700368, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 700512, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333}
{"step": 700600, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 700640, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 700696, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 700768, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 700928, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 701056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 701056, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 701168, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 701224, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 701264, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 701648, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 701704, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 701768, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 701976, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 702048, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 702912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 702984, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625}
{"step": 703048, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625}
{"step": 703080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 703368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 703504, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 703600, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 703784, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 703800, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 703865, "train_stats/mean_log_entropy": 0.08619097472224015, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2108212890625, "train/action_min": 0.0, "train/action_std": 1.7487408351898193, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012091634329408407, "train/actor_opt_grad_steps": 43270.0, "train/actor_opt_loss": -10.51458531665802, "train/adv_mag": 1.2052800302505493, "train/adv_max": 0.32994340801239014, "train/adv_mean": 0.0013496347881628025, "train/adv_min": -1.1805218515396119, "train/adv_std": 0.04017246587947011, "train/cont_avg": 0.99471875, "train/cont_loss_mean": 0.017231496162712575, "train/cont_loss_std": 0.2311558748781681, "train/cont_neg_acc": 0.34473507189750674, "train/cont_neg_loss": 2.605118291556835, "train/cont_pos_acc": 0.9999057683944702, "train/cont_pos_loss": 0.0033957083458080886, "train/cont_pred": 0.9949502940177918, "train/cont_rate": 0.99471875, "train/dyn_loss_mean": 1.0000048036575317, "train/dyn_loss_std": 0.0001405062660924159, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.21975905792415143, "train/extr_critic_critic_opt_grad_steps": 43270.0, "train/extr_critic_critic_opt_loss": 12199.28515625, "train/extr_critic_mag": 1.5173929386138916, "train/extr_critic_max": 1.5173929386138916, "train/extr_critic_mean": 1.444371724128723, "train/extr_critic_min": 1.216579321861267, "train/extr_critic_std": 0.02298519466817379, "train/extr_return_normed_mag": 1.1944511041641235, "train/extr_return_normed_max": 0.2951883907318115, "train/extr_return_normed_mean": 0.044969746939837935, "train/extr_return_normed_min": -1.1658122215270996, "train/extr_return_normed_std": 0.047257438004016876, "train/extr_return_rate": 0.9991047315597534, "train/extr_return_raw_mag": 1.6959399251937866, "train/extr_return_raw_max": 1.6959399251937866, "train/extr_return_raw_mean": 1.4457213459014893, "train/extr_return_raw_min": 0.2349393129348755, "train/extr_return_raw_std": 0.04725743791460991, "train/extr_reward_mag": 0.3322783060073852, "train/extr_reward_max": 0.3322783060073852, "train/extr_reward_mean": 0.002580457029864192, "train/extr_reward_min": 1.125335693359375e-07, "train/extr_reward_std": 0.009722146134823561, "train/image_loss_mean": 0.09349317017197609, "train/image_loss_std": 0.10245852214097977, "train/model_loss_mean": 0.7236545844078064, "train/model_loss_std": 0.435927341401577, "train/model_opt_grad_norm": 20.928692092895506, "train/model_opt_grad_steps": 43232.768, "train/model_opt_loss": 3618.27290625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.3129002923965454, "train/policy_entropy_max": 1.3129002923965454, "train/policy_entropy_mean": 0.10125713402032852, "train/policy_entropy_min": 0.06468649345636368, "train/policy_entropy_std": 0.12893624663352965, "train/policy_logprob_mag": 6.551080245971679, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10195307356119156, "train/policy_logprob_min": -6.551080245971679, "train/policy_logprob_std": 0.6427438316345215, "train/policy_randomness_mag": 0.6746973247528076, "train/policy_randomness_max": 0.6746973247528076, "train/policy_randomness_mean": 0.05203587651252747, "train/policy_randomness_min": 0.03324228221178055, "train/policy_randomness_std": 0.06626012727618218, "train/post_ent_mag": 50.39456707763672, "train/post_ent_max": 50.39456707763672, "train/post_ent_mean": 48.90974047851562, "train/post_ent_min": 47.89747045898437, "train/post_ent_std": 0.4844510006904602, "train/prior_ent_mag": 52.60057809448242, "train/prior_ent_max": 52.60057809448242, "train/prior_ent_mean": 48.346951263427734, "train/prior_ent_min": 45.57788119506836, "train/prior_ent_std": 1.1559616765975953, "train/rep_loss_mean": 1.0000048036575317, "train/rep_loss_std": 0.0001405062660924159, "train/reward_avg": 0.001852319334866479, "train/reward_loss_mean": 0.012927012177184224, "train/reward_loss_std": 0.20516684271022678, "train/reward_max_data": 0.7594499990940095, "train/reward_max_pred": 0.27023704528808595, "train/reward_neg_acc": 0.9996865758895874, "train/reward_neg_loss": 0.0022081697806715967, "train/reward_pos_acc": 0.21863439814610916, "train/reward_pos_loss": 3.90762187281916, "train/reward_pred": 0.0014092174554243683, "train/reward_rate": 0.002734375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01366013940423727, "report/cont_loss_std": 0.18175162374973297, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 2.6705238819122314, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003241065191105008, "report/cont_pred": 0.9962155818939209, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09216120839118958, "report/image_loss_std": 0.10943926125764847, "report/model_loss_mean": 0.715997576713562, "report/model_loss_std": 0.3751153349876404, "report/post_ent_mag": 50.573150634765625, "report/post_ent_max": 50.573150634765625, "report/post_ent_mean": 49.13331604003906, "report/post_ent_min": 48.12498474121094, "report/post_ent_std": 0.4728584885597229, "report/prior_ent_mag": 52.161834716796875, "report/prior_ent_max": 52.161834716796875, "report/prior_ent_mean": 48.450904846191406, "report/prior_ent_min": 45.470916748046875, "report/prior_ent_std": 1.045930027961731, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0011138916015625, "report/reward_loss_mean": 0.010176203213632107, "report/reward_loss_std": 0.1811995953321457, "report/reward_max_data": 0.6312500238418579, "report/reward_max_pred": 0.029374122619628906, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002193671651184559, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.089249610900879, "report/reward_pred": 0.001147766481153667, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.038169942796230316, "eval/cont_loss_std": 0.5599221587181091, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.578818321228027, "eval/cont_pos_acc": 0.9980391263961792, "eval/cont_pos_loss": 0.00859877374023199, "eval/cont_pred": 0.9953823089599609, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20058724284172058, "eval/image_loss_std": 0.1596032828092575, "eval/model_loss_mean": 0.8422120809555054, "eval/model_loss_std": 0.5812439322471619, "eval/post_ent_mag": 50.57331085205078, "eval/post_ent_max": 50.57331085205078, "eval/post_ent_mean": 49.0645866394043, "eval/post_ent_min": 48.119102478027344, "eval/post_ent_std": 0.4712594747543335, "eval/prior_ent_mag": 52.294734954833984, "eval/prior_ent_max": 52.294734954833984, "eval/prior_ent_mean": 48.248931884765625, "eval/prior_ent_min": 45.77501678466797, "eval/prior_ent_std": 1.091890573501587, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005859375232830644, "eval/reward_loss_mean": 0.0034548689145594835, "eval/reward_loss_std": 0.06422051042318344, "eval/reward_max_data": 0.6000000238418579, "eval/reward_max_pred": 0.1307295560836792, "eval/reward_neg_acc": 0.9980449676513672, "eval/reward_neg_loss": 0.0014822466764599085, "eval/reward_pos_acc": 1.0, "eval/reward_pos_loss": 2.0214474201202393, "eval/reward_pred": 0.0008504893630743027, "eval/reward_rate": 0.0009765625, "replay/size": 703361.0, "replay/inserts": 20032.0, "replay/samples": 20032.0, "replay/insert_wait_avg": 1.239795654345625e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.49379152992663e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2392.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2645553984370918e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.2157289981842, "timer/env.step_count": 2504.0, "timer/env.step_total": 5.446593523025513, "timer/env.step_frac": 0.01088848912035168, "timer/env.step_avg": 0.0021751571577577926, "timer/env.step_min": 0.001104593276977539, "timer/env.step_max": 0.008109807968139648, "timer/replay._sample_count": 20032.0, "timer/replay._sample_total": 1350.3997979164124, "timer/replay._sample_frac": 2.69963481680384, "timer/replay._sample_avg": 0.06741213048704135, "timer/replay._sample_min": 0.00034332275390625, "timer/replay._sample_max": 0.09330630302429199, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2803.0, "timer/agent.policy_total": 18.497454404830933, "timer/agent.policy_frac": 0.03697895394428526, "timer/agent.policy_avg": 0.00659916318402816, "timer/agent.policy_min": 0.0052187442779541016, "timer/agent.policy_max": 0.00977778434753418, "timer/dataset_train_count": 1252.0, "timer/dataset_train_total": 0.09800481796264648, "timer/dataset_train_frac": 0.00019592510247314163, "timer/dataset_train_avg": 7.8278608596363e-05, "timer/dataset_train_min": 5.745887756347656e-05, "timer/dataset_train_max": 0.00017189979553222656, "timer/agent.train_count": 1252.0, "timer/agent.train_total": 470.3187367916107, "timer/agent.train_frac": 0.9402318030533542, "timer/agent.train_avg": 0.37565394312428974, "timer/agent.train_min": 0.353334903717041, "timer/agent.train_max": 0.4695866107940674, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4238009452819824, "timer/agent.report_frac": 0.000847236343668675, "timer/agent.report_avg": 0.2119004726409912, "timer/agent.report_min": 0.21100068092346191, "timer/agent.report_max": 0.2128002643585205, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 6.672841164164975e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 40.04608595530351}
{"step": 703944, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 703960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 704224, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 704288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 704360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 704376, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 704504, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 704560, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 704560, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 704680, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 704776, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 704856, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 704872, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 705064, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 705272, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 705312, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 705336, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 705416, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 705448, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 705560, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903}
{"step": 705952, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 705984, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 706032, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 706208, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125}
{"step": 706536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 706544, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 706936, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093}
{"step": 706984, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 707168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 707224, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 707648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 707656, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 707696, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 707760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 707896, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04}
{"step": 708080, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 708136, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667}
{"step": 708160, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 708232, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 708296, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 708536, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 708768, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 708848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 708856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 708976, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 709312, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 709520, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 709536, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 709664, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 709712, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 709744, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464}
{"step": 709928, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 710008, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 710008, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 710008, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 710008, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 710008, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 710008, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 710008, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 710008, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 710072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 710328, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 710544, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 710608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 710640, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 710848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 710880, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 710968, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025}
{"step": 711120, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 711368, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 711536, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 711568, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 711808, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 711976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 712048, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 712112, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705}
{"step": 712264, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 712280, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 712384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 712632, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 712640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 712664, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 712736, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 712928, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304}
{"step": 713080, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 713152, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 713160, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 713192, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 713432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 713616, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 713640, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 713800, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 713904, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 714064, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 714064, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 714176, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 714192, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 714360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 714408, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 714592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 714752, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 714776, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 714792, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 714936, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 715432, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 715504, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 715664, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 715680, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 715904, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877}
{"step": 716000, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641}
{"step": 716112, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 716112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 716392, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 716432, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 716456, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 716504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 716632, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04}
{"step": 716776, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 716888, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 716936, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 717184, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 717216, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025}
{"step": 717216, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 717544, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 717616, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 717816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 717976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 718072, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839}
{"step": 718160, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 718376, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 718528, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 718672, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 718680, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 718728, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 718808, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 719192, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 719240, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 719248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 719336, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 719528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 719552, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 719752, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 719856, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 720096, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 720096, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 720096, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 720096, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 720096, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 720096, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 720096, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 720096, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 720112, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 720160, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 720264, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 720368, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 720376, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 720488, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025}
{"step": 720552, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456}
{"step": 720840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 721040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 721072, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 721072, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 721144, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 721392, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522}
{"step": 721400, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 721512, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 721616, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 721744, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 721944, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 721952, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 722128, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 722160, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 722384, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 722576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 722712, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 722984, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 723208, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 723352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 723528, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 723832, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 723913, "train_stats/mean_log_entropy": 0.0724001978864757, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1687158203125, "train/action_min": 0.0, "train/action_std": 1.783076629638672, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01134180684387684, "train/actor_opt_grad_steps": 44520.0, "train/actor_opt_loss": -10.838408388137818, "train/adv_mag": 1.1368548064231871, "train/adv_max": 0.2646013774871826, "train/adv_mean": 0.0015919851220969577, "train/adv_min": -1.1070230536460877, "train/adv_std": 0.03834142721444368, "train/cont_avg": 0.9950859375, "train/cont_loss_mean": 0.01578793668933213, "train/cont_loss_std": 0.21894637016952037, "train/cont_neg_acc": 0.34442857807874677, "train/cont_neg_loss": 2.5426761374399067, "train/cont_pos_acc": 0.9998350877761841, "train/cont_pos_loss": 0.003360504413023591, "train/cont_pred": 0.9951772875785828, "train/cont_rate": 0.9950859375, "train/dyn_loss_mean": 1.0000063486099242, "train/dyn_loss_std": 0.00019364787091035395, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1885721166729927, "train/extr_critic_critic_opt_grad_steps": 44520.0, "train/extr_critic_critic_opt_loss": 10431.8501328125, "train/extr_critic_mag": 1.5465354957580566, "train/extr_critic_max": 1.5465354957580566, "train/extr_critic_mean": 1.4800604400634765, "train/extr_critic_min": 1.3732157135009766, "train/extr_critic_std": 0.02376792387664318, "train/extr_return_normed_mag": 1.1255958576202392, "train/extr_return_normed_max": 0.3019043846130371, "train/extr_return_normed_mean": 0.04888228803873062, "train/extr_return_normed_min": -1.0811215677261352, "train/extr_return_normed_std": 0.046157377392053604, "train/extr_return_rate": 0.9992068090438843, "train/extr_return_raw_mag": 1.7346744451522826, "train/extr_return_raw_max": 1.7346744451522826, "train/extr_return_raw_mean": 1.4816524305343628, "train/extr_return_raw_min": 0.35164849281311034, "train/extr_return_raw_std": 0.046157377019524576, "train/extr_reward_mag": 0.31212544441223145, "train/extr_reward_max": 0.31212544441223145, "train/extr_reward_mean": 0.0024800692349672315, "train/extr_reward_min": 1.0967254638671875e-07, "train/extr_reward_std": 0.009059614289551973, "train/image_loss_mean": 0.09123025465011597, "train/image_loss_std": 0.10139779090881347, "train/model_loss_mean": 0.7189605216979981, "train/model_loss_std": 0.41704435765743253, "train/model_opt_grad_norm": 20.101425376892088, "train/model_opt_grad_steps": 44481.576, "train/model_opt_loss": 3623.393390625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5040.0, "train/policy_entropy_mag": 1.3035390253067016, "train/policy_entropy_max": 1.3035390253067016, "train/policy_entropy_mean": 0.09822758054733276, "train/policy_entropy_min": 0.06468649309873581, "train/policy_entropy_std": 0.12406957244873047, "train/policy_logprob_mag": 6.551080234527588, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09865433806180954, "train/policy_logprob_min": -6.551080234527588, "train/policy_logprob_std": 0.6381001486778259, "train/policy_randomness_mag": 0.6698865866661072, "train/policy_randomness_max": 0.6698865866661072, "train/policy_randomness_mean": 0.05047899368405342, "train/policy_randomness_min": 0.033242282032966614, "train/policy_randomness_std": 0.06375915160775185, "train/post_ent_mag": 50.07950900268555, "train/post_ent_max": 50.07950900268555, "train/post_ent_mean": 48.588963165283204, "train/post_ent_min": 47.594876312255856, "train/post_ent_std": 0.48764571332931517, "train/prior_ent_mag": 52.19532388305664, "train/prior_ent_max": 52.19532388305664, "train/prior_ent_mean": 47.87292474365234, "train/prior_ent_min": 45.070510528564455, "train/prior_ent_std": 1.1270265097618104, "train/rep_loss_mean": 1.0000063486099242, "train/rep_loss_std": 0.00019364787091035395, "train/reward_avg": 0.001648120116791688, "train/reward_loss_mean": 0.011938496054150163, "train/reward_loss_std": 0.19481083519384265, "train/reward_max_data": 0.6938749998807907, "train/reward_max_pred": 0.22734148216247557, "train/reward_neg_acc": 0.999788486480713, "train/reward_neg_loss": 0.0020798273631371556, "train/reward_pos_acc": 0.18700739111879777, "train/reward_pos_loss": 3.999896983648169, "train/reward_pred": 0.0012947326712310315, "train/reward_rate": 0.0024765625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01579182595014572, "report/cont_loss_std": 0.20411962270736694, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.0916810035705566, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00372951477766037, "report/cont_pred": 0.9960265159606934, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08631843328475952, "report/image_loss_std": 0.08325063437223434, "report/model_loss_mean": 0.7107256650924683, "report/model_loss_std": 0.31007030606269836, "report/post_ent_mag": 49.12950897216797, "report/post_ent_max": 49.12950897216797, "report/post_ent_mean": 47.605690002441406, "report/post_ent_min": 46.48005676269531, "report/post_ent_std": 0.5197733044624329, "report/prior_ent_mag": 52.223575592041016, "report/prior_ent_max": 52.223575592041016, "report/prior_ent_mean": 47.720069885253906, "report/prior_ent_min": 44.829383850097656, "report/prior_ent_std": 1.1066542863845825, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014007568825036287, "report/reward_loss_mean": 0.008615419268608093, "report/reward_loss_std": 0.1357523649930954, "report/reward_max_data": 0.737500011920929, "report/reward_max_pred": 0.0985410213470459, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0027030021883547306, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.029860496520996, "report/reward_pred": 0.0015105956699699163, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.07171308994293213, "eval/cont_loss_std": 0.9178930521011353, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.968761444091797, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001592957996763289, "eval/cont_pred": 0.9984304904937744, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2015233039855957, "eval/image_loss_std": 0.15169072151184082, "eval/model_loss_mean": 0.8936419486999512, "eval/model_loss_std": 1.2337219715118408, "eval/post_ent_mag": 49.13595199584961, "eval/post_ent_max": 49.13595199584961, "eval/post_ent_mean": 47.54459762573242, "eval/post_ent_min": 46.58380126953125, "eval/post_ent_std": 0.525982141494751, "eval/prior_ent_mag": 52.13164520263672, "eval/prior_ent_max": 52.13164520263672, "eval/prior_ent_mean": 47.6695556640625, "eval/prior_ent_min": 45.35757827758789, "eval/prior_ent_std": 1.0922982692718506, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0013275146484375, "eval/reward_loss_mean": 0.020405523478984833, "eval/reward_loss_std": 0.44700154662132263, "eval/reward_max_data": 0.8125, "eval/reward_max_pred": 0.027411818504333496, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0008828742429614067, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.996479034423828, "eval/reward_pred": 0.00045726122334599495, "eval/reward_rate": 0.001953125, "replay/size": 723409.0, "replay/inserts": 20048.0, "replay/samples": 20048.0, "replay/insert_wait_avg": 1.2337638203467926e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.449448598449171e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2272.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2158088281121051e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.10053157806396, "timer/env.step_count": 2506.0, "timer/env.step_total": 5.4580700397491455, "timer/env.step_frac": 0.010913945687132628, "timer/env.step_avg": 0.002178000813946187, "timer/env.step_min": 0.001069784164428711, "timer/env.step_max": 0.010199308395385742, "timer/replay._sample_count": 20048.0, "timer/replay._sample_total": 1347.6447041034698, "timer/replay._sample_frac": 2.694747593750772, "timer/replay._sample_avg": 0.06722090503309407, "timer/replay._sample_min": 0.0003178119659423828, "timer/replay._sample_max": 0.09192132949829102, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2790.0, "timer/agent.policy_total": 18.26444101333618, "timer/agent.policy_frac": 0.03652153889079633, "timer/agent.policy_avg": 0.006546394628435907, "timer/agent.policy_min": 0.005071878433227539, "timer/agent.policy_max": 0.009517669677734375, "timer/dataset_train_count": 1253.0, "timer/dataset_train_total": 0.09679365158081055, "timer/dataset_train_frac": 0.00019354838771192426, "timer/dataset_train_avg": 7.724952241086236e-05, "timer/dataset_train_min": 5.650520324707031e-05, "timer/dataset_train_max": 0.000232696533203125, "timer/agent.train_count": 1253.0, "timer/agent.train_total": 470.25136399269104, "timer/agent.train_frac": 0.940313665552036, "timer/agent.train_avg": 0.37530037030541985, "timer/agent.train_min": 0.3514549732208252, "timer/agent.train_max": 0.621849536895752, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.42836713790893555, "timer/agent.report_frac": 0.0008565620527481261, "timer/agent.report_avg": 0.21418356895446777, "timer/agent.report_min": 0.21269989013671875, "timer/agent.report_max": 0.2156672477722168, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 7.00809715545341e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 40.087423193931436}
{"step": 723920, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391}
{"step": 723928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 724088, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 724256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 724264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 724416, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 724816, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 724960, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 725216, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 725296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 725312, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 725344, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875}
{"step": 725552, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333}
{"step": 725800, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 725920, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 725968, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 726144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 726240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 726400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 726416, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 726608, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 726672, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 726952, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 726976, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 727128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 727208, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 727224, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 727360, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655}
{"step": 727472, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 727680, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 728032, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 728208, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 728416, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 728552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 728728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 728984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 729040, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 729304, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 729480, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 729480, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 729520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 729536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 729992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 730000, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 730080, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 730080, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 730080, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 730080, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 730080, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 730080, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 730080, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 730080, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 730096, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 730152, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 730296, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555}
{"step": 730368, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 730728, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641}
{"step": 730728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 730744, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 730784, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 730824, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 731008, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 731400, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 731400, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 731512, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 731712, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 731832, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 731848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 731968, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 732032, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 732312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 732632, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 732704, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 732712, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 732976, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 733184, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 733320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 733648, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 733672, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 733696, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 733712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 733976, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 734144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 734240, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 734280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 734472, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 734528, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 734536, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 734552, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 734792, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 734976, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 735088, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 735360, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 735408, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 735616, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 735632, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 735880, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 736008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 736104, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756}
{"step": 736248, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555}
{"step": 736384, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 736464, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 736592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 736848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 737048, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 737064, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 737184, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 737384, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 737920, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 737928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 737944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 737992, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 738072, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625}
{"step": 738312, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 738320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 738696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 738720, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 738776, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 738840, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 739152, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 739360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 739392, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 739408, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 739496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 739784, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 739928, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 739936, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842}
{"step": 740064, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 740064, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 740064, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 740064, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 740064, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 740064, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 740064, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 740064, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 740232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 740248, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182}
{"step": 740472, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 740584, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 740672, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 740856, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705}
{"step": 741008, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 741432, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 741464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 741480, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 741552, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 741800, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 741832, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 741952, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 742248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 742496, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 742544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 742672, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 742776, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 742784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 743048, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 743168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 743416, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 743417, "train_stats/mean_log_entropy": 0.08052075134826378, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2022760109823256, "train/action_min": 0.0, "train/action_std": 1.8070797881142038, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011386583688989526, "train/actor_opt_grad_steps": 45755.0, "train/actor_opt_loss": -12.365065078266332, "train/adv_mag": 1.1591162877004655, "train/adv_max": 0.1955480839385361, "train/adv_mean": 0.0010217985970976755, "train/adv_min": -1.141697036438301, "train/adv_std": 0.030892128109565525, "train/cont_avg": 0.9945488601434426, "train/cont_loss_mean": 0.01688669554623928, "train/cont_loss_std": 0.22910110437555514, "train/cont_neg_acc": 0.3533860338760204, "train/cont_neg_loss": 2.4627498128970506, "train/cont_pos_acc": 0.9998631257502759, "train/cont_pos_loss": 0.0034304523046632283, "train/cont_pred": 0.9947510889319123, "train/cont_rate": 0.9945488601434426, "train/dyn_loss_mean": 1.000024754492963, "train/dyn_loss_std": 0.00032130216271473387, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15733145887306968, "train/extr_critic_critic_opt_grad_steps": 45755.0, "train/extr_critic_critic_opt_loss": 8263.198146132172, "train/extr_critic_mag": 1.5698231106898823, "train/extr_critic_max": 1.5698231106898823, "train/extr_critic_mean": 1.509169551192737, "train/extr_critic_min": 1.391586845038367, "train/extr_critic_std": 0.02420371796813656, "train/extr_return_normed_mag": 1.1551689642374632, "train/extr_return_normed_max": 0.2270152539503379, "train/extr_return_normed_mean": 0.04625211011801587, "train/extr_return_normed_min": -1.1227995372209392, "train/extr_return_normed_std": 0.040548635463489864, "train/extr_return_rate": 0.999440786779904, "train/extr_return_raw_mag": 1.6909544252958455, "train/extr_return_raw_max": 1.6909544252958455, "train/extr_return_raw_mean": 1.510191358503748, "train/extr_return_raw_min": 0.34113963412456827, "train/extr_return_raw_std": 0.04054863569250361, "train/extr_reward_mag": 0.2216756920345494, "train/extr_reward_max": 0.2216756920345494, "train/extr_reward_mean": 0.002247660493356038, "train/extr_reward_min": 1.1823216422659452e-07, "train/extr_reward_std": 0.0071721200899938576, "train/image_loss_mean": 0.09021059576360906, "train/image_loss_std": 0.1017280406028521, "train/model_loss_mean": 0.7200854904338961, "train/model_loss_std": 0.43441269558961276, "train/model_opt_grad_norm": 19.726179685748992, "train/model_opt_grad_steps": 45715.41803278688, "train/model_opt_loss": 3714.330130154969, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5163.934426229508, "train/policy_entropy_mag": 1.3339409046485775, "train/policy_entropy_max": 1.3339409046485775, "train/policy_entropy_mean": 0.09898772426560278, "train/policy_entropy_min": 0.06468649269616017, "train/policy_entropy_std": 0.1244442877588702, "train/policy_logprob_mag": 6.551080254257703, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09953189409169995, "train/policy_logprob_min": -6.551080254257703, "train/policy_logprob_std": 0.6395320848363345, "train/policy_randomness_mag": 0.685510060826286, "train/policy_randomness_max": 0.685510060826286, "train/policy_randomness_mean": 0.0508696299779122, "train/policy_randomness_min": 0.033242281831678794, "train/policy_randomness_std": 0.06395171695678938, "train/post_ent_mag": 49.91227015510934, "train/post_ent_max": 49.91227015510934, "train/post_ent_mean": 48.459166511160426, "train/post_ent_min": 47.471665241679204, "train/post_ent_std": 0.48999682019968505, "train/prior_ent_mag": 51.08171241009822, "train/prior_ent_max": 51.08171241009822, "train/prior_ent_mean": 47.81156002107214, "train/prior_ent_min": 45.564753704383726, "train/prior_ent_std": 0.8781462612210728, "train/rep_loss_mean": 1.000024754492963, "train/rep_loss_std": 0.00032130216271473387, "train/reward_avg": 0.0018898135286824565, "train/reward_loss_mean": 0.012973322208634898, "train/reward_loss_std": 0.205925612977599, "train/reward_max_data": 0.7796106563239801, "train/reward_max_pred": 0.26938094955975894, "train/reward_neg_acc": 0.9997029724668284, "train/reward_neg_loss": 0.0021995818492914474, "train/reward_pos_acc": 0.2079431796524705, "train/reward_pos_loss": 3.8172576587741114, "train/reward_pred": 0.0014155523929760226, "train/reward_rate": 0.0028096183401639346, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.007969573140144348, "report/cont_loss_std": 0.186997652053833, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 2.20515513420105, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001513592666015029, "report/cont_pred": 0.997062087059021, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06512949615716934, "report/image_loss_std": 0.0797186940908432, "report/model_loss_mean": 0.6741277575492859, "report/model_loss_std": 0.20950613915920258, "report/post_ent_mag": 50.43937301635742, "report/post_ent_max": 50.43937301635742, "report/post_ent_mean": 48.967830657958984, "report/post_ent_min": 48.22945785522461, "report/post_ent_std": 0.4391918182373047, "report/prior_ent_mag": 49.413734436035156, "report/prior_ent_max": 49.413734436035156, "report/prior_ent_mean": 47.53116989135742, "report/prior_ent_min": 45.73747253417969, "report/prior_ent_std": 0.6720042824745178, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.001028688158839941, "report/reward_loss_std": 0.007336530834436417, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.07494866847991943, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.001028688158839941, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0004932836163789034, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.05536637827754021, "eval/cont_loss_std": 0.7180172801017761, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.627981185913086, "eval/cont_pos_acc": 0.9990177154541016, "eval/cont_pos_loss": 0.004840163979679346, "eval/cont_pred": 0.9965116381645203, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.158708393573761, "eval/image_loss_std": 0.14591281116008759, "eval/model_loss_mean": 0.8244450092315674, "eval/model_loss_std": 0.8036409020423889, "eval/post_ent_mag": 50.43937301635742, "eval/post_ent_max": 50.43937301635742, "eval/post_ent_mean": 49.024383544921875, "eval/post_ent_min": 48.24150466918945, "eval/post_ent_std": 0.45840534567832947, "eval/prior_ent_mag": 49.70389938354492, "eval/prior_ent_max": 49.70389938354492, "eval/prior_ent_mean": 47.621070861816406, "eval/prior_ent_min": 45.72993469238281, "eval/prior_ent_std": 0.7001540064811707, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0014678954612463713, "eval/reward_loss_mean": 0.010370220057666302, "eval/reward_loss_std": 0.19983208179473877, "eval/reward_max_data": 0.7718750238418579, "eval/reward_max_pred": 0.059183359146118164, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015451511135324836, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.519980430603027, "eval/reward_pred": 0.0008012086618691683, "eval/reward_rate": 0.001953125, "replay/size": 742913.0, "replay/inserts": 19504.0, "replay/samples": 19504.0, "replay/insert_wait_avg": 1.2591909051821602e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.776858701385173e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2256.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3620295423142453e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 3.933906555175781e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.3704137802124, "timer/env.step_count": 2438.0, "timer/env.step_total": 5.401219606399536, "timer/env.step_frac": 0.010794442392375383, "timer/env.step_avg": 0.0022154305194419755, "timer/env.step_min": 0.0010836124420166016, "timer/env.step_max": 0.008777618408203125, "timer/replay._sample_count": 19504.0, "timer/replay._sample_total": 1328.122852563858, "timer/replay._sample_frac": 2.6542793418382162, "timer/replay._sample_avg": 0.06809489605023883, "timer/replay._sample_min": 0.02151036262512207, "timer/replay._sample_max": 0.0993034839630127, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2720.0, "timer/agent.policy_total": 18.421590328216553, "timer/agent.policy_frac": 0.036815906418296414, "timer/agent.policy_avg": 0.006772643503020792, "timer/agent.policy_min": 0.005251407623291016, "timer/agent.policy_max": 0.012645244598388672, "timer/dataset_train_count": 1219.0, "timer/dataset_train_total": 0.09710407257080078, "timer/dataset_train_frac": 0.0001940643769026954, "timer/dataset_train_avg": 7.965879620246167e-05, "timer/dataset_train_min": 6.67572021484375e-05, "timer/dataset_train_max": 0.000209808349609375, "timer/agent.train_count": 1219.0, "timer/agent.train_total": 469.3404612541199, "timer/agent.train_frac": 0.9379860366010321, "timer/agent.train_avg": 0.3850208870009187, "timer/agent.train_min": 0.3528416156768799, "timer/agent.train_max": 1.91062593460083, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.43694067001342773, "timer/agent.report_frac": 0.0008732344238989195, "timer/agent.report_avg": 0.21847033500671387, "timer/agent.report_min": 0.21832919120788574, "timer/agent.report_max": 0.218611478805542, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 7.004317234336782e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 38.97849467470038}
{"step": 743568, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 743576, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 743864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 744112, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 744200, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 744304, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357}
{"step": 744440, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 744544, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 744560, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 744560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 744808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 745064, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 745144, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 745328, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 745408, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 745480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 745496, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 745728, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 745816, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 745896, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 746064, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 746152, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 746280, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 746512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 746552, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 746616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 746680, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 746696, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 747008, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 747208, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 747272, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 747640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 747704, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 747816, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 747872, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 747968, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 748160, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 748208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 748392, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 748464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 748488, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 748496, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 748744, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 748864, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 748992, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 748992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 749096, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 749104, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 749872, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 749976, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 750048, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 750048, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 750048, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 750048, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 750048, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 750048, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 750048, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 750048, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 750408, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 750480, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248}
{"step": 750776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 750808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 751056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 751072, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667}
{"step": 751088, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 751208, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 751304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 751416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 751584, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 751632, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 751888, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 751944, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 752160, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 752208, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761}
{"step": 752336, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 752600, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 752704, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 752824, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064}
{"step": 753216, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 753256, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 753360, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 753368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 753616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 753728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 753816, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 753888, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 753944, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 753960, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 754200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 754304, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 754400, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 754496, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 754616, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 754648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 754704, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809}
{"step": 754912, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 754984, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 755160, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 755288, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 755304, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 755328, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 755392, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 755800, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 755944, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 756040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 756224, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 756424, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 756616, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 756616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 756896, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 757024, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 757120, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 757312, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 757472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 757600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 757800, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 758008, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 758040, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 758200, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05}
{"step": 758256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 758624, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 758720, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 758848, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093}
{"step": 758920, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 758928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 759080, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 759240, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 759288, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 759336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 759400, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 759616, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 759784, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 759824, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 759912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 760032, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 760032, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 760032, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 760032, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 760032, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 760032, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 760032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760320, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 760496, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357}
{"step": 760616, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 760856, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 761232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 761288, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 761296, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291}
{"step": 761600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 761928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 761936, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 761984, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 761993, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2279084304283403, "train/action_min": 0.0, "train/action_std": 1.7781849472687161, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010671137597267356, "train/actor_opt_grad_steps": 46945.0, "train/actor_opt_loss": -12.190895546099235, "train/adv_mag": 1.1329344223285545, "train/adv_max": 0.24095001302916427, "train/adv_mean": 0.0012030329092120719, "train/adv_min": -1.095495175698708, "train/adv_std": 0.03251167889363293, "train/cont_avg": 0.9943342537715517, "train/cont_loss_mean": 0.018785896391912908, "train/cont_loss_std": 0.2459830914318947, "train/cont_neg_acc": 0.3173934597008187, "train/cont_neg_loss": 2.710021315913262, "train/cont_pos_acc": 0.9999068420508812, "train/cont_pos_loss": 0.0036094832175876945, "train/cont_pred": 0.9946654788379011, "train/cont_rate": 0.9943342537715517, "train/dyn_loss_mean": 1.000000533358804, "train/dyn_loss_std": 1.7067267529863125e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1581492493539278, "train/extr_critic_critic_opt_grad_steps": 46945.0, "train/extr_critic_critic_opt_loss": 6547.958803374192, "train/extr_critic_mag": 1.591613574274655, "train/extr_critic_max": 1.591613574274655, "train/extr_critic_mean": 1.5289551718481655, "train/extr_critic_min": 1.3942093479222264, "train/extr_critic_std": 0.022427246456259285, "train/extr_return_normed_mag": 1.1303858870062335, "train/extr_return_normed_max": 0.26941858283404646, "train/extr_return_normed_mean": 0.04511687980065572, "train/extr_return_normed_min": -1.0773305759347718, "train/extr_return_normed_std": 0.04066246473390994, "train/extr_return_rate": 0.9994191542781633, "train/extr_return_raw_mag": 1.7544598250553525, "train/extr_return_raw_max": 1.7544598250553525, "train/extr_return_raw_mean": 1.53015821041732, "train/extr_return_raw_min": 0.4077106662865343, "train/extr_return_raw_std": 0.04066246486236823, "train/extr_reward_mag": 0.2652876675128937, "train/extr_reward_max": 0.2652876675128937, "train/extr_reward_mean": 0.002499434046230504, "train/extr_reward_min": 1.1098795923693426e-07, "train/extr_reward_std": 0.008237414210553056, "train/image_loss_mean": 0.09040702725278921, "train/image_loss_std": 0.10081326531182075, "train/model_loss_mean": 0.723940404324696, "train/model_loss_std": 0.4660491291433573, "train/model_opt_grad_norm": 20.13376449716502, "train/model_opt_grad_steps": 46904.28448275862, "train/model_opt_loss": 3744.0303765658673, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5172.413793103448, "train/policy_entropy_mag": 1.3038831127100978, "train/policy_entropy_max": 1.3038831127100978, "train/policy_entropy_mean": 0.10034847927504573, "train/policy_entropy_min": 0.06468649658149686, "train/policy_entropy_std": 0.1260216492388783, "train/policy_logprob_mag": 6.5510802474515195, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10034599187302179, "train/policy_logprob_min": -6.5510802474515195, "train/policy_logprob_std": 0.6374661059215151, "train/policy_randomness_mag": 0.6700634103396843, "train/policy_randomness_max": 0.6700634103396843, "train/policy_randomness_mean": 0.05156891998545877, "train/policy_randomness_min": 0.03324228377434714, "train/policy_randomness_std": 0.0647623201767946, "train/post_ent_mag": 49.741079001591125, "train/post_ent_max": 49.741079001591125, "train/post_ent_mean": 48.2981940960062, "train/post_ent_min": 47.31356959507383, "train/post_ent_std": 0.4824566412074813, "train/prior_ent_mag": 49.52864357520794, "train/prior_ent_max": 49.52864357520794, "train/prior_ent_mean": 47.18268331988104, "train/prior_ent_min": 44.93537449014598, "train/prior_ent_std": 0.7681176482603468, "train/rep_loss_mean": 1.000000533358804, "train/rep_loss_std": 1.7067267529863125e-05, "train/reward_avg": 0.002148095486863267, "train/reward_loss_mean": 0.014747139279216784, "train/reward_loss_std": 0.2193512704769342, "train/reward_max_data": 0.7502155184488872, "train/reward_max_pred": 0.28200526895194217, "train/reward_neg_acc": 0.9997212408945478, "train/reward_neg_loss": 0.002418250687508683, "train/reward_pos_acc": 0.21007575975223022, "train/reward_pos_loss": 3.879405654560436, "train/reward_pred": 0.0015613258703900822, "train/reward_rate": 0.0031064789870689654, "train_stats/mean_log_entropy": 0.08827142309451448, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.02664177119731903, "report/cont_loss_std": 0.2949046492576599, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 3.234633207321167, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004561201669275761, "report/cont_pred": 0.9944759011268616, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0769972950220108, "report/image_loss_std": 0.08709573745727539, "report/model_loss_mean": 0.7281296253204346, "report/model_loss_std": 0.5946351289749146, "report/post_ent_mag": 49.63935089111328, "report/post_ent_max": 49.63935089111328, "report/post_ent_mean": 48.2205696105957, "report/post_ent_min": 47.128047943115234, "report/post_ent_std": 0.5020520687103271, "report/prior_ent_mag": 49.18748092651367, "report/prior_ent_max": 49.18748092651367, "report/prior_ent_mean": 46.958831787109375, "report/prior_ent_min": 44.376625061035156, "report/prior_ent_std": 0.8500380516052246, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003283691592514515, "report/reward_loss_mean": 0.02449052222073078, "report/reward_loss_std": 0.3000907301902771, "report/reward_max_data": 0.796875, "report/reward_max_pred": 0.15722262859344482, "report/reward_neg_acc": 0.9980372786521912, "report/reward_neg_loss": 0.003518125042319298, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.2986650466918945, "report/reward_pred": 0.0018818002426996827, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.039076052606105804, "eval/cont_loss_std": 0.605762243270874, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.629050254821777, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.005389878526329994, "eval/cont_pred": 0.9971102476119995, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15483513474464417, "eval/image_loss_std": 0.1391703188419342, "eval/model_loss_mean": 0.79877769947052, "eval/model_loss_std": 0.6710416674613953, "eval/post_ent_mag": 49.639198303222656, "eval/post_ent_max": 49.639198303222656, "eval/post_ent_mean": 48.075767517089844, "eval/post_ent_min": 46.997215270996094, "eval/post_ent_std": 0.5224420428276062, "eval/prior_ent_mag": 49.10927963256836, "eval/prior_ent_max": 49.10927963256836, "eval/prior_ent_mean": 46.58868408203125, "eval/prior_ent_min": 44.112403869628906, "eval/prior_ent_std": 0.8633701801300049, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007080078357830644, "eval/reward_loss_mean": 0.004866461735218763, "eval/reward_loss_std": 0.1251482516527176, "eval/reward_max_data": 0.7250000238418579, "eval/reward_max_pred": 0.021170496940612793, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009557005250826478, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.005575180053711, "eval/reward_pred": 0.0005198433063924313, "eval/reward_rate": 0.0009765625, "replay/size": 761489.0, "replay/inserts": 18576.0, "replay/samples": 18576.0, "replay/insert_wait_avg": 1.4025701930253901e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.626717085267428e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3468748887742027e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.1831748485565, "timer/env.step_count": 2322.0, "timer/env.step_total": 5.494528770446777, "timer/env.step_frac": 0.010985033177316268, "timer/env.step_avg": 0.002366291460140731, "timer/env.step_min": 0.0011262893676757812, "timer/env.step_max": 0.010519027709960938, "timer/replay._sample_count": 18576.0, "timer/replay._sample_total": 1295.7115931510925, "timer/replay._sample_frac": 2.590474166875771, "timer/replay._sample_avg": 0.06975191608263849, "timer/replay._sample_min": 0.00037288665771484375, "timer/replay._sample_max": 0.09790158271789551, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2761.0, "timer/agent.policy_total": 19.738215923309326, "timer/agent.policy_frac": 0.03946197496404309, "timer/agent.policy_avg": 0.007148937313766507, "timer/agent.policy_min": 0.005470752716064453, "timer/agent.policy_max": 0.011258363723754883, "timer/dataset_train_count": 1161.0, "timer/dataset_train_total": 0.09885454177856445, "timer/dataset_train_frac": 0.00019763667941948514, "timer/dataset_train_avg": 8.514603081702364e-05, "timer/dataset_train_min": 7.200241088867188e-05, "timer/dataset_train_max": 0.00023818016052246094, "timer/agent.train_count": 1161.0, "timer/agent.train_total": 467.5000202655792, "timer/agent.train_frac": 0.9346576289918729, "timer/agent.train_avg": 0.4026701294277168, "timer/agent.train_min": 0.3541445732116699, "timer/agent.train_max": 0.5124313831329346, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4921844005584717, "timer/agent.report_frac": 0.000984008309970629, "timer/agent.report_avg": 0.24609220027923584, "timer/agent.report_min": 0.24557089805603027, "timer/agent.report_max": 0.2466135025024414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 6.863940475610758e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 37.137809568219154}
{"step": 762216, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776}
{"step": 762344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 762456, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 762768, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 762808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 762928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 763032, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693}
{"step": 763144, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 763368, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 763464, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 763544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 763856, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 763888, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 764248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 764360, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 764528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 764648, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 764784, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705}
{"step": 765080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 765192, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 765200, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 765360, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 765400, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 765456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 765776, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 765816, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 765976, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 765976, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 766080, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736}
{"step": 766200, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 766512, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 766640, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 766656, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 766776, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 767000, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 767088, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756}
{"step": 767264, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 767280, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 767296, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 767392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 768072, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 768240, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444}
{"step": 768288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 768392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 768568, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 768600, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 768928, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 768960, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 769072, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 769232, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 769312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 769576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 769592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 769760, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 769808, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035}
{"step": 769896, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 770016, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 770016, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 770016, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 770016, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 770016, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 770016, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 770016, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 770016, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 770024, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 770096, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 770320, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705}
{"step": 770552, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 770712, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 770712, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 770912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 771208, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 771240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 771248, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 771688, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 771784, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 771888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 772080, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315}
{"step": 772208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 772256, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 772432, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 772688, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 772944, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125}
{"step": 772944, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 772952, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 773024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 773024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 773048, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 773400, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 773504, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 773560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 773736, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 773768, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 773872, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564}
{"step": 774000, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 774032, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 774096, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 774536, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 774552, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 774744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 775064, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154}
{"step": 775136, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 775256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 775336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 775480, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 775752, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 775816, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 776128, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 776160, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 776312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 776344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 776496, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 776848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 777048, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 777208, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 777376, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 777448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 777648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 777728, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 777808, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 777808, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 778008, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 778328, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 778440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 778472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 778488, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 778496, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345}
{"step": 778584, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 778656, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 778968, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 779136, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 779136, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 779192, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 779240, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 779416, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 779536, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 779544, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 779840, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 779904, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 779928, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 780000, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 780000, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 780000, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 780000, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 780000, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 780000, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 780000, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 780000, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 780120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 780216, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 780408, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 780472, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 780552, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 780713, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.229645557892628, "train/action_min": 0.0, "train/action_std": 1.7797678790540776, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01126356652746789, "train/actor_opt_grad_steps": 48110.0, "train/actor_opt_loss": -13.37969306595305, "train/adv_mag": 1.0423848343710613, "train/adv_max": 0.2156006087604751, "train/adv_mean": -5.9572197222643386e-05, "train/adv_min": -1.00133802748134, "train/adv_std": 0.028486116876841612, "train/cont_avg": 0.9946915064102564, "train/cont_loss_mean": 0.017856200711212605, "train/cont_loss_std": 0.23884042132741365, "train/cont_neg_acc": 0.33541305146665656, "train/cont_neg_loss": 2.6381430656850164, "train/cont_pos_acc": 0.999748167828617, "train/cont_pos_loss": 0.0036302009193449575, "train/cont_pred": 0.9948097890258855, "train/cont_rate": 0.9946915064102564, "train/dyn_loss_mean": 1.000000461553916, "train/dyn_loss_std": 1.4773809128270772e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15970328572787282, "train/extr_critic_critic_opt_grad_steps": 48110.0, "train/extr_critic_critic_opt_loss": 5868.809614132612, "train/extr_critic_mag": 1.6129742218897893, "train/extr_critic_max": 1.6129742218897893, "train/extr_critic_mean": 1.5362694100437002, "train/extr_critic_min": 1.4353067446977665, "train/extr_critic_std": 0.022284306076347318, "train/extr_return_normed_mag": 1.0513434868592482, "train/extr_return_normed_max": 0.27775796967693883, "train/extr_return_normed_mean": 0.04335846064182428, "train/extr_return_normed_min": -0.9788248803880479, "train/extr_return_normed_std": 0.037428478352152385, "train/extr_return_rate": 0.9996389028353568, "train/extr_return_raw_mag": 1.770609269794236, "train/extr_return_raw_max": 1.770609269794236, "train/extr_return_raw_mean": 1.5362098441164718, "train/extr_return_raw_min": 0.5140264197292491, "train/extr_return_raw_std": 0.03742847860687309, "train/extr_reward_mag": 0.2563886285847069, "train/extr_reward_max": 0.2563886285847069, "train/extr_reward_mean": 0.0023144361439646566, "train/extr_reward_min": 1.1717152391743456e-07, "train/extr_reward_std": 0.008116283434100894, "train/image_loss_mean": 0.0886534185300016, "train/image_loss_std": 0.10058223914641601, "train/model_loss_mean": 0.7206249456120353, "train/model_loss_std": 0.45466491529065317, "train/model_opt_grad_norm": 20.04222207191663, "train/model_opt_grad_steps": 48068.179487179485, "train/model_opt_loss": 3727.5433172242256, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5170.940170940171, "train/policy_entropy_mag": 1.3438031510410147, "train/policy_entropy_max": 1.3438031510410147, "train/policy_entropy_mean": 0.10242300639804612, "train/policy_entropy_min": 0.06468650233796519, "train/policy_entropy_std": 0.13115540541644788, "train/policy_logprob_mag": 6.551080230973724, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10335155098866193, "train/policy_logprob_min": -6.551080230973724, "train/policy_logprob_std": 0.6447778527553265, "train/policy_randomness_mag": 0.690578254369589, "train/policy_randomness_max": 0.690578254369589, "train/policy_randomness_mean": 0.05263501603124488, "train/policy_randomness_min": 0.03324228674810157, "train/policy_randomness_std": 0.06740054930759291, "train/post_ent_mag": 50.177403311444145, "train/post_ent_max": 50.177403311444145, "train/post_ent_mean": 48.76941129896376, "train/post_ent_min": 47.769779368343514, "train/post_ent_std": 0.4843716993291154, "train/prior_ent_mag": 49.82433896187024, "train/prior_ent_max": 49.82433896187024, "train/prior_ent_mean": 47.36531484228933, "train/prior_ent_min": 44.99675757253272, "train/prior_ent_std": 0.819624862100324, "train/rep_loss_mean": 1.000000461553916, "train/rep_loss_std": 1.4773809128270772e-05, "train/reward_avg": 0.0019820254086118797, "train/reward_loss_mean": 0.014115023664517216, "train/reward_loss_std": 0.21693784838669702, "train/reward_max_data": 0.7580662374822502, "train/reward_max_pred": 0.2614355729176448, "train/reward_neg_acc": 0.9997068638475533, "train/reward_neg_loss": 0.002373580894488682, "train/reward_pos_acc": 0.1598214302212, "train/reward_pos_loss": 4.043751452650342, "train/reward_pred": 0.0014883678687067751, "train/reward_rate": 0.0029296875, "train_stats/mean_log_entropy": 0.09149204466464746, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.017182301729917526, "report/cont_loss_std": 0.23481431603431702, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.5171077251434326, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0049157398752868176, "report/cont_pred": 0.9932834506034851, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06867314875125885, "report/image_loss_std": 0.0870499536395073, "report/model_loss_mean": 0.6973176002502441, "report/model_loss_std": 0.42038413882255554, "report/post_ent_mag": 50.616912841796875, "report/post_ent_max": 50.616912841796875, "report/post_ent_mean": 49.17793273925781, "report/post_ent_min": 48.19775390625, "report/post_ent_std": 0.4785584509372711, "report/prior_ent_mag": 49.93559646606445, "report/prior_ent_max": 49.93559646606445, "report/prior_ent_mean": 47.754249572753906, "report/prior_ent_min": 45.21514892578125, "report/prior_ent_std": 0.7844669818878174, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0013793944381177425, "report/reward_loss_mean": 0.011462105438113213, "report/reward_loss_std": 0.1972639262676239, "report/reward_max_data": 0.7124999761581421, "report/reward_max_pred": 0.037465453147888184, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0027446276508271694, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.46609354019165, "report/reward_pred": 0.001469862530939281, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.054640334099531174, "eval/cont_loss_std": 0.7301681637763977, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.244380950927734, "eval/cont_pos_acc": 0.9980353713035583, "eval/cont_pos_loss": 0.006370748858898878, "eval/cont_pred": 0.9953688383102417, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14560596644878387, "eval/image_loss_std": 0.12689869105815887, "eval/model_loss_mean": 0.8271077871322632, "eval/model_loss_std": 1.0976982116699219, "eval/post_ent_mag": 50.61790466308594, "eval/post_ent_max": 50.61790466308594, "eval/post_ent_mean": 49.120018005371094, "eval/post_ent_min": 48.185543060302734, "eval/post_ent_std": 0.5245569348335266, "eval/prior_ent_mag": 49.965057373046875, "eval/prior_ent_max": 49.965057373046875, "eval/prior_ent_mean": 47.662776947021484, "eval/prior_ent_min": 45.3233757019043, "eval/prior_ent_std": 0.7538157105445862, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002124023623764515, "eval/reward_loss_mean": 0.02686147950589657, "eval/reward_loss_std": 0.4407920241355896, "eval/reward_max_data": 0.637499988079071, "eval/reward_max_pred": 0.03282320499420166, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.0014029343146830797, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.518790245056152, "eval/reward_pred": 0.0007588494336232543, "eval/reward_rate": 0.00390625, "replay/size": 780209.0, "replay/inserts": 18720.0, "replay/samples": 18720.0, "replay/insert_wait_avg": 1.3429257604810926e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.681451430687537e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2704.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3005451337825617e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.0250988006592, "timer/env.step_count": 2340.0, "timer/env.step_total": 5.549647808074951, "timer/env.step_frac": 0.01109873848610024, "timer/env.step_avg": 0.0023716443624251927, "timer/env.step_min": 0.0011205673217773438, "timer/env.step_max": 0.009360790252685547, "timer/replay._sample_count": 18720.0, "timer/replay._sample_total": 1310.2567772865295, "timer/replay._sample_frac": 2.6203820176812336, "timer/replay._sample_avg": 0.06999234921402402, "timer/replay._sample_min": 0.0003311634063720703, "timer/replay._sample_max": 0.10175442695617676, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2678.0, "timer/agent.policy_total": 19.082501888275146, "timer/agent.policy_frac": 0.038163088081069725, "timer/agent.policy_avg": 0.007125654177847328, "timer/agent.policy_min": 0.005399227142333984, "timer/agent.policy_max": 0.011971712112426758, "timer/dataset_train_count": 1170.0, "timer/dataset_train_total": 0.10027909278869629, "timer/dataset_train_frac": 0.0002005481185428928, "timer/dataset_train_avg": 8.570862631512503e-05, "timer/dataset_train_min": 6.604194641113281e-05, "timer/dataset_train_max": 0.00020265579223632812, "timer/agent.train_count": 1170.0, "timer/agent.train_total": 468.53889322280884, "timer/agent.train_frac": 0.9370307497496188, "timer/agent.train_avg": 0.4004605924981272, "timer/agent.train_min": 0.358034610748291, "timer/agent.train_max": 0.5030472278594971, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.44695401191711426, "timer/agent.report_frac": 0.0008938631540479884, "timer/agent.report_avg": 0.22347700595855713, "timer/agent.report_min": 0.22299623489379883, "timer/agent.report_max": 0.22395777702331543, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.695487976074219e-05, "timer/dataset_eval_frac": 7.390604961507078e-08, "timer/dataset_eval_avg": 3.695487976074219e-05, "timer/dataset_eval_min": 3.695487976074219e-05, "timer/dataset_eval_max": 3.695487976074219e-05, "fps": 37.43771378722592}
{"step": 780736, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216}
{"step": 780768, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 780800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 781152, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 781192, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 781448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 781608, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 781848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 782064, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 782152, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 782248, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 782464, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 782528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 782720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 782760, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225}
{"step": 782816, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 783040, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 783288, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 783344, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 783504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 783800, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703}
{"step": 783912, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 784000, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757}
{"step": 784096, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 784104, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 784376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 784464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 784768, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 784776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 784856, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 784872, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 784944, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993}
{"step": 785192, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 785392, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 785472, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 785608, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035}
{"step": 786200, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 786224, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 786312, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 786416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 786688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 786776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 786904, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 786920, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 787136, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 787184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 787256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 787456, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 787760, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 787832, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 787904, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 787976, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 788064, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 788272, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464}
{"step": 788312, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 788600, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 788696, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 788920, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 788976, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 789000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 789056, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 789232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 789448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 789456, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 789488, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 789576, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 789632, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 789704, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035}
{"step": 790056, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 790088, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 790088, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 790088, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 790088, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 790088, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 790088, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 790088, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 790088, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 790104, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 790144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 790528, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 790560, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 790584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 790712, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 791192, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 791200, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 791304, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 791424, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655}
{"step": 791544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 791640, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 791880, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 791944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 792016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 792184, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 792280, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 792304, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 792368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 792760, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 792952, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 792960, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 793128, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 793168, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 793440, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 793616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 793720, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 793856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 794032, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 794184, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 794352, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 794496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 794616, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 795256, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 795264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 795272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 795456, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 795928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 796080, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 796168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 796224, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 796432, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315}
{"step": 796496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 796544, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 796664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 797040, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 797064, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 797168, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 797360, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 797584, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 797600, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093}
{"step": 797704, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 797768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 797832, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903}
{"step": 798048, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 798352, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 798392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 798480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 798528, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705}
{"step": 798584, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 798640, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 798808, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 798912, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 799160, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 799256, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 799305, "train_stats/mean_log_entropy": 0.08014788306248721, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2455386952457266, "train/action_min": 0.0, "train/action_std": 1.7705258395936754, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010385679707934078, "train/actor_opt_grad_steps": 49280.0, "train/actor_opt_loss": -13.294496301911835, "train/adv_mag": 1.1273728884183443, "train/adv_max": 0.27329352065029305, "train/adv_mean": 0.0013129495948507814, "train/adv_min": -1.090369590327271, "train/adv_std": 0.03197815683152941, "train/cont_avg": 0.9945913461538461, "train/cont_loss_mean": 0.017859252981650524, "train/cont_loss_std": 0.23355050968467936, "train/cont_neg_acc": 0.3250752668827772, "train/cont_neg_loss": 2.634598777428719, "train/cont_pos_acc": 0.9998405030649952, "train/cont_pos_loss": 0.0037161046539584543, "train/cont_pred": 0.9947016524453448, "train/cont_rate": 0.9945913461538461, "train/dyn_loss_mean": 1.0000104455866365, "train/dyn_loss_std": 0.00023071768765266126, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1628745957158315, "train/extr_critic_critic_opt_grad_steps": 49280.0, "train/extr_critic_critic_opt_loss": 5836.425338875534, "train/extr_critic_mag": 1.6284678797436576, "train/extr_critic_max": 1.6284678797436576, "train/extr_critic_mean": 1.5379818443559174, "train/extr_critic_min": 1.433364554348155, "train/extr_critic_std": 0.023632906361395478, "train/extr_return_normed_mag": 1.1270894688418789, "train/extr_return_normed_max": 0.33178821282509047, "train/extr_return_normed_mean": 0.048249276179788456, "train/extr_return_normed_min": -1.0587999708632119, "train/extr_return_normed_std": 0.04120496416894289, "train/extr_return_rate": 0.9995893841115837, "train/extr_return_raw_mag": 1.8228336501325297, "train/extr_return_raw_max": 1.8228336501325297, "train/extr_return_raw_mean": 1.5392947930556078, "train/extr_return_raw_min": 0.43224546644422746, "train/extr_return_raw_std": 0.04120496443958364, "train/extr_reward_mag": 0.31332147121429443, "train/extr_reward_max": 0.31332147121429443, "train/extr_reward_mean": 0.0024545627873008833, "train/extr_reward_min": 1.1615264110076122e-07, "train/extr_reward_std": 0.009404062138249477, "train/image_loss_mean": 0.08775830001403125, "train/image_loss_std": 0.09953806902735661, "train/model_loss_mean": 0.7196717960202795, "train/model_loss_std": 0.44842588035469383, "train/model_opt_grad_norm": 19.407793591165134, "train/model_opt_grad_steps": 49237.02564102564, "train/model_opt_loss": 3905.933608356704, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5427.350427350428, "train/policy_entropy_mag": 1.3456418850483038, "train/policy_entropy_max": 1.3456418850483038, "train/policy_entropy_mean": 0.09920936784683129, "train/policy_entropy_min": 0.06468649775299251, "train/policy_entropy_std": 0.12530497162260562, "train/policy_logprob_mag": 6.551080243200318, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09956817207937567, "train/policy_logprob_min": -6.551080243200318, "train/policy_logprob_std": 0.6388281787562574, "train/policy_randomness_mag": 0.6915231744448344, "train/policy_randomness_max": 0.6915231744448344, "train/policy_randomness_mean": 0.05098353173488226, "train/policy_randomness_min": 0.033242284360094965, "train/policy_randomness_std": 0.06439402072220786, "train/post_ent_mag": 49.95185431455955, "train/post_ent_max": 49.95185431455955, "train/post_ent_mean": 48.54020240979317, "train/post_ent_min": 47.54563013712565, "train/post_ent_std": 0.48787528480220044, "train/prior_ent_mag": 50.07053844745342, "train/prior_ent_max": 50.07053844745342, "train/prior_ent_mean": 47.54460698315221, "train/prior_ent_min": 45.2480220957699, "train/prior_ent_std": 0.7994765674966013, "train/rep_loss_mean": 1.0000104455866365, "train/rep_loss_std": 0.00023071768765266126, "train/reward_avg": 0.0020055787157243453, "train/reward_loss_mean": 0.014047953978769926, "train/reward_loss_std": 0.2131692755422117, "train/reward_max_data": 0.7487980748853112, "train/reward_max_pred": 0.24595323281410414, "train/reward_neg_acc": 0.9996735896819677, "train/reward_neg_loss": 0.002521017777761365, "train/reward_pos_acc": 0.1533639161685191, "train/reward_pos_loss": 4.011292522106696, "train/reward_pred": 0.001543708335663964, "train/reward_rate": 0.00288795405982906, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.017346343025565147, "report/cont_loss_std": 0.2682744562625885, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.070672035217285, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005500304978340864, "report/cont_pred": 0.9946480393409729, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09039067476987839, "report/image_loss_std": 0.10538139194250107, "report/model_loss_mean": 0.7117422819137573, "report/model_loss_std": 0.2890196442604065, "report/post_ent_mag": 50.200157165527344, "report/post_ent_max": 50.200157165527344, "report/post_ent_mean": 48.823822021484375, "report/post_ent_min": 47.95735549926758, "report/post_ent_std": 0.43687525391578674, "report/prior_ent_mag": 50.78056335449219, "report/prior_ent_max": 50.78056335449219, "report/prior_ent_mean": 48.549049377441406, "report/prior_ent_min": 46.233680725097656, "report/prior_ent_std": 0.7480984926223755, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0040052225813269615, "report/reward_loss_std": 0.014077729545533657, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0863039493560791, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0040052225813269615, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.002159934723749757, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.018503140658140182, "eval/cont_loss_std": 0.2755846083164215, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.967716693878174, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.003960886970162392, "eval/cont_pred": 0.9964099526405334, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15818344056606293, "eval/image_loss_std": 0.14458653330802917, "eval/model_loss_mean": 0.8006790280342102, "eval/model_loss_std": 0.7158129215240479, "eval/post_ent_mag": 50.19979476928711, "eval/post_ent_max": 50.19979476928711, "eval/post_ent_mean": 48.69879150390625, "eval/post_ent_min": 47.68408966064453, "eval/post_ent_std": 0.49399638175964355, "eval/prior_ent_mag": 50.75, "eval/prior_ent_max": 50.75, "eval/prior_ent_mean": 48.356346130371094, "eval/prior_ent_min": 46.250850677490234, "eval/prior_ent_std": 0.7148533463478088, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0018157958984375, "eval/reward_loss_mean": 0.023992415517568588, "eval/reward_loss_std": 0.4099443256855011, "eval/reward_max_data": 0.8843749761581421, "eval/reward_max_pred": 0.5570424795150757, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.002941817743703723, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.1882123947143555, "eval/reward_pred": 0.0014349137200042605, "eval/reward_rate": 0.0029296875, "replay/size": 798801.0, "replay/inserts": 18592.0, "replay/samples": 18592.0, "replay/insert_wait_avg": 1.3482088476368153e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.520604512777673e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3700388010265757e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.281724691391, "timer/env.step_count": 2324.0, "timer/env.step_total": 5.542958498001099, "timer/env.step_frac": 0.011079674160435074, "timer/env.step_avg": 0.002385094018072762, "timer/env.step_min": 0.001093149185180664, "timer/env.step_max": 0.02067875862121582, "timer/replay._sample_count": 18592.0, "timer/replay._sample_total": 1303.8388397693634, "timer/replay._sample_frac": 2.6062092125665055, "timer/replay._sample_avg": 0.07012902537485818, "timer/replay._sample_min": 0.0005247592926025391, "timer/replay._sample_max": 0.11943507194519043, "timer/agent.save_count": 1.0, "timer/agent.save_total": 1.0973320007324219, "timer/agent.save_frac": 0.0021934281157468495, "timer/agent.save_avg": 1.0973320007324219, "timer/agent.save_min": 1.0973320007324219, "timer/agent.save_max": 1.0973320007324219, "timer/agent.policy_count": 2427.0, "timer/agent.policy_total": 18.376327991485596, "timer/agent.policy_frac": 0.03673195938312839, "timer/agent.policy_avg": 0.007571622575807827, "timer/agent.policy_min": 0.005364894866943359, "timer/agent.policy_max": 1.0908865928649902, "timer/dataset_train_count": 1162.0, "timer/dataset_train_total": 0.10080385208129883, "timer/dataset_train_frac": 0.00020149417239552722, "timer/dataset_train_avg": 8.675030299595424e-05, "timer/dataset_train_min": 7.295608520507812e-05, "timer/dataset_train_max": 0.00022530555725097656, "timer/agent.train_count": 1162.0, "timer/agent.train_total": 468.7189347743988, "timer/agent.train_frac": 0.9369099682054899, "timer/agent.train_avg": 0.40337257725851877, "timer/agent.train_min": 0.3566741943359375, "timer/agent.train_max": 0.6844358444213867, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46529102325439453, "timer/agent.report_frac": 0.0009300580058994135, "timer/agent.report_avg": 0.23264551162719727, "timer/agent.report_min": 0.21604537963867188, "timer/agent.report_max": 0.24924564361572266, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 7.148529538490614e-08, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05, "fps": 37.162524807196384}
{"step": 799376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 799584, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 799592, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 799712, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 799912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 800048, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 800072, "eval_episode/length": 16.0, "eval_episode/score": 0.949999988079071, "eval_episode/reward_rate": 0.058823529411764705}
{"step": 800072, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 800072, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 800072, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 800072, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 800072, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 800072, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 800072, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 800432, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 800544, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 800672, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 800840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 800872, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04}
{"step": 800896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 800968, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625}
{"step": 801224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 801280, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 801344, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 801472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 801624, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 801672, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04}
{"step": 801920, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 802072, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 802176, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 802296, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 802360, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 802472, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 802632, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 802744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 802968, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 803032, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 803216, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 803352, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 803520, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 803760, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 803912, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 803936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 803984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 803984, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 804240, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 804344, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 804488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 804584, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 804680, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 804704, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 804792, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 804904, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 804960, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 805000, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 805104, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564}
{"step": 805256, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 805360, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 805456, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 805464, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 805664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 806056, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 806248, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 806272, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 806288, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 806768, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 807016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 807312, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 807312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 807392, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 807416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 807544, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655}
{"step": 807776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 807944, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 808112, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 808528, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 808560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 808568, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 808584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 808632, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 808896, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 808944, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 809160, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035}
{"step": 809416, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 809440, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 809480, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 809552, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 809704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 810056, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 810056, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 810056, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 810056, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 810056, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 810056, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 810056, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 810056, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 810080, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 810088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 810192, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 810256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 810408, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 810656, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 811024, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 811272, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 811472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 811752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 812016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 812392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 812568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 812616, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 812720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 812736, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 812776, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 813096, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 813248, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 813336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 813416, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 813464, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 813584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 813784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 814120, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 814344, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 814528, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 814880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 814928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 815192, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 815336, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 815408, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035}
{"step": 815560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 815728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 815776, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 816056, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 816064, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 816096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 816376, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 816400, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 816432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 816568, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 816656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 816664, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 816752, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 816880, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 817016, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 817360, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 817456, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 817528, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 817648, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 817872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 817944, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 818024, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 818136, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664}
{"step": 818240, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 818368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 818488, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 818505, "train_stats/mean_log_entropy": 0.07895629998782407, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.24765625, "train/action_min": 0.0, "train/action_std": 1.7819273640712103, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012615766056114808, "train/actor_opt_grad_steps": 50465.0, "train/actor_opt_loss": -14.168361047903696, "train/adv_mag": 1.0981252680222193, "train/adv_max": 0.28222931424776715, "train/adv_mean": 2.2297439488738747e-05, "train/adv_min": -1.0536722709735236, "train/adv_std": 0.03324362223502249, "train/cont_avg": 0.9946207682291667, "train/cont_loss_mean": 0.01856017569079995, "train/cont_loss_std": 0.24327152934080612, "train/cont_neg_acc": 0.3069654928520322, "train/cont_neg_loss": 2.7375951138945918, "train/cont_pos_acc": 0.9998607605695724, "train/cont_pos_loss": 0.0037663004914065823, "train/cont_pred": 0.9947083001335462, "train/cont_rate": 0.9946207682291667, "train/dyn_loss_mean": 1.0000253011782965, "train/dyn_loss_std": 0.00036571502037077155, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.18068665613730747, "train/extr_critic_critic_opt_grad_steps": 50465.0, "train/extr_critic_critic_opt_loss": 4939.034745279948, "train/extr_critic_mag": 1.6236747403939564, "train/extr_critic_max": 1.6236747403939564, "train/extr_critic_mean": 1.5475459585587183, "train/extr_critic_min": 1.4499630252520244, "train/extr_critic_std": 0.02302174043531219, "train/extr_return_normed_mag": 1.0975881397724152, "train/extr_return_normed_max": 0.33729269007841745, "train/extr_return_normed_mean": 0.04558413241369029, "train/extr_return_normed_min": -1.0245006561279297, "train/extr_return_normed_std": 0.0419902253895998, "train/extr_return_rate": 0.9995388825734456, "train/extr_return_raw_mag": 1.8392767349878947, "train/extr_return_raw_max": 1.8392767349878947, "train/extr_return_raw_mean": 1.54756827155749, "train/extr_return_raw_min": 0.47748338878154756, "train/extr_return_raw_std": 0.0419902253895998, "train/extr_reward_mag": 0.3222583780686061, "train/extr_reward_max": 0.3222583780686061, "train/extr_reward_mean": 0.002390579738615391, "train/extr_reward_min": 5.5631001790364584e-08, "train/extr_reward_std": 0.009170933521818369, "train/image_loss_mean": 0.08685838608071209, "train/image_loss_std": 0.10091984458267689, "train/model_loss_mean": 0.7205620686213176, "train/model_loss_std": 0.4784038415799538, "train/model_opt_grad_norm": 18.58758036295573, "train/model_opt_grad_steps": 50420.85, "train/model_opt_loss": 3749.7835001627604, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5208.333333333333, "train/policy_entropy_mag": 1.3341710895299912, "train/policy_entropy_max": 1.3341710895299912, "train/policy_entropy_mean": 0.09797434136271477, "train/policy_entropy_min": 0.06468649376183748, "train/policy_entropy_std": 0.12290563515077034, "train/policy_logprob_mag": 6.55108023484548, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0975704246511062, "train/policy_logprob_min": -6.55108023484548, "train/policy_logprob_std": 0.6336444770296414, "train/policy_randomness_mag": 0.6856283535559972, "train/policy_randomness_max": 0.6856283535559972, "train/policy_randomness_mean": 0.050348854158073664, "train/policy_randomness_min": 0.03324228236451745, "train/policy_randomness_std": 0.06316100570062796, "train/post_ent_mag": 49.793631839752194, "train/post_ent_max": 49.793631839752194, "train/post_ent_mean": 48.40398562749227, "train/post_ent_min": 47.39939438501994, "train/post_ent_std": 0.4815257839858532, "train/prior_ent_mag": 50.44599666595459, "train/prior_ent_max": 50.44599666595459, "train/prior_ent_mean": 48.053896299997966, "train/prior_ent_min": 45.52699375152588, "train/prior_ent_std": 0.8280569886167845, "train/rep_loss_mean": 1.0000253011782965, "train/rep_loss_std": 0.00036571502037077155, "train/reward_avg": 0.0021029917256479773, "train/reward_loss_mean": 0.015128310460325641, "train/reward_loss_std": 0.23183115530603876, "train/reward_max_data": 0.7919010400772095, "train/reward_max_pred": 0.26468734741210936, "train/reward_neg_acc": 0.9997142806649209, "train/reward_neg_loss": 0.0025553022118401715, "train/reward_pos_acc": 0.15823070756320295, "train/reward_pos_loss": 4.1597568351646945, "train/reward_pred": 0.0015835954565166807, "train/reward_rate": 0.002994791666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.026581021025776863, "report/cont_loss_std": 0.33003413677215576, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 3.226041078567505, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004559173248708248, "report/cont_pred": 0.9935334920883179, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08367014676332474, "report/image_loss_std": 0.10217791050672531, "report/model_loss_mean": 0.7268803119659424, "report/model_loss_std": 0.5194506049156189, "report/post_ent_mag": 49.652626037597656, "report/post_ent_max": 49.652626037597656, "report/post_ent_mean": 48.26691818237305, "report/post_ent_min": 47.30257797241211, "report/post_ent_std": 0.5089135766029358, "report/prior_ent_mag": 50.24458312988281, "report/prior_ent_max": 50.24458312988281, "report/prior_ent_mean": 48.36845016479492, "report/prior_ent_min": 45.74667739868164, "report/prior_ent_std": 0.8224830627441406, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0026947022415697575, "report/reward_loss_mean": 0.016629096120595932, "report/reward_loss_std": 0.2292945384979248, "report/reward_max_data": 0.8218749761581421, "report/reward_max_pred": 0.7293225526809692, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0033878472167998552, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.3931474685668945, "report/reward_pred": 0.0025183730758726597, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0159398652613163, "eval/cont_loss_std": 0.2332330346107483, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.294944763183594, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0033668801188468933, "eval/cont_pred": 0.9966609477996826, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1630435734987259, "eval/image_loss_std": 0.15675687789916992, "eval/model_loss_mean": 0.7968739867210388, "eval/model_loss_std": 0.5674365162849426, "eval/post_ent_mag": 49.652671813964844, "eval/post_ent_max": 49.652671813964844, "eval/post_ent_mean": 48.2196044921875, "eval/post_ent_min": 47.28761291503906, "eval/post_ent_std": 0.4898584187030792, "eval/prior_ent_mag": 50.044551849365234, "eval/prior_ent_max": 50.044551849365234, "eval/prior_ent_mean": 48.21038818359375, "eval/prior_ent_min": 45.39263916015625, "eval/prior_ent_std": 0.8511472344398499, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0022155761253088713, "eval/reward_loss_mean": 0.017890555784106255, "eval/reward_loss_std": 0.2923457622528076, "eval/reward_max_data": 0.8343750238418579, "eval/reward_max_pred": 0.0695260763168335, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0022473700810223818, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.341788291931152, "eval/reward_pred": 0.001158566796220839, "eval/reward_rate": 0.0029296875, "replay/size": 818001.0, "replay/inserts": 19200.0, "replay/samples": 19200.0, "replay/insert_wait_avg": 1.2986486156781515e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.073340773582459e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2336.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3311023581517887e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.119117975235, "timer/env.step_count": 2400.0, "timer/env.step_total": 5.488614320755005, "timer/env.step_frac": 0.010974614093890311, "timer/env.step_avg": 0.0022869226336479187, "timer/env.step_min": 0.0010867118835449219, "timer/env.step_max": 0.009062767028808594, "timer/replay._sample_count": 19200.0, "timer/replay._sample_total": 1316.5296137332916, "timer/replay._sample_frac": 2.6324320875061686, "timer/replay._sample_avg": 0.0685692507152756, "timer/replay._sample_min": 0.0003838539123535156, "timer/replay._sample_max": 0.10232973098754883, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2692.0, "timer/agent.policy_total": 18.403594493865967, "timer/agent.policy_frac": 0.03679842228062411, "timer/agent.policy_avg": 0.0068364021151062285, "timer/agent.policy_min": 0.005210161209106445, "timer/agent.policy_max": 0.01184988021850586, "timer/dataset_train_count": 1200.0, "timer/dataset_train_total": 0.10077333450317383, "timer/dataset_train_frac": 0.00020149866478042525, "timer/dataset_train_avg": 8.397777875264486e-05, "timer/dataset_train_min": 6.365776062011719e-05, "timer/dataset_train_max": 0.0002415180206298828, "timer/agent.train_count": 1200.0, "timer/agent.train_total": 469.7529888153076, "timer/agent.train_frac": 0.9392822068413088, "timer/agent.train_avg": 0.39146082401275634, "timer/agent.train_min": 0.35481786727905273, "timer/agent.train_max": 0.5002543926239014, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.49317336082458496, "timer/agent.report_frac": 0.0009861117943685688, "timer/agent.report_avg": 0.24658668041229248, "timer/agent.report_min": 0.2373652458190918, "timer/agent.report_max": 0.25580811500549316, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 7.00783670694732e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 38.39043126072182}
{"step": 818664, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 818688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 818856, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 818976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 819072, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 819136, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 819224, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 819344, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 819488, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 819536, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 819624, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 819824, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 820040, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 820040, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 820040, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 820040, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 820040, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 820040, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 820040, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 820040, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 820136, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 820152, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 820392, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 820400, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 820552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 820856, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 821000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 821096, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 821120, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 821192, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 821288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 821368, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494}
{"step": 821800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 821832, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 822168, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 822464, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 822568, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652}
{"step": 823128, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 823168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 823280, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842}
{"step": 823400, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 823408, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064}
{"step": 823504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 823600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 823680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 823768, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 823856, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474}
{"step": 823880, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 823888, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 824024, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 824360, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 824384, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 824472, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 824768, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 824792, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 824856, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 824928, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 825272, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 825408, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 825456, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 825528, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 825680, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 825912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 825928, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 826168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 826192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 826232, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 826440, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 826472, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 826616, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 826720, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 826752, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952}
{"step": 826936, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025}
{"step": 826960, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 827080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 827488, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357}
{"step": 827504, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 827552, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 827656, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 827680, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 827712, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 828008, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 828240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 828336, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 828368, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 828480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 828512, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 828920, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 828968, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 829064, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 829072, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 829192, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 829560, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 829608, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 829640, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 829696, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 829768, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464}
{"step": 829776, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839}
{"step": 829800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 829864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 830024, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 830024, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 830024, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 830024, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 830024, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 830024, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 830024, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 830024, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 830048, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 830120, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 830336, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035}
{"step": 830360, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 830536, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 830744, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 831064, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602}
{"step": 831096, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 831256, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 831256, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128}
{"step": 831296, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 831592, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 831696, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 831728, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 831920, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 832080, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 832176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 832456, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 832456, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 832480, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 833168, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695}
{"step": 833192, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 833272, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676}
{"step": 833304, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 833568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 833592, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761}
{"step": 833608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 833936, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 834032, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 834144, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 834232, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 834488, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 834736, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 834768, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 834792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 835016, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 835192, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 835504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 835576, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 835584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 835632, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 835696, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 835712, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 835864, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616}
{"step": 835872, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 836136, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 836208, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 836448, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 836536, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 836544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 837088, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 837096, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494}
{"step": 837104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 837168, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 837296, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 837448, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 837880, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 837944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 837952, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 838185, "train_stats/mean_log_entropy": 0.08134286443622696, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2205845282329775, "train/action_min": 0.0, "train/action_std": 1.7929973485993176, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013055356808112768, "train/actor_opt_grad_steps": 51680.0, "train/actor_opt_loss": -13.606656295497244, "train/adv_mag": 1.1646166148224497, "train/adv_max": 0.2875273062930844, "train/adv_mean": -0.00010994970249320305, "train/adv_min": -1.1233161387404775, "train/adv_std": 0.03654199384334611, "train/cont_avg": 0.994482024898374, "train/cont_loss_mean": 0.018760637951848225, "train/cont_loss_std": 0.24647631429559816, "train/cont_neg_acc": 0.3095639965277377, "train/cont_neg_loss": 2.762174009792204, "train/cont_pos_acc": 0.9998083482912885, "train/cont_pos_loss": 0.003993695973782096, "train/cont_pred": 0.9944637480790053, "train/cont_rate": 0.994482024898374, "train/dyn_loss_mean": 1.0000032273734487, "train/dyn_loss_std": 0.00010322344799836476, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1217985508312297, "train/extr_critic_critic_opt_grad_steps": 51680.0, "train/extr_critic_critic_opt_loss": 6296.873733644563, "train/extr_critic_mag": 1.6240669498598672, "train/extr_critic_max": 1.6240669498598672, "train/extr_critic_mean": 1.5325166898045113, "train/extr_critic_min": 1.4210218491593027, "train/extr_critic_std": 0.02318462234263013, "train/extr_return_normed_mag": 1.1610675420218366, "train/extr_return_normed_max": 0.3472184882900579, "train/extr_return_normed_mean": 0.0431647414144704, "train/extr_return_normed_min": -1.0967744802071797, "train/extr_return_normed_std": 0.04462836596478776, "train/extr_return_rate": 0.9993918727083904, "train/extr_return_raw_mag": 1.8364604207558362, "train/extr_return_raw_max": 1.8364604207558362, "train/extr_return_raw_mean": 1.5324067613942836, "train/extr_return_raw_min": 0.3924674522585985, "train/extr_return_raw_std": 0.04462836593450085, "train/extr_reward_mag": 0.3474186639475629, "train/extr_reward_max": 0.3474186639475629, "train/extr_reward_mean": 0.0023656393424039933, "train/extr_reward_min": 6.784268511020071e-09, "train/extr_reward_std": 0.009064484747293277, "train/image_loss_mean": 0.0849991027659517, "train/image_loss_std": 0.09829520525001897, "train/model_loss_mean": 0.718370806395523, "train/model_loss_std": 0.4650714419236997, "train/model_opt_grad_norm": 18.284459231329745, "train/model_opt_grad_steps": 51634.67479674797, "train/model_opt_loss": 3650.718795652312, "train/model_opt_model_opt_grad_overflow": 0.008130081300813009, "train/model_opt_model_opt_grad_scale": 5040.650406504065, "train/policy_entropy_mag": 1.3309851729772924, "train/policy_entropy_max": 1.3309851729772924, "train/policy_entropy_mean": 0.09763742644127792, "train/policy_entropy_min": 0.06468649263062128, "train/policy_entropy_std": 0.1218580724141462, "train/policy_logprob_mag": 6.551080242405093, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09741714203018483, "train/policy_logprob_min": -6.551080242405093, "train/policy_logprob_std": 0.633565330408453, "train/policy_randomness_mag": 0.683991113813912, "train/policy_randomness_max": 0.683991113813912, "train/policy_randomness_mean": 0.05017571405666631, "train/policy_randomness_min": 0.03324228179890935, "train/policy_randomness_std": 0.06262266511718433, "train/post_ent_mag": 50.66450847842829, "train/post_ent_max": 50.66450847842829, "train/post_ent_mean": 49.25587168747817, "train/post_ent_min": 48.2008452376699, "train/post_ent_std": 0.5031396826592888, "train/prior_ent_mag": 50.91878307931791, "train/prior_ent_max": 50.91878307931791, "train/prior_ent_mean": 48.739958817396705, "train/prior_ent_min": 46.38333170200751, "train/prior_ent_std": 0.788205354194331, "train/rep_loss_mean": 1.0000032273734487, "train/rep_loss_std": 0.00010322344799836476, "train/reward_avg": 0.0020557434512945877, "train/reward_loss_mean": 0.014609104874203117, "train/reward_loss_std": 0.2204674782148161, "train/reward_max_data": 0.7632113816292305, "train/reward_max_pred": 0.24841735421157465, "train/reward_neg_acc": 0.9996495479490699, "train/reward_neg_loss": 0.002688022062553441, "train/reward_pos_acc": 0.15957425566295447, "train/reward_pos_loss": 4.048808558512542, "train/reward_pred": 0.0016390645206428881, "train/reward_rate": 0.002961445630081301, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.020253511145710945, "report/cont_loss_std": 0.2519896924495697, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 2.2627954483032227, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004818118177354336, "report/cont_pred": 0.992383599281311, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08128705620765686, "report/image_loss_std": 0.10718599706888199, "report/model_loss_mean": 0.719316840171814, "report/model_loss_std": 0.5115717053413391, "report/post_ent_mag": 49.805912017822266, "report/post_ent_max": 49.805912017822266, "report/post_ent_mean": 48.35914993286133, "report/post_ent_min": 47.20445251464844, "report/post_ent_std": 0.562008261680603, "report/prior_ent_mag": 50.31935119628906, "report/prior_ent_max": 50.31935119628906, "report/prior_ent_mean": 48.39205551147461, "report/prior_ent_min": 46.076316833496094, "report/prior_ent_std": 0.694234311580658, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0017150879139080644, "report/reward_loss_mean": 0.017776256427168846, "report/reward_loss_std": 0.2682340741157532, "report/reward_max_data": 0.784375011920929, "report/reward_max_pred": 0.12332987785339355, "report/reward_neg_acc": 0.999020516872406, "report/reward_neg_loss": 0.0035248291678726673, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.868012428283691, "report/reward_pred": 0.0017687245272099972, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.024655327200889587, "eval/cont_loss_std": 0.4366866648197174, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.9493255615234375, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004308599047362804, "eval/cont_pred": 0.9957928657531738, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12071506679058075, "eval/image_loss_std": 0.1216355711221695, "eval/model_loss_mean": 0.7712900638580322, "eval/model_loss_std": 0.9535478949546814, "eval/post_ent_mag": 49.76868438720703, "eval/post_ent_max": 49.76868438720703, "eval/post_ent_mean": 48.27394485473633, "eval/post_ent_min": 47.290184020996094, "eval/post_ent_std": 0.5502458214759827, "eval/prior_ent_mag": 50.17521667480469, "eval/prior_ent_max": 50.17521667480469, "eval/prior_ent_mean": 48.16116714477539, "eval/prior_ent_min": 46.045684814453125, "eval/prior_ent_std": 0.7615808248519897, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0022827149368822575, "eval/reward_loss_mean": 0.025919603183865547, "eval/reward_loss_std": 0.4967222511768341, "eval/reward_max_data": 0.875, "eval/reward_max_pred": 0.07226157188415527, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0020088758319616318, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.163537979125977, "eval/reward_pred": 0.001083992887288332, "eval/reward_rate": 0.0029296875, "replay/size": 837681.0, "replay/inserts": 19680.0, "replay/samples": 19680.0, "replay/insert_wait_avg": 1.295371268822895e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.851068147798864e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2282632354997163e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.30051851272583, "timer/env.step_count": 2460.0, "timer/env.step_total": 5.459052801132202, "timer/env.step_frac": 0.0109115473582971, "timer/env.step_avg": 0.0022191271549317896, "timer/env.step_min": 0.0010411739349365234, "timer/env.step_max": 0.008863210678100586, "timer/replay._sample_count": 19680.0, "timer/replay._sample_total": 1336.018815279007, "timer/replay._sample_frac": 2.670432601690425, "timer/replay._sample_avg": 0.06788713492271377, "timer/replay._sample_min": 0.0003211498260498047, "timer/replay._sample_max": 0.0967264175415039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2811.0, "timer/agent.policy_total": 18.816044569015503, "timer/agent.policy_frac": 0.03760948444537119, "timer/agent.policy_avg": 0.0066937191636483465, "timer/agent.policy_min": 0.004921674728393555, "timer/agent.policy_max": 0.011374473571777344, "timer/dataset_train_count": 1230.0, "timer/dataset_train_total": 0.10039234161376953, "timer/dataset_train_frac": 0.00020066407668777164, "timer/dataset_train_avg": 8.161978992989392e-05, "timer/dataset_train_min": 6.890296936035156e-05, "timer/dataset_train_max": 0.0001842975616455078, "timer/agent.train_count": 1230.0, "timer/agent.train_total": 469.4172513484955, "timer/agent.train_frac": 0.9382705673461245, "timer/agent.train_avg": 0.3816400417467443, "timer/agent.train_min": 0.35629963874816895, "timer/agent.train_max": 0.4734020233154297, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4372560977935791, "timer/agent.report_frac": 0.0008739868971022401, "timer/agent.report_avg": 0.21862804889678955, "timer/agent.report_min": 0.21559691429138184, "timer/agent.report_max": 0.22165918350219727, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 6.957640710089071e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 39.33573774234964}
{"step": 838368, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 838528, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 838856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 838952, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 838960, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 839016, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05}
{"step": 839400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 839432, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 839480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 839488, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091}
{"step": 839608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 839632, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 839872, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 839920, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564}
{"step": 839936, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 840008, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 840008, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 840008, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 840008, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 840008, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 840008, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 840008, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 840008, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 840072, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 840112, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036}
{"step": 840176, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 840192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 840256, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 840296, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 840648, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 840744, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 840760, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 840848, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 841024, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 841096, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 841384, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 841488, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 841944, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 842056, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 842232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 842464, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 842504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 842584, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 842608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 842784, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 842960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 843072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 843256, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 843408, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 843448, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052}
{"step": 843504, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 843624, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 843880, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 844344, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 844408, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 844416, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 844776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 844784, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 844880, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 845096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 845272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 845360, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 845424, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 845720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 845816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 846016, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 846304, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 846504, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 847088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 847192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 847368, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 847584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 847672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 847736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 847856, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 847896, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 848032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 848248, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 848248, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 848432, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 848560, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 848608, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 848616, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 848616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 848688, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 848960, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 849000, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 849256, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 849504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 849616, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 849920, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 850040, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 850096, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 850096, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 850096, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 850096, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 850096, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 850096, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 850096, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 850096, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 850368, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 850744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 850752, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 850872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 850928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 850936, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 851000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 851240, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 851432, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 851528, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 851568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 851688, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 851760, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 851816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 851992, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 852112, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 852120, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625}
{"step": 852120, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641}
{"step": 852256, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555}
{"step": 852472, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 852584, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 852840, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 853168, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 853248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 853536, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 853608, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506}
{"step": 853624, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444}
{"step": 853832, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 853840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 854128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 854136, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 854216, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 854240, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 854488, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903}
{"step": 854592, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 854896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 854984, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 855208, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 855560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 855672, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757}
{"step": 855936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 856120, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 856224, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 856376, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125}
{"step": 856528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 856624, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805}
{"step": 856624, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 856904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 856920, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 856952, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 857064, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 857136, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 857208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 857328, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 857400, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 857400, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 857408, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 857416, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 857560, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 857864, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 857912, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 858128, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 858153, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2125091552734375, "train/action_min": 0.0, "train/action_std": 1.7586406229003784, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013062389740239709, "train/actor_opt_grad_steps": 52915.0, "train/actor_opt_loss": -13.121187301773217, "train/adv_mag": 1.2116729078754302, "train/adv_max": 0.2734133293551783, "train/adv_mean": -0.000650729940169244, "train/adv_min": -1.1813211719835959, "train/adv_std": 0.035780995573487975, "train/cont_avg": 0.9944398941532258, "train/cont_loss_mean": 0.018977986881509423, "train/cont_loss_std": 0.245739403451162, "train/cont_neg_acc": 0.33601452860861053, "train/cont_neg_loss": 2.655695936799842, "train/cont_pos_acc": 0.9998335516260516, "train/cont_pos_loss": 0.003871982772609279, "train/cont_pred": 0.9946074514619766, "train/cont_rate": 0.9944398941532258, "train/dyn_loss_mean": 1.0000016910414542, "train/dyn_loss_std": 5.409686409327532e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12389148253526899, "train/extr_critic_critic_opt_grad_steps": 52915.0, "train/extr_critic_critic_opt_loss": 6853.551135647682, "train/extr_critic_mag": 1.6210850631037066, "train/extr_critic_max": 1.6210850631037066, "train/extr_critic_mean": 1.5266636686940347, "train/extr_critic_min": 1.3924007146589217, "train/extr_critic_std": 0.02306614757605618, "train/extr_return_normed_mag": 1.214355440870408, "train/extr_return_normed_max": 0.3150924982563142, "train/extr_return_normed_mean": 0.04256362119509328, "train/extr_return_normed_min": -1.1650179980262634, "train/extr_return_normed_std": 0.043573511343809865, "train/extr_return_rate": 0.9994230328067657, "train/extr_return_raw_mag": 1.7985417419864285, "train/extr_return_raw_max": 1.7985417419864285, "train/extr_return_raw_mean": 1.5260129369074298, "train/extr_return_raw_min": 0.318431245703851, "train/extr_return_raw_std": 0.04357351120861788, "train/extr_reward_mag": 0.3065382319111978, "train/extr_reward_max": 0.3065382319111978, "train/extr_reward_mean": 0.002237146587914697, "train/extr_reward_min": 6.345010572864163e-08, "train/extr_reward_std": 0.008653250770763524, "train/image_loss_mean": 0.08665411796180471, "train/image_loss_std": 0.1011531199178388, "train/model_loss_mean": 0.7201396476837897, "train/model_loss_std": 0.4626249651154203, "train/model_opt_grad_norm": 18.049127924826838, "train/model_opt_grad_steps": 52868.58870967742, "train/model_opt_loss": 3951.750082692792, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5483.870967741936, "train/policy_entropy_mag": 1.33728735389248, "train/policy_entropy_max": 1.33728735389248, "train/policy_entropy_mean": 0.09656674559077909, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12064795634679255, "train/policy_logprob_mag": 6.551080265352803, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09679076027485632, "train/policy_logprob_min": -6.551080265352803, "train/policy_logprob_std": 0.6357257976647346, "train/policy_randomness_mag": 0.6872297958020241, "train/policy_randomness_max": 0.6872297958020241, "train/policy_randomness_mean": 0.04962549301525278, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06200078907873361, "train/post_ent_mag": 50.662581905241936, "train/post_ent_max": 50.662581905241936, "train/post_ent_mean": 49.281313926942886, "train/post_ent_min": 48.20640865448983, "train/post_ent_std": 0.5142776307559782, "train/prior_ent_mag": 50.91669491798647, "train/prior_ent_max": 50.91669491798647, "train/prior_ent_mean": 48.87799515262727, "train/prior_ent_min": 46.47391636140885, "train/prior_ent_std": 0.7635637685175864, "train/rep_loss_mean": 1.0000016910414542, "train/rep_loss_std": 5.409686409327532e-05, "train/reward_avg": 0.002045539115164091, "train/reward_loss_mean": 0.01450650156062517, "train/reward_loss_std": 0.21890839244118862, "train/reward_max_data": 0.7321824576825865, "train/reward_max_pred": 0.24668787083318156, "train/reward_neg_acc": 0.9997075627888402, "train/reward_neg_loss": 0.0025043660636818515, "train/reward_pos_acc": 0.160073262376663, "train/reward_pos_loss": 4.131237720831846, "train/reward_pred": 0.0015682063737673866, "train/reward_rate": 0.0029611895161290322, "train_stats/mean_log_entropy": 0.07839405358041802, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.011964894831180573, "report/cont_loss_std": 0.16745290160179138, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 2.3472533226013184, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0028068998362869024, "report/cont_pred": 0.9962769150733948, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07020202279090881, "report/image_loss_std": 0.08256645500659943, "report/model_loss_mean": 0.695188045501709, "report/model_loss_std": 0.4060690701007843, "report/post_ent_mag": 50.056884765625, "report/post_ent_max": 50.056884765625, "report/post_ent_mean": 48.73583984375, "report/post_ent_min": 47.80720520019531, "report/post_ent_std": 0.4883146286010742, "report/prior_ent_mag": 51.59280014038086, "report/prior_ent_max": 51.59280014038086, "report/prior_ent_mean": 48.985050201416016, "report/prior_ent_min": 47.09296417236328, "report/prior_ent_std": 0.6273256540298462, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0022460937034338713, "report/reward_loss_mean": 0.01302112266421318, "report/reward_loss_std": 0.21244560182094574, "report/reward_max_data": 0.7875000238418579, "report/reward_max_pred": 0.036229848861694336, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0015449378406628966, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.9187495708465576, "report/reward_pred": 0.0008832289604470134, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03870699554681778, "eval/cont_loss_std": 0.5560940504074097, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.053842067718506, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032543351408094168, "eval/cont_pred": 0.996642529964447, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12772426009178162, "eval/image_loss_std": 0.12414152920246124, "eval/model_loss_mean": 0.7973816394805908, "eval/model_loss_std": 0.9371264576911926, "eval/post_ent_mag": 50.05678939819336, "eval/post_ent_max": 50.05678939819336, "eval/post_ent_mean": 48.69966125488281, "eval/post_ent_min": 47.65401077270508, "eval/post_ent_std": 0.4837687909603119, "eval/prior_ent_mag": 50.531585693359375, "eval/prior_ent_max": 50.531585693359375, "eval/prior_ent_mean": 48.795654296875, "eval/prior_ent_min": 47.051876068115234, "eval/prior_ent_std": 0.6406624913215637, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0036376952193677425, "eval/reward_loss_mean": 0.030950404703617096, "eval/reward_loss_std": 0.45513787865638733, "eval/reward_max_data": 0.965624988079071, "eval/reward_max_pred": 0.04565715789794922, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0017732253763824701, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.977260112762451, "eval/reward_pred": 0.0009783474961295724, "eval/reward_rate": 0.0048828125, "replay/size": 857649.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.2458230440433208e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.500415005745032e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2208.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2714577757793923e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.556510925292969e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.35909056663513, "timer/env.step_count": 2496.0, "timer/env.step_total": 5.513269662857056, "timer/env.step_frac": 0.011018625956437636, "timer/env.step_avg": 0.0022088420123626026, "timer/env.step_min": 0.001049041748046875, "timer/env.step_max": 0.008665800094604492, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 1354.7387614250183, "timer/replay._sample_frac": 2.7075330237146984, "timer/replay._sample_avg": 0.0678454908566215, "timer/replay._sample_min": 0.0003542900085449219, "timer/replay._sample_max": 0.09421753883361816, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2772.0, "timer/agent.policy_total": 18.412482261657715, "timer/agent.policy_frac": 0.03679853650866295, "timer/agent.policy_avg": 0.006642309618202639, "timer/agent.policy_min": 0.00516819953918457, "timer/agent.policy_max": 0.010322093963623047, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.10210871696472168, "timer/dataset_train_frac": 0.0002040708740778307, "timer/dataset_train_avg": 8.181788218327057e-05, "timer/dataset_train_min": 6.246566772460938e-05, "timer/dataset_train_max": 0.00017333030700683594, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 469.9052264690399, "timer/agent.train_frac": 0.9391359831933751, "timer/agent.train_avg": 0.3765266237732692, "timer/agent.train_min": 0.35239267349243164, "timer/agent.train_max": 0.43034887313842773, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.43518519401550293, "timer/agent.report_frac": 0.0008697457530404303, "timer/agent.report_avg": 0.21759259700775146, "timer/agent.report_min": 0.21545934677124023, "timer/agent.report_max": 0.2197258472442627, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 6.86152725870238e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 39.90669857994349}
{"step": 858264, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 858376, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 858400, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 858480, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 858680, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 859136, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 859264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 859312, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 859448, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 859472, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 859728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 860008, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 860080, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 860080, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 860080, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 860080, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 860080, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 860080, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 860080, "eval_episode/length": 262.0, "eval_episode/score": 0.18125000596046448, "eval_episode/reward_rate": 0.0038022813688212928}
{"step": 860080, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 860416, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 860440, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 860544, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625}
{"step": 860792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 860864, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 860896, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545}
{"step": 861024, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 861248, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 861344, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 861504, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 861512, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 861760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 861784, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 861784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 861848, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 861936, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609}
{"step": 862240, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 862440, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 862528, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213}
{"step": 862552, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 862824, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703}
{"step": 863120, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 863400, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 863424, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695}
{"step": 863656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 863912, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 864072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 864096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 864184, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 864312, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 864552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 864784, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 864968, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 864976, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 865032, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 865096, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757}
{"step": 865136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 865384, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 865488, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 865680, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 865736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 865880, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 866104, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 866232, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 866408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 866600, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 866840, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 866928, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 867000, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 867184, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 867224, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 867344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 867448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 867472, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 867928, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 867936, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 867992, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 867992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 868120, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 868456, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 868552, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 868984, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 869240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 869312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 869392, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 869648, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 869656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 869776, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 869856, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374}
{"step": 870064, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 870064, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 870064, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 870064, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 870064, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 870064, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 870064, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 870064, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 870208, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 870248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 870432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 870496, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 870560, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 870624, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 870648, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 870752, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 871512, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 871520, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 871592, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 871624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 871632, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667}
{"step": 872056, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095}
{"step": 872104, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 872184, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 872192, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 872560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 872856, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 872864, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 873064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 873552, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 873832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 873944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 874368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 874496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 874504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 874688, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 874744, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 875176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 875272, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 875336, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 875376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 875568, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 875648, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 875864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 875880, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 875920, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 876384, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 876600, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 876808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 876864, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008}
{"step": 877056, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 877240, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 877520, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 877616, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 877880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 877944, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 877960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 878120, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 878145, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.097984375, "train/action_min": 0.0, "train/action_std": 1.7440820169448852, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.014466777689754963, "train/actor_opt_grad_steps": 54160.0, "train/actor_opt_loss": -13.180371314048767, "train/adv_mag": 1.1780217037200928, "train/adv_max": 0.32225647163391113, "train/adv_mean": 0.0021630287548177877, "train/adv_min": -1.1374897603988647, "train/adv_std": 0.03913418157398701, "train/cont_avg": 0.99484375, "train/cont_loss_mean": 0.017204832727089524, "train/cont_loss_std": 0.23111323201283812, "train/cont_neg_acc": 0.3379365153312683, "train/cont_neg_loss": 2.6263673522211612, "train/cont_pos_acc": 0.9998273410797119, "train/cont_pos_loss": 0.003924768057651818, "train/cont_pred": 0.9944582777023315, "train/cont_rate": 0.99484375, "train/dyn_loss_mean": 1.0000023107528686, "train/dyn_loss_std": 7.391276676207781e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1863570338487625, "train/extr_critic_critic_opt_grad_steps": 54160.0, "train/extr_critic_critic_opt_loss": 6262.73173828125, "train/extr_critic_mag": 1.6487766017913819, "train/extr_critic_max": 1.6487766017913819, "train/extr_critic_mean": 1.53826034450531, "train/extr_critic_min": 1.3974459123611451, "train/extr_critic_std": 0.026151172831654548, "train/extr_return_normed_mag": 1.1775111331939698, "train/extr_return_normed_max": 0.3864408292770386, "train/extr_return_normed_mean": 0.05281042914092541, "train/extr_return_normed_min": -1.1074227895736695, "train/extr_return_normed_std": 0.04889818967878819, "train/extr_return_rate": 0.9994875411987305, "train/extr_return_raw_mag": 1.874053689956665, "train/extr_return_raw_max": 1.874053689956665, "train/extr_return_raw_mean": 1.540423369407654, "train/extr_return_raw_min": 0.38019007110595704, "train/extr_return_raw_std": 0.048898189604282376, "train/extr_reward_mag": 0.36583217906951904, "train/extr_reward_max": 0.36583217906951904, "train/extr_reward_mean": 0.0024546331269666554, "train/extr_reward_min": 2.765655517578125e-08, "train/extr_reward_std": 0.011532971266657114, "train/image_loss_mean": 0.08446537372469902, "train/image_loss_std": 0.09965929687023163, "train/model_loss_mean": 0.7147863950729371, "train/model_loss_std": 0.42935557371377947, "train/model_opt_grad_norm": 17.95371913909912, "train/model_opt_grad_steps": 54112.4, "train/model_opt_loss": 3602.807884765625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5040.0, "train/policy_entropy_mag": 1.3009430599212646, "train/policy_entropy_max": 1.3009430599212646, "train/policy_entropy_mean": 0.09818026787042618, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12273719131946564, "train/policy_logprob_mag": 6.551080238342285, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09770334124565125, "train/policy_logprob_min": -6.551080238342285, "train/policy_logprob_std": 0.6337604990005493, "train/policy_randomness_mag": 0.6685525226593018, "train/policy_randomness_max": 0.6685525226593018, "train/policy_randomness_mean": 0.05045467889308929, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06307444262504577, "train/post_ent_mag": 50.343726623535154, "train/post_ent_max": 50.343726623535154, "train/post_ent_mean": 49.023547485351564, "train/post_ent_min": 47.98961740112305, "train/post_ent_std": 0.4856593902111053, "train/prior_ent_mag": 50.30554711914063, "train/prior_ent_max": 50.30554711914063, "train/prior_ent_mean": 48.32603131103516, "train/prior_ent_min": 46.27637585449219, "train/prior_ent_std": 0.6697168784141541, "train/rep_loss_mean": 1.0000023107528686, "train/rep_loss_std": 7.391276676207781e-05, "train/reward_avg": 0.0019115966813405977, "train/reward_loss_mean": 0.013114779971539973, "train/reward_loss_std": 0.19643419343605636, "train/reward_max_data": 0.7321250022649765, "train/reward_max_pred": 0.29856602096557616, "train/reward_neg_acc": 0.9994987530708312, "train/reward_neg_loss": 0.002669065922033042, "train/reward_pos_acc": 0.222932333486122, "train/reward_pos_loss": 3.7393058046959995, "train/reward_pred": 0.0016586794145405292, "train/reward_rate": 0.002765625, "train_stats/mean_log_entropy": 0.08061050555405726, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.015327004715800285, "report/cont_loss_std": 0.2074369490146637, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.392577886581421, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003662378527224064, "report/cont_pred": 0.9948109984397888, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09056795388460159, "report/image_loss_std": 0.10306928306818008, "report/model_loss_mean": 0.722582995891571, "report/model_loss_std": 0.5004453063011169, "report/post_ent_mag": 49.970367431640625, "report/post_ent_max": 49.970367431640625, "report/post_ent_mean": 48.56386184692383, "report/post_ent_min": 47.62525939941406, "report/post_ent_std": 0.5267573595046997, "report/prior_ent_mag": 51.5928955078125, "report/prior_ent_max": 51.5928955078125, "report/prior_ent_mean": 49.248008728027344, "report/prior_ent_min": 47.05792236328125, "report/prior_ent_std": 0.7322357892990112, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023986815940588713, "report/reward_loss_mean": 0.01668800786137581, "report/reward_loss_std": 0.26206591725349426, "report/reward_max_data": 0.859375, "report/reward_max_pred": 0.07877933979034424, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0025333405937999487, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.833993434906006, "report/reward_pred": 0.0012894079554826021, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.04182090237736702, "eval/cont_loss_std": 0.5092366337776184, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.34480094909668, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.005320551805198193, "eval/cont_pred": 0.9947546720504761, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13768601417541504, "eval/image_loss_std": 0.1464185267686844, "eval/model_loss_mean": 0.8119588494300842, "eval/model_loss_std": 0.8535512089729309, "eval/post_ent_mag": 49.97076416015625, "eval/post_ent_max": 49.97076416015625, "eval/post_ent_mean": 48.609832763671875, "eval/post_ent_min": 47.598876953125, "eval/post_ent_std": 0.5498000979423523, "eval/prior_ent_mag": 51.662879943847656, "eval/prior_ent_max": 51.662879943847656, "eval/prior_ent_mean": 49.232887268066406, "eval/prior_ent_min": 47.097312927246094, "eval/prior_ent_std": 0.7391500473022461, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.004620361607521772, "eval/reward_loss_mean": 0.032451894134283066, "eval/reward_loss_std": 0.3901892602443695, "eval/reward_max_data": 0.8843749761581421, "eval/reward_max_pred": 0.06105542182922363, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002791463164612651, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.064838409423828, "eval/reward_pred": 0.0015150188701227307, "eval/reward_rate": 0.005859375, "replay/size": 877641.0, "replay/inserts": 19992.0, "replay/samples": 19984.0, "replay/insert_wait_avg": 1.2230758621197502e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.361554716185058e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2998301613779745e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 499.9857370853424, "timer/env.step_count": 2499.0, "timer/env.step_total": 5.319025039672852, "timer/env.step_frac": 0.010638353547203185, "timer/env.step_avg": 0.0021284614004293124, "timer/env.step_min": 0.0010721683502197266, "timer/env.step_max": 0.01002812385559082, "timer/replay._sample_count": 19984.0, "timer/replay._sample_total": 1341.7591660022736, "timer/replay._sample_frac": 2.683594883774153, "timer/replay._sample_avg": 0.06714167163742361, "timer/replay._sample_min": 0.0003466606140136719, "timer/replay._sample_max": 0.0920419692993164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2977.0, "timer/agent.policy_total": 19.545599937438965, "timer/agent.policy_frac": 0.0390923150155836, "timer/agent.policy_avg": 0.006565535753254607, "timer/agent.policy_min": 0.005185127258300781, "timer/agent.policy_max": 0.009579658508300781, "timer/dataset_train_count": 1249.0, "timer/dataset_train_total": 0.09879064559936523, "timer/dataset_train_frac": 0.0001975869275297001, "timer/dataset_train_avg": 7.909579311398337e-05, "timer/dataset_train_min": 6.151199340820312e-05, "timer/dataset_train_max": 0.0003116130828857422, "timer/agent.train_count": 1249.0, "timer/agent.train_total": 468.26861357688904, "timer/agent.train_frac": 0.9365639434169708, "timer/agent.train_avg": 0.37491482271968696, "timer/agent.train_min": 0.3532378673553467, "timer/agent.train_max": 0.4981565475463867, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4222536087036133, "timer/agent.report_frac": 0.0008445313083631803, "timer/agent.report_avg": 0.21112680435180664, "timer/agent.report_min": 0.21081066131591797, "timer/agent.report_max": 0.2114429473876953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.1961669921875e-05, "timer/dataset_eval_frac": 8.392573389491023e-08, "timer/dataset_eval_avg": 4.1961669921875e-05, "timer/dataset_eval_min": 4.1961669921875e-05, "timer/dataset_eval_max": 4.1961669921875e-05, "fps": 39.984430225690865}
{"step": 878232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 878536, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 878552, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877}
{"step": 878576, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 878672, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 878776, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 879064, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 879152, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 879152, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629}
{"step": 879176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 879504, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 879648, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 879880, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 880048, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 880048, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 880048, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 880048, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 880048, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 880048, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 880048, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 880048, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 880120, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 880144, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 880320, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 880536, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 880544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 880864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 881072, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 881464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 881464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 881656, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 882176, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 882432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 882456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 882680, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 882776, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 882848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 882856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 883144, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776}
{"step": 883176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 883336, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 883448, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 883520, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 883528, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 883600, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993}
{"step": 883776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 883936, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 884136, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223}
{"step": 884248, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564}
{"step": 884256, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 884384, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064}
{"step": 884616, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 884664, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761}
{"step": 884848, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655}
{"step": 884856, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 885000, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 885120, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 885304, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 885456, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 885488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 885648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 885760, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 885792, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 885896, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 885936, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 885976, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 886032, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 886344, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 886464, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 886488, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 886680, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 886720, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 886896, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 887008, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 887056, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 887432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 887512, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 887792, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 888224, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 888248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 888320, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 888344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 888560, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 888776, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 888976, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 889032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 889320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 889368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 889496, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374}
{"step": 889864, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 890032, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 890032, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 890032, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 890032, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 890032, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 890032, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 890032, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 890032, "eval_episode/length": 216.0, "eval_episode/score": 0.32499998807907104, "eval_episode/reward_rate": 0.004608294930875576}
{"step": 890096, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 890336, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 890440, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 890560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 890640, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 890656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 890808, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 890944, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 891088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 891176, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 891176, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655}
{"step": 891240, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 891288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 891520, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 891648, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 891680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 891760, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 891824, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456}
{"step": 891880, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 892480, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 892512, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 892584, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 892784, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 892872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 893264, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 893368, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 893400, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 893600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 893800, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 893832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 894072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 894208, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 894656, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 894864, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 894896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 895096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 895248, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 895544, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 895680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 895736, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 895888, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 895912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 896264, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 896384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 896488, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 896544, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 896792, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 896984, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 897208, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 897208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 897560, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 897568, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 897648, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 897696, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 897808, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 897832, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216}
{"step": 897856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 898152, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055}
{"step": 898233, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1551576644655257, "train/action_min": 0.0, "train/action_std": 1.833492701015775, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009617266200837634, "train/actor_opt_grad_steps": 55415.0, "train/actor_opt_loss": -16.540386207520015, "train/adv_mag": 0.9726545659322587, "train/adv_max": 0.24520971661522276, "train/adv_mean": -0.0008092675760871142, "train/adv_min": -0.9325564948339311, "train/adv_std": 0.02831159552027072, "train/cont_avg": 0.9942181299603174, "train/cont_loss_mean": 0.019545211443781026, "train/cont_loss_std": 0.2463089827307692, "train/cont_neg_acc": 0.3212261574845465, "train/cont_neg_loss": 2.6664867115092448, "train/cont_pos_acc": 0.9998205815042768, "train/cont_pos_loss": 0.0041123678397742055, "train/cont_pred": 0.9941962933729566, "train/cont_rate": 0.9942181299603174, "train/dyn_loss_mean": 1.000002922519805, "train/dyn_loss_std": 9.347811144488376e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1035830746774399, "train/extr_critic_critic_opt_grad_steps": 55415.0, "train/extr_critic_critic_opt_loss": 5657.935484871032, "train/extr_critic_mag": 1.6322180032730103, "train/extr_critic_max": 1.6322180032730103, "train/extr_critic_mean": 1.538627494895269, "train/extr_critic_min": 1.3588683784954132, "train/extr_critic_std": 0.025384756544279675, "train/extr_return_normed_mag": 0.9932013447322543, "train/extr_return_normed_max": 0.30188521695515463, "train/extr_return_normed_mean": 0.0464855982138524, "train/extr_return_normed_min": -0.9118502140045166, "train/extr_return_normed_std": 0.039532454965251776, "train/extr_return_rate": 0.9996398942811149, "train/extr_return_raw_mag": 1.7932177706370278, "train/extr_return_raw_max": 1.7932177706370278, "train/extr_return_raw_mean": 1.537818207627251, "train/extr_return_raw_min": 0.5794823396773565, "train/extr_return_raw_std": 0.03953245449219904, "train/extr_reward_mag": 0.2839543563979013, "train/extr_reward_max": 0.2839543563979013, "train/extr_reward_mean": 0.002126110499144517, "train/extr_reward_min": 8.704170348152281e-08, "train/extr_reward_std": 0.008056641526756779, "train/image_loss_mean": 0.08530376724425763, "train/image_loss_std": 0.10025223196735458, "train/model_loss_mean": 0.7202868419034141, "train/model_loss_std": 0.47309093549847603, "train/model_opt_grad_norm": 18.260894858647905, "train/model_opt_grad_steps": 55366.206349206346, "train/model_opt_loss": 3630.6364222935267, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5039.68253968254, "train/policy_entropy_mag": 1.2940195685341245, "train/policy_entropy_max": 1.2940195685341245, "train/policy_entropy_mean": 0.1016095123948559, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12816891044614806, "train/policy_logprob_mag": 6.551080268526834, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10179523201215834, "train/policy_logprob_min": -6.551080268526834, "train/policy_logprob_std": 0.638687884523755, "train/policy_randomness_mag": 0.664994548237513, "train/policy_randomness_max": 0.664994548237513, "train/policy_randomness_mean": 0.052216962452918764, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06586579484717241, "train/post_ent_mag": 50.64458383832659, "train/post_ent_max": 50.64458383832659, "train/post_ent_mean": 49.306436387319415, "train/post_ent_min": 48.286671865554084, "train/post_ent_std": 0.48683283253321574, "train/prior_ent_mag": 50.63316838703458, "train/prior_ent_max": 50.63316838703458, "train/prior_ent_mean": 48.65472920735677, "train/prior_ent_min": 46.46546721079993, "train/prior_ent_std": 0.7185056564353761, "train/rep_loss_mean": 1.000002922519805, "train/rep_loss_std": 9.347811144488376e-05, "train/reward_avg": 0.0021897330986417178, "train/reward_loss_mean": 0.015436083885900204, "train/reward_loss_std": 0.22854031863371058, "train/reward_max_data": 0.7888640908021776, "train/reward_max_pred": 0.27196491616112844, "train/reward_neg_acc": 0.9995333358408913, "train/reward_neg_loss": 0.00278114330066028, "train/reward_pos_acc": 0.15362903415676085, "train/reward_pos_loss": 3.989370420575142, "train/reward_pred": 0.0017366941005641978, "train/reward_rate": 0.003185453869047619, "train_stats/mean_log_entropy": 0.08578745728092534, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.025924479588866234, "report/cont_loss_std": 0.2602250277996063, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 2.9225094318389893, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.005987319629639387, "report/cont_pred": 0.9929732084274292, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09821546822786331, "report/image_loss_std": 0.10581262409687042, "report/model_loss_mean": 0.7505849599838257, "report/model_loss_std": 0.6002438068389893, "report/post_ent_mag": 50.62107849121094, "report/post_ent_max": 50.62107849121094, "report/post_ent_mean": 49.466365814208984, "report/post_ent_min": 48.41022491455078, "report/post_ent_std": 0.44260409474372864, "report/prior_ent_mag": 51.085777282714844, "report/prior_ent_max": 51.085777282714844, "report/prior_ent_mean": 48.519561767578125, "report/prior_ent_min": 46.547271728515625, "report/prior_ent_std": 0.6409993171691895, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003018188290297985, "report/reward_loss_mean": 0.02644500695168972, "report/reward_loss_std": 0.31746742129325867, "report/reward_max_data": 0.8062499761581421, "report/reward_max_pred": 0.03061676025390625, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00433305511251092, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.53286075592041, "report/reward_pred": 0.002361285500228405, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.028543394058942795, "eval/cont_loss_std": 0.33366844058036804, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.3568878173828125, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.007305198349058628, "eval/cont_pred": 0.9948639869689941, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1471465677022934, "eval/image_loss_std": 0.1321794092655182, "eval/model_loss_mean": 0.8073650598526001, "eval/model_loss_std": 0.7670460939407349, "eval/post_ent_mag": 50.62114715576172, "eval/post_ent_max": 50.62114715576172, "eval/post_ent_mean": 49.29875183105469, "eval/post_ent_min": 48.236167907714844, "eval/post_ent_std": 0.5073273181915283, "eval/prior_ent_mag": 50.22162628173828, "eval/prior_ent_max": 50.22162628173828, "eval/prior_ent_mean": 48.299766540527344, "eval/prior_ent_min": 46.555702209472656, "eval/prior_ent_std": 0.6650063395500183, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0032287598587572575, "eval/reward_loss_mean": 0.03167511895298958, "eval/reward_loss_std": 0.3995038568973541, "eval/reward_max_data": 0.8843749761581421, "eval/reward_max_pred": 0.31185173988342285, "eval/reward_neg_acc": 0.999018669128418, "eval/reward_neg_loss": 0.005557251162827015, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.354496479034424, "eval/reward_pred": 0.0015364038990810513, "eval/reward_rate": 0.0048828125, "replay/size": 897729.0, "replay/inserts": 20088.0, "replay/samples": 20096.0, "replay/insert_wait_avg": 1.2177886453960485e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.260845468302441e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2616.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2064927943985033e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.30329489707947, "timer/env.step_count": 2511.0, "timer/env.step_total": 5.296884059906006, "timer/env.step_frac": 0.010587345943815264, "timer/env.step_avg": 0.0021094719473938694, "timer/env.step_min": 0.001070261001586914, "timer/env.step_max": 0.008728265762329102, "timer/replay._sample_count": 20096.0, "timer/replay._sample_total": 1342.4499824047089, "timer/replay._sample_frac": 2.6832723192056385, "timer/replay._sample_avg": 0.06680185023908781, "timer/replay._sample_min": 0.0003726482391357422, "timer/replay._sample_max": 0.09339165687561035, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2838.0, "timer/agent.policy_total": 18.419289588928223, "timer/agent.policy_frac": 0.03681624681827724, "timer/agent.policy_avg": 0.006490235936902122, "timer/agent.policy_min": 0.005059719085693359, "timer/agent.policy_max": 0.01098775863647461, "timer/dataset_train_count": 1256.0, "timer/dataset_train_total": 0.09861922264099121, "timer/dataset_train_frac": 0.00019711887498418093, "timer/dataset_train_avg": 7.85184893638465e-05, "timer/dataset_train_min": 6.246566772460938e-05, "timer/dataset_train_max": 0.00024056434631347656, "timer/agent.train_count": 1256.0, "timer/agent.train_total": 470.34797167778015, "timer/agent.train_frac": 0.9401256727172632, "timer/agent.train_avg": 0.3744808691702071, "timer/agent.train_min": 0.3530852794647217, "timer/agent.train_max": 2.3595058917999268, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.41840577125549316, "timer/agent.report_frac": 0.0008363042488887986, "timer/agent.report_avg": 0.20920288562774658, "timer/agent.report_min": 0.2085580825805664, "timer/agent.report_max": 0.20984768867492676, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 6.719328054842389e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 40.15098172056226}
{"step": 898376, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 898560, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216}
{"step": 898704, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 898800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 898832, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629}
{"step": 899128, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629}
{"step": 899136, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 899800, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 899864, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 899880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 899960, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 900016, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 900016, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 900016, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 900016, "eval_episode/length": 6.0, "eval_episode/score": 0.981249988079071, "eval_episode/reward_rate": 0.14285714285714285}
{"step": 900016, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 900016, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 900016, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 900016, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 900096, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 900120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 900152, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384}
{"step": 900440, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 900464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 900472, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 900520, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 900520, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 900616, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456}
{"step": 900768, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 900784, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 900880, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 900968, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 901264, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 901432, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 901456, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 901552, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 901664, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655}
{"step": 901664, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 901936, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 902056, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 902504, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 902656, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 902784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 902832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 903272, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052}
{"step": 903280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 903336, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 903400, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 903616, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 903768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 903784, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 903864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 904088, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 904088, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 904456, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 904544, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 904688, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 904704, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 904824, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 904968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 905296, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391}
{"step": 905400, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 905576, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 905592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 905896, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 905928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 905976, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 906008, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374}
{"step": 906160, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 906712, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 906792, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 906912, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 907000, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 907608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 907808, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 907880, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 907888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 908000, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664}
{"step": 908240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 908288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 908368, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 908464, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827}
{"step": 908544, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 908664, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 909024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 909096, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 909104, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 909232, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 909312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 909640, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629}
{"step": 909888, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 909888, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 910000, "eval_episode/length": 17.0, "eval_episode/score": 0.9468749761581421, "eval_episode/reward_rate": 0.05555555555555555}
{"step": 910000, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 910000, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 910000, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 910000, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 910000, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 910000, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 910000, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 910552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 910816, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213}
{"step": 910856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 910904, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 910936, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 911184, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 911416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 911472, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 911544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 911744, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 911952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 912048, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154}
{"step": 912360, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 912408, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 912488, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 912728, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 912760, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052}
{"step": 912880, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 913128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 913288, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 913496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 913552, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 913976, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 914032, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 914040, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 914304, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875}
{"step": 914608, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 914672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 914800, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 914920, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903}
{"step": 915008, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 915040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 915280, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 915448, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 916080, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652}
{"step": 916288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 916288, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 916344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 916616, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315}
{"step": 916616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 917064, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 917112, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 917296, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 917320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 917352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 917752, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 917760, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 917880, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 917912, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 918088, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025}
{"step": 918313, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1872412109375, "train/action_min": 0.0, "train/action_std": 1.7784322080612183, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009996019780635834, "train/actor_opt_grad_steps": 56670.0, "train/actor_opt_loss": -15.575102226257325, "train/adv_mag": 1.033762764930725, "train/adv_max": 0.2629814558029175, "train/adv_mean": -0.00033676996704889463, "train/adv_min": -0.9967033758163452, "train/adv_std": 0.029339508451521397, "train/cont_avg": 0.9940703125, "train/cont_loss_mean": 0.0212959603369236, "train/cont_loss_std": 0.26688333758711813, "train/cont_neg_acc": 0.2840989961624146, "train/cont_neg_loss": 2.8736388804130257, "train/cont_pos_acc": 0.9998820748329162, "train/cont_pos_loss": 0.003981970299035311, "train/cont_pred": 0.994484658241272, "train/cont_rate": 0.9940703125, "train/dyn_loss_mean": 1.0000010299682618, "train/dyn_loss_std": 3.291935380548239e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11204256020486354, "train/extr_critic_critic_opt_grad_steps": 56670.0, "train/extr_critic_critic_opt_loss": 6631.13452734375, "train/extr_critic_mag": 1.6318183345794677, "train/extr_critic_max": 1.6318183345794677, "train/extr_critic_mean": 1.5287122945785523, "train/extr_critic_min": 1.3428498716354371, "train/extr_critic_std": 0.02448508894443512, "train/extr_return_normed_mag": 1.0580115385055542, "train/extr_return_normed_max": 0.31545888900756835, "train/extr_return_normed_mean": 0.045760536342859266, "train/extr_return_normed_min": -0.9828211250305176, "train/extr_return_normed_std": 0.03934206660091877, "train/extr_return_rate": 0.9996312861442566, "train/extr_return_raw_mag": 1.7980738067626953, "train/extr_return_raw_max": 1.7980738067626953, "train/extr_return_raw_mean": 1.5283755292892456, "train/extr_return_raw_min": 0.4997937927246094, "train/extr_return_raw_std": 0.03934206673502922, "train/extr_reward_mag": 0.2940428304672241, "train/extr_reward_max": 0.2940428304672241, "train/extr_reward_mean": 0.0022152678878046574, "train/extr_reward_min": 3.4332275390625e-08, "train/extr_reward_std": 0.008383225109428167, "train/image_loss_mean": 0.08394609948992729, "train/image_loss_std": 0.09891584020853042, "train/model_loss_mean": 0.7216537551879882, "train/model_loss_std": 0.4963823980689049, "train/model_opt_grad_norm": 17.815243049621582, "train/model_opt_grad_steps": 56619.816, "train/model_opt_loss": 3638.448265625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5080.0, "train/policy_entropy_mag": 1.284659468650818, "train/policy_entropy_max": 1.284659468650818, "train/policy_entropy_mean": 0.10045371580123902, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12548708575963974, "train/policy_logprob_mag": 6.551080253601074, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10000767254829407, "train/policy_logprob_min": -6.551080253601074, "train/policy_logprob_std": 0.6350658550262451, "train/policy_randomness_mag": 0.6601844100952149, "train/policy_randomness_max": 0.6601844100952149, "train/policy_randomness_mean": 0.05162299996614456, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06448760876059532, "train/post_ent_mag": 50.83981155395508, "train/post_ent_max": 50.83981155395508, "train/post_ent_mean": 49.5368359375, "train/post_ent_min": 48.510244598388674, "train/post_ent_std": 0.47859180450439454, "train/prior_ent_mag": 50.93034649658203, "train/prior_ent_max": 50.93034649658203, "train/prior_ent_mean": 48.676907806396486, "train/prior_ent_min": 46.52311148071289, "train/prior_ent_std": 0.7268750681877136, "train/rep_loss_mean": 1.0000010299682618, "train/rep_loss_std": 3.291935380548239e-05, "train/reward_avg": 0.0024352294916752727, "train/reward_loss_mean": 0.016411053337156773, "train/reward_loss_std": 0.2358758799061179, "train/reward_max_data": 0.7990499985218048, "train/reward_max_pred": 0.3076787042617798, "train/reward_neg_acc": 0.9995846185684204, "train/reward_neg_loss": 0.0027725252080708744, "train/reward_pos_acc": 0.17256700711660697, "train/reward_pos_loss": 3.9914191394555765, "train/reward_pred": 0.0017963473442941904, "train/reward_rate": 0.003421875, "train_stats/mean_log_entropy": 0.08073131473206763, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.02793242037296295, "report/cont_loss_std": 0.3376094698905945, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 2.758392810821533, "report/cont_pos_acc": 0.999015748500824, "report/cont_pos_loss": 0.006432733964174986, "report/cont_pred": 0.9919029474258423, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09966833889484406, "report/image_loss_std": 0.11040859669446945, "report/model_loss_mean": 0.7435264587402344, "report/model_loss_std": 0.4976194202899933, "report/post_ent_mag": 50.715057373046875, "report/post_ent_max": 50.715057373046875, "report/post_ent_mean": 49.465179443359375, "report/post_ent_min": 48.36613082885742, "report/post_ent_std": 0.49566376209259033, "report/prior_ent_mag": 53.18878936767578, "report/prior_ent_max": 53.18878936767578, "report/prior_ent_mean": 50.363346099853516, "report/prior_ent_min": 48.06449890136719, "report/prior_ent_std": 0.7577903270721436, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0019287108443677425, "report/reward_loss_mean": 0.01592571660876274, "report/reward_loss_std": 0.20927760004997253, "report/reward_max_data": 0.699999988079071, "report/reward_max_pred": 0.14560997486114502, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0052903140895068645, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.6355080604553223, "report/reward_pred": 0.002053170697763562, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.027971096336841583, "eval/cont_loss_std": 0.5069727897644043, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.32697057723999, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.006524479482322931, "eval/cont_pred": 0.9950381517410278, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10591131448745728, "eval/image_loss_std": 0.1091616153717041, "eval/model_loss_mean": 0.7468293905258179, "eval/model_loss_std": 0.6213924884796143, "eval/post_ent_mag": 50.71575927734375, "eval/post_ent_max": 50.71575927734375, "eval/post_ent_mean": 49.420318603515625, "eval/post_ent_min": 48.45998764038086, "eval/post_ent_std": 0.506697416305542, "eval/prior_ent_mag": 53.150184631347656, "eval/prior_ent_max": 53.150184631347656, "eval/prior_ent_mean": 50.324363708496094, "eval/prior_ent_min": 47.688812255859375, "eval/prior_ent_std": 0.8570359349250793, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0015136718284338713, "eval/reward_loss_mean": 0.0129469633102417, "eval/reward_loss_std": 0.20378263294696808, "eval/reward_max_data": 0.7906249761581421, "eval/reward_max_pred": 0.5902743339538574, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.004466283600777388, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.346574783325195, "eval/reward_pred": 0.0020357612520456314, "eval/reward_rate": 0.001953125, "replay/size": 917809.0, "replay/inserts": 20080.0, "replay/samples": 20080.0, "replay/insert_wait_avg": 1.212360849418488e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.204364123097454e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2328.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2554868390060373e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.0189096927643, "timer/env.step_count": 2510.0, "timer/env.step_total": 5.280354738235474, "timer/env.step_frac": 0.010560310092032276, "timer/env.step_avg": 0.0021037269873448103, "timer/env.step_min": 0.0010704994201660156, "timer/env.step_max": 0.008053302764892578, "timer/replay._sample_count": 20080.0, "timer/replay._sample_total": 1339.6335234642029, "timer/replay._sample_frac": 2.6791657225270504, "timer/replay._sample_avg": 0.0667148169055878, "timer/replay._sample_min": 0.0003383159637451172, "timer/replay._sample_max": 0.0901334285736084, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2801.0, "timer/agent.policy_total": 18.310911893844604, "timer/agent.policy_frac": 0.036620438825195056, "timer/agent.policy_avg": 0.00653727664899843, "timer/agent.policy_min": 0.005188703536987305, "timer/agent.policy_max": 0.009169578552246094, "timer/dataset_train_count": 1255.0, "timer/dataset_train_total": 0.09749150276184082, "timer/dataset_train_frac": 0.00019497563166509903, "timer/dataset_train_avg": 7.768247232019189e-05, "timer/dataset_train_min": 5.936622619628906e-05, "timer/dataset_train_max": 0.00012803077697753906, "timer/agent.train_count": 1255.0, "timer/agent.train_total": 470.1925494670868, "timer/agent.train_frac": 0.9403495354925592, "timer/agent.train_avg": 0.3746554179020612, "timer/agent.train_min": 0.3501436710357666, "timer/agent.train_max": 0.4204385280609131, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.42420005798339844, "timer/agent.report_frac": 0.0008483680312091545, "timer/agent.report_avg": 0.21210002899169922, "timer/agent.report_min": 0.2115623950958252, "timer/agent.report_max": 0.21263766288757324, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 6.770831577794586e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 40.157785986170154}
{"step": 918384, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 918392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 918568, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 918600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 918600, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 918832, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 918840, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 918888, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 918992, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 919144, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 919232, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 919408, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 919408, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 919416, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 919664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 919800, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 920080, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 920080, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 920088, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 920088, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 920088, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 920088, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 920088, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 920088, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 920088, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 920088, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 920424, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 920704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 921032, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269}
{"step": 921152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 921272, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154}
{"step": 921392, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 921544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 921728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 922256, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 922392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 922680, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 922736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 922920, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 922952, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762}
{"step": 923080, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 923344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 923464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 923464, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 923504, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 923616, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 923784, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713}
{"step": 924040, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 924136, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 924288, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842}
{"step": 924560, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 924632, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 924912, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 924992, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345}
{"step": 925344, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 925472, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 925776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 925776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 925792, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 926096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 926120, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 926200, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 926352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 926632, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 926648, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 926728, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 926920, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993}
{"step": 927152, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 927224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 927328, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 927360, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 927504, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374}
{"step": 927936, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 928088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 928328, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 928664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 928720, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 928880, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 929168, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 929192, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 929232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 929448, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125}
{"step": 929464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 929640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 929744, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 929816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 930056, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 930072, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 930072, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 930072, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 930072, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 930072, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 930072, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 930072, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 930072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930104, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 930272, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 930656, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 930864, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 931032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 931352, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 931480, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 931608, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 932128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 932336, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 932368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 932416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 932888, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 932968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 932968, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 933040, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 933176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 933312, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 933792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 933856, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 933896, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 933920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 934224, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 934312, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422}
{"step": 934312, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952}
{"step": 934368, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 934720, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 934872, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 935016, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 935328, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 935352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 935376, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203}
{"step": 935544, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 935624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 935808, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517}
{"step": 936096, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 936208, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 936208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 936632, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886}
{"step": 937032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 937208, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 937328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 937352, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357}
{"step": 937400, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861}
{"step": 937664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 937792, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 937856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 938256, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 938272, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 938392, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 938393, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.172516837952629, "train/action_min": 0.0, "train/action_std": 1.73350856701533, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011583522753050876, "train/actor_opt_grad_steps": 57925.0, "train/actor_opt_loss": -16.713984682446434, "train/adv_mag": 0.928757222398879, "train/adv_max": 0.3010647476665557, "train/adv_mean": -0.001123220413224169, "train/adv_min": -0.865861600826657, "train/adv_std": 0.02805864348978041, "train/cont_avg": 0.9945126488095238, "train/cont_loss_mean": 0.019077955970599775, "train/cont_loss_std": 0.2472651568315332, "train/cont_neg_acc": 0.3130162237655549, "train/cont_neg_loss": 2.7547096879709336, "train/cont_pos_acc": 0.9998674610304454, "train/cont_pos_loss": 0.004005418406681172, "train/cont_pred": 0.9943754545279911, "train/cont_rate": 0.9945126488095238, "train/dyn_loss_mean": 1.0000008817703006, "train/dyn_loss_std": 2.8201861173978875e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09374290110454672, "train/extr_critic_critic_opt_grad_steps": 57925.0, "train/extr_critic_critic_opt_loss": 8987.609832279266, "train/extr_critic_mag": 1.614090747303433, "train/extr_critic_max": 1.614090747303433, "train/extr_critic_mean": 1.5010876021687947, "train/extr_critic_min": 1.2951742779640925, "train/extr_critic_std": 0.024608974389377095, "train/extr_return_normed_mag": 0.9405580569827368, "train/extr_return_normed_max": 0.3196975948318603, "train/extr_return_normed_mean": 0.045539666795068316, "train/extr_return_normed_min": -0.8530109155745733, "train/extr_return_normed_std": 0.03799732527621682, "train/extr_return_rate": 0.9996863977303581, "train/extr_return_raw_mag": 1.7741222457280235, "train/extr_return_raw_max": 1.7741222457280235, "train/extr_return_raw_mean": 1.4999643914283267, "train/extr_return_raw_min": 0.6014137353215899, "train/extr_return_raw_std": 0.03799732532056551, "train/extr_reward_mag": 0.32050912058542647, "train/extr_reward_max": 0.32050912058542647, "train/extr_reward_mean": 0.002037620123860145, "train/extr_reward_min": 3.1221480596633186e-08, "train/extr_reward_std": 0.008055404281347163, "train/image_loss_mean": 0.08398734452942061, "train/image_loss_std": 0.1002401609624189, "train/model_loss_mean": 0.7184591714351897, "train/model_loss_std": 0.4695122100058056, "train/model_opt_grad_norm": 18.17429774905008, "train/model_opt_grad_steps": 57873.642857142855, "train/model_opt_loss": 3703.973578559028, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5158.730158730159, "train/policy_entropy_mag": 1.30507693215022, "train/policy_entropy_max": 1.30507693215022, "train/policy_entropy_mean": 0.10321968799782177, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13029932236624142, "train/policy_logprob_mag": 6.551080249604725, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10174895296730692, "train/policy_logprob_min": -6.551080249604725, "train/policy_logprob_std": 0.6329935060607063, "train/policy_randomness_mag": 0.6706769097419012, "train/policy_randomness_max": 0.6706769097419012, "train/policy_randomness_mean": 0.053044428694106284, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06696061018322196, "train/post_ent_mag": 51.091717614067925, "train/post_ent_max": 51.091717614067925, "train/post_ent_mean": 49.79499483865405, "train/post_ent_min": 48.75725086151608, "train/post_ent_std": 0.4858537219346516, "train/prior_ent_mag": 51.22135422721742, "train/prior_ent_max": 51.22135422721742, "train/prior_ent_mean": 49.07516240316724, "train/prior_ent_min": 46.7219120207287, "train/prior_ent_std": 0.7751884734819806, "train/rep_loss_mean": 1.0000008817703006, "train/rep_loss_std": 2.8201861173978875e-05, "train/reward_avg": 0.002201479960647356, "train/reward_loss_mean": 0.015393317601318278, "train/reward_loss_std": 0.22535870844010442, "train/reward_max_data": 0.7547619045372047, "train/reward_max_pred": 0.28718303687988767, "train/reward_neg_acc": 0.9996810115519024, "train/reward_neg_loss": 0.002898389580733483, "train/reward_pos_acc": 0.23628493084395227, "train/reward_pos_loss": 3.885542086333283, "train/reward_pred": 0.0018236345522815273, "train/reward_rate": 0.003224206349206349, "train_stats/mean_log_entropy": 0.0909033562092818, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.016239749267697334, "report/cont_loss_std": 0.22522246837615967, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.5116775035858154, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003995207604020834, "report/cont_pred": 0.9946258068084717, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06628836691379547, "report/image_loss_std": 0.0813748836517334, "report/model_loss_mean": 0.6932286024093628, "report/model_loss_std": 0.38092344999313354, "report/post_ent_mag": 51.583438873291016, "report/post_ent_max": 51.583438873291016, "report/post_ent_mean": 50.188507080078125, "report/post_ent_min": 49.044227600097656, "report/post_ent_std": 0.5125897526741028, "report/prior_ent_mag": 52.79761505126953, "report/prior_ent_max": 52.79761505126953, "report/prior_ent_mean": 50.428985595703125, "report/prior_ent_min": 48.29607009887695, "report/prior_ent_std": 0.6639822721481323, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0015624999068677425, "report/reward_loss_mean": 0.010700437240302563, "report/reward_loss_std": 0.17555710673332214, "report/reward_max_data": 0.8218749761581421, "report/reward_max_pred": 0.11507606506347656, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.0029656337574124336, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.9631850719451904, "report/reward_pred": 0.0015105451457202435, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02563278190791607, "eval/cont_loss_std": 0.3884311318397522, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.289626598358154, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.007227315567433834, "eval/cont_pred": 0.9938291907310486, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1166951134800911, "eval/image_loss_std": 0.14775924384593964, "eval/model_loss_mean": 0.7562404274940491, "eval/model_loss_std": 0.5753124952316284, "eval/post_ent_mag": 51.583438873291016, "eval/post_ent_max": 51.583438873291016, "eval/post_ent_mean": 50.25559616088867, "eval/post_ent_min": 49.082366943359375, "eval/post_ent_std": 0.5142956376075745, "eval/prior_ent_mag": 52.38125991821289, "eval/prior_ent_max": 52.38125991821289, "eval/prior_ent_mean": 50.43311309814453, "eval/prior_ent_min": 48.73740768432617, "eval/prior_ent_std": 0.674156904220581, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.00152587890625, "eval/reward_loss_mean": 0.013912491500377655, "eval/reward_loss_std": 0.23798029124736786, "eval/reward_max_data": 0.875, "eval/reward_max_pred": 0.06625819206237793, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0040507931262254715, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.053240776062012, "eval/reward_pred": 0.001995122991502285, "eval/reward_rate": 0.001953125, "replay/size": 937889.0, "replay/inserts": 20080.0, "replay/samples": 20080.0, "replay/insert_wait_avg": 1.1990269816729177e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.144403275265637e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3912.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2674824104231072e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.1500105857849, "timer/env.step_count": 2510.0, "timer/env.step_total": 5.232866287231445, "timer/env.step_frac": 0.010462593574880896, "timer/env.step_avg": 0.00208480728574958, "timer/env.step_min": 0.001001596450805664, "timer/env.step_max": 0.009083747863769531, "timer/replay._sample_count": 20080.0, "timer/replay._sample_total": 1340.531237602234, "timer/replay._sample_frac": 2.6802583409569043, "timer/replay._sample_avg": 0.06675952378497181, "timer/replay._sample_min": 0.0003528594970703125, "timer/replay._sample_max": 0.09282779693603516, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2999.0, "timer/agent.policy_total": 19.51221776008606, "timer/agent.policy_frac": 0.03901273087494888, "timer/agent.policy_avg": 0.006506241333806622, "timer/agent.policy_min": 0.00522160530090332, "timer/agent.policy_max": 0.009718179702758789, "timer/dataset_train_count": 1255.0, "timer/dataset_train_total": 0.09881877899169922, "timer/dataset_train_frac": 0.0001975782803162612, "timer/dataset_train_avg": 7.8740062941593e-05, "timer/dataset_train_min": 6.008148193359375e-05, "timer/dataset_train_max": 0.00017881393432617188, "timer/agent.train_count": 1255.0, "timer/agent.train_total": 468.17494010925293, "timer/agent.train_frac": 0.9360690396885483, "timer/agent.train_avg": 0.37304776104322945, "timer/agent.train_min": 0.3477053642272949, "timer/agent.train_max": 0.41919755935668945, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.42371153831481934, "timer/agent.report_frac": 0.0008471689080213365, "timer/agent.report_avg": 0.21185576915740967, "timer/agent.report_min": 0.21126055717468262, "timer/agent.report_max": 0.21245098114013672, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 6.244693232281295e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 40.14729955560924}
{"step": 938520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 938568, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 938640, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 938848, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 938880, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052}
{"step": 939312, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 939368, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 939488, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 939520, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 939712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 939744, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 939808, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 940056, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 940056, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 940056, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 940056, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 940056, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 940056, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 940056, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 940056, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 940232, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 940256, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 940432, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 940496, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 940512, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 940832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 940880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 940928, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904}
{"step": 940992, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 941072, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 941296, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 941304, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 941488, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 941496, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426}
{"step": 941536, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 941648, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 941848, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 941984, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 942000, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 942248, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02}
{"step": 942320, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 942328, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 942472, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 942584, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 942768, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 942808, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 942912, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 943240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 943384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 943392, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 943664, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 943672, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259}
{"step": 944000, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 944120, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 944264, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 944280, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 944312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 944544, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304}
{"step": 944632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 944896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 945056, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 945104, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 945112, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 945160, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 945360, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 945672, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 945984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 946000, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 946024, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 946624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 946856, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 946992, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356}
{"step": 947120, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 947408, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 947424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 947472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 947616, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 947672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 947696, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474}
{"step": 947704, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 947736, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304}
{"step": 947960, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 948008, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 948016, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372}
{"step": 948224, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464}
{"step": 948280, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 948296, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 948336, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 948560, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 948608, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403}
{"step": 948640, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941}
{"step": 948904, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 948944, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105}
{"step": 949104, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 949336, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547}
{"step": 949528, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 949584, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 949848, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 950040, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 950040, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 950040, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 950040, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 950040, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 950040, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 950040, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 950040, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 950040, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 950104, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694}
{"step": 950184, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808}
{"step": 950320, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 950608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 950616, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 950632, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 950808, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 951024, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 951160, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 951392, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 951416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 951840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 952104, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 952184, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 952312, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 952464, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542}
{"step": 952512, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609}
{"step": 952880, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 952920, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 952920, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 952928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 953064, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 953120, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 953248, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 953280, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728}
{"step": 953376, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 953408, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 953568, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 953840, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 954016, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856}
{"step": 954096, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 954192, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 954312, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 954368, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 954424, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 954576, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666}
{"step": 954800, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 954864, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516}
{"step": 955200, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 955240, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301}
{"step": 955376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 955424, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943}
{"step": 955504, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154}
{"step": 955576, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 955592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 955648, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 955912, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 956024, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 956032, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818}
{"step": 956040, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 956224, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009}
{"step": 956232, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 956232, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 956464, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 956584, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176}
{"step": 956776, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 956792, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 956880, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 957392, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 957472, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 957512, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 957768, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 957888, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 958112, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112}
{"step": 958216, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 958344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 958472, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 958505, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.0547984289744545, "train/action_min": 0.0, "train/action_std": 1.8338724772135417, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010735870494196812, "train/actor_opt_grad_steps": 59185.0, "train/actor_opt_loss": -16.412979773112706, "train/adv_mag": 0.9146405354378715, "train/adv_max": 0.3048511753006587, "train/adv_mean": 0.00037215610396266303, "train/adv_min": -0.8578809887643845, "train/adv_std": 0.026967992570014702, "train/cont_avg": 0.9945901537698413, "train/cont_loss_mean": 0.019241037061585795, "train/cont_loss_std": 0.24468016428577286, "train/cont_neg_acc": 0.3048374961529459, "train/cont_neg_loss": 2.749040980775294, "train/cont_pos_acc": 0.9999220659808506, "train/cont_pos_loss": 0.004223735294386094, "train/cont_pred": 0.9943197847358765, "train/cont_rate": 0.9945901537698413, "train/dyn_loss_mean": 1.000000790944175, "train/dyn_loss_std": 2.527583903487077e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09722956755597677, "train/extr_critic_critic_opt_grad_steps": 59185.0, "train/extr_critic_critic_opt_loss": 10068.332294766866, "train/extr_critic_mag": 1.593449356063964, "train/extr_critic_max": 1.593449356063964, "train/extr_critic_mean": 1.4852434585964869, "train/extr_critic_min": 1.2224431246046037, "train/extr_critic_std": 0.026853818860318925, "train/extr_return_normed_mag": 0.9411412354499574, "train/extr_return_normed_max": 0.3003551382867117, "train/extr_return_normed_mean": 0.05120773013267252, "train/extr_return_normed_min": -0.8527303773259359, "train/extr_return_normed_std": 0.03921862016062415, "train/extr_return_rate": 0.9996905288999043, "train/extr_return_raw_mag": 1.7347629458185225, "train/extr_return_raw_max": 1.7347629458185225, "train/extr_return_raw_mean": 1.4856156186451988, "train/extr_return_raw_min": 0.5816774302058749, "train/extr_return_raw_std": 0.03921862023453864, "train/extr_reward_mag": 0.28626872528166997, "train/extr_reward_max": 0.28626872528166997, "train/extr_reward_mean": 0.0021360960441626727, "train/extr_reward_min": 6.055075024801587e-08, "train/extr_reward_std": 0.007938237624272468, "train/image_loss_mean": 0.0825984865013096, "train/image_loss_std": 0.09951013610476539, "train/model_loss_mean": 0.7172644332287803, "train/model_loss_std": 0.46858276414965827, "train/model_opt_grad_norm": 17.620835107470317, "train/model_opt_grad_steps": 59132.50793650794, "train/model_opt_loss": 3839.02879890563, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5357.142857142857, "train/policy_entropy_mag": 1.3051160327971927, "train/policy_entropy_max": 1.3051160327971927, "train/policy_entropy_mean": 0.0998834449029158, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1251108112434546, "train/policy_logprob_mag": 6.551080283664522, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09955015542015197, "train/policy_logprob_min": -6.551080283664522, "train/policy_logprob_std": 0.6353071237367297, "train/policy_randomness_mag": 0.6706970069143507, "train/policy_randomness_max": 0.6706970069143507, "train/policy_randomness_mean": 0.05132993822178197, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06429424198965232, "train/post_ent_mag": 50.93173898969378, "train/post_ent_max": 50.93173898969378, "train/post_ent_mean": 49.69418286520337, "train/post_ent_min": 48.74297096615746, "train/post_ent_std": 0.44728687594807337, "train/prior_ent_mag": 51.5128308856298, "train/prior_ent_max": 51.5128308856298, "train/prior_ent_mean": 49.49508488367474, "train/prior_ent_min": 47.277329883878195, "train/prior_ent_std": 0.7225126638298943, "train/rep_loss_mean": 1.000000790944175, "train/rep_loss_std": 2.527583903487077e-05, "train/reward_avg": 0.00211111400766106, "train/reward_loss_mean": 0.015424412039537278, "train/reward_loss_std": 0.2238121298067863, "train/reward_max_data": 0.7862351163039132, "train/reward_max_pred": 0.23943055905993021, "train/reward_neg_acc": 0.9997044953088912, "train/reward_neg_loss": 0.0029436889250526233, "train/reward_pos_acc": 0.189043749032951, "train/reward_pos_loss": 3.9099229840728325, "train/reward_pred": 0.0017986205648556942, "train/reward_rate": 0.003115699404761905, "train_stats/mean_log_entropy": 0.08368320296270938, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.02278294414281845, "report/cont_loss_std": 0.2667880952358246, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 2.641335964202881, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004759471397846937, "report/cont_pred": 0.9935035705566406, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08666247129440308, "report/image_loss_std": 0.10182584077119827, "report/model_loss_mean": 0.725159764289856, "report/model_loss_std": 0.4775056540966034, "report/post_ent_mag": 50.606536865234375, "report/post_ent_max": 50.606536865234375, "report/post_ent_mean": 49.47343063354492, "report/post_ent_min": 48.69731140136719, "report/post_ent_std": 0.39900481700897217, "report/prior_ent_mag": 50.486263275146484, "report/prior_ent_max": 50.486263275146484, "report/prior_ent_mean": 48.95978546142578, "report/prior_ent_min": 46.530216217041016, "report/prior_ent_std": 0.7270994186401367, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0026275634299963713, "report/reward_loss_mean": 0.015714313834905624, "report/reward_loss_std": 0.2211015373468399, "report/reward_max_data": 0.778124988079071, "report/reward_max_pred": 0.5417696237564087, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.003335647052153945, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.172274589538574, "report/reward_pred": 0.002440199488773942, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.04636036604642868, "eval/cont_loss_std": 0.6242615580558777, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.343552112579346, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.003016871167346835, "eval/cont_pred": 0.9968641996383667, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1344967484474182, "eval/image_loss_std": 0.1456877738237381, "eval/model_loss_mean": 0.803206205368042, "eval/model_loss_std": 0.9121963977813721, "eval/post_ent_mag": 50.606536865234375, "eval/post_ent_max": 50.606536865234375, "eval/post_ent_mean": 49.49828338623047, "eval/post_ent_min": 48.637046813964844, "eval/post_ent_std": 0.41797783970832825, "eval/prior_ent_mag": 50.43189239501953, "eval/prior_ent_max": 50.43189239501953, "eval/prior_ent_mean": 48.94745635986328, "eval/prior_ent_min": 46.955223083496094, "eval/prior_ent_std": 0.6764898896217346, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002862548688426614, "eval/reward_loss_mean": 0.022349026054143906, "eval/reward_loss_std": 0.3594089448451996, "eval/reward_max_data": 0.90625, "eval/reward_max_pred": 0.04901599884033203, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.0017314647557213902, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.279827117919922, "eval/reward_pred": 0.0010143504478037357, "eval/reward_rate": 0.00390625, "replay/size": 958001.0, "replay/inserts": 20112.0, "replay/samples": 20112.0, "replay/insert_wait_avg": 1.2081676565092901e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.167988243801023e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1912.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2829962135857618e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.00909662246704, "timer/env.step_count": 2514.0, "timer/env.step_total": 5.3967578411102295, "timer/env.step_frac": 0.010793319316718479, "timer/env.step_avg": 0.002146681718818707, "timer/env.step_min": 0.0010797977447509766, "timer/env.step_max": 0.007666826248168945, "timer/replay._sample_count": 20112.0, "timer/replay._sample_total": 1344.6979858875275, "timer/replay._sample_frac": 2.689347043825574, "timer/replay._sample_avg": 0.06686048060299958, "timer/replay._sample_min": 0.00030517578125, "timer/replay._sample_max": 0.09331274032592773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2753.0, "timer/agent.policy_total": 17.908644199371338, "timer/agent.policy_frac": 0.03581663677789706, "timer/agent.policy_avg": 0.006505137740418212, "timer/agent.policy_min": 0.005163908004760742, "timer/agent.policy_max": 0.008981466293334961, "timer/dataset_train_count": 1257.0, "timer/dataset_train_total": 0.09950757026672363, "timer/dataset_train_frac": 0.0001990115198681216, "timer/dataset_train_avg": 7.916274484226223e-05, "timer/dataset_train_min": 6.937980651855469e-05, "timer/dataset_train_max": 0.00018262863159179688, "timer/agent.train_count": 1257.0, "timer/agent.train_total": 470.3937864303589, "timer/agent.train_frac": 0.9407704571933633, "timer/agent.train_avg": 0.37421940050147884, "timer/agent.train_min": 0.3479142189025879, "timer/agent.train_max": 0.4235820770263672, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4175848960876465, "timer/agent.report_frac": 0.0008351545980031337, "timer/agent.report_avg": 0.20879244804382324, "timer/agent.report_min": 0.20768976211547852, "timer/agent.report_max": 0.20989513397216797, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 6.532550219096632e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 40.22263970255935}
{"step": 958536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 958544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 958816, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 958864, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025}
{"step": 958872, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714}
{"step": 959192, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374}
{"step": 959568, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 959688, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993}
{"step": 959976, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 959976, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 960024, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 960024, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 960024, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 960024, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 960024, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 960024, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 960024, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 960024, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 960424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 960528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 960632, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 960784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 960848, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931}
{"step": 961176, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 961176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 961256, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549}
{"step": 961792, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 961808, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248}
{"step": 961880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 962016, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 962136, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213}
{"step": 962232, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 962288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 962336, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 962608, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 962680, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 962712, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 962880, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353}
{"step": 962920, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 963328, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756}
{"step": 963368, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 963496, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391}
{"step": 963568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 964096, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 964192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 964256, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809}
{"step": 964992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 965000, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894}
{"step": 965192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 965256, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125}
{"step": 965264, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 965640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 965648, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 965680, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 965880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 966176, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667}
{"step": 966264, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633}
{"step": 966328, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 966824, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 966888, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 967568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 967576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 967696, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842}
{"step": 967960, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 967968, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 967992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 968432, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288}
{"step": 968600, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 968640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 968736, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 969080, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291}
{"step": 969120, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 969120, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 969136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 969176, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358}
{"step": 969416, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 969648, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152}
{"step": 969728, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258}
{"step": 969888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 970008, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 970008, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 970008, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 970008, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 970008, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 970008, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 970008, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 970008, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 970208, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 970352, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494}
{"step": 970480, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 970512, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809}
{"step": 970600, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815}
{"step": 970640, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 970744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 970864, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 970896, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332}
{"step": 970944, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304}
{"step": 971184, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364}
{"step": 971392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 971456, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 971464, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 971632, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 971784, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 971912, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 971920, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 972160, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333}
{"step": 972312, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835}
{"step": 972448, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 972600, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 972728, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 972768, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756}
{"step": 972800, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 972912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 972952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 972976, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085}
{"step": 973104, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154}
{"step": 973464, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 973488, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 973552, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888}
{"step": 973760, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 973768, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 973824, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 973976, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 974120, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315}
{"step": 974312, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 974448, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952}
{"step": 974528, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693}
{"step": 974536, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 974632, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513}
{"step": 974848, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408}
{"step": 974960, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 975016, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
{"step": 975144, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 975152, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421}
{"step": 975328, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 975656, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 975896, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425}
{"step": 976104, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 976136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 976456, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285}
{"step": 976704, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 976840, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 976848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 977272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 977392, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 977464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 977720, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 977784, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 977968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 978016, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617}
{"step": 978032, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 978602, "train_stats/mean_log_entropy": 0.08416330626717321, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.0830234375, "train/action_min": 0.0, "train/action_std": 1.8499948921203613, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009677984356880187, "train/actor_opt_grad_steps": 60440.0, "train/actor_opt_loss": -17.541818489074707, "train/adv_mag": 0.9866076784133911, "train/adv_max": 0.2958539161682129, "train/adv_mean": 0.0003890448121601366, "train/adv_min": -0.9431101379394531, "train/adv_std": 0.02558344969898462, "train/cont_avg": 0.9942890625, "train/cont_loss_mean": 0.020551249798387287, "train/cont_loss_std": 0.2530234466567636, "train/cont_neg_acc": 0.28249841803312303, "train/cont_neg_loss": 2.808679155692458, "train/cont_pos_acc": 0.9999057202339172, "train/cont_pos_loss": 0.004244503409601748, "train/cont_pred": 0.9943065748214722, "train/cont_rate": 0.9942890625, "train/dyn_loss_mean": 1.0000031490325927, "train/dyn_loss_std": 0.00010073916334658861, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08668024431169033, "train/extr_critic_critic_opt_grad_steps": 60440.0, "train/extr_critic_critic_opt_loss": 9161.5355546875, "train/extr_critic_mag": 1.602038963317871, "train/extr_critic_max": 1.602038963317871, "train/extr_critic_mean": 1.4973746719360352, "train/extr_critic_min": 1.2223774070739746, "train/extr_critic_std": 0.02837306962907314, "train/extr_return_normed_mag": 1.0351022748947143, "train/extr_return_normed_max": 0.3008148078918457, "train/extr_return_normed_mean": 0.05461305445432663, "train/extr_return_normed_min": -0.9568165340423584, "train/extr_return_normed_std": 0.03910870718955994, "train/extr_return_rate": 0.9996792044639587, "train/extr_return_raw_mag": 1.7439653949737548, "train/extr_return_raw_max": 1.7439653949737548, "train/extr_return_raw_mean": 1.4977637205123902, "train/extr_return_raw_min": 0.4863340530395508, "train/extr_return_raw_std": 0.03910870692133903, "train/extr_reward_mag": 0.2796804666519165, "train/extr_reward_max": 0.2796804666519165, "train/extr_reward_mean": 0.0021768065099604427, "train/extr_reward_min": 4.76837158203125e-08, "train/extr_reward_std": 0.007589553903788328, "train/image_loss_mean": 0.0837448990046978, "train/image_loss_std": 0.09971645474433899, "train/model_loss_mean": 0.7211674308776855, "train/model_loss_std": 0.4957805894613266, "train/model_opt_grad_norm": 17.2685191116333, "train/model_opt_grad_steps": 60386.344, "train/model_opt_loss": 3750.705255859375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5200.0, "train/policy_entropy_mag": 1.2864827718734742, "train/policy_entropy_max": 1.2864827718734742, "train/policy_entropy_mean": 0.0969917806982994, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1195770223736763, "train/policy_logprob_mag": 6.551080284118652, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09748543697595596, "train/policy_logprob_min": -6.551080284118652, "train/policy_logprob_std": 0.6364922051429749, "train/policy_randomness_mag": 0.6611214017868042, "train/policy_randomness_max": 0.6611214017868042, "train/policy_randomness_mean": 0.04984391698241234, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.061450436979532244, "train/post_ent_mag": 50.624103118896485, "train/post_ent_max": 50.624103118896485, "train/post_ent_mean": 49.545392822265626, "train/post_ent_min": 48.69358938598633, "train/post_ent_std": 0.3857415614128113, "train/prior_ent_mag": 50.80975323486328, "train/prior_ent_max": 50.80975323486328, "train/prior_ent_mean": 49.01571475219727, "train/prior_ent_min": 46.85266705322265, "train/prior_ent_std": 0.6926292724609375, "train/rep_loss_mean": 1.0000031490325927, "train/rep_loss_std": 0.00010073916334658861, "train/reward_avg": 0.0023209960830863565, "train/reward_loss_mean": 0.016869369607418777, "train/reward_loss_std": 0.24288345680385828, "train/reward_max_data": 0.7879249994754791, "train/reward_max_pred": 0.23072055625915527, "train/reward_neg_acc": 0.9997883834838868, "train/reward_neg_loss": 0.002945718504022807, "train/reward_pos_acc": 0.1321038266674417, "train/reward_pos_loss": 4.158999794819316, "train/reward_pred": 0.0017923027500510217, "train/reward_rate": 0.003359375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00559314014390111, "report/cont_loss_std": 0.10846152901649475, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 0.7043830752372742, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002164338016882539, "report/cont_pred": 0.993981122970581, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06072993203997612, "report/image_loss_std": 0.07380186021327972, "report/model_loss_mean": 0.6729104518890381, "report/model_loss_std": 0.2744031846523285, "report/post_ent_mag": 50.602657318115234, "report/post_ent_max": 50.602657318115234, "report/post_ent_mean": 49.486061096191406, "report/post_ent_min": 48.634971618652344, "report/post_ent_std": 0.39023834466934204, "report/prior_ent_mag": 50.714359283447266, "report/prior_ent_max": 50.714359283447266, "report/prior_ent_mean": 48.86524200439453, "report/prior_ent_min": 46.69956588745117, "report/prior_ent_std": 0.7138791084289551, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008361816871911287, "report/reward_loss_mean": 0.00658740708604455, "report/reward_loss_std": 0.13601776957511902, "report/reward_max_data": 0.721875011920929, "report/reward_max_pred": 0.2110651731491089, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0015688254497945309, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.571082592010498, "report/reward_pred": 0.0010558267822489142, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.04758201539516449, "eval/cont_loss_std": 0.60727459192276, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.646501064300537, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0027946738991886377, "eval/cont_pred": 0.9972438812255859, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13010507822036743, "eval/image_loss_std": 0.13538649678230286, "eval/model_loss_mean": 0.8133281469345093, "eval/model_loss_std": 1.1447149515151978, "eval/post_ent_mag": 50.60267639160156, "eval/post_ent_max": 50.60267639160156, "eval/post_ent_mean": 49.51850509643555, "eval/post_ent_min": 48.756832122802734, "eval/post_ent_std": 0.4008568823337555, "eval/prior_ent_mag": 50.672447204589844, "eval/prior_ent_max": 50.672447204589844, "eval/prior_ent_mean": 49.023529052734375, "eval/prior_ent_min": 47.13511657714844, "eval/prior_ent_std": 0.6294490694999695, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0026977539528161287, "eval/reward_loss_mean": 0.03564102202653885, "eval/reward_loss_std": 0.5674108266830444, "eval/reward_max_data": 0.90625, "eval/reward_max_pred": 0.06651604175567627, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.0017306715017184615, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.682781219482422, "eval/reward_pred": 0.0009399480186402798, "eval/reward_rate": 0.00390625, "replay/size": 978098.0, "replay/inserts": 20097.0, "replay/samples": 20096.0, "replay/insert_wait_avg": 1.2151909187705254e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.157391546638149e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2552.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2277809430065574e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 499.9988660812378, "timer/env.step_count": 2512.0, "timer/env.step_total": 5.268994331359863, "timer/env.step_frac": 0.010538012561220046, "timer/env.step_avg": 0.0020975295905094997, "timer/env.step_min": 0.001071929931640625, "timer/env.step_max": 0.008888483047485352, "timer/replay._sample_count": 20096.0, "timer/replay._sample_total": 1343.202224969864, "timer/replay._sample_frac": 2.6864105422823616, "timer/replay._sample_avg": 0.06683928269157365, "timer/replay._sample_min": 0.00041556358337402344, "timer/replay._sample_max": 0.09126663208007812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2831.0, "timer/agent.policy_total": 18.393029928207397, "timer/agent.policy_frac": 0.03678614328141091, "timer/agent.policy_avg": 0.00649700809897824, "timer/agent.policy_min": 0.005154609680175781, "timer/agent.policy_max": 0.010429620742797852, "timer/dataset_train_count": 1256.0, "timer/dataset_train_total": 0.09898853302001953, "timer/dataset_train_frac": 0.00019797751502087662, "timer/dataset_train_avg": 7.881252628982447e-05, "timer/dataset_train_min": 5.8650970458984375e-05, "timer/dataset_train_max": 0.00022935867309570312, "timer/agent.train_count": 1256.0, "timer/agent.train_total": 469.28554105758667, "timer/agent.train_frac": 0.9385732106467198, "timer/agent.train_avg": 0.3736349849184607, "timer/agent.train_min": 0.35297107696533203, "timer/agent.train_max": 0.42003631591796875, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4228396415710449, "timer/agent.report_frac": 0.0008456812010096512, "timer/agent.report_avg": 0.21141982078552246, "timer/agent.report_min": 0.21138238906860352, "timer/agent.report_max": 0.2114572525024414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 6.67573535432689e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 40.19346243942523}
{"step": 978768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 978816, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005}
{"step": 978928, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 979232, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052}
{"step": 979496, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304}
{"step": 979576, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 979584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 979744, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 979776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 979984, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576}
{"step": 980096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 980096, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 980096, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 980096, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 980096, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 980096, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 980096, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 980096, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 980096, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 980344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 980416, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525}
{"step": 980432, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 980544, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 980632, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761}
{"step": 981056, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775}
{"step": 981080, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678}
{"step": 981336, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102}
{"step": 981536, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 981568, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 981880, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 981896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 982296, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 982296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 982384, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745}
{"step": 982400, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 982408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 982512, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541}
{"step": 982728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 982960, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 983040, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993}
{"step": 983176, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338}
{"step": 983208, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 983328, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 983416, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 983456, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099}
{"step": 983488, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 983624, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232}
{"step": 983632, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806}
{"step": 984112, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 984320, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616}
{"step": 984328, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505}
{"step": 984392, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 984696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 984736, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061}
{"step": 984824, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667}
{"step": 984976, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 985480, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012}
{"step": 985632, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 985640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 985760, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 985800, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 986328, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186}
{"step": 986424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 986568, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 986632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 986640, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 986720, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333}
{"step": 986736, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203}
{"step": 986808, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 986912, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 987392, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863}
{"step": 987456, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009}
{"step": 987568, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064}
{"step": 987608, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218}
{"step": 987656, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044}
{"step": 987672, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857}
{"step": 987960, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169}
{"step": 988264, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 988280, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282}
{"step": 988336, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 988728, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143}
{"step": 988880, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988}
{"step": 988928, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357}
{"step": 988952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 989032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 989144, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901}
{"step": 989392, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625}
{"step": 989584, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374}
{"step": 989664, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548}
{"step": 989880, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414}
{"step": 990080, "eval_episode/length": 213.0, "eval_episode/score": 0.3343749940395355, "eval_episode/reward_rate": 0.004672897196261682}
{"step": 990080, "eval_episode/length": 224.0, "eval_episode/score": 0.30000001192092896, "eval_episode/reward_rate": 0.0044444444444444444}
{"step": 990080, "eval_episode/length": 237.0, "eval_episode/score": 0.2593750059604645, "eval_episode/reward_rate": 0.004201680672268907}
{"step": 990080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990176, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 990184, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 990272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 990648, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357}
{"step": 990824, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406}
{"step": 991192, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936}
{"step": 991240, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 991344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 991408, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 991832, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514}
{"step": 991952, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965}
{"step": 992192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 992360, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315}
{"step": 992360, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496}
{"step": 992400, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695}
{"step": 992488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 992656, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 993448, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588}
{"step": 993720, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 994120, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036}
{"step": 994200, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992}
{"step": 994504, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895}
{"step": 994504, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928}
{"step": 994568, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608}
{"step": 994800, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475}
{"step": 994888, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556}
{"step": 994968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 995288, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306}
{"step": 995376, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082}
{"step": 995440, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 995680, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 995832, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612}
{"step": 996032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 996400, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125}
{"step": 996432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 996632, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01}
{"step": 996816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 996880, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 996904, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872}
{"step": 997192, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 997280, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 997392, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 997448, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 997760, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 997912, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 997912, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266}
{"step": 997936, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124}
{"step": 997992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 998088, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125}
{"step": 998272, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909}
{"step": 998344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0}
{"step": 998432, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385}
{"step": 998489, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.0688634072580645, "train/action_min": 0.0, "train/action_std": 1.839338578524128, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012038482754911867, "train/actor_opt_grad_steps": 61685.0, "train/actor_opt_loss": -18.706861520486495, "train/adv_mag": 0.9422704414013894, "train/adv_max": 0.31222081280523734, "train/adv_mean": 0.0017746648104695205, "train/adv_min": -0.871072321168838, "train/adv_std": 0.03301915162873845, "train/cont_avg": 0.9944477696572581, "train/cont_loss_mean": 0.019864353676131295, "train/cont_loss_std": 0.25298465565673167, "train/cont_neg_acc": 0.29338838268191586, "train/cont_neg_loss": 2.8073689649106877, "train/cont_pos_acc": 0.9998732199591975, "train/cont_pos_loss": 0.004040755063009959, "train/cont_pred": 0.9944849903545072, "train/cont_rate": 0.9944477696572581, "train/dyn_loss_mean": 1.0000031205915636, "train/dyn_loss_std": 9.979267093923784e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13137869421212423, "train/extr_critic_critic_opt_grad_steps": 61685.0, "train/extr_critic_critic_opt_loss": 8355.82413015058, "train/extr_critic_mag": 1.624373399442242, "train/extr_critic_max": 1.624373399442242, "train/extr_critic_mean": 1.511279074415084, "train/extr_critic_min": 1.2479402749769148, "train/extr_critic_std": 0.03224521220451401, "train/extr_return_normed_mag": 0.9556951580509063, "train/extr_return_normed_max": 0.33227070300809797, "train/extr_return_normed_mean": 0.06202746888682727, "train/extr_return_normed_min": -0.8601636030981618, "train/extr_return_normed_std": 0.047860539833744685, "train/extr_return_rate": 0.9995710772852744, "train/extr_return_raw_mag": 1.783296896565345, "train/extr_return_raw_max": 1.783296896565345, "train/extr_return_raw_mean": 1.5130537315722434, "train/extr_return_raw_min": 0.5908625904590853, "train/extr_return_raw_std": 0.04786053966851004, "train/extr_reward_mag": 0.3019297642092551, "train/extr_reward_max": 0.3019297642092551, "train/extr_reward_mean": 0.002354925005009488, "train/extr_reward_min": 1.442047857469128e-08, "train/extr_reward_std": 0.009193695957712349, "train/image_loss_mean": 0.08282592799514532, "train/image_loss_std": 0.10030733769939791, "train/model_loss_mean": 0.7183475561680333, "train/model_loss_std": 0.48164002681451457, "train/model_opt_grad_norm": 17.8586032044503, "train/model_opt_grad_steps": 61630.153225806454, "train/model_opt_loss": 3738.2582614037296, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5201.612903225807, "train/policy_entropy_mag": 1.3071396725793039, "train/policy_entropy_max": 1.3071396725793039, "train/policy_entropy_mean": 0.09719092116480874, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12118776292810517, "train/policy_logprob_mag": 6.551080261507342, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09699156009141476, "train/policy_logprob_min": -6.551080261507342, "train/policy_logprob_std": 0.633203205562407, "train/policy_randomness_mag": 0.6717369493938261, "train/policy_randomness_max": 0.6717369493938261, "train/policy_randomness_mean": 0.04994625535102621, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06227819447315509, "train/post_ent_mag": 50.69267697488108, "train/post_ent_max": 50.69267697488108, "train/post_ent_mean": 49.642178289351925, "train/post_ent_min": 48.82844715733682, "train/post_ent_std": 0.3784626390664808, "train/prior_ent_mag": 50.878340351966116, "train/prior_ent_max": 50.878340351966116, "train/prior_ent_mean": 49.0272420760124, "train/prior_ent_min": 46.856642815374556, "train/prior_ent_std": 0.7183828964348762, "train/rep_loss_mean": 1.0000031205915636, "train/rep_loss_std": 9.979267093923784e-05, "train/reward_avg": 0.002189144002547818, "train/reward_loss_mean": 0.015655379359339996, "train/reward_loss_std": 0.22830217093559763, "train/reward_max_data": 0.7553175428221303, "train/reward_max_pred": 0.25593648129893887, "train/reward_neg_acc": 0.9997472359288123, "train/reward_neg_loss": 0.002786577094323753, "train/reward_pos_acc": 0.1660411639486329, "train/reward_pos_loss": 4.035546031543764, "train/reward_pred": 0.0017329441175060046, "train/reward_rate": 0.0031659526209677417, "train_stats/mean_log_entropy": 0.08135250844617388, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0289517380297184, "report/cont_loss_std": 0.36705389618873596, "report/cont_neg_acc": 0.375, "report/cont_neg_loss": 3.1095833778381348, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004694798029959202, "report/cont_pred": 0.9923967123031616, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08464035391807556, "report/image_loss_std": 0.10207571089267731, "report/model_loss_mean": 0.7315564155578613, "report/model_loss_std": 0.5736035108566284, "report/post_ent_mag": 50.40081787109375, "report/post_ent_max": 50.40081787109375, "report/post_ent_mean": 49.41389083862305, "report/post_ent_min": 48.61293411254883, "report/post_ent_std": 0.38747724890708923, "report/prior_ent_mag": 50.71466827392578, "report/prior_ent_max": 50.71466827392578, "report/prior_ent_mean": 49.139686584472656, "report/prior_ent_min": 46.87765884399414, "report/prior_ent_std": 0.751806378364563, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0028869628440588713, "report/reward_loss_mean": 0.01796424202620983, "report/reward_loss_std": 0.25701525807380676, "report/reward_max_data": 0.84375, "report/reward_max_pred": 0.7546133995056152, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.003575817449018359, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.6870126724243164, "report/reward_pred": 0.0026587508618831635, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.024107197299599648, "eval/cont_loss_std": 0.3135918080806732, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.145301342010498, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038854419253766537, "eval/cont_pred": 0.9960367679595947, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09814995527267456, "eval/image_loss_std": 0.11673660576343536, "eval/model_loss_mean": 0.7408187985420227, "eval/model_loss_std": 0.5444892048835754, "eval/post_ent_mag": 50.400840759277344, "eval/post_ent_max": 50.400840759277344, "eval/post_ent_mean": 49.40050506591797, "eval/post_ent_min": 48.61665344238281, "eval/post_ent_std": 0.39780184626579285, "eval/prior_ent_mag": 50.67283630371094, "eval/prior_ent_max": 50.67283630371094, "eval/prior_ent_mean": 49.112125396728516, "eval/prior_ent_min": 47.274269104003906, "eval/prior_ent_std": 0.657698929309845, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0026672363746911287, "eval/reward_loss_mean": 0.018561620265245438, "eval/reward_loss_std": 0.2501417398452759, "eval/reward_max_data": 0.75, "eval/reward_max_pred": 0.03559446334838867, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.002923472784459591, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.006289482116699, "eval/reward_pred": 0.0016136516351252794, "eval/reward_rate": 0.00390625, "replay/size": 997985.0, "replay/inserts": 19887.0, "replay/samples": 19888.0, "replay/insert_wait_avg": 1.2450348397584536e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 5.457445391703304e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3408.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2154590355958178e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 500.42269492149353, "timer/env.step_count": 2486.0, "timer/env.step_total": 5.35387659072876, "timer/env.step_frac": 0.010698708601872418, "timer/env.step_avg": 0.0021536108570912147, "timer/env.step_min": 0.0009844303131103516, "timer/env.step_max": 0.00902247428894043, "timer/replay._sample_count": 19888.0, "timer/replay._sample_total": 1338.0608110427856, "timer/replay._sample_frac": 2.6738611670134205, "timer/replay._sample_avg": 0.06727980747399365, "timer/replay._sample_min": 0.0003573894500732422, "timer/replay._sample_max": 0.09113311767578125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2912.0, "timer/agent.policy_total": 19.265175342559814, "timer/agent.policy_frac": 0.03849780503176847, "timer/agent.policy_avg": 0.006615788235769167, "timer/agent.policy_min": 0.005094051361083984, "timer/agent.policy_max": 0.009992837905883789, "timer/dataset_train_count": 1243.0, "timer/dataset_train_total": 0.10027623176574707, "timer/dataset_train_frac": 0.00020038306172640399, "timer/dataset_train_avg": 8.067275282843691e-05, "timer/dataset_train_min": 6.890296936035156e-05, "timer/dataset_train_max": 0.0001571178436279297, "timer/agent.train_count": 1243.0, "timer/agent.train_total": 468.88869071006775, "timer/agent.train_frac": 0.9369852635952635, "timer/agent.train_avg": 0.3772234036283731, "timer/agent.train_min": 0.35271763801574707, "timer/agent.train_max": 0.5311009883880615, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4362523555755615, "timer/agent.report_frac": 0.0008717677275687925, "timer/agent.report_avg": 0.21812617778778076, "timer/agent.report_min": 0.21416306495666504, "timer/agent.report_max": 0.22208929061889648, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 6.622437957238577e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 39.73972107210794}
{"step": 998528, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666}
{"step": 998848, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364}
{"step": 998872, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334}
{"step": 998880, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644}
{"step": 999160, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179}
{"step": 999168, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669}
{"step": 999304, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464}
{"step": 999448, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521}
{"step": 999608, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684}
{"step": 999696, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903}
{"step": 1000056, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428}
