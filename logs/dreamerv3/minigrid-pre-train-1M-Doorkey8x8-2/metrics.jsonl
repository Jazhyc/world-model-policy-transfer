{"step": 1560, "time": 112.3716471195221, "eval_episode/length": 580.0, "eval_episode/score": 0.18437500298023224, "eval_episode/reward_rate": 0.0017211703958691911}
{"step": 1560, "time": 113.56633925437927, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 113.57670450210571, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 113.58523201942444, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 113.59344363212585, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 113.6018443107605, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 113.61003065109253, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 113.61832022666931, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 236.60098934173584, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.85333251953125, "train/action_min": 0.0, "train/action_std": 1.83516526222229, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0010002430062741041, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.797097086906433, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.6333669424057007, "train/cont_loss_std": 0.25742945075035095, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.6337890625, "train/cont_pos_loss": 0.6333669424057007, "train/cont_pred": 0.547575831413269, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.998153686523438, "train/dyn_loss_std": 0.3699451982975006, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 10.124852180480957, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 40302.828125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5001.5625, "train/image_loss_std": 40.9649543762207, "train/model_loss_mean": 5014.3359375, "train/model_loss_std": 40.971343994140625, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50143360.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9188684225082397, "train/policy_entropy_max": 1.9188684225082397, "train/policy_entropy_mean": 1.637658953666687, "train/policy_entropy_min": 0.72793048620224, "train/policy_entropy_std": 0.13939125835895538, "train/policy_logprob_mag": 4.636440753936768, "train/policy_logprob_max": -0.17986755073070526, "train/policy_logprob_mean": -1.6484825611114502, "train/policy_logprob_min": -4.636440753936768, "train/policy_logprob_std": 0.7320331931114197, "train/policy_randomness_mag": 0.986103355884552, "train/policy_randomness_max": 0.986103355884552, "train/policy_randomness_mean": 0.8415902853012085, "train/policy_randomness_min": 0.3740822970867157, "train/policy_randomness_std": 0.07163293659687042, "train/post_ent_mag": 105.61354064941406, "train/post_ent_max": 105.61354064941406, "train/post_ent_mean": 105.3157730102539, "train/post_ent_min": 104.97392272949219, "train/post_ent_std": 0.1163194477558136, "train/prior_ent_mag": 106.42049407958984, "train/prior_ent_max": 106.42049407958984, "train/prior_ent_mean": 105.5657958984375, "train/prior_ent_min": 104.71128845214844, "train/prior_ent_std": 0.25896352529525757, "train/rep_loss_mean": 10.998153686523438, "train/rep_loss_std": 0.3699451982975006, "train/reward_avg": 0.0002769467537291348, "train/reward_loss_mean": 5.541263580322266, "train/reward_loss_std": 2.8233671400812455e-07, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263580322266, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.6185562610626221, "report/cont_loss_std": 0.26872146129608154, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.66796875, "report/cont_pos_loss": 0.6185562610626221, "report/cont_pred": 0.5570448637008667, "report/cont_rate": 1.0, "report/dyn_loss_mean": 11.03693962097168, "report/dyn_loss_std": 0.3650050759315491, "report/image_loss_mean": 5001.8173828125, "report/image_loss_std": 42.35860061645508, "report/model_loss_mean": 5014.599609375, "report/model_loss_std": 42.36480712890625, "report/post_ent_mag": 105.64704895019531, "report/post_ent_max": 105.64704895019531, "report/post_ent_mean": 105.29432678222656, "report/post_ent_min": 104.90432739257812, "report/post_ent_std": 0.11245463043451309, "report/prior_ent_mag": 106.30564880371094, "report/prior_ent_max": 106.30564880371094, "report/prior_ent_mean": 105.55906677246094, "report/prior_ent_min": 104.70135498046875, "report/prior_ent_std": 0.2568005323410034, "report/rep_loss_mean": 11.03693962097168, "report/rep_loss_std": 0.3650050759315491, "report/reward_avg": 0.0002769467537291348, "report/reward_loss_mean": 5.541263580322266, "report/reward_loss_std": 2.8233671400812455e-07, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263580322266, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.6003941297531128, "eval/cont_loss_std": 0.25916963815689087, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.7021484375, "eval/cont_pos_loss": 0.6003941297531128, "eval/cont_pred": 0.5657336115837097, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.058734893798828, "eval/dyn_loss_std": 0.41081368923187256, "eval/image_loss_mean": 4998.88330078125, "eval/image_loss_std": 40.94770812988281, "eval/model_loss_mean": 5011.66015625, "eval/model_loss_std": 41.01510238647461, "eval/post_ent_mag": 105.70442199707031, "eval/post_ent_max": 105.70442199707031, "eval/post_ent_mean": 105.2738037109375, "eval/post_ent_min": 104.89981842041016, "eval/post_ent_std": 0.1217188835144043, "eval/prior_ent_mag": 106.6022720336914, "eval/prior_ent_max": 106.6022720336914, "eval/prior_ent_mean": 105.54252624511719, "eval/prior_ent_min": 104.55014038085938, "eval/prior_ent_std": 0.3067512512207031, "eval/rep_loss_mean": 11.058734893798828, "eval/rep_loss_std": 0.41081368923187256, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 7.619695383755802e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.876328059605189e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6184.0, "eval_replay/inserts": 6184.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.651619261017438e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 154.74044680595398, "timer/env.step_count": 196.0, "timer/env.step_total": 1.3864374160766602, "timer/env.step_frac": 0.0089597609719666, "timer/env.step_avg": 0.007073660286105409, "timer/env.step_min": 0.006283283233642578, "timer/env.step_max": 0.014451265335083008, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.08013224601745605, "timer/replay._sample_frac": 0.0005178493901981727, "timer/replay._sample_avg": 0.0007154664822987147, "timer/replay._sample_min": 0.00033354759216308594, "timer/replay._sample_max": 0.0012023448944091797, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.081317186355591, "timer/agent.save_frac": 0.013450375963858905, "timer/agent.save_avg": 2.081317186355591, "timer/agent.save_min": 2.081317186355591, "timer/agent.save_max": 2.081317186355591, "timer/agent.policy_count": 642.0, "timer/agent.policy_total": 23.50825595855713, "timer/agent.policy_frac": 0.1519205640399676, "timer/agent.policy_avg": 0.03661722111924787, "timer/agent.policy_min": 0.008991718292236328, "timer/agent.policy_max": 14.783153057098389, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 4.1961669921875e-05, "timer/dataset_train_frac": 2.711745428426696e-07, "timer/dataset_train_avg": 4.1961669921875e-05, "timer/dataset_train_min": 4.1961669921875e-05, "timer/dataset_train_max": 4.1961669921875e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 89.78030610084534, "timer/agent.train_frac": 0.580199346415425, "timer/agent.train_avg": 89.78030610084534, "timer/agent.train_min": 89.78030610084534, "timer/agent.train_max": 89.78030610084534, "timer/agent.report_count": 2.0, "timer/agent.report_total": 31.012975931167603, "timer/agent.report_frac": 0.20041932520757275, "timer/agent.report_avg": 15.506487965583801, "timer/agent.report_min": 7.375472784042358, "timer/agent.report_max": 23.637503147125244, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.6716461181640625e-05, "timer/dataset_eval_frac": 2.3727772498733588e-07, "timer/dataset_eval_avg": 3.6716461181640625e-05, "timer/dataset_eval_min": 3.6716461181640625e-05, "timer/dataset_eval_max": 3.6716461181640625e-05}
{"step": 5128, "time": 349.91214990615845, "episode/length": 640.0, "episode/score": 0.11502259152860006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11502259152860006}
{"step": 5128, "time": 349.9242444038391, "episode/length": 640.0, "episode/score": 0.15167122378778686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15167122378778686}
{"step": 5128, "time": 349.9332928657532, "episode/length": 640.0, "episode/score": 0.1356368822927152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1356368822927152}
{"step": 5128, "time": 349.94198751449585, "episode/length": 640.0, "episode/score": 0.15096185697865394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15096185697865394}
{"step": 5128, "time": 349.9512393474579, "episode/length": 640.0, "episode/score": 0.13147745116293663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13147745116293663}
{"step": 5128, "time": 349.95985198020935, "episode/length": 640.0, "episode/score": 0.14152171150783488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14152171150783488}
{"step": 5128, "time": 349.96863293647766, "episode/length": 640.0, "episode/score": 0.11647638351445266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11647638351445266}
{"step": 5128, "time": 349.9775137901306, "episode/length": 640.0, "episode/score": 0.1139254549011639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1139254549011639}
{"step": 9544, "time": 490.01714754104614, "episode/length": 551.0, "episode/score": 0.13438648936823938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13438648936823938}
{"step": 10088, "time": 519.2982096672058, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 519.3074049949646, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 519.3159012794495, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 519.324248790741, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 519.3324239253998, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 519.3406019210815, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 519.3487460613251, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 519.357011795044, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10256, "time": 524.9031732082367, "episode/length": 640.0, "episode/score": 0.11600257764860089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11600257764860089}
{"step": 10256, "time": 524.9126508235931, "episode/length": 640.0, "episode/score": 0.1263085797426129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1263085797426129}
{"step": 10256, "time": 524.921468257904, "episode/length": 640.0, "episode/score": 0.1207365509755789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1207365509755789}
{"step": 10256, "time": 524.9304451942444, "episode/length": 640.0, "episode/score": 0.10230713411968395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10230713411968395}
{"step": 10256, "time": 524.9392600059509, "episode/length": 640.0, "episode/score": 0.1502671118322496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1502671118322496}
{"step": 10256, "time": 524.9475629329681, "episode/length": 640.0, "episode/score": 0.11739471967050008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11739471967050008}
{"step": 10256, "time": 524.9564065933228, "episode/length": 640.0, "episode/score": 0.11106709703381057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11106709703381057}
{"step": 12880, "time": 608.0352177619934, "episode/length": 327.0, "episode/score": 0.09204566248172341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09204566248172341}
{"step": 14672, "time": 664.8189444541931, "episode/length": 640.0, "episode/score": 0.11544849179222183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11544849179222183}
{"step": 15384, "time": 687.3489286899567, "episode/length": 640.0, "episode/score": 0.11464306635642174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11464306635642174}
{"step": 15384, "time": 687.3594682216644, "episode/length": 640.0, "episode/score": 0.1543694435437999, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1543694435437999}
{"step": 15384, "time": 687.3683061599731, "episode/length": 640.0, "episode/score": 0.1613109877531258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1613109877531258}
{"step": 15384, "time": 687.3771176338196, "episode/length": 640.0, "episode/score": 0.09205467355394603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09205467355394603}
{"step": 15384, "time": 687.3853919506073, "episode/length": 640.0, "episode/score": 0.15865130036132769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15865130036132769}
{"step": 15384, "time": 687.3940877914429, "episode/length": 640.0, "episode/score": 0.13499910260981096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13499910260981096}
{"step": 18008, "time": 771.2025651931763, "episode/length": 640.0, "episode/score": 0.13446445544269636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13446445544269636}
{"step": 19800, "time": 828.3064184188843, "episode/length": 640.0, "episode/score": 0.14447199886467388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14447199886467388}
{"step": 20072, "time": 849.0749268531799, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 849.0842363834381, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 849.0927205085754, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 849.1010241508484, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 849.1094973087311, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 849.1181192398071, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 849.1263296604156, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 849.134468793869, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20512, "time": 863.3992099761963, "episode/length": 640.0, "episode/score": 0.13259386840707066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13259386840707066}
{"step": 20512, "time": 863.4091746807098, "episode/length": 640.0, "episode/score": 0.14772296659452877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14772296659452877}
{"step": 20512, "time": 863.4185457229614, "episode/length": 640.0, "episode/score": 0.11268320372494145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11268320372494145}
{"step": 20512, "time": 863.4276413917542, "episode/length": 640.0, "episode/score": 0.050626509769074346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050626509769074346}
{"step": 20512, "time": 863.4363906383514, "episode/length": 640.0, "episode/score": 0.14967646630378795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14967646630378795}
{"step": 20512, "time": 863.4451653957367, "episode/length": 640.0, "episode/score": 0.10014185423426625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10014185423426625}
{"step": 23136, "time": 946.5587491989136, "episode/length": 640.0, "episode/score": 0.14022551569985353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14022551569985353}
{"step": 24928, "time": 1004.0520694255829, "episode/length": 640.0, "episode/score": 0.13484629893594047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13484629893594047}
{"step": 25640, "time": 1026.4729344844818, "episode/length": 640.0, "episode/score": 0.0916836219345214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0916836219345214}
{"step": 25640, "time": 1026.4825491905212, "episode/length": 640.0, "episode/score": 0.12619109160220887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12619109160220887}
{"step": 25640, "time": 1026.49174618721, "episode/length": 640.0, "episode/score": 0.08138811649234867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08138811649234867}
{"step": 25640, "time": 1026.5003561973572, "episode/length": 640.0, "episode/score": 0.09076570988418098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09076570988418098}
{"step": 25640, "time": 1026.5090763568878, "episode/length": 640.0, "episode/score": 0.15226424898628466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15226424898628466}
{"step": 25640, "time": 1026.5177443027496, "episode/length": 640.0, "episode/score": 0.10635166445047162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10635166445047162}
{"step": 28264, "time": 1109.765067577362, "episode/length": 640.0, "episode/score": 0.09623520634681881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09623520634681881}
{"step": 30056, "time": 1167.314824104309, "episode/length": 640.0, "episode/score": 0.08367716161370709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08367716161370709}
{"step": 30056, "time": 1178.9705219268799, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1178.9801969528198, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1178.988929271698, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1178.9972081184387, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1179.0052633285522, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1179.0140299797058, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1179.0223150253296, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1179.0304129123688, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30768, "time": 1201.7469263076782, "episode/length": 640.0, "episode/score": 0.07041251956690076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07041251956690076}
{"step": 30768, "time": 1201.7566921710968, "episode/length": 640.0, "episode/score": 0.09351469034817228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09351469034817228}
{"step": 30768, "time": 1201.765674829483, "episode/length": 640.0, "episode/score": 0.09060238809797738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09060238809797738}
{"step": 30768, "time": 1201.7750115394592, "episode/length": 640.0, "episode/score": 0.0601346787753414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0601346787753414}
{"step": 30768, "time": 1201.783541917801, "episode/length": 640.0, "episode/score": 0.09351551625439924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09351551625439924}
{"step": 30768, "time": 1201.7925794124603, "episode/length": 640.0, "episode/score": 0.0930014640147192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0930014640147192}
{"step": 30889, "time": 1206.4150578975677, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0009975746029713, "train/action_min": 0.0, "train/action_std": 1.9991828190172956, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0005183782765026016, "train/actor_opt_grad_steps": 920.0, "train/actor_opt_loss": 11.445367453528233, "train/adv_mag": 0.0015302029172585333, "train/adv_max": 0.0015300933259580784, "train/adv_mean": 0.0008960205815584739, "train/adv_min": 0.00010997806618326495, "train/adv_std": 0.00041649328992266166, "train/cont_avg": 0.9988846909153005, "train/cont_loss_mean": 0.012166687064981814, "train/cont_loss_std": 0.1790548817922375, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.7082622129409035, "train/cont_pos_acc": 0.9980468736971663, "train/cont_pos_loss": 0.004691485407569668, "train/cont_pred": 0.9963447940154154, "train/cont_rate": 0.9988846909153005, "train/dyn_loss_mean": 1.0728466250205952, "train/dyn_loss_std": 0.00539406400981494, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.587383138026045, "train/extr_critic_critic_opt_grad_steps": 920.0, "train/extr_critic_critic_opt_loss": 10510.836164297301, "train/extr_critic_mag": 0.013326891133042633, "train/extr_critic_max": 0.013326882664623157, "train/extr_critic_mean": 0.013295359900478722, "train/extr_critic_min": 0.013259918963322874, "train/extr_critic_std": 7.989219349390491e-06, "train/extr_return_normed_mag": 0.0027973363706157136, "train/extr_return_normed_max": 0.0027972370622467, "train/extr_return_normed_mean": 0.0021898088857320044, "train/extr_return_normed_min": 0.001417341824589182, "train/extr_return_normed_std": 0.0004161258747070327, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.014798914547330153, "train/extr_return_raw_max": 0.01479879938720156, "train/extr_return_raw_mean": 0.014191371719764395, "train/extr_return_raw_min": 0.013418904150545004, "train/extr_return_raw_std": 0.0004161258752052474, "train/extr_reward_mag": 0.00018175573296885672, "train/extr_reward_max": 0.00018173684187925578, "train/extr_reward_mean": 0.00018152272915095076, "train/extr_reward_min": 0.00018103461447960693, "train/extr_reward_std": 8.072852776427931e-08, "train/image_loss_mean": 28.65415012201325, "train/image_loss_std": 0.45145832527367796, "train/model_loss_mean": 29.43245576509361, "train/model_loss_std": 0.5708314850112128, "train/model_opt_grad_norm": 104.69966906767625, "train/model_opt_grad_steps": 910.0, "train/model_opt_loss": 559.384679226276, "train/model_opt_model_opt_grad_overflow": 0.00546448087431694, "train/model_opt_model_opt_grad_scale": 14.141478825136613, "train/policy_entropy_mag": 1.9458004021253743, "train/policy_entropy_max": 1.9458004021253743, "train/policy_entropy_mean": 1.9409550715013932, "train/policy_entropy_min": 1.8833529160973803, "train/policy_entropy_std": 0.003100300534396773, "train/policy_logprob_mag": 2.366635564897881, "train/policy_logprob_max": -1.509327432171243, "train/policy_logprob_mean": -1.9408994958700378, "train/policy_logprob_min": -2.366635564897881, "train/policy_logprob_std": 0.08774468239620735, "train/policy_randomness_mag": 0.9999436602566412, "train/policy_randomness_max": 0.9999436602566412, "train/policy_randomness_mean": 0.9974536534215583, "train/policy_randomness_min": 0.9678520008188779, "train/policy_randomness_std": 0.0015932393894541011, "train/post_ent_mag": 78.0011441590356, "train/post_ent_max": 78.0011441590356, "train/post_ent_mean": 77.90688040477983, "train/post_ent_min": 77.8397498000515, "train/post_ent_std": 0.022636018782508014, "train/prior_ent_mag": 82.53285559148736, "train/prior_ent_max": 82.53285559148736, "train/prior_ent_mean": 82.03204575001868, "train/prior_ent_min": 81.90410818298007, "train/prior_ent_std": 0.09342242098449031, "train/rep_loss_mean": 1.0728466250205952, "train/rep_loss_std": 0.00539406400981494, "train/reward_avg": 0.000196329491417168, "train/reward_loss_mean": 0.1224278326863881, "train/reward_loss_std": 0.015376710681924451, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00018167951719357016, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.12242782798142789, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0001813018340820986, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.9355428616205852, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.007883332669734955, "report/cont_loss_std": 0.2011955827474594, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.442999362945557, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0015928938519209623, "report/cont_pred": 0.998408317565918, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2700203061103821, "report/image_loss_std": 0.1092119812965393, "report/model_loss_mean": 0.8884930610656738, "report/model_loss_std": 0.23340599238872528, "report/post_ent_mag": 63.50185775756836, "report/post_ent_max": 63.50185775756836, "report/post_ent_mean": 63.24566650390625, "report/post_ent_min": 63.2174186706543, "report/post_ent_std": 0.037827882915735245, "report/prior_ent_mag": 70.2557373046875, "report/prior_ent_max": 70.2557373046875, "report/prior_ent_mean": 69.96701049804688, "report/prior_ent_min": 69.90869903564453, "report/prior_ent_std": 0.05835018306970596, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00020942428091075271, "report/reward_loss_mean": 0.010589363053441048, "report/reward_loss_std": 0.016118422150611877, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00019824504852294922, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010589363053441048, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0001982246758416295, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0015928938519209623, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0015928938519209623, "eval/cont_pred": 0.998408317565918, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24912947416305542, "eval/image_loss_std": 0.1005849838256836, "eval/model_loss_mean": 0.852439284324646, "eval/model_loss_std": 0.1005849540233612, "eval/post_ent_mag": 63.49882507324219, "eval/post_ent_max": 63.49882507324219, "eval/post_ent_mean": 63.24542999267578, "eval/post_ent_min": 63.22016906738281, "eval/post_ent_std": 0.03675434738397598, "eval/prior_ent_mag": 70.2557373046875, "eval/prior_ent_max": 70.2557373046875, "eval/prior_ent_mean": 69.9675064086914, "eval/prior_ent_min": 69.90676879882812, "eval/prior_ent_std": 0.05717149376869202, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001716887578368187, "eval/reward_loss_std": 1.0332812507840572e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00019824504852294922, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001716887578368187, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00019822327885776758, "eval/reward_rate": 0.0, "replay/size": 30385.0, "replay/inserts": 29328.0, "replay/samples": 29328.0, "replay/insert_wait_avg": 1.2563231598791111e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.104345672324389e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21568.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1502332632825576e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 969.8001148700714, "timer/env.step_count": 3666.0, "timer/env.step_total": 34.62747645378113, "timer/env.step_frac": 0.03570578712338091, "timer/env.step_avg": 0.009445574591866101, "timer/env.step_min": 0.007754802703857422, "timer/env.step_max": 0.035650014877319336, "timer/replay._sample_count": 29328.0, "timer/replay._sample_total": 14.456817150115967, "timer/replay._sample_frac": 0.014907007050677462, "timer/replay._sample_avg": 0.000492935663874658, "timer/replay._sample_min": 0.0003342628479003906, "timer/replay._sample_max": 0.00981450080871582, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5589.0, "timer/agent.policy_total": 56.92003297805786, "timer/agent.policy_frac": 0.05869254097343936, "timer/agent.policy_avg": 0.010184296471293229, "timer/agent.policy_min": 0.00879669189453125, "timer/agent.policy_max": 0.08623504638671875, "timer/dataset_train_count": 1833.0, "timer/dataset_train_total": 0.19577765464782715, "timer/dataset_train_frac": 0.0002018742333043097, "timer/dataset_train_avg": 0.00010680723112265528, "timer/dataset_train_min": 8.344650268554688e-05, "timer/dataset_train_max": 0.0002803802490234375, "timer/agent.train_count": 1833.0, "timer/agent.train_total": 822.3976058959961, "timer/agent.train_frac": 0.848007329846704, "timer/agent.train_avg": 0.4486620872318582, "timer/agent.train_min": 0.43755292892456055, "timer/agent.train_max": 0.8448565006256104, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47876644134521484, "timer/agent.report_frac": 0.0004936753811473381, "timer/agent.report_avg": 0.23938322067260742, "timer/agent.report_min": 0.23434138298034668, "timer/agent.report_max": 0.24442505836486816, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.950116117074346e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 30.24081219467238}
{"step": 33392, "time": 1286.8473422527313, "episode/length": 640.0, "episode/score": 0.05077579396981946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05077579396981946}
{"step": 35184, "time": 1343.7624101638794, "episode/length": 640.0, "episode/score": 0.12554613182234675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12554613182234675}
{"step": 35896, "time": 1365.997060060501, "episode/length": 640.0, "episode/score": 0.19492446014521647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19492446014521647}
{"step": 35896, "time": 1366.0296955108643, "episode/length": 640.0, "episode/score": 0.10667150838580142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10667150838580142}
{"step": 35896, "time": 1366.039525270462, "episode/length": 640.0, "episode/score": 0.12421157275528572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12421157275528572}
{"step": 35896, "time": 1366.0674641132355, "episode/length": 640.0, "episode/score": 0.0386941401095271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0386941401095271}
{"step": 35896, "time": 1366.0764939785004, "episode/length": 640.0, "episode/score": 0.1313594115094645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1313594115094645}
{"step": 35896, "time": 1366.0959482192993, "episode/length": 640.0, "episode/score": 0.13359202839114914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13359202839114914}
{"step": 38520, "time": 1449.404503107071, "episode/length": 640.0, "episode/score": 0.11172336362920987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11172336362920987}
{"step": 40040, "time": 1507.7486622333527, "eval_episode/length": 531.0, "eval_episode/score": 0.25328123569488525, "eval_episode/reward_rate": 0.0018796992481203006}
{"step": 40040, "time": 1509.1711366176605, "eval_episode/length": 610.0, "eval_episode/score": 0.14218750596046448, "eval_episode/reward_rate": 0.0016366612111292963}
{"step": 40040, "time": 1509.7078766822815, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1509.7173602581024, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1509.725942850113, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1509.7340352535248, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1509.7422547340393, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1509.7504777908325, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40312, "time": 1518.4466891288757, "episode/length": 640.0, "episode/score": 0.12449208793842104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12449208793842104}
{"step": 41024, "time": 1541.6124410629272, "episode/length": 640.0, "episode/score": 0.11375996891524665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11375996891524665}
{"step": 41024, "time": 1541.6222324371338, "episode/length": 640.0, "episode/score": 0.12191569741747799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12191569741747799}
{"step": 41024, "time": 1541.6311268806458, "episode/length": 640.0, "episode/score": 0.07239377866790164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07239377866790164}
{"step": 41024, "time": 1541.6399624347687, "episode/length": 640.0, "episode/score": 0.13028752715160863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13028752715160863}
{"step": 41024, "time": 1541.6491072177887, "episode/length": 640.0, "episode/score": 0.02880169542999056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02880169542999056}
{"step": 41024, "time": 1541.6579267978668, "episode/length": 640.0, "episode/score": 0.08716348103112637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08716348103112637}
{"step": 43648, "time": 1625.5065264701843, "episode/length": 640.0, "episode/score": 0.07381801039286984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07381801039286984}
{"step": 45176, "time": 1673.8657639026642, "episode/length": 607.0, "episode/score": 0.08355663984281136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08355663984281136}
{"step": 46152, "time": 1705.1213641166687, "episode/length": 640.0, "episode/score": 0.10793202185010387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10793202185010387}
{"step": 46152, "time": 1705.1324517726898, "episode/length": 640.0, "episode/score": 0.10764955624802042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10764955624802042}
{"step": 46152, "time": 1705.1417701244354, "episode/length": 640.0, "episode/score": 0.07978036897628726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07978036897628726}
{"step": 46152, "time": 1705.1517343521118, "episode/length": 640.0, "episode/score": 0.10284815042228956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10284815042228956}
{"step": 46152, "time": 1705.1611335277557, "episode/length": 640.0, "episode/score": 0.12762731491284285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12762731491284285}
{"step": 46152, "time": 1705.1710529327393, "episode/length": 640.0, "episode/score": 0.06489560206694023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06489560206694023}
{"step": 48776, "time": 1788.776249408722, "episode/length": 640.0, "episode/score": 0.12630041695356908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12630041695356908}
{"step": 50024, "time": 1840.743889093399, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1840.7531242370605, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1840.7618279457092, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1840.7703144550323, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1840.778291940689, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1840.7861387729645, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1840.7941453456879, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1840.8020639419556, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50304, "time": 1849.9321987628937, "episode/length": 640.0, "episode/score": 0.03814964252092068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03814964252092068}
{"step": 51280, "time": 1881.2772212028503, "episode/length": 640.0, "episode/score": 0.1285061890689576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1285061890689576}
{"step": 51280, "time": 1881.2872664928436, "episode/length": 640.0, "episode/score": 0.1053969667821093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1053969667821093}
{"step": 51280, "time": 1881.2976806163788, "episode/length": 640.0, "episode/score": 0.059527282072934895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059527282072934895}
{"step": 51280, "time": 1881.307389497757, "episode/length": 640.0, "episode/score": 0.06483810849013594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06483810849013594}
{"step": 51280, "time": 1881.3167753219604, "episode/length": 640.0, "episode/score": 0.10594806794435385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10594806794435385}
{"step": 51280, "time": 1881.3266866207123, "episode/length": 640.0, "episode/score": 0.09324674247199027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09324674247199027}
{"step": 53904, "time": 1965.0228073596954, "episode/length": 640.0, "episode/score": 0.17508329646992138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17508329646992138}
{"step": 55432, "time": 2013.1178486347198, "episode/length": 640.0, "episode/score": 0.08111273790771634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08111273790771634}
{"step": 56408, "time": 2044.1162221431732, "episode/length": 640.0, "episode/score": 0.08190941731209023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08190941731209023}
{"step": 56408, "time": 2044.1262052059174, "episode/length": 640.0, "episode/score": 0.11924665334947804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11924665334947804}
{"step": 56408, "time": 2044.1350319385529, "episode/length": 640.0, "episode/score": 0.1426137713106641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1426137713106641}
{"step": 56408, "time": 2044.1441490650177, "episode/length": 640.0, "episode/score": 0.12687688008429632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12687688008429632}
{"step": 56408, "time": 2044.1528940200806, "episode/length": 640.0, "episode/score": 0.1663584551254189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1663584551254189}
{"step": 56408, "time": 2044.161373615265, "episode/length": 640.0, "episode/score": 0.13194969867601003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13194969867601003}
{"step": 59032, "time": 2127.928811788559, "episode/length": 640.0, "episode/score": 0.11729115264193979, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11729115264193979}
{"step": 60008, "time": 2171.003619670868, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2171.0131208896637, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2171.022225379944, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2171.0306730270386, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2171.0390768051147, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2171.04727935791, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2171.0561048984528, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2171.0645155906677, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60560, "time": 2188.8681983947754, "episode/length": 640.0, "episode/score": 0.03969325432711912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03969325432711912}
{"step": 61097, "time": 2206.8842346668243, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9989766115864747, "train/action_min": 0.0, "train/action_std": 1.999825980297472, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0001991271962877979, "train/actor_opt_grad_steps": 2780.0, "train/actor_opt_loss": 2.361374999970572, "train/adv_mag": 0.0007938475461390914, "train/adv_max": 0.0007938475461390914, "train/adv_mean": 0.0004216599120005778, "train/adv_min": -7.494949001483816e-06, "train/adv_std": 0.00019908793999415592, "train/cont_avg": 0.9985532407407407, "train/cont_loss_mean": 0.010967459129576113, "train/cont_loss_std": 0.2218834700811419, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.571941686581962, "train/cont_pos_acc": 0.9999999981077891, "train/cont_pos_loss": 0.0014479120786144108, "train/cont_pred": 0.9985532230801053, "train/cont_rate": 0.9985532407407407, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09308160902567642, "train/extr_critic_critic_opt_grad_steps": 2780.0, "train/extr_critic_critic_opt_loss": 10513.40913835152, "train/extr_critic_mag": 0.03677755058127106, "train/extr_critic_max": 0.03677755058127106, "train/extr_critic_mean": 0.036714530673134266, "train/extr_critic_min": 0.03664200205020804, "train/extr_critic_std": 2.0444080251968624e-05, "train/extr_return_normed_mag": 0.0015252037318768325, "train/extr_return_normed_max": 0.0015252037318768325, "train/extr_return_normed_mean": 0.0012208589133387677, "train/extr_return_normed_min": 0.0008265937939680442, "train/extr_return_normed_std": 0.00019682758060750853, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.037440522224026385, "train/extr_return_raw_max": 0.037440522224026385, "train/extr_return_raw_mean": 0.037136179419658175, "train/extr_return_raw_min": 0.036741912286117596, "train/extr_return_raw_std": 0.00019682758029953147, "train/extr_reward_mag": 0.0001769797511832424, "train/extr_reward_max": 0.0001769797511832424, "train/extr_reward_mean": 0.0001768764011714627, "train/extr_reward_min": 0.00017674070186715908, "train/extr_reward_std": 4.34921210157313e-08, "train/image_loss_mean": 0.28800862649130443, "train/image_loss_std": 0.12535502462002335, "train/model_loss_mean": 0.907935224197529, "train/model_loss_std": 0.2701180074659605, "train/model_opt_grad_norm": 81.14313458639478, "train/model_opt_grad_steps": 2770.0, "train/model_opt_loss": 46.9430659460643, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 51.876653439153436, "train/policy_entropy_mag": 1.9458883862016063, "train/policy_entropy_max": 1.9458883862016063, "train/policy_entropy_mean": 1.9448437343829523, "train/policy_entropy_min": 1.9298270877706942, "train/policy_entropy_std": 0.0007041248923448461, "train/policy_logprob_mag": 2.1796494917894798, "train/policy_logprob_max": -1.7186594450915302, "train/policy_logprob_mean": -1.944862648923561, "train/policy_logprob_min": -2.1796494917894798, "train/policy_logprob_std": 0.0458613275574944, "train/policy_randomness_mag": 0.9999888747457474, "train/policy_randomness_max": 0.9999888747457474, "train/policy_randomness_mean": 0.9994520251713102, "train/policy_randomness_min": 0.9917349995128693, "train/policy_randomness_std": 0.00036184862248350686, "train/post_ent_mag": 53.59169414056041, "train/post_ent_max": 53.59169414056041, "train/post_ent_mean": 53.32881352258107, "train/post_ent_min": 53.3024708783185, "train/post_ent_std": 0.03902376765414836, "train/prior_ent_mag": 62.27517100742885, "train/prior_ent_max": 62.27517100742885, "train/prior_ent_mean": 61.83453177396583, "train/prior_ent_min": 61.77441874509135, "train/prior_ent_std": 0.07797814426677567, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0001768153543471945, "train/reward_loss_mean": 0.00895911859220298, "train/reward_loss_std": 0.015100425429563358, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00017715509606416893, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008959118562637182, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.000177010332687546, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.9418985616593134, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020479995757341385, "report/cont_loss_std": 0.34877365827560425, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.454699516296387, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0015743505209684372, "report/cont_pred": 0.9984266757965088, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2804071605205536, "report/image_loss_std": 0.13202553987503052, "report/model_loss_mean": 0.9105256795883179, "report/model_loss_std": 0.3831368386745453, "report/post_ent_mag": 47.22190856933594, "report/post_ent_max": 47.22190856933594, "report/post_ent_mean": 47.03318786621094, "report/post_ent_min": 47.00852584838867, "report/post_ent_std": 0.0276759322732687, "report/prior_ent_mag": 54.032875061035156, "report/prior_ent_max": 54.032875061035156, "report/prior_ent_mean": 53.479000091552734, "report/prior_ent_min": 53.412986755371094, "report/prior_ent_std": 0.09840244054794312, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00019525221432559192, "report/reward_loss_mean": 0.009638535790145397, "report/reward_loss_std": 0.016215456649661064, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00017452239990234375, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009638536721467972, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00017452239990234375, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.001574350637383759, "eval/cont_loss_std": 1.1641532182693481e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001574350637383759, "eval/cont_pred": 0.9984266757965088, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23995396494865417, "eval/image_loss_std": 0.09733202308416367, "eval/model_loss_mean": 0.842734694480896, "eval/model_loss_std": 0.09733203053474426, "eval/post_ent_mag": 47.21845626831055, "eval/post_ent_max": 47.21845626831055, "eval/post_ent_mean": 47.032833099365234, "eval/post_ent_min": 47.007076263427734, "eval/post_ent_std": 0.024921543896198273, "eval/prior_ent_mag": 54.032875061035156, "eval/prior_ent_max": 54.032875061035156, "eval/prior_ent_mean": 53.47184371948242, "eval/prior_ent_min": 53.41487121582031, "eval/prior_ent_std": 0.09021397680044174, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012063859030604362, "eval/reward_loss_std": 2.3340176369401888e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00017511844635009766, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012063859030604362, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00017452356405556202, "eval/reward_rate": 0.0, "replay/size": 60593.0, "replay/inserts": 30208.0, "replay/samples": 30208.0, "replay/insert_wait_avg": 1.2846174255266029e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.34574311062441e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 36952.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.138392923030764e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4521090984344, "timer/env.step_count": 3776.0, "timer/env.step_total": 35.395814180374146, "timer/env.step_frac": 0.03537981864246493, "timer/env.step_avg": 0.009373891467260103, "timer/env.step_min": 0.007630825042724609, "timer/env.step_max": 0.041933298110961914, "timer/replay._sample_count": 30208.0, "timer/replay._sample_total": 15.214781522750854, "timer/replay._sample_frac": 0.015207905890129792, "timer/replay._sample_avg": 0.0005036672908749621, "timer/replay._sample_min": 0.0003364086151123047, "timer/replay._sample_max": 0.01115870475769043, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5699.0, "timer/agent.policy_total": 58.57920169830322, "timer/agent.policy_frac": 0.05855272947656869, "timer/agent.policy_avg": 0.010278856237638748, "timer/agent.policy_min": 0.00872945785522461, "timer/agent.policy_max": 0.09682393074035645, "timer/dataset_train_count": 1888.0, "timer/dataset_train_total": 0.20301270484924316, "timer/dataset_train_frac": 0.00020292096243586285, "timer/dataset_train_avg": 0.00010752791570404829, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.00037598609924316406, "timer/agent.train_count": 1888.0, "timer/agent.train_total": 849.6174795627594, "timer/agent.train_frac": 0.8492335333556337, "timer/agent.train_avg": 0.450009258242987, "timer/agent.train_min": 0.43796753883361816, "timer/agent.train_max": 0.599632740020752, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4683818817138672, "timer/agent.report_frac": 0.0004681702176988295, "timer/agent.report_avg": 0.2341909408569336, "timer/agent.report_min": 0.22339129447937012, "timer/agent.report_max": 0.24499058723449707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9788854575509782e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 30.19383430867296}
{"step": 61536, "time": 2220.8220195770264, "episode/length": 640.0, "episode/score": 0.09283497552456765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09283497552456765}
{"step": 61536, "time": 2220.8325452804565, "episode/length": 640.0, "episode/score": 0.09812690629701137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09812690629701137}
{"step": 61536, "time": 2220.841377735138, "episode/length": 640.0, "episode/score": 0.1096004792375993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1096004792375993}
{"step": 61536, "time": 2220.8504679203033, "episode/length": 640.0, "episode/score": 0.11498431748697158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11498431748697158}
{"step": 61536, "time": 2220.8598420619965, "episode/length": 640.0, "episode/score": 0.09358508545676614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09358508545676614}
{"step": 61536, "time": 2220.868899345398, "episode/length": 640.0, "episode/score": 0.058363121549803054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058363121549803054}
{"step": 64160, "time": 2303.5944695472717, "episode/length": 640.0, "episode/score": 0.1170389253262556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1170389253262556}
{"step": 65688, "time": 2352.0915088653564, "episode/length": 640.0, "episode/score": 0.11391106704365939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11391106704365939}
{"step": 66664, "time": 2382.793442249298, "episode/length": 640.0, "episode/score": 0.14209272604364287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14209272604364287}
{"step": 66664, "time": 2382.803690433502, "episode/length": 640.0, "episode/score": 0.060594315017112876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060594315017112876}
{"step": 66664, "time": 2382.8125183582306, "episode/length": 640.0, "episode/score": 0.08663438544886048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08663438544886048}
{"step": 66664, "time": 2382.8211917877197, "episode/length": 640.0, "episode/score": 0.15581439309659117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15581439309659117}
{"step": 66664, "time": 2382.8299009799957, "episode/length": 640.0, "episode/score": 0.12662905842682903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12662905842682903}
{"step": 66664, "time": 2382.839444875717, "episode/length": 640.0, "episode/score": 0.04283431797182402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04283431797182402}
{"step": 69288, "time": 2465.5450325012207, "episode/length": 640.0, "episode/score": 0.0779223517228047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0779223517228047}
{"step": 70096, "time": 2499.104111433029, "eval_episode/length": 429.0, "eval_episode/score": 0.39671874046325684, "eval_episode/reward_rate": 0.002325581395348837}
{"step": 70096, "time": 2503.5431418418884, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2503.552463531494, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2503.5611474514008, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2503.5696907043457, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2503.578145503998, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2503.5865280628204, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2503.5954518318176, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70816, "time": 2526.382790327072, "episode/length": 640.0, "episode/score": 0.05046972232088365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05046972232088365}
{"step": 71792, "time": 2558.0645105838776, "episode/length": 640.0, "episode/score": 0.09651320330539193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09651320330539193}
{"step": 71792, "time": 2558.074132204056, "episode/length": 640.0, "episode/score": 0.10596242801540257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10596242801540257}
{"step": 71792, "time": 2558.0827207565308, "episode/length": 640.0, "episode/score": 0.08215328159138835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08215328159138835}
{"step": 71792, "time": 2558.0920910835266, "episode/length": 640.0, "episode/score": 0.0912890476231496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0912890476231496}
{"step": 71792, "time": 2558.1007409095764, "episode/length": 640.0, "episode/score": 0.12163910161854119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12163910161854119}
{"step": 71792, "time": 2558.1097927093506, "episode/length": 640.0, "episode/score": 0.08398329922698622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08398329922698622}
{"step": 74416, "time": 2641.545536994934, "episode/length": 640.0, "episode/score": 0.11202336960741377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11202336960741377}
{"step": 75944, "time": 2690.389628648758, "episode/length": 640.0, "episode/score": 0.07167465141577622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07167465141577622}
{"step": 76920, "time": 2721.1710357666016, "episode/length": 640.0, "episode/score": 0.08991594145840054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08991594145840054}
{"step": 76920, "time": 2721.1805880069733, "episode/length": 640.0, "episode/score": 0.10624561045747782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10624561045747782}
{"step": 76920, "time": 2721.1894404888153, "episode/length": 640.0, "episode/score": 0.1528732149627956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1528732149627956}
{"step": 76920, "time": 2721.1980142593384, "episode/length": 640.0, "episode/score": 0.075498780030955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.075498780030955}
{"step": 76920, "time": 2721.207057237625, "episode/length": 640.0, "episode/score": 0.12872876420871648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12872876420871648}
{"step": 76920, "time": 2721.2154433727264, "episode/length": 640.0, "episode/score": 0.10024640311129929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10024640311129929}
{"step": 79544, "time": 2804.325393676758, "episode/length": 640.0, "episode/score": 0.04193844380822043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04193844380822043}
{"step": 80080, "time": 2832.867862701416, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2832.876953601837, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2832.8853857517242, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2832.8935420513153, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2832.904305458069, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2832.9137194156647, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2832.9224123954773, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2832.930876970291, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 81072, "time": 2864.3067874908447, "episode/length": 640.0, "episode/score": 0.07574581005468417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07574581005468417}
{"step": 82048, "time": 2895.6812376976013, "episode/length": 640.0, "episode/score": 0.07870979792903654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07870979792903654}
{"step": 82048, "time": 2895.6914553642273, "episode/length": 640.0, "episode/score": 0.13550576566879613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13550576566879613}
{"step": 82048, "time": 2895.7003655433655, "episode/length": 640.0, "episode/score": 0.08872218682427047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08872218682427047}
{"step": 82048, "time": 2895.7095007896423, "episode/length": 640.0, "episode/score": 0.1278679416315356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1278679416315356}
{"step": 82048, "time": 2895.7181720733643, "episode/length": 640.0, "episode/score": 0.05343320380765704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05343320380765704}
{"step": 82048, "time": 2895.7268698215485, "episode/length": 640.0, "episode/score": 0.1180693584556991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1180693584556991}
{"step": 84672, "time": 2978.652359724045, "episode/length": 640.0, "episode/score": 0.1043084950219395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1043084950219395}
{"step": 86200, "time": 3027.288814306259, "episode/length": 640.0, "episode/score": 0.09091954832517501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09091954832517501}
{"step": 87176, "time": 3058.510873556137, "episode/length": 640.0, "episode/score": 0.124321980264682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.124321980264682}
{"step": 87176, "time": 3058.521386861801, "episode/length": 640.0, "episode/score": 0.12721345027880204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12721345027880204}
{"step": 87176, "time": 3058.530658006668, "episode/length": 640.0, "episode/score": 0.03946676762920731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03946676762920731}
{"step": 87176, "time": 3058.539766550064, "episode/length": 640.0, "episode/score": 0.12754565295473697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12754565295473697}
{"step": 87176, "time": 3058.5489389896393, "episode/length": 640.0, "episode/score": 0.1123041217273908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1123041217273908}
{"step": 87176, "time": 3058.558389902115, "episode/length": 640.0, "episode/score": 0.1087015747145017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1087015747145017}
{"step": 89800, "time": 3141.967076063156, "episode/length": 640.0, "episode/score": 0.10854249511027092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10854249511027092}
{"step": 90064, "time": 3162.3972516059875, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3162.406065940857, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3162.4143583774567, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3162.422367334366, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3162.429986000061, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3162.4377975463867, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3162.4459183216095, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3162.453379392624, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 91328, "time": 3202.923045873642, "episode/length": 640.0, "episode/score": 0.16283466936010882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16283466936010882}
{"step": 91433, "time": 3206.9263923168182, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9999131298569774, "train/action_min": 0.0, "train/action_std": 1.9996807701373227, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 8.198531028779505e-05, "train/actor_opt_grad_steps": 4670.0, "train/actor_opt_loss": -2.428868699621744, "train/adv_mag": 0.000389964196574751, "train/adv_max": 0.0003887690682575185, "train/adv_mean": 0.0001712769040659142, "train/adv_min": -6.68544539068111e-05, "train/adv_std": 8.959266748331689e-05, "train/cont_avg": 0.9984964037698413, "train/cont_loss_mean": 0.011332167160054226, "train/cont_loss_std": 0.21449727854686243, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.53278595168015, "train/cont_pos_acc": 0.9999999962155781, "train/cont_pos_loss": 0.0014942643872003943, "train/cont_pred": 0.9985069317161721, "train/cont_rate": 0.9984964037698413, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03372063368519462, "train/extr_critic_critic_opt_grad_steps": 4670.0, "train/extr_critic_critic_opt_loss": 11813.098937665343, "train/extr_critic_mag": 0.04713891170642994, "train/extr_critic_max": 0.04713891170642994, "train/extr_critic_mean": 0.04705958825255197, "train/extr_critic_min": 0.04698041317954896, "train/extr_critic_std": 2.3403027461083994e-05, "train/extr_return_normed_mag": 0.0006583891611881356, "train/extr_return_normed_max": 0.0006579580327505788, "train/extr_return_normed_mean": 0.0005149115745468778, "train/extr_return_normed_min": 0.0003261192253342381, "train/extr_return_normed_std": 8.35501362479393e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.047373895351060485, "train/extr_return_raw_max": 0.047373895351060485, "train/extr_return_raw_mean": 0.0472308509840221, "train/extr_return_raw_min": 0.04704205654364414, "train/extr_return_raw_std": 8.35501362142543e-05, "train/extr_reward_mag": 0.00016847615519528667, "train/extr_reward_max": 0.00016847615519528667, "train/extr_reward_mean": 0.00016838780666822222, "train/extr_reward_min": 0.00016832288610872138, "train/extr_reward_std": 3.2364251898676707e-08, "train/image_loss_mean": 0.2735291635075574, "train/image_loss_std": 0.12719370117263187, "train/model_loss_mean": 0.8932946835245404, "train/model_loss_std": 0.26918258230206826, "train/model_opt_grad_norm": 68.0803232445288, "train/model_opt_grad_steps": 4660.0, "train/model_opt_loss": 172.93751433034421, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 193.86574074074073, "train/policy_entropy_mag": 1.9458983568918138, "train/policy_entropy_max": 1.9458983568918138, "train/policy_entropy_mean": 1.9453333294580852, "train/policy_entropy_min": 1.9357538917077282, "train/policy_entropy_std": 0.00040238679841865424, "train/policy_logprob_mag": 2.1287403031001015, "train/policy_logprob_max": -1.7626431190147602, "train/policy_logprob_mean": -1.94536195797895, "train/policy_logprob_min": -2.1287403031001015, "train/policy_logprob_std": 0.03385436071684121, "train/policy_randomness_mag": 0.9999940010605666, "train/policy_randomness_max": 0.9999940010605666, "train/policy_randomness_mean": 0.9997036296223837, "train/policy_randomness_min": 0.9947807722621493, "train/policy_randomness_std": 0.00020678593283124939, "train/post_ent_mag": 44.508230219442375, "train/post_ent_max": 44.508230219442375, "train/post_ent_mean": 44.41848433963836, "train/post_ent_min": 44.36612945637375, "train/post_ent_std": 0.018839903954396803, "train/prior_ent_mag": 49.76550815723561, "train/prior_ent_max": 49.76550815723561, "train/prior_ent_mean": 49.4589356921968, "train/prior_ent_min": 49.15212330490193, "train/prior_ent_std": 0.09372080791564215, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00016824152134605264, "train/reward_loss_mean": 0.00843333256081062, "train/reward_loss_std": 0.014838331127687105, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0001684994924636114, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008433332553419172, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00016839077348806082, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.9423335492610931, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.007799515035003424, "report/cont_loss_std": 0.20656411349773407, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.614622592926025, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0013412336120381951, "report/cont_pred": 0.9986594915390015, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2680974006652832, "report/image_loss_std": 0.13114158809185028, "report/model_loss_mean": 0.884168803691864, "report/model_loss_std": 0.25568726658821106, "report/post_ent_mag": 43.23363494873047, "report/post_ent_max": 43.23363494873047, "report/post_ent_mean": 43.202396392822266, "report/post_ent_min": 43.047142028808594, "report/post_ent_std": 0.03678048402070999, "report/prior_ent_mag": 45.055999755859375, "report/prior_ent_max": 45.055999755859375, "report/prior_ent_mean": 44.9930419921875, "report/prior_ent_min": 44.453826904296875, "report/prior_ent_std": 0.09210336208343506, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00016522522491868585, "report/reward_loss_mean": 0.008271843194961548, "report/reward_loss_std": 0.015378400683403015, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0001569986343383789, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008271844126284122, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00015652866568416357, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0013412695843726397, "eval/cont_loss_std": 1.1156249684063368e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013412695843726397, "eval/cont_pred": 0.9986594915390015, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22973063588142395, "eval/image_loss_std": 0.11287794262170792, "eval/model_loss_mean": 0.8320938348770142, "eval/model_loss_std": 0.11287796497344971, "eval/post_ent_mag": 43.228904724121094, "eval/post_ent_max": 43.228904724121094, "eval/post_ent_mean": 43.20310592651367, "eval/post_ent_min": 43.04109573364258, "eval/post_ent_std": 0.03620322421193123, "eval/prior_ent_mag": 45.04920959472656, "eval/prior_ent_max": 45.04920959472656, "eval/prior_ent_mean": 44.994895935058594, "eval/prior_ent_min": 44.453826904296875, "eval/prior_ent_std": 0.08987013250589371, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010219300165772438, "eval/reward_loss_std": 3.3690582768031163e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0001569986343383789, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010219300165772438, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00015653029549866915, "eval/reward_rate": 0.0, "replay/size": 90929.0, "replay/inserts": 30336.0, "replay/samples": 30336.0, "replay/insert_wait_avg": 1.291866229556281e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.401472734499582e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 52336.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1329686833866176e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0274455547333, "timer/env.step_count": 3792.0, "timer/env.step_total": 34.69855284690857, "timer/env.step_frac": 0.034697600552013506, "timer/env.step_avg": 0.009150462248657324, "timer/env.step_min": 0.007571697235107422, "timer/env.step_max": 0.03537750244140625, "timer/replay._sample_count": 30336.0, "timer/replay._sample_total": 15.306050539016724, "timer/replay._sample_frac": 0.015305630467498001, "timer/replay._sample_avg": 0.0005045507166078825, "timer/replay._sample_min": 0.0003750324249267578, "timer/replay._sample_max": 0.025653839111328125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5715.0, "timer/agent.policy_total": 58.46574282646179, "timer/agent.policy_frac": 0.05846413824575564, "timer/agent.policy_avg": 0.01023022621635377, "timer/agent.policy_min": 0.008909940719604492, "timer/agent.policy_max": 0.08544373512268066, "timer/dataset_train_count": 1896.0, "timer/dataset_train_total": 0.20231366157531738, "timer/dataset_train_frac": 0.0002023081091170356, "timer/dataset_train_avg": 0.00010670551770850073, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0010762214660644531, "timer/agent.train_count": 1896.0, "timer/agent.train_total": 850.4748642444611, "timer/agent.train_frac": 0.850451523130635, "timer/agent.train_avg": 0.4485626921120575, "timer/agent.train_min": 0.4362332820892334, "timer/agent.train_max": 0.9922316074371338, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4648096561431885, "timer/agent.report_frac": 0.00046479689953444244, "timer/agent.report_avg": 0.23240482807159424, "timer/agent.report_min": 0.2226872444152832, "timer/agent.report_max": 0.24212241172790527, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.218562482638314e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 30.33465023483308}
{"step": 92304, "time": 3234.2857370376587, "episode/length": 640.0, "episode/score": 0.1344159968717804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1344159968717804}
{"step": 92304, "time": 3234.2960073947906, "episode/length": 640.0, "episode/score": 0.1271257937805501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1271257937805501}
{"step": 92304, "time": 3234.3060789108276, "episode/length": 640.0, "episode/score": 0.13610120376800694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13610120376800694}
{"step": 92304, "time": 3234.315870285034, "episode/length": 640.0, "episode/score": 0.11363373174255287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11363373174255287}
{"step": 92304, "time": 3234.325223684311, "episode/length": 640.0, "episode/score": 0.12442181348158954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12442181348158954}
{"step": 92304, "time": 3234.334272623062, "episode/length": 640.0, "episode/score": 0.12920901881618363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12920901881618363}
{"step": 94928, "time": 3317.3225376605988, "episode/length": 640.0, "episode/score": 0.16139976154880742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16139976154880742}
{"step": 96456, "time": 3365.427975177765, "episode/length": 640.0, "episode/score": 0.11952012436879045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11952012436879045}
{"step": 97432, "time": 3396.664929628372, "episode/length": 640.0, "episode/score": 0.08305945515657243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08305945515657243}
{"step": 97432, "time": 3396.675558567047, "episode/length": 640.0, "episode/score": 0.0907416238752603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0907416238752603}
{"step": 97432, "time": 3396.684609413147, "episode/length": 640.0, "episode/score": 0.11980334632546885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11980334632546885}
{"step": 97432, "time": 3396.6935358047485, "episode/length": 640.0, "episode/score": 0.10948642414206233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10948642414206233}
{"step": 97432, "time": 3396.702418088913, "episode/length": 640.0, "episode/score": 0.06392737719563968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06392737719563968}
{"step": 97432, "time": 3396.7113704681396, "episode/length": 640.0, "episode/score": 0.09399836370489822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09399836370489822}
{"step": 100048, "time": 3492.572408914566, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3492.5811507701874, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3492.589587688446, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3492.5978598594666, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3492.6058065891266, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3492.61349773407, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3492.621424436569, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3492.6295671463013, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100056, "time": 3492.666679620743, "episode/length": 640.0, "episode/score": 0.07955122696162675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07955122696162675}
{"step": 101584, "time": 3540.7963321208954, "episode/length": 640.0, "episode/score": 0.03803578926299167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03803578926299167}
{"step": 102560, "time": 3571.5255403518677, "episode/length": 640.0, "episode/score": 0.09070083397641326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09070083397641326}
{"step": 102560, "time": 3571.5367443561554, "episode/length": 640.0, "episode/score": 0.09689274549155868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09689274549155868}
{"step": 102560, "time": 3571.5488379001617, "episode/length": 640.0, "episode/score": 0.08835636152421955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08835636152421955}
{"step": 102560, "time": 3571.5629494190216, "episode/length": 640.0, "episode/score": 0.05403718796326018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05403718796326018}
{"step": 102560, "time": 3571.572675228119, "episode/length": 640.0, "episode/score": 0.047782696289445425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047782696289445425}
{"step": 102560, "time": 3571.5841403007507, "episode/length": 640.0, "episode/score": 0.08184163608878237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08184163608878237}
{"step": 105184, "time": 3654.7354238033295, "episode/length": 640.0, "episode/score": 0.04475840488106542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04475840488106542}
{"step": 106712, "time": 3703.3227088451385, "episode/length": 640.0, "episode/score": 0.04429727764539848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04429727764539848}
{"step": 107688, "time": 3734.5951228141785, "episode/length": 640.0, "episode/score": 0.10754437180128207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10754437180128207}
{"step": 107688, "time": 3734.606380224228, "episode/length": 640.0, "episode/score": 0.10254450127109749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10254450127109749}
{"step": 107688, "time": 3734.61599111557, "episode/length": 640.0, "episode/score": 0.1041806155545828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1041806155545828}
{"step": 107688, "time": 3734.62531709671, "episode/length": 640.0, "episode/score": 0.11341148683914071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11341148683914071}
{"step": 107688, "time": 3734.6343433856964, "episode/length": 640.0, "episode/score": 0.06018720829689528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06018720829689528}
{"step": 107688, "time": 3734.6432449817657, "episode/length": 640.0, "episode/score": 0.08799275364617642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08799275364617642}
{"step": 110032, "time": 3814.703261613846, "eval_episode/length": 337.0, "eval_episode/score": 0.5260937213897705, "eval_episode/reward_rate": 0.0029585798816568047}
{"step": 110032, "time": 3819.8830196857452, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3819.8918738365173, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3819.90013051033, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3819.908149242401, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3819.91593003273, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3819.923948764801, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3819.9317989349365, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110312, "time": 3828.592232942581, "episode/length": 640.0, "episode/score": 0.08149725096080829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08149725096080829}
{"step": 111840, "time": 3877.3768174648285, "episode/length": 640.0, "episode/score": 0.06763965649827242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06763965649827242}
{"step": 112816, "time": 3908.095193862915, "episode/length": 640.0, "episode/score": 0.0979196196144585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0979196196144585}
{"step": 112816, "time": 3908.1045401096344, "episode/length": 640.0, "episode/score": 0.09846266617734045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09846266617734045}
{"step": 112816, "time": 3908.113348007202, "episode/length": 640.0, "episode/score": 0.05618407053799501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05618407053799501}
{"step": 112816, "time": 3908.1220152378082, "episode/length": 640.0, "episode/score": 0.1303448523960924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1303448523960924}
{"step": 112816, "time": 3908.1311087608337, "episode/length": 640.0, "episode/score": 0.10927880462304529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10927880462304529}
{"step": 112816, "time": 3908.1396458148956, "episode/length": 640.0, "episode/score": 0.1256869288347957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1256869288347957}
{"step": 115440, "time": 3991.4903588294983, "episode/length": 640.0, "episode/score": 0.07795255058283601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07795255058283601}
{"step": 116968, "time": 4040.026837348938, "episode/length": 640.0, "episode/score": 0.07384029632714828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07384029632714828}
{"step": 117944, "time": 4070.952303171158, "episode/length": 640.0, "episode/score": 0.07301404630115371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07301404630115371}
{"step": 117944, "time": 4070.9619178771973, "episode/length": 640.0, "episode/score": 0.11357730232012386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11357730232012386}
{"step": 117944, "time": 4070.9705278873444, "episode/length": 640.0, "episode/score": 0.06408719045251132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06408719045251132}
{"step": 117944, "time": 4070.978870153427, "episode/length": 640.0, "episode/score": 0.07667627529480114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07667627529480114}
{"step": 117944, "time": 4070.987516641617, "episode/length": 640.0, "episode/score": 0.12112402129707789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12112402129707789}
{"step": 117944, "time": 4070.9960448741913, "episode/length": 640.0, "episode/score": 0.070715019160275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.070715019160275}
{"step": 120016, "time": 4148.4441175460815, "eval_episode/length": 579.0, "eval_episode/score": 0.18578125536441803, "eval_episode/reward_rate": 0.0017241379310344827}
{"step": 120016, "time": 4149.555425167084, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4149.564722061157, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4149.573443651199, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4149.581976890564, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4149.59036231041, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4149.5987384319305, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4149.607094526291, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120360, "time": 4160.461895465851, "episode/length": 423.0, "episode/score": 0.1049744156546808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1049744156546808}
{"step": 120568, "time": 4167.103857755661, "episode/length": 640.0, "episode/score": 0.12916926325206646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12916926325206646}
{"step": 121785, "time": 4206.985310077667, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0003389057360197, "train/action_min": 0.0, "train/action_std": 2.000325751932044, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 3.9964926959088954e-05, "train/actor_opt_grad_steps": 6565.0, "train/actor_opt_loss": -4.37123465036091, "train/adv_mag": 0.00023586471614084746, "train/adv_max": 0.0002243998215386742, "train/adv_mean": 6.97887954273531e-05, "train/adv_min": -9.535894190010272e-05, "train/adv_std": 5.222258852678638e-05, "train/cont_avg": 0.9984529194078947, "train/cont_loss_mean": 0.01156877592438832, "train/cont_loss_std": 0.22728834515901686, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.483928143978119, "train/cont_pos_acc": 0.9999999981177481, "train/cont_pos_loss": 0.0015395346158919366, "train/cont_pred": 0.998461712034125, "train/cont_rate": 0.9984529194078947, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02219801018210618, "train/extr_critic_critic_opt_grad_steps": 6565.0, "train/extr_critic_critic_opt_loss": 12214.790003083881, "train/extr_critic_mag": 0.051253852718754815, "train/extr_critic_max": 0.051253852718754815, "train/extr_critic_mean": 0.05117419511079788, "train/extr_critic_min": 0.051095391574658845, "train/extr_critic_std": 2.3334066702655095e-05, "train/extr_return_normed_mag": 0.0003214806710418902, "train/extr_return_normed_max": 0.000294014772302226, "train/extr_return_normed_mean": 0.0002089699015127017, "train/extr_return_normed_min": 0.00010051793958011426, "train/extr_return_normed_std": 4.336465157458155e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.051329008352599646, "train/extr_return_raw_max": 0.051329008352599646, "train/extr_return_raw_mean": 0.05124396564144837, "train/extr_return_raw_min": 0.05113551151987753, "train/extr_return_raw_std": 4.3364652207001974e-05, "train/extr_reward_mag": 0.00016478613803261205, "train/extr_reward_max": 0.00016478613803261205, "train/extr_reward_mean": 0.00016470371728677204, "train/extr_reward_min": 0.00016460230475977847, "train/extr_reward_std": 3.88642083696442e-08, "train/image_loss_mean": 0.2707013832895379, "train/image_loss_std": 0.12555581429287008, "train/model_loss_mean": 0.8906030924696672, "train/model_loss_std": 0.27432950095910774, "train/model_opt_grad_norm": 57.43249190481085, "train/model_opt_grad_steps": 6555.0, "train/model_opt_loss": 644.4814377634149, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 723.6842105263158, "train/policy_entropy_mag": 1.9459018042213039, "train/policy_entropy_max": 1.9459018042213039, "train/policy_entropy_mean": 1.9454735448485927, "train/policy_entropy_min": 1.9368966359841195, "train/policy_entropy_std": 0.00031708091172683787, "train/policy_logprob_mag": 2.115855026245117, "train/policy_logprob_max": -1.7798246948342575, "train/policy_logprob_mean": -1.9454746635336624, "train/policy_logprob_min": -2.115855026245117, "train/policy_logprob_std": 0.029543476698822096, "train/policy_randomness_mag": 0.9999957702661816, "train/policy_randomness_max": 0.9999957702661816, "train/policy_randomness_mean": 0.9997756835661437, "train/policy_randomness_min": 0.9953680280007814, "train/policy_randomness_std": 0.00016294737985222846, "train/post_ent_mag": 43.56627197265625, "train/post_ent_max": 43.56627197265625, "train/post_ent_mean": 43.51478883843673, "train/post_ent_min": 43.00644212020071, "train/post_ent_std": 0.1027978167133896, "train/prior_ent_mag": 45.13392811825401, "train/prior_ent_max": 45.13392811825401, "train/prior_ent_mean": 45.07707065783049, "train/prior_ent_min": 44.569863188894175, "train/prior_ent_std": 0.09025259621833501, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00016687346299142135, "train/reward_loss_mean": 0.00833291282730275, "train/reward_loss_std": 0.01483805657511479, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0001648651926141036, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008332912800343413, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00016469152484971443, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.9424203485250473, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.007792835123836994, "report/cont_loss_std": 0.2071741670370102, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.634128093719482, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0013154795160517097, "report/cont_pred": 0.9986852407455444, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2643759846687317, "report/image_loss_std": 0.1249389722943306, "report/model_loss_mean": 0.8788976669311523, "report/model_loss_std": 0.24708177149295807, "report/post_ent_mag": 45.298641204833984, "report/post_ent_max": 45.298641204833984, "report/post_ent_mean": 45.22626495361328, "report/post_ent_min": 44.34454345703125, "report/post_ent_std": 0.16737216711044312, "report/prior_ent_mag": 45.214073181152344, "report/prior_ent_max": 45.214073181152344, "report/prior_ent_mean": 45.157928466796875, "report/prior_ent_min": 44.66950225830078, "report/prior_ent_std": 0.08849930763244629, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00013049050176050514, "report/reward_loss_mean": 0.0067288740538060665, "report/reward_loss_std": 0.012383021414279938, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0001556873321533203, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.006728874519467354, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00015544635243713856, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0013154495973140001, "eval/cont_loss_std": 8.358875334124605e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013154495973140001, "eval/cont_pred": 0.9986852407455444, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24353653192520142, "eval/image_loss_std": 0.10890059918165207, "eval/model_loss_mean": 0.8458488583564758, "eval/model_loss_std": 0.10890047252178192, "eval/post_ent_mag": 45.29651641845703, "eval/post_ent_max": 45.29651641845703, "eval/post_ent_mean": 45.2298583984375, "eval/post_ent_min": 44.342159271240234, "eval/post_ent_std": 0.16325964033603668, "eval/prior_ent_mag": 45.213470458984375, "eval/prior_ent_max": 45.213470458984375, "eval/prior_ent_mean": 45.15948486328125, "eval/prior_ent_min": 44.66950225830078, "eval/prior_ent_std": 0.08503936231136322, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0009968066588044167, "eval/reward_loss_std": 3.1674669571657432e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0001556873321533203, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009968066588044167, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000155423185788095, "eval/reward_rate": 0.0, "replay/size": 121281.0, "replay/inserts": 30352.0, "replay/samples": 30352.0, "replay/insert_wait_avg": 1.2881845691421502e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.428228737243427e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 67720.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1473661651849376e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0377924442291, "timer/env.step_count": 3794.0, "timer/env.step_total": 34.67471766471863, "timer/env.step_frac": 0.03467340727190807, "timer/env.step_avg": 0.009139356263763476, "timer/env.step_min": 0.007544279098510742, "timer/env.step_max": 0.03514814376831055, "timer/replay._sample_count": 30352.0, "timer/replay._sample_total": 15.331338167190552, "timer/replay._sample_frac": 0.015330758780344355, "timer/replay._sample_avg": 0.0005051178890086502, "timer/replay._sample_min": 0.00032782554626464844, "timer/replay._sample_max": 0.03617572784423828, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5717.0, "timer/agent.policy_total": 58.0464084148407, "timer/agent.policy_frac": 0.05804421478209072, "timer/agent.policy_avg": 0.010153298655735648, "timer/agent.policy_min": 0.008770465850830078, "timer/agent.policy_max": 0.08575248718261719, "timer/dataset_train_count": 1897.0, "timer/dataset_train_total": 0.20600175857543945, "timer/dataset_train_frac": 0.00020599397355968216, "timer/dataset_train_avg": 0.00010859344152632549, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.00042128562927246094, "timer/agent.train_count": 1897.0, "timer/agent.train_total": 850.9728827476501, "timer/agent.train_frac": 0.8509407236178105, "timer/agent.train_avg": 0.4485887626503164, "timer/agent.train_min": 0.4347798824310303, "timer/agent.train_max": 0.5999743938446045, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4753692150115967, "timer/agent.report_frac": 0.0004753512503259795, "timer/agent.report_avg": 0.23768460750579834, "timer/agent.report_min": 0.22961974143981934, "timer/agent.report_max": 0.24574947357177734, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027801526569514e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 30.35032321190915}
{"step": 123072, "time": 4249.114261865616, "episode/length": 640.0, "episode/score": 0.056628788001120256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056628788001120256}
{"step": 123072, "time": 4249.123711824417, "episode/length": 640.0, "episode/score": 0.07662794546703822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07662794546703822}
{"step": 123072, "time": 4249.132434606552, "episode/length": 640.0, "episode/score": 0.09621832774183758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09621832774183758}
{"step": 123072, "time": 4249.141158103943, "episode/length": 640.0, "episode/score": 0.09959777237250478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09959777237250478}
{"step": 123072, "time": 4249.150094509125, "episode/length": 640.0, "episode/score": 0.11896585546574556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11896585546574556}
{"step": 123072, "time": 4249.158407926559, "episode/length": 640.0, "episode/score": 0.07320458785746098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07320458785746098}
{"step": 125488, "time": 4325.113890647888, "episode/length": 640.0, "episode/score": 0.15326510628719348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15326510628719348}
{"step": 125696, "time": 4331.6572115421295, "episode/length": 640.0, "episode/score": 0.11764374251983156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11764374251983156}
{"step": 128200, "time": 4410.344779253006, "episode/length": 640.0, "episode/score": 0.034970846762774954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034970846762774954}
{"step": 128200, "time": 4410.355011940002, "episode/length": 640.0, "episode/score": 0.1358970137901423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1358970137901423}
{"step": 128200, "time": 4410.363888025284, "episode/length": 640.0, "episode/score": 0.03841003961883871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03841003961883871}
{"step": 128200, "time": 4410.372569561005, "episode/length": 640.0, "episode/score": 0.10809394482203061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10809394482203061}
{"step": 128200, "time": 4410.381274938583, "episode/length": 640.0, "episode/score": 0.10365531481991752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10365531481991752}
{"step": 128200, "time": 4410.3897931575775, "episode/length": 640.0, "episode/score": 0.06397284280301108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06397284280301108}
{"step": 130000, "time": 4478.50365281105, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4478.514575481415, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4478.52286696434, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4478.530823945999, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4478.538906574249, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4478.5467965602875, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4478.554899692535, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4478.562716245651, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130616, "time": 4497.66255736351, "episode/length": 640.0, "episode/score": 0.15834207878387474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15834207878387474}
{"step": 130824, "time": 4504.180075645447, "episode/length": 640.0, "episode/score": 0.07851479841585274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07851479841585274}
{"step": 133328, "time": 4584.802546262741, "episode/length": 640.0, "episode/score": 0.04962498245623692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04962498245623692}
{"step": 133328, "time": 4584.813914775848, "episode/length": 640.0, "episode/score": 0.06906567310502965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06906567310502965}
{"step": 133328, "time": 4584.82439494133, "episode/length": 640.0, "episode/score": 0.07870821322499921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07870821322499921}
{"step": 133328, "time": 4584.833265542984, "episode/length": 640.0, "episode/score": 0.02812659997526623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02812659997526623}
{"step": 133328, "time": 4584.844106674194, "episode/length": 640.0, "episode/score": 0.03837155436187345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03837155436187345}
{"step": 133328, "time": 4584.852875709534, "episode/length": 640.0, "episode/score": 0.0565557746005112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0565557746005112}
{"step": 135744, "time": 4661.459453582764, "episode/length": 640.0, "episode/score": 0.06255464994902127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06255464994902127}
{"step": 135952, "time": 4668.212625026703, "episode/length": 640.0, "episode/score": 0.03874219371920162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03874219371920162}
{"step": 137968, "time": 4731.73833823204, "episode/length": 579.0, "episode/score": 0.14043984174770685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14043984174770685}
{"step": 138456, "time": 4746.893445491791, "episode/length": 640.0, "episode/score": 0.08479035342361385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08479035342361385}
{"step": 138456, "time": 4746.902693033218, "episode/length": 640.0, "episode/score": 0.15211972576145172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15211972576145172}
{"step": 138456, "time": 4746.9113557338715, "episode/length": 640.0, "episode/score": 0.1260167418751621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1260167418751621}
{"step": 138456, "time": 4746.9197652339935, "episode/length": 640.0, "episode/score": 0.16092147508186372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16092147508186372}
{"step": 138456, "time": 4746.928284168243, "episode/length": 640.0, "episode/score": 0.14707890669194512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14707890669194512}
{"step": 140088, "time": 4810.8680210113525, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4810.877065896988, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4810.885764598846, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4810.893933773041, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4810.902239322662, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4810.910309791565, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4810.918398618698, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4810.926604509354, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140872, "time": 4835.689063072205, "episode/length": 640.0, "episode/score": 0.14276839941936714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14276839941936714}
{"step": 141080, "time": 4842.24476146698, "episode/length": 640.0, "episode/score": 0.1381989852283425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1381989852283425}
{"step": 143096, "time": 4905.809002876282, "episode/length": 640.0, "episode/score": 0.14951269260967592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14951269260967592}
{"step": 143584, "time": 4921.585138559341, "episode/length": 640.0, "episode/score": 0.11374201931829475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11374201931829475}
{"step": 143584, "time": 4921.594486713409, "episode/length": 640.0, "episode/score": 0.10366794742239449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10366794742239449}
{"step": 143584, "time": 4921.60382938385, "episode/length": 640.0, "episode/score": 0.1115055662187956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1115055662187956}
{"step": 143584, "time": 4921.612928390503, "episode/length": 640.0, "episode/score": 0.07924717820682758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07924717820682758}
{"step": 143584, "time": 4921.621928691864, "episode/length": 640.0, "episode/score": 0.10699772596393586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10699772596393586}
{"step": 146000, "time": 4998.072739839554, "episode/length": 640.0, "episode/score": 0.09710447257791088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09710447257791088}
{"step": 146208, "time": 5004.61484003067, "episode/length": 640.0, "episode/score": 0.10334364400461027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10334364400461027}
{"step": 148224, "time": 5068.560576677322, "episode/length": 640.0, "episode/score": 0.06251354733623771, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06251354733623771}
{"step": 148712, "time": 5083.6525621414185, "episode/length": 640.0, "episode/score": 0.1362335948282123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1362335948282123}
{"step": 148712, "time": 5083.66179060936, "episode/length": 640.0, "episode/score": 0.10773106687847189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10773106687847189}
{"step": 148712, "time": 5083.672029495239, "episode/length": 640.0, "episode/score": 0.11194841106492959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11194841106492959}
{"step": 148712, "time": 5083.683613061905, "episode/length": 640.0, "episode/score": 0.07259814827801847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07259814827801847}
{"step": 148712, "time": 5083.695552587509, "episode/length": 640.0, "episode/score": 0.10719155065615382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10719155065615382}
{"step": 150072, "time": 5138.109188556671, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5138.118261098862, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5138.126662492752, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5138.134781122208, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5138.142375946045, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5138.15008354187, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5138.157924413681, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5138.1656839847565, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 151128, "time": 5171.348520040512, "episode/length": 640.0, "episode/score": 0.10151822498971796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10151822498971796}
{"step": 151336, "time": 5177.985440969467, "episode/length": 640.0, "episode/score": 0.11689385647906647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11689385647906647}
{"step": 152233, "time": 5207.258245944977, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.99814453125, "train/action_min": 0.0, "train/action_std": 1.9995213703105323, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.1348225462762024e-05, "train/actor_opt_grad_steps": 8465.0, "train/actor_opt_loss": -5.370707581545178, "train/adv_mag": 0.00021741445127286408, "train/adv_max": 0.00018891284340306333, "train/adv_mean": 1.7534169915889883e-05, "train/adv_min": -0.00014021367226776325, "train/adv_std": 4.722120640843442e-05, "train/cont_avg": 0.9986173930921053, "train/cont_loss_mean": 0.010502526672606014, "train/cont_loss_std": 0.20524841074289046, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.4962810882150315, "train/cont_pos_acc": 0.9999999981177481, "train/cont_pos_loss": 0.0015266642544271521, "train/cont_pred": 0.9984745543254049, "train/cont_rate": 0.9986173930921053, "train/dyn_loss_mean": 1.0087126311502959, "train/dyn_loss_std": 0.000386267956223731, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.022055809268433795, "train/extr_critic_critic_opt_grad_steps": 8465.0, "train/extr_critic_critic_opt_loss": 12326.40603412829, "train/extr_critic_mag": 0.05251058653781288, "train/extr_critic_max": 0.05251058653781288, "train/extr_critic_mean": 0.05242267633347135, "train/extr_critic_min": 0.05232607565428081, "train/extr_critic_std": 2.923160890611299e-05, "train/extr_return_normed_mag": 0.00023252313074312712, "train/extr_return_normed_max": 0.00016696313886266007, "train/extr_return_normed_mean": 7.77101126834174e-05, "train/extr_return_normed_min": -8.44540956773256e-06, "train/extr_return_normed_std": 3.458119031195469e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.052529442173085715, "train/extr_return_raw_max": 0.052529442173085715, "train/extr_return_raw_mean": 0.052440191883789865, "train/extr_return_raw_min": 0.05235403362465532, "train/extr_return_raw_std": 3.458119074351591e-05, "train/extr_reward_mag": 0.00016026747854132401, "train/extr_reward_max": 0.00016026747854132401, "train/extr_reward_mean": 0.00016016934946252916, "train/extr_reward_min": 0.00016008113559923674, "train/extr_reward_std": 4.75677509796584e-08, "train/image_loss_mean": 0.26598053692202817, "train/image_loss_std": 0.12484729544896829, "train/model_loss_mean": 0.8897441942440836, "train/model_loss_std": 0.2593973689565533, "train/model_opt_grad_norm": 50.32941373523913, "train/model_opt_grad_steps": 8454.815789473685, "train/model_opt_loss": 1990.9226703844572, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2236.842105263158, "train/policy_entropy_mag": 1.9458922335976048, "train/policy_entropy_max": 1.9458922335976048, "train/policy_entropy_mean": 1.9450957599439118, "train/policy_entropy_min": 1.9307137727737427, "train/policy_entropy_std": 0.0005700439773806322, "train/policy_logprob_mag": 2.1791333675384523, "train/policy_logprob_max": -1.7307923549099973, "train/policy_logprob_mean": -1.9451268578830518, "train/policy_logprob_min": -2.1791333675384523, "train/policy_logprob_std": 0.03938247291861396, "train/policy_randomness_mag": 0.9999908525692789, "train/policy_randomness_max": 0.9999908525692789, "train/policy_randomness_mean": 0.9995815446502284, "train/policy_randomness_min": 0.9921906659477635, "train/policy_randomness_std": 0.00029294467799206213, "train/post_ent_mag": 50.59189483241031, "train/post_ent_max": 50.59189483241031, "train/post_ent_mean": 50.48157276354338, "train/post_ent_min": 49.96692382410953, "train/post_ent_std": 0.10669847754271407, "train/prior_ent_mag": 50.79728439732602, "train/prior_ent_max": 50.79728439732602, "train/prior_ent_mean": 50.755729454442076, "train/prior_ent_min": 50.43703528956363, "train/prior_ent_std": 0.05971811868887591, "train/rep_loss_mean": 1.0087126311502959, "train/rep_loss_std": 0.000386267956223731, "train/reward_avg": 0.00016026938886314288, "train/reward_loss_mean": 0.00803352836274395, "train/reward_loss_std": 0.014632788285809127, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00016031578967445775, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008033528377449042, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00016018698347340288, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.9421297560135524, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.0012167815584689379, "report/cont_loss_std": 0.0, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0012167815584689379, "report/cont_pred": 0.9987840056419373, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25840461254119873, "report/image_loss_std": 0.14184148609638214, "report/model_loss_mean": 0.8679207563400269, "report/model_loss_std": 0.14741390943527222, "report/post_ent_mag": 51.0830078125, "report/post_ent_max": 51.0830078125, "report/post_ent_mean": 50.96968078613281, "report/post_ent_min": 50.959571838378906, "report/post_ent_std": 0.017351197078824043, "report/prior_ent_mag": 53.075340270996094, "report/prior_ent_max": 53.075340270996094, "report/prior_ent_mean": 53.05146789550781, "report/prior_ent_min": 52.886085510253906, "report/prior_ent_std": 0.031729936599731445, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00016644607239868492, "report/reward_loss_mean": 0.008299333043396473, "report/reward_loss_std": 0.014962497167289257, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0001690387725830078, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008299333974719048, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00016852014232426882, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0012167815584689379, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0012167815584689379, "eval/cont_pred": 0.9987840056419373, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19858691096305847, "eval/image_loss_std": 0.10792366415262222, "eval/model_loss_mean": 0.8008773326873779, "eval/model_loss_std": 0.1079237163066864, "eval/post_ent_mag": 51.08363723754883, "eval/post_ent_max": 51.08363723754883, "eval/post_ent_mean": 50.96969223022461, "eval/post_ent_min": 50.96011734008789, "eval/post_ent_std": 0.017443202435970306, "eval/prior_ent_mag": 53.075740814208984, "eval/prior_ent_max": 53.075740814208984, "eval/prior_ent_mean": 53.05157470703125, "eval/prior_ent_min": 52.886085510253906, "eval/prior_ent_std": 0.03150210529565811, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010736510157585144, "eval/reward_loss_std": 3.736709459190024e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0001690387725830078, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010736510157585144, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00016851502005010843, "eval/reward_rate": 0.0, "replay/size": 151729.0, "replay/inserts": 30448.0, "replay/samples": 30448.0, "replay/insert_wait_avg": 1.2754313393260577e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.486614563060446e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83104.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1205549235152999e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2594265937805, "timer/env.step_count": 3806.0, "timer/env.step_total": 34.5029661655426, "timer/env.step_frac": 0.03449401750007675, "timer/env.step_avg": 0.009065414126521966, "timer/env.step_min": 0.007537841796875, "timer/env.step_max": 0.035645484924316406, "timer/replay._sample_count": 30448.0, "timer/replay._sample_total": 15.465716123580933, "timer/replay._sample_frac": 0.015461704946132719, "timer/replay._sample_avg": 0.000507938653559542, "timer/replay._sample_min": 0.00038123130798339844, "timer/replay._sample_max": 0.011076211929321289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5729.0, "timer/agent.policy_total": 57.56776142120361, "timer/agent.policy_frac": 0.05755283068637622, "timer/agent.policy_avg": 0.010048483403945473, "timer/agent.policy_min": 0.008404254913330078, "timer/agent.policy_max": 0.08610296249389648, "timer/dataset_train_count": 1903.0, "timer/dataset_train_total": 0.20461297035217285, "timer/dataset_train_frac": 0.00020455990207355384, "timer/dataset_train_avg": 0.00010752126660650176, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0006506443023681641, "timer/agent.train_count": 1903.0, "timer/agent.train_total": 852.1437060832977, "timer/agent.train_frac": 0.8519226946804525, "timer/agent.train_avg": 0.44778965112101826, "timer/agent.train_min": 0.4372076988220215, "timer/agent.train_max": 1.1456019878387451, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47115111351013184, "timer/agent.report_frac": 0.00047102891608286036, "timer/agent.report_avg": 0.23557555675506592, "timer/agent.report_min": 0.2286527156829834, "timer/agent.report_max": 0.24249839782714844, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.384665750935337e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 30.43955787321673}
{"step": 153352, "time": 5242.405414104462, "episode/length": 640.0, "episode/score": 0.127569162137263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.127569162137263}
{"step": 153840, "time": 5257.91318821907, "episode/length": 640.0, "episode/score": 0.09363242023766816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09363242023766816}
{"step": 153840, "time": 5257.920110940933, "episode/length": 640.0, "episode/score": 0.12530980124847702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12530980124847702}
{"step": 153840, "time": 5257.9291224479675, "episode/length": 640.0, "episode/score": 0.14338903340819797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14338903340819797}
{"step": 153840, "time": 5257.938316345215, "episode/length": 640.0, "episode/score": 0.1521095114455875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1521095114455875}
{"step": 153840, "time": 5257.9465317726135, "episode/length": 640.0, "episode/score": 0.14108414950669612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14108414950669612}
{"step": 156256, "time": 5334.852696418762, "episode/length": 640.0, "episode/score": 0.09143630032127703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09143630032127703}
{"step": 156464, "time": 5341.386407375336, "episode/length": 640.0, "episode/score": 0.09866080940378197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09866080940378197}
{"step": 158480, "time": 5405.737533569336, "episode/length": 640.0, "episode/score": 0.08417722980340159, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08417722980340159}
{"step": 158968, "time": 5420.909233570099, "episode/length": 640.0, "episode/score": 0.11016783518022066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11016783518022066}
{"step": 158968, "time": 5420.918662786484, "episode/length": 640.0, "episode/score": 0.05744957204046841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05744957204046841}
{"step": 158968, "time": 5420.927420139313, "episode/length": 640.0, "episode/score": 0.09541522350150444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09541522350150444}
{"step": 158968, "time": 5420.936022520065, "episode/length": 640.0, "episode/score": 0.11032839217148194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11032839217148194}
{"step": 158968, "time": 5420.944290161133, "episode/length": 640.0, "episode/score": 0.1486191979268483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1486191979268483}
{"step": 160056, "time": 5464.316723823547, "eval_episode/length": 502.0, "eval_episode/score": 0.2940624952316284, "eval_episode/reward_rate": 0.0019880715705765406}
{"step": 160056, "time": 5466.7653641700745, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5466.776835203171, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5466.785218477249, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5466.79353427887, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5466.801701545715, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5466.809710741043, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5466.817664861679, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 161384, "time": 5508.652495622635, "episode/length": 640.0, "episode/score": 0.10144312681114798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10144312681114798}
{"step": 161592, "time": 5515.22225356102, "episode/length": 640.0, "episode/score": 0.12161281655170342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12161281655170342}
{"step": 163608, "time": 5578.860139131546, "episode/length": 640.0, "episode/score": 0.11058229888237747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11058229888237747}
{"step": 164096, "time": 5594.952814340591, "episode/length": 640.0, "episode/score": 0.12124482315303453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12124482315303453}
{"step": 164096, "time": 5594.962294578552, "episode/length": 640.0, "episode/score": 0.12315685578963098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12315685578963098}
{"step": 164096, "time": 5594.970721006393, "episode/length": 640.0, "episode/score": 0.05955932035129763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05955932035129763}
{"step": 164096, "time": 5594.979872465134, "episode/length": 640.0, "episode/score": 0.12430186702954416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12430186702954416}
{"step": 164096, "time": 5594.988336324692, "episode/length": 640.0, "episode/score": 0.07249914596960139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07249914596960139}
{"step": 166512, "time": 5671.72638964653, "episode/length": 640.0, "episode/score": 0.12924052499522531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12924052499522531}
{"step": 166720, "time": 5678.254168987274, "episode/length": 640.0, "episode/score": 0.06435256634378561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06435256634378561}
{"step": 168736, "time": 5741.656080245972, "episode/length": 640.0, "episode/score": 0.10282986225419677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10282986225419677}
{"step": 169224, "time": 5756.982689857483, "episode/length": 640.0, "episode/score": 0.09998617618234107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09998617618234107}
{"step": 169224, "time": 5756.992196798325, "episode/length": 640.0, "episode/score": 0.1299909731941824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1299909731941824}
{"step": 169224, "time": 5757.001042366028, "episode/length": 640.0, "episode/score": 0.11688776375130772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11688776375130772}
{"step": 169224, "time": 5757.010282754898, "episode/length": 640.0, "episode/score": 0.1463003754164447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1463003754164447}
{"step": 169224, "time": 5757.018569469452, "episode/length": 640.0, "episode/score": 0.12388426608818293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12388426608818293}
{"step": 170040, "time": 5794.952978849411, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5794.962037086487, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5794.970555305481, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5794.978761672974, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5794.987551450729, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5794.995596408844, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5795.003664255142, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5795.011667013168, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 171640, "time": 5845.922778129578, "episode/length": 640.0, "episode/score": 0.11571162089686027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11571162089686027}
{"step": 171848, "time": 5852.454967737198, "episode/length": 640.0, "episode/score": 0.17364403338886802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17364403338886802}
{"step": 173016, "time": 5889.770325660706, "episode/length": 473.0, "episode/score": 0.09048273963315978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09048273963315978}
{"step": 173864, "time": 5916.487871646881, "episode/length": 640.0, "episode/score": 0.1517894103309203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1517894103309203}
{"step": 174352, "time": 5932.161502599716, "episode/length": 640.0, "episode/score": 0.11263560502041514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11263560502041514}
{"step": 174352, "time": 5932.172152519226, "episode/length": 640.0, "episode/score": 0.16295984409040898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16295984409040898}
{"step": 174352, "time": 5932.183972597122, "episode/length": 640.0, "episode/score": 0.12837957736103078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12837957736103078}
{"step": 174352, "time": 5932.197657108307, "episode/length": 640.0, "episode/score": 0.1233364909833341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1233364909833341}
{"step": 176768, "time": 6008.56524014473, "episode/length": 640.0, "episode/score": 0.12273669389765018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12273669389765018}
{"step": 176976, "time": 6015.068090438843, "episode/length": 640.0, "episode/score": 0.1268037364887391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1268037364887391}
{"step": 178144, "time": 6052.207786560059, "episode/length": 640.0, "episode/score": 0.12706690349341443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12706690349341443}
{"step": 178992, "time": 6079.097621917725, "episode/length": 640.0, "episode/score": 0.08621152157016354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08621152157016354}
{"step": 179480, "time": 6094.242533683777, "episode/length": 640.0, "episode/score": 0.15189958667679093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15189958667679093}
{"step": 179480, "time": 6094.251722097397, "episode/length": 640.0, "episode/score": 0.12307588532701175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12307588532701175}
{"step": 179480, "time": 6094.2600955963135, "episode/length": 640.0, "episode/score": 0.07793946684952857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07793946684952857}
{"step": 179480, "time": 6094.269461631775, "episode/length": 640.0, "episode/score": 0.125552061477066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.125552061477066}
{"step": 180024, "time": 6124.293561935425, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6124.302317142487, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6124.310269832611, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6124.318020820618, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6124.325592756271, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6124.333076238632, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6124.3405418396, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6124.3483674526215, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 181896, "time": 6183.389487743378, "episode/length": 640.0, "episode/score": 0.08048444380190745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08048444380190745}
{"step": 182104, "time": 6189.92033457756, "episode/length": 640.0, "episode/score": 0.08805715796890468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08805715796890468}
{"step": 182633, "time": 6207.615303039551, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9976784153988487, "train/action_min": 0.0, "train/action_std": 2.0006658472512897, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 3.6617887091875006e-05, "train/actor_opt_grad_steps": 10365.0, "train/actor_opt_loss": -5.236851041567953, "train/adv_mag": 0.00027090977681310554, "train/adv_max": 0.00023755346866030443, "train/adv_mean": 2.445968667957818e-05, "train/adv_min": -0.00019401319717106066, "train/adv_std": 6.418684100409385e-05, "train/cont_avg": 0.9983295641447368, "train/cont_loss_mean": 0.01240956663325625, "train/cont_loss_std": 0.23669170486808963, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.494120443829838, "train/cont_pos_acc": 0.9999999971766221, "train/cont_pos_loss": 0.0015463926504660202, "train/cont_pred": 0.9984548302073227, "train/cont_rate": 0.9983295641447368, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.019148523300445003, "train/extr_critic_critic_opt_grad_steps": 10365.0, "train/extr_critic_critic_opt_loss": 12370.083100328948, "train/extr_critic_mag": 0.05310452360855906, "train/extr_critic_max": 0.05310452360855906, "train/extr_critic_mean": 0.05298126183058086, "train/extr_critic_min": 0.05286552341360795, "train/extr_critic_std": 4.140581517468059e-05, "train/extr_return_normed_mag": 0.00028191491177207545, "train/extr_return_normed_max": 0.00021657528061615793, "train/extr_return_normed_mean": 0.00010241720578152892, "train/extr_return_normed_min": -1.6037296307714363e-05, "train/extr_return_normed_std": 4.587074317896622e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.05311989782280044, "train/extr_return_raw_max": 0.05311989782280044, "train/extr_return_raw_mean": 0.053005742438529665, "train/extr_return_raw_min": 0.05288728524587656, "train/extr_return_raw_std": 4.5870743461388264e-05, "train/extr_reward_mag": 0.00016304066306666325, "train/extr_reward_max": 0.00016304066306666325, "train/extr_reward_mean": 0.00016294255550938511, "train/extr_reward_min": 0.0001628474185341283, "train/extr_reward_std": 4.9166631645535195e-08, "train/image_loss_mean": 0.2654721476529774, "train/image_loss_std": 0.12551531913249117, "train/model_loss_mean": 0.8861115333281065, "train/model_loss_std": 0.2823120911262537, "train/model_opt_grad_norm": 45.863829688420374, "train/model_opt_grad_steps": 10353.357894736842, "train/model_opt_loss": 2378.1706440172698, "train/model_opt_model_opt_grad_overflow": 0.005263157894736842, "train/model_opt_model_opt_grad_scale": 2684.2105263157896, "train/policy_entropy_mag": 1.9458936314833792, "train/policy_entropy_max": 1.9458936314833792, "train/policy_entropy_mean": 1.9451411240979244, "train/policy_entropy_min": 1.9321965757169222, "train/policy_entropy_std": 0.0005352464611764605, "train/policy_logprob_mag": 2.1808646239732443, "train/policy_logprob_max": -1.740373933315277, "train/policy_logprob_mean": -1.945137668283362, "train/policy_logprob_min": -2.1808646239732443, "train/policy_logprob_std": 0.03921324314647599, "train/policy_randomness_mag": 0.9999915690798509, "train/policy_randomness_max": 0.9999915690798509, "train/policy_randomness_mean": 0.9996048557130914, "train/policy_randomness_min": 0.9929526746273041, "train/policy_randomness_std": 0.0002750622843067456, "train/post_ent_mag": 51.43042562384355, "train/post_ent_max": 51.43042562384355, "train/post_ent_mean": 51.31009774459036, "train/post_ent_min": 51.29764992563348, "train/post_ent_std": 0.0190085648313949, "train/prior_ent_mag": 53.0511006003932, "train/prior_ent_max": 53.0511006003932, "train/prior_ent_mean": 53.0262496145148, "train/prior_ent_min": 52.86549178675601, "train/prior_ent_std": 0.03060695688779417, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00016480859646291816, "train/reward_loss_mean": 0.008229799230435961, "train/reward_loss_std": 0.014833682030439378, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00016297666650069386, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008229799240239357, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00016288562420461523, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.9421003957589467, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.007885744795203209, "report/cont_loss_std": 0.20107361674308777, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.439099311828613, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0015991234686225653, "report/cont_pred": 0.9984023571014404, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2633167505264282, "report/image_loss_std": 0.1290433555841446, "report/model_loss_mean": 0.8800210952758789, "report/model_loss_std": 0.24385061860084534, "report/post_ent_mag": 52.09258270263672, "report/post_ent_max": 52.09258270263672, "report/post_ent_mean": 51.968849182128906, "report/post_ent_min": 51.95339584350586, "report/post_ent_std": 0.019440285861492157, "report/prior_ent_mag": 53.0546875, "report/prior_ent_max": 53.0546875, "report/prior_ent_mean": 53.02622985839844, "report/prior_ent_min": 52.85113525390625, "report/prior_ent_std": 0.030930884182453156, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00017845476395450532, "report/reward_loss_mean": 0.008818551898002625, "report/reward_loss_std": 0.01574959233403206, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0001703500747680664, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008818551898002625, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0001691809156909585, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.001599123585037887, "eval/cont_loss_std": 1.1641532182693481e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001599123585037887, "eval/cont_pred": 0.9984023571014404, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22775888442993164, "eval/image_loss_std": 0.11936049908399582, "eval/model_loss_mean": 0.8304349184036255, "eval/model_loss_std": 0.11936047673225403, "eval/post_ent_mag": 52.09081268310547, "eval/post_ent_max": 52.09081268310547, "eval/post_ent_mean": 51.96812438964844, "eval/post_ent_min": 51.954261779785156, "eval/post_ent_std": 0.01946769282221794, "eval/prior_ent_mag": 53.05120849609375, "eval/prior_ent_max": 53.05120849609375, "eval/prior_ent_mean": 53.02545166015625, "eval/prior_ent_min": 52.85113525390625, "eval/prior_ent_std": 0.030660701915621758, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010768929496407509, "eval/reward_loss_std": 2.9218956569820875e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0001703500747680664, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010768929496407509, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000169214210473001, "eval/reward_rate": 0.0, "replay/size": 182129.0, "replay/inserts": 30400.0, "replay/samples": 30400.0, "replay/insert_wait_avg": 1.2809900861037405e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.566755997507196e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 98488.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1336505877990247e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3382003307343, "timer/env.step_count": 3800.0, "timer/env.step_total": 34.498005628585815, "timer/env.step_frac": 0.034486342336201896, "timer/env.step_avg": 0.009078422533838372, "timer/env.step_min": 0.0074307918548583984, "timer/env.step_max": 0.03853607177734375, "timer/replay._sample_count": 30400.0, "timer/replay._sample_total": 15.49435305595398, "timer/replay._sample_frac": 0.015489114632262567, "timer/replay._sample_avg": 0.0005096826663142757, "timer/replay._sample_min": 0.0003724098205566406, "timer/replay._sample_max": 0.01782536506652832, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5723.0, "timer/agent.policy_total": 58.876291275024414, "timer/agent.policy_frac": 0.05885638602580466, "timer/agent.policy_avg": 0.010287662288139859, "timer/agent.policy_min": 0.008680105209350586, "timer/agent.policy_max": 0.8301239013671875, "timer/dataset_train_count": 1900.0, "timer/dataset_train_total": 0.206329345703125, "timer/dataset_train_frac": 0.00020625958864202917, "timer/dataset_train_avg": 0.00010859439247532895, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.0010864734649658203, "timer/agent.train_count": 1900.0, "timer/agent.train_total": 850.57506275177, "timer/agent.train_frac": 0.8502874952396607, "timer/agent.train_avg": 0.44767108565882635, "timer/agent.train_min": 0.4349806308746338, "timer/agent.train_max": 0.5805280208587646, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4753556251525879, "timer/agent.report_frac": 0.0004751949140754843, "timer/agent.report_avg": 0.23767781257629395, "timer/agent.report_min": 0.23148202896118164, "timer/agent.report_max": 0.24387359619140625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1460612451869924e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 30.38919540984417}
{"step": 183272, "time": 6227.8770496845245, "episode/length": 640.0, "episode/score": 0.09171328775849474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09171328775849474}
{"step": 184120, "time": 6254.752685546875, "episode/length": 640.0, "episode/score": 0.09567021964255673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09567021964255673}
{"step": 184608, "time": 6270.398028373718, "episode/length": 640.0, "episode/score": 0.07306843438274768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07306843438274768}
{"step": 184608, "time": 6270.407471418381, "episode/length": 640.0, "episode/score": 0.07644289969076112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07644289969076112}
{"step": 184608, "time": 6270.416236162186, "episode/length": 640.0, "episode/score": 0.07938049453039753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07938049453039753}
{"step": 184608, "time": 6270.4256138801575, "episode/length": 640.0, "episode/score": 0.09739085296018857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09739085296018857}
{"step": 187024, "time": 6346.83623957634, "episode/length": 640.0, "episode/score": 0.06766057080776022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06766057080776022}
{"step": 187232, "time": 6353.340510368347, "episode/length": 640.0, "episode/score": 0.10641396158219152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10641396158219152}
{"step": 188400, "time": 6390.147968053818, "episode/length": 640.0, "episode/score": 0.1051874683456191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1051874683456191}
{"step": 189248, "time": 6417.4170207977295, "episode/length": 640.0, "episode/score": 0.10791555465975478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10791555465975478}
{"step": 189736, "time": 6432.525589227676, "episode/length": 640.0, "episode/score": 0.09054565969157125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09054565969157125}
{"step": 189736, "time": 6432.535026311874, "episode/length": 640.0, "episode/score": 0.06356051793774498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06356051793774498}
{"step": 189736, "time": 6432.543659448624, "episode/length": 640.0, "episode/score": 0.028551801809854283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028551801809854283}
{"step": 189736, "time": 6432.552589178085, "episode/length": 640.0, "episode/score": 0.09187904091564292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09187904091564292}
{"step": 190008, "time": 6452.740590572357, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6452.749402523041, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6452.757563114166, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6452.7654440402985, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6452.773166656494, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6452.780906200409, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6452.788668870926, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6452.796273231506, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190592, "time": 6471.706350564957, "episode/length": 419.0, "episode/score": 0.10840374572460121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10840374572460121}
{"step": 192152, "time": 6520.9885177612305, "episode/length": 640.0, "episode/score": 0.07970451558763614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07970451558763614}
{"step": 193528, "time": 6564.428781032562, "episode/length": 640.0, "episode/score": 0.06394640979561927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06394640979561927}
{"step": 194376, "time": 6591.146738767624, "episode/length": 640.0, "episode/score": 0.03542480230186129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03542480230186129}
{"step": 194864, "time": 6606.733717441559, "episode/length": 640.0, "episode/score": 0.06142919869847674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06142919869847674}
{"step": 194864, "time": 6606.74338388443, "episode/length": 640.0, "episode/score": 0.07254615179482471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07254615179482471}
{"step": 194864, "time": 6606.752417802811, "episode/length": 640.0, "episode/score": 0.040509856175162895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040509856175162895}
{"step": 194864, "time": 6606.761428117752, "episode/length": 640.0, "episode/score": 0.05663091436014156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05663091436014156}
{"step": 195720, "time": 6633.485761165619, "episode/length": 640.0, "episode/score": 0.0932431961738871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0932431961738871}
{"step": 197280, "time": 6683.551513910294, "episode/length": 640.0, "episode/score": 0.07551739938492119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07551739938492119}
{"step": 198656, "time": 6727.460822582245, "episode/length": 640.0, "episode/score": 0.034565648121883896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034565648121883896}
{"step": 199384, "time": 6750.219712972641, "episode/length": 564.0, "episode/score": 0.10998631884228871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10998631884228871}
{"step": 199504, "time": 6754.220749378204, "episode/length": 640.0, "episode/score": 0.12030059676533256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12030059676533256}
{"step": 199992, "time": 6769.432470321655, "episode/length": 640.0, "episode/score": 0.054668481640248956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054668481640248956}
{"step": 199992, "time": 6769.442798137665, "episode/length": 640.0, "episode/score": 0.08195506856884549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08195506856884549}
{"step": 199992, "time": 6769.45170712471, "episode/length": 640.0, "episode/score": 0.08508527172421054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08508527172421054}
{"step": 200096, "time": 6784.965063095093, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6784.97395658493, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6784.982148170471, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6784.990020751953, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6784.998114347458, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6785.006322383881, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6785.013875722885, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6785.02138376236, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200848, "time": 6808.727015256882, "episode/length": 640.0, "episode/score": 0.09655428420785483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09655428420785483}
{"step": 202408, "time": 6858.388032674789, "episode/length": 640.0, "episode/score": 0.08654832697391157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08654832697391157}
{"step": 203784, "time": 6901.780424118042, "episode/length": 640.0, "episode/score": 0.02678461137412569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02678461137412569}
{"step": 204512, "time": 6925.010565519333, "episode/length": 640.0, "episode/score": 0.08110472363216559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08110472363216559}
{"step": 204632, "time": 6928.556144237518, "episode/length": 640.0, "episode/score": 0.09579322623025632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09579322623025632}
{"step": 205120, "time": 6944.5690104961395, "episode/length": 640.0, "episode/score": 0.05137844203215991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05137844203215991}
{"step": 205120, "time": 6944.57870554924, "episode/length": 640.0, "episode/score": 0.07849589535175028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07849589535175028}
{"step": 205120, "time": 6944.587540149689, "episode/length": 640.0, "episode/score": 0.06766986380915796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06766986380915796}
{"step": 205976, "time": 6971.519512891769, "episode/length": 640.0, "episode/score": 0.08500888116702754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08500888116702754}
{"step": 207536, "time": 7021.351138353348, "episode/length": 640.0, "episode/score": 0.09326138807557527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09326138807557527}
{"step": 208912, "time": 7064.9081473350525, "episode/length": 640.0, "episode/score": 0.05409752679202029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05409752679202029}
{"step": 209640, "time": 7087.7721564769745, "episode/length": 640.0, "episode/score": 0.06294427235940248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06294427235940248}
{"step": 209760, "time": 7091.860750675201, "episode/length": 640.0, "episode/score": 0.05913033798617562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05913033798617562}
{"step": 210080, "time": 7113.692471027374, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7113.702259063721, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7113.711359500885, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7113.72029542923, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7113.730054616928, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7113.739126443863, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7113.74798989296, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7113.756557941437, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210248, "time": 7118.928326845169, "episode/length": 640.0, "episode/score": 0.016827424236737443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016827424236737443}
{"step": 210248, "time": 7118.938219308853, "episode/length": 640.0, "episode/score": 0.0506834526482578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0506834526482578}
{"step": 210248, "time": 7118.94740653038, "episode/length": 640.0, "episode/score": 0.03397492694119819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03397492694119819}
{"step": 211104, "time": 7146.305257558823, "episode/length": 640.0, "episode/score": 0.08939265208101688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08939265208101688}
{"step": 212664, "time": 7195.167591094971, "episode/length": 640.0, "episode/score": 0.06897657360383391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06897657360383391}
{"step": 213017, "time": 7207.665059328079, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.990759919819079, "train/action_min": 0.0, "train/action_std": 2.005087715073636, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00012718377518371868, "train/actor_opt_grad_steps": 12265.0, "train/actor_opt_loss": -5.652886512404994, "train/adv_mag": 0.00043460581647722347, "train/adv_max": 0.00039403258185637623, "train/adv_mean": 2.3438211302929727e-06, "train/adv_min": -0.0003658867980304517, "train/adv_std": 0.00010181275591477108, "train/cont_avg": 0.9985454358552631, "train/cont_loss_mean": 0.010967511933689054, "train/cont_loss_std": 0.21859120830886, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.498417562739864, "train/cont_pos_acc": 0.9999999974903307, "train/cont_pos_loss": 0.0015333637313329075, "train/cont_pred": 0.998467859468962, "train/cont_rate": 0.9985454358552631, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.015046881726716253, "train/extr_critic_critic_opt_grad_steps": 12265.0, "train/extr_critic_critic_opt_loss": 12386.954954769737, "train/extr_critic_mag": 0.05336096349515413, "train/extr_critic_max": 0.05336096349515413, "train/extr_critic_mean": 0.05315488355332299, "train/extr_critic_min": 0.05285509260077226, "train/extr_critic_std": 7.984785666358699e-05, "train/extr_return_normed_mag": 0.000357822132738013, "train/extr_return_normed_max": 0.0002736385127431468, "train/extr_return_normed_mean": 7.422823877469024e-05, "train/extr_return_normed_min": -0.00017321262704698663, "train/extr_return_normed_std": 7.103663456770223e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.05335661839497717, "train/extr_return_raw_max": 0.05335661839497717, "train/extr_return_raw_mean": 0.0531572112715558, "train/extr_return_raw_min": 0.052909767255187035, "train/extr_return_raw_std": 7.103663453658795e-05, "train/extr_reward_mag": 0.00016016897402311626, "train/extr_reward_max": 0.00016016897402311626, "train/extr_reward_mean": 0.0001598626296694611, "train/extr_reward_min": 0.00015970782229774875, "train/extr_reward_std": 8.991735024391358e-08, "train/image_loss_mean": 0.25813754310733394, "train/image_loss_std": 0.12497461308774195, "train/model_loss_mean": 0.8771240413188934, "train/model_loss_std": 0.26723384637581676, "train/model_opt_grad_norm": 42.644281005859376, "train/model_opt_grad_steps": 12251.5, "train/model_opt_loss": 2250.2605108963817, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2565.7894736842104, "train/policy_entropy_mag": 1.9458332369202063, "train/policy_entropy_max": 1.9458332369202063, "train/policy_entropy_mean": 1.9417110480760273, "train/policy_entropy_min": 1.903747540398648, "train/policy_entropy_std": 0.0030267033033612137, "train/policy_logprob_mag": 2.3296058428914925, "train/policy_logprob_max": -1.571576919367439, "train/policy_logprob_mean": -1.941787880972812, "train/policy_logprob_min": -2.3296058428914925, "train/policy_logprob_std": 0.08116658943656244, "train/policy_randomness_mag": 0.9999605329413163, "train/policy_randomness_max": 0.9999605329413163, "train/policy_randomness_mean": 0.9978421421427476, "train/policy_randomness_min": 0.978332761714333, "train/policy_randomness_std": 0.0015554179069831183, "train/post_ent_mag": 53.143967337357374, "train/post_ent_max": 53.143967337357374, "train/post_ent_mean": 53.036436823794716, "train/post_ent_min": 52.97827236777858, "train/post_ent_std": 0.028446969615393565, "train/prior_ent_mag": 53.38014448065507, "train/prior_ent_max": 53.38014448065507, "train/prior_ent_mean": 53.0420078679135, "train/prior_ent_min": 52.64682902285927, "train/prior_ent_std": 0.10906756681046988, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00016002038085532962, "train/reward_loss_mean": 0.008018966536282708, "train/reward_loss_std": 0.014618886203358048, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00016010560487446032, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008018966455404695, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00015983784902154615, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.9398087461789448, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014228954911231995, "report/cont_loss_std": 0.2897408902645111, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.563911437988281, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0014115700032562017, "report/cont_pred": 0.9985893368721008, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2437213659286499, "report/image_loss_std": 0.132099449634552, "report/model_loss_mean": 0.8662897348403931, "report/model_loss_std": 0.31977272033691406, "report/post_ent_mag": 57.37240219116211, "report/post_ent_max": 57.37240219116211, "report/post_ent_mean": 57.14340591430664, "report/post_ent_min": 56.8788948059082, "report/post_ent_std": 0.09539885073900223, "report/prior_ent_mag": 53.92281723022461, "report/prior_ent_max": 53.92281723022461, "report/prior_ent_mean": 52.96521759033203, "report/prior_ent_min": 52.23011016845703, "report/prior_ent_std": 0.30826830863952637, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001673742226557806, "report/reward_loss_mean": 0.00833933986723423, "report/reward_loss_std": 0.01543887797743082, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00015842914581298828, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00833933986723423, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00015763496048748493, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.00782034918665886, "eval/cont_loss_std": 0.20497797429561615, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.563911437988281, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0014116561505943537, "eval/cont_pred": 0.998589277267456, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24244281649589539, "eval/image_loss_std": 0.13628654181957245, "eval/model_loss_mean": 0.8512656688690186, "eval/model_loss_std": 0.24312375485897064, "eval/post_ent_mag": 57.35199737548828, "eval/post_ent_max": 57.35199737548828, "eval/post_ent_mean": 57.15504837036133, "eval/post_ent_min": 56.88987350463867, "eval/post_ent_std": 0.08933411538600922, "eval/prior_ent_mag": 53.97981262207031, "eval/prior_ent_max": 53.97981262207031, "eval/prior_ent_mean": 52.94886779785156, "eval/prior_ent_min": 52.22399139404297, "eval/prior_ent_std": 0.3161887526512146, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010024281218647957, "eval/reward_loss_std": 1.5473523262699018e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00015842914581298828, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010024281218647957, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00015760923270136118, "eval/reward_rate": 0.0, "replay/size": 212513.0, "replay/inserts": 30384.0, "replay/samples": 30384.0, "replay/insert_wait_avg": 1.293984195192969e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.527403319742003e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0977731170098854e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0326466560364, "timer/env.step_count": 3798.0, "timer/env.step_total": 34.53998351097107, "timer/env.step_frac": 0.03453885593282154, "timer/env.step_avg": 0.009094255795411024, "timer/env.step_min": 0.007559776306152344, "timer/env.step_max": 0.04606342315673828, "timer/replay._sample_count": 30384.0, "timer/replay._sample_total": 15.311418294906616, "timer/replay._sample_frac": 0.015310918444618554, "timer/replay._sample_avg": 0.0005039303019650676, "timer/replay._sample_min": 0.00038361549377441406, "timer/replay._sample_max": 0.010914325714111328, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5721.0, "timer/agent.policy_total": 57.768803119659424, "timer/agent.policy_frac": 0.057766917222982564, "timer/agent.policy_avg": 0.01009767577690254, "timer/agent.policy_min": 0.008855342864990234, "timer/agent.policy_max": 0.08002471923828125, "timer/dataset_train_count": 1899.0, "timer/dataset_train_total": 0.20835566520690918, "timer/dataset_train_frac": 0.000208348863313233, "timer/dataset_train_avg": 0.00010971862306840925, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0005314350128173828, "timer/agent.train_count": 1899.0, "timer/agent.train_total": 851.3655774593353, "timer/agent.train_frac": 0.8513377841275261, "timer/agent.train_avg": 0.44832310556047145, "timer/agent.train_min": 0.43706274032592773, "timer/agent.train_max": 0.5816500186920166, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4658041000366211, "timer/agent.report_frac": 0.0004657888935868266, "timer/agent.report_avg": 0.23290205001831055, "timer/agent.report_min": 0.22423553466796875, "timer/agent.report_max": 0.24156856536865234, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.123181424800754e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 30.38249140929141}
{"step": 214040, "time": 7239.596817016602, "episode/length": 640.0, "episode/score": 0.05725771890088538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05725771890088538}
{"step": 214768, "time": 7262.727344512939, "episode/length": 640.0, "episode/score": 0.02377646776005804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02377646776005804}
{"step": 214888, "time": 7266.278075456619, "episode/length": 640.0, "episode/score": 0.04780898933863398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04780898933863398}
{"step": 215376, "time": 7281.899064540863, "episode/length": 640.0, "episode/score": 0.025505534315129808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025505534315129808}
{"step": 215376, "time": 7281.909413814545, "episode/length": 640.0, "episode/score": 0.08117199818440213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08117199818440213}
{"step": 215376, "time": 7281.918213367462, "episode/length": 640.0, "episode/score": 0.027876225079978667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027876225079978667}
{"step": 216232, "time": 7308.729445695877, "episode/length": 640.0, "episode/score": 0.05034915074662649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05034915074662649}
{"step": 217792, "time": 7358.291298151016, "episode/length": 640.0, "episode/score": 0.04295483230089303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04295483230089303}
{"step": 219168, "time": 7402.071435451508, "episode/length": 640.0, "episode/score": 0.029169865163964914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029169865163964914}
{"step": 219648, "time": 7417.402535438538, "episode/length": 594.0, "episode/score": 0.10904155832031392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10904155832031392}
{"step": 219896, "time": 7424.948657751083, "episode/length": 640.0, "episode/score": 0.06611157586866057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06611157586866057}
{"step": 220064, "time": 7442.455554008484, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7442.464330434799, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7442.472408533096, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7442.480181694031, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7442.487879753113, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7442.495671987534, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7442.503688812256, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7442.511193990707, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220504, "time": 7456.160080432892, "episode/length": 640.0, "episode/score": 0.053009069600591374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053009069600591374}
{"step": 220504, "time": 7456.2026081085205, "episode/length": 640.0, "episode/score": 0.019799066787641095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019799066787641095}
{"step": 220504, "time": 7456.210813999176, "episode/length": 640.0, "episode/score": 0.08754418015377041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08754418015377041}
{"step": 221360, "time": 7484.034424066544, "episode/length": 640.0, "episode/score": 0.05528820811713331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05528820811713331}
{"step": 222920, "time": 7533.107361078262, "episode/length": 640.0, "episode/score": 0.053530565996368296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053530565996368296}
{"step": 224296, "time": 7576.631278514862, "episode/length": 640.0, "episode/score": 0.14932746917719442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14932746917719442}
{"step": 224304, "time": 7577.1099445819855, "episode/length": 474.0, "episode/score": 0.10449413604277424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10449413604277424}
{"step": 224776, "time": 7591.699084043503, "episode/length": 640.0, "episode/score": 0.14135816128793977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14135816128793977}
{"step": 225024, "time": 7599.669982433319, "episode/length": 640.0, "episode/score": 0.11690814287754847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11690814287754847}
{"step": 225632, "time": 7618.917395353317, "episode/length": 640.0, "episode/score": 0.08620091954901454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08620091954901454}
{"step": 225632, "time": 7618.9269642829895, "episode/length": 640.0, "episode/score": 0.1988084967207442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1988084967207442}
{"step": 226488, "time": 7645.728229045868, "episode/length": 640.0, "episode/score": 0.12631227840989823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12631227840989823}
{"step": 228048, "time": 7695.576456308365, "episode/length": 640.0, "episode/score": 0.1122826826850769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1122826826850769}
{"step": 229424, "time": 7740.226361274719, "episode/length": 640.0, "episode/score": 0.1908135699523541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1908135699523541}
{"step": 229432, "time": 7740.265923500061, "episode/length": 640.0, "episode/score": 0.223893926636606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.223893926636606}
{"step": 229904, "time": 7755.523493766785, "episode/length": 640.0, "episode/score": 0.07503806916196254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07503806916196254}
{"step": 230048, "time": 7771.951523303986, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7771.960481882095, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7771.968604564667, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7771.976406574249, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7771.984658002853, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7771.992791175842, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7772.000696659088, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7772.008881568909, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230152, "time": 7775.042120695114, "episode/length": 640.0, "episode/score": 0.21848922687991035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21848922687991035}
{"step": 230760, "time": 7794.149070978165, "episode/length": 640.0, "episode/score": 0.14672959094468752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14672959094468752}
{"step": 230760, "time": 7794.15837931633, "episode/length": 640.0, "episode/score": 0.21175150271787402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21175150271787402}
{"step": 231616, "time": 7821.5496871471405, "episode/length": 640.0, "episode/score": 0.10754487123494982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10754487123494982}
{"step": 233176, "time": 7870.525062322617, "episode/length": 640.0, "episode/score": 0.1112793840335371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1112793840335371}
{"step": 234552, "time": 7913.864621400833, "episode/length": 640.0, "episode/score": 0.22374345722647604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22374345722647604}
{"step": 234560, "time": 7914.34765124321, "episode/length": 640.0, "episode/score": 0.22158250481200525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22158250481200525}
{"step": 235032, "time": 7928.992902994156, "episode/length": 640.0, "episode/score": 0.22368566868377115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22368566868377115}
{"step": 235280, "time": 7937.079612493515, "episode/length": 640.0, "episode/score": 0.17095954734756447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17095954734756447}
{"step": 235888, "time": 7956.143809556961, "episode/length": 640.0, "episode/score": 0.28445597794612354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28445597794612354}
{"step": 235888, "time": 7956.153234004974, "episode/length": 640.0, "episode/score": 0.16820293346913218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16820293346913218}
{"step": 236744, "time": 7983.26517367363, "episode/length": 640.0, "episode/score": 0.1913482199321379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1913482199321379}
{"step": 238304, "time": 8033.598423242569, "episode/length": 640.0, "episode/score": 0.19171559048220388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19171559048220388}
{"step": 239680, "time": 8077.155942201614, "episode/length": 640.0, "episode/score": 0.126760616301965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.126760616301965}
{"step": 239688, "time": 8077.194431066513, "episode/length": 640.0, "episode/score": 0.07883315346765585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07883315346765585}
{"step": 240032, "time": 8099.849987983704, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8099.859501123428, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8099.868225097656, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8099.876562595367, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8099.884916305542, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8099.892948389053, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8099.901640415192, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8099.910383462906, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240160, "time": 8104.026662111282, "episode/length": 640.0, "episode/score": 0.19777074296808905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19777074296808905}
{"step": 240408, "time": 8111.735556364059, "episode/length": 640.0, "episode/score": 0.26053041381788944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26053041381788944}
{"step": 241016, "time": 8131.203800916672, "episode/length": 640.0, "episode/score": 0.10029107322696973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10029107322696973}
{"step": 241016, "time": 8131.214045524597, "episode/length": 640.0, "episode/score": 0.217418616049315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.217418616049315}
{"step": 241872, "time": 8158.899384975433, "episode/length": 640.0, "episode/score": 0.26692001045478264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26692001045478264}
{"step": 243385, "time": 8207.791122436523, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4120778937088816, "train/action_min": 0.0, "train/action_std": 1.86366765028552, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0004310805006657335, "train/actor_opt_grad_steps": 14165.0, "train/actor_opt_loss": 0.2601611015828032, "train/adv_mag": 0.0023286406538988416, "train/adv_max": 0.002306398063113815, "train/adv_mean": 0.00041452573128289693, "train/adv_min": -0.0010624209320858906, "train/adv_std": 0.00044835457198419854, "train/cont_avg": 0.9983501233552632, "train/cont_loss_mean": 0.012250664427043183, "train/cont_loss_std": 0.23076722611790218, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.481019939914827, "train/cont_pos_acc": 0.9999999971766221, "train/cont_pos_loss": 0.0015562000488372224, "train/cont_pred": 0.9984450531633277, "train/cont_rate": 0.9983501233552632, "train/dyn_loss_mean": 1.0000022135282818, "train/dyn_loss_std": 6.933936728225824e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08043911664939705, "train/extr_critic_critic_opt_grad_steps": 14165.0, "train/extr_critic_critic_opt_loss": 12789.661328125, "train/extr_critic_mag": 0.06004210961492438, "train/extr_critic_max": 0.06004210961492438, "train/extr_critic_mean": 0.05936357263279589, "train/extr_critic_min": 0.0585007485590483, "train/extr_critic_std": 0.00019336196978417177, "train/extr_return_normed_mag": 0.0032597903358308894, "train/extr_return_normed_max": 0.0032422176121096862, "train/extr_return_normed_mean": 0.0014081992691851492, "train/extr_return_normed_min": 8.522448571104752e-05, "train/extr_return_normed_std": 0.0004383132942357885, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.061612054391911156, "train/extr_return_raw_max": 0.061612054391911156, "train/extr_return_raw_mean": 0.05977803896132269, "train/extr_return_raw_min": 0.05845506126551252, "train/extr_return_raw_std": 0.0004383132926274189, "train/extr_reward_mag": 0.0007653882628992985, "train/extr_reward_max": 0.0007653882628992985, "train/extr_reward_mean": 0.00024451559040340054, "train/extr_reward_min": 6.290423242669357e-05, "train/extr_reward_std": 0.00013841300339340466, "train/image_loss_mean": 0.23927978786982987, "train/image_loss_std": 0.12419408399023507, "train/model_loss_mean": 0.8588886160599558, "train/model_loss_std": 0.27827125772049555, "train/model_opt_grad_norm": 39.111009110902486, "train/model_opt_grad_steps": 14149.694736842106, "train/model_opt_loss": 2352.166300884046, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2736.842105263158, "train/policy_entropy_mag": 1.8992249582943164, "train/policy_entropy_max": 1.8992249582943164, "train/policy_entropy_mean": 1.7715528117982964, "train/policy_entropy_min": 1.4594563315573492, "train/policy_entropy_std": 0.051258513319159024, "train/policy_logprob_mag": 3.308286286655225, "train/policy_logprob_max": -0.7265250080216088, "train/policy_logprob_mean": -1.771664855041002, "train/policy_logprob_min": -3.308286286655225, "train/policy_logprob_std": 0.4930318247330816, "train/policy_randomness_mag": 0.9760086159957083, "train/policy_randomness_max": 0.9760086159957083, "train/policy_randomness_mean": 0.9103981107473373, "train/policy_randomness_min": 0.7500122338925538, "train/policy_randomness_std": 0.026341666554492948, "train/post_ent_mag": 58.96865541558517, "train/post_ent_max": 58.96865541558517, "train/post_ent_mean": 58.48394789444773, "train/post_ent_min": 58.15053696883352, "train/post_ent_std": 0.15598329411525474, "train/prior_ent_mag": 57.21137404190866, "train/prior_ent_max": 57.21137404190866, "train/prior_ent_mean": 54.64541595860531, "train/prior_ent_min": 53.604502728110866, "train/prior_ent_std": 0.519403308316281, "train/rep_loss_mean": 1.0000022135282818, "train/rep_loss_std": 6.933936728225824e-05, "train/reward_avg": 0.00015544051708083747, "train/reward_loss_mean": 0.0073568148244368406, "train/reward_loss_std": 0.013750103287594883, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0005674349634270919, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.007356814831789387, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0001578999321760708, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.783016805953168, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.008246277458965778, "report/cont_loss_std": 0.18936055898666382, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.064826011657715, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0023258652072399855, "report/cont_pred": 0.9976769089698792, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24113652110099792, "report/image_loss_std": 0.1183491200208664, "report/model_loss_mean": 0.8581081032752991, "report/model_loss_std": 0.22316017746925354, "report/post_ent_mag": 58.05238342285156, "report/post_ent_max": 58.05238342285156, "report/post_ent_mean": 57.517372131347656, "report/post_ent_min": 57.14089584350586, "report/post_ent_std": 0.18776899576187134, "report/prior_ent_mag": 59.38459777832031, "report/prior_ent_max": 59.38459777832031, "report/prior_ent_mean": 56.14681625366211, "report/prior_ent_min": 54.92918395996094, "report/prior_ent_std": 0.6946722269058228, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002004415146075189, "report/reward_loss_mean": 0.008725278079509735, "report/reward_loss_std": 0.014853428117930889, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0007940530776977539, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008725278079509735, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00019008805975317955, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0023258652072399855, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0023258652072399855, "eval/cont_pred": 0.9976769089698792, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2460378259420395, "eval/image_loss_std": 0.14375823736190796, "eval/model_loss_mean": 0.8494234085083008, "eval/model_loss_std": 0.14386919140815735, "eval/post_ent_mag": 58.07746124267578, "eval/post_ent_max": 58.07746124267578, "eval/post_ent_mean": 57.4865608215332, "eval/post_ent_min": 57.11785125732422, "eval/post_ent_std": 0.17017768323421478, "eval/prior_ent_mag": 58.72982406616211, "eval/prior_ent_max": 58.72982406616211, "eval/prior_ent_mean": 56.09791564941406, "eval/prior_ent_min": 54.92918395996094, "eval/prior_ent_std": 0.6486343741416931, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010596904903650284, "eval/reward_loss_std": 0.0013556786580011249, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0007712841033935547, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010596904903650284, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001665331656113267, "eval/reward_rate": 0.0, "replay/size": 242881.0, "replay/inserts": 30368.0, "replay/samples": 30368.0, "replay/insert_wait_avg": 1.315431800858364e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.467125566038367e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.092937794812818e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1061420440674, "timer/env.step_count": 3796.0, "timer/env.step_total": 34.43460655212402, "timer/env.step_frac": 0.034430951980501626, "timer/env.step_avg": 0.009071287289811386, "timer/env.step_min": 0.007542610168457031, "timer/env.step_max": 0.03728151321411133, "timer/replay._sample_count": 30368.0, "timer/replay._sample_total": 15.322153091430664, "timer/replay._sample_frac": 0.015320526939385128, "timer/replay._sample_avg": 0.0005045492983216103, "timer/replay._sample_min": 0.00037670135498046875, "timer/replay._sample_max": 0.025589942932128906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5719.0, "timer/agent.policy_total": 58.22827625274658, "timer/agent.policy_frac": 0.05822209644042051, "timer/agent.policy_avg": 0.010181548566663154, "timer/agent.policy_min": 0.008822917938232422, "timer/agent.policy_max": 0.09584975242614746, "timer/dataset_train_count": 1898.0, "timer/dataset_train_total": 0.2109839916229248, "timer/dataset_train_frac": 0.00021096159972751, "timer/dataset_train_avg": 0.00011116121792567165, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0005059242248535156, "timer/agent.train_count": 1898.0, "timer/agent.train_total": 851.2484033107758, "timer/agent.train_frac": 0.8511580596544996, "timer/agent.train_avg": 0.44849757814055624, "timer/agent.train_min": 0.43502116203308105, "timer/agent.train_max": 0.597567081451416, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4784121513366699, "timer/agent.report_frac": 0.00047836137708230354, "timer/agent.report_avg": 0.23920607566833496, "timer/agent.report_min": 0.23357009887695312, "timer/agent.report_max": 0.2448420524597168, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003755271955244e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 30.36427161154378}
{"step": 243432, "time": 8209.064059734344, "episode/length": 640.0, "episode/score": 0.0910602045200335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0910602045200335}
{"step": 244808, "time": 8252.636423110962, "episode/length": 640.0, "episode/score": 0.05963969287640225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05963969287640225}
{"step": 244816, "time": 8253.125601530075, "episode/length": 640.0, "episode/score": 0.22164744175981355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22164744175981355}
{"step": 245288, "time": 8267.963963031769, "episode/length": 640.0, "episode/score": 0.09181076039746472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09181076039746472}
{"step": 245536, "time": 8275.950109481812, "episode/length": 640.0, "episode/score": 0.15981532348203586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15981532348203586}
{"step": 246144, "time": 8295.59081530571, "episode/length": 640.0, "episode/score": 0.21742278410727067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21742278410727067}
{"step": 246144, "time": 8295.6007335186, "episode/length": 640.0, "episode/score": 0.11468977612577191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11468977612577191}
{"step": 247000, "time": 8322.663346767426, "episode/length": 640.0, "episode/score": 0.17335104950473124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17335104950473124}
{"step": 248560, "time": 8373.113577842712, "episode/length": 640.0, "episode/score": 0.08992721415921778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08992721415921778}
{"step": 249936, "time": 8416.829622745514, "episode/length": 640.0, "episode/score": 0.07017503875050579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07017503875050579}
{"step": 249944, "time": 8416.870966672897, "episode/length": 640.0, "episode/score": 0.1383175089821691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1383175089821691}
{"step": 250016, "time": 8431.142449378967, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8431.151322603226, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8431.159590005875, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8431.167663812637, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8431.175422906876, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8431.183255195618, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8431.190979480743, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8431.198614358902, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250416, "time": 8443.946374416351, "episode/length": 640.0, "episode/score": 0.1814401682700293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1814401682700293}
{"step": 250664, "time": 8451.726046562195, "episode/length": 640.0, "episode/score": 0.11805848148119935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11805848148119935}
{"step": 251272, "time": 8470.921164274216, "episode/length": 640.0, "episode/score": 0.1337365326623967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1337365326623967}
{"step": 251272, "time": 8470.931004047394, "episode/length": 640.0, "episode/score": 0.16132390406090735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16132390406090735}
{"step": 252128, "time": 8498.157286643982, "episode/length": 640.0, "episode/score": 0.052730305438331015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052730305438331015}
{"step": 253688, "time": 8547.215613126755, "episode/length": 640.0, "episode/score": 0.13542577940427236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13542577940427236}
{"step": 255064, "time": 8591.241779088974, "episode/length": 640.0, "episode/score": 0.10572265734487019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10572265734487019}
{"step": 255072, "time": 8591.730884075165, "episode/length": 640.0, "episode/score": 0.16601695430625796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16601695430625796}
{"step": 255544, "time": 8606.877054929733, "episode/length": 640.0, "episode/score": 0.18853083436832208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18853083436832208}
{"step": 255792, "time": 8615.033254861832, "episode/length": 640.0, "episode/score": 0.012862443078631713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012862443078631713}
{"step": 256400, "time": 8634.371192455292, "episode/length": 640.0, "episode/score": 0.14168802150012993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14168802150012993}
{"step": 256400, "time": 8634.377654790878, "episode/length": 640.0, "episode/score": 0.04661150577760509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04661150577760509}
{"step": 257256, "time": 8661.104724407196, "episode/length": 640.0, "episode/score": 0.14001720174871934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14001720174871934}
{"step": 258816, "time": 8710.33468580246, "episode/length": 640.0, "episode/score": 0.12906460253552154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12906460253552154}
{"step": 260000, "time": 8758.929105520248, "eval_episode/length": 611.0, "eval_episode/score": 0.1407812535762787, "eval_episode/reward_rate": 0.0016339869281045752}
{"step": 260000, "time": 8759.449163913727, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8759.45788192749, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8759.466076135635, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8759.474246263504, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8759.482825279236, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8759.490984201431, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8759.49863910675, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260192, "time": 8765.494607448578, "episode/length": 640.0, "episode/score": 0.059887800457090634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059887800457090634}
{"step": 260200, "time": 8765.53164768219, "episode/length": 640.0, "episode/score": 0.09046689657483853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09046689657483853}
{"step": 260672, "time": 8780.616169214249, "episode/length": 640.0, "episode/score": 0.11440455602041766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11440455602041766}
{"step": 260920, "time": 8788.156087636948, "episode/length": 640.0, "episode/score": 0.12008194166310204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12008194166310204}
{"step": 261528, "time": 8807.36019229889, "episode/length": 640.0, "episode/score": 0.08063810872226895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08063810872226895}
{"step": 261528, "time": 8807.369645118713, "episode/length": 640.0, "episode/score": 0.07030136330809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07030136330809}
{"step": 262384, "time": 8834.937717199326, "episode/length": 640.0, "episode/score": 0.04711473346344519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04711473346344519}
{"step": 263944, "time": 8883.906955718994, "episode/length": 640.0, "episode/score": 0.21665455230436237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21665455230436237}
{"step": 265320, "time": 8927.1498503685, "episode/length": 640.0, "episode/score": 0.1866625404146589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1866625404146589}
{"step": 265328, "time": 8927.632187843323, "episode/length": 640.0, "episode/score": 0.15639263363596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15639263363596}
{"step": 265800, "time": 8942.236063718796, "episode/length": 640.0, "episode/score": 0.1820734408811404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1820734408811404}
{"step": 266048, "time": 8950.219871044159, "episode/length": 640.0, "episode/score": 0.1469890247620924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1469890247620924}
{"step": 266656, "time": 8969.3811647892, "episode/length": 640.0, "episode/score": 0.15370584855190828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15370584855190828}
{"step": 266656, "time": 8969.390506029129, "episode/length": 640.0, "episode/score": 0.18391466431290837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18391466431290837}
{"step": 267512, "time": 8996.308290719986, "episode/length": 640.0, "episode/score": 0.1027772452526392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1027772452526392}
{"step": 269072, "time": 9045.577556371689, "episode/length": 640.0, "episode/score": 0.19291160278618236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19291160278618236}
{"step": 270088, "time": 9088.706559181213, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 9088.716081142426, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 9088.7253074646, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 9088.733998775482, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 9088.742328882217, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 9088.750570774078, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 9088.758870601654, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 9088.766967058182, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270448, "time": 9100.77944970131, "episode/length": 640.0, "episode/score": 0.12475337047550283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12475337047550283}
{"step": 270456, "time": 9100.818652629852, "episode/length": 640.0, "episode/score": 0.09003579348387802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09003579348387802}
{"step": 270928, "time": 9116.059679746628, "episode/length": 640.0, "episode/score": 0.1656863116559748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1656863116559748}
{"step": 271176, "time": 9123.789824962616, "episode/length": 640.0, "episode/score": 0.09151010964916395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09151010964916395}
{"step": 271784, "time": 9143.064279556274, "episode/length": 640.0, "episode/score": 0.16069520264034054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16069520264034054}
{"step": 271784, "time": 9143.073554515839, "episode/length": 640.0, "episode/score": 0.08020831223882396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08020831223882396}
{"step": 272640, "time": 9170.19124341011, "episode/length": 640.0, "episode/score": 0.09281133951367337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09281133951367337}
{"step": 273801, "time": 9207.789802312851, "train_stats/mean_log_entropy": 1.761678233742714, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.184783293071546, "train/action_min": 0.0, "train/action_std": 1.8605437793229755, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0003141380109713952, "train/actor_opt_grad_steps": 16065.0, "train/actor_opt_loss": -2.575982644801077, "train/adv_mag": 0.0022214675812344802, "train/adv_max": 0.0021319077595284112, "train/adv_mean": 0.00020971666636365914, "train/adv_min": -0.0016546766224660372, "train/adv_std": 0.00047284142270463664, "train/cont_avg": 0.9986019736842106, "train/cont_loss_mean": 0.010608175472282854, "train/cont_loss_std": 0.2108005252077772, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.472554942361669, "train/cont_pos_acc": 0.9999999968629134, "train/cont_pos_loss": 0.0015588898732522992, "train/cont_pred": 0.9984423577785492, "train/cont_rate": 0.9986019736842106, "train/dyn_loss_mean": 1.0000004071938364, "train/dyn_loss_std": 1.3030326226726174e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03921063554329234, "train/extr_critic_critic_opt_grad_steps": 16065.0, "train/extr_critic_critic_opt_loss": 13476.717619243422, "train/extr_critic_mag": 0.07547604473013626, "train/extr_critic_max": 0.07547604473013626, "train/extr_critic_mean": 0.07459636820774329, "train/extr_critic_min": 0.07350176698283145, "train/extr_critic_std": 0.0002482846846473158, "train/extr_return_normed_mag": 0.003164339575328325, "train/extr_return_normed_max": 0.0031601178410806154, "train/extr_return_normed_mean": 0.0011869367867850661, "train/extr_return_normed_min": -0.0005137702352122257, "train/extr_return_normed_std": 0.00047955598290029327, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.07677926809379929, "train/extr_return_raw_max": 0.07677926809379929, "train/extr_return_raw_mean": 0.07480609103253014, "train/extr_return_raw_min": 0.07310538001750645, "train/extr_return_raw_std": 0.00047955598259393715, "train/extr_reward_mag": 0.0008732965118006656, "train/extr_reward_max": 0.0008732965118006656, "train/extr_reward_mean": 0.0002636025535665747, "train/extr_reward_min": 5.739613583213405e-06, "train/extr_reward_std": 0.00021413225155188947, "train/image_loss_mean": 0.2371364758202904, "train/image_loss_std": 0.1220366700307319, "train/model_loss_mean": 0.8551628655508945, "train/model_loss_std": 0.25943291677456154, "train/model_opt_grad_norm": 37.15790897168611, "train/model_opt_grad_steps": 16047.931578947368, "train/model_opt_loss": 2206.465014005962, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2578.9473684210525, "train/policy_entropy_mag": 1.906913379618996, "train/policy_entropy_max": 1.906913379618996, "train/policy_entropy_mean": 1.7660642467047039, "train/policy_entropy_min": 1.4394426992065028, "train/policy_entropy_std": 0.050474824030932626, "train/policy_logprob_mag": 3.320788507712515, "train/policy_logprob_max": -0.5831890959488718, "train/policy_logprob_mean": -1.7663830888898748, "train/policy_logprob_min": -3.320788507712515, "train/policy_logprob_std": 0.597432563806835, "train/policy_randomness_mag": 0.9799596824144062, "train/policy_randomness_max": 0.9799596824144062, "train/policy_randomness_mean": 0.9075775391177128, "train/policy_randomness_min": 0.7397272608782116, "train/policy_randomness_std": 0.02593893000954076, "train/post_ent_mag": 58.22879048397667, "train/post_ent_max": 58.22879048397667, "train/post_ent_mean": 57.62662572358784, "train/post_ent_min": 57.21523895263672, "train/post_ent_std": 0.21166395678331978, "train/prior_ent_mag": 59.59620413529245, "train/prior_ent_max": 59.59620413529245, "train/prior_ent_mean": 56.358442346673264, "train/prior_ent_min": 54.19434354681718, "train/prior_ent_std": 0.8431946534859507, "train/rep_loss_mean": 1.0000004071938364, "train/rep_loss_std": 1.3030326226726174e-05, "train/reward_avg": 0.00016396329971796246, "train/reward_loss_mean": 0.007417947725441895, "train/reward_loss_std": 0.01349123747235066, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0007607616876301013, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.007417947742597837, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00016528030269240078, "train/reward_rate": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.026691945269703865, "report/cont_loss_std": 0.4000951945781708, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.415699481964111, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0016370139783248305, "report/cont_pred": 0.9983643889427185, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.23057954013347626, "report/image_loss_std": 0.111015684902668, "report/model_loss_mean": 0.8659159541130066, "report/model_loss_std": 0.4213387370109558, "report/post_ent_mag": 58.941993713378906, "report/post_ent_max": 58.941993713378906, "report/post_ent_mean": 58.3443603515625, "report/post_ent_min": 57.88239669799805, "report/post_ent_std": 0.22260600328445435, "report/prior_ent_mag": 59.32589340209961, "report/prior_ent_max": 59.32589340209961, "report/prior_ent_mean": 56.3615837097168, "report/prior_ent_min": 53.93218231201172, "report/prior_ent_std": 0.7741763591766357, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001950622972799465, "report/reward_loss_mean": 0.00864439457654953, "report/reward_loss_std": 0.014060654677450657, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0007506608963012695, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00864439457654953, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0001774326665326953, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0016370140947401524, "eval/cont_loss_std": 3.4924596548080444e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0016370140947401524, "eval/cont_pred": 0.9983643889427185, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24979710578918457, "eval/image_loss_std": 0.12680600583553314, "eval/model_loss_mean": 0.8523750305175781, "eval/model_loss_std": 0.12687070667743683, "eval/post_ent_mag": 58.9412727355957, "eval/post_ent_max": 58.9412727355957, "eval/post_ent_mean": 58.369136810302734, "eval/post_ent_min": 57.858985900878906, "eval/post_ent_std": 0.22574745118618011, "eval/prior_ent_mag": 59.85736083984375, "eval/prior_ent_max": 59.85736083984375, "eval/prior_ent_mean": 56.36381149291992, "eval/prior_ent_min": 54.180381774902344, "eval/prior_ent_std": 0.766229510307312, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0009408444166183472, "eval/reward_loss_std": 0.0011689806124195457, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0006731748580932617, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009408444166183472, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00014795421157032251, "eval/reward_rate": 0.0, "replay/size": 273297.0, "replay/inserts": 30416.0, "replay/samples": 30416.0, "replay/insert_wait_avg": 1.2980392893510765e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.466540356174009e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1050106024779321e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9836494922638, "timer/env.step_count": 3802.0, "timer/env.step_total": 34.05232334136963, "timer/env.step_frac": 0.03405288012324952, "timer/env.step_avg": 0.008956423814142458, "timer/env.step_min": 0.007466316223144531, "timer/env.step_max": 0.03532075881958008, "timer/replay._sample_count": 30416.0, "timer/replay._sample_total": 15.216351985931396, "timer/replay._sample_frac": 0.015216600785080251, "timer/replay._sample_avg": 0.0005002745918572921, "timer/replay._sample_min": 0.00038433074951171875, "timer/replay._sample_max": 0.009720087051391602, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5725.0, "timer/agent.policy_total": 57.380144119262695, "timer/agent.policy_frac": 0.05738108232909323, "timer/agent.policy_avg": 0.010022732597251127, "timer/agent.policy_min": 0.008577585220336914, "timer/agent.policy_max": 0.09128642082214355, "timer/dataset_train_count": 1901.0, "timer/dataset_train_total": 0.20794177055358887, "timer/dataset_train_frac": 0.00020794517056270886, "timer/dataset_train_avg": 0.00010938546583565958, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0004172325134277344, "timer/agent.train_count": 1901.0, "timer/agent.train_total": 852.1770277023315, "timer/agent.train_frac": 0.8521909614572396, "timer/agent.train_avg": 0.4482782891648246, "timer/agent.train_min": 0.43675851821899414, "timer/agent.train_max": 1.3761236667633057, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4690897464752197, "timer/agent.report_frac": 0.00046909741645615653, "timer/agent.report_avg": 0.23454487323760986, "timer/agent.report_min": 0.22495508193969727, "timer/agent.report_max": 0.24413466453552246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.004123215619565e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 30.41594203695662}
{"step": 274200, "time": 9220.100850820541, "episode/length": 640.0, "episode/score": 0.0694500251890986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0694500251890986}
{"step": 275576, "time": 9263.40969991684, "episode/length": 640.0, "episode/score": 0.2731087517806543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2731087517806543}
{"step": 275584, "time": 9263.889913320541, "episode/length": 640.0, "episode/score": 0.23910125551103079, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23910125551103079}
{"step": 276056, "time": 9278.454982995987, "episode/length": 640.0, "episode/score": 0.13017116716110877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13017116716110877}
{"step": 276304, "time": 9286.58693265915, "episode/length": 640.0, "episode/score": 0.2128088246892048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2128088246892048}
{"step": 276912, "time": 9305.766996383667, "episode/length": 640.0, "episode/score": 0.14554731302467872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14554731302467872}
{"step": 276912, "time": 9305.777682065964, "episode/length": 640.0, "episode/score": 0.1719730683693399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1719730683693399}
{"step": 277768, "time": 9332.835733652115, "episode/length": 640.0, "episode/score": 0.19678451676909958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19678451676909958}
{"step": 279328, "time": 9383.032176494598, "episode/length": 640.0, "episode/score": 0.26901704026613515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26901704026613515}
{"step": 280072, "time": 9418.75191116333, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9418.760834217072, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9418.769092559814, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9418.777134180069, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9418.785017251968, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9418.793088674545, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9418.800949811935, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9418.80890583992, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280704, "time": 9438.942081451416, "episode/length": 640.0, "episode/score": 0.22519799170993338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22519799170993338}
{"step": 280712, "time": 9438.98133802414, "episode/length": 640.0, "episode/score": 0.1892873062961371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1892873062961371}
{"step": 281184, "time": 9453.992079496384, "episode/length": 640.0, "episode/score": 0.14591493827174418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14591493827174418}
{"step": 281432, "time": 9461.551330804825, "episode/length": 640.0, "episode/score": 0.18498570353528976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18498570353528976}
{"step": 282040, "time": 9480.634273290634, "episode/length": 640.0, "episode/score": 0.20894930726626626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20894930726626626}
{"step": 282040, "time": 9480.644501924515, "episode/length": 640.0, "episode/score": 0.10424044037790736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10424044037790736}
{"step": 282896, "time": 9508.256086587906, "episode/length": 640.0, "episode/score": 0.20258707081609373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20258707081609373}
{"step": 284456, "time": 9557.91191482544, "episode/length": 640.0, "episode/score": 0.08157936210784555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08157936210784555}
{"step": 285832, "time": 9601.725545167923, "episode/length": 640.0, "episode/score": 0.18662478493308754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18662478493308754}
{"step": 285840, "time": 9602.213416814804, "episode/length": 640.0, "episode/score": 0.1769465317263439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1769465317263439}
{"step": 286312, "time": 9617.144041061401, "episode/length": 640.0, "episode/score": 0.0915006582802107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0915006582802107}
{"step": 286560, "time": 9625.315341234207, "episode/length": 640.0, "episode/score": 0.2359260620673922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2359260620673922}
{"step": 287168, "time": 9645.122397184372, "episode/length": 640.0, "episode/score": 0.12230499918928217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12230499918928217}
{"step": 287168, "time": 9645.13187623024, "episode/length": 640.0, "episode/score": 0.16873432573243008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16873432573243008}
{"step": 288024, "time": 9672.056331396103, "episode/length": 640.0, "episode/score": 0.140459554062204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.140459554062204}
{"step": 289584, "time": 9722.021122932434, "episode/length": 640.0, "episode/score": 0.13770434468654003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13770434468654003}
{"step": 290056, "time": 9748.114268779755, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9748.123568058014, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9748.13189649582, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9748.140142917633, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9748.148192882538, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9748.156317710876, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9748.164427280426, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9748.172722578049, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290960, "time": 9777.319113969803, "episode/length": 640.0, "episode/score": 0.0537285098545226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0537285098545226}
{"step": 290968, "time": 9777.358974695206, "episode/length": 640.0, "episode/score": 0.07413772279414843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07413772279414843}
{"step": 291440, "time": 9792.538835525513, "episode/length": 640.0, "episode/score": 0.047939298930145924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047939298930145924}
{"step": 291688, "time": 9800.328908920288, "episode/length": 640.0, "episode/score": 0.11769450758561106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11769450758561106}
{"step": 292296, "time": 9819.609553098679, "episode/length": 640.0, "episode/score": 0.16685461722897799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16685461722897799}
{"step": 292296, "time": 9819.618696689606, "episode/length": 640.0, "episode/score": 0.16332654988548256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16332654988548256}
{"step": 293152, "time": 9846.802006483078, "episode/length": 640.0, "episode/score": 0.04564318227949116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04564318227949116}
{"step": 294712, "time": 9895.633029937744, "episode/length": 640.0, "episode/score": 0.14261432803607477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14261432803607477}
{"step": 296088, "time": 9939.482211351395, "episode/length": 640.0, "episode/score": 0.09432429602156844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09432429602156844}
{"step": 296096, "time": 9939.965566396713, "episode/length": 640.0, "episode/score": 0.14826631415644442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14826631415644442}
{"step": 296568, "time": 9954.66802930832, "episode/length": 640.0, "episode/score": 0.033375950137951804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033375950137951804}
{"step": 296816, "time": 9962.781249046326, "episode/length": 640.0, "episode/score": 0.1228307591588873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1228307591588873}
{"step": 297424, "time": 9982.161227226257, "episode/length": 640.0, "episode/score": 0.1214299141729498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1214299141729498}
{"step": 297424, "time": 9982.170540809631, "episode/length": 640.0, "episode/score": 0.0804840532716753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0804840532716753}
{"step": 298280, "time": 10008.875330924988, "episode/length": 640.0, "episode/score": 0.13909601500188273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13909601500188273}
{"step": 299840, "time": 10058.666647911072, "episode/length": 640.0, "episode/score": 0.11859010014450178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11859010014450178}
{"step": 300040, "time": 10076.298695802689, "eval_episode/length": 618.0, "eval_episode/score": 0.13093750178813934, "eval_episode/reward_rate": 0.0016155088852988692}
{"step": 300040, "time": 10076.688036203384, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 10076.696985960007, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 10076.705183029175, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 10076.713387489319, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 10076.721374034882, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 10076.730286359787, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 10076.738193750381, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 301216, "time": 10114.097208738327, "episode/length": 640.0, "episode/score": 0.21121001225964164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21121001225964164}
{"step": 301224, "time": 10114.135560274124, "episode/length": 640.0, "episode/score": 0.14018792491782506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14018792491782506}
{"step": 301696, "time": 10129.353022098541, "episode/length": 640.0, "episode/score": 0.18487760832556432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18487760832556432}
{"step": 301944, "time": 10136.92169713974, "episode/length": 640.0, "episode/score": 0.12240950053262623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12240950053262623}
{"step": 302552, "time": 10156.030318021774, "episode/length": 640.0, "episode/score": 0.25604844986531816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25604844986531816}
{"step": 302552, "time": 10156.039539813995, "episode/length": 640.0, "episode/score": 0.13298024869635583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13298024869635583}
{"step": 303408, "time": 10183.71824479103, "episode/length": 640.0, "episode/score": 0.11625781608023544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11625781608023544}
{"step": 304153, "time": 10208.142279624939, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.220134855571546, "train/action_min": 0.0, "train/action_std": 1.855669619535145, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0002826843630923816, "train/actor_opt_grad_steps": 17965.0, "train/actor_opt_loss": -4.932707915920764, "train/adv_mag": 0.0020973320854337594, "train/adv_max": 0.0019350158540826095, "train/adv_mean": 6.825201302547157e-05, "train/adv_min": -0.001821027303996839, "train/adv_std": 0.00045305339843157286, "train/cont_avg": 0.9984015213815789, "train/cont_loss_mean": 0.011905029476130088, "train/cont_loss_std": 0.22427695866275607, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.458850125343569, "train/cont_pos_acc": 0.9999999946669529, "train/cont_pos_loss": 0.0015901277135861548, "train/cont_pred": 0.9984111682364815, "train/cont_rate": 0.9984015213815789, "train/dyn_loss_mean": 1.0000085554624858, "train/dyn_loss_std": 0.00018727763360259, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.015370374184873838, "train/extr_critic_critic_opt_grad_steps": 17965.0, "train/extr_critic_critic_opt_loss": 13535.488800370065, "train/extr_critic_mag": 0.07930346162695634, "train/extr_critic_max": 0.07930346162695634, "train/extr_critic_mean": 0.07833127234327165, "train/extr_critic_min": 0.07696315050125122, "train/extr_critic_std": 0.0002608992900748394, "train/extr_return_normed_mag": 0.0027876322598833787, "train/extr_return_normed_max": 0.002784336397522374, "train/extr_return_normed_mean": 0.0008584270765009263, "train/extr_return_normed_min": -0.0008831432383311422, "train/extr_return_normed_std": 0.00045865619169107, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08032539416300623, "train/extr_return_raw_max": 0.08032539416300623, "train/extr_return_raw_mean": 0.07839948868280963, "train/extr_return_raw_min": 0.07665791452715272, "train/extr_return_raw_std": 0.00045865619276331637, "train/extr_reward_mag": 0.0008299689543874641, "train/extr_reward_max": 0.0008299689543874641, "train/extr_reward_mean": 0.0002509061965515445, "train/extr_reward_min": 5.023730428595292e-06, "train/extr_reward_std": 0.0002090832666573605, "train/image_loss_mean": 0.236097704266247, "train/image_loss_std": 0.12188910579210833, "train/model_loss_mean": 0.8558078229427337, "train/model_loss_std": 0.2713409664991655, "train/model_opt_grad_norm": 34.889075173272026, "train/model_opt_grad_steps": 17946.305263157894, "train/model_opt_loss": 2443.5576788651315, "train/model_opt_model_opt_grad_overflow": 0.005263157894736842, "train/model_opt_model_opt_grad_scale": 2842.1052631578946, "train/policy_entropy_mag": 1.9106616973876953, "train/policy_entropy_max": 1.9106616973876953, "train/policy_entropy_mean": 1.783874575715316, "train/policy_entropy_min": 1.4465797662734985, "train/policy_entropy_std": 0.05166441662923286, "train/policy_logprob_mag": 3.3153391524365072, "train/policy_logprob_max": -0.5992018553771471, "train/policy_logprob_mean": -1.7840369557079516, "train/policy_logprob_min": -3.3153391524365072, "train/policy_logprob_std": 0.5664823274863394, "train/policy_randomness_mag": 0.9818859370131242, "train/policy_randomness_max": 0.9818859370131242, "train/policy_randomness_mean": 0.9167302329289285, "train/policy_randomness_min": 0.7433949862655841, "train/policy_randomness_std": 0.026550259666615412, "train/post_ent_mag": 57.87192043505217, "train/post_ent_max": 57.87192043505217, "train/post_ent_mean": 57.26376545554713, "train/post_ent_min": 56.685935271413705, "train/post_ent_std": 0.22563451904999582, "train/prior_ent_mag": 59.047682330482886, "train/prior_ent_max": 59.047682330482886, "train/prior_ent_mean": 55.56458545484041, "train/prior_ent_min": 53.4033790989926, "train/prior_ent_std": 0.8593885032754195, "train/rep_loss_mean": 1.0000085554624858, "train/rep_loss_std": 0.00018727763360259, "train/reward_avg": 0.00017291242946061846, "train/reward_loss_mean": 0.007799933049337644, "train/reward_loss_std": 0.013722737050174098, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0007548238101758455, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.007799933061591889, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00017182106446278722, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.782596488793691, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.007910562679171562, "report/cont_loss_std": 0.19985350966453552, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.400100231170654, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0016620885580778122, "report/cont_pred": 0.9983393549919128, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.243584543466568, "report/image_loss_std": 0.10191993415355682, "report/model_loss_mean": 0.8605642318725586, "report/model_loss_std": 0.22299031913280487, "report/post_ent_mag": 54.02871322631836, "report/post_ent_max": 54.02871322631836, "report/post_ent_mean": 53.58988952636719, "report/post_ent_min": 53.10942840576172, "report/post_ent_std": 0.17347483336925507, "report/prior_ent_mag": 56.65431213378906, "report/prior_ent_max": 56.65431213378906, "report/prior_ent_mean": 53.76771545410156, "report/prior_ent_min": 51.74041748046875, "report/prior_ent_std": 0.8537184000015259, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00020234714611433446, "report/reward_loss_mean": 0.009069034829735756, "report/reward_loss_std": 0.01449275016784668, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0008616447448730469, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009069033898413181, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002168676583096385, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.007910543121397495, "eval/cont_loss_std": 0.19985350966453552, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.400100231170654, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0016620694659650326, "eval/cont_pred": 0.9983394145965576, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24586613476276398, "eval/image_loss_std": 0.09815448522567749, "eval/model_loss_mean": 0.8548731207847595, "eval/model_loss_std": 0.22021394968032837, "eval/post_ent_mag": 54.04237365722656, "eval/post_ent_max": 54.04237365722656, "eval/post_ent_mean": 53.59307098388672, "eval/post_ent_min": 53.13164520263672, "eval/post_ent_std": 0.167819082736969, "eval/prior_ent_mag": 56.852142333984375, "eval/prior_ent_max": 56.852142333984375, "eval/prior_ent_mean": 53.77108383178711, "eval/prior_ent_min": 51.495689392089844, "eval/prior_ent_std": 0.9059362411499023, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010964106768369675, "eval/reward_loss_std": 0.0013513140147551894, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0008683204650878906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010964106768369675, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000172419473528862, "eval/reward_rate": 0.0, "replay/size": 303649.0, "replay/inserts": 30352.0, "replay/samples": 30352.0, "replay/insert_wait_avg": 1.3097704368072493e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.429249902744324e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0820893155245252e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3323349952698, "timer/env.step_count": 3794.0, "timer/env.step_total": 34.582945823669434, "timer/env.step_frac": 0.03457145651883078, "timer/env.step_avg": 0.009115167586628739, "timer/env.step_min": 0.0074732303619384766, "timer/env.step_max": 0.04395723342895508, "timer/replay._sample_count": 30352.0, "timer/replay._sample_total": 15.341533184051514, "timer/replay._sample_frac": 0.01533643634954983, "timer/replay._sample_avg": 0.000505453781762372, "timer/replay._sample_min": 0.0003962516784667969, "timer/replay._sample_max": 0.011076927185058594, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5717.0, "timer/agent.policy_total": 58.391918897628784, "timer/agent.policy_frac": 0.0583725196665815, "timer/agent.policy_avg": 0.01021373428330047, "timer/agent.policy_min": 0.00863504409790039, "timer/agent.policy_max": 0.10658860206604004, "timer/dataset_train_count": 1897.0, "timer/dataset_train_total": 0.21264314651489258, "timer/dataset_train_frac": 0.00021257250123370058, "timer/dataset_train_avg": 0.00011209443675007515, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0010962486267089844, "timer/agent.train_count": 1897.0, "timer/agent.train_total": 851.3021140098572, "timer/agent.train_frac": 0.8510192905179684, "timer/agent.train_avg": 0.44876231629407337, "timer/agent.train_min": 0.4339721202850342, "timer/agent.train_max": 0.5999102592468262, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4772489070892334, "timer/agent.report_frac": 0.0004770903532689365, "timer/agent.report_avg": 0.2386244535446167, "timer/agent.report_min": 0.2324213981628418, "timer/agent.report_max": 0.2448275089263916, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.0745778805847557e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 30.34138629038421}
{"step": 304968, "time": 10233.548992872238, "episode/length": 640.0, "episode/score": 0.11117816669229796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11117816669229796}
{"step": 306272, "time": 10274.668022155762, "episode/length": 630.0, "episode/score": 0.23683158299502338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23683158299502338}
{"step": 306344, "time": 10276.8182284832, "episode/length": 640.0, "episode/score": 0.12725308554593084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12725308554593084}
{"step": 306824, "time": 10291.829334020615, "episode/length": 640.0, "episode/score": 0.20358572554545162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20358572554545162}
{"step": 307072, "time": 10299.827937364578, "episode/length": 640.0, "episode/score": 0.14105179708184323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14105179708184323}
{"step": 307680, "time": 10319.08977174759, "episode/length": 640.0, "episode/score": 0.22224277954620675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22224277954620675}
{"step": 307680, "time": 10319.099268913269, "episode/length": 640.0, "episode/score": 0.19381884391202675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19381884391202675}
{"step": 308536, "time": 10345.947572469711, "episode/length": 640.0, "episode/score": 0.05675206069483352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05675206069483352}
{"step": 310024, "time": 10404.942394256592, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10404.951378822327, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10404.959315538406, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10404.967005968094, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10404.97492313385, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10404.983540534973, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10404.991446495056, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10404.999136209488, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310096, "time": 10407.495176553726, "episode/length": 640.0, "episode/score": 0.20795326877322395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20795326877322395}
{"step": 311400, "time": 10448.945670604706, "episode/length": 640.0, "episode/score": 0.2326337011380133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2326337011380133}
{"step": 311472, "time": 10451.463918685913, "episode/length": 640.0, "episode/score": 0.20552641647259406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20552641647259406}
{"step": 311952, "time": 10466.667229652405, "episode/length": 640.0, "episode/score": 0.26055220875900886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26055220875900886}
{"step": 312176, "time": 10473.668077230453, "episode/length": 561.0, "episode/score": 0.25497121437092574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25497121437092574}
{"step": 312200, "time": 10474.203820466995, "episode/length": 640.0, "episode/score": 0.26048251464837335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26048251464837335}
{"step": 312808, "time": 10493.401210069656, "episode/length": 640.0, "episode/score": 0.13656989952676213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13656989952676213}
{"step": 313664, "time": 10520.688158988953, "episode/length": 640.0, "episode/score": 0.11719064857038575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11719064857038575}
{"step": 315224, "time": 10569.608311414719, "episode/length": 640.0, "episode/score": 0.1923649811095629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1923649811095629}
{"step": 316528, "time": 10610.970007419586, "episode/length": 640.0, "episode/score": 0.23072213403122532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23072213403122532}
{"step": 316600, "time": 10613.039693832397, "episode/length": 640.0, "episode/score": 0.21740237694257303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21740237694257303}
{"step": 317080, "time": 10628.14964222908, "episode/length": 640.0, "episode/score": 0.2669463708796229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2669463708796229}
{"step": 317304, "time": 10635.194276809692, "episode/length": 640.0, "episode/score": 0.2836822422489149, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2836822422489149}
{"step": 317328, "time": 10636.301247358322, "episode/length": 640.0, "episode/score": 0.09329676941092657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09329676941092657}
{"step": 317936, "time": 10655.37632060051, "episode/length": 640.0, "episode/score": 0.2532300792067872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2532300792067872}
{"step": 318792, "time": 10682.322521209717, "episode/length": 640.0, "episode/score": 0.17441839203524978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17441839203524978}
{"step": 320008, "time": 10733.802050352097, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10733.811355352402, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10733.819785356522, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10733.828128814697, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10733.83632016182, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10733.844505548477, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10733.85258102417, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10733.86109828949, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320352, "time": 10745.064390420914, "episode/length": 640.0, "episode/score": 0.1793054344026359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1793054344026359}
{"step": 321656, "time": 10786.558094024658, "episode/length": 640.0, "episode/score": 0.17749158858487135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17749158858487135}
{"step": 321728, "time": 10789.094086408615, "episode/length": 640.0, "episode/score": 0.17128866313714752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17128866313714752}
{"step": 322208, "time": 10805.249680757523, "episode/length": 640.0, "episode/score": 0.1939395522696259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1939395522696259}
{"step": 322432, "time": 10812.39602279663, "episode/length": 640.0, "episode/score": 0.20763619267768263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20763619267768263}
{"step": 322456, "time": 10812.94165468216, "episode/length": 640.0, "episode/score": 0.13449251550457575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13449251550457575}
{"step": 322472, "time": 10813.458881855011, "episode/length": 264.0, "episode/score": 0.12128956466676755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12128956466676755}
{"step": 323064, "time": 10832.224298000336, "episode/length": 640.0, "episode/score": 0.07799856767826441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07799856767826441}
{"step": 323920, "time": 10859.408773183823, "episode/length": 640.0, "episode/score": 0.16757674902271447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16757674902271447}
{"step": 325832, "time": 10919.679072380066, "episode/length": 421.0, "episode/score": 0.15880483846160587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15880483846160587}
{"step": 326784, "time": 10950.222123861313, "episode/length": 640.0, "episode/score": 0.09999555554566086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09999555554566086}
{"step": 326856, "time": 10952.291007041931, "episode/length": 640.0, "episode/score": 0.18424863267904357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18424863267904357}
{"step": 327336, "time": 10967.505334615707, "episode/length": 640.0, "episode/score": 0.1828363224968257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1828363224968257}
{"step": 327560, "time": 10974.652475357056, "episode/length": 640.0, "episode/score": 0.1389508136713289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1389508136713289}
{"step": 327600, "time": 10976.125874757767, "episode/length": 640.0, "episode/score": 0.046975182504638724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046975182504638724}
{"step": 328192, "time": 10995.3242893219, "episode/length": 640.0, "episode/score": 0.18581601040631313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18581601040631313}
{"step": 329048, "time": 11022.179494857788, "episode/length": 640.0, "episode/score": 0.061999853405723115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061999853405723115}
{"step": 330096, "time": 11066.945616006851, "eval_episode/length": 579.0, "eval_episode/score": 0.18578125536441803, "eval_episode/reward_rate": 0.0017241379310344827}
{"step": 330096, "time": 11068.106889486313, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 11068.116551399231, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 11068.126010894775, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 11068.13484621048, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 11068.143404722214, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 11068.152052164078, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 11068.160943746567, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330960, "time": 11095.642517328262, "episode/length": 640.0, "episode/score": 0.1995553750435306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1995553750435306}
{"step": 331912, "time": 11125.413652181625, "episode/length": 640.0, "episode/score": 0.18133369016055667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18133369016055667}
{"step": 331984, "time": 11127.922134637833, "episode/length": 640.0, "episode/score": 0.12258915092473899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12258915092473899}
{"step": 332464, "time": 11143.000997066498, "episode/length": 640.0, "episode/score": 0.15869268602881448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15869268602881448}
{"step": 332688, "time": 11150.13255405426, "episode/length": 640.0, "episode/score": 0.17457292301207872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17457292301207872}
{"step": 332728, "time": 11151.167660951614, "episode/length": 640.0, "episode/score": 0.1532299722538255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1532299722538255}
{"step": 333320, "time": 11169.709015369415, "episode/length": 640.0, "episode/score": 0.05985101053329345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05985101053329345}
{"step": 334176, "time": 11196.911096572876, "episode/length": 640.0, "episode/score": 0.12549179188204107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12549179188204107}
{"step": 334505, "time": 11208.164256334305, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1817832545230265, "train/action_min": 0.0, "train/action_std": 1.8351690204519975, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00026000679269935447, "train/actor_opt_grad_steps": 19865.0, "train/actor_opt_loss": -4.9191882007216154, "train/adv_mag": 0.0022333852554622447, "train/adv_max": 0.0021243313817601453, "train/adv_mean": 7.233480786286045e-05, "train/adv_min": -0.0018903331929131558, "train/adv_std": 0.00048329672840497406, "train/cont_avg": 0.998303865131579, "train/cont_loss_mean": 0.01253752928766373, "train/cont_loss_std": 0.23010076556054615, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.473734982808431, "train/cont_pos_acc": 0.9999999962354961, "train/cont_pos_loss": 0.0015642910025474663, "train/cont_pred": 0.9984369597936932, "train/cont_rate": 0.998303865131579, "train/dyn_loss_mean": 1.0000082097555463, "train/dyn_loss_std": 0.0002236377702119123, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.012625824953551943, "train/extr_critic_critic_opt_grad_steps": 19865.0, "train/extr_critic_critic_opt_loss": 13548.062068256579, "train/extr_critic_mag": 0.08133482368368851, "train/extr_critic_max": 0.08133482368368851, "train/extr_critic_mean": 0.08035928159952163, "train/extr_critic_min": 0.07907907649090415, "train/extr_critic_std": 0.00026190343587107856, "train/extr_return_normed_mag": 0.0030431708222941347, "train/extr_return_normed_max": 0.0030431708222941347, "train/extr_return_normed_mean": 0.0009045233573200868, "train/extr_return_normed_min": -0.0009022331943637446, "train/extr_return_normed_std": 0.0004883308590107941, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0825702680568946, "train/extr_return_raw_max": 0.0825702680568946, "train/extr_return_raw_mean": 0.08043162395295343, "train/extr_return_raw_min": 0.07862486404023672, "train/extr_return_raw_std": 0.0004883308576321915, "train/extr_reward_mag": 0.0008576637820193642, "train/extr_reward_max": 0.0008576637820193642, "train/extr_reward_mean": 0.00025702988319895476, "train/extr_reward_min": 5.127881702623869e-06, "train/extr_reward_std": 0.0002102451469430602, "train/image_loss_mean": 0.23238900711661892, "train/image_loss_std": 0.11885486402009662, "train/model_loss_mean": 0.8530651547406849, "train/model_loss_std": 0.277362587224496, "train/model_opt_grad_norm": 32.849908989354184, "train/model_opt_grad_steps": 19844.58947368421, "train/model_opt_loss": 2425.376478978207, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2842.1052631578946, "train/policy_entropy_mag": 1.9094678753300718, "train/policy_entropy_max": 1.9094678753300718, "train/policy_entropy_mean": 1.7677425591569198, "train/policy_entropy_min": 1.3817908042355587, "train/policy_entropy_std": 0.05848940575593396, "train/policy_logprob_mag": 3.4186911620591816, "train/policy_logprob_max": -0.544948003950872, "train/policy_logprob_mean": -1.7686068359174227, "train/policy_logprob_min": -3.4186911620591816, "train/policy_logprob_std": 0.590997640710128, "train/policy_randomness_mag": 0.9812724348745848, "train/policy_randomness_max": 0.9812724348745848, "train/policy_randomness_mean": 0.9084400189550299, "train/policy_randomness_min": 0.7101000450159374, "train/policy_randomness_std": 0.030057610316496147, "train/post_ent_mag": 48.10742775766473, "train/post_ent_max": 48.10742775766473, "train/post_ent_mean": 47.732652945267525, "train/post_ent_min": 47.38366255509226, "train/post_ent_std": 0.12404522582104331, "train/prior_ent_mag": 49.245073298404094, "train/prior_ent_max": 49.245073298404094, "train/prior_ent_mean": 47.11322629828202, "train/prior_ent_min": 45.57786664460835, "train/prior_ent_std": 0.563368580843273, "train/rep_loss_mean": 1.0000082097555463, "train/rep_loss_std": 0.0002236377702119123, "train/reward_avg": 0.00018074027263393968, "train/reward_loss_mean": 0.008133668918162584, "train/reward_loss_std": 0.013842749884842258, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0007662773132324219, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008133668923064281, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00017920940330154017, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7692589638184528, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.007979674264788628, "report/cont_loss_std": 0.19704727828502655, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.310412883758545, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0018189363181591034, "report/cont_pred": 0.9981825351715088, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.23140659928321838, "report/image_loss_std": 0.11474471539258957, "report/model_loss_mean": 0.8498733043670654, "report/model_loss_std": 0.23827823996543884, "report/post_ent_mag": 42.948341369628906, "report/post_ent_max": 42.948341369628906, "report/post_ent_mean": 42.614501953125, "report/post_ent_min": 42.34407424926758, "report/post_ent_std": 0.10457994043827057, "report/prior_ent_mag": 43.953590393066406, "report/prior_ent_max": 43.953590393066406, "report/prior_ent_mean": 42.09739303588867, "report/prior_ent_min": 40.42007827758789, "report/prior_ent_std": 0.5472723841667175, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00024461501743644476, "report/reward_loss_mean": 0.010486996732652187, "report/reward_loss_std": 0.016248321160674095, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0008701086044311523, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010486997663974762, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00020475266501307487, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0018189364345744252, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0018189364345744252, "eval/cont_pred": 0.9981825351715088, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0000481605529785, "eval/dyn_loss_std": 0.0015392978675663471, "eval/image_loss_mean": 0.2387310266494751, "eval/image_loss_std": 0.12212579697370529, "eval/model_loss_mean": 0.8416533470153809, "eval/model_loss_std": 0.12225723266601562, "eval/post_ent_mag": 42.92048645019531, "eval/post_ent_max": 42.92048645019531, "eval/post_ent_mean": 42.62328338623047, "eval/post_ent_min": 42.33612823486328, "eval/post_ent_std": 0.10533434897661209, "eval/prior_ent_mag": 44.18746566772461, "eval/prior_ent_max": 44.18746566772461, "eval/prior_ent_mean": 42.19872283935547, "eval/prior_ent_min": 40.70866394042969, "eval/prior_ent_std": 0.5680322051048279, "eval/rep_loss_mean": 1.0000481605529785, "eval/rep_loss_std": 0.0015392978675663471, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010744435712695122, "eval/reward_loss_std": 0.0014306791126728058, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0008113384246826172, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010744435712695122, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00016896857414394617, "eval/reward_rate": 0.0, "replay/size": 334001.0, "replay/inserts": 30352.0, "replay/samples": 30352.0, "replay/insert_wait_avg": 1.2921592594764078e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.443938975718754e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1491949088363926e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0067777633667, "timer/env.step_count": 3794.0, "timer/env.step_total": 34.10985565185547, "timer/env.step_frac": 0.03410962446489232, "timer/env.step_avg": 0.008990473287257635, "timer/env.step_min": 0.007485151290893555, "timer/env.step_max": 0.03442096710205078, "timer/replay._sample_count": 30352.0, "timer/replay._sample_total": 15.235778093338013, "timer/replay._sample_frac": 0.015235674829539286, "timer/replay._sample_avg": 0.0005019694943772408, "timer/replay._sample_min": 0.00034880638122558594, "timer/replay._sample_max": 0.01195073127746582, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5717.0, "timer/agent.policy_total": 58.37454915046692, "timer/agent.policy_frac": 0.05837415350426774, "timer/agent.policy_avg": 0.010210696020721869, "timer/agent.policy_min": 0.008445978164672852, "timer/agent.policy_max": 0.08651947975158691, "timer/dataset_train_count": 1897.0, "timer/dataset_train_total": 0.20755243301391602, "timer/dataset_train_frac": 0.00020755102628217337, "timer/dataset_train_avg": 0.0001094108766546737, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0002593994140625, "timer/agent.train_count": 1897.0, "timer/agent.train_total": 851.5230026245117, "timer/agent.train_frac": 0.8515172312422157, "timer/agent.train_avg": 0.4488787573139229, "timer/agent.train_min": 0.43433547019958496, "timer/agent.train_max": 1.5340251922607422, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46475887298583984, "timer/agent.report_frac": 0.0004647557229815262, "timer/agent.report_avg": 0.23237943649291992, "timer/agent.report_min": 0.22246384620666504, "timer/agent.report_max": 0.2422950267791748, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1947873064485676e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 30.351271643985562}
{"step": 336088, "time": 11258.397437095642, "episode/length": 640.0, "episode/score": 0.11598624891666987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11598624891666987}
{"step": 337040, "time": 11288.998179197311, "episode/length": 640.0, "episode/score": 0.07341728724873064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07341728724873064}
{"step": 337112, "time": 11291.048685312271, "episode/length": 640.0, "episode/score": 0.16193393751848362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16193393751848362}
{"step": 337592, "time": 11306.163796663284, "episode/length": 640.0, "episode/score": 0.17120278135541867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17120278135541867}
{"step": 337816, "time": 11313.195581912994, "episode/length": 640.0, "episode/score": 0.12865196367897624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12865196367897624}
{"step": 337856, "time": 11314.67617893219, "episode/length": 640.0, "episode/score": 0.12883249095415295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12883249095415295}
{"step": 338448, "time": 11333.395479440689, "episode/length": 640.0, "episode/score": 0.16817321448996836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16817321448996836}
{"step": 339304, "time": 11360.127107858658, "episode/length": 640.0, "episode/score": 0.0943834616570598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0943834616570598}
{"step": 340080, "time": 11397.34536075592, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11397.354847669601, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11397.364111661911, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11397.372501373291, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11397.380781173706, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11397.389012336731, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11397.397112369537, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11397.405446767807, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 341216, "time": 11433.15792298317, "episode/length": 640.0, "episode/score": 0.12588487931657255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12588487931657255}
{"step": 342168, "time": 11462.968220949173, "episode/length": 640.0, "episode/score": 0.08202358376360053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08202358376360053}
{"step": 342240, "time": 11465.466795444489, "episode/length": 640.0, "episode/score": 0.1051756449644472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1051756449644472}
{"step": 342720, "time": 11480.657209396362, "episode/length": 640.0, "episode/score": 0.04619041340617969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04619041340617969}
{"step": 342944, "time": 11487.707280397415, "episode/length": 640.0, "episode/score": 0.10750808319244243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10750808319244243}
{"step": 342984, "time": 11488.749559879303, "episode/length": 640.0, "episode/score": 0.1824330141387236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1824330141387236}
{"step": 343576, "time": 11507.368098974228, "episode/length": 640.0, "episode/score": 0.1446910270914259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1446910270914259}
{"step": 344432, "time": 11535.479822397232, "episode/length": 640.0, "episode/score": 0.2175267721969476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2175267721969476}
{"step": 346344, "time": 11596.028020858765, "episode/length": 640.0, "episode/score": 0.14681386819984255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14681386819984255}
{"step": 347296, "time": 11626.586742639542, "episode/length": 640.0, "episode/score": 0.22308887322930104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22308887322930104}
{"step": 347368, "time": 11628.689445972443, "episode/length": 640.0, "episode/score": 0.16719896842164417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16719896842164417}
{"step": 347848, "time": 11644.02890586853, "episode/length": 640.0, "episode/score": 0.17086654154462622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17086654154462622}
{"step": 348072, "time": 11651.172899961472, "episode/length": 640.0, "episode/score": 0.1849283864768836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1849283864768836}
{"step": 348112, "time": 11652.710149049759, "episode/length": 640.0, "episode/score": 0.19622854239963772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19622854239963772}
{"step": 348704, "time": 11671.699015140533, "episode/length": 640.0, "episode/score": 0.16614104582106393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16614104582106393}
{"step": 349560, "time": 11698.894787549973, "episode/length": 640.0, "episode/score": 0.19223954303373603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19223954303373603}
{"step": 350064, "time": 11726.866217136383, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11726.875103712082, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11726.883395671844, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11726.891684055328, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11726.89963722229, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11726.907320737839, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11726.915061473846, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11726.92278265953, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 351472, "time": 11771.508249044418, "episode/length": 640.0, "episode/score": 0.17029991014402412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17029991014402412}
{"step": 352424, "time": 11801.781198263168, "episode/length": 640.0, "episode/score": 0.23117092040376974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23117092040376974}
{"step": 352496, "time": 11804.264449357986, "episode/length": 640.0, "episode/score": 0.15964164016423865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15964164016423865}
{"step": 352976, "time": 11819.383862257004, "episode/length": 640.0, "episode/score": 0.26455842781001593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26455842781001593}
{"step": 353200, "time": 11826.414202928543, "episode/length": 640.0, "episode/score": 0.23854535858845338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23854535858845338}
{"step": 353240, "time": 11827.479834318161, "episode/length": 640.0, "episode/score": 0.19533684180680666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19533684180680666}
{"step": 353832, "time": 11846.176927804947, "episode/length": 640.0, "episode/score": 0.22015694478432124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22015694478432124}
{"step": 354688, "time": 11873.436125993729, "episode/length": 640.0, "episode/score": 0.16072291070764777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16072291070764777}
{"step": 356600, "time": 11933.527769804, "episode/length": 640.0, "episode/score": 0.1518161569708809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1518161569708809}
{"step": 357552, "time": 11963.91004562378, "episode/length": 640.0, "episode/score": 0.1897050634097468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1897050634097468}
{"step": 357624, "time": 11965.970801353455, "episode/length": 640.0, "episode/score": 0.15595328577074952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15595328577074952}
{"step": 358104, "time": 11981.205198049545, "episode/length": 640.0, "episode/score": 0.16345994251025786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16345994251025786}
{"step": 358328, "time": 11988.448611021042, "episode/length": 640.0, "episode/score": 0.1560094950619373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1560094950619373}
{"step": 358368, "time": 11989.976935625076, "episode/length": 640.0, "episode/score": 0.183740661842819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.183740661842819}
{"step": 358960, "time": 12008.845613718033, "episode/length": 640.0, "episode/score": 0.08336769315434367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08336769315434367}
{"step": 359816, "time": 12035.648803949356, "episode/length": 640.0, "episode/score": 0.24971473434487734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24971473434487734}
{"step": 360048, "time": 12055.022224903107, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 12055.031158208847, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 12055.03939652443, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 12055.04747724533, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 12055.055394172668, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 12055.06326007843, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 12055.071039676666, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 12055.07889509201, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 361728, "time": 12108.852277994156, "episode/length": 640.0, "episode/score": 0.18384717845120235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18384717845120235}
{"step": 362680, "time": 12138.892094373703, "episode/length": 640.0, "episode/score": 0.18157152842005075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18157152842005075}
{"step": 362752, "time": 12141.415056228638, "episode/length": 640.0, "episode/score": 0.2173070912588173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2173070912588173}
{"step": 363232, "time": 12156.715553998947, "episode/length": 640.0, "episode/score": 0.22695910006203235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22695910006203235}
{"step": 363456, "time": 12163.82550239563, "episode/length": 640.0, "episode/score": 0.16289927808742277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16289927808742277}
{"step": 363496, "time": 12164.899324178696, "episode/length": 640.0, "episode/score": 0.22374746179190197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22374746179190197}
{"step": 364088, "time": 12183.781547307968, "episode/length": 640.0, "episode/score": 0.13539668736476074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13539668736476074}
{"step": 364825, "time": 12208.467818975449, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2046334402901784, "train/action_min": 0.0, "train/action_std": 1.8548549382144182, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00026608715970290913, "train/actor_opt_grad_steps": 21760.0, "train/actor_opt_loss": -5.26193299684575, "train/adv_mag": 0.002608312106637097, "train/adv_max": 0.0024915681708426703, "train/adv_mean": 5.467772006438411e-05, "train/adv_min": -0.0020162422190267574, "train/adv_std": 0.0005151112931940665, "train/cont_avg": 0.9984499007936508, "train/cont_loss_mean": 0.011595421623458307, "train/cont_loss_std": 0.21988670765842872, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.446040915815454, "train/cont_pos_acc": 0.9999999965309466, "train/cont_pos_loss": 0.0016024080905866214, "train/cont_pred": 0.9983988987705695, "train/cont_rate": 0.9984499007936508, "train/dyn_loss_mean": 1.0001046720635953, "train/dyn_loss_std": 0.0008032313415906318, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.01304711726486126, "train/extr_critic_critic_opt_grad_steps": 21760.0, "train/extr_critic_critic_opt_loss": 13553.459594080688, "train/extr_critic_mag": 0.08341513361249651, "train/extr_critic_max": 0.08341513361249651, "train/extr_critic_mean": 0.08245556352157442, "train/extr_critic_min": 0.08126961049579438, "train/extr_critic_std": 0.0002632703989831652, "train/extr_return_normed_mag": 0.003515137645302626, "train/extr_return_normed_max": 0.003515137645302626, "train/extr_return_normed_mean": 0.0009350411838139827, "train/extr_return_normed_min": -0.000998269431490116, "train/extr_return_normed_std": 0.0005295558302249345, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08509031371780174, "train/extr_return_raw_max": 0.08509031371780174, "train/extr_return_raw_mean": 0.08251022196635999, "train/extr_return_raw_min": 0.080576906641009, "train/extr_return_raw_std": 0.0005295558309948772, "train/extr_reward_mag": 0.0011270254377334836, "train/extr_reward_max": 0.0011270254377334836, "train/extr_reward_mean": 0.00025765461555839805, "train/extr_reward_min": 2.3015592464063534e-06, "train/extr_reward_std": 0.00021556272508980578, "train/image_loss_mean": 0.22398061522100338, "train/image_loss_std": 0.12130728734548761, "train/model_loss_mean": 0.8440309952175806, "train/model_loss_std": 0.26824568472211324, "train/model_opt_grad_norm": 31.877922643429386, "train/model_opt_grad_steps": 21738.100529100528, "train/model_opt_loss": 2501.4996544570517, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2962.962962962963, "train/policy_entropy_mag": 1.9143034434192394, "train/policy_entropy_max": 1.9143034434192394, "train/policy_entropy_mean": 1.7699904227382923, "train/policy_entropy_min": 1.3125045703201699, "train/policy_entropy_std": 0.06324038315544683, "train/policy_logprob_mag": 3.413844958814994, "train/policy_logprob_max": -0.4890335982754117, "train/policy_logprob_mean": -1.7699096606522011, "train/policy_logprob_min": -3.413844958814994, "train/policy_logprob_std": 0.5926420751702849, "train/policy_randomness_mag": 0.983757423976111, "train/policy_randomness_max": 0.983757423976111, "train/policy_randomness_mean": 0.9095951946324141, "train/policy_randomness_min": 0.6744939612333106, "train/policy_randomness_std": 0.032499129810030496, "train/post_ent_mag": 37.84316948986558, "train/post_ent_max": 37.84316948986558, "train/post_ent_mean": 37.50599504904772, "train/post_ent_min": 37.271559023983265, "train/post_ent_std": 0.10394751367272523, "train/prior_ent_mag": 40.92185550265842, "train/prior_ent_max": 40.92185550265842, "train/prior_ent_mean": 39.24528913144712, "train/prior_ent_min": 37.6412072358308, "train/prior_ent_std": 0.5228687650942928, "train/rep_loss_mean": 1.0001046720635953, "train/rep_loss_std": 0.0008032313415906318, "train/reward_avg": 0.00018682801920770318, "train/reward_loss_mean": 0.008392130707208284, "train/reward_loss_std": 0.013888916892625352, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0007911157355737434, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008392130719527366, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00018608245491074822, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7709607291728893, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.007876232266426086, "report/cont_loss_std": 0.20156162977218628, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.454699516296387, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001574350637383759, "report/cont_pred": 0.9984266757965088, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.21339166164398193, "report/image_loss_std": 0.11252715438604355, "report/model_loss_mean": 0.8301035165786743, "report/model_loss_std": 0.2384749948978424, "report/post_ent_mag": 31.70929718017578, "report/post_ent_max": 31.70929718017578, "report/post_ent_mean": 31.28459930419922, "report/post_ent_min": 30.95616340637207, "report/post_ent_std": 0.13430120050907135, "report/prior_ent_mag": 35.98505401611328, "report/prior_ent_max": 35.98505401611328, "report/prior_ent_mean": 33.78157043457031, "report/prior_ent_min": 31.38851547241211, "report/prior_ent_std": 0.7334700226783752, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00019586985581554472, "report/reward_loss_mean": 0.008835658431053162, "report/reward_loss_std": 0.013968787156045437, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0007506608963012695, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008835658431053162, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00018604786600917578, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014178113080561161, "eval/cont_loss_std": 0.2849119007587433, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.454699516296387, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001574350637383759, "eval/cont_pred": 0.9984266757965088, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2518647611141205, "eval/image_loss_std": 0.14495044946670532, "eval/model_loss_mean": 0.8668790459632874, "eval/model_loss_std": 0.3177812695503235, "eval/post_ent_mag": 31.710538864135742, "eval/post_ent_max": 31.710538864135742, "eval/post_ent_mean": 31.290807723999023, "eval/post_ent_min": 31.003280639648438, "eval/post_ent_std": 0.14262162148952484, "eval/prior_ent_mag": 35.971763610839844, "eval/prior_ent_max": 35.971763610839844, "eval/prior_ent_mean": 33.563941955566406, "eval/prior_ent_min": 31.16546058654785, "eval/prior_ent_std": 0.8280101418495178, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0008361386135220528, "eval/reward_loss_std": 0.0010995978955179453, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0007361173629760742, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0008361386135220528, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00013154384214431047, "eval/reward_rate": 0.0, "replay/size": 364321.0, "replay/inserts": 30320.0, "replay/samples": 30320.0, "replay/insert_wait_avg": 1.2900080718591534e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.439718890630475e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0959598711859851e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2813470363617, "timer/env.step_count": 3790.0, "timer/env.step_total": 34.463433265686035, "timer/env.step_frac": 0.03445373980809945, "timer/env.step_avg": 0.009093254159811619, "timer/env.step_min": 0.007512569427490234, "timer/env.step_max": 0.0431523323059082, "timer/replay._sample_count": 30320.0, "timer/replay._sample_total": 15.262361288070679, "timer/replay._sample_frac": 0.01525806847572443, "timer/replay._sample_avg": 0.0005033760319284524, "timer/replay._sample_min": 0.00038242340087890625, "timer/replay._sample_max": 0.010825872421264648, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5713.0, "timer/agent.policy_total": 58.81193780899048, "timer/agent.policy_frac": 0.05879539589860269, "timer/agent.policy_avg": 0.010294405357778834, "timer/agent.policy_min": 0.008793354034423828, "timer/agent.policy_max": 0.09181571006774902, "timer/dataset_train_count": 1895.0, "timer/dataset_train_total": 0.2112874984741211, "timer/dataset_train_frac": 0.00021122807008260694, "timer/dataset_train_avg": 0.00011149736067235942, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0003688335418701172, "timer/agent.train_count": 1895.0, "timer/agent.train_total": 851.0435283184052, "timer/agent.train_frac": 0.8508041570902836, "timer/agent.train_avg": 0.4490994872392639, "timer/agent.train_min": 0.4362778663635254, "timer/agent.train_max": 0.6312460899353027, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4828190803527832, "timer/agent.report_frac": 0.00048268327884277946, "timer/agent.report_avg": 0.2414095401763916, "timer/agent.report_min": 0.23445773124694824, "timer/agent.report_max": 0.24836134910583496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.1484832763671875e-05, "timer/dataset_eval_frac": 4.1473164411776084e-08, "timer/dataset_eval_avg": 4.1484832763671875e-05, "timer/dataset_eval_min": 4.1484832763671875e-05, "timer/dataset_eval_max": 4.1484832763671875e-05, "fps": 30.310934204285605}
{"step": 364944, "time": 12212.326403856277, "episode/length": 640.0, "episode/score": 0.21676828716746854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21676828716746854}
{"step": 366856, "time": 12273.324124097824, "episode/length": 640.0, "episode/score": 0.16579245785965213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16579245785965213}
{"step": 367808, "time": 12303.513613462448, "episode/length": 640.0, "episode/score": 0.05635663492628851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05635663492628851}
{"step": 367880, "time": 12305.583896636963, "episode/length": 640.0, "episode/score": 0.07623220080790816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07623220080790816}
{"step": 368360, "time": 12320.772449016571, "episode/length": 640.0, "episode/score": 0.09357626149531484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09357626149531484}
{"step": 368584, "time": 12327.750114440918, "episode/length": 640.0, "episode/score": 0.0796052944172061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0796052944172061}
{"step": 368624, "time": 12329.244683027267, "episode/length": 640.0, "episode/score": 0.10614942012517758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10614942012517758}
{"step": 369216, "time": 12348.452356100082, "episode/length": 640.0, "episode/score": 0.20101160008471197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20101160008471197}
{"step": 370032, "time": 12386.256285190582, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12386.266095876694, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12386.274480819702, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12386.282685041428, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12386.290876865387, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12386.29920244217, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12386.307401180267, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12386.31563425064, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370072, "time": 12387.357120275497, "episode/length": 640.0, "episode/score": 0.2295896946142193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2295896946142193}
{"step": 371984, "time": 12447.973577976227, "episode/length": 640.0, "episode/score": 0.225615978486843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.225615978486843}
{"step": 372352, "time": 12459.530378103256, "episode/length": 284.0, "episode/score": 0.11429835256387832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11429835256387832}
{"step": 372936, "time": 12477.783322095871, "episode/length": 640.0, "episode/score": 0.19883879765703227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19883879765703227}
{"step": 373008, "time": 12480.270624399185, "episode/length": 640.0, "episode/score": 0.13944011038245208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13944011038245208}
{"step": 373488, "time": 12495.403043031693, "episode/length": 640.0, "episode/score": 0.21596533379937455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21596533379937455}
{"step": 373712, "time": 12502.545069217682, "episode/length": 640.0, "episode/score": 0.12424532139840494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12424532139840494}
{"step": 373752, "time": 12503.575739860535, "episode/length": 640.0, "episode/score": 0.22577614136790203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22577614136790203}
{"step": 374344, "time": 12522.141846179962, "episode/length": 640.0, "episode/score": 0.14597247552646309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14597247552646309}
{"step": 377112, "time": 12610.877771377563, "episode/length": 640.0, "episode/score": 0.16663491609631365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16663491609631365}
{"step": 377480, "time": 12622.708158254623, "episode/length": 640.0, "episode/score": 0.1800589076453889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1800589076453889}
{"step": 378064, "time": 12641.232662677765, "episode/length": 640.0, "episode/score": 0.21666209962830862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21666209962830862}
{"step": 378136, "time": 12643.2730717659, "episode/length": 640.0, "episode/score": 0.18057317864241895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18057317864241895}
{"step": 378616, "time": 12658.390104532242, "episode/length": 640.0, "episode/score": 0.1102471424105147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1102471424105147}
{"step": 378840, "time": 12665.47920179367, "episode/length": 640.0, "episode/score": 0.13196444059980195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13196444059980195}
{"step": 378880, "time": 12666.971243619919, "episode/length": 640.0, "episode/score": 0.1485384062092976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1485384062092976}
{"step": 379472, "time": 12685.625791549683, "episode/length": 640.0, "episode/score": 0.12101956854036189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12101956854036189}
{"step": 380016, "time": 12706.642800092697, "eval_episode/length": 170.0, "eval_episode/score": 0.760937511920929, "eval_episode/reward_rate": 0.005847953216374269}
{"step": 380016, "time": 12711.815013885498, "eval_episode/length": 454.0, "eval_episode/score": 0.36156249046325684, "eval_episode/reward_rate": 0.002197802197802198}
{"step": 380016, "time": 12715.158673524857, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12715.168222665787, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12715.17660021782, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12715.184908390045, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12715.193130731583, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12715.201127529144, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 382240, "time": 12785.065016269684, "episode/length": 640.0, "episode/score": 0.1757383518140614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1757383518140614}
{"step": 382608, "time": 12796.644414901733, "episode/length": 640.0, "episode/score": 0.20849499662364224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20849499662364224}
{"step": 383192, "time": 12814.848356723785, "episode/length": 640.0, "episode/score": 0.11750585429626881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11750585429626881}
{"step": 383264, "time": 12817.353301048279, "episode/length": 640.0, "episode/score": 0.2341725783872448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2341725783872448}
{"step": 383744, "time": 12832.76722240448, "episode/length": 640.0, "episode/score": 0.12570779598036097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12570779598036097}
{"step": 383968, "time": 12839.938824415207, "episode/length": 640.0, "episode/score": 0.14614548961560558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14614548961560558}
{"step": 384008, "time": 12840.996150016785, "episode/length": 640.0, "episode/score": 0.22765508939045276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22765508939045276}
{"step": 384600, "time": 12859.94515633583, "episode/length": 640.0, "episode/score": 0.15554631999833646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15554631999833646}
{"step": 387368, "time": 12947.49939084053, "episode/length": 640.0, "episode/score": 0.11780665230907061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11780665230907061}
{"step": 387736, "time": 12959.03094959259, "episode/length": 640.0, "episode/score": 0.09605890902082592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09605890902082592}
{"step": 388320, "time": 12977.677455186844, "episode/length": 640.0, "episode/score": 0.23568734560279836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23568734560279836}
{"step": 388392, "time": 12979.71472811699, "episode/length": 640.0, "episode/score": 0.11362532642050382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11362532642050382}
{"step": 388872, "time": 12994.82593178749, "episode/length": 640.0, "episode/score": 0.20942800768148118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20942800768148118}
{"step": 389096, "time": 13001.972670555115, "episode/length": 640.0, "episode/score": 0.20311761653238136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20311761653238136}
{"step": 389136, "time": 13003.479173183441, "episode/length": 640.0, "episode/score": 0.17796501372311013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17796501372311013}
{"step": 389728, "time": 13022.208886623383, "episode/length": 640.0, "episode/score": 0.13544376219226706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13544376219226706}
{"step": 390000, "time": 13043.133332967758, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 13043.142201662064, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 13043.150178670883, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 13043.158264160156, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 13043.166336297989, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 13043.174711227417, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 13043.182572126389, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 13043.190463542938, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 392496, "time": 13122.390267848969, "episode/length": 640.0, "episode/score": 0.16000045224268433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16000045224268433}
{"step": 392864, "time": 13134.091625452042, "episode/length": 640.0, "episode/score": 0.179799351572683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.179799351572683}
{"step": 393448, "time": 13152.930057287216, "episode/length": 640.0, "episode/score": 0.20313792184731483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20313792184731483}
{"step": 393520, "time": 13155.436992645264, "episode/length": 640.0, "episode/score": 0.14354847070853793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14354847070853793}
{"step": 394000, "time": 13170.597424030304, "episode/length": 640.0, "episode/score": 0.04317563082651077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04317563082651077}
{"step": 394224, "time": 13177.672048568726, "episode/length": 640.0, "episode/score": 0.10820016640275298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10820016640275298}
{"step": 394264, "time": 13178.719455242157, "episode/length": 640.0, "episode/score": 0.1535394495411424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1535394495411424}
{"step": 394856, "time": 13197.38240480423, "episode/length": 640.0, "episode/score": 0.09479840100192405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09479840100192405}
{"step": 395185, "time": 13208.454333782196, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2192774722450657, "train/action_min": 0.0, "train/action_std": 1.8627419201951279, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00033238191750378494, "train/actor_opt_grad_steps": 23655.0, "train/actor_opt_loss": -4.7242012695262305, "train/adv_mag": 0.003355932078863445, "train/adv_max": 0.0033116452395915985, "train/adv_mean": 9.408346823204881e-05, "train/adv_min": -0.0024233769037221606, "train/adv_std": 0.0006575429115113558, "train/cont_avg": 0.9985043174342105, "train/cont_loss_mean": 0.011209306405170968, "train/cont_loss_std": 0.21432203591397483, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.4569369751886025, "train/cont_pos_acc": 0.9999999974903307, "train/cont_pos_loss": 0.0015707302856945286, "train/cont_pred": 0.9984305215509315, "train/cont_rate": 0.9985043174342105, "train/dyn_loss_mean": 1.0000082423812464, "train/dyn_loss_std": 0.00023188547592757172, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.016988357053732646, "train/extr_critic_critic_opt_grad_steps": 23655.0, "train/extr_critic_critic_opt_loss": 13536.256080386513, "train/extr_critic_mag": 0.08705647870113975, "train/extr_critic_max": 0.08705647870113975, "train/extr_critic_mean": 0.08546051579086404, "train/extr_critic_min": 0.08317910495557283, "train/extr_critic_std": 0.0004547521812032516, "train/extr_return_normed_mag": 0.004889921020520361, "train/extr_return_normed_max": 0.004889921020520361, "train/extr_return_normed_mean": 0.0014039930769956157, "train/extr_return_normed_min": -0.001444594758121591, "train/extr_return_normed_std": 0.0007835825111741495, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08904050796439773, "train/extr_return_raw_max": 0.08904050796439773, "train/extr_return_raw_mean": 0.08555458454709304, "train/extr_return_raw_min": 0.08270599218575578, "train/extr_return_raw_std": 0.0007835825093360127, "train/extr_reward_mag": 0.001195053677809866, "train/extr_reward_max": 0.001195053677809866, "train/extr_reward_mean": 0.0002674713483429514, "train/extr_reward_min": 3.022269198769017e-06, "train/extr_reward_std": 0.0002298354834477466, "train/image_loss_mean": 0.2006597881254397, "train/image_loss_std": 0.12012473070307782, "train/model_loss_mean": 0.8205077550913158, "train/model_loss_std": 0.26385394323029016, "train/model_opt_grad_norm": 29.555499699241235, "train/model_opt_grad_steps": 23631.373684210525, "train/model_opt_loss": 2286.555705180921, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2789.4736842105262, "train/policy_entropy_mag": 1.924102216645291, "train/policy_entropy_max": 1.924102216645291, "train/policy_entropy_mean": 1.7519529374022234, "train/policy_entropy_min": 1.1238411257141514, "train/policy_entropy_std": 0.08655830555056271, "train/policy_logprob_mag": 3.618096913789448, "train/policy_logprob_max": -0.36322177821084073, "train/policy_logprob_mean": -1.7519198141599956, "train/policy_logprob_min": -3.618096913789448, "train/policy_logprob_std": 0.6268291341631036, "train/policy_randomness_mag": 0.9887929979123568, "train/policy_randomness_max": 0.9887929979123568, "train/policy_randomness_mean": 0.9003257610295948, "train/policy_randomness_min": 0.5775401273840353, "train/policy_randomness_std": 0.04448217255504508, "train/post_ent_mag": 28.217322741056744, "train/post_ent_max": 28.217322741056744, "train/post_ent_mean": 27.698125507957055, "train/post_ent_min": 27.41415733538176, "train/post_ent_std": 0.15486065533600354, "train/prior_ent_mag": 31.628766541731984, "train/prior_ent_max": 31.628766541731984, "train/prior_ent_mean": 28.282538223266602, "train/prior_ent_min": 25.820187147040116, "train/prior_ent_std": 0.9468445900239443, "train/rep_loss_mean": 1.0000082423812464, "train/rep_loss_std": 0.00023188547592757172, "train/reward_avg": 0.00019343288624536637, "train/reward_loss_mean": 0.008633694724228822, "train/reward_loss_std": 0.013989839183264657, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0008652003187882273, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008633694677662692, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00019186917986524732, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7464770759854997, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02690233662724495, "report/cont_loss_std": 0.40569937229156494, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.505402565002441, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.001496457727625966, "report/cont_pred": 0.998504638671875, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1884276270866394, "report/image_loss_std": 0.12880291044712067, "report/model_loss_mean": 0.8238985538482666, "report/model_loss_std": 0.42894113063812256, "report/post_ent_mag": 24.155900955200195, "report/post_ent_max": 24.155900955200195, "report/post_ent_mean": 23.596166610717773, "report/post_ent_min": 23.323776245117188, "report/post_ent_std": 0.16933301091194153, "report/prior_ent_mag": 26.66168975830078, "report/prior_ent_max": 26.66168975830078, "report/prior_ent_mean": 23.24425506591797, "report/prior_ent_min": 21.04515838623047, "report/prior_ent_std": 0.9449397325515747, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00019372548558749259, "report/reward_loss_mean": 0.008568556979298592, "report/reward_loss_std": 0.014434431679546833, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0009514093399047852, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008568556979298592, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00019874796271324158, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014199399389326572, "eval/cont_loss_std": 0.2871539294719696, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.505402565002441, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001496457727625966, "eval/cont_pred": 0.998504638671875, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26254764199256897, "eval/image_loss_std": 0.16182368993759155, "eval/model_loss_mean": 0.8777127265930176, "eval/model_loss_std": 0.3251229226589203, "eval/post_ent_mag": 24.155900955200195, "eval/post_ent_max": 24.155900955200195, "eval/post_ent_mean": 23.605194091796875, "eval/post_ent_min": 23.331161499023438, "eval/post_ent_std": 0.1669733077287674, "eval/prior_ent_mag": 26.795860290527344, "eval/prior_ent_max": 26.795860290527344, "eval/prior_ent_mean": 23.212554931640625, "eval/prior_ent_min": 20.879512786865234, "eval/prior_ent_std": 0.9805546998977661, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0009656809270381927, "eval/reward_loss_std": 0.0013551987940445542, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0009045600891113281, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009656809270381927, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001518850913271308, "eval/reward_rate": 0.0, "replay/size": 394681.0, "replay/inserts": 30360.0, "replay/samples": 30352.0, "replay/insert_wait_avg": 1.30272665513834e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.432627604016519e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1208028887561753e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9744193553925, "timer/env.step_count": 3795.0, "timer/env.step_total": 34.439170837402344, "timer/env.step_frac": 0.03444005183612863, "timer/env.step_avg": 0.009074880326061224, "timer/env.step_min": 0.007530689239501953, "timer/env.step_max": 0.048453330993652344, "timer/replay._sample_count": 30352.0, "timer/replay._sample_total": 15.37909722328186, "timer/replay._sample_frac": 0.015379490640566183, "timer/replay._sample_avg": 0.0005066913950738621, "timer/replay._sample_min": 0.0003821849822998047, "timer/replay._sample_max": 0.03427743911743164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5718.0, "timer/agent.policy_total": 58.762792348861694, "timer/agent.policy_frac": 0.05876429557742247, "timer/agent.policy_avg": 0.010276808735372804, "timer/agent.policy_min": 0.008784294128417969, "timer/agent.policy_max": 0.09791731834411621, "timer/dataset_train_count": 1897.0, "timer/dataset_train_total": 0.20563626289367676, "timer/dataset_train_frac": 0.00020564152333640178, "timer/dataset_train_avg": 0.00010840077116166407, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0005979537963867188, "timer/agent.train_count": 1897.0, "timer/agent.train_total": 849.9425230026245, "timer/agent.train_frac": 0.8499642656364329, "timer/agent.train_avg": 0.44804561043891644, "timer/agent.train_min": 0.4349849224090576, "timer/agent.train_max": 0.5968327522277832, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46763181686401367, "timer/agent.report_frac": 0.00046764377949333984, "timer/agent.report_avg": 0.23381590843200684, "timer/agent.report_min": 0.2231905460357666, "timer/agent.report_max": 0.24444127082824707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051835880429058e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 30.3602522237274}
{"step": 397624, "time": 13285.415163040161, "episode/length": 640.0, "episode/score": 0.13503881421684127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13503881421684127}
{"step": 397992, "time": 13297.07627940178, "episode/length": 640.0, "episode/score": 0.09385632128498855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09385632128498855}
{"step": 398576, "time": 13316.021708011627, "episode/length": 640.0, "episode/score": 0.1821285643963506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1821285643963506}
{"step": 398648, "time": 13318.089581251144, "episode/length": 640.0, "episode/score": 0.1255686122472639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1255686122472639}
{"step": 399128, "time": 13333.307565450668, "episode/length": 640.0, "episode/score": 0.12105471388701972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12105471388701972}
{"step": 399352, "time": 13340.501326322556, "episode/length": 640.0, "episode/score": 0.15914655544611378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15914655544611378}
{"step": 399392, "time": 13341.987133264542, "episode/length": 640.0, "episode/score": 0.12377816501970074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12377816501970074}
{"step": 399984, "time": 13360.786240577698, "episode/length": 640.0, "episode/score": 0.08808279842293132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08808279842293132}
{"step": 400088, "time": 13375.353043079376, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13375.36340546608, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13375.37146282196, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13375.379121303558, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13375.387744665146, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13375.395493984222, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13375.403070926666, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13375.410677909851, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 402752, "time": 13461.19850230217, "episode/length": 640.0, "episode/score": 0.09026800183812611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09026800183812611}
{"step": 403120, "time": 13474.194288492203, "episode/length": 640.0, "episode/score": 0.12431950530069003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12431950530069003}
{"step": 403704, "time": 13492.700824737549, "episode/length": 640.0, "episode/score": 0.05258094674141489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05258094674141489}
{"step": 403776, "time": 13495.1868891716, "episode/length": 640.0, "episode/score": 0.0681353720609934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0681353720609934}
{"step": 404256, "time": 13510.301635026932, "episode/length": 640.0, "episode/score": 0.050727775882336346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050727775882336346}
{"step": 404480, "time": 13517.426664590836, "episode/length": 640.0, "episode/score": 0.10868292476632746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10868292476632746}
{"step": 404520, "time": 13518.466698169708, "episode/length": 640.0, "episode/score": 0.06213199441725692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06213199441725692}
{"step": 405112, "time": 13537.143651008606, "episode/length": 640.0, "episode/score": 0.07557035604756379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07557035604756379}
{"step": 407880, "time": 13624.504925489426, "episode/length": 640.0, "episode/score": 0.1548141380680761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1548141380680761}
{"step": 408248, "time": 13636.137553453445, "episode/length": 640.0, "episode/score": 0.07701040402105264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07701040402105264}
{"step": 408832, "time": 13654.685247182846, "episode/length": 640.0, "episode/score": 0.17534414698874912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17534414698874912}
{"step": 408904, "time": 13656.751487970352, "episode/length": 640.0, "episode/score": 0.15485833232983737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15485833232983737}
{"step": 409384, "time": 13671.997889995575, "episode/length": 640.0, "episode/score": 0.17777590288952183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17777590288952183}
{"step": 409608, "time": 13679.317375898361, "episode/length": 640.0, "episode/score": 0.1818169714383373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1818169714383373}
{"step": 409648, "time": 13681.035666704178, "episode/length": 640.0, "episode/score": 0.15545919408921804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15545919408921804}
{"step": 410072, "time": 13706.345778226852, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13706.354840517044, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13706.362868785858, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13706.370789051056, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13706.378964424133, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13706.387177944183, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13706.395067453384, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13706.402626276016, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410240, "time": 13711.889733552933, "episode/length": 640.0, "episode/score": 0.14473491876668731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14473491876668731}
{"step": 413008, "time": 13799.014062643051, "episode/length": 640.0, "episode/score": 0.18658549350342923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18658549350342923}
{"step": 413280, "time": 13807.493999958038, "episode/length": 546.0, "episode/score": 0.185382129063413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.185382129063413}
{"step": 413376, "time": 13810.495258331299, "episode/length": 640.0, "episode/score": 0.2470515069068142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2470515069068142}
{"step": 413920, "time": 13827.661619663239, "episode/length": 566.0, "episode/score": 0.13404657877529758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13404657877529758}
{"step": 413960, "time": 13828.696013212204, "episode/length": 640.0, "episode/score": 0.148136847173987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.148136847173987}
{"step": 414736, "time": 13853.261489629745, "episode/length": 640.0, "episode/score": 0.17394804773289252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17394804773289252}
{"step": 414776, "time": 13854.295056819916, "episode/length": 640.0, "episode/score": 0.1276641483894423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1276641483894423}
{"step": 415368, "time": 13872.903615236282, "episode/length": 640.0, "episode/score": 0.0751459510647976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0751459510647976}
{"step": 416584, "time": 13911.23020362854, "episode/length": 446.0, "episode/score": 0.08541379607413546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08541379607413546}
{"step": 418408, "time": 13969.493685483932, "episode/length": 640.0, "episode/score": 0.1887155109585592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1887155109585592}
{"step": 418504, "time": 13972.502018928528, "episode/length": 640.0, "episode/score": 0.1268818715307134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1268818715307134}
{"step": 418768, "time": 13981.005401134491, "episode/length": 605.0, "episode/score": 0.17814156943973103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17814156943973103}
{"step": 419088, "time": 13991.021146774292, "episode/length": 640.0, "episode/score": 0.15709747317839629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15709747317839629}
{"step": 419864, "time": 14015.226863145828, "episode/length": 640.0, "episode/score": 0.1254270268076425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1254270268076425}
{"step": 419904, "time": 14016.708902359009, "episode/length": 640.0, "episode/score": 0.06504443866526799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06504443866526799}
{"step": 420056, "time": 14033.612577438354, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 14033.62190937996, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 14033.630573511124, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 14033.638932704926, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 14033.647053003311, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 14033.655070781708, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 14033.663081169128, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 14033.671346902847, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420496, "time": 14047.77390575409, "episode/length": 640.0, "episode/score": 0.07973049229690332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07973049229690332}
{"step": 421712, "time": 14086.211000204086, "episode/length": 640.0, "episode/score": 0.22430886641700454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22430886641700454}
{"step": 423536, "time": 14144.328169345856, "episode/length": 640.0, "episode/score": 0.2304992728426214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2304992728426214}
{"step": 423632, "time": 14147.52351975441, "episode/length": 640.0, "episode/score": 0.1796617579791473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1796617579791473}
{"step": 423896, "time": 14155.671466827393, "episode/length": 640.0, "episode/score": 0.10737400707080269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10737400707080269}
{"step": 424216, "time": 14165.691867113113, "episode/length": 640.0, "episode/score": 0.18659561277650027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18659561277650027}
{"step": 424992, "time": 14190.425013303757, "episode/length": 640.0, "episode/score": 0.2282193915074231, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2282193915074231}
{"step": 425032, "time": 14191.463135957718, "episode/length": 640.0, "episode/score": 0.2629181016214943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2629181016214943}
{"step": 425545, "time": 14208.65697145462, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2306361148231906, "train/action_min": 0.0, "train/action_std": 1.8558755140555532, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0004028429090364003, "train/actor_opt_grad_steps": 25555.0, "train/actor_opt_loss": -4.470995310184203, "train/adv_mag": 0.004165486050279517, "train/adv_max": 0.004103971586415642, "train/adv_mean": 0.00011921459901809851, "train/adv_min": -0.0031953002669309317, "train/adv_std": 0.0008212713043720118, "train/cont_avg": 0.9985300164473684, "train/cont_loss_mean": 0.011080531372174032, "train/cont_loss_std": 0.21602053168205088, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 6.470897743125367, "train/cont_pos_acc": 0.9999999974903307, "train/cont_pos_loss": 0.0015607927264155526, "train/cont_pred": 0.9984404429009086, "train/cont_rate": 0.9985300164473684, "train/dyn_loss_mean": 1.0000108154196488, "train/dyn_loss_std": 0.00031861617979685484, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.020907923335050184, "train/extr_critic_critic_opt_grad_steps": 25555.0, "train/extr_critic_critic_opt_loss": 13463.564977384869, "train/extr_critic_mag": 0.09295421274084793, "train/extr_critic_max": 0.09295421274084793, "train/extr_critic_mean": 0.09003762532221643, "train/extr_critic_min": 0.0851047202160484, "train/extr_critic_std": 0.0009417277959935171, "train/extr_return_normed_mag": 0.006922369803252973, "train/extr_return_normed_max": 0.006921454793528506, "train/extr_return_normed_mean": 0.002347618361052714, "train/extr_return_normed_min": -0.0028850947163606947, "train/extr_return_normed_std": 0.0012488446180022469, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09473071874756563, "train/extr_return_raw_max": 0.09473071874756563, "train/extr_return_raw_mean": 0.09015688692268573, "train/extr_return_raw_min": 0.08492416923767641, "train/extr_return_raw_std": 0.0012488446112624125, "train/extr_reward_mag": 0.0013469959560193513, "train/extr_reward_max": 0.0013469959560193513, "train/extr_reward_mean": 0.00027040996478478374, "train/extr_reward_min": 1.3420456334164269e-06, "train/extr_reward_std": 0.00023841608995816817, "train/image_loss_mean": 0.1778151116088817, "train/image_loss_std": 0.12041511151351426, "train/model_loss_mean": 0.7975826872022529, "train/model_loss_std": 0.2643067476388655, "train/model_opt_grad_norm": 28.810713808372537, "train/model_opt_grad_steps": 25529.7, "train/model_opt_loss": 2329.8236392372532, "train/model_opt_model_opt_grad_overflow": 0.005263157894736842, "train/model_opt_model_opt_grad_scale": 2907.8947368421054, "train/policy_entropy_mag": 1.9347899041677776, "train/policy_entropy_max": 1.9347899041677776, "train/policy_entropy_mean": 1.7253433045588042, "train/policy_entropy_min": 0.9204654932022095, "train/policy_entropy_std": 0.11945739278667851, "train/policy_logprob_mag": 3.9434980317165977, "train/policy_logprob_max": -0.26024780618517024, "train/policy_logprob_mean": -1.7251669501003466, "train/policy_logprob_min": -3.9434980317165977, "train/policy_logprob_std": 0.6699326741067987, "train/policy_randomness_mag": 0.9942853824088448, "train/policy_randomness_max": 0.9942853824088448, "train/policy_randomness_mean": 0.886651120687786, "train/policy_randomness_min": 0.47302571770391966, "train/policy_randomness_std": 0.061388959519957244, "train/post_ent_mag": 22.588422032406456, "train/post_ent_max": 22.588422032406456, "train/post_ent_mean": 21.935588836669922, "train/post_ent_min": 21.588627333390086, "train/post_ent_std": 0.18983407553873563, "train/prior_ent_mag": 25.28514741596423, "train/prior_ent_max": 25.28514741596423, "train/prior_ent_mean": 21.29255489550139, "train/prior_ent_min": 19.182452753970498, "train/prior_ent_std": 0.9431686975454029, "train/rep_loss_mean": 1.0000108154196488, "train/rep_loss_std": 0.00031861617979685484, "train/reward_avg": 0.0001947271260034636, "train/reward_loss_mean": 0.008680532581025833, "train/reward_loss_std": 0.013881757899530623, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.000925432380877043, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008680532558968192, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00019480738739826176, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.715150736747904, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014237641356885433, "report/cont_loss_std": 0.29181212186813354, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.610722064971924, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0013286707689985633, "report/cont_pred": 0.9986721873283386, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.14638826251029968, "report/image_loss_std": 0.10377776622772217, "report/model_loss_mean": 0.7689771056175232, "report/model_loss_std": 0.3098626136779785, "report/post_ent_mag": 20.236473083496094, "report/post_ent_max": 20.236473083496094, "report/post_ent_mean": 19.514629364013672, "report/post_ent_min": 19.107677459716797, "report/post_ent_std": 0.21417462825775146, "report/prior_ent_mag": 23.66190528869629, "report/prior_ent_max": 23.66190528869629, "report/prior_ent_mean": 19.09402847290039, "report/prior_ent_min": 17.32213020324707, "report/prior_ent_std": 0.9081884026527405, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.000184306176379323, "report/reward_loss_mean": 0.00835117045789957, "report/reward_loss_std": 0.01343408040702343, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0008734464645385742, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008351171389222145, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00020139140542596579, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.007798217236995697, "eval/cont_loss_std": 0.20693007111549377, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.626326084136963, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013284932356327772, "eval/cont_pred": 0.998672366142273, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3196587562561035, "eval/image_loss_std": 0.1707584261894226, "eval/model_loss_mean": 0.928361713886261, "eval/model_loss_std": 0.2664708197116852, "eval/post_ent_mag": 20.236970901489258, "eval/post_ent_max": 20.236970901489258, "eval/post_ent_mean": 19.530996322631836, "eval/post_ent_min": 19.18682861328125, "eval/post_ent_std": 0.20635627210140228, "eval/prior_ent_mag": 23.708330154418945, "eval/prior_ent_max": 23.708330154418945, "eval/prior_ent_mean": 19.113136291503906, "eval/prior_ent_min": 17.168781280517578, "eval/prior_ent_std": 0.9348954558372498, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0009046923369169235, "eval/reward_loss_std": 0.0012424823362380266, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0010647773742675781, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009046923369169235, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001423116773366928, "eval/reward_rate": 0.0, "replay/size": 425041.0, "replay/inserts": 30360.0, "replay/samples": 30368.0, "replay/insert_wait_avg": 1.2889995248264319e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.509363841709021e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1020040239323195e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1858885288239, "timer/env.step_count": 3795.0, "timer/env.step_total": 34.3445143699646, "timer/env.step_frac": 0.034338131305253705, "timer/env.step_avg": 0.009049937910399104, "timer/env.step_min": 0.007503509521484375, "timer/env.step_max": 0.05030655860900879, "timer/replay._sample_count": 30368.0, "timer/replay._sample_total": 15.384891748428345, "timer/replay._sample_frac": 0.01538203240505425, "timer/replay._sample_avg": 0.0005066152446136837, "timer/replay._sample_min": 0.0003745555877685547, "timer/replay._sample_max": 0.02545619010925293, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5718.0, "timer/agent.policy_total": 58.21170735359192, "timer/agent.policy_frac": 0.05820088847605687, "timer/agent.policy_avg": 0.010180431506399426, "timer/agent.policy_min": 0.008558034896850586, "timer/agent.policy_max": 0.08437347412109375, "timer/dataset_train_count": 1898.0, "timer/dataset_train_total": 0.20067214965820312, "timer/dataset_train_frac": 0.00020063485394037337, "timer/dataset_train_avg": 0.00010572821372929564, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0006883144378662109, "timer/agent.train_count": 1898.0, "timer/agent.train_total": 851.6030178070068, "timer/agent.train_frac": 0.8514447439961705, "timer/agent.train_avg": 0.44868441401844406, "timer/agent.train_min": 0.4360535144805908, "timer/agent.train_max": 1.7054455280303955, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46476101875305176, "timer/agent.report_frac": 0.00046467464106764194, "timer/agent.report_avg": 0.23238050937652588, "timer/agent.report_min": 0.22156953811645508, "timer/agent.report_max": 0.24319148063659668, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.3134023260279316e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 30.353841533252208}
{"step": 425624, "time": 14210.90941810608, "episode/length": 640.0, "episode/score": 0.06044034594765435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06044034594765435}
{"step": 426840, "time": 14249.606095075607, "episode/length": 640.0, "episode/score": 0.2185128479247851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2185128479247851}
{"step": 428664, "time": 14307.299820184708, "episode/length": 640.0, "episode/score": 0.20066433916451842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20066433916451842}
{"step": 428760, "time": 14310.333622217178, "episode/length": 640.0, "episode/score": 0.23004164514037484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23004164514037484}
{"step": 429024, "time": 14318.815923213959, "episode/length": 640.0, "episode/score": 0.1846093355109133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1846093355109133}
{"step": 429344, "time": 14329.084472179413, "episode/length": 640.0, "episode/score": 0.15254211214499946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15254211214499946}
{"step": 430040, "time": 14363.011748552322, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14363.0210044384, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14363.029723644257, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14363.038102149963, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14363.04631781578, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14363.05444574356, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14363.06247997284, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14363.070700883865, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430120, "time": 14365.643148422241, "episode/length": 640.0, "episode/score": 0.19624432865049357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19624432865049357}
{"step": 430160, "time": 14367.113720417023, "episode/length": 640.0, "episode/score": 0.20667461384999797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20667461384999797}
{"step": 430752, "time": 14385.571645498276, "episode/length": 640.0, "episode/score": 0.22622397916427417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22622397916427417}
{"step": 431968, "time": 14424.267222881317, "episode/length": 640.0, "episode/score": 0.14908684801270056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14908684801270056}
{"step": 433792, "time": 14481.977664470673, "episode/length": 640.0, "episode/score": 0.20268697069957398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20268697069957398}
{"step": 433888, "time": 14485.005850791931, "episode/length": 640.0, "episode/score": 0.27949328803134676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27949328803134676}
{"step": 434152, "time": 14493.090678453445, "episode/length": 640.0, "episode/score": 0.22130283530424322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22130283530424322}
{"step": 434472, "time": 14503.687218427658, "episode/length": 640.0, "episode/score": 0.2671850056479457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2671850056479457}
{"step": 435248, "time": 14528.492952823639, "episode/length": 640.0, "episode/score": 0.1360206639686794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1360206639686794}
{"step": 435288, "time": 14529.544477462769, "episode/length": 640.0, "episode/score": 0.22020434683935264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22020434683935264}
{"step": 435880, "time": 14548.241928577423, "episode/length": 640.0, "episode/score": 0.20978566272327726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20978566272327726}
{"step": 437096, "time": 14586.790848731995, "episode/length": 640.0, "episode/score": 0.18942439638203723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18942439638203723}
{"step": 438920, "time": 14644.564094781876, "episode/length": 640.0, "episode/score": 0.1389403305217911, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1389403305217911}
{"step": 439016, "time": 14647.647250175476, "episode/length": 640.0, "episode/score": 0.1602543688853757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1602543688853757}
{"step": 439280, "time": 14656.445049524307, "episode/length": 640.0, "episode/score": 0.10144123954967199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10144123954967199}
{"step": 439600, "time": 14666.478590965271, "episode/length": 640.0, "episode/score": 0.09669379145759649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09669379145759649}
{"step": 440024, "time": 14691.596054077148, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14691.604855775833, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14691.613346099854, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14691.621379375458, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14691.629028320312, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14691.63669848442, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14691.644911289215, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14691.652460813522, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440376, "time": 14702.73908829689, "episode/length": 640.0, "episode/score": 0.10211554640238774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10211554640238774}
{"step": 440416, "time": 14704.22454714775, "episode/length": 640.0, "episode/score": 0.1843174086051249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1843174086051249}
{"step": 441008, "time": 14722.972558259964, "episode/length": 640.0, "episode/score": 0.22588290797500576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22588290797500576}
{"step": 442224, "time": 14761.659138679504, "episode/length": 640.0, "episode/score": 0.15104440870709368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15104440870709368}
{"step": 444048, "time": 14819.628531694412, "episode/length": 640.0, "episode/score": 0.15145484751371896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15145484751371896}
{"step": 444144, "time": 14822.650221824646, "episode/length": 640.0, "episode/score": 0.21270923548536302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21270923548536302}
{"step": 444408, "time": 14830.710004806519, "episode/length": 640.0, "episode/score": 0.06995753612710587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06995753612710587}
{"step": 444728, "time": 14840.86953997612, "episode/length": 640.0, "episode/score": 0.12090841621733261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12090841621733261}
{"step": 445504, "time": 14865.426300764084, "episode/length": 640.0, "episode/score": 0.18204990744021643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18204990744021643}
{"step": 445544, "time": 14866.58170247078, "episode/length": 640.0, "episode/score": 0.09208662742048546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09208662742048546}
{"step": 446136, "time": 14885.185570716858, "episode/length": 640.0, "episode/score": 0.15435495314000036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15435495314000036}
{"step": 447352, "time": 14923.871079921722, "episode/length": 640.0, "episode/score": 0.16131437433597284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16131437433597284}
{"step": 449176, "time": 14981.726786136627, "episode/length": 640.0, "episode/score": 0.14629746265597987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14629746265597987}
{"step": 449272, "time": 14984.81078696251, "episode/length": 640.0, "episode/score": 0.2901063054871429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2901063054871429}
{"step": 449536, "time": 14993.520390987396, "episode/length": 640.0, "episode/score": 0.206133583203723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.206133583203723}
{"step": 449856, "time": 15003.54341173172, "episode/length": 640.0, "episode/score": 0.13571938013990348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13571938013990348}
{"step": 450008, "time": 15019.404171466827, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 15019.413059711456, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 15019.421312570572, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 15019.429316282272, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 15019.43765926361, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 15019.44523024559, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 15019.452999353409, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 15019.460615873337, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450256, "time": 15027.465989112854, "episode/length": 134.0, "episode/score": 0.05808480617110945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05808480617110945}
{"step": 450632, "time": 15039.531309366226, "episode/length": 640.0, "episode/score": 0.19015392393089314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19015392393089314}
{"step": 450672, "time": 15041.035935401917, "episode/length": 640.0, "episode/score": 0.3080449296101051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3080449296101051}
{"step": 451264, "time": 15059.893052816391, "episode/length": 640.0, "episode/score": 0.303564158118661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.303564158118661}
{"step": 452480, "time": 15098.56868672371, "episode/length": 640.0, "episode/score": 0.26805323172072804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26805323172072804}
{"step": 454400, "time": 15159.476882219315, "episode/length": 640.0, "episode/score": 0.19861916507511523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19861916507511523}
{"step": 454664, "time": 15167.72979927063, "episode/length": 640.0, "episode/score": 0.21258091878155483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21258091878155483}
{"step": 454984, "time": 15177.856106996536, "episode/length": 640.0, "episode/score": 0.17925342788618082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17925342788618082}
{"step": 455384, "time": 15190.449406147003, "episode/length": 640.0, "episode/score": 0.0717930320493565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0717930320493565}
{"step": 455760, "time": 15202.559840202332, "episode/length": 640.0, "episode/score": 0.24853539536024982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24853539536024982}
{"step": 455800, "time": 15203.607951164246, "episode/length": 640.0, "episode/score": 0.19094449751401044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19094449751401044}
{"step": 455945, "time": 15209.117556095123, "train_stats/mean_log_entropy": 1.7025866849081857, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.209416439658717, "train/action_min": 0.0, "train/action_std": 1.8497022051560252, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00042092151385364365, "train/actor_opt_grad_steps": 27455.0, "train/actor_opt_loss": -4.92373842161737, "train/adv_mag": 0.007568302907441792, "train/adv_max": 0.004146046662016919, "train/adv_mean": 9.335071447127886e-05, "train/adv_min": -0.006845796108245849, "train/adv_std": 0.0008800792599734115, "train/cont_avg": 0.9985916940789473, "train/cont_loss_mean": 0.010241059297511942, "train/cont_loss_std": 0.19514341995468865, "train/cont_neg_acc": 0.009661835820778557, "train/cont_neg_loss": 6.250462661618772, "train/cont_pos_acc": 0.9999948476490221, "train/cont_pos_loss": 0.0014841063349434224, "train/cont_pred": 0.9985019796773007, "train/cont_rate": 0.9985916940789473, "train/dyn_loss_mean": 1.0000105788833216, "train/dyn_loss_std": 0.000284383878246636, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.01992492836296534, "train/extr_critic_critic_opt_grad_steps": 27455.0, "train/extr_critic_critic_opt_loss": 13350.615008223684, "train/extr_critic_mag": 0.09714512699528745, "train/extr_critic_max": 0.09714512699528745, "train/extr_critic_mean": 0.09421735786293682, "train/extr_critic_min": 0.08833825964676706, "train/extr_critic_std": 0.0010742464709389758, "train/extr_return_normed_mag": 0.010326198174765235, "train/extr_return_normed_max": 0.007194408735162333, "train/extr_return_normed_mean": 0.002635524426832011, "train/extr_return_normed_min": -0.006679532167158629, "train/extr_return_normed_std": 0.0013750056111204781, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09886960920534636, "train/extr_return_raw_max": 0.09886960920534636, "train/extr_return_raw_mean": 0.09431072951931703, "train/extr_return_raw_min": 0.08499566830302539, "train/extr_return_raw_std": 0.0013750056092823415, "train/extr_reward_mag": 0.0012946850375125283, "train/extr_reward_max": 0.0012946850375125283, "train/extr_reward_mean": 0.0002737643404735105, "train/extr_reward_min": 9.963386937191612e-07, "train/extr_reward_std": 0.00024599875614512713, "train/image_loss_mean": 0.15923078648353878, "train/image_loss_std": 0.12276550766668821, "train/model_loss_mean": 0.7783933096810391, "train/model_loss_std": 0.25250448376724594, "train/model_opt_grad_norm": 27.037120392448024, "train/model_opt_grad_steps": 27428.43157894737, "train/model_opt_loss": 2435.9151418585525, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3131.5789473684213, "train/policy_entropy_mag": 1.9373431676312496, "train/policy_entropy_max": 1.9373431676312496, "train/policy_entropy_mean": 1.7112744833293714, "train/policy_entropy_min": 0.8479852256022001, "train/policy_entropy_std": 0.132482195998493, "train/policy_logprob_mag": 4.095440327493768, "train/policy_logprob_max": -0.2320745423436165, "train/policy_logprob_mean": -1.7113847538044578, "train/policy_logprob_min": -4.095440327493768, "train/policy_logprob_std": 0.687864195045672, "train/policy_randomness_mag": 0.9955975018049541, "train/policy_randomness_max": 0.9955975018049541, "train/policy_randomness_mean": 0.8794211751536319, "train/policy_randomness_min": 0.4357782266641918, "train/policy_randomness_std": 0.06808238505925003, "train/post_ent_mag": 19.478179469861484, "train/post_ent_max": 19.478179469861484, "train/post_ent_mean": 18.715947743466025, "train/post_ent_min": 18.3189090628373, "train/post_ent_std": 0.22140927087319526, "train/prior_ent_mag": 22.109118933426707, "train/prior_ent_max": 22.109118933426707, "train/prior_ent_mean": 17.528860433478105, "train/prior_ent_min": 15.665190847296463, "train/prior_ent_std": 0.9355921259051875, "train/rep_loss_mean": 1.0000105788833216, "train/rep_loss_std": 0.000284383878246636, "train/reward_avg": 0.00020113912009707603, "train/reward_loss_mean": 0.008915097881598692, "train/reward_loss_std": 0.014046602656966762, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0009981080105430202, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008915097901205484, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00019804679077902907, "train/reward_rate": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.002656382042914629, "report/cont_loss_std": 0.026327909901738167, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 0.529214084148407, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0016259364783763885, "report/cont_pred": 0.9971878528594971, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12761607766151428, "report/image_loss_std": 0.11502360552549362, "report/model_loss_mean": 0.7382622957229614, "report/model_loss_std": 0.1224123015999794, "report/post_ent_mag": 18.498559951782227, "report/post_ent_max": 18.498559951782227, "report/post_ent_mean": 17.62998390197754, "report/post_ent_min": 17.15919303894043, "report/post_ent_std": 0.24893854558467865, "report/prior_ent_mag": 20.89486312866211, "report/prior_ent_max": 20.89486312866211, "report/prior_ent_mean": 16.221309661865234, "report/prior_ent_min": 14.829801559448242, "report/prior_ent_std": 0.8775914907455444, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001788970548659563, "report/reward_loss_mean": 0.007989825680851936, "report/reward_loss_std": 0.013580644503235817, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0008207559585571289, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007989826612174511, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00017159583512693644, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02137158066034317, "eval/cont_loss_std": 0.35895872116088867, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.599515914916992, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0020430481527000666, "eval/cont_pred": 0.9979692697525024, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2529295086860657, "eval/image_loss_std": 0.14563043415546417, "eval/model_loss_mean": 0.8754745721817017, "eval/model_loss_std": 0.3900207579135895, "eval/post_ent_mag": 18.498538970947266, "eval/post_ent_max": 18.498538970947266, "eval/post_ent_mean": 17.64085578918457, "eval/post_ent_min": 17.230947494506836, "eval/post_ent_std": 0.25825732946395874, "eval/prior_ent_mag": 20.713096618652344, "eval/prior_ent_max": 20.713096618652344, "eval/prior_ent_mean": 16.351465225219727, "eval/prior_ent_min": 14.849564552307129, "eval/prior_ent_std": 0.8663408160209656, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001173430122435093, "eval/reward_loss_std": 0.0011992044746875763, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0008192062377929688, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001173430122435093, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00018460501451045275, "eval/reward_rate": 0.0, "replay/size": 455441.0, "replay/inserts": 30400.0, "replay/samples": 30400.0, "replay/insert_wait_avg": 1.3135059883719996e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.49468143362748e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0991679214898089e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.443589925766, "timer/env.step_count": 3800.0, "timer/env.step_total": 34.29655861854553, "timer/env.step_frac": 0.034281351756264816, "timer/env.step_avg": 0.00902541016277514, "timer/env.step_min": 0.007486820220947266, "timer/env.step_max": 0.03538250923156738, "timer/replay._sample_count": 30400.0, "timer/replay._sample_total": 15.290294885635376, "timer/replay._sample_frac": 0.015283515272230324, "timer/replay._sample_avg": 0.0005029702265011637, "timer/replay._sample_min": 0.0003657341003417969, "timer/replay._sample_max": 0.011033773422241211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5723.0, "timer/agent.policy_total": 57.875584840774536, "timer/agent.policy_frac": 0.05784992319763773, "timer/agent.policy_avg": 0.010112805319024032, "timer/agent.policy_min": 0.008419275283813477, "timer/agent.policy_max": 0.08397793769836426, "timer/dataset_train_count": 1900.0, "timer/dataset_train_total": 0.1983017921447754, "timer/dataset_train_frac": 0.00019821386647046196, "timer/dataset_train_avg": 0.00010436936428672389, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.0004012584686279297, "timer/agent.train_count": 1900.0, "timer/agent.train_total": 852.6048195362091, "timer/agent.train_frac": 0.8522267803219903, "timer/agent.train_avg": 0.44873937870326797, "timer/agent.train_min": 0.43552160263061523, "timer/agent.train_max": 0.630136251449585, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4748518466949463, "timer/agent.report_frac": 0.0004746413005956496, "timer/agent.report_avg": 0.23742592334747314, "timer/agent.report_min": 0.2316577434539795, "timer/agent.report_max": 0.2431941032409668, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2410549764448456e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 30.386007547739037}
{"step": 456392, "time": 15223.102608442307, "episode/length": 640.0, "episode/score": 0.2064947153585308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2064947153585308}
{"step": 457608, "time": 15261.968354225159, "episode/length": 640.0, "episode/score": 0.2207895670891844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2207895670891844}
{"step": 459528, "time": 15323.471658945084, "episode/length": 640.0, "episode/score": 0.15069137671957833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15069137671957833}
{"step": 459792, "time": 15332.02279496193, "episode/length": 640.0, "episode/score": 0.12009620540618471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12009620540618471}
{"step": 460096, "time": 15353.444719314575, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15353.45341038704, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15353.462032556534, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15353.469665527344, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15353.477635383606, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15353.485465049744, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15353.493573188782, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15353.501095294952, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460112, "time": 15354.034232854843, "episode/length": 640.0, "episode/score": 0.1838727954612409, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1838727954612409}
{"step": 460512, "time": 15366.665471076965, "episode/length": 640.0, "episode/score": 0.22635917733390443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22635917733390443}
{"step": 460888, "time": 15378.399587631226, "episode/length": 640.0, "episode/score": 0.08994739126023887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08994739126023887}
{"step": 460928, "time": 15379.907143115997, "episode/length": 640.0, "episode/score": 0.23005173766352982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23005173766352982}
{"step": 461520, "time": 15398.65800356865, "episode/length": 640.0, "episode/score": 0.11707713978671563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11707713978671563}
{"step": 462736, "time": 15437.260080575943, "episode/length": 640.0, "episode/score": 0.08442768771789133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08442768771789133}
{"step": 464656, "time": 15497.73466348648, "episode/length": 640.0, "episode/score": 0.13684739096163412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13684739096163412}
{"step": 464920, "time": 15505.796206474304, "episode/length": 640.0, "episode/score": 0.24871759658941528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24871759658941528}
{"step": 465240, "time": 15515.813645124435, "episode/length": 640.0, "episode/score": 0.11229166646404565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11229166646404565}
{"step": 465640, "time": 15528.416462898254, "episode/length": 640.0, "episode/score": 0.07271458270201947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07271458270201947}
{"step": 466016, "time": 15540.396992206573, "episode/length": 640.0, "episode/score": 0.1767693350952868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1767693350952868}
{"step": 466056, "time": 15541.452002048492, "episode/length": 640.0, "episode/score": 0.13473644326791145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13473644326791145}
{"step": 466648, "time": 15560.09994840622, "episode/length": 640.0, "episode/score": 0.14345289839434372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14345289839434372}
{"step": 467864, "time": 15599.394587993622, "episode/length": 640.0, "episode/score": 0.186202069871797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.186202069871797}
{"step": 468704, "time": 15626.256942510605, "episode/length": 472.0, "episode/score": 0.16162486021949007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16162486021949007}
{"step": 469784, "time": 15660.18221783638, "episode/length": 640.0, "episode/score": 0.10902542238522983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10902542238522983}
{"step": 470080, "time": 15681.976952314377, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15681.985787630081, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15681.994126558304, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15682.002375125885, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15682.010456323624, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15682.019158363342, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15682.02709364891, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15682.039718151093, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470368, "time": 15691.06451678276, "episode/length": 640.0, "episode/score": 0.07383865886015428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07383865886015428}
{"step": 470768, "time": 15703.613758802414, "episode/length": 640.0, "episode/score": 0.21813361341673954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21813361341673954}
{"step": 471144, "time": 15715.291513204575, "episode/length": 640.0, "episode/score": 0.16120440170692518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16120440170692518}
{"step": 471184, "time": 15716.790842294693, "episode/length": 640.0, "episode/score": 0.06202821383385526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06202821383385526}
{"step": 471776, "time": 15735.320791482925, "episode/length": 640.0, "episode/score": 0.14146449262887018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14146449262887018}
{"step": 472992, "time": 15773.675533771515, "episode/length": 640.0, "episode/score": 0.11395388277060192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11395388277060192}
{"step": 473832, "time": 15799.757730722427, "episode/length": 640.0, "episode/score": 0.1705521080342578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1705521080342578}
{"step": 474912, "time": 15834.063937425613, "episode/length": 640.0, "episode/score": 0.20984205334661965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20984205334661965}
{"step": 475496, "time": 15852.887004375458, "episode/length": 640.0, "episode/score": 0.17919939013279418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17919939013279418}
{"step": 475896, "time": 15865.49312543869, "episode/length": 640.0, "episode/score": 0.20807802911451745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20807802911451745}
{"step": 476272, "time": 15877.481724262238, "episode/length": 640.0, "episode/score": 0.2290090232885973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2290090232885973}
{"step": 476312, "time": 15878.51371049881, "episode/length": 640.0, "episode/score": 0.15463363934441077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15463363934441077}
{"step": 476904, "time": 15897.146946907043, "episode/length": 640.0, "episode/score": 0.1749966163819181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1749966163819181}
{"step": 478120, "time": 15935.473256349564, "episode/length": 640.0, "episode/score": 0.08653375051034118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08653375051034118}
{"step": 478960, "time": 15962.212731599808, "episode/length": 640.0, "episode/score": 0.07620251730048722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07620251730048722}
{"step": 480040, "time": 15996.549292564392, "episode/length": 640.0, "episode/score": 0.15525256538700205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15525256538700205}
{"step": 480064, "time": 16009.129957199097, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 16009.138998270035, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 16009.147142648697, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 16009.155154943466, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 16009.162797927856, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 16009.170454740524, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 16009.178243637085, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 16009.185871601105, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480624, "time": 16026.792243719101, "episode/length": 640.0, "episode/score": 0.13767743159166912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13767743159166912}
{"step": 481024, "time": 16039.422836780548, "episode/length": 640.0, "episode/score": 0.1565451723851652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1565451723851652}
{"step": 481400, "time": 16051.220912218094, "episode/length": 640.0, "episode/score": 0.2119879787719583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2119879787719583}
{"step": 481440, "time": 16052.705493927002, "episode/length": 640.0, "episode/score": 0.12330890327166344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12330890327166344}
{"step": 482032, "time": 16071.510476589203, "episode/length": 640.0, "episode/score": 0.16618878624444733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16618878624444733}
{"step": 483248, "time": 16109.953332901001, "episode/length": 640.0, "episode/score": 0.2528901589350312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2528901589350312}
{"step": 484088, "time": 16136.682693719864, "episode/length": 640.0, "episode/score": 0.11045356564039821, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11045356564039821}
{"step": 485168, "time": 16171.099542856216, "episode/length": 640.0, "episode/score": 0.17389589666584016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17389589666584016}
{"step": 485752, "time": 16189.326743364334, "episode/length": 640.0, "episode/score": 0.17892704606418874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17892704606418874}
{"step": 486152, "time": 16201.877999782562, "episode/length": 640.0, "episode/score": 0.16930974707088353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16930974707088353}
{"step": 486361, "time": 16209.37183189392, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.230548738178454, "train/action_min": 0.0, "train/action_std": 1.8804058777658563, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0005652869098795284, "train/actor_opt_grad_steps": 29355.0, "train/actor_opt_loss": -6.658135151863098, "train/adv_mag": 0.0378524485779436, "train/adv_max": 0.004162252380659706, "train/adv_mean": -1.5337941920877615e-05, "train/adv_min": -0.03733818829059601, "train/adv_std": 0.0013879353373532036, "train/cont_avg": 0.9984837582236842, "train/cont_loss_mean": 0.00826885183663475, "train/cont_loss_std": 0.1727605334498405, "train/cont_neg_acc": 0.16865828183462034, "train/cont_neg_loss": 4.592001596576997, "train/cont_pos_acc": 0.9999072683484931, "train/cont_pos_loss": 0.0013870801137895077, "train/cont_pred": 0.998439456600892, "train/cont_rate": 0.9984837582236842, "train/dyn_loss_mean": 1.000005220739465, "train/dyn_loss_std": 0.0001420548882666289, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.025838975262472797, "train/extr_critic_critic_opt_grad_steps": 29355.0, "train/extr_critic_critic_opt_loss": 13298.29679790296, "train/extr_critic_mag": 0.09825904243870785, "train/extr_critic_max": 0.09825904243870785, "train/extr_critic_mean": 0.09556498656931676, "train/extr_critic_min": 0.08978824239028127, "train/extr_critic_std": 0.0010384228028430555, "train/extr_return_normed_mag": 0.0388028400508981, "train/extr_return_normed_max": 0.007059772704776965, "train/extr_return_normed_mean": 0.0023117842860397343, "train/extr_return_normed_min": -0.036622155222453566, "train/extr_return_normed_std": 0.0017894665673865299, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1002975843846798, "train/extr_return_raw_max": 0.1002975843846798, "train/extr_return_raw_mean": 0.0955496000616174, "train/extr_return_raw_min": 0.05661565645744926, "train/extr_return_raw_std": 0.0017894665643229688, "train/extr_reward_mag": 0.0012643858006126001, "train/extr_reward_max": 0.0012643858006126001, "train/extr_reward_mean": 0.00027064093791475324, "train/extr_reward_min": 1.0371208190917968e-06, "train/extr_reward_std": 0.000252365053089115, "train/image_loss_mean": 0.1446277412536897, "train/image_loss_std": 0.12093165144324303, "train/model_loss_mean": 0.7618578876319685, "train/model_loss_std": 0.22808711995419703, "train/model_opt_grad_norm": 25.830291268686768, "train/model_opt_grad_steps": 29327.41052631579, "train/model_opt_loss": 2810.119822291324, "train/model_opt_model_opt_grad_overflow": 0.005263157894736842, "train/model_opt_model_opt_grad_scale": 3671.0526315789475, "train/policy_entropy_mag": 1.939017719344089, "train/policy_entropy_max": 1.939017719344089, "train/policy_entropy_mean": 1.7235864551443802, "train/policy_entropy_min": 0.8538866488557113, "train/policy_entropy_std": 0.12991058991143578, "train/policy_logprob_mag": 4.030594528348822, "train/policy_logprob_max": -0.23416606932878495, "train/policy_logprob_mean": -1.7233305347593206, "train/policy_logprob_min": -4.030594528348822, "train/policy_logprob_std": 0.6704704108991121, "train/policy_randomness_mag": 0.9964580495106546, "train/policy_randomness_max": 0.9964580495106546, "train/policy_randomness_mean": 0.8857482747027748, "train/policy_randomness_min": 0.43881095914464247, "train/policy_randomness_std": 0.06676084075711275, "train/post_ent_mag": 17.727111083582827, "train/post_ent_max": 17.727111083582827, "train/post_ent_mean": 16.826434100301643, "train/post_ent_min": 16.361113523182116, "train/post_ent_std": 0.2601642876079208, "train/prior_ent_mag": 19.457062450208163, "train/prior_ent_max": 19.457062450208163, "train/prior_ent_mean": 15.29467726255718, "train/prior_ent_min": 13.614928235505756, "train/prior_ent_std": 0.8652686037515339, "train/rep_loss_mean": 1.000005220739465, "train/rep_loss_std": 0.0001420548882666289, "train/reward_avg": 0.0002025096614440707, "train/reward_loss_mean": 0.008958137942183959, "train/reward_loss_std": 0.013918244039737864, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0010667273872777036, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008958137978946693, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00020399492381042555, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.715109726657038, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.000980084529146552, "report/cont_loss_std": 0.009321466088294983, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.27852803468704224, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0007087767007760704, "report/cont_pred": 0.9985586404800415, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12969350814819336, "report/image_loss_std": 0.1146002933382988, "report/model_loss_mean": 0.739473819732666, "report/model_loss_std": 0.11974959075450897, "report/post_ent_mag": 21.413818359375, "report/post_ent_max": 21.413818359375, "report/post_ent_mean": 20.05048942565918, "report/post_ent_min": 19.358903884887695, "report/post_ent_std": 0.3779495358467102, "report/prior_ent_mag": 18.979726791381836, "report/prior_ent_max": 18.979726791381836, "report/prior_ent_mean": 16.496562957763672, "report/prior_ent_min": 15.358837127685547, "report/prior_ent_std": 0.5533523559570312, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00020447045972105116, "report/reward_loss_mean": 0.008800214156508446, "report/reward_loss_std": 0.014991811476647854, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.000989079475402832, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008800214156508446, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00016692036297172308, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0024189394898712635, "eval/cont_loss_std": 0.053360145539045334, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.9990234375, "eval/cont_pos_loss": 0.0024189394898712635, "eval/cont_pred": 0.9984517097473145, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2738470733165741, "eval/image_loss_std": 0.16440007090568542, "eval/model_loss_mean": 0.8772792816162109, "eval/model_loss_std": 0.17609372735023499, "eval/post_ent_mag": 21.413694381713867, "eval/post_ent_max": 21.413694381713867, "eval/post_ent_mean": 20.06044578552246, "eval/post_ent_min": 19.516735076904297, "eval/post_ent_std": 0.36859816312789917, "eval/prior_ent_mag": 18.979726791381836, "eval/prior_ent_max": 18.979726791381836, "eval/prior_ent_mean": 16.441322326660156, "eval/prior_ent_min": 15.074363708496094, "eval/prior_ent_std": 0.5821719169616699, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001013185828924179, "eval/reward_loss_std": 0.001230923691764474, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0010836124420166016, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001013185828924179, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00015939422883093357, "eval/reward_rate": 0.0, "replay/size": 485857.0, "replay/inserts": 30416.0, "replay/samples": 30416.0, "replay/insert_wait_avg": 1.2872925813043826e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.473046386574269e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.120182975653987e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2347531318665, "timer/env.step_count": 3802.0, "timer/env.step_total": 34.18847584724426, "timer/env.step_frac": 0.03418045187911703, "timer/env.step_avg": 0.008992234573183657, "timer/env.step_min": 0.007506132125854492, "timer/env.step_max": 0.04367375373840332, "timer/replay._sample_count": 30416.0, "timer/replay._sample_total": 15.34049916267395, "timer/replay._sample_frac": 0.015336898777652777, "timer/replay._sample_avg": 0.0005043562323340989, "timer/replay._sample_min": 0.0003795623779296875, "timer/replay._sample_max": 0.009944677352905273, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5725.0, "timer/agent.policy_total": 58.02264046669006, "timer/agent.policy_frac": 0.05800902266694249, "timer/agent.policy_avg": 0.010134959033482981, "timer/agent.policy_min": 0.008785247802734375, "timer/agent.policy_max": 0.11716198921203613, "timer/dataset_train_count": 1901.0, "timer/dataset_train_total": 0.2062549591064453, "timer/dataset_train_frac": 0.00020620655147267572, "timer/dataset_train_avg": 0.0001084981373521543, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.00034308433532714844, "timer/agent.train_count": 1901.0, "timer/agent.train_total": 851.9893112182617, "timer/agent.train_frac": 0.8517893510004239, "timer/agent.train_avg": 0.4481795429869867, "timer/agent.train_min": 0.4355924129486084, "timer/agent.train_max": 0.5913312435150146, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4781155586242676, "timer/agent.report_frac": 0.0004780033458417886, "timer/agent.report_avg": 0.2390577793121338, "timer/agent.report_min": 0.23175454139709473, "timer/agent.report_max": 0.24636101722717285, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1702228823004464e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 30.40834290192779}
{"step": 486528, "time": 16214.586130142212, "episode/length": 640.0, "episode/score": 0.1714987904957752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1714987904957752}
{"step": 486568, "time": 16215.62380027771, "episode/length": 640.0, "episode/score": 0.14496789460253012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14496789460253012}
{"step": 487160, "time": 16234.353914499283, "episode/length": 640.0, "episode/score": 0.1766855249911714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1766855249911714}
{"step": 488024, "time": 16261.546520709991, "episode/length": 491.0, "episode/score": 0.16422202893392068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16422202893392068}
{"step": 488376, "time": 16272.63612985611, "episode/length": 640.0, "episode/score": 0.13327083446017696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13327083446017696}
{"step": 490048, "time": 16338.170785665512, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16338.179603338242, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16338.18765258789, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16338.195290327072, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16338.202984333038, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16338.210675477982, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16338.218410730362, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16338.226062297821, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490296, "time": 16345.720441102982, "episode/length": 640.0, "episode/score": 0.14350622232097976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14350622232097976}
{"step": 490880, "time": 16364.205623149872, "episode/length": 640.0, "episode/score": 0.08119778928008259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08119778928008259}
{"step": 491280, "time": 16376.906941652298, "episode/length": 640.0, "episode/score": 0.11145379331637173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11145379331637173}
{"step": 491656, "time": 16389.030086040497, "episode/length": 640.0, "episode/score": 0.08171339318073478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08171339318073478}
{"step": 491696, "time": 16390.50235414505, "episode/length": 640.0, "episode/score": 0.17047030253078788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17047030253078788}
{"step": 492288, "time": 16409.060894966125, "episode/length": 640.0, "episode/score": 0.1117952067001795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1117952067001795}
{"step": 493152, "time": 16436.150535345078, "episode/length": 640.0, "episode/score": 0.08113699314546352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08113699314546352}
{"step": 493504, "time": 16448.539746761322, "episode/length": 640.0, "episode/score": 0.13595972220124963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13595972220124963}
{"step": 495424, "time": 16508.871047258377, "episode/length": 640.0, "episode/score": 0.11767957822274866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11767957822274866}
{"step": 496008, "time": 16527.052046775818, "episode/length": 640.0, "episode/score": 0.1144334453543081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1144334453543081}
{"step": 496408, "time": 16539.609342336655, "episode/length": 640.0, "episode/score": 0.15990103019873914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15990103019873914}
{"step": 496784, "time": 16551.865076303482, "episode/length": 640.0, "episode/score": 0.18893882334793943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18893882334793943}
{"step": 496824, "time": 16552.906081676483, "episode/length": 640.0, "episode/score": 0.11183773563502086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11183773563502086}
{"step": 497416, "time": 16571.432188987732, "episode/length": 640.0, "episode/score": 0.1667216563160423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1667216563160423}
{"step": 497512, "time": 16574.44550180435, "episode/length": 544.0, "episode/score": 0.20889158707007027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20889158707007027}
{"step": 498632, "time": 16609.757098197937, "episode/length": 640.0, "episode/score": 0.1704749139645685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1704749139645685}
{"step": 500032, "time": 16666.522592782974, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16666.531498908997, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16666.53961777687, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16666.547527313232, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16666.555779218674, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16666.56356906891, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16666.571196317673, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16666.579137325287, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500552, "time": 16682.66482925415, "episode/length": 640.0, "episode/score": 0.23342403618005392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23342403618005392}
{"step": 501136, "time": 16701.1596763134, "episode/length": 640.0, "episode/score": 0.19566344177925998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19566344177925998}
{"step": 501536, "time": 16713.59780216217, "episode/length": 640.0, "episode/score": 0.24455408401095724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24455408401095724}
{"step": 501912, "time": 16725.136690855026, "episode/length": 640.0, "episode/score": 0.12249070736089607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12249070736089607}
{"step": 501952, "time": 16726.684000730515, "episode/length": 640.0, "episode/score": 0.2665533034216594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2665533034216594}
{"step": 502544, "time": 16745.151743412018, "episode/length": 640.0, "episode/score": 0.10724517772911213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10724517772911213}
{"step": 502640, "time": 16748.13307118416, "episode/length": 640.0, "episode/score": 0.13111035972343643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13111035972343643}
{"step": 503760, "time": 16783.2714574337, "episode/length": 640.0, "episode/score": 0.2545519086206127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2545519086206127}
{"step": 505680, "time": 16843.632234811783, "episode/length": 640.0, "episode/score": 0.21075430771713854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21075430771713854}
{"step": 506264, "time": 16861.837460756302, "episode/length": 640.0, "episode/score": 0.19729356117329644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19729356117329644}
{"step": 506664, "time": 16874.5962164402, "episode/length": 640.0, "episode/score": 0.18066903497310705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18066903497310705}
{"step": 507040, "time": 16886.853357315063, "episode/length": 640.0, "episode/score": 0.2035659173594695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2035659173594695}
{"step": 507080, "time": 16887.884249210358, "episode/length": 640.0, "episode/score": 0.2055690635852443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2055690635852443}
{"step": 507672, "time": 16906.456744909286, "episode/length": 640.0, "episode/score": 0.21176514549807735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21176514549807735}
{"step": 507768, "time": 16909.470652103424, "episode/length": 640.0, "episode/score": 0.19740400021277082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19740400021277082}
{"step": 508888, "time": 16945.191611528397, "episode/length": 640.0, "episode/score": 0.12643905289172608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12643905289172608}
{"step": 510016, "time": 16992.65451025963, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16992.66410923004, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16992.672645807266, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16992.681064128876, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16992.689484119415, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16992.698097229004, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16992.70627117157, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16992.714585781097, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510808, "time": 17017.753555059433, "episode/length": 640.0, "episode/score": 0.062132869451431816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062132869451431816}
{"step": 511392, "time": 17036.600088596344, "episode/length": 640.0, "episode/score": 0.2393819123279286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2393819123279286}
{"step": 511792, "time": 17049.295333862305, "episode/length": 640.0, "episode/score": 0.24456646995065512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24456646995065512}
{"step": 512168, "time": 17060.919022083282, "episode/length": 640.0, "episode/score": 0.2061032901008275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2061032901008275}
{"step": 512208, "time": 17062.38292980194, "episode/length": 640.0, "episode/score": 0.1946690650850087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1946690650850087}
{"step": 512800, "time": 17080.801903009415, "episode/length": 640.0, "episode/score": 0.2447658730833382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2447658730833382}
{"step": 512896, "time": 17083.799429655075, "episode/length": 640.0, "episode/score": 0.20925071086537628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20925071086537628}
{"step": 514016, "time": 17118.883610248566, "episode/length": 640.0, "episode/score": 0.24019472277257137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24019472277257137}
{"step": 515936, "time": 17178.931510925293, "episode/length": 640.0, "episode/score": 0.10885422597237948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10885422597237948}
{"step": 516520, "time": 17197.427513837814, "episode/length": 640.0, "episode/score": 0.10609855562358916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10609855562358916}
{"step": 516873, "time": 17209.545565128326, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2111042223478616, "train/action_min": 0.0, "train/action_std": 1.8582559177750035, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007576344234525765, "train/actor_opt_grad_steps": 31255.0, "train/actor_opt_loss": -6.923560720623324, "train/adv_mag": 0.06762942805101997, "train/adv_max": 0.004415100695271241, "train/adv_mean": -3.2074284017892895e-05, "train/adv_min": -0.06730732851122555, "train/adv_std": 0.002132688929314578, "train/cont_avg": 0.9984631990131579, "train/cont_loss_mean": 0.0058408437120593395, "train/cont_loss_std": 0.12497925715150288, "train/cont_neg_acc": 0.4440785425824004, "train/cont_neg_loss": 3.0415731278163465, "train/cont_pos_acc": 0.9998506078594609, "train/cont_pos_loss": 0.001194655148490136, "train/cont_pred": 0.9983181624036086, "train/cont_rate": 0.9984631990131579, "train/dyn_loss_mean": 1.0000226579214397, "train/dyn_loss_std": 0.0007242462989923202, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.027897433794140326, "train/extr_critic_critic_opt_grad_steps": 31255.0, "train/extr_critic_critic_opt_loss": 13320.086472039473, "train/extr_critic_mag": 0.09731507866006149, "train/extr_critic_max": 0.09731507866006149, "train/extr_critic_mean": 0.09463584168176901, "train/extr_critic_min": 0.08925139966763948, "train/extr_critic_std": 0.001024252142891974, "train/extr_return_normed_mag": 0.06677462329205713, "train/extr_return_normed_max": 0.00719187236145923, "train/extr_return_normed_mean": 0.002211114845704287, "train/extr_return_normed_min": -0.06566179986847075, "train/extr_return_normed_std": 0.002422525238331505, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09958456691942717, "train/extr_return_raw_max": 0.09958456691942717, "train/extr_return_raw_mean": 0.09460381351803479, "train/extr_return_raw_min": 0.026730894689497194, "train/extr_return_raw_std": 0.00242252523955693, "train/extr_reward_mag": 0.0012465282490378932, "train/extr_reward_max": 0.0012465282490378932, "train/extr_reward_mean": 0.00027106884050513865, "train/extr_reward_min": 1.1807993838661596e-06, "train/extr_reward_std": 0.00025614870468607955, "train/image_loss_mean": 0.13533809930086135, "train/image_loss_std": 0.12355838523883568, "train/model_loss_mean": 0.7502872009026377, "train/model_loss_std": 0.1990379790726461, "train/model_opt_grad_norm": 25.86910945992721, "train/model_opt_grad_steps": 31226.031578947368, "train/model_opt_loss": 2713.1825053967927, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3618.4210526315787, "train/policy_entropy_mag": 1.9371608100439373, "train/policy_entropy_max": 1.9371608100439373, "train/policy_entropy_mean": 1.7092136514814276, "train/policy_entropy_min": 0.8125824413801495, "train/policy_entropy_std": 0.1335242756887486, "train/policy_logprob_mag": 4.065735412898817, "train/policy_logprob_max": -0.2176260646628706, "train/policy_logprob_mean": -1.7088850742892214, "train/policy_logprob_min": -4.065735412898817, "train/policy_logprob_std": 0.6881371557712554, "train/policy_randomness_mag": 0.9955037879316431, "train/policy_randomness_max": 0.9955037879316431, "train/policy_randomness_mean": 0.8783621220212233, "train/policy_randomness_min": 0.4175847942891874, "train/policy_randomness_std": 0.06861790781350512, "train/post_ent_mag": 16.714041679783872, "train/post_ent_max": 16.714041679783872, "train/post_ent_mean": 15.841919733348645, "train/post_ent_min": 15.372794342041015, "train/post_ent_std": 0.2547045641039547, "train/prior_ent_mag": 18.80871326044986, "train/prior_ent_max": 18.80871326044986, "train/prior_ent_mean": 16.087013756601433, "train/prior_ent_min": 14.202833080291748, "train/prior_ent_std": 0.6725130275676124, "train/rep_loss_mean": 1.0000226579214397, "train/rep_loss_std": 0.0007242462989923202, "train/reward_avg": 0.00020652958544240774, "train/reward_loss_mean": 0.009094638857794435, "train/reward_loss_std": 0.013972902793045106, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0011374184959813168, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009094638840638493, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0002061837230269846, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7065105641141851, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.00024858335382305086, "report/cont_loss_std": 0.0005877993535250425, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00024858335382305086, "report/cont_pred": 0.9997515678405762, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.13188210129737854, "report/image_loss_std": 0.12636089324951172, "report/model_loss_mean": 0.7414864301681519, "report/model_loss_std": 0.1302107572555542, "report/post_ent_mag": 15.769427299499512, "report/post_ent_max": 15.769427299499512, "report/post_ent_mean": 14.947317123413086, "report/post_ent_min": 14.410846710205078, "report/post_ent_std": 0.2412460595369339, "report/prior_ent_mag": 18.178482055664062, "report/prior_ent_max": 18.178482055664062, "report/prior_ent_mean": 15.611085891723633, "report/prior_ent_min": 13.812182426452637, "report/prior_ent_std": 0.6876422762870789, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002144189056707546, "report/reward_loss_mean": 0.00935572013258934, "report/reward_loss_std": 0.014033354818820953, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001157522201538086, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009355721063911915, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00020568585023283958, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.00936147104948759, "eval/cont_loss_std": 0.28892526030540466, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.250096321105957, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0003284939157310873, "eval/cont_pred": 0.999674916267395, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.27201634645462036, "eval/image_loss_std": 0.173352912068367, "eval/model_loss_mean": 0.8823955655097961, "eval/model_loss_std": 0.3411007225513458, "eval/post_ent_mag": 15.769491195678711, "eval/post_ent_max": 15.769491195678711, "eval/post_ent_mean": 14.936683654785156, "eval/post_ent_min": 14.463586807250977, "eval/post_ent_std": 0.24385011196136475, "eval/prior_ent_mag": 18.178482055664062, "eval/prior_ent_max": 18.178482055664062, "eval/prior_ent_mean": 15.521321296691895, "eval/prior_ent_min": 12.814762115478516, "eval/prior_ent_std": 0.7312759757041931, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001017729751765728, "eval/reward_loss_std": 0.0012466232292354107, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.000989079475402832, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001017729751765728, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00016010552644729614, "eval/reward_rate": 0.0, "replay/size": 516369.0, "replay/inserts": 30512.0, "replay/samples": 30512.0, "replay/insert_wait_avg": 1.3273988772763841e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.396222195077705e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1086060984706233e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1574063301086, "timer/env.step_count": 3814.0, "timer/env.step_total": 34.37063670158386, "timer/env.step_frac": 0.034365227397255914, "timer/env.step_avg": 0.009011703382691102, "timer/env.step_min": 0.007481575012207031, "timer/env.step_max": 0.03525853157043457, "timer/replay._sample_count": 30512.0, "timer/replay._sample_total": 15.443960189819336, "timer/replay._sample_frac": 0.015441529595314474, "timer/replay._sample_avg": 0.0005061602054869998, "timer/replay._sample_min": 0.0004146099090576172, "timer/replay._sample_max": 0.04902935028076172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5737.0, "timer/agent.policy_total": 58.43660020828247, "timer/agent.policy_frac": 0.05842740336514099, "timer/agent.policy_avg": 0.010185916020268864, "timer/agent.policy_min": 0.008771181106567383, "timer/agent.policy_max": 0.08838582038879395, "timer/dataset_train_count": 1907.0, "timer/dataset_train_total": 0.20287275314331055, "timer/dataset_train_frac": 0.00020284082471349617, "timer/dataset_train_avg": 0.00010638319514594156, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.00018477439880371094, "timer/agent.train_count": 1907.0, "timer/agent.train_total": 851.208984375, "timer/agent.train_frac": 0.8510750197794894, "timer/agent.train_avg": 0.4463602435107499, "timer/agent.train_min": 0.4341728687286377, "timer/agent.train_max": 1.846817970275879, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4749114513397217, "timer/agent.report_frac": 0.00047483670903595144, "timer/agent.report_avg": 0.23745572566986084, "timer/agent.report_min": 0.23104190826416016, "timer/agent.report_max": 0.24386954307556152, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.90824888825452e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 30.506663182829918}
{"step": 516920, "time": 17210.8186545372, "episode/length": 640.0, "episode/score": 0.2652052146551682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2652052146551682}
{"step": 517296, "time": 17222.808596134186, "episode/length": 640.0, "episode/score": 0.26879533170841796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26879533170841796}
{"step": 517336, "time": 17223.83986711502, "episode/length": 640.0, "episode/score": 0.27180377755206564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27180377755206564}
{"step": 517928, "time": 17242.41554927826, "episode/length": 640.0, "episode/score": 0.21524875991264025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21524875991264025}
{"step": 518024, "time": 17245.400372982025, "episode/length": 640.0, "episode/score": 0.2279776449549331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2279776449549331}
{"step": 519144, "time": 17280.44450044632, "episode/length": 640.0, "episode/score": 0.20023978298991096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20023978298991096}
{"step": 520000, "time": 17319.336545467377, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17319.345911741257, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17319.35455441475, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17319.362979888916, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17319.37085056305, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17319.378609657288, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17319.386386156082, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 17319.394079446793, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 521064, "time": 17352.60857152939, "episode/length": 640.0, "episode/score": 0.2205477744143991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2205477744143991}
{"step": 521648, "time": 17371.189260482788, "episode/length": 640.0, "episode/score": 0.16356114845689262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16356114845689262}
{"step": 522048, "time": 17383.855205774307, "episode/length": 640.0, "episode/score": 0.13313739869346364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13313739869346364}
{"step": 522424, "time": 17395.59786248207, "episode/length": 640.0, "episode/score": 0.2288988190815644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2288988190815644}
{"step": 522464, "time": 17397.06716823578, "episode/length": 640.0, "episode/score": 0.22750129717678647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22750129717678647}
{"step": 523056, "time": 17415.563940048218, "episode/length": 640.0, "episode/score": 0.11022456865399022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11022456865399022}
{"step": 523152, "time": 17418.631503582, "episode/length": 640.0, "episode/score": 0.1080280003538121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1080280003538121}
{"step": 524272, "time": 17453.646959543228, "episode/length": 640.0, "episode/score": 0.10510396566562008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10510396566562008}
{"step": 526192, "time": 17514.426340579987, "episode/length": 640.0, "episode/score": 0.19637846940307213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19637846940307213}
{"step": 526320, "time": 17518.507358551025, "episode/length": 533.0, "episode/score": 0.18836817160141095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18836817160141095}
{"step": 526776, "time": 17532.657788991928, "episode/length": 640.0, "episode/score": 0.15403536203774593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15403536203774593}
{"step": 527552, "time": 17557.25919175148, "episode/length": 640.0, "episode/score": 0.11812254278092382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11812254278092382}
{"step": 527592, "time": 17558.288940906525, "episode/length": 640.0, "episode/score": 0.12712908838150838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12712908838150838}
{"step": 528184, "time": 17576.853812932968, "episode/length": 640.0, "episode/score": 0.13908247590055112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13908247590055112}
{"step": 528280, "time": 17579.85635781288, "episode/length": 640.0, "episode/score": 0.1303600301938559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1303600301938559}
{"step": 529400, "time": 17614.971130609512, "episode/length": 640.0, "episode/score": 0.05339972830600459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05339972830600459}
{"step": 530088, "time": 17645.628787517548, "eval_episode/length": 507.0, "eval_episode/score": 0.28703126311302185, "eval_episode/reward_rate": 0.001968503937007874}
{"step": 530088, "time": 17648.07603096962, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17648.085862636566, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17648.094465255737, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17648.102580547333, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17648.110848903656, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17648.118893384933, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17648.12732553482, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 531320, "time": 17687.54513144493, "episode/length": 640.0, "episode/score": 0.08073080316671621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08073080316671621}
{"step": 531448, "time": 17691.626087903976, "episode/length": 640.0, "episode/score": 0.18263284763986576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18263284763986576}
{"step": 531904, "time": 17706.109545230865, "episode/length": 640.0, "episode/score": 0.20153399085285173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20153399085285173}
{"step": 532680, "time": 17730.676605463028, "episode/length": 640.0, "episode/score": 0.06841779789522207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06841779789522207}
{"step": 532720, "time": 17732.147791147232, "episode/length": 640.0, "episode/score": 0.17902896204967078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17902896204967078}
{"step": 533312, "time": 17750.87113237381, "episode/length": 640.0, "episode/score": 0.09677132829941115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09677132829941115}
{"step": 533408, "time": 17753.906407117844, "episode/length": 640.0, "episode/score": 0.04568864909947479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04568864909947479}
{"step": 534528, "time": 17789.209456443787, "episode/length": 640.0, "episode/score": 0.14618568617777328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14618568617777328}
{"step": 536448, "time": 17849.967893123627, "episode/length": 640.0, "episode/score": 0.13380740710431382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13380740710431382}
{"step": 536576, "time": 17853.97452688217, "episode/length": 640.0, "episode/score": 0.12080463171253086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12080463171253086}
{"step": 537032, "time": 17868.114268779755, "episode/length": 640.0, "episode/score": 0.0742905001369536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0742905001369536}
{"step": 537808, "time": 17892.585924863815, "episode/length": 640.0, "episode/score": 0.0820885099053612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0820885099053612}
{"step": 537848, "time": 17893.620459079742, "episode/length": 640.0, "episode/score": 0.08248143525031537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08248143525031537}
{"step": 538440, "time": 17912.495687007904, "episode/length": 640.0, "episode/score": 0.21101436914148053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21101436914148053}
{"step": 538536, "time": 17915.557112455368, "episode/length": 640.0, "episode/score": 0.0528193105212722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0528193105212722}
{"step": 539656, "time": 17951.154844522476, "episode/length": 640.0, "episode/score": 0.100294244415295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.100294244415295}
{"step": 540072, "time": 17974.970379829407, "eval_episode/length": 549.0, "eval_episode/score": 0.2279687523841858, "eval_episode/reward_rate": 0.0018181818181818182}
{"step": 540072, "time": 17976.68524837494, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17976.695347070694, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17976.70383453369, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17976.711998701096, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17976.719992160797, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17976.727915525436, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 17976.736124277115, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 541576, "time": 18024.440900325775, "episode/length": 640.0, "episode/score": 0.03812196146657243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03812196146657243}
{"step": 541704, "time": 18028.418684244156, "episode/length": 640.0, "episode/score": 0.1570702447918393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1570702447918393}
{"step": 542160, "time": 18042.88864517212, "episode/length": 640.0, "episode/score": 0.11013483418480519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11013483418480519}
{"step": 542936, "time": 18067.03784918785, "episode/length": 640.0, "episode/score": 0.0897420325920848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0897420325920848}
{"step": 542976, "time": 18068.522851228714, "episode/length": 640.0, "episode/score": 0.16646341071259485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16646341071259485}
{"step": 543568, "time": 18087.12784051895, "episode/length": 640.0, "episode/score": 0.07221231157149077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07221231157149077}
{"step": 543664, "time": 18090.155898332596, "episode/length": 640.0, "episode/score": 0.14943806479857358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14943806479857358}
{"step": 544784, "time": 18125.610893011093, "episode/length": 640.0, "episode/score": 0.093671091391343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.093671091391343}
{"step": 546704, "time": 18185.972990989685, "episode/length": 640.0, "episode/score": 0.10980068927096909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10980068927096909}
{"step": 546832, "time": 18190.066905736923, "episode/length": 640.0, "episode/score": 0.11942084578345202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11942084578345202}
{"step": 547288, "time": 18204.43494296074, "episode/length": 640.0, "episode/score": 0.06358433198477087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06358433198477087}
{"step": 547433, "time": 18210.011761426926, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.204772629662958, "train/action_min": 0.0, "train/action_std": 1.858795473712901, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0008141365650729203, "train/actor_opt_grad_steps": 33160.0, "train/actor_opt_loss": -7.243311317803348, "train/adv_mag": 0.0749675399033811, "train/adv_max": 0.004470271121769051, "train/adv_mean": -4.8966563254141026e-05, "train/adv_min": -0.0747657666343669, "train/adv_std": 0.002332414701551745, "train/cont_avg": 0.9984865837696335, "train/cont_loss_mean": 0.004378626977595749, "train/cont_loss_std": 0.099442034132391, "train/cont_neg_acc": 0.5482570827007294, "train/cont_neg_loss": 2.275695875985548, "train/cont_pos_acc": 0.9999026924527753, "train/cont_pos_loss": 0.000856149616359894, "train/cont_pred": 0.998444364333028, "train/cont_rate": 0.9984865837696335, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.035698644846588794, "train/extr_critic_critic_opt_grad_steps": 33160.0, "train/extr_critic_critic_opt_loss": 13351.103658785994, "train/extr_critic_mag": 0.0964061271457772, "train/extr_critic_max": 0.0964061271457772, "train/extr_critic_mean": 0.09366638447445724, "train/extr_critic_min": 0.08845210761924065, "train/extr_critic_std": 0.001026013166355993, "train/extr_return_normed_mag": 0.07367156492790003, "train/extr_return_normed_max": 0.0073470986638393704, "train/extr_return_normed_mean": 0.0021940967871402805, "train/extr_return_normed_min": -0.07285297981887588, "train/extr_return_normed_std": 0.002594761766800511, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09877041684395356, "train/extr_return_raw_max": 0.09877041684395356, "train/extr_return_raw_mean": 0.09361742035100597, "train/extr_return_raw_min": 0.01857033836123831, "train/extr_return_raw_std": 0.002594761773505058, "train/extr_reward_mag": 0.0012783030564872382, "train/extr_reward_max": 0.0012783030564872382, "train/extr_reward_mean": 0.00026846204478115683, "train/extr_reward_min": 1.3980565894960733e-06, "train/extr_reward_std": 0.0002609402099313429, "train/image_loss_mean": 0.1299199580132025, "train/image_loss_std": 0.12343360717696045, "train/model_loss_mean": 0.7433682820559796, "train/model_loss_std": 0.18275383469790063, "train/model_opt_grad_norm": 23.881983851887167, "train/model_opt_grad_steps": 33130.0, "train/model_opt_loss": 2791.2011373629744, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3756.544502617801, "train/policy_entropy_mag": 1.9385475313476244, "train/policy_entropy_max": 1.9385475313476244, "train/policy_entropy_mean": 1.7067446334199756, "train/policy_entropy_min": 0.7798938741858717, "train/policy_entropy_std": 0.13813296381715703, "train/policy_logprob_mag": 4.133442441830461, "train/policy_logprob_max": -0.2053034488911404, "train/policy_logprob_mean": -1.7062036073644749, "train/policy_logprob_min": -4.133442441830461, "train/policy_logprob_std": 0.688603531939821, "train/policy_randomness_mag": 0.9962164194796098, "train/policy_randomness_max": 0.9962164194796098, "train/policy_randomness_mean": 0.8770932904712817, "train/policy_randomness_min": 0.4007861926293498, "train/policy_randomness_std": 0.07098630513430265, "train/post_ent_mag": 15.509621859845067, "train/post_ent_max": 15.509621859845067, "train/post_ent_mean": 14.553646966424912, "train/post_ent_min": 14.020016295747608, "train/post_ent_std": 0.2810292133954183, "train/prior_ent_mag": 17.48435374953984, "train/prior_ent_max": 17.48435374953984, "train/prior_ent_mean": 14.486807593500426, "train/prior_ent_min": 12.408719262527546, "train/prior_ent_std": 0.7516879248993559, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00020616252152968432, "train/reward_loss_mean": 0.009069669389541393, "train/reward_loss_std": 0.01388119117244688, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0011862535127170424, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009069669389541393, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00020868896143462178, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7012436316937816, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.008239216171205044, "report/cont_loss_std": 0.2513435184955597, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 4.031103610992432, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00036668358370661736, "report/cont_pred": 0.9986724853515625, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10180218517780304, "report/image_loss_std": 0.11730566620826721, "report/model_loss_mean": 0.717796802520752, "report/model_loss_std": 0.2821388244628906, "report/post_ent_mag": 15.186846733093262, "report/post_ent_max": 15.186846733093262, "report/post_ent_mean": 14.078107833862305, "report/post_ent_min": 13.407766342163086, "report/post_ent_std": 0.3281746804714203, "report/prior_ent_mag": 17.06545639038086, "report/prior_ent_max": 17.06545639038086, "report/prior_ent_mean": 14.229333877563477, "report/prior_ent_min": 12.240875244140625, "report/prior_ent_std": 0.7399821281433105, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001755259436322376, "report/reward_loss_mean": 0.007755408063530922, "report/reward_loss_std": 0.013290653005242348, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013543367385864258, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007755408529192209, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00019304617308080196, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.01001016329973936, "eval/cont_loss_std": 0.3050263822078705, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.765682220458984, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00047382735647261143, "eval/cont_pred": 0.9995304942131042, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3125171959400177, "eval/image_loss_std": 0.1702185422182083, "eval/model_loss_mean": 0.9238021373748779, "eval/model_loss_std": 0.353547602891922, "eval/post_ent_mag": 15.186765670776367, "eval/post_ent_max": 15.186765670776367, "eval/post_ent_mean": 14.064268112182617, "eval/post_ent_min": 13.548458099365234, "eval/post_ent_std": 0.30318599939346313, "eval/prior_ent_mag": 17.06545639038086, "eval/prior_ent_max": 17.06545639038086, "eval/prior_ent_mean": 14.273090362548828, "eval/prior_ent_min": 12.360639572143555, "eval/prior_ent_std": 0.7432782053947449, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001274788286536932, "eval/reward_loss_std": 0.0015367281157523394, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001231551170349121, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001274788286536932, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00020049256272614002, "eval/reward_rate": 0.0, "replay/size": 546929.0, "replay/inserts": 30560.0, "replay/samples": 30560.0, "replay/insert_wait_avg": 1.3127923011779784e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.384438709438783e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1342240074185487e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4471938610077, "timer/env.step_count": 3820.0, "timer/env.step_total": 34.53562307357788, "timer/env.step_frac": 0.03452018585838117, "timer/env.step_avg": 0.009040739024496827, "timer/env.step_min": 0.007492542266845703, "timer/env.step_max": 0.045099496841430664, "timer/replay._sample_count": 30560.0, "timer/replay._sample_total": 15.404723882675171, "timer/replay._sample_frac": 0.01539783806402015, "timer/replay._sample_avg": 0.0005040812788833499, "timer/replay._sample_min": 0.00041413307189941406, "timer/replay._sample_max": 0.025479793548583984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5743.0, "timer/agent.policy_total": 58.63941788673401, "timer/agent.policy_frac": 0.05861320642064872, "timer/agent.policy_avg": 0.010210589915851298, "timer/agent.policy_min": 0.008380413055419922, "timer/agent.policy_max": 0.08360862731933594, "timer/dataset_train_count": 1910.0, "timer/dataset_train_total": 0.20246648788452148, "timer/dataset_train_frac": 0.00020237598658570498, "timer/dataset_train_avg": 0.00010600339679817878, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0005252361297607422, "timer/agent.train_count": 1910.0, "timer/agent.train_total": 851.0135462284088, "timer/agent.train_frac": 0.8506331483065165, "timer/agent.train_avg": 0.4455568304860779, "timer/agent.train_min": 0.4351823329925537, "timer/agent.train_max": 0.5838000774383545, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47810983657836914, "timer/agent.report_frac": 0.0004778961243653536, "timer/agent.report_avg": 0.23905491828918457, "timer/agent.report_min": 0.23276376724243164, "timer/agent.report_max": 0.2453460693359375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.883575289961482e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 30.54578841853583}
{"step": 548064, "time": 18229.923184871674, "episode/length": 640.0, "episode/score": 0.03528090621080082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03528090621080082}
{"step": 548104, "time": 18230.97163772583, "episode/length": 640.0, "episode/score": 0.034613226746500914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034613226746500914}
{"step": 548696, "time": 18249.88821029663, "episode/length": 640.0, "episode/score": 0.037251178384565264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037251178384565264}
{"step": 548792, "time": 18252.949681282043, "episode/length": 640.0, "episode/score": 0.06745770092487646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06745770092487646}
{"step": 549912, "time": 18289.31552386284, "episode/length": 640.0, "episode/score": 0.16073878494876226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16073878494876226}
{"step": 550056, "time": 18305.850497961044, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18305.860000371933, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18305.868445396423, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18305.876705169678, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18305.8846719265, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18305.89238524437, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18305.90040254593, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 18305.908507347107, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 551200, "time": 18342.174935102463, "episode/length": 312.0, "episode/score": 0.11781344475298283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11781344475298283}
{"step": 551832, "time": 18361.92443752289, "episode/length": 640.0, "episode/score": 0.13774830287195527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13774830287195527}
{"step": 551960, "time": 18365.948234796524, "episode/length": 640.0, "episode/score": 0.10193634378919114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10193634378919114}
{"step": 552416, "time": 18380.580300807953, "episode/length": 640.0, "episode/score": 0.11596342631895595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11596342631895595}
{"step": 553192, "time": 18404.69891667366, "episode/length": 640.0, "episode/score": 0.12033369887075196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12033369887075196}
{"step": 553232, "time": 18406.31993150711, "episode/length": 640.0, "episode/score": 0.08954889305391589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08954889305391589}
{"step": 553920, "time": 18427.91459918022, "episode/length": 640.0, "episode/score": 0.10293413684303232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10293413684303232}
{"step": 555040, "time": 18463.061913967133, "episode/length": 640.0, "episode/score": 0.1611972669392685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1611972669392685}
{"step": 556328, "time": 18503.466025352478, "episode/length": 640.0, "episode/score": 0.07026757192704736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07026757192704736}
{"step": 556960, "time": 18523.578993320465, "episode/length": 640.0, "episode/score": 0.03688730434720355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03688730434720355}
{"step": 557088, "time": 18528.209730386734, "episode/length": 640.0, "episode/score": 0.0853308983498664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0853308983498664}
{"step": 557544, "time": 18542.284908771515, "episode/length": 640.0, "episode/score": 0.05936827122377508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05936827122377508}
{"step": 558320, "time": 18566.98659682274, "episode/length": 640.0, "episode/score": 0.045470450819664165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045470450819664165}
{"step": 558360, "time": 18568.038482904434, "episode/length": 640.0, "episode/score": 0.032366543364162226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032366543364162226}
{"step": 559048, "time": 18589.68546795845, "episode/length": 640.0, "episode/score": 0.1009951091085668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1009951091085668}
{"step": 560040, "time": 18632.34667634964, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18632.35637307167, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18632.365193605423, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18632.37340593338, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18632.38159942627, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18632.389542102814, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18632.397786855698, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 18632.40583395958, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560168, "time": 18636.492279291153, "episode/length": 640.0, "episode/score": 0.03934691068081975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03934691068081975}
{"step": 561456, "time": 18677.87012696266, "episode/length": 640.0, "episode/score": 0.0845786618707507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0845786618707507}
{"step": 562088, "time": 18697.889347553253, "episode/length": 640.0, "episode/score": 0.11544450433365228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11544450433365228}
{"step": 562216, "time": 18701.992095708847, "episode/length": 640.0, "episode/score": 0.02876545396173924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02876545396173924}
{"step": 562672, "time": 18716.817584753036, "episode/length": 640.0, "episode/score": 0.029530415713793445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029530415713793445}
{"step": 563448, "time": 18741.115964889526, "episode/length": 640.0, "episode/score": 0.023174872417939696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023174872417939696}
{"step": 563488, "time": 18742.63232564926, "episode/length": 640.0, "episode/score": 0.06836037272381645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06836037272381645}
{"step": 564176, "time": 18764.29494857788, "episode/length": 640.0, "episode/score": 0.08204567599818802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08204567599818802}
{"step": 565296, "time": 18800.223958969116, "episode/length": 640.0, "episode/score": 0.17961099990733942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17961099990733942}
{"step": 566584, "time": 18840.52439880371, "episode/length": 640.0, "episode/score": 0.08835257411973885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08835257411973885}
{"step": 567216, "time": 18860.83421754837, "episode/length": 640.0, "episode/score": 0.09857690204086111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09857690204086111}
{"step": 567344, "time": 18864.881899356842, "episode/length": 640.0, "episode/score": 0.06815161003717662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06815161003717662}
{"step": 567800, "time": 18879.034546613693, "episode/length": 640.0, "episode/score": 0.09277873376996126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09277873376996126}
{"step": 568576, "time": 18903.73789358139, "episode/length": 640.0, "episode/score": 0.12367386042262751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12367386042262751}
{"step": 568616, "time": 18904.80045890808, "episode/length": 640.0, "episode/score": 0.08598323209582759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08598323209582759}
{"step": 569304, "time": 18926.477788209915, "episode/length": 640.0, "episode/score": 0.12382818840410437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12382818840410437}
{"step": 570024, "time": 18957.40719127655, "eval_episode/length": 425.0, "eval_episode/score": 0.40234375, "eval_episode/reward_rate": 0.002347417840375587}
{"step": 570024, "time": 18961.17772579193, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18961.187672376633, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18961.19727897644, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18961.20592021942, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18961.214763641357, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18961.223615407944, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570024, "time": 18961.23202395439, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 570424, "time": 18974.040850639343, "episode/length": 640.0, "episode/score": 0.07665431710458392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07665431710458392}
{"step": 571528, "time": 19009.506469249725, "episode/length": 538.0, "episode/score": 0.07162868343570494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07162868343570494}
{"step": 571712, "time": 19015.615580558777, "episode/length": 640.0, "episode/score": 0.06936159838406297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06936159838406297}
{"step": 572472, "time": 19039.64800620079, "episode/length": 640.0, "episode/score": 0.12477612481060874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12477612481060874}
{"step": 572928, "time": 19054.206838607788, "episode/length": 640.0, "episode/score": 0.11455031372756252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11455031372756252}
{"step": 573704, "time": 19078.944711446762, "episode/length": 640.0, "episode/score": 0.12156166431597626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12156166431597626}
{"step": 573744, "time": 19080.46108174324, "episode/length": 640.0, "episode/score": 0.08783406752593237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08783406752593237}
{"step": 574432, "time": 19102.37528204918, "episode/length": 640.0, "episode/score": 0.043209345936332966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043209345936332966}
{"step": 575552, "time": 19137.49088716507, "episode/length": 640.0, "episode/score": 0.011485632482873598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.011485632482873598}
{"step": 576656, "time": 19172.309967517853, "episode/length": 640.0, "episode/score": 0.05745639515652101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05745639515652101}
{"step": 576840, "time": 19177.949871778488, "episode/length": 640.0, "episode/score": 0.10502435285690126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10502435285690126}
{"step": 577600, "time": 19202.243403434753, "episode/length": 640.0, "episode/score": 0.10236449080593957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10236449080593957}
{"step": 577833, "time": 19210.34570455551, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2671165064761514, "train/action_min": 0.0, "train/action_std": 1.845972866761057, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.000788351777162844, "train/actor_opt_grad_steps": 35065.0, "train/actor_opt_loss": -7.910773920934451, "train/adv_mag": 0.07437741478022776, "train/adv_max": 0.00452139412886218, "train/adv_mean": -9.127370269891942e-05, "train/adv_min": -0.07419381965147821, "train/adv_std": 0.0022189271072612, "train/cont_avg": 0.9984580592105263, "train/cont_loss_mean": 0.0034119327633800964, "train/cont_loss_std": 0.07935855594711795, "train/cont_neg_acc": 0.6769736864064869, "train/cont_neg_loss": 1.7691235444755493, "train/cont_pos_acc": 0.9999227272836786, "train/cont_pos_loss": 0.0006111850975062944, "train/cont_pred": 0.9984741145058682, "train/cont_rate": 0.9984580592105263, "train/dyn_loss_mean": 1.0000002647701063, "train/dyn_loss_std": 7.937894521379156e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.031318496255277606, "train/extr_critic_critic_opt_grad_steps": 35065.0, "train/extr_critic_critic_opt_loss": 13429.854471628289, "train/extr_critic_mag": 0.09356207220177902, "train/extr_critic_max": 0.09356207220177902, "train/extr_critic_mean": 0.09060458278185443, "train/extr_critic_min": 0.08548909300252011, "train/extr_critic_std": 0.0010831885756679663, "train/extr_return_normed_mag": 0.07299082047845187, "train/extr_return_normed_max": 0.007606406235381177, "train/extr_return_normed_mean": 0.00214515792720608, "train/extr_return_normed_min": -0.07219440372366655, "train/extr_return_normed_std": 0.002508427523762772, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09597458396303027, "train/extr_return_raw_max": 0.09597458396303027, "train/extr_return_raw_mean": 0.09051333944264212, "train/extr_return_raw_min": 0.016173774003982545, "train/extr_return_raw_std": 0.0025084275452077, "train/extr_reward_mag": 0.0012866484491448654, "train/extr_reward_max": 0.0012866484491448654, "train/extr_reward_mean": 0.00025237866242318167, "train/extr_reward_min": 1.6639107152035362e-06, "train/extr_reward_std": 0.00026127113095227337, "train/image_loss_mean": 0.12293786292797641, "train/image_loss_std": 0.12200260562332053, "train/model_loss_mean": 0.7353769198844308, "train/model_loss_std": 0.17016504438299881, "train/model_opt_grad_norm": 24.04741731944837, "train/model_opt_grad_steps": 35033.07894736842, "train/model_opt_loss": 2746.3399581106087, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3736.842105263158, "train/policy_entropy_mag": 1.9393241637631466, "train/policy_entropy_max": 1.9393241637631466, "train/policy_entropy_mean": 1.7186475069899307, "train/policy_entropy_min": 0.8115607032650396, "train/policy_entropy_std": 0.13431153575840749, "train/policy_logprob_mag": 4.199910984541241, "train/policy_logprob_max": -0.2180617001495863, "train/policy_logprob_mean": -1.718901182475843, "train/policy_logprob_min": -4.199910984541241, "train/policy_logprob_std": 0.669987208905973, "train/policy_randomness_mag": 0.996615531570033, "train/policy_randomness_max": 0.996615531570033, "train/policy_randomness_mean": 0.8832101611714614, "train/policy_randomness_min": 0.417059725052432, "train/policy_randomness_std": 0.06902247959453808, "train/post_ent_mag": 15.57321067609285, "train/post_ent_max": 15.57321067609285, "train/post_ent_mean": 14.139841235311408, "train/post_ent_min": 13.297820442601255, "train/post_ent_std": 0.42850198557502345, "train/prior_ent_mag": 17.669875747279118, "train/prior_ent_max": 17.669875747279118, "train/prior_ent_mean": 13.869377929285953, "train/prior_ent_min": 11.707120810056988, "train/prior_ent_std": 0.8699480423801824, "train/rep_loss_mean": 1.0000002647701063, "train/rep_loss_std": 7.937894521379156e-06, "train/reward_avg": 0.0002053900818665218, "train/reward_loss_mean": 0.009026940767408202, "train/reward_loss_std": 0.013821069812892299, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012111588528281763, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009026940737998016, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00020705353848538116, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7124992211659749, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.000561147287953645, "report/cont_loss_std": 0.0024210421834141016, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002342851599678397, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0005576605908572674, "report/cont_pred": 0.9974979162216187, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11554427444934845, "report/image_loss_std": 0.12945465743541718, "report/model_loss_mean": 0.7254073023796082, "report/model_loss_std": 0.13392484188079834, "report/post_ent_mag": 16.462493896484375, "report/post_ent_max": 16.462493896484375, "report/post_ent_mean": 14.024490356445312, "report/post_ent_min": 12.80001449584961, "report/post_ent_std": 0.6757683157920837, "report/prior_ent_mag": 17.60426139831543, "report/prior_ent_max": 17.60426139831543, "report/prior_ent_mean": 13.378828048706055, "report/prior_ent_min": 11.268413543701172, "report/prior_ent_std": 0.9209573268890381, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00021296489285305142, "report/reward_loss_mean": 0.00930185616016388, "report/reward_loss_std": 0.01369518507272005, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012388229370117188, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009301857091486454, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002215433632954955, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.01001137588173151, "eval/cont_loss_std": 0.2512596547603607, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.976905822753906, "eval/cont_pos_acc": 0.9990224838256836, "eval/cont_pos_loss": 0.002223599934950471, "eval/cont_pred": 0.9982068538665771, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.29865241050720215, "eval/image_loss_std": 0.14260907471179962, "eval/model_loss_mean": 0.9100313186645508, "eval/model_loss_std": 0.2937038540840149, "eval/post_ent_mag": 16.414779663085938, "eval/post_ent_max": 16.414779663085938, "eval/post_ent_mean": 13.84735107421875, "eval/post_ent_min": 12.395524978637695, "eval/post_ent_std": 0.7254027128219604, "eval/prior_ent_mag": 17.60426139831543, "eval/prior_ent_max": 17.60426139831543, "eval/prior_ent_mean": 13.277288436889648, "eval/prior_ent_min": 10.92561149597168, "eval/prior_ent_std": 0.9465240836143494, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013674693182110786, "eval/reward_loss_std": 0.0013624322600662708, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001210331916809082, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013674693182110786, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00021511211525648832, "eval/reward_rate": 0.0, "replay/size": 577329.0, "replay/inserts": 30400.0, "replay/samples": 30400.0, "replay/insert_wait_avg": 1.2857741431186074e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.330847087659334e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0847084483812702e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3169121742249, "timer/env.step_count": 3800.0, "timer/env.step_total": 34.42308950424194, "timer/env.step_frac": 0.034412183864233704, "timer/env.step_avg": 0.009058707764274195, "timer/env.step_min": 0.007440805435180664, "timer/env.step_max": 0.03606700897216797, "timer/replay._sample_count": 30400.0, "timer/replay._sample_total": 15.332740306854248, "timer/replay._sample_frac": 0.015327882714217022, "timer/replay._sample_avg": 0.0005043664574623108, "timer/replay._sample_min": 0.00037097930908203125, "timer/replay._sample_max": 0.010659217834472656, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5723.0, "timer/agent.policy_total": 58.095659494400024, "timer/agent.policy_frac": 0.058077254105528435, "timer/agent.policy_avg": 0.01015125974041587, "timer/agent.policy_min": 0.008756160736083984, "timer/agent.policy_max": 0.08746480941772461, "timer/dataset_train_count": 1900.0, "timer/dataset_train_total": 0.2001965045928955, "timer/dataset_train_frac": 0.00020013307998338365, "timer/dataset_train_avg": 0.00010536658136468185, "timer/dataset_train_min": 8.749961853027344e-05, "timer/dataset_train_max": 0.0005490779876708984, "timer/agent.train_count": 1900.0, "timer/agent.train_total": 851.8283340930939, "timer/agent.train_frac": 0.8515584648485192, "timer/agent.train_avg": 0.4483307021542599, "timer/agent.train_min": 0.4358811378479004, "timer/agent.train_max": 0.7072350978851318, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47818493843078613, "timer/agent.report_frac": 0.00047803344381275526, "timer/agent.report_avg": 0.23909246921539307, "timer/agent.report_min": 0.23385286331176758, "timer/agent.report_max": 0.24433207511901855, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.81244793440865e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 30.389811355045627}
{"step": 578056, "time": 19217.24120402336, "episode/length": 640.0, "episode/score": 0.08351596882704371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08351596882704371}
{"step": 578832, "time": 19242.121975660324, "episode/length": 640.0, "episode/score": 0.0726672914030928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0726672914030928}
{"step": 578872, "time": 19243.1751537323, "episode/length": 640.0, "episode/score": 0.10961284256080717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10961284256080717}
{"step": 579560, "time": 19265.107676029205, "episode/length": 640.0, "episode/score": 0.04062353153148024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04062353153148024}
{"step": 580008, "time": 19291.48806333542, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19291.497570991516, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19291.506154060364, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19291.514323472977, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19291.52293086052, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19291.53098797798, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19291.539630174637, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580008, "time": 19291.547982931137, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 580680, "time": 19313.06148982048, "episode/length": 640.0, "episode/score": 0.07493016927571716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07493016927571716}
{"step": 581784, "time": 19348.55181288719, "episode/length": 640.0, "episode/score": 0.09631557284427572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09631557284427572}
{"step": 581968, "time": 19354.650944709778, "episode/length": 640.0, "episode/score": 0.03461577578394781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03461577578394781}
{"step": 582728, "time": 19378.77618598938, "episode/length": 640.0, "episode/score": 0.054499382418441655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054499382418441655}
{"step": 583184, "time": 19393.625769376755, "episode/length": 640.0, "episode/score": 0.14057938723345842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14057938723345842}
{"step": 583960, "time": 19418.075524806976, "episode/length": 640.0, "episode/score": 0.08409277272863847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08409277272863847}
{"step": 584000, "time": 19419.570353507996, "episode/length": 640.0, "episode/score": 0.09380038094155907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09380038094155907}
{"step": 584688, "time": 19441.26643705368, "episode/length": 640.0, "episode/score": 0.07222393901690793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07222393901690793}
{"step": 585808, "time": 19476.51432943344, "episode/length": 640.0, "episode/score": 0.02069420103293851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02069420103293851}
{"step": 586912, "time": 19511.187349319458, "episode/length": 640.0, "episode/score": 0.1093044543082442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1093044543082442}
{"step": 587096, "time": 19516.869265317917, "episode/length": 640.0, "episode/score": 0.09657387238257797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09657387238257797}
{"step": 587856, "time": 19540.875728845596, "episode/length": 640.0, "episode/score": 0.09424323658072353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09424323658072353}
{"step": 588312, "time": 19555.00983285904, "episode/length": 640.0, "episode/score": 0.04465643281821485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04465643281821485}
{"step": 589088, "time": 19579.691956996918, "episode/length": 640.0, "episode/score": 0.07290381476053653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07290381476053653}
{"step": 589128, "time": 19580.7318649292, "episode/length": 640.0, "episode/score": 0.11107369176505699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11107369176505699}
{"step": 589816, "time": 19602.35404753685, "episode/length": 640.0, "episode/score": 0.10416696145324522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10416696145324522}
{"step": 590096, "time": 19623.260108232498, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19623.268956661224, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19623.277188777924, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19623.285165548325, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19623.293110132217, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19623.301139593124, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19623.308829784393, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590096, "time": 19623.316321611404, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 590936, "time": 19649.644322872162, "episode/length": 640.0, "episode/score": 0.049018363533605225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049018363533605225}
{"step": 592040, "time": 19686.242207050323, "episode/length": 640.0, "episode/score": 0.047334235766470556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047334235766470556}
{"step": 592224, "time": 19692.33763360977, "episode/length": 640.0, "episode/score": 0.12248883196059523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12248883196059523}
{"step": 592984, "time": 19716.543117761612, "episode/length": 640.0, "episode/score": 0.08356763500398756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08356763500398756}
{"step": 593440, "time": 19731.46019911766, "episode/length": 640.0, "episode/score": 0.11983817167703137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11983817167703137}
{"step": 594216, "time": 19755.74809908867, "episode/length": 640.0, "episode/score": 0.06319883090355916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06319883090355916}
{"step": 594256, "time": 19757.375455856323, "episode/length": 640.0, "episode/score": 0.14102001241553808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14102001241553808}
{"step": 594944, "time": 19778.949208498, "episode/length": 640.0, "episode/score": 0.16157693389550332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16157693389550332}
{"step": 596064, "time": 19814.55864572525, "episode/length": 640.0, "episode/score": 0.18947604172046795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18947604172046795}
{"step": 597024, "time": 19845.197565555573, "episode/length": 622.0, "episode/score": 0.17135815163493362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17135815163493362}
{"step": 597352, "time": 19855.53077673912, "episode/length": 640.0, "episode/score": 0.23564212421752018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23564212421752018}
{"step": 597896, "time": 19872.69043970108, "episode/length": 613.0, "episode/score": 0.21088726781738387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21088726781738387}
{"step": 598568, "time": 19894.590079545975, "episode/length": 640.0, "episode/score": 0.1887367742576771, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1887367742576771}
{"step": 599048, "time": 19910.00648999214, "episode/length": 603.0, "episode/score": 0.13281152989816292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13281152989816292}
{"step": 599384, "time": 19920.595178365707, "episode/length": 640.0, "episode/score": 0.041635221402771094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041635221402771094}
{"step": 600072, "time": 19942.67611837387, "episode/length": 640.0, "episode/score": 0.1015155834423922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1015155834423922}
{"step": 600080, "time": 19955.45788502693, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19955.466799020767, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19955.475059509277, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19955.48295879364, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19955.490941286087, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19955.498639583588, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19955.506293058395, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19955.51395726204, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 601192, "time": 19990.381772756577, "episode/length": 640.0, "episode/score": 0.20565922879575282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20565922879575282}
{"step": 602152, "time": 20020.785408973694, "episode/length": 640.0, "episode/score": 0.13159952051762502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13159952051762502}
{"step": 602480, "time": 20031.410284280777, "episode/length": 640.0, "episode/score": 0.1286289695231062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1286289695231062}
{"step": 603024, "time": 20048.540513038635, "episode/length": 640.0, "episode/score": 0.22724155495211562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22724155495211562}
{"step": 603696, "time": 20069.738921880722, "episode/length": 640.0, "episode/score": 0.1784512181112632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1784512181112632}
{"step": 604176, "time": 20085.000338554382, "episode/length": 640.0, "episode/score": 0.15193829370412004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15193829370412004}
{"step": 604512, "time": 20095.653431415558, "episode/length": 640.0, "episode/score": 0.11451183032932022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11451183032932022}
{"step": 605200, "time": 20117.3222823143, "episode/length": 640.0, "episode/score": 0.20294499288633006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20294499288633006}
{"step": 606320, "time": 20153.028597593307, "episode/length": 640.0, "episode/score": 0.19999476151008366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19999476151008366}
{"step": 607280, "time": 20183.198959112167, "episode/length": 640.0, "episode/score": 0.06884955469922716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06884955469922716}
{"step": 607608, "time": 20193.310613632202, "episode/length": 640.0, "episode/score": 0.15735171333733433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15735171333733433}
{"step": 608121, "time": 20210.518319368362, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3409745065789473, "train/action_min": 0.0, "train/action_std": 1.8938643185715927, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.000783181455795114, "train/actor_opt_grad_steps": 36965.0, "train/actor_opt_loss": -8.713472700119018, "train/adv_mag": 0.0772552442001669, "train/adv_max": 0.004368725301403749, "train/adv_mean": -0.00014136360882580927, "train/adv_min": -0.07713038407658276, "train/adv_std": 0.0023526191527612115, "train/cont_avg": 0.9984786184210527, "train/cont_loss_mean": 0.0029056137482831746, "train/cont_loss_std": 0.07088392057523475, "train/cont_neg_acc": 0.7404914546089295, "train/cont_neg_loss": 1.5234979584783082, "train/cont_pos_acc": 0.9999330636702086, "train/cont_pos_loss": 0.0006100881467175082, "train/cont_pred": 0.9984005940587897, "train/cont_rate": 0.9984786184210527, "train/dyn_loss_mean": 1.0000143923257527, "train/dyn_loss_std": 0.0003879500427405889, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.031101164143030092, "train/extr_critic_critic_opt_grad_steps": 36965.0, "train/extr_critic_critic_opt_loss": 13507.459241365132, "train/extr_critic_mag": 0.08850376355020624, "train/extr_critic_max": 0.08850376355020624, "train/extr_critic_mean": 0.08569373127661253, "train/extr_critic_min": 0.08121009688628347, "train/extr_critic_std": 0.0009881228588423446, "train/extr_return_normed_mag": 0.07558986693620681, "train/extr_return_normed_max": 0.007092500046679848, "train/extr_return_normed_mean": 0.0018349693368930418, "train/extr_return_normed_min": -0.07516901544050167, "train/extr_return_normed_std": 0.002576259015691712, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09080993435100505, "train/extr_return_raw_max": 0.09080993435100505, "train/extr_return_raw_mean": 0.08555240725216112, "train/extr_return_raw_min": 0.008548418863823539, "train/extr_return_raw_std": 0.0025762590009866184, "train/extr_reward_mag": 0.0012599179619236997, "train/extr_reward_max": 0.0012599179619236997, "train/extr_reward_mean": 0.00023610032757891245, "train/extr_reward_min": 1.827039216694079e-06, "train/extr_reward_std": 0.0002539791289324823, "train/image_loss_mean": 0.12379622196680622, "train/image_loss_std": 0.12615839929172867, "train/model_loss_mean": 0.7355740983235208, "train/model_loss_std": 0.16796043366193772, "train/model_opt_grad_norm": 23.0611942843387, "train/model_opt_grad_steps": 36931.57894736842, "train/model_opt_loss": 2720.4376689710116, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3697.3684210526317, "train/policy_entropy_mag": 1.9396713909349943, "train/policy_entropy_max": 1.9396713909349943, "train/policy_entropy_mean": 1.742160097548836, "train/policy_entropy_min": 0.8814184784889221, "train/policy_entropy_std": 0.1225958379475694, "train/policy_logprob_mag": 4.143238476703042, "train/policy_logprob_max": -0.24634178602381757, "train/policy_logprob_mean": -1.7425611634003488, "train/policy_logprob_min": -4.143238476703042, "train/policy_logprob_std": 0.6377514478407408, "train/policy_randomness_mag": 0.9967939703088058, "train/policy_randomness_max": 0.9967939703088058, "train/policy_randomness_mean": 0.895293244562651, "train/policy_randomness_min": 0.45295952338921397, "train/policy_randomness_std": 0.0630018012500123, "train/post_ent_mag": 16.477674193131296, "train/post_ent_max": 16.477674193131296, "train/post_ent_mean": 14.326883777819182, "train/post_ent_min": 13.017879014266164, "train/post_ent_std": 0.6465766296574944, "train/prior_ent_mag": 16.125934620907433, "train/prior_ent_max": 16.125934620907433, "train/prior_ent_mean": 13.037099798102128, "train/prior_ent_min": 11.376385096499794, "train/prior_ent_std": 0.6751809744458449, "train/rep_loss_mean": 1.0000143923257527, "train/rep_loss_std": 0.0003879500427405889, "train/reward_avg": 0.00020119464285304084, "train/reward_loss_mean": 0.008863598664634322, "train/reward_loss_std": 0.013702351996969236, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012026266047829076, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00886359867198687, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0002017315415861575, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.742485135159594, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0003284732229076326, "report/cont_loss_std": 0.0014722609193995595, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.011249910108745098, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0003071005630772561, "report/cont_pred": 0.9977629780769348, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10599540174007416, "report/image_loss_std": 0.1156855970621109, "report/model_loss_mean": 0.7155288457870483, "report/model_loss_std": 0.11963760852813721, "report/post_ent_mag": 17.223953247070312, "report/post_ent_max": 17.223953247070312, "report/post_ent_mean": 14.285545349121094, "report/post_ent_min": 12.271242141723633, "report/post_ent_std": 0.9230658411979675, "report/prior_ent_mag": 15.298587799072266, "report/prior_ent_max": 15.298587799072266, "report/prior_ent_mean": 12.798362731933594, "report/prior_ent_min": 11.44573974609375, "report/prior_ent_std": 0.6373196840286255, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00021130486857146025, "report/reward_loss_mean": 0.009204935282468796, "report/reward_loss_std": 0.014146953821182251, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0011309385299682617, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009204935282468796, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00018236890900880098, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009677121415734291, "eval/cont_loss_std": 0.29891934990882874, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.570382118225098, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0003313686465844512, "eval/cont_pred": 0.9996693134307861, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.28499236702919006, "eval/image_loss_std": 0.1473267674446106, "eval/model_loss_mean": 0.9200011491775513, "eval/model_loss_std": 1.0732847452163696, "eval/post_ent_mag": 17.192176818847656, "eval/post_ent_max": 17.192176818847656, "eval/post_ent_mean": 14.078838348388672, "eval/post_ent_min": 12.535282135009766, "eval/post_ent_std": 0.9119382500648499, "eval/prior_ent_mag": 15.360629081726074, "eval/prior_ent_max": 15.360629081726074, "eval/prior_ent_mean": 12.71561050415039, "eval/prior_ent_min": 11.315673828125, "eval/prior_ent_std": 0.6426461338996887, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007431030389852822, "eval/reward_loss_mean": 0.02533162385225296, "eval/reward_loss_std": 0.7691185474395752, "eval/reward_max_data": 0.760937511920929, "eval/reward_max_pred": 0.0010144710540771484, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001284961006604135, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 24.62506866455078, "eval/reward_pred": 0.0002019503153860569, "eval/reward_rate": 0.0009765625, "replay/size": 607617.0, "replay/inserts": 30288.0, "replay/samples": 30288.0, "replay/insert_wait_avg": 1.28720685784551e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.37794763350449e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1185557037607433e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1564464569092, "timer/env.step_count": 3786.0, "timer/env.step_total": 34.33160138130188, "timer/env.step_frac": 0.03432623116405722, "timer/env.step_avg": 0.009068040512758025, "timer/env.step_min": 0.007479429244995117, "timer/env.step_max": 0.048185110092163086, "timer/replay._sample_count": 30288.0, "timer/replay._sample_total": 15.337956190109253, "timer/replay._sample_frac": 0.015335556996552414, "timer/replay._sample_avg": 0.0005064037305239453, "timer/replay._sample_min": 0.0003960132598876953, "timer/replay._sample_max": 0.018327713012695312, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5709.0, "timer/agent.policy_total": 58.108572483062744, "timer/agent.policy_frac": 0.058099483024795257, "timer/agent.policy_avg": 0.010178415218613197, "timer/agent.policy_min": 0.008781671524047852, "timer/agent.policy_max": 0.09972023963928223, "timer/dataset_train_count": 1893.0, "timer/dataset_train_total": 0.20608925819396973, "timer/dataset_train_frac": 0.0002060570213030656, "timer/dataset_train_avg": 0.00010886912741361317, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.00058746337890625, "timer/agent.train_count": 1893.0, "timer/agent.train_total": 851.333025932312, "timer/agent.train_frac": 0.851199858730292, "timer/agent.train_avg": 0.44972690223576967, "timer/agent.train_min": 0.43538761138916016, "timer/agent.train_max": 2.0681536197662354, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4782407283782959, "timer/agent.report_frac": 0.0004781659210141385, "timer/agent.report_avg": 0.23912036418914795, "timer/agent.report_min": 0.23186850547790527, "timer/agent.report_max": 0.24637222290039062, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075118579003896e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 30.28275072052208}
{"step": 608152, "time": 20211.25190424919, "episode/length": 640.0, "episode/score": 0.09350266639603433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09350266639603433}
{"step": 608824, "time": 20232.453935861588, "episode/length": 640.0, "episode/score": 0.19000145550506886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19000145550506886}
{"step": 609304, "time": 20247.748486042023, "episode/length": 640.0, "episode/score": 0.22484907079149252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22484907079149252}
{"step": 609640, "time": 20258.233954668045, "episode/length": 640.0, "episode/score": 0.23347782791228155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23347782791228155}
{"step": 610064, "time": 20283.68864607811, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 20283.742505311966, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 20283.794902801514, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 20283.858486413956, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 20283.909296751022, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 20283.952530622482, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 20283.989866495132, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610064, "time": 20284.047738552094, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 610328, "time": 20292.16854739189, "episode/length": 640.0, "episode/score": 0.14843731690586992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14843731690586992}
{"step": 611448, "time": 20327.782828092575, "episode/length": 640.0, "episode/score": 0.2430945019038404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2430945019038404}
{"step": 612408, "time": 20358.480525493622, "episode/length": 640.0, "episode/score": 0.19617405070977156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19617405070977156}
{"step": 612736, "time": 20369.217213630676, "episode/length": 640.0, "episode/score": 0.20711556238063622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20711556238063622}
{"step": 613280, "time": 20386.49952197075, "episode/length": 640.0, "episode/score": 0.2243125027562769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2243125027562769}
{"step": 613952, "time": 20407.560219287872, "episode/length": 640.0, "episode/score": 0.20922583985623078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20922583985623078}
{"step": 614432, "time": 20423.439661741257, "episode/length": 640.0, "episode/score": 0.22607404087824534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22607404087824534}
{"step": 614768, "time": 20434.02306175232, "episode/length": 640.0, "episode/score": 0.2360560689464819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2360560689464819}
{"step": 615456, "time": 20455.659482479095, "episode/length": 640.0, "episode/score": 0.18485920711970039, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18485920711970039}
{"step": 616576, "time": 20490.979818344116, "episode/length": 640.0, "episode/score": 0.09475413703444246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09475413703444246}
{"step": 617536, "time": 20521.27698659897, "episode/length": 640.0, "episode/score": 0.12997410122829933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12997410122829933}
{"step": 617864, "time": 20531.352741479874, "episode/length": 640.0, "episode/score": 0.15437791389189215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15437791389189215}
{"step": 618408, "time": 20548.54527258873, "episode/length": 640.0, "episode/score": 0.09821038867738707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09821038867738707}
{"step": 619080, "time": 20569.741500139236, "episode/length": 640.0, "episode/score": 0.13435787471689764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13435787471689764}
{"step": 619560, "time": 20584.836566209793, "episode/length": 640.0, "episode/score": 0.20573586699663338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20573586699663338}
{"step": 619896, "time": 20595.367985725403, "episode/length": 640.0, "episode/score": 0.08424520789361623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08424520789361623}
{"step": 620048, "time": 20611.690001010895, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20611.698918819427, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20611.707029104233, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20611.715064287186, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20611.722892045975, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20611.731344223022, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20611.738874197006, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620048, "time": 20611.746389627457, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 620584, "time": 20628.424695968628, "episode/length": 640.0, "episode/score": 0.16998767435546824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16998767435546824}
{"step": 621704, "time": 20663.928822755814, "episode/length": 640.0, "episode/score": 0.1377908087250148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1377908087250148}
{"step": 622664, "time": 20694.865676641464, "episode/length": 640.0, "episode/score": 0.13330059873487698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13330059873487698}
{"step": 622992, "time": 20705.4366877079, "episode/length": 640.0, "episode/score": 0.19251176762520572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19251176762520572}
{"step": 623536, "time": 20722.699726343155, "episode/length": 640.0, "episode/score": 0.20675185252972028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20675185252972028}
{"step": 624208, "time": 20743.769792318344, "episode/length": 640.0, "episode/score": 0.21125898374495478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21125898374495478}
{"step": 624688, "time": 20758.904526233673, "episode/length": 640.0, "episode/score": 0.12420804775359784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12420804775359784}
{"step": 625024, "time": 20769.478366613388, "episode/length": 640.0, "episode/score": 0.14690527806629916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14690527806629916}
{"step": 625712, "time": 20791.250804185867, "episode/length": 640.0, "episode/score": 0.20745729688155734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20745729688155734}
{"step": 626832, "time": 20826.994213819504, "episode/length": 640.0, "episode/score": 0.1516197717093064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1516197717093064}
{"step": 627792, "time": 20857.58889389038, "episode/length": 640.0, "episode/score": 0.23111511575771715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23111511575771715}
{"step": 628120, "time": 20867.89649271965, "episode/length": 640.0, "episode/score": 0.18508837820044732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18508837820044732}
{"step": 628664, "time": 20885.265089035034, "episode/length": 640.0, "episode/score": 0.2161928152351038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2161928152351038}
{"step": 629336, "time": 20906.75981235504, "episode/length": 640.0, "episode/score": 0.16824712006132359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16824712006132359}
{"step": 629816, "time": 20921.838978767395, "episode/length": 640.0, "episode/score": 0.1983218695838218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1983218695838218}
{"step": 630032, "time": 20940.84229183197, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20940.85107088089, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20940.85924744606, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20940.867911100388, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20940.8759701252, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20940.88368344307, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20940.891664266586, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20940.899719953537, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630152, "time": 20944.447043657303, "episode/length": 640.0, "episode/score": 0.2457388564208145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2457388564208145}
{"step": 630840, "time": 20966.62254023552, "episode/length": 640.0, "episode/score": 0.21936599476231322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21936599476231322}
{"step": 631960, "time": 21001.804180145264, "episode/length": 640.0, "episode/score": 0.13257493872424675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13257493872424675}
{"step": 632920, "time": 21032.305809497833, "episode/length": 640.0, "episode/score": 0.2166683722746825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2166683722746825}
{"step": 633248, "time": 21042.884039402008, "episode/length": 640.0, "episode/score": 0.18194244460676146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18194244460676146}
{"step": 633792, "time": 21060.155113220215, "episode/length": 640.0, "episode/score": 0.05861724090237885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05861724090237885}
{"step": 634464, "time": 21081.405343532562, "episode/length": 640.0, "episode/score": 0.16369497668466693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16369497668466693}
{"step": 634944, "time": 21096.4619743824, "episode/length": 640.0, "episode/score": 0.08848402563415902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08848402563415902}
{"step": 635280, "time": 21107.16156077385, "episode/length": 640.0, "episode/score": 0.08610866014396379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08610866014396379}
{"step": 635968, "time": 21128.840492486954, "episode/length": 640.0, "episode/score": 0.19132594970426453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19132594970426453}
{"step": 637088, "time": 21164.461145401, "episode/length": 640.0, "episode/score": 0.12354607211511848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12354607211511848}
{"step": 638048, "time": 21194.651584863663, "episode/length": 640.0, "episode/score": 0.1496211555751188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1496211555751188}
{"step": 638376, "time": 21204.85115623474, "episode/length": 640.0, "episode/score": 0.11424507671426909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11424507671426909}
{"step": 638537, "time": 21210.8811480999, "train_stats/mean_log_entropy": 1.7562348047892253, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3400098298725327, "train/action_min": 0.0, "train/action_std": 1.8791231908296284, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0006963643914787099, "train/actor_opt_grad_steps": 38865.0, "train/actor_opt_loss": -7.681877329475001, "train/adv_mag": 0.07099930538158668, "train/adv_max": 0.004521308682466808, "train/adv_mean": -8.039456731903796e-05, "train/adv_min": -0.0707995475514939, "train/adv_std": 0.0020839463515011105, "train/cont_avg": 0.9984272203947369, "train/cont_loss_mean": 0.0030140962639339515, "train/cont_loss_std": 0.07414182022315033, "train/cont_neg_acc": 0.7262786621296847, "train/cont_neg_loss": 1.519408143167693, "train/cont_pos_acc": 0.9999227636738828, "train/cont_pos_loss": 0.0005682303618462021, "train/cont_pred": 0.9984158632002379, "train/cont_rate": 0.9984272203947369, "train/dyn_loss_mean": 1.0000022285862973, "train/dyn_loss_std": 4.324785465877013e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.029451661505797682, "train/extr_critic_critic_opt_grad_steps": 38865.0, "train/extr_critic_critic_opt_loss": 13529.526310649671, "train/extr_critic_mag": 0.08466491009059705, "train/extr_critic_max": 0.08466491009059705, "train/extr_critic_mean": 0.08185615402303244, "train/extr_critic_min": 0.07752685923325388, "train/extr_critic_std": 0.000985747245814357, "train/extr_return_normed_mag": 0.06948063585319017, "train/extr_return_normed_max": 0.007388581766893989, "train/extr_return_normed_mean": 0.001969116925733703, "train/extr_return_normed_min": -0.06878132098599483, "train/extr_return_normed_std": 0.0023306754025581634, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08719524015721522, "train/extr_return_raw_max": 0.08719524015721522, "train/extr_return_raw_mean": 0.08177577947315416, "train/extr_return_raw_min": 0.011025337404326388, "train/extr_return_raw_std": 0.0023306753994946027, "train/extr_reward_mag": 0.0012720327628286262, "train/extr_reward_max": 0.0012720327628286262, "train/extr_reward_mean": 0.00023559127332287302, "train/extr_reward_min": 1.9443662543045847e-06, "train/extr_reward_std": 0.000257458918234701, "train/image_loss_mean": 0.11797253132650727, "train/image_loss_std": 0.12260671591288165, "train/model_loss_mean": 0.7299661551651202, "train/model_loss_std": 0.16715831850704393, "train/model_opt_grad_norm": 21.98445782912405, "train/model_opt_grad_steps": 38830.54210526316, "train/model_opt_loss": 3677.9171463815787, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5039.473684210527, "train/policy_entropy_mag": 1.9412902562241805, "train/policy_entropy_max": 1.9412902562241805, "train/policy_entropy_mean": 1.7545137763023377, "train/policy_entropy_min": 0.9029455351202111, "train/policy_entropy_std": 0.11896606507269959, "train/policy_logprob_mag": 4.089269039505407, "train/policy_logprob_max": -0.25444833965677965, "train/policy_logprob_mean": -1.754740560054779, "train/policy_logprob_min": -4.089269039505407, "train/policy_logprob_std": 0.6244293181519759, "train/policy_randomness_mag": 0.9976259030793843, "train/policy_randomness_max": 0.9976259030793843, "train/policy_randomness_mean": 0.9016417773146378, "train/policy_randomness_min": 0.46402224004268644, "train/policy_randomness_std": 0.061136467421525405, "train/post_ent_mag": 17.009619833293716, "train/post_ent_max": 17.009619833293716, "train/post_ent_mean": 14.470000698691921, "train/post_ent_min": 12.807143868898091, "train/post_ent_std": 0.8000015660336143, "train/prior_ent_mag": 15.391965278826262, "train/prior_ent_max": 15.391965278826262, "train/prior_ent_mean": 13.308761170035915, "train/prior_ent_min": 11.764168392984491, "train/prior_ent_std": 0.5616151475592663, "train/rep_loss_mean": 1.0000022285862973, "train/rep_loss_std": 4.324785465877013e-05, "train/reward_avg": 0.00020448278710797526, "train/reward_loss_mean": 0.00897816796787083, "train/reward_loss_std": 0.013798694170423243, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012041687965393066, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008978167945813192, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00020441104118761264, "train/reward_rate": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0002524717419873923, "report/cont_loss_std": 0.0007792572723701596, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.007462998852133751, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00022419512970373034, "report/cont_pred": 0.9958995580673218, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11848822981119156, "report/image_loss_std": 0.1323762834072113, "report/model_loss_mean": 0.7265578508377075, "report/model_loss_std": 0.1363207846879959, "report/post_ent_mag": 17.933509826660156, "report/post_ent_max": 17.933509826660156, "report/post_ent_mean": 15.30324649810791, "report/post_ent_min": 13.425068855285645, "report/post_ent_std": 0.8951275944709778, "report/prior_ent_mag": 15.764715194702148, "report/prior_ent_max": 15.764715194702148, "report/prior_ent_mean": 13.800317764282227, "report/prior_ent_min": 12.269006729125977, "report/prior_ent_std": 0.5826300978660583, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00017719200695864856, "report/reward_loss_mean": 0.007817158475518227, "report/reward_loss_std": 0.013451171107590199, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0011733770370483398, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007817158475518227, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00017360784113407135, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02463553659617901, "eval/cont_loss_std": 0.44872036576271057, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.282843589782715, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0003704824484884739, "eval/cont_pred": 0.9996311664581299, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3007570505142212, "eval/image_loss_std": 0.16173706948757172, "eval/model_loss_mean": 0.9266409873962402, "eval/model_loss_std": 0.4781183898448944, "eval/post_ent_mag": 17.918655395507812, "eval/post_ent_max": 17.918655395507812, "eval/post_ent_mean": 15.202728271484375, "eval/post_ent_min": 13.253011703491211, "eval/post_ent_std": 0.877258837223053, "eval/prior_ent_mag": 15.690031051635742, "eval/prior_ent_max": 15.690031051635742, "eval/prior_ent_mean": 13.850664138793945, "eval/prior_ent_min": 12.600740432739258, "eval/prior_ent_std": 0.560355007648468, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012483545579016209, "eval/reward_loss_std": 0.001281590899452567, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0009757280349731445, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012483545579016209, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00019638787489384413, "eval/reward_rate": 0.0, "replay/size": 638033.0, "replay/inserts": 30416.0, "replay/samples": 30416.0, "replay/insert_wait_avg": 1.2953820070550669e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.415511129781612e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.066560492314712e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3424651622772, "timer/env.step_count": 3802.0, "timer/env.step_total": 34.42813968658447, "timer/env.step_frac": 0.034416353284571884, "timer/env.step_avg": 0.00905527082761296, "timer/env.step_min": 0.007499217987060547, "timer/env.step_max": 0.0400080680847168, "timer/replay._sample_count": 30416.0, "timer/replay._sample_total": 15.387602090835571, "timer/replay._sample_frac": 0.015382334177265351, "timer/replay._sample_avg": 0.0005059048556955408, "timer/replay._sample_min": 0.000370025634765625, "timer/replay._sample_max": 0.011430025100708008, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5725.0, "timer/agent.policy_total": 57.29349970817566, "timer/agent.policy_frac": 0.05727388539771868, "timer/agent.policy_avg": 0.010007598202301425, "timer/agent.policy_min": 0.008835554122924805, "timer/agent.policy_max": 0.08593893051147461, "timer/dataset_train_count": 1901.0, "timer/dataset_train_total": 0.20159077644348145, "timer/dataset_train_frac": 0.00020152176226046652, "timer/dataset_train_avg": 0.00010604459570935373, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.00033783912658691406, "timer/agent.train_count": 1901.0, "timer/agent.train_total": 852.6256332397461, "timer/agent.train_frac": 0.8523337386276326, "timer/agent.train_avg": 0.44851427314031883, "timer/agent.train_min": 0.43529510498046875, "timer/agent.train_max": 0.5971686840057373, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47417211532592773, "timer/agent.report_frac": 0.00047400978348850433, "timer/agent.report_avg": 0.23708605766296387, "timer/agent.report_min": 0.23216915130615234, "timer/agent.report_max": 0.2420029640197754, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146047832359184e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 30.40507067677439}
{"step": 638920, "time": 21222.6463804245, "episode/length": 640.0, "episode/score": 0.12192736300664819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12192736300664819}
{"step": 639592, "time": 21244.386104106903, "episode/length": 640.0, "episode/score": 0.1329320279859303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1329320279859303}
{"step": 640016, "time": 21265.018205165863, "eval_episode/length": 398.0, "eval_episode/score": 0.4403125047683716, "eval_episode/reward_rate": 0.002506265664160401}
{"step": 640016, "time": 21269.23107123375, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 21269.239925146103, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 21269.247988939285, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 21269.25579047203, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 21269.263685703278, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 21269.271446943283, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640016, "time": 21269.27982378006, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 640072, "time": 21270.825277090073, "episode/length": 640.0, "episode/score": 0.119775492986264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.119775492986264}
{"step": 640408, "time": 21281.322774887085, "episode/length": 640.0, "episode/score": 0.18063408048692509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18063408048692509}
{"step": 641096, "time": 21303.06639480591, "episode/length": 640.0, "episode/score": 0.10348815958775504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10348815958775504}
{"step": 642216, "time": 21338.305166959763, "episode/length": 640.0, "episode/score": 0.10188557786784713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10188557786784713}
{"step": 643176, "time": 21368.605067253113, "episode/length": 640.0, "episode/score": 0.12931709513901524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12931709513901524}
{"step": 643504, "time": 21379.216351747513, "episode/length": 640.0, "episode/score": 0.06125453049969565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06125453049969565}
{"step": 644048, "time": 21396.36280107498, "episode/length": 640.0, "episode/score": 0.13052153233877561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13052153233877561}
{"step": 644720, "time": 21417.760897874832, "episode/length": 640.0, "episode/score": 0.137316402290935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.137316402290935}
{"step": 645200, "time": 21432.961327314377, "episode/length": 640.0, "episode/score": 0.2340291057532795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2340291057532795}
{"step": 645536, "time": 21443.586231470108, "episode/length": 640.0, "episode/score": 0.18879129721005938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18879129721005938}
{"step": 646224, "time": 21465.11356472969, "episode/length": 640.0, "episode/score": 0.22138492474186933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22138492474186933}
{"step": 647344, "time": 21500.943256139755, "episode/length": 640.0, "episode/score": 0.10173729473387993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10173729473387993}
{"step": 647464, "time": 21504.470442056656, "episode/length": 282.0, "episode/score": 0.13222067005534655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13222067005534655}
{"step": 648304, "time": 21531.16637992859, "episode/length": 640.0, "episode/score": 0.12550074855499815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12550074855499815}
{"step": 648632, "time": 21541.282388448715, "episode/length": 640.0, "episode/score": 0.13441749905280176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13441749905280176}
{"step": 649176, "time": 21558.638817071915, "episode/length": 640.0, "episode/score": 0.09395780503990636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09395780503990636}
{"step": 649848, "time": 21579.84184074402, "episode/length": 640.0, "episode/score": 0.12733626194062708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12733626194062708}
{"step": 650000, "time": 21596.720646858215, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21596.72945690155, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21596.73743724823, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21596.744994163513, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21596.752564907074, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21596.76043701172, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21596.76825070381, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650000, "time": 21596.775785446167, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 650664, "time": 21617.462649583817, "episode/length": 640.0, "episode/score": 0.14370698281152272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14370698281152272}
{"step": 651352, "time": 21639.034553527832, "episode/length": 640.0, "episode/score": 0.15729065403445475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15729065403445475}
{"step": 652472, "time": 21674.317006349564, "episode/length": 640.0, "episode/score": 0.16669970320310767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16669970320310767}
{"step": 652592, "time": 21678.490397691727, "episode/length": 640.0, "episode/score": 0.06484232898873188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06484232898873188}
{"step": 653432, "time": 21705.113110780716, "episode/length": 640.0, "episode/score": 0.14517016974281205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14517016974281205}
{"step": 653760, "time": 21715.766934633255, "episode/length": 640.0, "episode/score": 0.14156034486961744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14156034486961744}
{"step": 654304, "time": 21732.81972885132, "episode/length": 640.0, "episode/score": 0.13499357306426418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13499357306426418}
{"step": 654976, "time": 21754.025114536285, "episode/length": 640.0, "episode/score": 0.11929398666498514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11929398666498514}
{"step": 655136, "time": 21759.068315267563, "episode/length": 317.0, "episode/score": 0.10548857586039162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10548857586039162}
{"step": 655792, "time": 21780.30127930641, "episode/length": 640.0, "episode/score": 0.10624781299372899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10624781299372899}
{"step": 656480, "time": 21802.1009452343, "episode/length": 640.0, "episode/score": 0.10088238461324295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10088238461324295}
{"step": 657600, "time": 21837.410125255585, "episode/length": 640.0, "episode/score": 0.13871157275480073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13871157275480073}
{"step": 658560, "time": 21867.753265619278, "episode/length": 640.0, "episode/score": 0.0504281188743505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0504281188743505}
{"step": 658888, "time": 21877.89327812195, "episode/length": 640.0, "episode/score": 0.12984674746351743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12984674746351743}
{"step": 659432, "time": 21895.23512172699, "episode/length": 640.0, "episode/score": 0.04743411214042226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04743411214042226}
{"step": 660088, "time": 21920.114510297775, "eval_episode/length": 214.0, "eval_episode/score": 0.6990625262260437, "eval_episode/reward_rate": 0.004651162790697674}
{"step": 660088, "time": 21928.199024438858, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21928.208098888397, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21928.216151475906, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21928.223999023438, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21928.23163294792, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21928.23926758766, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660088, "time": 21928.24695944786, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 660104, "time": 21928.77264356613, "episode/length": 640.0, "episode/score": 0.13114988037659714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13114988037659714}
{"step": 660264, "time": 21933.789844036102, "episode/length": 640.0, "episode/score": 0.12745122592721714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12745122592721714}
{"step": 660920, "time": 21954.475370407104, "episode/length": 640.0, "episode/score": 0.17374344211754078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17374344211754078}
{"step": 661608, "time": 21976.362246513367, "episode/length": 640.0, "episode/score": 0.22733473004078064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22733473004078064}
{"step": 662728, "time": 22012.319152355194, "episode/length": 640.0, "episode/score": 0.08642363958642818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08642363958642818}
{"step": 663688, "time": 22043.18552994728, "episode/length": 640.0, "episode/score": 0.1620281779103152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1620281779103152}
{"step": 664016, "time": 22053.722556591034, "episode/length": 640.0, "episode/score": 0.1379519824253066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1379519824253066}
{"step": 664560, "time": 22070.902361869812, "episode/length": 640.0, "episode/score": 0.14293831117893774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14293831117893774}
{"step": 665232, "time": 22092.022661685944, "episode/length": 640.0, "episode/score": 0.19621191893534728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19621191893534728}
{"step": 665392, "time": 22097.168362379074, "episode/length": 640.0, "episode/score": 0.18452280872455162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18452280872455162}
{"step": 666048, "time": 22118.125644683838, "episode/length": 640.0, "episode/score": 0.2014125712669852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2014125712669852}
{"step": 666736, "time": 22139.99956536293, "episode/length": 640.0, "episode/score": 0.08038880346390442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08038880346390442}
{"step": 667856, "time": 22175.870783805847, "episode/length": 640.0, "episode/score": 0.21493188462285673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21493188462285673}
{"step": 668816, "time": 22206.578598976135, "episode/length": 640.0, "episode/score": 0.11083308852819584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11083308852819584}
{"step": 668937, "time": 22211.213364124298, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.324152253803454, "train/action_min": 0.0, "train/action_std": 1.8959716363957053, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0006793812331651631, "train/actor_opt_grad_steps": 40765.0, "train/actor_opt_loss": -7.291439342028216, "train/adv_mag": 0.06705366188758298, "train/adv_max": 0.004579181459389235, "train/adv_mean": -5.8519338831860965e-05, "train/adv_min": -0.06681090479618625, "train/adv_std": 0.002078308518914702, "train/cont_avg": 0.9984683388157894, "train/cont_loss_mean": 0.003083552019655288, "train/cont_loss_std": 0.07571596359944363, "train/cont_neg_acc": 0.7342887498011255, "train/cont_neg_loss": 1.5796347510439757, "train/cont_pos_acc": 0.9999227599093788, "train/cont_pos_loss": 0.0005750584618286475, "train/cont_pred": 0.9984454180064954, "train/cont_rate": 0.9984683388157894, "train/dyn_loss_mean": 1.0000009474001432, "train/dyn_loss_std": 2.4501633474995433e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03367844437383802, "train/extr_critic_critic_opt_grad_steps": 40765.0, "train/extr_critic_critic_opt_loss": 13520.53439555921, "train/extr_critic_mag": 0.08207043974023116, "train/extr_critic_max": 0.08207043974023116, "train/extr_critic_mean": 0.07909210579175698, "train/extr_critic_min": 0.07479585722873086, "train/extr_critic_std": 0.0010320983958847232, "train/extr_return_normed_mag": 0.06562112365898333, "train/extr_return_normed_max": 0.00767981986466207, "train/extr_return_normed_mean": 0.002030651944101249, "train/extr_return_normed_min": -0.06481205330867516, "train/extr_return_normed_std": 0.0023574015897649685, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0846827169782237, "train/extr_return_raw_max": 0.0846827169782237, "train/extr_return_raw_mean": 0.07903355277682605, "train/extr_return_raw_min": 0.012190843804886466, "train/extr_return_raw_std": 0.0023574015958920907, "train/extr_reward_mag": 0.0012608390105398077, "train/extr_reward_max": 0.0012608390105398077, "train/extr_reward_mean": 0.00023679118113298166, "train/extr_reward_min": 2.209136360570004e-06, "train/extr_reward_std": 0.0002579677775716654, "train/image_loss_mean": 0.11626725796806185, "train/image_loss_std": 0.1228298778988813, "train/model_loss_mean": 0.7283328950405121, "train/model_loss_std": 0.1684655713015481, "train/model_opt_grad_norm": 21.312496125070673, "train/model_opt_grad_steps": 40728.97894736842, "train/model_opt_loss": 2595.6556512129932, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3565.7894736842104, "train/policy_entropy_mag": 1.9412663440955313, "train/policy_entropy_max": 1.9412663440955313, "train/policy_entropy_mean": 1.7619716041966489, "train/policy_entropy_min": 0.9471938810850444, "train/policy_entropy_std": 0.11169118179302466, "train/policy_logprob_mag": 3.9393167520824233, "train/policy_logprob_max": -0.27398540597212945, "train/policy_logprob_mean": -1.7617100364283511, "train/policy_logprob_min": -3.9393167520824233, "train/policy_logprob_std": 0.612191240097347, "train/policy_randomness_mag": 0.9976136138564662, "train/policy_randomness_max": 0.9976136138564662, "train/policy_randomness_mean": 0.9054743393471366, "train/policy_randomness_min": 0.4867613942999589, "train/policy_randomness_std": 0.05739791665814425, "train/post_ent_mag": 19.270734686600534, "train/post_ent_max": 19.270734686600534, "train/post_ent_mean": 15.096670768135473, "train/post_ent_min": 12.406734848022461, "train/post_ent_std": 1.3312309550611596, "train/prior_ent_mag": 18.125087411780108, "train/prior_ent_max": 18.125087411780108, "train/prior_ent_mean": 14.983859704670154, "train/prior_ent_min": 12.793024022955644, "train/prior_ent_std": 0.878700379948867, "train/rep_loss_mean": 1.0000009474001432, "train/rep_loss_std": 2.4501633474995433e-05, "train/reward_avg": 0.00020471167104245213, "train/reward_loss_mean": 0.008981491044457805, "train/reward_loss_std": 0.013731321364052985, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012209108001307437, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008981491007695073, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0002082388578472953, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.771210218469302, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.007257521618157625, "report/cont_loss_std": 0.21952354907989502, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 1.7732652425765991, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0003320015675853938, "report/cont_pred": 0.9968020915985107, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10280229896306992, "report/image_loss_std": 0.11569417268037796, "report/model_loss_mean": 0.719721794128418, "report/model_loss_std": 0.25078871846199036, "report/post_ent_mag": 21.991470336914062, "report/post_ent_max": 21.991470336914062, "report/post_ent_mean": 16.25727081298828, "report/post_ent_min": 12.062650680541992, "report/post_ent_std": 1.8805516958236694, "report/prior_ent_mag": 19.87792205810547, "report/prior_ent_max": 19.87792205810547, "report/prior_ent_mean": 15.192230224609375, "report/prior_ent_min": 12.449671745300293, "report/prior_ent_std": 1.21438467502594, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00021842906426172704, "report/reward_loss_mean": 0.009661983698606491, "report/reward_loss_std": 0.013601201586425304, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013104677200317383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009661983698606491, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002506260061636567, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.02044261060655117, "eval/cont_loss_std": 0.45086193084716797, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.21097469329834, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.000500276277307421, "eval/cont_pred": 0.999505877494812, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.28119200468063354, "eval/image_loss_std": 0.15934066474437714, "eval/model_loss_mean": 0.9031409025192261, "eval/model_loss_std": 0.47964784502983093, "eval/post_ent_mag": 21.977371215820312, "eval/post_ent_max": 21.977371215820312, "eval/post_ent_mean": 15.732147216796875, "eval/post_ent_min": 12.045599937438965, "eval/post_ent_std": 1.8108432292938232, "eval/prior_ent_mag": 19.85225486755371, "eval/prior_ent_max": 19.85225486755371, "eval/prior_ent_mean": 14.989546775817871, "eval/prior_ent_min": 12.271078109741211, "eval/prior_ent_std": 1.1611506938934326, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015063043683767319, "eval/reward_loss_std": 0.0016080959467217326, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0012079477310180664, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015063043683767319, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023689563386142254, "eval/reward_rate": 0.0, "replay/size": 668433.0, "replay/inserts": 30400.0, "replay/samples": 30400.0, "replay/insert_wait_avg": 1.3052711361332943e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.435547351837158e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0728061168192578e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3134632110596, "timer/env.step_count": 3800.0, "timer/env.step_total": 34.41624164581299, "timer/env.step_frac": 0.034405456800846224, "timer/env.step_avg": 0.009056905696266576, "timer/env.step_min": 0.007475852966308594, "timer/env.step_max": 0.03496980667114258, "timer/replay._sample_count": 30400.0, "timer/replay._sample_total": 15.425887823104858, "timer/replay._sample_frac": 0.015421053890034566, "timer/replay._sample_avg": 0.0005074305204968703, "timer/replay._sample_min": 0.0003554821014404297, "timer/replay._sample_max": 0.0339360237121582, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5723.0, "timer/agent.policy_total": 57.69991660118103, "timer/agent.policy_frac": 0.05768183546781548, "timer/agent.policy_avg": 0.010082110187171244, "timer/agent.policy_min": 0.008719444274902344, "timer/agent.policy_max": 0.09917497634887695, "timer/dataset_train_count": 1900.0, "timer/dataset_train_total": 0.20721101760864258, "timer/dataset_train_frac": 0.00020714608493170147, "timer/dataset_train_avg": 0.0001090584303203382, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.00043702125549316406, "timer/agent.train_count": 1900.0, "timer/agent.train_total": 852.4236710071564, "timer/agent.train_frac": 0.8521565512782673, "timer/agent.train_avg": 0.44864403737218755, "timer/agent.train_min": 0.43747472763061523, "timer/agent.train_max": 0.6047217845916748, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47812962532043457, "timer/agent.report_frac": 0.000477979796238684, "timer/agent.report_avg": 0.23906481266021729, "timer/agent.report_min": 0.23371219635009766, "timer/agent.report_max": 0.24441742897033691, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.4083172990674684e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 30.38993156870904}
{"step": 669144, "time": 22217.700265169144, "episode/length": 640.0, "episode/score": 0.23658006841625934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23658006841625934}
{"step": 669688, "time": 22235.118537902832, "episode/length": 640.0, "episode/score": 0.14145700330774957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14145700330774957}
{"step": 670072, "time": 22258.644595861435, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 22258.6590988636, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 22258.66648387909, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 22258.675632476807, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 22258.683284044266, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 22258.691630125046, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 22258.699300527573, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 22258.707750320435, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670360, "time": 22267.78812646866, "episode/length": 640.0, "episode/score": 0.1505077466129734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1505077466129734}
{"step": 670520, "time": 22272.804427862167, "episode/length": 640.0, "episode/score": 0.11522380401808618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11522380401808618}
{"step": 671176, "time": 22293.71711397171, "episode/length": 640.0, "episode/score": 0.10225669646858648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10225669646858648}
{"step": 671864, "time": 22315.993584632874, "episode/length": 640.0, "episode/score": 0.17752386211328997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17752386211328997}
{"step": 672984, "time": 22351.46078133583, "episode/length": 640.0, "episode/score": 0.1631931887071545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1631931887071545}
{"step": 673944, "time": 22381.73055076599, "episode/length": 640.0, "episode/score": 0.2724071155251693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2724071155251693}
{"step": 674272, "time": 22392.280970573425, "episode/length": 640.0, "episode/score": 0.09716406398979416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09716406398979416}
{"step": 674816, "time": 22409.440368175507, "episode/length": 640.0, "episode/score": 0.24600593643724267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24600593643724267}
{"step": 674968, "time": 22414.00701022148, "episode/length": 473.0, "episode/score": 0.20756740850174538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20756740850174538}
{"step": 675488, "time": 22430.666723251343, "episode/length": 640.0, "episode/score": 0.12748461895961327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12748461895961327}
{"step": 675648, "time": 22435.724619865417, "episode/length": 640.0, "episode/score": 0.19982675143569395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19982675143569395}
{"step": 676992, "time": 22478.092046499252, "episode/length": 640.0, "episode/score": 0.21589921640702414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21589921640702414}
{"step": 678112, "time": 22513.35697221756, "episode/length": 640.0, "episode/score": 0.22229966703412174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22229966703412174}
{"step": 679072, "time": 22543.66783976555, "episode/length": 640.0, "episode/score": 0.18002451083100368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18002451083100368}
{"step": 679400, "time": 22553.982637405396, "episode/length": 640.0, "episode/score": 0.16453066803478578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16453066803478578}
{"step": 679944, "time": 22571.71102309227, "episode/length": 640.0, "episode/score": 0.20862400707926554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20862400707926554}
{"step": 680056, "time": 22588.111377716064, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22588.120859146118, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22588.12930703163, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22588.1374168396, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22588.145387887955, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22588.154366254807, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22588.162435770035, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680056, "time": 22588.17051744461, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 680096, "time": 22589.689229011536, "episode/length": 640.0, "episode/score": 0.17542111189300158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17542111189300158}
{"step": 680616, "time": 22606.193257570267, "episode/length": 640.0, "episode/score": 0.13306799502606736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13306799502606736}
{"step": 680776, "time": 22611.348171710968, "episode/length": 640.0, "episode/score": 0.12572865879963047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12572865879963047}
{"step": 682120, "time": 22654.019695043564, "episode/length": 640.0, "episode/score": 0.17737959492012578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17737959492012578}
{"step": 683240, "time": 22689.322322130203, "episode/length": 640.0, "episode/score": 0.2346530314893016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2346530314893016}
{"step": 684200, "time": 22719.72049164772, "episode/length": 640.0, "episode/score": 0.19630662234089868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19630662234089868}
{"step": 684528, "time": 22730.360739946365, "episode/length": 640.0, "episode/score": 0.2275667178698768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2275667178698768}
{"step": 685072, "time": 22747.581158638, "episode/length": 640.0, "episode/score": 0.23390363738815267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23390363738815267}
{"step": 685224, "time": 22752.140113830566, "episode/length": 640.0, "episode/score": 0.0971606934851934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0971606934851934}
{"step": 685744, "time": 22768.832094430923, "episode/length": 640.0, "episode/score": 0.2549189380201824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2549189380201824}
{"step": 685904, "time": 22773.869148254395, "episode/length": 640.0, "episode/score": 0.16721557778896567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16721557778896567}
{"step": 687248, "time": 22816.799577236176, "episode/length": 640.0, "episode/score": 0.17352775073823068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17352775073823068}
{"step": 688368, "time": 22853.21789073944, "episode/length": 640.0, "episode/score": 0.07310312901762472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07310312901762472}
{"step": 689328, "time": 22883.699347257614, "episode/length": 640.0, "episode/score": 0.10032296171823418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10032296171823418}
{"step": 689656, "time": 22893.793761968613, "episode/length": 640.0, "episode/score": 0.13179797893468503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13179797893468503}
{"step": 690040, "time": 22918.071394205093, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22918.08109855652, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22918.089725494385, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22918.097862005234, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22918.106158733368, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22918.11413693428, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22918.122054338455, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22918.130572795868, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690200, "time": 22923.26361632347, "episode/length": 640.0, "episode/score": 0.20042814188576585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20042814188576585}
{"step": 690352, "time": 22928.380684375763, "episode/length": 640.0, "episode/score": 0.12975018995234677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12975018995234677}
{"step": 690872, "time": 22944.62870001793, "episode/length": 640.0, "episode/score": 0.1727651374760626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1727651374760626}
{"step": 691032, "time": 22949.671847581863, "episode/length": 640.0, "episode/score": 0.12382229492851593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12382229492851593}
{"step": 692376, "time": 22992.233052015305, "episode/length": 640.0, "episode/score": 0.14456912293323398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14456912293323398}
{"step": 693496, "time": 23027.603005886078, "episode/length": 640.0, "episode/score": 0.1176221318376065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1176221318376065}
{"step": 694456, "time": 23057.877502679825, "episode/length": 640.0, "episode/score": 0.221503158839937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.221503158839937}
{"step": 694784, "time": 23068.434442281723, "episode/length": 640.0, "episode/score": 0.21017913035566949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21017913035566949}
{"step": 695328, "time": 23085.70233607292, "episode/length": 640.0, "episode/score": 0.06692308077776943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06692308077776943}
{"step": 695480, "time": 23090.51478910446, "episode/length": 640.0, "episode/score": 0.09938502628872925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09938502628872925}
{"step": 695760, "time": 23099.648074150085, "episode/length": 422.0, "episode/score": 0.10044506251830398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10044506251830398}
{"step": 696000, "time": 23107.213801383972, "episode/length": 640.0, "episode/score": 0.1718869770979552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1718869770979552}
{"step": 696160, "time": 23112.335433006287, "episode/length": 640.0, "episode/score": 0.10479086483934452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10479086483934452}
{"step": 698624, "time": 23191.195536136627, "episode/length": 640.0, "episode/score": 0.1397628751709874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1397628751709874}
{"step": 699241, "time": 23211.580528974533, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3189054620329035, "train/action_min": 0.0, "train/action_std": 1.8794044899562048, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0006912836576159057, "train/actor_opt_grad_steps": 42660.0, "train/actor_opt_loss": -6.650780027347897, "train/adv_mag": 0.0691140439144518, "train/adv_max": 0.004623371457296704, "train/adv_mean": -2.051997444708989e-05, "train/adv_min": -0.06890093712579637, "train/adv_std": 0.0021319063297206803, "train/cont_avg": 0.9985067377645502, "train/cont_loss_mean": 0.0027933026969703236, "train/cont_loss_std": 0.07143166295724561, "train/cont_neg_acc": 0.7106575973990823, "train/cont_neg_loss": 1.6640846821819588, "train/cont_pos_acc": 0.9999378954291974, "train/cont_pos_loss": 0.0005354070140922901, "train/cont_pred": 0.9984508856894478, "train/cont_rate": 0.9985067377645502, "train/dyn_loss_mean": 1.000000974488637, "train/dyn_loss_std": 3.115648789351027e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.028502708545327927, "train/extr_critic_critic_opt_grad_steps": 42660.0, "train/extr_critic_critic_opt_loss": 13503.426003430886, "train/extr_critic_mag": 0.08023789383116223, "train/extr_critic_max": 0.08023789383116223, "train/extr_critic_mean": 0.07739578140160394, "train/extr_critic_min": 0.0733355062979239, "train/extr_critic_std": 0.000991198658344469, "train/extr_return_normed_mag": 0.06734175380890962, "train/extr_return_normed_max": 0.007686481944152287, "train/extr_return_normed_mean": 0.0020686295878255454, "train/extr_return_normed_min": -0.06672109139186365, "train/extr_return_normed_std": 0.002377066142837364, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08299309618416287, "train/extr_return_raw_max": 0.08299309618416287, "train/extr_return_raw_mean": 0.07737524720726821, "train/extr_return_raw_min": 0.008585522848146933, "train/extr_return_raw_std": 0.0023770661385256854, "train/extr_reward_mag": 0.00125441727814851, "train/extr_reward_max": 0.00125441727814851, "train/extr_reward_mean": 0.0002387913137830784, "train/extr_reward_min": 2.40373863744988e-06, "train/extr_reward_std": 0.0002605589809636561, "train/image_loss_mean": 0.11613222562446796, "train/image_loss_std": 0.12411376613157767, "train/model_loss_mean": 0.7281522249418592, "train/model_loss_std": 0.16772877752150178, "train/model_opt_grad_norm": 20.917231807002313, "train/model_opt_grad_steps": 42622.88888888889, "train/model_opt_loss": 2561.093344390708, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3518.5185185185187, "train/policy_entropy_mag": 1.9406204463312866, "train/policy_entropy_max": 1.9406204463312866, "train/policy_entropy_mean": 1.7565406075230352, "train/policy_entropy_min": 0.954972506200195, "train/policy_entropy_std": 0.11222686425403312, "train/policy_logprob_mag": 4.019356774274634, "train/policy_logprob_max": -0.27914762157927114, "train/policy_logprob_mean": -1.7566178765877214, "train/policy_logprob_min": -4.019356774274634, "train/policy_logprob_std": 0.6199652811206838, "train/policy_randomness_mag": 0.997281690753957, "train/policy_randomness_max": 0.997281690753957, "train/policy_randomness_mean": 0.902683364966559, "train/policy_randomness_min": 0.49075881782032194, "train/policy_randomness_std": 0.057673203014822864, "train/post_ent_mag": 19.679521045987567, "train/post_ent_max": 19.679521045987567, "train/post_ent_mean": 15.711882717394955, "train/post_ent_min": 12.939905534976374, "train/post_ent_std": 1.3131649052655254, "train/prior_ent_mag": 18.452229171833665, "train/prior_ent_max": 18.452229171833665, "train/prior_ent_mean": 15.199842377314491, "train/prior_ent_min": 12.671313785371327, "train/prior_ent_std": 0.9672376210727389, "train/rep_loss_mean": 1.000000974488637, "train/rep_loss_std": 3.115648789351027e-05, "train/reward_avg": 0.00021123188748283105, "train/reward_loss_mean": 0.009226091082882944, "train/reward_loss_std": 0.01393732088544066, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012105596128594938, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009226091105057291, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0002089210659038847, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7665068037966465, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.006523253861814737, "report/cont_loss_std": 0.1999114602804184, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 2.1535792350769043, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00021456912509165704, "report/cont_pred": 0.9978899359703064, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10685759782791138, "report/image_loss_std": 0.12212836742401123, "report/model_loss_mean": 0.7220403552055359, "report/model_loss_std": 0.24282802641391754, "report/post_ent_mag": 22.60995101928711, "report/post_ent_max": 22.60995101928711, "report/post_ent_mean": 15.796516418457031, "report/post_ent_min": 11.705992698669434, "report/post_ent_std": 1.9625462293624878, "report/prior_ent_mag": 20.052745819091797, "report/prior_ent_max": 20.052745819091797, "report/prior_ent_mean": 15.44572925567627, "report/prior_ent_min": 12.32741641998291, "report/prior_ent_std": 1.4150958061218262, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00019820014131255448, "report/reward_loss_mean": 0.008659452199935913, "report/reward_loss_std": 0.013698644004762173, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0010731220245361328, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008659452199935913, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0001712848898023367, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.047268204391002655, "eval/cont_loss_std": 0.6726120114326477, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.629767417907715, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.000249072298174724, "eval/cont_pred": 0.9997521638870239, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.29784733057022095, "eval/image_loss_std": 0.14982810616493225, "eval/model_loss_mean": 0.9465081095695496, "eval/model_loss_std": 0.6922170519828796, "eval/post_ent_mag": 21.433515548706055, "eval/post_ent_max": 21.433515548706055, "eval/post_ent_mean": 15.516035079956055, "eval/post_ent_min": 11.19564437866211, "eval/post_ent_std": 1.869089126586914, "eval/prior_ent_mag": 19.895423889160156, "eval/prior_ent_max": 19.895423889160156, "eval/prior_ent_mean": 15.351740837097168, "eval/prior_ent_min": 12.27108383178711, "eval/prior_ent_std": 1.4248849153518677, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013925684615969658, "eval/reward_loss_std": 0.0013500973582267761, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0010262727737426758, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013925684615969658, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000219060224480927, "eval/reward_rate": 0.0, "replay/size": 698737.0, "replay/inserts": 30304.0, "replay/samples": 30304.0, "replay/insert_wait_avg": 1.292852753696623e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.418998723296958e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.166691956145653e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3495163917542, "timer/env.step_count": 3788.0, "timer/env.step_total": 34.24681115150452, "timer/env.step_frac": 0.03423484551182896, "timer/env.step_avg": 0.009040868836194434, "timer/env.step_min": 0.007427692413330078, "timer/env.step_max": 0.03615856170654297, "timer/replay._sample_count": 30304.0, "timer/replay._sample_total": 15.256202936172485, "timer/replay._sample_frac": 0.015250872506243001, "timer/replay._sample_avg": 0.0005034385868589125, "timer/replay._sample_min": 0.0004074573516845703, "timer/replay._sample_max": 0.010266304016113281, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5711.0, "timer/agent.policy_total": 58.41705322265625, "timer/agent.policy_frac": 0.05839664263883057, "timer/agent.policy_avg": 0.010228865911864166, "timer/agent.policy_min": 0.008665323257446289, "timer/agent.policy_max": 0.08963871002197266, "timer/dataset_train_count": 1894.0, "timer/dataset_train_total": 0.20650506019592285, "timer/dataset_train_frac": 0.00020643290851060092, "timer/dataset_train_avg": 0.00010903118278559812, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.00024366378784179688, "timer/agent.train_count": 1894.0, "timer/agent.train_total": 851.3119351863861, "timer/agent.train_frac": 0.8510144916719264, "timer/agent.train_avg": 0.44947831847222075, "timer/agent.train_min": 0.4390864372253418, "timer/agent.train_max": 0.6156141757965088, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47974205017089844, "timer/agent.report_frac": 0.00047957443104618163, "timer/agent.report_avg": 0.23987102508544922, "timer/agent.report_min": 0.23335576057434082, "timer/agent.report_max": 0.24638628959655762, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.09835860120166e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 30.292829732818277}
{"step": 699584, "time": 23222.3914437294, "episode/length": 640.0, "episode/score": 0.0530847456280128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0530847456280128}
{"step": 699912, "time": 23232.56408762932, "episode/length": 640.0, "episode/score": 0.22858294103139087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22858294103139087}
{"step": 700024, "time": 23247.516978025436, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 23247.52614760399, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 23247.534477710724, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 23247.54235982895, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 23247.550357818604, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 23247.5580534935, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 23247.56581401825, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700024, "time": 23247.573632240295, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 700456, "time": 23262.992917060852, "episode/length": 640.0, "episode/score": 0.19295792661392852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19295792661392852}
{"step": 700608, "time": 23268.1281645298, "episode/length": 640.0, "episode/score": 0.11323062303375764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11323062303375764}
{"step": 700888, "time": 23276.74253630638, "episode/length": 640.0, "episode/score": 0.16920794395744565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16920794395744565}
{"step": 701128, "time": 23284.33479833603, "episode/length": 640.0, "episode/score": 0.24414644573781175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24414644573781175}
{"step": 701288, "time": 23289.385372400284, "episode/length": 640.0, "episode/score": 0.2016950462126772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2016950462126772}
{"step": 703752, "time": 23367.232868433, "episode/length": 640.0, "episode/score": 0.19020123572266812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19020123572266812}
{"step": 704712, "time": 23397.992623806, "episode/length": 640.0, "episode/score": 0.15790822861777087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15790822861777087}
{"step": 705040, "time": 23408.637318134308, "episode/length": 640.0, "episode/score": 0.17812330949266197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17812330949266197}
{"step": 705584, "time": 23426.075103998184, "episode/length": 640.0, "episode/score": 0.1168134935389844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1168134935389844}
{"step": 705736, "time": 23430.741260051727, "episode/length": 640.0, "episode/score": 0.23539445397301506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23539445397301506}
{"step": 706016, "time": 23439.85192847252, "episode/length": 640.0, "episode/score": 0.11749686714688323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11749686714688323}
{"step": 706256, "time": 23447.523664712906, "episode/length": 640.0, "episode/score": 0.19312885848125916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19312885848125916}
{"step": 706416, "time": 23452.60127711296, "episode/length": 640.0, "episode/score": 0.23801959256383043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23801959256383043}
{"step": 708624, "time": 23522.652826309204, "episode/length": 295.0, "episode/score": 0.1182382223107652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1182382223107652}
{"step": 708880, "time": 23530.688181638718, "episode/length": 640.0, "episode/score": 0.12682049674833706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12682049674833706}
{"step": 709840, "time": 23560.993863344193, "episode/length": 640.0, "episode/score": 0.15379955461003192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15379955461003192}
{"step": 710008, "time": 23578.0139837265, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23578.02344226837, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23578.031717061996, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23578.039736270905, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23578.04792022705, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23578.05596756935, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23578.064015865326, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710008, "time": 23578.071964263916, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 710168, "time": 23583.143183231354, "episode/length": 640.0, "episode/score": 0.09042816021587896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09042816021587896}
{"step": 710712, "time": 23600.424182653427, "episode/length": 640.0, "episode/score": 0.06675937246291141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06675937246291141}
{"step": 710864, "time": 23605.474539279938, "episode/length": 640.0, "episode/score": 0.19932821538247936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19932821538247936}
{"step": 711144, "time": 23614.04925584793, "episode/length": 640.0, "episode/score": 0.1478425390821485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1478425390821485}
{"step": 711544, "time": 23626.751676797867, "episode/length": 640.0, "episode/score": 0.06050700715542234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06050700715542234}
{"step": 713752, "time": 23697.641208171844, "episode/length": 640.0, "episode/score": 0.16344885096503958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16344885096503958}
{"step": 714008, "time": 23705.746984004974, "episode/length": 640.0, "episode/score": 0.12637440220078133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12637440220078133}
{"step": 714968, "time": 23736.315709590912, "episode/length": 640.0, "episode/score": 0.08032667944138439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08032667944138439}
{"step": 715296, "time": 23746.960124254227, "episode/length": 640.0, "episode/score": 0.1355931070082761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1355931070082761}
{"step": 715840, "time": 23764.38797712326, "episode/length": 640.0, "episode/score": 0.15398779724552014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15398779724552014}
{"step": 715992, "time": 23769.01788687706, "episode/length": 640.0, "episode/score": 0.09968893216637298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09968893216637298}
{"step": 716272, "time": 23778.37271952629, "episode/length": 640.0, "episode/score": 0.17834763819439559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17834763819439559}
{"step": 716672, "time": 23790.986075878143, "episode/length": 640.0, "episode/score": 0.11746002386206555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11746002386206555}
{"step": 718880, "time": 23861.190130233765, "episode/length": 640.0, "episode/score": 0.23338680531168166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23338680531168166}
{"step": 719136, "time": 23869.505009412766, "episode/length": 640.0, "episode/score": 0.20720674111169046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20720674111169046}
{"step": 720096, "time": 23900.269904136658, "episode/length": 640.0, "episode/score": 0.21431794642262503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21431794642262503}
{"step": 720096, "time": 23912.044604301453, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23912.05433011055, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23912.063086509705, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23912.071486473083, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23912.079573392868, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23912.08793616295, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23912.09638094902, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720096, "time": 23912.10441493988, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 720424, "time": 23922.369687318802, "episode/length": 640.0, "episode/score": 0.22453725063530783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22453725063530783}
{"step": 720968, "time": 23940.26583981514, "episode/length": 640.0, "episode/score": 0.21811312447402997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21811312447402997}
{"step": 721120, "time": 23945.29177427292, "episode/length": 640.0, "episode/score": 0.1912964128225667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1912964128225667}
{"step": 721400, "time": 23953.892068862915, "episode/length": 640.0, "episode/score": 0.16766078319369626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16766078319369626}
{"step": 721560, "time": 23959.041608333588, "episode/length": 334.0, "episode/score": 0.11861298204547666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11861298204547666}
{"step": 721800, "time": 23966.65211558342, "episode/length": 640.0, "episode/score": 0.15056970280147652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15056970280147652}
{"step": 724264, "time": 24045.179032087326, "episode/length": 640.0, "episode/score": 0.16336330583811787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16336330583811787}
{"step": 725224, "time": 24075.596747636795, "episode/length": 640.0, "episode/score": 0.1374568377872265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1374568377872265}
{"step": 725552, "time": 24086.297724723816, "episode/length": 640.0, "episode/score": 0.1626908702273795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1626908702273795}
{"step": 726096, "time": 24103.6830201149, "episode/length": 640.0, "episode/score": 0.16657590728294736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16657590728294736}
{"step": 726248, "time": 24108.45682811737, "episode/length": 640.0, "episode/score": 0.22813015305814588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22813015305814588}
{"step": 726528, "time": 24117.572041749954, "episode/length": 640.0, "episode/score": 0.19637065851924262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19637065851924262}
{"step": 726688, "time": 24122.637909650803, "episode/length": 640.0, "episode/score": 0.18466463530171495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18466463530171495}
{"step": 726928, "time": 24130.2463619709, "episode/length": 640.0, "episode/score": 0.18311709552403954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18311709552403954}
{"step": 729392, "time": 24208.800719738007, "episode/length": 640.0, "episode/score": 0.2082949912231129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2082949912231129}
{"step": 729465, "time": 24211.90058875084, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.293956292369378, "train/action_min": 0.0, "train/action_std": 1.8712650821322487, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.000662785693146929, "train/actor_opt_grad_steps": 44550.0, "train/actor_opt_loss": -6.109182481570219, "train/adv_mag": 0.06669367341295121, "train/adv_max": 0.004754645759781832, "train/adv_mean": 1.2725758720248618e-05, "train/adv_min": -0.06646424776347226, "train/adv_std": 0.0019918076651510856, "train/cont_avg": 0.9984654017857143, "train/cont_loss_mean": 0.002668825790847198, "train/cont_loss_std": 0.06582184694861382, "train/cont_neg_acc": 0.735472974745003, "train/cont_neg_loss": 1.3583918390968392, "train/cont_pos_acc": 0.9999378806068784, "train/cont_pos_loss": 0.0005000986953967537, "train/cont_pred": 0.9984358407202221, "train/cont_rate": 0.9984654017857143, "train/dyn_loss_mean": 1.0000015282757069, "train/dyn_loss_std": 4.055747562445326e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.025821375964571618, "train/extr_critic_critic_opt_grad_steps": 44550.0, "train/extr_critic_critic_opt_loss": 13504.742786871693, "train/extr_critic_mag": 0.0804874859158955, "train/extr_critic_max": 0.0804874859158955, "train/extr_critic_mean": 0.07742313189165932, "train/extr_critic_min": 0.0728140842346918, "train/extr_critic_std": 0.0011060595830838398, "train/extr_return_normed_mag": 0.06510847223498833, "train/extr_return_normed_max": 0.008157444575791636, "train/extr_return_normed_mean": 0.002339514662886147, "train/extr_return_normed_min": -0.06426467056627627, "train/extr_return_normed_std": 0.0023091187430841344, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08325378900324856, "train/extr_return_raw_max": 0.08325378900324856, "train/extr_return_raw_mean": 0.07743586237153048, "train/extr_return_raw_min": 0.010831673861180663, "train/extr_return_raw_std": 0.002309118744931997, "train/extr_reward_mag": 0.0012615622666777757, "train/extr_reward_max": 0.0012615622666777757, "train/extr_reward_mean": 0.00024289542539032894, "train/extr_reward_min": 2.4422135933366403e-06, "train/extr_reward_std": 0.0002619711526364049, "train/image_loss_mean": 0.11287105828523636, "train/image_loss_std": 0.12238484755079582, "train/model_loss_mean": 0.7246477096169083, "train/model_loss_std": 0.161963774531922, "train/model_opt_grad_norm": 19.72146297636486, "train/model_opt_grad_steps": 44511.95238095238, "train/model_opt_loss": 2885.5572561435597, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3981.4814814814813, "train/policy_entropy_mag": 1.9410463193106273, "train/policy_entropy_max": 1.9410463193106273, "train/policy_entropy_mean": 1.7469822237731287, "train/policy_entropy_min": 0.927513320610006, "train/policy_entropy_std": 0.11676569527419156, "train/policy_logprob_mag": 4.043184200922648, "train/policy_logprob_max": -0.2644246250548691, "train/policy_logprob_mean": -1.746502715443808, "train/policy_logprob_min": -4.043184200922648, "train/policy_logprob_std": 0.6332422829178906, "train/policy_randomness_mag": 0.9975005441872531, "train/policy_randomness_max": 0.9975005441872531, "train/policy_randomness_mean": 0.8977713200150343, "train/policy_randomness_min": 0.47664758405357444, "train/policy_randomness_std": 0.0600057005803421, "train/post_ent_mag": 24.371650080201487, "train/post_ent_max": 24.371650080201487, "train/post_ent_mean": 16.81728747029784, "train/post_ent_min": 12.030800587285764, "train/post_ent_std": 2.405250204303277, "train/prior_ent_mag": 22.78036584803667, "train/prior_ent_max": 22.78036584803667, "train/prior_ent_mean": 16.893050799294123, "train/prior_ent_min": 12.72300886729407, "train/prior_ent_std": 1.7822503892202226, "train/rep_loss_mean": 1.0000015282757069, "train/rep_loss_std": 4.055747562445326e-05, "train/reward_avg": 0.00020809517726770273, "train/reward_loss_mean": 0.009106886703718118, "train/reward_loss_std": 0.01375719762491013, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012176320666358585, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009106886622412179, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00020970630018464313, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7568256465756162, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.012858386151492596, "report/cont_loss_std": 0.2949754297733307, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.120136022567749, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0006729842280037701, "report/cont_pred": 0.9978711605072021, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12700214982032776, "report/image_loss_std": 0.1272384077310562, "report/model_loss_mean": 0.7508982419967651, "report/model_loss_std": 0.32434576749801636, "report/post_ent_mag": 28.368215560913086, "report/post_ent_max": 28.368215560913086, "report/post_ent_mean": 17.688600540161133, "report/post_ent_min": 11.681768417358398, "report/post_ent_std": 3.4462008476257324, "report/prior_ent_mag": 24.00441551208496, "report/prior_ent_max": 24.00441551208496, "report/prior_ent_mean": 17.07601547241211, "report/prior_ent_min": 12.069128036499023, "report/prior_ent_std": 2.196528434753418, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00025601641391403973, "report/reward_loss_mean": 0.011037726886570454, "report/reward_loss_std": 0.015812698751688004, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0011463165283203125, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.011037726886570454, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002317767357453704, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01724565401673317, "eval/cont_loss_std": 0.33337271213531494, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.465617656707764, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.0026695840060710907, "eval/cont_pred": 0.9978245496749878, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.30663320422172546, "eval/image_loss_std": 0.15389399230480194, "eval/model_loss_mean": 0.9253690242767334, "eval/model_loss_std": 0.35959360003471375, "eval/post_ent_mag": 29.435029983520508, "eval/post_ent_max": 29.435029983520508, "eval/post_ent_mean": 17.159835815429688, "eval/post_ent_min": 11.787565231323242, "eval/post_ent_std": 3.3238656520843506, "eval/prior_ent_mag": 24.00441551208496, "eval/prior_ent_max": 24.00441551208496, "eval/prior_ent_mean": 16.87249183654785, "eval/prior_ent_min": 12.629802703857422, "eval/prior_ent_std": 2.1417746543884277, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014901608228683472, "eval/reward_loss_std": 0.0013885219814255834, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0009385347366333008, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014901608228683472, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023440690711140633, "eval/reward_rate": 0.0, "replay/size": 728961.0, "replay/inserts": 30224.0, "replay/samples": 30224.0, "replay/insert_wait_avg": 1.3093379769393411e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.346149061898695e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.125886176194118e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3047728538513, "timer/env.step_count": 3778.0, "timer/env.step_total": 34.237263202667236, "timer/env.step_frac": 0.03422683179346325, "timer/env.step_avg": 0.009062271890594822, "timer/env.step_min": 0.007434368133544922, "timer/env.step_max": 0.03519725799560547, "timer/replay._sample_count": 30224.0, "timer/replay._sample_total": 15.186057567596436, "timer/replay._sample_frac": 0.015181430679642656, "timer/replay._sample_avg": 0.0005024502900872298, "timer/replay._sample_min": 0.00037360191345214844, "timer/replay._sample_max": 0.009597539901733398, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5701.0, "timer/agent.policy_total": 57.55438685417175, "timer/agent.policy_frac": 0.057536851183834836, "timer/agent.policy_avg": 0.010095489713062927, "timer/agent.policy_min": 0.008948564529418945, "timer/agent.policy_max": 0.08610200881958008, "timer/dataset_train_count": 1889.0, "timer/dataset_train_total": 0.20813703536987305, "timer/dataset_train_frac": 0.00020807362017883998, "timer/dataset_train_avg": 0.00011018371380088568, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0005269050598144531, "timer/agent.train_count": 1889.0, "timer/agent.train_total": 852.7826220989227, "timer/agent.train_frac": 0.8525227962933231, "timer/agent.train_avg": 0.4514465971937124, "timer/agent.train_min": 0.43790411949157715, "timer/agent.train_max": 2.259902238845825, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47679924964904785, "timer/agent.report_frac": 0.0004766539784557343, "timer/agent.report_avg": 0.23839962482452393, "timer/agent.report_min": 0.23428702354431152, "timer/agent.report_max": 0.24251222610473633, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9316550340779754e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 30.214255405868602}
{"step": 730080, "time": 24239.853439331055, "eval_episode/length": 452.0, "eval_episode/score": 0.3643749952316284, "eval_episode/reward_rate": 0.002207505518763797}
{"step": 730080, "time": 24243.14613032341, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 24243.155187129974, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 24243.163532972336, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 24243.171440839767, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 24243.17934370041, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 24243.18737387657, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730080, "time": 24243.195622444153, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 730352, "time": 24251.732306480408, "episode/length": 640.0, "episode/score": 0.23627840955015245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23627840955015245}
{"step": 730680, "time": 24261.925041675568, "episode/length": 640.0, "episode/score": 0.09896298479179677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09896298479179677}
{"step": 731224, "time": 24279.050543785095, "episode/length": 640.0, "episode/score": 0.16674791265330668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16674791265330668}
{"step": 731376, "time": 24284.037405490875, "episode/length": 640.0, "episode/score": 0.15481117737220984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15481117737220984}
{"step": 731656, "time": 24292.681515455246, "episode/length": 640.0, "episode/score": 0.11452106025541298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11452106025541298}
{"step": 731816, "time": 24297.715995550156, "episode/length": 640.0, "episode/score": 0.1646479334522155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1646479334522155}
{"step": 732056, "time": 24305.3507707119, "episode/length": 640.0, "episode/score": 0.17709520227720077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17709520227720077}
{"step": 734520, "time": 24383.587585926056, "episode/length": 640.0, "episode/score": 0.20709590289558832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20709590289558832}
{"step": 735480, "time": 24414.146852254868, "episode/length": 640.0, "episode/score": 0.20565044263517507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20565044263517507}
{"step": 735808, "time": 24424.70726466179, "episode/length": 640.0, "episode/score": 0.10310892242648606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10310892242648606}
{"step": 736352, "time": 24441.92458987236, "episode/length": 640.0, "episode/score": 0.24394848556178772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24394848556178772}
{"step": 736504, "time": 24446.498431682587, "episode/length": 640.0, "episode/score": 0.2327703117180704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2327703117180704}
{"step": 736784, "time": 24455.53533267975, "episode/length": 640.0, "episode/score": 0.27240123415410267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27240123415410267}
{"step": 736944, "time": 24460.580501317978, "episode/length": 640.0, "episode/score": 0.242782409918874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.242782409918874}
{"step": 737184, "time": 24468.243522167206, "episode/length": 640.0, "episode/score": 0.08207490575583165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08207490575583165}
{"step": 739648, "time": 24547.08055281639, "episode/length": 640.0, "episode/score": 0.2453837328760926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2453837328760926}
{"step": 740064, "time": 24572.767776727676, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24572.77711057663, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24572.78555035591, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24572.793844223022, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24572.802078962326, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24572.810117721558, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24572.818429231644, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740064, "time": 24572.82767057419, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 740608, "time": 24590.119896650314, "episode/length": 640.0, "episode/score": 0.20618056046041033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20618056046041033}
{"step": 740936, "time": 24600.160569429398, "episode/length": 640.0, "episode/score": 0.1583230620929328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1583230620929328}
{"step": 741480, "time": 24617.37497997284, "episode/length": 640.0, "episode/score": 0.24233618633056153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24233618633056153}
{"step": 741632, "time": 24622.403007745743, "episode/length": 640.0, "episode/score": 0.21682664512741212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21682664512741212}
{"step": 741912, "time": 24630.963635206223, "episode/length": 640.0, "episode/score": 0.07557599210755939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07557599210755939}
{"step": 742072, "time": 24635.984479904175, "episode/length": 640.0, "episode/score": 0.25177710781065343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25177710781065343}
{"step": 742312, "time": 24643.500221014023, "episode/length": 640.0, "episode/score": 0.1886587111962399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1886587111962399}
{"step": 744352, "time": 24708.371319770813, "episode/length": 358.0, "episode/score": 0.16062498926578428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16062498926578428}
{"step": 744776, "time": 24721.536685943604, "episode/length": 640.0, "episode/score": 0.23152434765819407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23152434765819407}
{"step": 745736, "time": 24752.31211900711, "episode/length": 640.0, "episode/score": 0.20898581924018345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20898581924018345}
{"step": 746064, "time": 24762.82666182518, "episode/length": 640.0, "episode/score": 0.21099621237704014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21099621237704014}
{"step": 746760, "time": 24784.919143676758, "episode/length": 640.0, "episode/score": 0.18836970834763633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18836970834763633}
{"step": 747040, "time": 24794.053713798523, "episode/length": 640.0, "episode/score": 0.17652658324010417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17652658324010417}
{"step": 747200, "time": 24799.18490099907, "episode/length": 640.0, "episode/score": 0.11486445153570912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11486445153570912}
{"step": 747440, "time": 24806.727429628372, "episode/length": 640.0, "episode/score": 0.11422314652742216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11422314652742216}
{"step": 749480, "time": 24870.833429336548, "episode/length": 640.0, "episode/score": 0.10579017318610795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10579017318610795}
{"step": 749904, "time": 24884.45921278, "episode/length": 640.0, "episode/score": 0.1770402844202863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1770402844202863}
{"step": 750048, "time": 24900.48126721382, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24900.4908952713, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24900.499457359314, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24900.50780749321, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24900.516286611557, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24900.524696588516, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24900.532984018326, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750048, "time": 24900.54129934311, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 750864, "time": 24926.23121738434, "episode/length": 640.0, "episode/score": 0.19934517736066937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19934517736066937}
{"step": 751192, "time": 24936.322365045547, "episode/length": 640.0, "episode/score": 0.07798443907472574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07798443907472574}
{"step": 751888, "time": 24958.52135825157, "episode/length": 640.0, "episode/score": 0.18696484099837107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18696484099837107}
{"step": 752168, "time": 24967.106511116028, "episode/length": 640.0, "episode/score": 0.14908762334312087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14908762334312087}
{"step": 752328, "time": 24972.13731598854, "episode/length": 640.0, "episode/score": 0.10027300284752982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10027300284752982}
{"step": 752568, "time": 24979.870123147964, "episode/length": 640.0, "episode/score": 0.17987076452914152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17987076452914152}
{"step": 752984, "time": 24992.98596382141, "episode/length": 437.0, "episode/score": 0.19246931945781398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19246931945781398}
{"step": 755032, "time": 25058.261202573776, "episode/length": 640.0, "episode/score": 0.3063878101336286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3063878101336286}
{"step": 755992, "time": 25088.541778087616, "episode/length": 640.0, "episode/score": 0.0846741825070012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0846741825070012}
{"step": 756320, "time": 25099.1502597332, "episode/length": 640.0, "episode/score": 0.22811375651303933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22811375651303933}
{"step": 757016, "time": 25120.775464057922, "episode/length": 640.0, "episode/score": 0.2560724646681365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2560724646681365}
{"step": 757296, "time": 25129.885038137436, "episode/length": 640.0, "episode/score": 0.2376506788154984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2376506788154984}
{"step": 757456, "time": 25134.903879404068, "episode/length": 640.0, "episode/score": 0.29026099361806246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29026099361806246}
{"step": 757696, "time": 25142.466426610947, "episode/length": 640.0, "episode/score": 0.15053176399351287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15053176399351287}
{"step": 758112, "time": 25155.579080581665, "episode/length": 640.0, "episode/score": 0.11656050348528879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11656050348528879}
{"step": 759881, "time": 25212.210074424744, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2895565635279604, "train/action_min": 0.0, "train/action_std": 1.8752397223522788, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.000710019175848605, "train/actor_opt_grad_steps": 46445.0, "train/actor_opt_loss": -5.610128131077478, "train/adv_mag": 0.06998284455192716, "train/adv_max": 0.004925192892551422, "train/adv_mean": 4.5695097503689315e-05, "train/adv_min": -0.06976280306514941, "train/adv_std": 0.002175916310117923, "train/cont_avg": 0.9985094572368421, "train/cont_loss_mean": 0.00253637516610692, "train/cont_loss_std": 0.06310534168641377, "train/cont_neg_acc": 0.7617647075185588, "train/cont_neg_loss": 1.3615934526517068, "train/cont_pos_acc": 0.9999639636591862, "train/cont_pos_loss": 0.0005127250800509692, "train/cont_pred": 0.9984587371349335, "train/cont_rate": 0.9985094572368421, "train/dyn_loss_mean": 1.0000056147575378, "train/dyn_loss_std": 0.00015123356463510917, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.032345070415421534, "train/extr_critic_critic_opt_grad_steps": 46445.0, "train/extr_critic_critic_opt_loss": 13511.946607730262, "train/extr_critic_mag": 0.08142768960250052, "train/extr_critic_max": 0.08142768960250052, "train/extr_critic_mean": 0.07825941866949986, "train/extr_critic_min": 0.07377791718432777, "train/extr_critic_std": 0.0011102534741726949, "train/extr_return_normed_mag": 0.06800129068525214, "train/extr_return_normed_max": 0.008373059097089266, "train/extr_return_normed_mean": 0.0024420740082859993, "train/extr_return_normed_min": -0.0672860718479282, "train/extr_return_normed_std": 0.0024731750446861903, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08423612882432184, "train/extr_return_raw_max": 0.08423612882432184, "train/extr_return_raw_mean": 0.07830514747061228, "train/extr_return_raw_min": 0.008576997879304384, "train/extr_return_raw_std": 0.002473175040397205, "train/extr_reward_mag": 0.0012603784862317538, "train/extr_reward_max": 0.0012603784862317538, "train/extr_reward_mean": 0.0002483949065974325, "train/extr_reward_min": 2.605664102654708e-06, "train/extr_reward_std": 0.00026689883479297065, "train/image_loss_mean": 0.11127834829844926, "train/image_loss_std": 0.12231243660575465, "train/model_loss_mean": 0.7230474264998185, "train/model_loss_std": 0.1603859243424315, "train/model_opt_grad_norm": 19.353171735060844, "train/model_opt_grad_steps": 46405.48947368421, "train/model_opt_loss": 3653.011271587171, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5052.631578947368, "train/policy_entropy_mag": 1.9407199094170018, "train/policy_entropy_max": 1.9407199094170018, "train/policy_entropy_mean": 1.7369432417969954, "train/policy_entropy_min": 0.8538596871652101, "train/policy_entropy_std": 0.12467170189085759, "train/policy_logprob_mag": 4.118676111572667, "train/policy_logprob_max": -0.2354197549192529, "train/policy_logprob_mean": -1.737376132136897, "train/policy_logprob_min": -4.118676111572667, "train/policy_logprob_std": 0.6472512185573578, "train/policy_randomness_mag": 0.9973328031991657, "train/policy_randomness_max": 0.9973328031991657, "train/policy_randomness_mean": 0.8926123041855661, "train/policy_randomness_min": 0.43879710482923606, "train/policy_randomness_std": 0.06406858461467843, "train/post_ent_mag": 25.39149334556178, "train/post_ent_max": 25.39149334556178, "train/post_ent_mean": 17.56372537612915, "train/post_ent_min": 12.152971373106304, "train/post_ent_std": 2.621019674602308, "train/prior_ent_mag": 24.872443008422852, "train/prior_ent_max": 24.872443008422852, "train/prior_ent_mean": 17.52322729512265, "train/prior_ent_min": 12.403073335948744, "train/prior_ent_std": 2.3099798403288188, "train/rep_loss_mean": 1.0000056147575378, "train/rep_loss_std": 0.00015123356463510917, "train/reward_avg": 0.00021146088578174576, "train/reward_loss_mean": 0.009229312023442042, "train/reward_loss_std": 0.013865044561067694, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001224468883715178, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009229312062655625, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00021186954354083067, "train/reward_rate": 0.0, "eval_stats/mean_log_entropy": 0.0, "train_stats/mean_log_entropy": 1.7504380469520886, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.004727293737232685, "report/cont_loss_std": 0.14065366983413696, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.2517595291137695, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0003299705567769706, "report/cont_pred": 0.9986840486526489, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11714813858270645, "report/image_loss_std": 0.11235340684652328, "report/model_loss_mean": 0.7317444682121277, "report/model_loss_std": 0.1878553330898285, "report/post_ent_mag": 25.08061981201172, "report/post_ent_max": 25.08061981201172, "report/post_ent_mean": 17.359390258789062, "report/post_ent_min": 11.927835464477539, "report/post_ent_std": 2.672081232070923, "report/prior_ent_mag": 25.588287353515625, "report/prior_ent_max": 25.588287353515625, "report/prior_ent_mean": 18.54907989501953, "report/prior_ent_min": 12.777416229248047, "report/prior_ent_std": 2.5301830768585205, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002240718313260004, "report/reward_loss_mean": 0.009868981316685677, "report/reward_loss_std": 0.014624496921896935, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0011134147644042969, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009868981316685677, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00021716125775128603, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02754155360162258, "eval/cont_loss_std": 0.496505469083786, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.18239974975586, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0006418760167434812, "eval/cont_pred": 0.9993644952774048, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.27926746010780334, "eval/image_loss_std": 0.13884055614471436, "eval/model_loss_mean": 0.9083110094070435, "eval/model_loss_std": 0.515045702457428, "eval/post_ent_mag": 25.366718292236328, "eval/post_ent_max": 25.366718292236328, "eval/post_ent_mean": 16.729896545410156, "eval/post_ent_min": 12.254308700561523, "eval/post_ent_std": 2.565277099609375, "eval/prior_ent_mag": 25.806787490844727, "eval/prior_ent_max": 25.806787490844727, "eval/prior_ent_mean": 18.097492218017578, "eval/prior_ent_min": 12.752750396728516, "eval/prior_ent_std": 2.4409265518188477, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015019401907920837, "eval/reward_loss_std": 0.0014223364414647222, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011986494064331055, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015019401907920837, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002362510422244668, "eval/reward_rate": 0.0, "replay/size": 759377.0, "replay/inserts": 30416.0, "replay/samples": 30416.0, "replay/insert_wait_avg": 1.2901536669623281e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.381021330069392e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1239644455773347e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2919683456421, "timer/env.step_count": 3802.0, "timer/env.step_total": 34.19603157043457, "timer/env.step_frac": 0.034186050325876884, "timer/env.step_avg": 0.008994221875443074, "timer/env.step_min": 0.007447242736816406, "timer/env.step_max": 0.04294180870056152, "timer/replay._sample_count": 30416.0, "timer/replay._sample_total": 15.23189640045166, "timer/replay._sample_frac": 0.015227450466930484, "timer/replay._sample_avg": 0.0005007856523031188, "timer/replay._sample_min": 0.0003745555877685547, "timer/replay._sample_max": 0.02035212516784668, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5725.0, "timer/agent.policy_total": 57.95731711387634, "timer/agent.policy_frac": 0.05794040035104001, "timer/agent.policy_avg": 0.010123548840851763, "timer/agent.policy_min": 0.008655548095703125, "timer/agent.policy_max": 0.09237456321716309, "timer/dataset_train_count": 1901.0, "timer/dataset_train_total": 0.20218467712402344, "timer/dataset_train_frac": 0.00020212566282863556, "timer/dataset_train_avg": 0.00010635701058601969, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0006420612335205078, "timer/agent.train_count": 1901.0, "timer/agent.train_total": 852.4880306720734, "timer/agent.train_frac": 0.8522392038016481, "timer/agent.train_avg": 0.44844188883328423, "timer/agent.train_min": 0.4377322196960449, "timer/agent.train_max": 0.604271411895752, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47820162773132324, "timer/agent.report_frac": 0.00047806204874583665, "timer/agent.report_avg": 0.23910081386566162, "timer/agent.report_min": 0.2338426113128662, "timer/agent.report_max": 0.24435901641845703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9793623592704268e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 30.406576080006936}
{"step": 760032, "time": 25228.877945423126, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 25228.887055158615, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 25228.89531826973, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 25228.903254508972, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 25228.911041498184, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 25228.91882801056, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 25228.92669081688, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760032, "time": 25228.93461751938, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 760160, "time": 25232.95059156418, "episode/length": 640.0, "episode/score": 0.10638491964073182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10638491964073182}
{"step": 761120, "time": 25262.996660470963, "episode/length": 640.0, "episode/score": 0.1458239982816849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1458239982816849}
{"step": 761448, "time": 25273.0719871521, "episode/length": 640.0, "episode/score": 0.1979658901464063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1979658901464063}
{"step": 762144, "time": 25295.5739402771, "episode/length": 640.0, "episode/score": 0.2095802335213648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2095802335213648}
{"step": 762424, "time": 25304.097799301147, "episode/length": 640.0, "episode/score": 0.20365139351338257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20365139351338257}
{"step": 762584, "time": 25309.188144683838, "episode/length": 640.0, "episode/score": 0.24032253337588827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24032253337588827}
{"step": 762824, "time": 25316.704175949097, "episode/length": 640.0, "episode/score": 0.1746067128347022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1746067128347022}
{"step": 763240, "time": 25329.746002197266, "episode/length": 640.0, "episode/score": 0.2256215008608251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2256215008608251}
{"step": 765288, "time": 25393.88297367096, "episode/length": 640.0, "episode/score": 0.130230596736169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.130230596736169}
{"step": 766248, "time": 25424.07032251358, "episode/length": 640.0, "episode/score": 0.08975260477382108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08975260477382108}
{"step": 766576, "time": 25434.798500061035, "episode/length": 640.0, "episode/score": 0.13759187221796765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13759187221796765}
{"step": 767272, "time": 25456.535626888275, "episode/length": 640.0, "episode/score": 0.1061418048041105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1061418048041105}
{"step": 767552, "time": 25465.499083280563, "episode/length": 640.0, "episode/score": 0.09038961558826486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09038961558826486}
{"step": 767712, "time": 25470.47617483139, "episode/length": 640.0, "episode/score": 0.05438576336018741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05438576336018741}
{"step": 767952, "time": 25478.11238670349, "episode/length": 640.0, "episode/score": 0.13800349927566913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13800349927566913}
{"step": 768368, "time": 25491.471400022507, "episode/length": 640.0, "episode/score": 0.06582639322442674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06582639322442674}
{"step": 770016, "time": 25555.219603061676, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25555.228266954422, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25555.236466407776, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25555.24494576454, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25555.25386452675, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25555.26158475876, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25555.269605875015, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770016, "time": 25555.277774095535, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 770416, "time": 25568.3106842041, "episode/length": 640.0, "episode/score": 0.1214977217617843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1214977217617843}
{"step": 771376, "time": 25598.382308721542, "episode/length": 640.0, "episode/score": 0.057251923753312894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057251923753312894}
{"step": 771376, "time": 25598.390844345093, "episode/length": 512.0, "episode/score": 0.1506470917669276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1506470917669276}
{"step": 771704, "time": 25608.50785303116, "episode/length": 640.0, "episode/score": 0.05526214490151915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05526214490151915}
{"step": 772680, "time": 25639.11614227295, "episode/length": 640.0, "episode/score": 0.1807322644630176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1807322644630176}
{"step": 772840, "time": 25644.126664876938, "episode/length": 640.0, "episode/score": 0.13462849232348617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13462849232348617}
{"step": 773080, "time": 25651.629899263382, "episode/length": 640.0, "episode/score": 0.16082790551547532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16082790551547532}
{"step": 773496, "time": 25664.661790132523, "episode/length": 640.0, "episode/score": 0.14792035721012553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14792035721012553}
{"step": 775544, "time": 25729.463576555252, "episode/length": 640.0, "episode/score": 0.11999641071525957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11999641071525957}
{"step": 776504, "time": 25759.65405702591, "episode/length": 640.0, "episode/score": 0.19572865622168933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19572865622168933}
{"step": 776504, "time": 25759.663277626038, "episode/length": 640.0, "episode/score": 0.09800140051419248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09800140051419248}
{"step": 776832, "time": 25770.14103269577, "episode/length": 640.0, "episode/score": 0.12657388694080396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12657388694080396}
{"step": 777808, "time": 25800.67481160164, "episode/length": 640.0, "episode/score": 0.12876103008653672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12876103008653672}
{"step": 777968, "time": 25805.674380540848, "episode/length": 640.0, "episode/score": 0.02404617146913779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02404617146913779}
{"step": 778208, "time": 25813.249486207962, "episode/length": 640.0, "episode/score": 0.13514175620500168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13514175620500168}
{"step": 778624, "time": 25827.061995983124, "episode/length": 640.0, "episode/score": 0.02528903511480962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02528903511480962}
{"step": 780000, "time": 25881.82265353203, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25881.835392713547, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25881.84354543686, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25881.851457357407, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25881.859942674637, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25881.867640018463, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25881.87532877922, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780000, "time": 25881.883069753647, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 780672, "time": 25902.86319732666, "episode/length": 640.0, "episode/score": 0.17582202000181724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17582202000181724}
{"step": 781632, "time": 25933.027426719666, "episode/length": 640.0, "episode/score": 0.16688416014505947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16688416014505947}
{"step": 781632, "time": 25933.037153482437, "episode/length": 640.0, "episode/score": 0.17156401645061692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17156401645061692}
{"step": 781960, "time": 25943.189989089966, "episode/length": 640.0, "episode/score": 0.16123663498092355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16123663498092355}
{"step": 782936, "time": 25973.966833353043, "episode/length": 640.0, "episode/score": 0.2224323801119965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2224323801119965}
{"step": 783096, "time": 25978.96880865097, "episode/length": 640.0, "episode/score": 0.14923367086547046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14923367086547046}
{"step": 783336, "time": 25986.492600917816, "episode/length": 640.0, "episode/score": 0.24441458364697155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24441458364697155}
{"step": 783752, "time": 25999.620548963547, "episode/length": 640.0, "episode/score": 0.07511468069122884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07511468069122884}
{"step": 785800, "time": 26063.71273779869, "episode/length": 640.0, "episode/score": 0.1662079993862733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1662079993862733}
{"step": 786760, "time": 26094.213819026947, "episode/length": 640.0, "episode/score": 0.2552914594724598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2552914594724598}
{"step": 786760, "time": 26094.223208904266, "episode/length": 640.0, "episode/score": 0.1937900412711997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1937900412711997}
{"step": 787088, "time": 26104.708631515503, "episode/length": 640.0, "episode/score": 0.16338309852389443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16338309852389443}
{"step": 788064, "time": 26135.822110176086, "episode/length": 640.0, "episode/score": 0.12056376873174202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12056376873174202}
{"step": 788224, "time": 26140.930500268936, "episode/length": 640.0, "episode/score": 0.19124016796418175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19124016796418175}
{"step": 788464, "time": 26148.574629068375, "episode/length": 640.0, "episode/score": 0.2680334778586797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2680334778586797}
{"step": 788880, "time": 26161.555005311966, "episode/length": 640.0, "episode/score": 0.1924268201855881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1924268201855881}
{"step": 790088, "time": 26211.447115182877, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 26211.45685648918, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 26211.465834617615, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 26211.47392129898, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 26211.481890439987, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 26211.490215301514, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 26211.498587608337, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790088, "time": 26211.506633520126, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 790089, "time": 26212.552097082138, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.241893627025463, "train/action_min": 0.0, "train/action_std": 1.8771868559418532, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007257958488057185, "train/actor_opt_grad_steps": 48340.0, "train/actor_opt_loss": -5.684977699721617, "train/adv_mag": 0.07021649658837646, "train/adv_max": 0.004926919818870605, "train/adv_mean": 4.056773938216531e-05, "train/adv_min": -0.06994428635431976, "train/adv_std": 0.0020992774485546367, "train/cont_avg": 0.9984447337962963, "train/cont_loss_mean": 0.0026459646304680044, "train/cont_loss_std": 0.0647721995088942, "train/cont_neg_acc": 0.7784313744579265, "train/cont_neg_loss": 1.2946379197982025, "train/cont_pos_acc": 0.9999533973673664, "train/cont_pos_loss": 0.0004698419735567378, "train/cont_pred": 0.9984380145552297, "train/cont_rate": 0.9984447337962963, "train/dyn_loss_mean": 1.0000040726686912, "train/dyn_loss_std": 8.829048705852724e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02703996735182098, "train/extr_critic_critic_opt_grad_steps": 48340.0, "train/extr_critic_critic_opt_loss": 13526.679697833995, "train/extr_critic_mag": 0.08361276432319924, "train/extr_critic_max": 0.08361276432319924, "train/extr_critic_mean": 0.08033330206360136, "train/extr_critic_min": 0.07555455883974752, "train/extr_critic_std": 0.0011862433468060637, "train/extr_return_normed_mag": 0.06817904493165394, "train/extr_return_normed_max": 0.008531674624435485, "train/extr_return_normed_mean": 0.0025681555228031895, "train/extr_return_normed_min": -0.06736676875876371, "train/extr_return_normed_std": 0.0024477794603814207, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08633744488002132, "train/extr_return_raw_max": 0.08633744488002132, "train/extr_return_raw_mean": 0.0803739299613332, "train/extr_return_raw_min": 0.010439001496822115, "train/extr_return_raw_std": 0.0024477794640771454, "train/extr_reward_mag": 0.0012582420672058428, "train/extr_reward_max": 0.0012582420672058428, "train/extr_reward_mean": 0.0002528772655216652, "train/extr_reward_min": 2.679370698474702e-06, "train/extr_reward_std": 0.0002669536340156343, "train/image_loss_mean": 0.11145344952111522, "train/image_loss_std": 0.1229346778500017, "train/model_loss_mean": 0.7234810779965113, "train/model_loss_std": 0.16253093432970148, "train/model_opt_grad_norm": 19.843200607905313, "train/model_opt_grad_steps": 48298.62433862434, "train/model_opt_loss": 3790.142817098628, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5238.0952380952385, "train/policy_entropy_mag": 1.9402266658803142, "train/policy_entropy_max": 1.9402266658803142, "train/policy_entropy_mean": 1.7202707182162653, "train/policy_entropy_min": 0.8142437143300576, "train/policy_entropy_std": 0.13304075508048294, "train/policy_logprob_mag": 4.164103986094237, "train/policy_logprob_max": -0.2195964433528759, "train/policy_logprob_mean": -1.7206319898524611, "train/policy_logprob_min": -4.164103986094237, "train/policy_logprob_std": 0.6678558673177447, "train/policy_randomness_mag": 0.9970793251007323, "train/policy_randomness_max": 0.9970793251007323, "train/policy_randomness_mean": 0.8840443255409361, "train/policy_randomness_min": 0.41843851943495414, "train/policy_randomness_std": 0.06836942733122559, "train/post_ent_mag": 27.327270174783372, "train/post_ent_max": 27.327270174783372, "train/post_ent_mean": 18.644864632339075, "train/post_ent_min": 12.157748484737658, "train/post_ent_std": 3.084160915758244, "train/prior_ent_mag": 26.406315445269225, "train/prior_ent_max": 26.406315445269225, "train/prior_ent_mean": 18.39455405744926, "train/prior_ent_min": 12.563111915790214, "train/prior_ent_std": 2.651931750080573, "train/rep_loss_mean": 1.0000040726686912, "train/rep_loss_std": 8.829048705852724e-05, "train/reward_avg": 0.0002151774476582884, "train/reward_loss_mean": 0.009379199779932462, "train/reward_loss_std": 0.013990944620990564, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012203688343996725, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009379199792251543, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00021510120301394077, "train/reward_rate": 0.0, "eval_stats/mean_log_entropy": 0.0, "train_stats/mean_log_entropy": 1.73221301784118, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0007611806504428387, "report/cont_loss_std": 0.010285243391990662, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000920790305826813, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0007608682499267161, "report/cont_pred": 0.9973375797271729, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1088782399892807, "report/image_loss_std": 0.11710555106401443, "report/model_loss_mean": 0.7172673344612122, "report/model_loss_std": 0.12108080834150314, "report/post_ent_mag": 26.256771087646484, "report/post_ent_max": 26.256771087646484, "report/post_ent_mean": 17.923917770385742, "report/post_ent_min": 11.552138328552246, "report/post_ent_std": 2.9924566745758057, "report/prior_ent_mag": 27.248985290527344, "report/prior_ent_max": 27.248985290527344, "report/prior_ent_mean": 19.221187591552734, "report/prior_ent_min": 13.126110076904297, "report/prior_ent_std": 2.729483127593994, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001701079891063273, "report/reward_loss_mean": 0.007627897895872593, "report/reward_loss_std": 0.012524100951850414, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012803077697753906, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007627897895872593, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0001800208119675517, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04245058819651604, "eval/cont_loss_std": 0.5946934819221497, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.663386344909668, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.008642993867397308, "eval/cont_pred": 0.9979370832443237, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3114320635795593, "eval/image_loss_std": 0.15497715771198273, "eval/model_loss_mean": 0.9553918838500977, "eval/model_loss_std": 0.609401285648346, "eval/post_ent_mag": 26.336936950683594, "eval/post_ent_max": 26.336936950683594, "eval/post_ent_mean": 17.23569107055664, "eval/post_ent_min": 11.830185890197754, "eval/post_ent_std": 2.9179189205169678, "eval/prior_ent_mag": 27.549041748046875, "eval/prior_ent_max": 27.549041748046875, "eval/prior_ent_mean": 18.59206199645996, "eval/prior_ent_min": 13.293797492980957, "eval/prior_ent_std": 2.7544124126434326, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015091639943420887, "eval/reward_loss_std": 0.0015350563917309046, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011529922485351562, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015091639943420887, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023736467119306326, "eval/reward_rate": 0.0, "replay/size": 789585.0, "replay/inserts": 30208.0, "replay/samples": 30208.0, "replay/insert_wait_avg": 1.2817761024176064e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.405423012830443e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 20512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0801482126232985e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3115994930267, "timer/env.step_count": 3776.0, "timer/env.step_total": 34.230831146240234, "timer/env.step_frac": 0.03422016815919054, "timer/env.step_avg": 0.009065368417966164, "timer/env.step_min": 0.007541179656982422, "timer/env.step_max": 0.048154354095458984, "timer/replay._sample_count": 30208.0, "timer/replay._sample_total": 15.230887651443481, "timer/replay._sample_frac": 0.015226143192943808, "timer/replay._sample_avg": 0.0005042004651563653, "timer/replay._sample_min": 0.00040221214294433594, "timer/replay._sample_max": 0.011057376861572266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 6340.0, "timer/agent.policy_total": 64.48114132881165, "timer/agent.policy_frac": 0.06446105529666124, "timer/agent.policy_avg": 0.010170527023471869, "timer/agent.policy_min": 0.008638620376586914, "timer/agent.policy_max": 0.15880489349365234, "timer/dataset_train_count": 1888.0, "timer/dataset_train_total": 0.19927310943603516, "timer/dataset_train_frac": 0.0001992110353784059, "timer/dataset_train_avg": 0.00010554719779451015, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0005462169647216797, "timer/agent.train_count": 1888.0, "timer/agent.train_total": 840.5502490997314, "timer/agent.train_frac": 0.840288415655417, "timer/agent.train_avg": 0.44520669973502724, "timer/agent.train_min": 0.4346284866333008, "timer/agent.train_max": 0.5872287750244141, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47890639305114746, "timer/agent.report_frac": 0.0004787572125464351, "timer/agent.report_avg": 0.23945319652557373, "timer/agent.report_min": 0.23407292366027832, "timer/agent.report_max": 0.24483346939086914, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.4083236492311726e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 30.198035701689193}
{"step": 790928, "time": 26239.343227386475, "episode/length": 640.0, "episode/score": 0.1754138885548997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1754138885548997}
{"step": 791888, "time": 26269.958201646805, "episode/length": 640.0, "episode/score": 0.22340665416068362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22340665416068362}
{"step": 791888, "time": 26269.968426465988, "episode/length": 640.0, "episode/score": 0.12830115043531976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12830115043531976}
{"step": 792216, "time": 26280.253945589066, "episode/length": 640.0, "episode/score": 0.19340770256799544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19340770256799544}
{"step": 793192, "time": 26311.280330896378, "episode/length": 640.0, "episode/score": 0.1952531168923457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1952531168923457}
{"step": 793352, "time": 26316.397180080414, "episode/length": 640.0, "episode/score": 0.2361674618815215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2361674618815215}
{"step": 793592, "time": 26324.002887248993, "episode/length": 640.0, "episode/score": 0.17374647613618777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17374647613618777}
{"step": 794008, "time": 26337.208880901337, "episode/length": 640.0, "episode/score": 0.16457626459295227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16457626459295227}
{"step": 796056, "time": 26402.714608192444, "episode/length": 640.0, "episode/score": 0.05697058954228851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05697058954228851}
{"step": 797016, "time": 26433.027729034424, "episode/length": 640.0, "episode/score": 0.18074414205705125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18074414205705125}
{"step": 797016, "time": 26433.03805756569, "episode/length": 640.0, "episode/score": 0.08861467757708397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08861467757708397}
{"step": 797344, "time": 26443.64618253708, "episode/length": 640.0, "episode/score": 0.19736736155732615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19736736155732615}
{"step": 798320, "time": 26474.909241437912, "episode/length": 640.0, "episode/score": 0.1026240040743005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1026240040743005}
{"step": 798480, "time": 26480.15233516693, "episode/length": 640.0, "episode/score": 0.12527501569729793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12527501569729793}
{"step": 798720, "time": 26487.84517931938, "episode/length": 640.0, "episode/score": 0.10959597073667737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10959597073667737}
{"step": 799136, "time": 26501.141836166382, "episode/length": 640.0, "episode/score": 0.10542526491349236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10542526491349236}
{"step": 800072, "time": 26542.21682024002, "eval_episode/length": 598.0, "eval_episode/score": 0.15906250476837158, "eval_episode/reward_rate": 0.001669449081803005}
{"step": 800072, "time": 26542.972581863403, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26542.98165178299, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26542.99001979828, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26542.998033761978, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26543.00595855713, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26543.013685703278, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 800072, "time": 26543.021533489227, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 801184, "time": 26578.26158452034, "episode/length": 640.0, "episode/score": 0.17797097356333325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17797097356333325}
{"step": 802144, "time": 26608.759938955307, "episode/length": 640.0, "episode/score": 0.09935061430371661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09935061430371661}
{"step": 802144, "time": 26608.770223617554, "episode/length": 640.0, "episode/score": 0.11280303671486536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11280303671486536}
{"step": 802472, "time": 26618.82884120941, "episode/length": 640.0, "episode/score": 0.04259728478365332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04259728478365332}
{"step": 803448, "time": 26650.099055051804, "episode/length": 640.0, "episode/score": 0.1734565702493569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1734565702493569}
{"step": 803608, "time": 26655.138815164566, "episode/length": 640.0, "episode/score": 0.16687996721867648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16687996721867648}
{"step": 803848, "time": 26662.884072065353, "episode/length": 640.0, "episode/score": 0.1787004711978284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1787004711978284}
{"step": 804264, "time": 26676.018224716187, "episode/length": 640.0, "episode/score": 0.20785404056215384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20785404056215384}
{"step": 806312, "time": 26741.283091306686, "episode/length": 640.0, "episode/score": 0.13240884813421872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13240884813421872}
{"step": 807272, "time": 26772.14029932022, "episode/length": 640.0, "episode/score": 0.2040970812940941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2040970812940941}
{"step": 807272, "time": 26772.15016770363, "episode/length": 640.0, "episode/score": 0.1715984796468888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1715984796468888}
{"step": 807496, "time": 26779.47550392151, "episode/length": 505.0, "episode/score": 0.15940798029350844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15940798029350844}
{"step": 807600, "time": 26783.01380133629, "episode/length": 640.0, "episode/score": 0.23012660588790368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23012660588790368}
{"step": 808736, "time": 26819.01981663704, "episode/length": 640.0, "episode/score": 0.18704083220535495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18704083220535495}
{"step": 808976, "time": 26826.565355539322, "episode/length": 640.0, "episode/score": 0.14236360100733236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14236360100733236}
{"step": 809392, "time": 26839.74222588539, "episode/length": 640.0, "episode/score": 0.2036331225180561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2036331225180561}
{"step": 810056, "time": 26872.788394212723, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26872.79779815674, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26872.806277751923, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26872.8145840168, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26872.822528600693, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26872.83093214035, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26872.83959722519, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 810056, "time": 26872.847427845, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 811440, "time": 26917.09422802925, "episode/length": 640.0, "episode/score": 0.18343744975254594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18343744975254594}
{"step": 812400, "time": 26947.25269150734, "episode/length": 640.0, "episode/score": 0.2120628576869592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2120628576869592}
{"step": 812400, "time": 26947.261966705322, "episode/length": 640.0, "episode/score": 0.21179529727172053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21179529727172053}
{"step": 812624, "time": 26954.311448574066, "episode/length": 640.0, "episode/score": 0.20992613232428425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20992613232428425}
{"step": 812728, "time": 26957.434711933136, "episode/length": 640.0, "episode/score": 0.24056654680856582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24056654680856582}
{"step": 813864, "time": 26993.15611743927, "episode/length": 640.0, "episode/score": 0.234336465511376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.234336465511376}
{"step": 814104, "time": 27000.703035116196, "episode/length": 640.0, "episode/score": 0.18467680912257833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18467680912257833}
{"step": 814520, "time": 27013.750100135803, "episode/length": 640.0, "episode/score": 0.245145644507204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.245145644507204}
{"step": 816568, "time": 27078.711838960648, "episode/length": 640.0, "episode/score": 0.25343350977556156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25343350977556156}
{"step": 817528, "time": 27109.020726442337, "episode/length": 640.0, "episode/score": 0.24395771575217395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24395771575217395}
{"step": 817528, "time": 27109.030362844467, "episode/length": 640.0, "episode/score": 0.11723798538167784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11723798538167784}
{"step": 817752, "time": 27116.139929771423, "episode/length": 640.0, "episode/score": 0.15735553018271276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15735553018271276}
{"step": 817856, "time": 27119.691591262817, "episode/length": 640.0, "episode/score": 0.20032510325745534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20032510325745534}
{"step": 818992, "time": 27155.85270357132, "episode/length": 640.0, "episode/score": 0.19211945792528695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19211945792528695}
{"step": 819232, "time": 27163.88927912712, "episode/length": 640.0, "episode/score": 0.19717680965823092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19717680965823092}
{"step": 819648, "time": 27177.103934526443, "episode/length": 640.0, "episode/score": 0.16891788523275864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16891788523275864}
{"step": 820040, "time": 27201.258289813995, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 27201.267290592194, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 27201.275312662125, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 27201.282927513123, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 27201.290581941605, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 27201.298220157623, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 27201.305656909943, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820040, "time": 27201.313351631165, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 820313, "time": 27212.918036222458, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.255275181361607, "train/action_min": 0.0, "train/action_std": 1.8734831942452326, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0006727510484221278, "train/actor_opt_grad_steps": 50230.0, "train/actor_opt_loss": -6.042760544826114, "train/adv_mag": 0.06862871904694845, "train/adv_max": 0.005007952175758503, "train/adv_mean": 2.16509021814971e-05, "train/adv_min": -0.0683113415405233, "train/adv_std": 0.0019686013243343462, "train/cont_avg": 0.9984240658068783, "train/cont_loss_mean": 0.00250877894688442, "train/cont_loss_std": 0.06322877973619302, "train/cont_neg_acc": 0.7822695055329207, "train/cont_neg_loss": 1.2243086078789593, "train/cont_pos_acc": 0.9999430769335025, "train/cont_pos_loss": 0.0004886833653063391, "train/cont_pred": 0.9983624210433354, "train/cont_rate": 0.9984240658068783, "train/dyn_loss_mean": 1.0000018076921897, "train/dyn_loss_std": 5.78046938966191e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03003066211659215, "train/extr_critic_critic_opt_grad_steps": 50230.0, "train/extr_critic_critic_opt_loss": 13533.628467055225, "train/extr_critic_mag": 0.08479049407615863, "train/extr_critic_max": 0.08479049407615863, "train/extr_critic_mean": 0.08134975690374929, "train/extr_critic_min": 0.07632447487462765, "train/extr_critic_std": 0.0012679801038564947, "train/extr_return_normed_mag": 0.06679600969981894, "train/extr_return_normed_max": 0.008907449505631887, "train/extr_return_normed_mean": 0.0027009945636289933, "train/extr_return_normed_min": -0.0657288611487106, "train/extr_return_normed_std": 0.0023763816256726546, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08757788620928608, "train/extr_return_raw_max": 0.08757788620928608, "train/extr_return_raw_mean": 0.08137143572802266, "train/extr_return_raw_min": 0.01294157555494359, "train/extr_return_raw_std": 0.002376381630600287, "train/extr_reward_mag": 0.0012536976072523329, "train/extr_reward_max": 0.0012536976072523329, "train/extr_reward_mean": 0.0002530488945825873, "train/extr_reward_min": 2.665494484876199e-06, "train/extr_reward_std": 0.00026861690399027554, "train/image_loss_mean": 0.1106853910460674, "train/image_loss_std": 0.12240691002083834, "train/model_loss_mean": 0.7226152653416629, "train/model_loss_std": 0.16083711117663713, "train/model_opt_grad_norm": 19.41498933519636, "train/model_opt_grad_steps": 50186.59788359788, "train/model_opt_loss": 2676.2441335203785, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3703.703703703704, "train/policy_entropy_mag": 1.9406545181123038, "train/policy_entropy_max": 1.9406545181123038, "train/policy_entropy_mean": 1.7217914181411582, "train/policy_entropy_min": 0.8520797465844129, "train/policy_entropy_std": 0.12989876923895388, "train/policy_logprob_mag": 4.179014941371938, "train/policy_logprob_max": -0.23577060369114397, "train/policy_logprob_mean": -1.7220430355223397, "train/policy_logprob_min": -4.179014941371938, "train/policy_logprob_std": 0.6646812643323626, "train/policy_randomness_mag": 0.9972991984357279, "train/policy_randomness_max": 0.9972991984357279, "train/policy_randomness_mean": 0.884825813391852, "train/policy_randomness_min": 0.43788239675224144, "train/policy_randomness_std": 0.06675476620279291, "train/post_ent_mag": 28.622858420881645, "train/post_ent_max": 28.622858420881645, "train/post_ent_mean": 19.250289735339937, "train/post_ent_min": 12.257765048395388, "train/post_ent_std": 3.362751628986742, "train/prior_ent_mag": 27.221139685817498, "train/prior_ent_max": 27.221139685817498, "train/prior_ent_mean": 19.258300518863415, "train/prior_ent_min": 13.179590290816373, "train/prior_ent_std": 2.8138258633790194, "train/rep_loss_mean": 1.0000018076921897, "train/rep_loss_std": 5.78046938966191e-05, "train/reward_avg": 0.0002163673931838718, "train/reward_loss_mean": 0.009419990284614778, "train/reward_loss_std": 0.01400250044685823, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012215375900268555, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009419990255048982, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00021490384701383178, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7306943908333778, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.00033254691516049206, "report/cont_loss_std": 0.0010198206873610616, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004460556956473738, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.000332435971358791, "report/cont_pred": 0.9986923933029175, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09277617931365967, "report/image_loss_std": 0.1065494641661644, "report/model_loss_mean": 0.6997107267379761, "report/model_loss_std": 0.10898663848638535, "report/post_ent_mag": 29.870006561279297, "report/post_ent_max": 29.870006561279297, "report/post_ent_mean": 20.11648178100586, "report/post_ent_min": 13.082242965698242, "report/post_ent_std": 3.4053781032562256, "report/prior_ent_mag": 27.57948112487793, "report/prior_ent_max": 27.57948112487793, "report/prior_ent_mean": 18.380367279052734, "report/prior_ent_min": 13.159406661987305, "report/prior_ent_std": 2.8582711219787598, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00014478981029242277, "report/reward_loss_mean": 0.006601941306143999, "report/reward_loss_std": 0.011089076288044453, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0011928081512451172, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.006601941771805286, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000173071282915771, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.010415426455438137, "eval/cont_loss_std": 0.3091650903224945, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.89848804473877, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.000749665719922632, "eval/cont_pred": 0.9992548823356628, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.30511942505836487, "eval/image_loss_std": 0.15823958814144135, "eval/model_loss_mean": 0.9170442819595337, "eval/model_loss_std": 0.352130651473999, "eval/post_ent_mag": 29.65081214904785, "eval/post_ent_max": 29.65081214904785, "eval/post_ent_mean": 19.803749084472656, "eval/post_ent_min": 12.738901138305664, "eval/post_ent_std": 3.0879082679748535, "eval/prior_ent_mag": 27.350528717041016, "eval/prior_ent_max": 27.350528717041016, "eval/prior_ent_mean": 18.155303955078125, "eval/prior_ent_min": 12.630594253540039, "eval/prior_ent_std": 2.6682653427124023, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015094117261469364, "eval/reward_loss_std": 0.001453764853067696, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0012125968933105469, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015094117261469364, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023741251789033413, "eval/reward_rate": 0.0, "replay/size": 819809.0, "replay/inserts": 30224.0, "replay/samples": 30224.0, "replay/insert_wait_avg": 1.3091249905167717e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.526083147039863e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1295436634970282e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3564925193787, "timer/env.step_count": 3778.0, "timer/env.step_total": 34.482393741607666, "timer/env.step_frac": 0.03447010540688791, "timer/env.step_avg": 0.009127155569509705, "timer/env.step_min": 0.0074100494384765625, "timer/env.step_max": 0.035529375076293945, "timer/replay._sample_count": 30224.0, "timer/replay._sample_total": 15.285184621810913, "timer/replay._sample_frac": 0.015279737509690638, "timer/replay._sample_avg": 0.0005057300364548343, "timer/replay._sample_min": 0.000400543212890625, "timer/replay._sample_max": 0.01101541519165039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5701.0, "timer/agent.policy_total": 58.68656086921692, "timer/agent.policy_frac": 0.05866564700491516, "timer/agent.policy_avg": 0.010294081892513053, "timer/agent.policy_min": 0.008534431457519531, "timer/agent.policy_max": 0.0907747745513916, "timer/dataset_train_count": 1889.0, "timer/dataset_train_total": 0.20666790008544922, "timer/dataset_train_frac": 0.00020659425078049933, "timer/dataset_train_avg": 0.00010940598204629392, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0006844997406005859, "timer/agent.train_count": 1889.0, "timer/agent.train_total": 850.8135969638824, "timer/agent.train_frac": 0.8505103963699228, "timer/agent.train_avg": 0.45040423343773556, "timer/agent.train_min": 0.4375450611114502, "timer/agent.train_max": 2.5055899620056152, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.475905179977417, "timer/agent.report_frac": 0.0004757355838005898, "timer/agent.report_avg": 0.2379525899887085, "timer/agent.report_min": 0.23053884506225586, "timer/agent.report_max": 0.24536633491516113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074503632864238e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 30.212708354077336}
{"step": 821696, "time": 27256.878278255463, "episode/length": 640.0, "episode/score": 0.15801113612462814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15801113612462814}
{"step": 822656, "time": 27287.60488319397, "episode/length": 640.0, "episode/score": 0.16710737507520435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16710737507520435}
{"step": 822656, "time": 27287.61494231224, "episode/length": 640.0, "episode/score": 0.14305927792452167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14305927792452167}
{"step": 822880, "time": 27294.791271209717, "episode/length": 640.0, "episode/score": 0.2119195980855011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2119195980855011}
{"step": 822984, "time": 27297.879054307938, "episode/length": 640.0, "episode/score": 0.19018973896032776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19018973896032776}
{"step": 824120, "time": 27334.025800943375, "episode/length": 640.0, "episode/score": 0.12554004008256925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12554004008256925}
{"step": 824360, "time": 27341.564766407013, "episode/length": 640.0, "episode/score": 0.18453803973318372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18453803973318372}
{"step": 824776, "time": 27354.7785320282, "episode/length": 640.0, "episode/score": 0.130535372066106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.130535372066106}
{"step": 825992, "time": 27393.274517774582, "episode/length": 416.0, "episode/score": 0.15507991774154561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15507991774154561}
{"step": 826824, "time": 27420.01526594162, "episode/length": 640.0, "episode/score": 0.1939918505958076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1939918505958076}
{"step": 827784, "time": 27451.228212356567, "episode/length": 640.0, "episode/score": 0.15175963964099992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15175963964099992}
{"step": 828008, "time": 27458.22221469879, "episode/length": 640.0, "episode/score": 0.1902154189740486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1902154189740486}
{"step": 828112, "time": 27461.694613456726, "episode/length": 640.0, "episode/score": 0.22032137232724835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22032137232724835}
{"step": 829248, "time": 27497.58907365799, "episode/length": 640.0, "episode/score": 0.14231196410230496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14231196410230496}
{"step": 829488, "time": 27505.110414505005, "episode/length": 640.0, "episode/score": 0.16812351079329346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16812351079329346}
{"step": 829904, "time": 27518.20970058441, "episode/length": 640.0, "episode/score": 0.10796934896939092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10796934896939092}
{"step": 830024, "time": 27533.236859560013, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27533.24586248398, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27533.254173755646, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27533.262716770172, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27533.270568609238, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27533.27841567993, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27533.286066532135, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 830024, "time": 27533.293791294098, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 831120, "time": 27568.632309436798, "episode/length": 640.0, "episode/score": 0.24981352071216634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24981352071216634}
{"step": 831952, "time": 27594.950557231903, "episode/length": 640.0, "episode/score": 0.20773584290384406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20773584290384406}
{"step": 832912, "time": 27625.173477888107, "episode/length": 640.0, "episode/score": 0.10954582535202917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10954582535202917}
{"step": 833136, "time": 27632.153916358948, "episode/length": 640.0, "episode/score": 0.24466723327742557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24466723327742557}
{"step": 833240, "time": 27635.18263912201, "episode/length": 640.0, "episode/score": 0.15305935228553835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15305935228553835}
{"step": 834376, "time": 27670.969938993454, "episode/length": 640.0, "episode/score": 0.15199514759041222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15199514759041222}
{"step": 834616, "time": 27678.639384508133, "episode/length": 640.0, "episode/score": 0.05424837402728144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05424837402728144}
{"step": 835032, "time": 27691.767983675003, "episode/length": 640.0, "episode/score": 0.1068753703629568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1068753703629568}
{"step": 836248, "time": 27730.54203557968, "episode/length": 640.0, "episode/score": 0.20039564779136754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20039564779136754}
{"step": 837080, "time": 27756.797060728073, "episode/length": 640.0, "episode/score": 0.0716809480399263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0716809480399263}
{"step": 838040, "time": 27787.341728925705, "episode/length": 640.0, "episode/score": 0.09378969069885557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09378969069885557}
{"step": 838264, "time": 27794.4942548275, "episode/length": 640.0, "episode/score": 0.1823799499750578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1823799499750578}
{"step": 838368, "time": 27798.15471291542, "episode/length": 640.0, "episode/score": 0.14676467713837837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14676467713837837}
{"step": 839504, "time": 27834.022548675537, "episode/length": 640.0, "episode/score": 0.09197982631386026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09197982631386026}
{"step": 839744, "time": 27841.57089304924, "episode/length": 640.0, "episode/score": 0.16231371862684796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16231371862684796}
{"step": 840008, "time": 27861.693654060364, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27861.70312309265, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27861.711455345154, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27861.719636440277, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27861.727577209473, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27861.73560857773, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27861.74400782585, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840008, "time": 27861.75196504593, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 840160, "time": 27866.717052936554, "episode/length": 640.0, "episode/score": 0.16755731653987027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16755731653987027}
{"step": 841376, "time": 27904.910365104675, "episode/length": 640.0, "episode/score": 0.2653717820646193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2653717820646193}
{"step": 842208, "time": 27931.105191230774, "episode/length": 640.0, "episode/score": 0.18788895916321735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18788895916321735}
{"step": 843168, "time": 27961.565684080124, "episode/length": 640.0, "episode/score": 0.14743098518067654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14743098518067654}
{"step": 843392, "time": 27968.69046807289, "episode/length": 640.0, "episode/score": 0.17929122401022823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17929122401022823}
{"step": 843496, "time": 27971.79664373398, "episode/length": 640.0, "episode/score": 0.06234264873583584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06234264873583584}
{"step": 844632, "time": 28008.610917806625, "episode/length": 640.0, "episode/score": 0.1665191040586933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1665191040586933}
{"step": 844872, "time": 28016.151161909103, "episode/length": 640.0, "episode/score": 0.23215523669449567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23215523669449567}
{"step": 845288, "time": 28029.171993732452, "episode/length": 640.0, "episode/score": 0.1878733596205393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1878733596205393}
{"step": 846504, "time": 28067.89251589775, "episode/length": 640.0, "episode/score": 0.2773091099792566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2773091099792566}
{"step": 847336, "time": 28094.10014605522, "episode/length": 640.0, "episode/score": 0.24594076096860817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24594076096860817}
{"step": 848296, "time": 28124.57193017006, "episode/length": 640.0, "episode/score": 0.21338922409574934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21338922409574934}
{"step": 848520, "time": 28131.84082365036, "episode/length": 640.0, "episode/score": 0.16104062560805232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16104062560805232}
{"step": 848624, "time": 28135.39406657219, "episode/length": 640.0, "episode/score": 0.18283939133459626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18283939133459626}
{"step": 849760, "time": 28171.654061555862, "episode/length": 640.0, "episode/score": 0.10982268734960599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10982268734960599}
{"step": 850000, "time": 28179.195642232895, "episode/length": 640.0, "episode/score": 0.1684776351129358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1684776351129358}
{"step": 850096, "time": 28191.857738256454, "eval_episode/length": 538.0, "eval_episode/score": 0.2434374988079071, "eval_episode/reward_rate": 0.0018552875695732839}
{"step": 850096, "time": 28194.320895195007, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 28194.33013153076, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 28194.338431596756, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 28194.347453832626, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 28194.355638980865, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 28194.363681793213, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850096, "time": 28194.371818304062, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 850416, "time": 28204.539588689804, "episode/length": 640.0, "episode/score": 0.174878725315466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.174878725315466}
{"step": 850665, "time": 28213.18473482132, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1975521689967104, "train/action_min": 0.0, "train/action_std": 1.8522803319127936, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007268494310617251, "train/actor_opt_grad_steps": 52125.0, "train/actor_opt_loss": -5.544351694953481, "train/adv_mag": 0.06874763561706794, "train/adv_max": 0.005159717170815719, "train/adv_mean": 5.689223947851324e-05, "train/adv_min": -0.06843041495272988, "train/adv_std": 0.002132009365595877, "train/cont_avg": 0.9984580592105263, "train/cont_loss_mean": 0.002240280436786921, "train/cont_loss_std": 0.05659046054489935, "train/cont_neg_acc": 0.7696759275471171, "train/cont_neg_loss": 1.2639111672906185, "train/cont_pos_acc": 0.9999279480231436, "train/cont_pos_loss": 0.0005247774241357356, "train/cont_pred": 0.9983814377533762, "train/cont_rate": 0.9984580592105263, "train/dyn_loss_mean": 1.0000188419693394, "train/dyn_loss_std": 0.0005642784085418832, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.029070738519505156, "train/extr_critic_critic_opt_grad_steps": 52125.0, "train/extr_critic_critic_opt_loss": 13528.050411184211, "train/extr_critic_mag": 0.0864188551902771, "train/extr_critic_max": 0.0864188551902771, "train/extr_critic_mean": 0.0828124822754609, "train/extr_critic_min": 0.07760499590321591, "train/extr_critic_std": 0.0013541179488560087, "train/extr_return_normed_mag": 0.06687179399948372, "train/extr_return_normed_max": 0.009270614503245605, "train/extr_return_normed_mean": 0.0029597003460175506, "train/extr_return_normed_min": -0.0656355934707742, "train/extr_return_normed_std": 0.002573616657479617, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0891802299179529, "train/extr_return_raw_max": 0.0891802299179529, "train/extr_return_raw_mean": 0.0828693199706705, "train/extr_return_raw_min": 0.014274021943933086, "train/extr_return_raw_std": 0.0025736166636067394, "train/extr_reward_mag": 0.00125566093545211, "train/extr_reward_max": 0.00125566093545211, "train/extr_reward_mean": 0.00026316338434729625, "train/extr_reward_min": 2.8158489026521382e-06, "train/extr_reward_std": 0.00027268115564335236, "train/image_loss_mean": 0.10962504117112411, "train/image_loss_std": 0.12317792365425512, "train/model_loss_mean": 0.7212866369046663, "train/model_loss_std": 0.15653179327124042, "train/model_opt_grad_norm": 19.223640065444144, "train/model_opt_grad_steps": 52080.55789473684, "train/model_opt_loss": 3691.8610165244654, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5131.578947368421, "train/policy_entropy_mag": 1.9392863574780916, "train/policy_entropy_max": 1.9392863574780916, "train/policy_entropy_mean": 1.6923328638076782, "train/policy_entropy_min": 0.7573415255860279, "train/policy_entropy_std": 0.14495779597445538, "train/policy_logprob_mag": 4.319929451691477, "train/policy_logprob_max": -0.19913429915904998, "train/policy_logprob_mean": -1.6931613514297887, "train/policy_logprob_min": -4.319929451691477, "train/policy_logprob_std": 0.700591735777102, "train/policy_randomness_mag": 0.9965961029655055, "train/policy_randomness_max": 0.9965961029655055, "train/policy_randomness_mean": 0.8696871014017807, "train/policy_randomness_min": 0.38919657829560733, "train/policy_randomness_std": 0.07449357454714021, "train/post_ent_mag": 29.979931991978695, "train/post_ent_max": 29.979931991978695, "train/post_ent_mean": 20.2072382675974, "train/post_ent_min": 12.456659226668508, "train/post_ent_std": 3.67745855732968, "train/prior_ent_mag": 30.50246391296387, "train/prior_ent_max": 30.50246391296387, "train/prior_ent_mean": 20.139265100579514, "train/prior_ent_min": 13.23086650246068, "train/prior_ent_std": 3.451928921749717, "train/rep_loss_mean": 1.0000188419693394, "train/rep_loss_std": 0.0005642784085418832, "train/reward_avg": 0.00021614145800030152, "train/reward_loss_mean": 0.009409988139707007, "train/reward_loss_std": 0.013925726956834918, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001220434590389854, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009409988166666345, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00021770038262107654, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.709557260076205, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.00020492277690209448, "report/cont_loss_std": 0.0005687140510417521, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00020492277690209448, "report/cont_pred": 0.9997952580451965, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10750670731067657, "report/image_loss_std": 0.11943148076534271, "report/model_loss_mean": 0.7182116508483887, "report/model_loss_std": 0.1222611665725708, "report/post_ent_mag": 30.307146072387695, "report/post_ent_max": 30.307146072387695, "report/post_ent_mean": 21.120176315307617, "report/post_ent_min": 14.022104263305664, "report/post_ent_std": 3.5660290718078613, "report/prior_ent_mag": 31.1070556640625, "report/prior_ent_max": 31.1070556640625, "report/prior_ent_mean": 20.447904586791992, "report/prior_ent_min": 12.463324546813965, "report/prior_ent_std": 3.994802713394165, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002416924835415557, "report/reward_loss_mean": 0.010499963536858559, "report/reward_loss_std": 0.014210793189704418, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0011048316955566406, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010499963536858559, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000219605746679008, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.02175311930477619, "eval/cont_loss_std": 0.4793919026851654, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.855487823486328, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0005520721315406263, "eval/cont_pred": 0.9994786977767944, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.28360554575920105, "eval/image_loss_std": 0.14271873235702515, "eval/model_loss_mean": 0.9068211317062378, "eval/model_loss_std": 0.5034838914871216, "eval/post_ent_mag": 30.071311950683594, "eval/post_ent_max": 30.071311950683594, "eval/post_ent_mean": 20.485429763793945, "eval/post_ent_min": 13.804380416870117, "eval/post_ent_std": 3.2476868629455566, "eval/prior_ent_mag": 29.459022521972656, "eval/prior_ent_max": 29.459022521972656, "eval/prior_ent_mean": 19.775043487548828, "eval/prior_ent_min": 12.740316390991211, "eval/prior_ent_std": 3.642784595489502, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014624805189669132, "eval/reward_loss_std": 0.0013998247450217605, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011484622955322266, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014624805189669132, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023005192633718252, "eval/reward_rate": 0.0, "replay/size": 850161.0, "replay/inserts": 30352.0, "replay/samples": 30352.0, "replay/insert_wait_avg": 1.296660242799589e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.47158899543533e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1051500829259245e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.250458240509, "timer/env.step_count": 3794.0, "timer/env.step_total": 34.50760221481323, "timer/env.step_frac": 0.03449896166557508, "timer/env.step_avg": 0.00909530896542257, "timer/env.step_min": 0.007507801055908203, "timer/env.step_max": 0.049781084060668945, "timer/replay._sample_count": 30352.0, "timer/replay._sample_total": 15.433263063430786, "timer/replay._sample_frac": 0.01542939864339445, "timer/replay._sample_avg": 0.0005084759839032283, "timer/replay._sample_min": 0.0003669261932373047, "timer/replay._sample_max": 0.011577367782592773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5717.0, "timer/agent.policy_total": 58.502296447753906, "timer/agent.policy_frac": 0.058487647734410834, "timer/agent.policy_avg": 0.01023304118379463, "timer/agent.policy_min": 0.008609533309936523, "timer/agent.policy_max": 0.0903167724609375, "timer/dataset_train_count": 1897.0, "timer/dataset_train_total": 0.2064347267150879, "timer/dataset_train_frac": 0.0002063830363829245, "timer/dataset_train_avg": 0.00010882167987089504, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.001085042953491211, "timer/agent.train_count": 1897.0, "timer/agent.train_total": 851.411682844162, "timer/agent.train_frac": 0.8511984931672394, "timer/agent.train_avg": 0.44882007530003265, "timer/agent.train_min": 0.43553709983825684, "timer/agent.train_max": 0.5959134101867676, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4794487953186035, "timer/agent.report_frac": 0.0004793287434848849, "timer/agent.report_avg": 0.23972439765930176, "timer/agent.report_min": 0.2326948642730713, "timer/agent.report_max": 0.24675393104553223, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1463372180569426e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 30.343837585648807}
{"step": 851632, "time": 28243.76553583145, "episode/length": 640.0, "episode/score": 0.14816952585482568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14816952585482568}
{"step": 852464, "time": 28270.600868225098, "episode/length": 640.0, "episode/score": 0.11558807578239794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11558807578239794}
{"step": 853424, "time": 28300.871670484543, "episode/length": 640.0, "episode/score": 0.16617033004496307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16617033004496307}
{"step": 853648, "time": 28308.059543132782, "episode/length": 640.0, "episode/score": 0.2242827013437818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2242827013437818}
{"step": 853752, "time": 28311.109085321426, "episode/length": 640.0, "episode/score": 0.1612102427394575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1612102427394575}
{"step": 854888, "time": 28346.913027524948, "episode/length": 640.0, "episode/score": 0.10811776299885878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10811776299885878}
{"step": 855128, "time": 28354.444485902786, "episode/length": 640.0, "episode/score": 0.21934012820963744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21934012820963744}
{"step": 855544, "time": 28367.65409231186, "episode/length": 640.0, "episode/score": 0.15683460699642637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15683460699642637}
{"step": 856760, "time": 28406.13841366768, "episode/length": 640.0, "episode/score": 0.2224488936024045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2224488936024045}
{"step": 857592, "time": 28432.34024620056, "episode/length": 640.0, "episode/score": 0.09014913243896672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09014913243896672}
{"step": 858552, "time": 28462.625281333923, "episode/length": 640.0, "episode/score": 0.19233874114817695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19233874114817695}
{"step": 858776, "time": 28469.67212152481, "episode/length": 640.0, "episode/score": 0.19120266943451725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19120266943451725}
{"step": 858880, "time": 28473.173625469208, "episode/length": 640.0, "episode/score": 0.24446657815801132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24446657815801132}
{"step": 860016, "time": 28508.99458360672, "episode/length": 640.0, "episode/score": 0.14756775779542863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14756775779542863}
{"step": 860080, "time": 28522.34490466118, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28522.35616493225, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28522.364276647568, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28522.372503757477, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28522.380316734314, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28522.388058423996, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28522.395500421524, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860080, "time": 28522.40296626091, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 860256, "time": 28528.436943292618, "episode/length": 640.0, "episode/score": 0.19135496214138925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19135496214138925}
{"step": 860672, "time": 28541.5243165493, "episode/length": 640.0, "episode/score": 0.234660382522776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.234660382522776}
{"step": 861888, "time": 28580.537029504776, "episode/length": 640.0, "episode/score": 0.12562036729821102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12562036729821102}
{"step": 862720, "time": 28606.65857720375, "episode/length": 640.0, "episode/score": 0.18955270851103023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18955270851103023}
{"step": 863680, "time": 28636.932334423065, "episode/length": 640.0, "episode/score": 0.1083131394549639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1083131394549639}
{"step": 863904, "time": 28643.94700026512, "episode/length": 640.0, "episode/score": 0.10103387249358775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10103387249358775}
{"step": 864008, "time": 28646.995509386063, "episode/length": 640.0, "episode/score": 0.22218128546955995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22218128546955995}
{"step": 865144, "time": 28682.846529722214, "episode/length": 640.0, "episode/score": 0.07934806154324292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07934806154324292}
{"step": 865384, "time": 28690.482670783997, "episode/length": 640.0, "episode/score": 0.2493603063470573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2493603063470573}
{"step": 865800, "time": 28703.890050411224, "episode/length": 640.0, "episode/score": 0.17402530487404988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17402530487404988}
{"step": 867016, "time": 28742.440117120743, "episode/length": 640.0, "episode/score": 0.10799977878994582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10799977878994582}
{"step": 867592, "time": 28760.61634016037, "episode/length": 488.0, "episode/score": 0.22992879914687592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22992879914687592}
{"step": 867848, "time": 28768.65309548378, "episode/length": 640.0, "episode/score": 0.1747885795476236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1747885795476236}
{"step": 869032, "time": 28806.357386112213, "episode/length": 640.0, "episode/score": 0.17437036914878945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17437036914878945}
{"step": 869136, "time": 28809.865663290024, "episode/length": 640.0, "episode/score": 0.13877603617629575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13877603617629575}
{"step": 870064, "time": 28851.29065155983, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28851.299474477768, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28851.30769443512, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28851.31569623947, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28851.32369184494, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28851.33177947998, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28851.340277194977, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870064, "time": 28851.348682641983, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 870184, "time": 28854.867404699326, "episode/length": 130.0, "episode/score": 0.06199309910846296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06199309910846296}
{"step": 870272, "time": 28857.84451365471, "episode/length": 640.0, "episode/score": 0.1886356233345623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1886356233345623}
{"step": 870512, "time": 28865.37376689911, "episode/length": 640.0, "episode/score": 0.10011198825839074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10011198825839074}
{"step": 870928, "time": 28878.555864334106, "episode/length": 640.0, "episode/score": 0.19314913618558194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19314913618558194}
{"step": 872144, "time": 28917.482310771942, "episode/length": 640.0, "episode/score": 0.298151110469405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.298151110469405}
{"step": 872720, "time": 28935.65567088127, "episode/length": 640.0, "episode/score": 0.18257774959278095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18257774959278095}
{"step": 872976, "time": 28943.812645435333, "episode/length": 640.0, "episode/score": 0.06380354328911153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06380354328911153}
{"step": 874160, "time": 28981.431298971176, "episode/length": 640.0, "episode/score": 0.2412402393741786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2412402393741786}
{"step": 875312, "time": 29018.19308066368, "episode/length": 640.0, "episode/score": 0.24992047513416082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24992047513416082}
{"step": 875400, "time": 29020.702939510345, "episode/length": 640.0, "episode/score": 0.21362135112570968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21362135112570968}
{"step": 875640, "time": 29028.376664161682, "episode/length": 640.0, "episode/score": 0.18977186187726147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18977186187726147}
{"step": 876056, "time": 29041.43488407135, "episode/length": 640.0, "episode/score": 0.10577894030507196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10577894030507196}
{"step": 877272, "time": 29080.351389169693, "episode/length": 640.0, "episode/score": 0.16712296747544997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16712296747544997}
{"step": 877848, "time": 29098.468386411667, "episode/length": 640.0, "episode/score": 0.09240891307547372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09240891307547372}
{"step": 878104, "time": 29106.489387750626, "episode/length": 640.0, "episode/score": 0.22002758650432952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22002758650432952}
{"step": 879288, "time": 29143.729840040207, "episode/length": 640.0, "episode/score": 0.20734785310548887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20734785310548887}
{"step": 879880, "time": 29162.507682561874, "episode/length": 570.0, "episode/score": 0.08548829636350774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08548829636350774}
{"step": 880048, "time": 29179.604134082794, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 29179.624798297882, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 29179.63259792328, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 29179.641503334045, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 29179.649878263474, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 29179.65782046318, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 29179.66578722, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880048, "time": 29179.67394065857, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 880528, "time": 29194.7443048954, "episode/length": 640.0, "episode/score": 0.07526387216142894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07526387216142894}
{"step": 880768, "time": 29202.279948472977, "episode/length": 640.0, "episode/score": 0.13034890979304237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13034890979304237}
{"step": 881097, "time": 29213.464200496674, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2641209652549343, "train/action_min": 0.0, "train/action_std": 1.8945050609739202, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007555890822243925, "train/actor_opt_grad_steps": 54025.0, "train/actor_opt_loss": -6.300213219303834, "train/adv_mag": 0.07261898066652449, "train/adv_max": 0.005027571791096737, "train/adv_mean": 6.933150235143234e-06, "train/adv_min": -0.07246054371720866, "train/adv_std": 0.0022075424203649163, "train/cont_avg": 0.9984220805921052, "train/cont_loss_mean": 0.0031113789446719333, "train/cont_loss_std": 0.08268225411133914, "train/cont_neg_acc": 0.705274264080615, "train/cont_neg_loss": 1.7773603844800878, "train/cont_pos_acc": 0.9999587887211849, "train/cont_pos_loss": 0.00048502146153049056, "train/cont_pred": 0.9984653974834241, "train/cont_rate": 0.9984220805921052, "train/dyn_loss_mean": 1.0000071155397516, "train/dyn_loss_std": 0.00021156152336181165, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03006588750040943, "train/extr_critic_critic_opt_grad_steps": 54025.0, "train/extr_critic_critic_opt_loss": 13523.17550884046, "train/extr_critic_mag": 0.08775138478530081, "train/extr_critic_max": 0.08775138478530081, "train/extr_critic_mean": 0.08407262932313116, "train/extr_critic_min": 0.0786182121226662, "train/extr_critic_std": 0.0014083841533743238, "train/extr_return_normed_mag": 0.07043043739701572, "train/extr_return_normed_max": 0.009166470366088968, "train/extr_return_normed_mean": 0.0029040431027839843, "train/extr_return_normed_min": -0.06960959638419904, "train/extr_return_normed_std": 0.0026680088546862336, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0903419127589778, "train/extr_return_raw_max": 0.0903419127589778, "train/extr_return_raw_mean": 0.08407948966089047, "train/extr_return_raw_min": 0.01156584600868978, "train/extr_return_raw_std": 0.002668008839368428, "train/extr_reward_mag": 0.00125484215585809, "train/extr_reward_max": 0.00125484215585809, "train/extr_reward_mean": 0.0002564128524299074, "train/extr_reward_min": 2.762518431010999e-06, "train/extr_reward_std": 0.0002719531147465061, "train/image_loss_mean": 0.10752492896036098, "train/image_loss_std": 0.12149116557679679, "train/model_loss_mean": 0.7200554828894766, "train/model_loss_std": 0.1721580603405049, "train/model_opt_grad_norm": 18.848692888962596, "train/model_opt_grad_steps": 53978.71578947368, "train/model_opt_loss": 3656.483214689556, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5078.9473684210525, "train/policy_entropy_mag": 1.9405582289946706, "train/policy_entropy_max": 1.9405582289946706, "train/policy_entropy_mean": 1.7056941283376594, "train/policy_entropy_min": 0.7753269499854037, "train/policy_entropy_std": 0.14377272858431464, "train/policy_logprob_mag": 4.313458063727931, "train/policy_logprob_max": -0.20242543879308197, "train/policy_logprob_mean": -1.7053684724004645, "train/policy_logprob_min": -4.313458063727931, "train/policy_logprob_std": 0.6838636705749913, "train/policy_randomness_mag": 0.9972497158928921, "train/policy_randomness_max": 0.9972497158928921, "train/policy_randomness_mean": 0.8765534369569076, "train/policy_randomness_min": 0.39843925818016657, "train/policy_randomness_std": 0.07388457138287394, "train/post_ent_mag": 31.788910946093107, "train/post_ent_max": 31.788910946093107, "train/post_ent_mean": 20.81833587445711, "train/post_ent_min": 11.787846590343275, "train/post_ent_std": 4.146283048077634, "train/prior_ent_mag": 31.498801070765445, "train/prior_ent_max": 31.498801070765445, "train/prior_ent_mean": 20.69990357850727, "train/prior_ent_min": 12.651197860115452, "train/prior_ent_std": 3.9723432616183634, "train/rep_loss_mean": 1.0000071155397516, "train/rep_loss_std": 0.00021156152336181165, "train/reward_avg": 0.00021616834833127396, "train/reward_loss_mean": 0.009414878664048094, "train/reward_loss_std": 0.013900366160822542, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012225703189247532, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00941487867385149, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00021674997283537922, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.7097236961126328, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0085934242233634, "report/cont_loss_std": 0.2694009244441986, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 4.3128662109375, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00017019249207805842, "report/cont_pred": 0.9988542199134827, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09167774766683578, "report/image_loss_std": 0.11065798997879028, "report/model_loss_mean": 0.7083737850189209, "report/model_loss_std": 0.29611295461654663, "report/post_ent_mag": 29.297677993774414, "report/post_ent_max": 29.297677993774414, "report/post_ent_mean": 18.928913116455078, "report/post_ent_min": 9.985153198242188, "report/post_ent_std": 4.181795597076416, "report/prior_ent_mag": 29.93070411682129, "report/prior_ent_max": 29.93070411682129, "report/prior_ent_mean": 18.87017822265625, "report/prior_ent_min": 11.578384399414062, "report/prior_ent_std": 3.8787953853607178, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018465257016941905, "report/reward_loss_mean": 0.008102582767605782, "report/reward_loss_std": 0.013030526228249073, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001210331916809082, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008102582767605782, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00021324411500245333, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.00020700052846223116, "eval/cont_loss_std": 0.0005599367432296276, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00020700052846223116, "eval/cont_pred": 0.9997931718826294, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3111719489097595, "eval/image_loss_std": 0.16376060247421265, "eval/model_loss_mean": 0.9128683805465698, "eval/model_loss_std": 0.16393272578716278, "eval/post_ent_mag": 30.27381134033203, "eval/post_ent_max": 30.27381134033203, "eval/post_ent_mean": 17.908950805664062, "eval/post_ent_min": 10.05693531036377, "eval/post_ent_std": 3.992094039916992, "eval/prior_ent_mag": 30.640106201171875, "eval/prior_ent_max": 30.640106201171875, "eval/prior_ent_mean": 18.222393035888672, "eval/prior_ent_min": 11.985849380493164, "eval/prior_ent_std": 3.7591938972473145, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014894339255988598, "eval/reward_loss_std": 0.0015353757189586759, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001194000244140625, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014894339255988598, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023426010739058256, "eval/reward_rate": 0.0, "replay/size": 880593.0, "replay/inserts": 30432.0, "replay/samples": 30432.0, "replay/insert_wait_avg": 1.2911519292275863e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.518497149149576e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0610587635327923e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.263973236084, "timer/env.step_count": 3804.0, "timer/env.step_total": 34.35260224342346, "timer/env.step_frac": 0.03434353646896318, "timer/env.step_avg": 0.009030652535074516, "timer/env.step_min": 0.00731968879699707, "timer/env.step_max": 0.03586459159851074, "timer/replay._sample_count": 30432.0, "timer/replay._sample_total": 15.359514951705933, "timer/replay._sample_frac": 0.015355461520836715, "timer/replay._sample_avg": 0.0005047159224403895, "timer/replay._sample_min": 0.00037217140197753906, "timer/replay._sample_max": 0.00806117057800293, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5727.0, "timer/agent.policy_total": 57.93799328804016, "timer/agent.policy_frac": 0.05792270324462195, "timer/agent.policy_avg": 0.010116639302957947, "timer/agent.policy_min": 0.008852481842041016, "timer/agent.policy_max": 0.18063926696777344, "timer/dataset_train_count": 1902.0, "timer/dataset_train_total": 0.20974397659301758, "timer/dataset_train_frac": 0.00020968862440826254, "timer/dataset_train_avg": 0.00011027548716772743, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0003962516784667969, "timer/agent.train_count": 1902.0, "timer/agent.train_total": 852.2095670700073, "timer/agent.train_frac": 0.8519846659206504, "timer/agent.train_avg": 0.44805970929022465, "timer/agent.train_min": 0.4362196922302246, "timer/agent.train_max": 0.6029088497161865, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4832935333251953, "timer/agent.report_frac": 0.00048316599043513443, "timer/agent.report_avg": 0.24164676666259766, "timer/agent.report_min": 0.23598527908325195, "timer/agent.report_max": 0.24730825424194336, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.4799926299667316e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 30.423436517642532}
{"step": 881184, "time": 29216.1802983284, "episode/length": 640.0, "episode/score": 0.15337361895632284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15337361895632284}
{"step": 882400, "time": 29254.9079413414, "episode/length": 640.0, "episode/score": 0.17335564751289212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17335564751289212}
{"step": 882976, "time": 29273.49243068695, "episode/length": 640.0, "episode/score": 0.08372473396423175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08372473396423175}
{"step": 883232, "time": 29281.691706180573, "episode/length": 640.0, "episode/score": 0.07660795418945554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07660795418945554}
{"step": 884416, "time": 29319.159695625305, "episode/length": 640.0, "episode/score": 0.24284236582332142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24284236582332142}
{"step": 885008, "time": 29338.353128910065, "episode/length": 640.0, "episode/score": 0.12569126453377066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12569126453377066}
{"step": 885656, "time": 29358.52642941475, "episode/length": 640.0, "episode/score": 0.2351754086340634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2351754086340634}
{"step": 885896, "time": 29366.06512737274, "episode/length": 640.0, "episode/score": 0.17576991096893835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17576991096893835}
{"step": 886312, "time": 29379.09086704254, "episode/length": 640.0, "episode/score": 0.1581800054470932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1581800054470932}
{"step": 887528, "time": 29417.333218812943, "episode/length": 640.0, "episode/score": 0.09098452919801048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09098452919801048}
{"step": 888104, "time": 29435.421003818512, "episode/length": 640.0, "episode/score": 0.18182330663245239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18182330663245239}
{"step": 888360, "time": 29443.459515571594, "episode/length": 640.0, "episode/score": 0.23299531638326698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23299531638326698}
{"step": 889544, "time": 29480.91240620613, "episode/length": 640.0, "episode/score": 0.2086932145710989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2086932145710989}
{"step": 890032, "time": 29508.53807091713, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29508.54713821411, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29508.555454730988, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29508.563493967056, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29508.57134604454, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29508.579223155975, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29508.586728811264, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890032, "time": 29508.594403743744, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 890136, "time": 29511.65341234207, "episode/length": 640.0, "episode/score": 0.08335394896460002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08335394896460002}
{"step": 890784, "time": 29532.483862638474, "episode/length": 640.0, "episode/score": 0.05382085811481829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05382085811481829}
{"step": 891024, "time": 29540.248022317886, "episode/length": 640.0, "episode/score": 0.21534751030583266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21534751030583266}
{"step": 891440, "time": 29553.495710611343, "episode/length": 640.0, "episode/score": 0.20535081257423826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20535081257423826}
{"step": 892656, "time": 29592.190725326538, "episode/length": 640.0, "episode/score": 0.17251726520049715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17251726520049715}
{"step": 893232, "time": 29611.142763137817, "episode/length": 640.0, "episode/score": 0.12264448293774421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12264448293774421}
{"step": 893488, "time": 29619.182853460312, "episode/length": 640.0, "episode/score": 0.1451625467402664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1451625467402664}
{"step": 894672, "time": 29656.613040208817, "episode/length": 640.0, "episode/score": 0.1224856823924938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1224856823924938}
{"step": 895264, "time": 29675.42961716652, "episode/length": 640.0, "episode/score": 0.22758971602047495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22758971602047495}
{"step": 895912, "time": 29695.687650203705, "episode/length": 640.0, "episode/score": 0.21251152868404688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21251152868404688}
{"step": 896152, "time": 29703.25071835518, "episode/length": 640.0, "episode/score": 0.0985687555930781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0985687555930781}
{"step": 896568, "time": 29716.40085721016, "episode/length": 640.0, "episode/score": 0.1974216647886351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1974216647886351}
{"step": 897784, "time": 29754.756345033646, "episode/length": 640.0, "episode/score": 0.15530530713016333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15530530713016333}
{"step": 898360, "time": 29773.077451467514, "episode/length": 640.0, "episode/score": 0.1936963836641894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1936963836641894}
{"step": 898616, "time": 29781.186371803284, "episode/length": 640.0, "episode/score": 0.10592214859536853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10592214859536853}
{"step": 899800, "time": 29818.66778445244, "episode/length": 640.0, "episode/score": 0.22848958721408508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22848958721408508}
{"step": 900016, "time": 29838.209171295166, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29838.218359470367, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29838.226768016815, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29838.234965324402, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29838.242856264114, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29838.25137925148, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29838.259352207184, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900016, "time": 29838.267152547836, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 900392, "time": 29850.038086414337, "episode/length": 640.0, "episode/score": 0.2143471833482522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2143471833482522}
{"step": 901040, "time": 29870.755685806274, "episode/length": 640.0, "episode/score": 0.22116739057196355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22116739057196355}
{"step": 901280, "time": 29878.786109924316, "episode/length": 640.0, "episode/score": 0.26279320391677174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26279320391677174}
{"step": 901696, "time": 29891.858481407166, "episode/length": 640.0, "episode/score": 0.2308092176538139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2308092176538139}
{"step": 902912, "time": 29930.177884817123, "episode/length": 640.0, "episode/score": 0.19860011746686723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19860011746686723}
{"step": 903488, "time": 29948.262609243393, "episode/length": 640.0, "episode/score": 0.18774711361658092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18774711361658092}
{"step": 903744, "time": 29956.389928340912, "episode/length": 640.0, "episode/score": 0.1742244028010873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1742244028010873}
{"step": 904928, "time": 29993.807721138, "episode/length": 640.0, "episode/score": 0.23998387487324635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23998387487324635}
{"step": 905520, "time": 30012.70139336586, "episode/length": 640.0, "episode/score": 0.16862210716232084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16862210716232084}
{"step": 906168, "time": 30033.146889209747, "episode/length": 640.0, "episode/score": 0.1615418509275628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1615418509275628}
{"step": 906408, "time": 30040.696181297302, "episode/length": 640.0, "episode/score": 0.10017570282400357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10017570282400357}
{"step": 906824, "time": 30053.93468093872, "episode/length": 640.0, "episode/score": 0.15769048621086768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15769048621086768}
{"step": 908040, "time": 30092.448248147964, "episode/length": 640.0, "episode/score": 0.19236081976555397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19236081976555397}
{"step": 908616, "time": 30110.5975151062, "episode/length": 640.0, "episode/score": 0.15974505575599096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15974505575599096}
{"step": 908872, "time": 30118.599994421005, "episode/length": 640.0, "episode/score": 0.13053272714176956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13053272714176956}
{"step": 910000, "time": 30166.26185297966, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 30166.270620584488, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 30166.27851343155, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 30166.286831378937, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 30166.294614076614, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 30166.30240726471, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 30166.31014084816, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910000, "time": 30166.318105459213, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 910056, "time": 30167.885075330734, "episode/length": 640.0, "episode/score": 0.10692553705740693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10692553705740693}
{"step": 910648, "time": 30186.81629395485, "episode/length": 640.0, "episode/score": 0.0842972342756525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0842972342756525}
{"step": 911296, "time": 30207.598814487457, "episode/length": 640.0, "episode/score": 0.1374632276817067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1374632276817067}
{"step": 911465, "time": 30213.76527428627, "train_stats/mean_log_entropy": 1.701668046890421, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2166176243832236, "train/action_min": 0.0, "train/action_std": 1.8744039347297268, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007619474265467081, "train/actor_opt_grad_steps": 55925.0, "train/actor_opt_loss": -5.753076891581479, "train/adv_mag": 0.07470163714728857, "train/adv_max": 0.005258088362844367, "train/adv_mean": 4.3336507938145015e-05, "train/adv_min": -0.074506337274062, "train/adv_std": 0.0021864587658599606, "train/cont_avg": 0.998303865131579, "train/cont_loss_mean": 0.002982254195491183, "train/cont_loss_std": 0.07633134563312571, "train/cont_neg_acc": 0.7281250016763806, "train/cont_neg_loss": 1.5041783917481553, "train/cont_pos_acc": 0.9999742614595514, "train/cont_pos_loss": 0.0004552262324738733, "train/cont_pred": 0.9983524758564798, "train/cont_rate": 0.998303865131579, "train/dyn_loss_mean": 1.0000056185220416, "train/dyn_loss_std": 0.0001608846346100204, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03092312727730084, "train/extr_critic_critic_opt_grad_steps": 55925.0, "train/extr_critic_critic_opt_loss": 13519.026927425986, "train/extr_critic_mag": 0.08842241701326872, "train/extr_critic_max": 0.08842241701326872, "train/extr_critic_mean": 0.08461117426815785, "train/extr_critic_min": 0.07882249669024818, "train/extr_critic_std": 0.001488396075652226, "train/extr_return_normed_mag": 0.07233337485476544, "train/extr_return_normed_max": 0.009703220740744941, "train/extr_return_normed_mean": 0.0031704267768777514, "train/extr_return_normed_min": -0.0714462933963851, "train/extr_return_normed_std": 0.0026891016591291286, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09118724453606103, "train/extr_return_raw_max": 0.09118724453606103, "train/extr_return_raw_mean": 0.0846544548869133, "train/extr_return_raw_min": 0.010037730398931001, "train/extr_return_raw_std": 0.0026891016560655675, "train/extr_reward_mag": 0.0012606865481326454, "train/extr_reward_max": 0.0012606865481326454, "train/extr_reward_mean": 0.00026351453040996076, "train/extr_reward_min": 2.807692477577611e-06, "train/extr_reward_std": 0.0002752025410269485, "train/image_loss_mean": 0.10801596300382363, "train/image_loss_std": 0.12282770456452119, "train/model_loss_mean": 0.7206599746879778, "train/model_loss_std": 0.16977713257074356, "train/model_opt_grad_norm": 17.77844608206498, "train/model_opt_grad_steps": 55876.86842105263, "train/model_opt_loss": 3678.818134508635, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5105.263157894737, "train/policy_entropy_mag": 1.940513224978196, "train/policy_entropy_max": 1.940513224978196, "train/policy_entropy_mean": 1.6945455664082578, "train/policy_entropy_min": 0.7428006260018599, "train/policy_entropy_std": 0.1486902763184748, "train/policy_logprob_mag": 4.316856558699357, "train/policy_logprob_max": -0.19296362733370379, "train/policy_logprob_mean": -1.6948626311201798, "train/policy_logprob_min": -4.316856558699357, "train/policy_logprob_std": 0.6975086168238991, "train/policy_randomness_mag": 0.9972265874084674, "train/policy_randomness_max": 0.9972265874084674, "train/policy_randomness_mean": 0.8708242102673179, "train/policy_randomness_min": 0.38172403244595776, "train/policy_randomness_std": 0.07641169087667214, "train/post_ent_mag": 33.494996201364614, "train/post_ent_max": 33.494996201364614, "train/post_ent_mean": 21.901668438158538, "train/post_ent_min": 11.98312289087396, "train/post_ent_std": 4.512153117280257, "train/prior_ent_mag": 33.77117221229955, "train/prior_ent_max": 33.77117221229955, "train/prior_ent_mean": 21.74371259588944, "train/prior_ent_min": 12.860309108934905, "train/prior_ent_std": 4.444891988603692, "train/rep_loss_mean": 1.0000056185220416, "train/rep_loss_std": 0.0001608846346100204, "train/reward_avg": 0.00022239559146232512, "train/reward_loss_mean": 0.009658360464106265, "train/reward_loss_std": 0.014074738108013806, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001230738037510922, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00965836047145881, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022311118970576085, "train/reward_rate": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0005279786419123411, "report/cont_loss_std": 0.004153957590460777, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.006851842161267996, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0004969488945789635, "report/cont_pred": 0.9946638345718384, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08445931226015091, "report/image_loss_std": 0.10567523539066315, "report/model_loss_mean": 0.6926826238632202, "report/model_loss_std": 0.10868509113788605, "report/post_ent_mag": 31.016992568969727, "report/post_ent_max": 31.016992568969727, "report/post_ent_mean": 21.88401222229004, "report/post_ent_min": 13.420719146728516, "report/post_ent_std": 3.602292776107788, "report/prior_ent_mag": 32.991844177246094, "report/prior_ent_max": 32.991844177246094, "report/prior_ent_mean": 21.522729873657227, "report/prior_ent_min": 13.628911972045898, "report/prior_ent_std": 4.28364372253418, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00017336857854388654, "report/reward_loss_mean": 0.007695271633565426, "report/reward_loss_std": 0.012110881507396698, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001175522804260254, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007695272099226713, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00018511491362005472, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02987782657146454, "eval/cont_loss_std": 0.54243004322052, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.000066757202148, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0005824617110192776, "eval/cont_pred": 0.9994295239448547, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2704966962337494, "eval/image_loss_std": 0.14377140998840332, "eval/model_loss_mean": 0.9016886949539185, "eval/model_loss_std": 0.5638078451156616, "eval/post_ent_mag": 30.905431747436523, "eval/post_ent_max": 30.905431747436523, "eval/post_ent_mean": 20.477279663085938, "eval/post_ent_min": 13.164074897766113, "eval/post_ent_std": 3.6053895950317383, "eval/prior_ent_mag": 33.76201629638672, "eval/prior_ent_max": 33.76201629638672, "eval/prior_ent_mean": 19.952739715576172, "eval/prior_ent_min": 13.349079132080078, "eval/prior_ent_std": 4.085453510284424, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013141189701855183, "eval/reward_loss_std": 0.0013820588355883956, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011080503463745117, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013141189701855183, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00020671728998422623, "eval/reward_rate": 0.0, "replay/size": 910961.0, "replay/inserts": 30368.0, "replay/samples": 30368.0, "replay/insert_wait_avg": 1.3052019731262336e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.439961173134935e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.105227572063698e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2799456119537, "timer/env.step_count": 3796.0, "timer/env.step_total": 34.43436002731323, "timer/env.step_frac": 0.03442472297717305, "timer/env.step_avg": 0.009071222346499798, "timer/env.step_min": 0.00730133056640625, "timer/env.step_max": 0.03547334671020508, "timer/replay._sample_count": 30368.0, "timer/replay._sample_total": 15.352003335952759, "timer/replay._sample_frac": 0.01534770681277697, "timer/replay._sample_avg": 0.0005055322489447036, "timer/replay._sample_min": 0.0003867149353027344, "timer/replay._sample_max": 0.01122283935546875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5719.0, "timer/agent.policy_total": 58.86326599121094, "timer/agent.policy_frac": 0.05884679208998779, "timer/agent.policy_avg": 0.01029258016982181, "timer/agent.policy_min": 0.008829355239868164, "timer/agent.policy_max": 0.08854198455810547, "timer/dataset_train_count": 1898.0, "timer/dataset_train_total": 0.2127394676208496, "timer/dataset_train_frac": 0.00021267992880802917, "timer/dataset_train_avg": 0.00011208612624913046, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.00032591819763183594, "timer/agent.train_count": 1898.0, "timer/agent.train_total": 850.7280156612396, "timer/agent.train_frac": 0.8504899247387981, "timer/agent.train_avg": 0.44822340129675425, "timer/agent.train_min": 0.4373137950897217, "timer/agent.train_max": 0.6242415904998779, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4816112518310547, "timer/agent.report_frac": 0.0004814764646075288, "timer/agent.report_avg": 0.24080562591552734, "timer/agent.report_min": 0.23483848571777344, "timer/agent.report_max": 0.24677276611328125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.193914837517221e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 30.35887368670759}
{"step": 911536, "time": 30216.05144715309, "episode/length": 640.0, "episode/score": 0.20125530686536308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20125530686536308}
{"step": 911952, "time": 30229.473451137543, "episode/length": 640.0, "episode/score": 0.20340277475483504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20340277475483504}
{"step": 913168, "time": 30268.06969189644, "episode/length": 640.0, "episode/score": 0.24482357217883077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24482357217883077}
{"step": 913744, "time": 30286.176814317703, "episode/length": 640.0, "episode/score": 0.2259540040357706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2259540040357706}
{"step": 914000, "time": 30294.220515727997, "episode/length": 640.0, "episode/score": 0.22746522614076525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22746522614076525}
{"step": 915184, "time": 30331.698895692825, "episode/length": 640.0, "episode/score": 0.2518730442024264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2518730442024264}
{"step": 915776, "time": 30350.354063510895, "episode/length": 640.0, "episode/score": 0.2588760794706104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2588760794706104}
{"step": 916424, "time": 30370.507718086243, "episode/length": 640.0, "episode/score": 0.1818617903285542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1818617903285542}
{"step": 916664, "time": 30378.245124816895, "episode/length": 640.0, "episode/score": 0.2944649549216649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2944649549216649}
{"step": 917080, "time": 30391.559105157852, "episode/length": 640.0, "episode/score": 0.18700882052641532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18700882052641532}
{"step": 918296, "time": 30430.70804142952, "episode/length": 640.0, "episode/score": 0.16645465338362442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16645465338362442}
{"step": 918872, "time": 30448.898232221603, "episode/length": 640.0, "episode/score": 0.22320968734612734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22320968734612734}
{"step": 919128, "time": 30456.946420431137, "episode/length": 640.0, "episode/score": 0.17583484224667245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17583484224667245}
{"step": 920088, "time": 30499.49861931801, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30499.507663726807, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30499.515853881836, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30499.5241587162, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30499.531937360764, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30499.539742469788, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30499.54780483246, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920088, "time": 30499.555392742157, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 920312, "time": 30506.631229400635, "episode/length": 640.0, "episode/score": 0.21576240274077918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21576240274077918}
{"step": 920904, "time": 30525.176541805267, "episode/length": 640.0, "episode/score": 0.1970889805443221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1970889805443221}
{"step": 921552, "time": 30546.23348259926, "episode/length": 640.0, "episode/score": 0.19632256993361352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19632256993361352}
{"step": 921792, "time": 30553.911515951157, "episode/length": 640.0, "episode/score": 0.0784759904161092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0784759904161092}
{"step": 922208, "time": 30567.067487239838, "episode/length": 640.0, "episode/score": 0.10237714758179095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10237714758179095}
{"step": 923424, "time": 30605.318066358566, "episode/length": 640.0, "episode/score": 0.17940206262602487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17940206262602487}
{"step": 924000, "time": 30623.506916999817, "episode/length": 640.0, "episode/score": 0.1912000316839908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1912000316839908}
{"step": 924256, "time": 30631.538216114044, "episode/length": 640.0, "episode/score": 0.13537298782368623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13537298782368623}
{"step": 925440, "time": 30668.985934495926, "episode/length": 640.0, "episode/score": 0.17780567669164782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17780567669164782}
{"step": 926032, "time": 30688.15915799141, "episode/length": 640.0, "episode/score": 0.09900063104484502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09900063104484502}
{"step": 926680, "time": 30708.402529239655, "episode/length": 640.0, "episode/score": 0.09189825382202343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09189825382202343}
{"step": 926920, "time": 30715.96440887451, "episode/length": 640.0, "episode/score": 0.18173071588576306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18173071588576306}
{"step": 927336, "time": 30729.014580011368, "episode/length": 640.0, "episode/score": 0.16508789582344718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16508789582344718}
{"step": 928552, "time": 30767.381169319153, "episode/length": 640.0, "episode/score": 0.11908543542604377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11908543542604377}
{"step": 929128, "time": 30785.452432870865, "episode/length": 640.0, "episode/score": 0.23459663235769312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23459663235769312}
{"step": 929384, "time": 30793.473393917084, "episode/length": 640.0, "episode/score": 0.19216658157708366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19216658157708366}
{"step": 930072, "time": 30827.158291101456, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30827.167439460754, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30827.17592048645, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30827.184086084366, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30827.19183588028, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30827.199506759644, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30827.20752644539, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930072, "time": 30827.21513080597, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 930568, "time": 30842.82281923294, "episode/length": 640.0, "episode/score": 0.1755115694460727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1755115694460727}
{"step": 931160, "time": 30861.549317359924, "episode/length": 640.0, "episode/score": 0.12732421775841374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12732421775841374}
{"step": 931808, "time": 30882.16498732567, "episode/length": 640.0, "episode/score": 0.14132482985849038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14132482985849038}
{"step": 932048, "time": 30889.8386759758, "episode/length": 640.0, "episode/score": 0.1845633436261238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1845633436261238}
{"step": 932464, "time": 30902.881131887436, "episode/length": 640.0, "episode/score": 0.1816485871935356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1816485871935356}
{"step": 933680, "time": 30941.680804491043, "episode/length": 640.0, "episode/score": 0.09752415265764114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09752415265764114}
{"step": 934256, "time": 30960.71416258812, "episode/length": 640.0, "episode/score": 0.09618228237224002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09618228237224002}
{"step": 934512, "time": 30968.918145418167, "episode/length": 640.0, "episode/score": 0.19750330376965053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19750330376965053}
{"step": 935696, "time": 31006.909611940384, "episode/length": 640.0, "episode/score": 0.2273088810336361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2273088810336361}
{"step": 936288, "time": 31025.802346229553, "episode/length": 640.0, "episode/score": 0.18880015424049645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18880015424049645}
{"step": 936936, "time": 31046.37896132469, "episode/length": 640.0, "episode/score": 0.2642895751509968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2642895751509968}
{"step": 937176, "time": 31054.02719116211, "episode/length": 640.0, "episode/score": 0.1281772832030441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1281772832030441}
{"step": 937592, "time": 31067.435161590576, "episode/length": 640.0, "episode/score": 0.11589002490595135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11589002490595135}
{"step": 938808, "time": 31106.20182609558, "episode/length": 640.0, "episode/score": 0.31378663532133544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31378663532133544}
{"step": 939384, "time": 31124.34602880478, "episode/length": 640.0, "episode/score": 0.09683254928972929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09683254928972929}
{"step": 939640, "time": 31132.566030979156, "episode/length": 640.0, "episode/score": 0.3039782361684047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3039782361684047}
{"step": 940056, "time": 31157.4017701149, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 31157.410700798035, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 31157.41896891594, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 31157.426845788956, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 31157.434501171112, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 31157.442237615585, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 31157.45020723343, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940056, "time": 31157.458108901978, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 940824, "time": 31181.57064652443, "episode/length": 640.0, "episode/score": 0.11773905523773465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11773905523773465}
{"step": 941416, "time": 31200.283019065857, "episode/length": 640.0, "episode/score": 0.23397959578676364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23397959578676364}
{"step": 941817, "time": 31214.032024145126, "train_stats/mean_log_entropy": 1.6604123774995194, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1725260416666665, "train/action_min": 0.0, "train/action_std": 1.8337988828225111, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007650229895719027, "train/actor_opt_grad_steps": 57820.0, "train/actor_opt_loss": -5.632258735912502, "train/adv_mag": 0.0710244434614661, "train/adv_max": 0.0052273911300790375, "train/adv_mean": 5.2831296986947184e-05, "train/adv_min": -0.07069569652673428, "train/adv_std": 0.002130163769747707, "train/cont_avg": 0.9985429067460317, "train/cont_loss_mean": 0.002697246317953739, "train/cont_loss_std": 0.06728858951697553, "train/cont_neg_acc": 0.7634009030219671, "train/cont_neg_loss": 1.4570686034412084, "train/cont_pos_acc": 0.9999327101404705, "train/cont_pos_loss": 0.0004981983210195457, "train/cont_pred": 0.998514728571372, "train/cont_rate": 0.9985429067460317, "train/dyn_loss_mean": 1.0000061030110354, "train/dyn_loss_std": 0.00016746953161797984, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.028869201616130317, "train/extr_critic_critic_opt_grad_steps": 57820.0, "train/extr_critic_critic_opt_loss": 13498.967587425595, "train/extr_critic_mag": 0.09065010055663093, "train/extr_critic_max": 0.09065010055663093, "train/extr_critic_mean": 0.08688575723183849, "train/extr_critic_min": 0.08130038604534492, "train/extr_critic_std": 0.0014600672564474206, "train/extr_return_normed_mag": 0.06920146370533282, "train/extr_return_normed_max": 0.00958643211101098, "train/extr_return_normed_mean": 0.0031131131564656263, "train/extr_return_normed_min": -0.06785752360152189, "train/extr_return_normed_std": 0.002632107885638203, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09341193018136201, "train/extr_return_raw_max": 0.09341193018136201, "train/extr_return_raw_mean": 0.08693861551385708, "train/extr_return_raw_min": 0.01596797446882914, "train/extr_return_raw_std": 0.00263210788071057, "train/extr_reward_mag": 0.001267694291614351, "train/extr_reward_max": 0.001267694291614351, "train/extr_reward_mean": 0.0002682683529749897, "train/extr_reward_min": 2.647833849387194e-06, "train/extr_reward_std": 0.0002757582972725489, "train/image_loss_mean": 0.106394248349326, "train/image_loss_std": 0.12176295409284571, "train/model_loss_mean": 0.7188160075712456, "train/model_loss_std": 0.16430472507678642, "train/model_opt_grad_norm": 17.457587706348882, "train/model_opt_grad_steps": 57770.04761904762, "train/model_opt_loss": 3707.6878229373347, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5158.730158730159, "train/policy_entropy_mag": 1.9401281050273351, "train/policy_entropy_max": 1.9401281050273351, "train/policy_entropy_mean": 1.6718903994434093, "train/policy_entropy_min": 0.6705803481674699, "train/policy_entropy_std": 0.1616094840109033, "train/policy_logprob_mag": 4.3897095130234165, "train/policy_logprob_max": -0.16656937505360003, "train/policy_logprob_mean": -1.671518260209018, "train/policy_logprob_min": -4.3897095130234165, "train/policy_logprob_std": 0.7245491796700412, "train/policy_randomness_mag": 0.9970286759749922, "train/policy_randomness_max": 0.9970286759749922, "train/policy_randomness_mean": 0.8591817510191095, "train/policy_randomness_min": 0.34461015005591056, "train/policy_randomness_std": 0.08305085115331821, "train/post_ent_mag": 35.260221380405326, "train/post_ent_max": 35.260221380405326, "train/post_ent_mean": 23.288694371622075, "train/post_ent_min": 12.776123112471646, "train/post_ent_std": 4.620152338471993, "train/prior_ent_mag": 35.712904612223305, "train/prior_ent_max": 35.712904612223305, "train/prior_ent_mean": 23.24761993166, "train/prior_ent_min": 13.961705162411643, "train/prior_ent_std": 4.612629384590835, "train/rep_loss_mean": 1.0000061030110354, "train/rep_loss_std": 0.00016746953161797984, "train/reward_avg": 0.00022407841810798913, "train/reward_loss_mean": 0.0097208269970324, "train/reward_loss_std": 0.014088831846873281, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00123369504535009, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009720826972394235, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022260579908828414, "train/reward_rate": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.000310676172375679, "report/cont_loss_std": 0.003750124480575323, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0016189253656193614, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00030811596661806107, "report/cont_pred": 0.9977493286132812, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10471484810113907, "report/image_loss_std": 0.1232399269938469, "report/model_loss_mean": 0.7152469158172607, "report/model_loss_std": 0.12827150523662567, "report/post_ent_mag": 37.9945182800293, "report/post_ent_max": 37.9945182800293, "report/post_ent_mean": 25.320072174072266, "report/post_ent_min": 14.089374542236328, "report/post_ent_std": 4.940820693969727, "report/prior_ent_mag": 36.41050720214844, "report/prior_ent_max": 36.41050720214844, "report/prior_ent_mean": 25.023576736450195, "report/prior_ent_min": 15.84437370300293, "report/prior_ent_std": 4.381400108337402, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00023637613048776984, "report/reward_loss_mean": 0.010221368633210659, "report/reward_loss_std": 0.014750043861567974, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012865066528320312, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010221367701888084, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00025791802909225225, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.001130308024585247, "eval/cont_loss_std": 0.01876707933843136, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001130308024585247, "eval/cont_pred": 0.9990212917327881, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.3029327988624573, "eval/image_loss_std": 0.15624064207077026, "eval/model_loss_mean": 0.9057481288909912, "eval/model_loss_std": 0.15684998035430908, "eval/post_ent_mag": 36.73853302001953, "eval/post_ent_max": 36.73853302001953, "eval/post_ent_mean": 24.087596893310547, "eval/post_ent_min": 14.162124633789062, "eval/post_ent_std": 4.590569972991943, "eval/prior_ent_mag": 37.68018341064453, "eval/prior_ent_max": 37.68018341064453, "eval/prior_ent_mean": 23.813051223754883, "eval/prior_ent_min": 16.24718475341797, "eval/prior_ent_std": 4.09015417098999, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0016850344836711884, "eval/reward_loss_std": 0.0016338638961315155, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011265277862548828, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0016850344836711884, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00026499724481254816, "eval/reward_rate": 0.0, "replay/size": 941313.0, "replay/inserts": 30352.0, "replay/samples": 30352.0, "replay/insert_wait_avg": 1.307586713659179e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.436947919597234e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0696135643429888e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2468495368958, "timer/env.step_count": 3794.0, "timer/env.step_total": 34.57693839073181, "timer/env.step_frac": 0.03456840519591797, "timer/env.step_avg": 0.009113584183113288, "timer/env.step_min": 0.007485628128051758, "timer/env.step_max": 0.0353236198425293, "timer/replay._sample_count": 30352.0, "timer/replay._sample_total": 15.343094110488892, "timer/replay._sample_frac": 0.015339307609509183, "timer/replay._sample_avg": 0.0005055052092280209, "timer/replay._sample_min": 0.00036525726318359375, "timer/replay._sample_max": 0.025925159454345703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5717.0, "timer/agent.policy_total": 58.716403007507324, "timer/agent.policy_frac": 0.0587019124675998, "timer/agent.policy_avg": 0.01027049204259355, "timer/agent.policy_min": 0.008760690689086914, "timer/agent.policy_max": 0.08742022514343262, "timer/dataset_train_count": 1897.0, "timer/dataset_train_total": 0.21274638175964355, "timer/dataset_train_frac": 0.0002126938783742663, "timer/dataset_train_avg": 0.00011214885701615369, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.00021982192993164062, "timer/agent.train_count": 1897.0, "timer/agent.train_total": 850.9074411392212, "timer/agent.train_frac": 0.8506974468684233, "timer/agent.train_avg": 0.4485542652288989, "timer/agent.train_min": 0.4366745948791504, "timer/agent.train_max": 0.6943693161010742, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4788212776184082, "timer/agent.report_frac": 0.0004787031099773997, "timer/agent.report_avg": 0.2394106388092041, "timer/agent.report_min": 0.23200273513793945, "timer/agent.report_max": 0.24681854248046875, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.337036361541424e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 30.344005859999836}
{"step": 942064, "time": 31222.08327817917, "episode/length": 640.0, "episode/score": 0.20684196285844791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20684196285844791}
{"step": 942304, "time": 31230.196378469467, "episode/length": 640.0, "episode/score": 0.24963891015340778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24963891015340778}
{"step": 942720, "time": 31243.22782945633, "episode/length": 640.0, "episode/score": 0.20631920385767444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20631920385767444}
{"step": 943936, "time": 31281.651058912277, "episode/length": 640.0, "episode/score": 0.20377258322514535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20377258322514535}
{"step": 944512, "time": 31300.125525712967, "episode/length": 640.0, "episode/score": 0.18675857003307783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18675857003307783}
{"step": 944768, "time": 31308.393552303314, "episode/length": 640.0, "episode/score": 0.11815567235328217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11815567235328217}
{"step": 945952, "time": 31345.643663167953, "episode/length": 640.0, "episode/score": 0.11772565378646505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11772565378646505}
{"step": 946544, "time": 31364.225350618362, "episode/length": 640.0, "episode/score": 0.15840035635187633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15840035635187633}
{"step": 947192, "time": 31384.4899828434, "episode/length": 640.0, "episode/score": 0.10697567899603655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10697567899603655}
{"step": 947432, "time": 31392.03010392189, "episode/length": 640.0, "episode/score": 0.2094498353505969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2094498353505969}
{"step": 947848, "time": 31405.21572446823, "episode/length": 640.0, "episode/score": 0.19731711271037966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19731711271037966}
{"step": 949064, "time": 31443.53524708748, "episode/length": 640.0, "episode/score": 0.1681302985815023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1681302985815023}
{"step": 949640, "time": 31462.016492128372, "episode/length": 640.0, "episode/score": 0.14099026708345264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14099026708345264}
{"step": 949896, "time": 31470.090085029602, "episode/length": 640.0, "episode/score": 0.06017348816652657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06017348816652657}
{"step": 950040, "time": 31486.522101402283, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31486.53106188774, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31486.53924679756, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31486.547622442245, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31486.55516409874, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31486.56267952919, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31486.5701713562, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 950040, "time": 31486.577730178833, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 951080, "time": 31519.94397354126, "episode/length": 640.0, "episode/score": 0.07030108274787494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07030108274787494}
{"step": 951672, "time": 31540.86261343956, "episode/length": 640.0, "episode/score": 0.152719321205808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.152719321205808}
{"step": 952320, "time": 31561.518007278442, "episode/length": 640.0, "episode/score": 0.16315876696805276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16315876696805276}
{"step": 952560, "time": 31569.077450037003, "episode/length": 640.0, "episode/score": 0.056301443311042476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056301443311042476}
{"step": 952976, "time": 31582.306701660156, "episode/length": 640.0, "episode/score": 0.126231806446242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.126231806446242}
{"step": 954192, "time": 31620.55828475952, "episode/length": 640.0, "episode/score": 0.23567474674678124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23567474674678124}
{"step": 954768, "time": 31638.64190554619, "episode/length": 640.0, "episode/score": 0.08803524061374901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08803524061374901}
{"step": 955024, "time": 31646.632246017456, "episode/length": 640.0, "episode/score": 0.1843471452787071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1843471452787071}
{"step": 956208, "time": 31684.501281023026, "episode/length": 640.0, "episode/score": 0.26167832913222355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26167832913222355}
{"step": 956800, "time": 31703.538268089294, "episode/length": 640.0, "episode/score": 0.2614567890523176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2614567890523176}
{"step": 957448, "time": 31724.02106666565, "episode/length": 640.0, "episode/score": 0.10836704617886994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10836704617886994}
{"step": 957688, "time": 31731.682316303253, "episode/length": 640.0, "episode/score": 0.22606029092119684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22606029092119684}
{"step": 958104, "time": 31744.74637913704, "episode/length": 640.0, "episode/score": 0.20627445437366987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20627445437366987}
{"step": 959320, "time": 31783.659470558167, "episode/length": 640.0, "episode/score": 0.2001840203854499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2001840203854499}
{"step": 959896, "time": 31802.022022485733, "episode/length": 640.0, "episode/score": 0.1775653905698391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1775653905698391}
{"step": 960024, "time": 31817.380192279816, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31817.38939166069, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31817.397934675217, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31817.406446695328, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31817.414580106735, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31817.422632455826, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31817.430697202682, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960024, "time": 31817.43904018402, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 960152, "time": 31821.47735929489, "episode/length": 640.0, "episode/score": 0.1669242896114156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1669242896114156}
{"step": 961336, "time": 31858.632435798645, "episode/length": 640.0, "episode/score": 0.15706925508357017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15706925508357017}
{"step": 961928, "time": 31877.315892457962, "episode/length": 640.0, "episode/score": 0.1622993794139802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1622993794139802}
{"step": 962576, "time": 31897.949204206467, "episode/length": 640.0, "episode/score": 0.19512720104171422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19512720104171422}
{"step": 962816, "time": 31905.449999332428, "episode/length": 640.0, "episode/score": 0.10205366883212719, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10205366883212719}
{"step": 963232, "time": 31918.58530664444, "episode/length": 640.0, "episode/score": 0.09946946228114939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09946946228114939}
{"step": 964448, "time": 31956.690449237823, "episode/length": 640.0, "episode/score": 0.24143038758199964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24143038758199964}
{"step": 965024, "time": 31974.789360523224, "episode/length": 640.0, "episode/score": 0.08789619426624995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08789619426624995}
{"step": 965280, "time": 31982.77672100067, "episode/length": 640.0, "episode/score": 0.08077697365274616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08077697365274616}
{"step": 966464, "time": 32019.95546936989, "episode/length": 640.0, "episode/score": 0.15254534667701591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15254534667701591}
{"step": 967056, "time": 32039.06893634796, "episode/length": 640.0, "episode/score": 0.12741338745661324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12741338745661324}
{"step": 967704, "time": 32059.460244178772, "episode/length": 640.0, "episode/score": 0.18106413447958403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18106413447958403}
{"step": 967944, "time": 32067.092812538147, "episode/length": 640.0, "episode/score": 0.26018352325218075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26018352325218075}
{"step": 968360, "time": 32080.12642788887, "episode/length": 640.0, "episode/score": 0.27128274002382113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27128274002382113}
{"step": 969576, "time": 32118.80084514618, "episode/length": 640.0, "episode/score": 0.19157380628462306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19157380628462306}
{"step": 970008, "time": 32139.462368249893, "eval_episode/length": 338.0, "eval_episode/score": 0.5246875286102295, "eval_episode/reward_rate": 0.0029498525073746312}
{"step": 970008, "time": 32145.033141851425, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 32145.043269872665, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 32145.05270600319, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 32145.061188936234, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 32145.069355010986, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 32145.077476024628, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970008, "time": 32145.085623025894, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 970152, "time": 32149.780458927155, "episode/length": 640.0, "episode/score": 0.1116365642423034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1116365642423034}
{"step": 970408, "time": 32157.82798743248, "episode/length": 640.0, "episode/score": 0.2573806194092185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2573806194092185}
{"step": 971592, "time": 32195.467171907425, "episode/length": 640.0, "episode/score": 0.18212538293380476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18212538293380476}
{"step": 971704, "time": 32199.07311987877, "episode/length": 580.0, "episode/score": 0.19941490512576365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19941490512576365}
{"step": 972137, "time": 32214.05346608162, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1999029862253288, "train/action_min": 0.0, "train/action_std": 1.8399452805519103, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0008007056772169706, "train/actor_opt_grad_steps": 59715.0, "train/actor_opt_loss": -5.974063392689353, "train/adv_mag": 0.07723554890406759, "train/adv_max": 0.005244962165230199, "train/adv_mean": 3.150986669371186e-05, "train/adv_min": -0.07704437406439531, "train/adv_std": 0.002312355758438475, "train/cont_avg": 0.9983706825657894, "train/cont_loss_mean": 0.002296094009714005, "train/cont_loss_std": 0.0549965837565986, "train/cont_neg_acc": 0.8099567119951372, "train/cont_neg_loss": 1.0568484715627224, "train/cont_pos_acc": 0.9999639730704458, "train/cont_pos_loss": 0.0004143531647921344, "train/cont_pred": 0.9983336718458878, "train/cont_rate": 0.9983706825657894, "train/dyn_loss_mean": 1.0000047388829683, "train/dyn_loss_std": 0.00014097877432696373, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03188729959932205, "train/extr_critic_critic_opt_grad_steps": 59715.0, "train/extr_critic_critic_opt_loss": 13478.575668174342, "train/extr_critic_mag": 0.09187836647033691, "train/extr_critic_max": 0.09187836647033691, "train/extr_critic_mean": 0.08793658159281079, "train/extr_critic_min": 0.08208446251718622, "train/extr_critic_std": 0.0015500676554725751, "train/extr_return_normed_mag": 0.07483358630224278, "train/extr_return_normed_max": 0.00972208066990501, "train/extr_return_normed_mean": 0.003176315191912612, "train/extr_return_normed_min": -0.07397981015475173, "train/extr_return_normed_std": 0.0028332298548009835, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0945138497964332, "train/extr_return_raw_max": 0.0945138497964332, "train/extr_return_raw_mean": 0.08796808907860204, "train/extr_return_raw_min": 0.01081195897177646, "train/extr_return_raw_std": 0.0028332298578645446, "train/extr_reward_mag": 0.0012609149280347323, "train/extr_reward_max": 0.0012609149280347323, "train/extr_reward_mean": 0.00026801769096269516, "train/extr_reward_min": 2.792634462055407e-06, "train/extr_reward_std": 0.000277614639689043, "train/image_loss_mean": 0.10763030820771267, "train/image_loss_std": 0.12221953449280638, "train/model_loss_mean": 0.7195879726033462, "train/model_loss_std": 0.15630937093182615, "train/model_opt_grad_norm": 17.517728649942498, "train/model_opt_grad_steps": 59663.20526315789, "train/model_opt_loss": 3692.5040180407073, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5131.578947368421, "train/policy_entropy_mag": 1.9403098802817496, "train/policy_entropy_max": 1.9403098802817496, "train/policy_entropy_mean": 1.6706297372516832, "train/policy_entropy_min": 0.6665203086639705, "train/policy_entropy_std": 0.1615534732216283, "train/policy_logprob_mag": 4.452794458991603, "train/policy_logprob_max": -0.1647861985391692, "train/policy_logprob_mean": -1.6709072056569552, "train/policy_logprob_min": -4.452794458991603, "train/policy_logprob_std": 0.72527880700011, "train/policy_randomness_mag": 0.9971220894863732, "train/policy_randomness_max": 0.9971220894863732, "train/policy_randomness_mean": 0.8585339034858502, "train/policy_randomness_min": 0.34252370188110753, "train/policy_randomness_std": 0.08302206722529311, "train/post_ent_mag": 36.11303118655556, "train/post_ent_max": 36.11303118655556, "train/post_ent_mean": 24.071704452916194, "train/post_ent_min": 13.575182944849917, "train/post_ent_std": 4.664370546842877, "train/prior_ent_mag": 37.1013041646857, "train/prior_ent_max": 37.1013041646857, "train/prior_ent_mean": 24.18023262023926, "train/prior_ent_min": 14.644584058460437, "train/prior_ent_std": 4.705271673202515, "train/rep_loss_mean": 1.0000047388829683, "train/rep_loss_std": 0.00014097877432696373, "train/reward_avg": 0.0002221293613394281, "train/reward_loss_mean": 0.009658704876997753, "train/reward_loss_std": 0.013927573426381538, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012284981577019942, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009658704864743508, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022433278592009294, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.6727459356188774, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.00026921764947474003, "report/cont_loss_std": 0.0009608924156054854, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000186840450624004, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00026937888469547033, "report/cont_pred": 0.9977788925170898, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10001148283481598, "report/image_loss_std": 0.12240587174892426, "report/model_loss_mean": 0.7083458304405212, "report/model_loss_std": 0.1264737844467163, "report/post_ent_mag": 38.313331604003906, "report/post_ent_max": 38.313331604003906, "report/post_ent_mean": 24.57196807861328, "report/post_ent_min": 11.801666259765625, "report/post_ent_std": 5.530671119689941, "report/prior_ent_mag": 38.521141052246094, "report/prior_ent_max": 38.521141052246094, "report/prior_ent_mean": 25.092924118041992, "report/prior_ent_min": 14.109824180603027, "report/prior_ent_std": 5.192032337188721, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018176838057115674, "report/reward_loss_mean": 0.008065085858106613, "report/reward_loss_std": 0.012702790088951588, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012079477310180664, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008065085858106613, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00018103932961821556, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.021315308287739754, "eval/cont_loss_std": 0.4673328697681427, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.48834228515625, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0008318855543620884, "eval/cont_pred": 0.9991841316223145, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.30932164192199707, "eval/image_loss_std": 0.15517868101596832, "eval/model_loss_mean": 0.9320595264434814, "eval/model_loss_std": 0.5008907318115234, "eval/post_ent_mag": 38.12676239013672, "eval/post_ent_max": 38.12676239013672, "eval/post_ent_mean": 22.450130462646484, "eval/post_ent_min": 11.917001724243164, "eval/post_ent_std": 5.494330883026123, "eval/prior_ent_mag": 37.899559020996094, "eval/prior_ent_max": 37.899559020996094, "eval/prior_ent_mean": 23.24366569519043, "eval/prior_ent_min": 15.076059341430664, "eval/prior_ent_std": 5.089478015899658, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014225444756448269, "eval/reward_loss_std": 0.001435031066648662, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001093149185180664, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014225444756448269, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022376247216016054, "eval/reward_rate": 0.0, "replay/size": 971633.0, "replay/inserts": 30320.0, "replay/samples": 30320.0, "replay/insert_wait_avg": 1.2940498643940546e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.374138054558344e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1003457563839662e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0026624202728, "timer/env.step_count": 3790.0, "timer/env.step_total": 34.184821128845215, "timer/env.step_frac": 0.03418473011472674, "timer/env.step_avg": 0.009019741722650453, "timer/env.step_min": 0.007299184799194336, "timer/env.step_max": 0.034816741943359375, "timer/replay._sample_count": 30320.0, "timer/replay._sample_total": 15.159801721572876, "timer/replay._sample_frac": 0.0151597613599169, "timer/replay._sample_avg": 0.0004999934604740394, "timer/replay._sample_min": 0.00038552284240722656, "timer/replay._sample_max": 0.011134862899780273, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5713.0, "timer/agent.policy_total": 58.34709692001343, "timer/agent.policy_frac": 0.05834694157593332, "timer/agent.policy_avg": 0.01021303989497872, "timer/agent.policy_min": 0.008670568466186523, "timer/agent.policy_max": 0.09170413017272949, "timer/dataset_train_count": 1895.0, "timer/dataset_train_total": 0.21029233932495117, "timer/dataset_train_frac": 0.00021029177943985438, "timer/dataset_train_avg": 0.0001109722107255679, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0002529621124267578, "timer/agent.train_count": 1895.0, "timer/agent.train_total": 851.7143466472626, "timer/agent.train_frac": 0.8517120790317567, "timer/agent.train_avg": 0.44945348108034966, "timer/agent.train_min": 0.4344189167022705, "timer/agent.train_max": 2.7172963619232178, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48289942741394043, "timer/agent.report_frac": 0.0004828981417361382, "timer/agent.report_avg": 0.24144971370697021, "timer/agent.report_min": 0.23583650588989258, "timer/agent.report_max": 0.24706292152404785, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.552427370558632e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 30.31936978015529}
{"step": 972832, "time": 32236.062864780426, "episode/length": 640.0, "episode/score": 0.1477582695019919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1477582695019919}
{"step": 973072, "time": 32243.852264881134, "episode/length": 640.0, "episode/score": 0.21538926744364062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21538926744364062}
{"step": 973488, "time": 32256.976511240005, "episode/length": 640.0, "episode/score": 0.18683965345951492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18683965345951492}
{"step": 974704, "time": 32295.358557462692, "episode/length": 640.0, "episode/score": 0.24022866858797443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24022866858797443}
{"step": 975280, "time": 32314.102892637253, "episode/length": 640.0, "episode/score": 0.18345884119423772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18345884119423772}
{"step": 975536, "time": 32322.163917779922, "episode/length": 640.0, "episode/score": 0.2618238930318171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2618238930318171}
{"step": 976720, "time": 32359.698230981827, "episode/length": 640.0, "episode/score": 0.210913960573464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.210913960573464}
{"step": 976832, "time": 32363.23174214363, "episode/length": 640.0, "episode/score": 0.23190894210910074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23190894210910074}
{"step": 977960, "time": 32398.55297255516, "episode/length": 640.0, "episode/score": 0.22905754642891907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22905754642891907}
{"step": 978200, "time": 32406.139246225357, "episode/length": 640.0, "episode/score": 0.21809437513252306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21809437513252306}
{"step": 978616, "time": 32419.36171889305, "episode/length": 640.0, "episode/score": 0.15380806849776718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15380806849776718}
{"step": 979832, "time": 32457.754925251007, "episode/length": 640.0, "episode/score": 0.19379263545579306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19379263545579306}
{"step": 980096, "time": 32478.339262485504, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32478.348222255707, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32478.356365442276, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32478.364085435867, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32478.371658086777, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32478.379268169403, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32478.386986255646, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980096, "time": 32478.39493751526, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 980408, "time": 32487.964718580246, "episode/length": 640.0, "episode/score": 0.17807524945615683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17807524945615683}
{"step": 980664, "time": 32496.044446706772, "episode/length": 640.0, "episode/score": 0.14426693221804499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14426693221804499}
{"step": 981848, "time": 32533.544711589813, "episode/length": 640.0, "episode/score": 0.23516789113983805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23516789113983805}
{"step": 981960, "time": 32537.1599714756, "episode/length": 640.0, "episode/score": 0.08727918366909648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08727918366909648}
{"step": 983088, "time": 32573.618695497513, "episode/length": 640.0, "episode/score": 0.22163112945511898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22163112945511898}
{"step": 983328, "time": 32581.290363788605, "episode/length": 640.0, "episode/score": 0.21522016494697027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21522016494697027}
{"step": 983744, "time": 32594.575058698654, "episode/length": 640.0, "episode/score": 0.12253156503055607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12253156503055607}
{"step": 984960, "time": 32633.66056585312, "episode/length": 640.0, "episode/score": 0.21447186012233033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21447186012233033}
{"step": 985536, "time": 32651.830512285233, "episode/length": 640.0, "episode/score": 0.26960787194627756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26960787194627756}
{"step": 985792, "time": 32659.973113536835, "episode/length": 640.0, "episode/score": 0.26115242278112305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26115242278112305}
{"step": 986976, "time": 32697.657729387283, "episode/length": 640.0, "episode/score": 0.2189986691711283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2189986691711283}
{"step": 987088, "time": 32701.212082624435, "episode/length": 640.0, "episode/score": 0.17310075336160935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17310075336160935}
{"step": 988216, "time": 32736.97948050499, "episode/length": 640.0, "episode/score": 0.1278138455362523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1278138455362523}
{"step": 988456, "time": 32744.543652057648, "episode/length": 640.0, "episode/score": 0.22309384500067608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22309384500067608}
{"step": 988872, "time": 32757.646789312363, "episode/length": 640.0, "episode/score": 0.20910215028823131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20910215028823131}
{"step": 990080, "time": 32808.6815636158, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32808.691215753555, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32808.70012784004, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32808.71256351471, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32808.72129201889, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32808.73003935814, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32808.73832368851, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990080, "time": 32808.746502161026, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 990088, "time": 32808.787346839905, "episode/length": 640.0, "episode/score": 0.1714195014337747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1714195014337747}
{"step": 990664, "time": 32827.253029584885, "episode/length": 640.0, "episode/score": 0.11355944211823044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11355944211823044}
{"step": 990920, "time": 32835.33160281181, "episode/length": 640.0, "episode/score": 0.21548827953961336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21548827953961336}
{"step": 992104, "time": 32873.514795064926, "episode/length": 640.0, "episode/score": 0.13050504560976606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13050504560976606}
{"step": 992216, "time": 32877.067249298096, "episode/length": 640.0, "episode/score": 0.15357143969310982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15357143969310982}
{"step": 993344, "time": 32912.79558944702, "episode/length": 640.0, "episode/score": 0.10426393257876043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10426393257876043}
{"step": 993584, "time": 32920.34734463692, "episode/length": 640.0, "episode/score": 0.0745235550630241, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0745235550630241}
{"step": 994000, "time": 32933.39306163788, "episode/length": 640.0, "episode/score": 0.0918342223720856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0918342223720856}
{"step": 995216, "time": 32972.04268813133, "episode/length": 640.0, "episode/score": 0.1978438116276493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1978438116276493}
{"step": 995792, "time": 32990.36554479599, "episode/length": 640.0, "episode/score": 0.1221994711137313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1221994711137313}
{"step": 996048, "time": 32998.555436849594, "episode/length": 640.0, "episode/score": 0.06866805728259351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06866805728259351}
{"step": 997232, "time": 33036.36867523193, "episode/length": 640.0, "episode/score": 0.1442210845708587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1442210845708587}
{"step": 997344, "time": 33039.883650541306, "episode/length": 640.0, "episode/score": 0.14597775582404893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14597775582404893}
{"step": 998008, "time": 33060.572556734085, "episode/length": 500.0, "episode/score": 0.20528613072701773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20528613072701773}
{"step": 998472, "time": 33075.385570287704, "episode/length": 640.0, "episode/score": 0.16204576907239243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16204576907239243}
{"step": 998712, "time": 33083.1271879673, "episode/length": 640.0, "episode/score": 0.1340456897481772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1340456897481772}
{"step": 1000064, "time": 33139.325449705124, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 33139.33493709564, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 33139.34423494339, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 33139.35332989693, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 33139.36174201965, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 33139.37002801895, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 33139.3783082962, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 33139.38642311096, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000344, "time": 33147.94803071022, "episode/length": 640.0, "episode/score": 0.24881217132957545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24881217132957545}
{"step": 1000752, "time": 33161.10812830925, "episode/length": 254.0, "episode/score": 0.10552290340677928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10552290340677928}
{"step": 1000920, "time": 33166.35710430145, "episode/length": 640.0, "episode/score": 0.20395012668780055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20395012668780055}
{"step": 1001176, "time": 33174.48581409454, "episode/length": 640.0, "episode/score": 0.2692728989187003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2692728989187003}
{"step": 1002360, "time": 33212.05306124687, "episode/length": 640.0, "episode/score": 0.21917442330254744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21917442330254744}
{"step": 1002393, "time": 33214.08630490303, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.201800311053241, "train/action_min": 0.0, "train/action_std": 1.8182501427080267, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007988650928603771, "train/actor_opt_grad_steps": 61610.0, "train/actor_opt_loss": -6.4774504411945895, "train/adv_mag": 0.07245435983573319, "train/adv_max": 0.005017237491393215, "train/adv_mean": 1.3752843875365562e-07, "train/adv_min": -0.07218646293594724, "train/adv_std": 0.002291377646129125, "train/cont_avg": 0.9985170717592593, "train/cont_loss_mean": 0.002257338073197013, "train/cont_loss_std": 0.057027626572769365, "train/cont_neg_acc": 0.8029316509662031, "train/cont_neg_loss": 1.0952336177542994, "train/cont_pos_acc": 0.9999481855876862, "train/cont_pos_loss": 0.0004429105952906881, "train/cont_pred": 0.998465515318371, "train/cont_rate": 0.9985170717592593, "train/dyn_loss_mean": 1.0000150039713218, "train/dyn_loss_std": 0.00038321309374329983, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03403177123489696, "train/extr_critic_critic_opt_grad_steps": 61610.0, "train/extr_critic_critic_opt_loss": 13473.153061962632, "train/extr_critic_mag": 0.09230069823996731, "train/extr_critic_max": 0.09230069823996731, "train/extr_critic_mean": 0.08848498477822259, "train/extr_critic_min": 0.0827299022169971, "train/extr_critic_std": 0.0015281528886161232, "train/extr_return_normed_mag": 0.07042283206074326, "train/extr_return_normed_max": 0.009513447327273232, "train/extr_return_normed_mean": 0.003148290880576328, "train/extr_return_normed_min": -0.06917863839833194, "train/extr_return_normed_std": 0.0028103952457458176, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09485029902250047, "train/extr_return_raw_max": 0.09485029902250047, "train/extr_return_raw_mean": 0.08848514754778494, "train/extr_return_raw_min": 0.016158213296895305, "train/extr_return_raw_std": 0.0028103952334267357, "train/extr_reward_mag": 0.0012622472470399564, "train/extr_reward_max": 0.0012622472470399564, "train/extr_reward_mean": 0.00026726638054396347, "train/extr_reward_min": 2.841470102784495e-06, "train/extr_reward_std": 0.0002768610499549174, "train/image_loss_mean": 0.10546055183839545, "train/image_loss_std": 0.1213864462164344, "train/model_loss_mean": 0.7173312243330415, "train/model_loss_std": 0.15663326511938105, "train/model_opt_grad_norm": 16.880153466784765, "train/model_opt_grad_steps": 61556.34391534392, "train/model_opt_loss": 3662.137081731564, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5105.820105820106, "train/policy_entropy_mag": 1.940157761018743, "train/policy_entropy_max": 1.940157761018743, "train/policy_entropy_mean": 1.6737602305790735, "train/policy_entropy_min": 0.6849978539363417, "train/policy_entropy_std": 0.1595929199583316, "train/policy_logprob_mag": 4.48193005153111, "train/policy_logprob_max": -0.16992511690924408, "train/policy_logprob_mean": -1.6736258135901556, "train/policy_logprob_min": -4.48193005153111, "train/policy_logprob_std": 0.7212063771076304, "train/policy_randomness_mag": 0.9970439158419453, "train/policy_randomness_max": 0.9970439158419453, "train/policy_randomness_mean": 0.860142658311854, "train/policy_randomness_min": 0.3520192825604999, "train/policy_randomness_std": 0.08201454244751148, "train/post_ent_mag": 36.45897290063283, "train/post_ent_max": 36.45897290063283, "train/post_ent_mean": 23.976174944923038, "train/post_ent_min": 13.066264102067898, "train/post_ent_std": 4.836094847431889, "train/prior_ent_mag": 37.18851208560681, "train/prior_ent_max": 37.18851208560681, "train/prior_ent_mean": 24.288590153689107, "train/prior_ent_min": 14.594307949934056, "train/prior_ent_std": 4.895272189347201, "train/rep_loss_mean": 1.0000150039713218, "train/rep_loss_std": 0.00038321309374329983, "train/reward_avg": 0.00022106897008910816, "train/reward_loss_mean": 0.009604308266370069, "train/reward_loss_std": 0.01397031303692274, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012365289466090934, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009604308244195722, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.00022419674504331496, "train/reward_rate": 0.0, "train_stats/mean_log_entropy": 1.6703689446051915, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.0005664540221914649, "report/cont_loss_std": 0.0016646181466057897, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0014848207356408238, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0005655562272295356, "report/cont_pred": 0.9984613656997681, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10362082719802856, "report/image_loss_std": 0.12734559178352356, "report/model_loss_mean": 0.7135328650474548, "report/model_loss_std": 0.13072015345096588, "report/post_ent_mag": 32.31371307373047, "report/post_ent_max": 32.31371307373047, "report/post_ent_mean": 22.893680572509766, "report/post_ent_min": 12.443885803222656, "report/post_ent_std": 3.9173269271850586, "report/prior_ent_mag": 34.10020446777344, "report/prior_ent_max": 34.10020446777344, "report/prior_ent_mean": 23.028888702392578, "report/prior_ent_min": 13.723344802856445, "report/prior_ent_std": 4.023258686065674, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002136703988071531, "report/reward_loss_mean": 0.009345600381493568, "report/reward_loss_std": 0.013314635492861271, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012447834014892578, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009345600381493568, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002416039351373911, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.011454708874225616, "eval/cont_loss_std": 0.27421608567237854, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.632990837097168, "eval/cont_pos_acc": 0.9990224838256836, "eval/cont_pos_loss": 0.003027010941877961, "eval/cont_pred": 0.9977957010269165, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2841053009033203, "eval/image_loss_std": 0.1424223780632019, "eval/model_loss_mean": 0.8971635103225708, "eval/model_loss_std": 0.30976206064224243, "eval/post_ent_mag": 32.11402130126953, "eval/post_ent_max": 32.11402130126953, "eval/post_ent_mean": 20.761947631835938, "eval/post_ent_min": 11.903051376342773, "eval/post_ent_std": 3.9232876300811768, "eval/prior_ent_mag": 33.58787155151367, "eval/prior_ent_max": 33.58787155151367, "eval/prior_ent_mean": 20.845672607421875, "eval/prior_ent_min": 14.103887557983398, "eval/prior_ent_std": 3.8487026691436768, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001603513490408659, "eval/reward_loss_std": 0.001579874660819769, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0012423992156982422, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001603513490408659, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00025219807866960764, "eval/reward_rate": 0.0, "replay/size": 1000000.0, "replay/inserts": 30256.0, "replay/samples": 30256.0, "replay/insert_wait_avg": 1.3015860921172854e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.32739297452268e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 15384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1204929322050812e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0067496299744, "timer/env.step_count": 3782.0, "timer/env.step_total": 34.451796531677246, "timer/env.step_frac": 0.034451563996368235, "timer/env.step_avg": 0.009109412091929468, "timer/env.step_min": 0.00744318962097168, "timer/env.step_max": 0.03534269332885742, "timer/replay._sample_count": 30256.0, "timer/replay._sample_total": 15.0343177318573, "timer/replay._sample_frac": 0.015034216256460614, "timer/replay._sample_avg": 0.0004969036796621265, "timer/replay._sample_min": 0.00040435791015625, "timer/replay._sample_max": 0.009334564208984375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5705.0, "timer/agent.policy_total": 58.93471002578735, "timer/agent.policy_frac": 0.058934312240986934, "timer/agent.policy_avg": 0.010330361091286128, "timer/agent.policy_min": 0.008709430694580078, "timer/agent.policy_max": 0.08832621574401855, "timer/dataset_train_count": 1891.0, "timer/dataset_train_total": 0.20960378646850586, "timer/dataset_train_frac": 0.00020960237173005494, "timer/dataset_train_avg": 0.00011084282732337697, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.00041794776916503906, "timer/agent.train_count": 1891.0, "timer/agent.train_total": 850.0072815418243, "timer/agent.train_frac": 0.8500015443459223, "timer/agent.train_avg": 0.44950147093697745, "timer/agent.train_min": 0.43642592430114746, "timer/agent.train_max": 0.5904707908630371, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4832427501678467, "timer/agent.report_frac": 0.0004832394884801104, "timer/agent.report_avg": 0.24162137508392334, "timer/agent.report_min": 0.23604869842529297, "timer/agent.report_max": 0.2471940517425537, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9563704264529294e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 30.25526260847565}
{"step": 1002472, "time": 33216.33630156517, "episode/length": 640.0, "episode/score": 0.21351422418968014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21351422418968014}
{"step": 1003136, "time": 33237.87512302399, "episode/length": 640.0, "episode/score": 0.10919576759175698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10919576759175698}
{"step": 1003600, "time": 33252.68556571007, "episode/length": 640.0, "episode/score": 0.1891824630893666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1891824630893666}
{"step": 1004104, "time": 33268.40293312073, "episode/length": 217.0, "episode/score": 0.0758785539169935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0758785539169935}
{"step": 1005472, "time": 33311.7951567173, "episode/length": 640.0, "episode/score": 0.18335454413733032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18335454413733032}
{"step": 1005880, "time": 33324.64987492561, "episode/length": 640.0, "episode/score": 0.24484870448853258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24484870448853258}
{"step": 1006048, "time": 33330.12747168541, "episode/length": 640.0, "episode/score": 0.20839787989908132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20839787989908132}
{"step": 1006304, "time": 33338.16255450249, "episode/length": 640.0, "episode/score": 0.18700634220235202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18700634220235202}
{"step": 1007600, "time": 33379.114027023315, "episode/length": 640.0, "episode/score": 0.24387879928016787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24387879928016787}
{"step": 1008264, "time": 33400.30146551132, "episode/length": 640.0, "episode/score": 0.18591842672128678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18591842672128678}
{"step": 1008728, "time": 33415.067528009415, "episode/length": 640.0, "episode/score": 0.19467392519896976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19467392519896976}
{"step": 1009232, "time": 33431.22001695633, "episode/length": 640.0, "episode/score": 0.20032408520202694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20032408520202694}
{"step": 1010048, "time": 33464.58112573624, "eval_episode/length": 431.0, "eval_episode/score": 0.39390623569488525, "eval_episode/reward_rate": 0.0023148148148148147}
{"step": 1010048, "time": 33465.15778040886, "eval_episode/length": 464.0, "eval_episode/score": 0.3474999964237213, "eval_episode/reward_rate": 0.002150537634408602}
{"step": 1010048, "time": 33468.94377422333, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 33468.952432870865, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 33468.96036076546, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 33468.96819448471, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 33468.975633859634, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010048, "time": 33468.98377203941, "eval_episode/length": 640.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1010600, "time": 33486.116567373276, "episode/length": 640.0, "episode/score": 0.07973636650703497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07973636650703497}
{"step": 1011008, "time": 33499.26515698433, "episode/length": 640.0, "episode/score": 0.16299714225857542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16299714225857542}
{"step": 1011176, "time": 33504.402789354324, "episode/length": 640.0, "episode/score": 0.12415614286106802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12415614286106802}
{"step": 1011432, "time": 33512.52854704857, "episode/length": 640.0, "episode/score": 0.13855818622567995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13855818622567995}
{"step": 1012728, "time": 33553.767374038696, "episode/length": 640.0, "episode/score": 0.21412465634719524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21412465634719524}
{"step": 1013392, "time": 33575.260701179504, "episode/length": 640.0, "episode/score": 0.04507135822262853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04507135822262853}
{"step": 1013856, "time": 33590.032346725464, "episode/length": 640.0, "episode/score": 0.18886139829172066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18886139829172066}
{"step": 1014360, "time": 33605.918644189835, "episode/length": 640.0, "episode/score": 0.201974500010067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.201974500010067}
{"step": 1015728, "time": 33649.93427109718, "episode/length": 640.0, "episode/score": 0.10380416691069172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10380416691069172}
{"step": 1016136, "time": 33663.05862927437, "episode/length": 640.0, "episode/score": 0.106822768032373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.106822768032373}
{"step": 1016304, "time": 33668.535370111465, "episode/length": 640.0, "episode/score": 0.22093995803723487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22093995803723487}
{"step": 1016560, "time": 33676.66021633148, "episode/length": 640.0, "episode/score": 0.22319622905541792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22319622905541792}
{"step": 1017856, "time": 33717.493455410004, "episode/length": 640.0, "episode/score": 0.21703895141365592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21703895141365592}
{"step": 1018520, "time": 33738.24205994606, "episode/length": 640.0, "episode/score": 0.21483332462059934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21483332462059934}
{"step": 1018984, "time": 33752.80038833618, "episode/length": 640.0, "episode/score": 0.1915195071794642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1915195071794642}
{"step": 1019488, "time": 33769.03235435486, "episode/length": 640.0, "episode/score": 0.18632211780391117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18632211780391117}
